name repository,creator user,url_html issue,url_api issue,title,body,state,pull request,data open,updated at
perf-tests,girishkalele,https://github.com/kubernetes/perf-tests/pull/1,https://api.github.com/repos/kubernetes/perf-tests/issues/1,Network Performance Benchmarks,"Moved changes from PR https://github.com/kubernetes/kubernetes/pull/28136 here.
",closed,True,2016-09-21 22:02:29,2016-09-23 05:01:35
perf-tests,girishkalele,https://github.com/kubernetes/perf-tests/pull/2,https://api.github.com/repos/kubernetes/perf-tests/issues/2,DNSPerf container build and Job yaml,"Moving dnsperf changes from contrib repository here.

https://github.com/kubernetes/contrib/pull/1189
",closed,True,2016-09-21 22:09:07,2016-09-23 05:01:04
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/3,https://api.github.com/repos/kubernetes/perf-tests/issues/3,First version of boilerplate files,"cc @timothysc @wojtek-t 
",closed,True,2016-09-26 10:15:28,2016-09-26 17:25:30
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/issues/4,https://api.github.com/repos/kubernetes/perf-tests/issues/4,Move performance-related e2e tests to this repo,"Is is currently possible to have e2e tests in a separate repo, or do they need to sit in main kubernetes one? @kubernetes/test-infra-maintainers 

cc @timothysc @wojtek-t 
",closed,False,2016-09-26 10:24:49,2018-02-16 00:47:02
perf-tests,jeremyeder,https://github.com/kubernetes/perf-tests/issues/5,https://api.github.com/repos/kubernetes/perf-tests/issues/5,Basic needs for this repo to be useful,"At least:
- Which sig owns this repository
- An architecture discussion
- An agreed-upon automation framework
- Modularized to support also running on distributions of Kubernetes
- Modularized so there is no dependency on any cloud/infra
- Some understanding of how the merge queue works...don't want delays.
- Discussion around what tests to move from e2e
- CI of the tests within the repo
- Policy of unit tests for the tests themselves
- CI of running the tests themselves
- Does this repository depend on kubernetes e2e tests
  - Can this repository import useful framework helpers/functions from e2e
",closed,False,2016-09-26 15:14:47,2017-12-28 11:58:41
perf-tests,zilman,https://github.com/kubernetes/perf-tests/issues/6,https://api.github.com/repos/kubernetes/perf-tests/issues/6,Missing some files,"In [dnsperf](https://github.com/kubernetes/perf-tests/tree/master/dns/dnsperf):

> Change the completions and parallelism parameters in the dnsperf-job.yaml file to increase the number of test pods.

But no such file.

In [netperf](https://github.com/kubernetes/perf-tests/tree/master/network/benchmarks/netperf) the images directory is missing so the graphics in the readme don't show up.
",closed,False,2016-09-26 17:51:05,2018-02-16 00:47:03
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/issues/7,https://api.github.com/repos/kubernetes/perf-tests/issues/7,Setup mungers for this repo,"We need a couple of mungers running in this repo:
- CLA bot
- build/gofmt/golint bot
- unit test bot (we'll probably have some unit tests for frameworks here)

cc @kubernetes/sig-scalability @apelisse
",closed,False,2016-10-04 08:37:33,2017-12-28 12:00:01
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/8,https://api.github.com/repos/kubernetes/perf-tests/issues/8,Add basic verify scripts,"Copied scripts from `test-infra` and `contrib`

cc @timothysc @apelisse 
",closed,True,2016-10-06 10:38:13,2016-10-06 12:36:16
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/9,https://api.github.com/repos/kubernetes/perf-tests/issues/9,Add travis config to perf-tests,"cc @spxtr @timothysc 
",closed,True,2016-10-06 12:42:26,2016-10-06 12:45:30
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/10,https://api.github.com/repos/kubernetes/perf-tests/issues/10,test,,closed,True,2016-10-06 12:47:09,2016-10-20 09:38:22
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/11,https://api.github.com/repos/kubernetes/perf-tests/issues/11,"Travis config, attempt 2",,closed,True,2016-10-06 13:03:41,2016-10-06 13:04:57
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/12,https://api.github.com/repos/kubernetes/perf-tests/issues/12,hack -> verify,,closed,True,2016-10-06 13:07:47,2016-10-06 13:08:42
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/13,https://api.github.com/repos/kubernetes/perf-tests/issues/13,hack->verify again,,closed,True,2016-10-06 13:22:43,2016-10-06 13:23:27
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/14,https://api.github.com/repos/kubernetes/perf-tests/issues/14,and again,,closed,True,2016-10-06 13:26:43,2016-10-06 13:26:46
perf-tests,bowei,https://github.com/kubernetes/perf-tests/pull/15,https://api.github.com/repos/kubernetes/perf-tests/issues/15,Adds dns/perf framework for running performance DNS benchmarks,"Adds a performance testing framework for Kubernetes DNS.

- Python performance runner
- Build for dnsperf docker image",closed,True,2016-12-01 08:30:09,2016-12-06 23:04:37
perf-tests,sjug,https://github.com/kubernetes/perf-tests/pull/16,https://api.github.com/repos/kubernetes/perf-tests/issues/16,Cluster Loader initial,"This is the Cluster Loader tool based on e2e/framework, but extracted out of kubernetes main repo. Let me know your suggestions for improvement.

/cc @timothysc @gmarek @spiffxp @jayunit100 @jeremyeder ",closed,True,2016-12-07 20:58:37,2017-01-05 17:29:11
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/17,https://api.github.com/repos/kubernetes/perf-tests/issues/17,Generate godep for network,"This should help with travis.

cc @jeremyeder",closed,True,2016-12-13 15:44:10,2016-12-17 00:44:19
perf-tests,bowei,https://github.com/kubernetes/perf-tests/pull/18,https://api.github.com/repos/kubernetes/perf-tests/issues/18,Fix image path,Looks like this was somehow missed,closed,True,2016-12-15 20:24:16,2016-12-21 02:07:06
perf-tests,CodeJuan,https://github.com/kubernetes/perf-tests/issues/19,https://api.github.com/repos/kubernetes/perf-tests/issues/19,"404, network/benchmarks/netperf/images/BenchmarkingKubernetesNetworkingPerformance.svg","In [network/benchmarks/netperf/README.md](https://github.com/kubernetes/perf-tests/blob/master/network/benchmarks/netperf/README.md), the urls of 
[svg, e.g. netperf.svg & BenchmarkingKubernetesNetworkingPerformance.svg](https://github.com/kubernetes/perf-tests/raw/master/network/benchmarks/netperf/images/netperf.svg) are 404

Thanks :smile: 
",closed,False,2017-01-03 02:11:27,2018-02-19 11:07:59
perf-tests,sjug,https://github.com/kubernetes/perf-tests/pull/20,https://api.github.com/repos/kubernetes/perf-tests/issues/20,Additional functionality to enable workload generation,"Functions will pass CL config parameters to pods as environment variables on creation. Some functionality to get cluster state. Small HTTP function to support synchronized tests.

/cc @timothysc @gmarek @spiffxp @jayunit100 @jeremyeder",closed,True,2017-01-12 21:25:21,2017-06-23 11:50:52
perf-tests,orangefuzzball,https://github.com/kubernetes/perf-tests/issues/21,https://api.github.com/repos/kubernetes/perf-tests/issues/21,Docker image ``girishkalele/netperf-latest`` has mssStepSize set to 1 not 64,"Attempting to run the netperf tests, the image ``girishkalele/netperf-latest`` is pulled.  If you look at the output, mssStepSize appears to be set to 1, not 64.  That will make the tests take *forever*.

```bash
Received TCP output from worker netperf-w1 for test 2 iperf TCP. Same VM using Virtual IP from netperf-w1 to netperf-w2 MSS: 117
Connecting to host 100.70.29.66, port 5201
[  4] local 100.96.2.16 port 60848 connected to 100.70.29.66 port 5201
[  6] local 100.96.2.16 port 60850 connected to 100.70.29.66 port 5201
[  8] local 100.96.2.16 port 60852 connected to 100.70.29.66 port 5201
[ 10] local 100.96.2.16 port 60854 connected to 100.70.29.66 port 5201
[ 12] local 100.96.2.16 port 60856 connected to 100.70.29.66 port 5201
[ 14] local 100.96.2.16 port 60858 connected to 100.70.29.66 port 5201
[ 16] local 100.96.2.16 port 60860 connected to 100.70.29.66 port 5201
[ 18] local 100.96.2.16 port 60862 connected to 100.70.29.66 port 5201
[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd
[  4]   0.00-10.00  sec  2.90 GBytes  2492 Mbits/sec   12    166 KBytes       
[  6]   0.00-10.00  sec  2.90 GBytes  2492 Mbits/sec    2    175 KBytes       
[  8]   0.00-10.00  sec  2.90 GBytes  2491 Mbits/sec    5    166 KBytes       
[ 10]   0.00-10.00  sec  2.90 GBytes  2490 Mbits/sec    6    227 KBytes       
[ 12]   0.00-10.00  sec  2.90 GBytes  2487 Mbits/sec    1    166 KBytes       
[ 14]   0.00-10.00  sec  2.89 GBytes  2486 Mbits/sec    6    227 KBytes       
[ 16]   0.00-10.00  sec  2.89 GBytes  2485 Mbits/sec    2    166 KBytes       
[ 18]   0.00-10.00  sec  2.89 GBytes  2484 Mbits/sec    5    227 KBytes       
[SUM]   0.00-10.00  sec  23.2 GBytes  19909 Mbits/sec   39             
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth       Retr
[  4]   0.00-10.00  sec  2.90 GBytes  2492 Mbits/sec   12             sender
[  4]   0.00-10.00  sec  2.90 GBytes  2492 Mbits/sec                  receiver
[  6]   0.00-10.00  sec  2.90 GBytes  2492 Mbits/sec    2             sender
[  6]   0.00-10.00  sec  2.90 GBytes  2492 Mbits/sec                  receiver
[  8]   0.00-10.00  sec  2.90 GBytes  2491 Mbits/sec    5             sender
[  8]   0.00-10.00  sec  2.90 GBytes  2491 Mbits/sec                  receiver
[ 10]   0.00-10.00  sec  2.90 GBytes  2490 Mbits/sec    6             sender
[ 10]   0.00-10.00  sec  2.90 GBytes  2490 Mbits/sec                  receiver
[ 12]   0.00-10.00  sec  2.90 GBytes  2488 Mbits/sec    1             sender
[ 12]   0.00-10.00  sec  2.90 GBytes  2488 Mbits/sec                  receiver
[ 14]   0.00-10.00  sec  2.89 GBytes  2486 Mbits/sec    6             sender
[ 14]   0.00-10.00  sec  2.89 GBytes  2486 Mbits/sec                  receiver
[ 16]   0.00-10.00  sec  2.89 GBytes  2485 Mbits/sec    2             sender
[ 16]   0.00-10.00  sec  2.89 GBytes  2485 Mbits/sec                  receiver
[ 18]   0.00-10.00  sec  2.89 GBytes  2484 Mbits/sec    5             sender
[ 18]   0.00-10.00  sec  2.89 GBytes  2484 Mbits/sec                  receiver
[SUM]   0.00-10.00  sec  23.2 GBytes  19909 Mbits/sec   39             sender
[SUM]   0.00-10.00  sec  23.2 GBytes  19909 Mbits/sec                  receiver

iperf Done.
Received TCP output from worker netperf-w1 for test 2 iperf TCP. Same VM using Virtual IP from netperf-w1 to netperf-w2 MSS: 118
Connecting to host 100.70.29.66, port 5201
[  4] local 100.96.2.16 port 60890 connected to 100.70.29.66 port 5201
[  6] local 100.96.2.16 port 60892 connected to 100.70.29.66 port 5201
[  8] local 100.96.2.16 port 60894 connected to 100.70.29.66 port 5201
[ 10] local 100.96.2.16 port 60896 connected to 100.70.29.66 port 5201
[ 12] local 100.96.2.16 port 60898 connected to 100.70.29.66 port 5201
[ 14] local 100.96.2.16 port 60900 connected to 100.70.29.66 port 5201
[ 16] local 100.96.2.16 port 60902 connected to 100.70.29.66 port 5201
[ 18] local 100.96.2.16 port 60904 connected to 100.70.29.66 port 5201
[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd
[  4]   0.00-10.00  sec  2.98 GBytes  2560 Mbits/sec    5    166 KBytes       
[  6]   0.00-10.00  sec  2.98 GBytes  2558 Mbits/sec    6    166 KBytes       
[  8]   0.00-10.00  sec  2.98 GBytes  2557 Mbits/sec   11    166 KBytes       
[ 10]   0.00-10.00  sec  2.97 GBytes  2555 Mbits/sec   13    175 KBytes       
[ 12]   0.00-10.00  sec  2.98 GBytes  2555 Mbits/sec    4    166 KBytes       
[ 14]   0.00-10.00  sec  2.97 GBytes  2554 Mbits/sec   12    166 KBytes       
[ 16]   0.00-10.00  sec  2.97 GBytes  2551 Mbits/sec    1    227 KBytes       
[ 18]   0.00-10.00  sec  2.97 GBytes  2550 Mbits/sec   10    166 KBytes       
[SUM]   0.00-10.00  sec  23.8 GBytes  20439 Mbits/sec   62             
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth       Retr
[  4]   0.00-10.00  sec  2.98 GBytes  2560 Mbits/sec    5             sender
[  4]   0.00-10.00  sec  2.98 GBytes  2560 Mbits/sec                  receiver
[  6]   0.00-10.00  sec  2.98 GBytes  2558 Mbits/sec    6             sender
[  6]   0.00-10.00  sec  2.98 GBytes  2558 Mbits/sec                  receiver
[  8]   0.00-10.00  sec  2.98 GBytes  2557 Mbits/sec   11             sender
[  8]   0.00-10.00  sec  2.98 GBytes  2557 Mbits/sec                  receiver
[ 10]   0.00-10.00  sec  2.97 GBytes  2555 Mbits/sec   13             sender
[ 10]   0.00-10.00  sec  2.97 GBytes  2555 Mbits/sec                  receiver
[ 12]   0.00-10.00  sec  2.98 GBytes  2555 Mbits/sec    4             sender
[ 12]   0.00-10.00  sec  2.98 GBytes  2555 Mbits/sec                  receiver
[ 14]   0.00-10.00  sec  2.97 GBytes  2554 Mbits/sec   12             sender
[ 14]   0.00-10.00  sec  2.97 GBytes  2554 Mbits/sec                  receiver
[ 16]   0.00-10.00  sec  2.97 GBytes  2551 Mbits/sec    1             sender
[ 16]   0.00-10.00  sec  2.97 GBytes  2551 Mbits/sec                  receiver
[ 18]   0.00-10.00  sec  2.97 GBytes  2550 Mbits/sec   10             sender
[ 18]   0.00-10.00  sec  2.97 GBytes  2550 Mbits/sec                  receiver
[SUM]   0.00-10.00  sec  23.8 GBytes  20439 Mbits/sec   62             sender
[SUM]   0.00-10.00  sec  23.8 GBytes  20439 Mbits/sec                  receiver

iperf Done.
Received TCP output from worker netperf-w1 for test 2 iperf TCP. Same VM using Virtual IP from netperf-w1 to netperf-w2 MSS: 119
Connecting to host 100.70.29.66, port 5201
[  4] local 100.96.2.16 port 60932 connected to 100.70.29.66 port 5201
[  6] local 100.96.2.16 port 60934 connected to 100.70.29.66 port 5201
[  8] local 100.96.2.16 port 60936 connected to 100.70.29.66 port 5201
[ 10] local 100.96.2.16 port 60938 connected to 100.70.29.66 port 5201
[ 12] local 100.96.2.16 port 60940 connected to 100.70.29.66 port 5201
[ 14] local 100.96.2.16 port 60942 connected to 100.70.29.66 port 5201
[ 16] local 100.96.2.16 port 60944 connected to 100.70.29.66 port 5201
[ 18] local 100.96.2.16 port 60946 connected to 100.70.29.66 port 5201
[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd
[  4]   0.00-10.01  sec  2.94 GBytes  2523 Mbits/sec    7    175 KBytes       
[  6]   0.00-10.01  sec  2.94 GBytes  2523 Mbits/sec    6    166 KBytes       
[  8]   0.00-10.01  sec  2.94 GBytes  2523 Mbits/sec    5    166 KBytes       
[ 10]   0.00-10.01  sec  2.94 GBytes  2521 Mbits/sec    1    227 KBytes       
[ 12]   0.00-10.01  sec  2.93 GBytes  2520 Mbits/sec    1    227 KBytes       
[ 14]   0.00-10.01  sec  2.93 GBytes  2517 Mbits/sec    4    227 KBytes       
[ 16]   0.00-10.01  sec  2.93 GBytes  2516 Mbits/sec   32    227 KBytes       
[ 18]   0.00-10.01  sec  2.93 GBytes  2514 Mbits/sec    1    175 KBytes       
[SUM]   0.00-10.01  sec  23.5 GBytes  20157 Mbits/sec   57             
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth       Retr
root@netperf-orch-m3cb3:/tmp# more output.txt  
Received TCP output from worker netperf-w1 for test 2 iperf TCP. Same VM using Virtual IP from netperf-w1 to netperf-w2 MSS: 96
Connecting to host 100.70.29.66, port 5201
[  4] local 100.96.2.16 port 59916 connected to 100.70.29.66 port 5201
[  6] local 100.96.2.16 port 59918 connected to 100.70.29.66 port 5201
[  8] local 100.96.2.16 port 59920 connected to 100.70.29.66 port 5201
[ 10] local 100.96.2.16 port 59922 connected to 100.70.29.66 port 5201
[ 12] local 100.96.2.16 port 59924 connected to 100.70.29.66 port 5201
[ 14] local 100.96.2.16 port 59926 connected to 100.70.29.66 port 5201
[ 16] local 100.96.2.16 port 59928 connected to 100.70.29.66 port 5201
[ 18] local 100.96.2.16 port 59930 connected to 100.70.29.66 port 5201
[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd
[  4]   0.00-10.00  sec  2.95 GBytes  2532 Mbits/sec    1    192 KBytes       
[  6]   0.00-10.00  sec  2.95 GBytes  2532 Mbits/sec    6    166 KBytes       
[  8]   0.00-10.00  sec  2.94 GBytes  2529 Mbits/sec   10    166 KBytes       
[ 10]   0.00-10.00  sec  2.94 GBytes  2528 Mbits/sec    3    166 KBytes       
[ 12]   0.00-10.00  sec  2.94 GBytes  2527 Mbits/sec   18    166 KBytes       
[ 14]   0.00-10.00  sec  2.94 GBytes  2524 Mbits/sec    8    210 KBytes       
[ 16]   0.00-10.00  sec  2.94 GBytes  2522 Mbits/sec    3    210 KBytes       
[ 18]   0.00-10.00  sec  2.94 GBytes  2522 Mbits/sec    6    166 KBytes       
[SUM]   0.00-10.00  sec  23.5 GBytes  20216 Mbits/sec   55             
- - - - - - - - - - - - - - - - - - - - - - - - -
[ ID] Interval           Transfer     Bandwidth       Retr
[  4]   0.00-10.00  sec  2.95 GBytes  2532 Mbits/sec    1             sender
[  4]   0.00-10.00  sec  2.95 GBytes  2532 Mbits/sec                  receiver
[  6]   0.00-10.00  sec  2.95 GBytes  2532 Mbits/sec    6             sender
[  6]   0.00-10.00  sec  2.95 GBytes  2531 Mbits/sec                  receiver
[  8]   0.00-10.00  sec  2.94 GBytes  2529 Mbits/sec   10             sender
[  8]   0.00-10.00  sec  2.94 GBytes  2529 Mbits/sec                  receiver
[ 10]   0.00-10.00  sec  2.94 GBytes  2528 Mbits/sec    3             sender
[ 10]   0.00-10.00  sec  2.94 GBytes  2528 Mbits/sec                  receiver
[ 12]   0.00-10.00  sec  2.94 GBytes  2527 Mbits/sec   18             sender
[ 12]   0.00-10.00  sec  2.94 GBytes  2526 Mbits/sec                  receiver
[ 14]   0.00-10.00  sec  2.94 GBytes  2524 Mbits/sec    8             sender
[ 14]   0.00-10.00  sec  2.94 GBytes  2523 Mbits/sec                  receiver
[ 16]   0.00-10.00  sec  2.94 GBytes  2522 Mbits/sec    3             sender
[ 16]   0.00-10.00  sec  2.94 GBytes  2522 Mbits/sec                  receiver
[ 18]   0.00-10.00  sec  2.94 GBytes  2522 Mbits/sec    6             sender
[ 18]   0.00-10.00  sec  2.94 GBytes  2522 Mbits/sec                  receiver
[SUM]   0.00-10.00  sec  23.5 GBytes  20216 Mbits/sec   55             sender
[SUM]   0.00-10.00  sec  23.5 GBytes  20212 Mbits/sec                  receiver

iperf Done.
```",closed,False,2017-01-13 21:43:46,2018-07-30 00:37:22
perf-tests,bowei,https://github.com/kubernetes/perf-tests/issues/22,https://api.github.com/repos/kubernetes/perf-tests/issues/22,Update DNS perf tests to use RBAC,1.6 enables RBAC by default which causes non-`kube-system` kube-dns instances to no longer work. The test needs to create RBAC authorization for the test.,closed,False,2017-01-13 22:42:09,2018-02-18 10:44:00
perf-tests,bowei,https://github.com/kubernetes/perf-tests/pull/23,https://api.github.com/repos/kubernetes/perf-tests/issues/23,"Add `dig` to dnsperf image, somehow was missing",,closed,True,2017-01-17 19:37:51,2017-03-03 17:30:30
perf-tests,rflorenc,https://github.com/kubernetes/perf-tests/pull/24,https://api.github.com/repos/kubernetes/perf-tests/issues/24,base logger config and template,Clusterloader logger template,closed,True,2017-01-19 09:55:20,2017-02-06 21:55:26
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/25,https://api.github.com/repos/kubernetes/perf-tests/issues/25,Copied compare tool from k8s.io/contrib and updated its Godeps,"Copied the compare tool to perf-tests repo from contrib, as it makes more sense to have this tool here.
Updated its dependencies (mainly k8s.io/*) to newer revisions and added/removed used/unused packages.
Also migrated the dependencies from Godeps/_workspace to vendor, since _workspace support would be deprecated starting from go1.8.

cc @k8s-sig-testing-misc @wojtek-t @gmarek ",closed,True,2017-01-27 11:53:29,2017-01-30 13:55:52
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/issues/26,https://api.github.com/repos/kubernetes/perf-tests/issues/26,Travis is unhappy,"Seems like Travis is failing always due to `go get ./...` and `go test ./..` commands run against the repo.
This is because we use glide as our dep manager instead of godep in `clusterloader` which works differently.
We need to fix this by doing one of the following:
- Use glide's get and test equivalents for clusterloader and go for all the other directories
- Move clusterloader to godep, so we have uniformity across the whole repo

cc @kubernetes/sig-scalability-misc @gmarek @spxtr ",closed,False,2017-01-28 13:45:11,2017-05-04 12:06:16
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/27,https://api.github.com/repos/kubernetes/perf-tests/issues/27,Prototype of the performance benchmarking tool,"[Design doc](https://docs.google.com/document/d/1olGQ7nHqoZVO714XtgBzrPvifR7nWu0pQWwelN3VQtM) for the tool.

Here's the basic benchmarking tool prototype designed as per the discussion we had and the design doc. To run the tool:
- `make` (in the benchmark directory)
- `./bin/benchmark` (for running the benchmark with default configuration, i.e. comparing jobs ci-kubernetes-e2e-gce-scalability and ci-kubernetes-kubemark-100-gce using their runs from last 48 hours with KS Test)
Note: `./bin/benchmark --help` (for knowing the flags)

cc @kubernetes/sig-scalability-misc @wojtek-t @gmarek ",closed,True,2017-02-01 21:55:16,2017-04-25 11:59:14
perf-tests,zihaoyu,https://github.com/kubernetes/perf-tests/issues/28,https://api.github.com/repos/kubernetes/perf-tests/issues/28,dns perf test throws error,"I'm running DNS perf test against existing kubedns installation. Client pod was created successfully.

```
DEBUG 02-15 11:03:32 runner.py:121] kubectl ['/Users/zyu/bin/kbe', 'exec', 'kube-dns-perf-client', '--', '/dnsperf', '-s', '10.0.0.10', '-l', '60', '-Q', '500', '-d', '/queries/nx-domain.txt']
DEBUG 02-15 11:03:32 runner.py:128] kubectl ret=127
DEBUG 02-15 11:03:32 runner.py:129] kubectl stdout
out |
DEBUG 02-15 11:03:32 runner.py:130] kubectl stderr
err | Error loading shared library libcrypto.so.1.0.0: No such file or directory (needed by /dnsperf)
err |
INFO 02-15 11:03:32 runner.py:102] Exception caught during run, cleaning up
```
Also, path to `tar` binary is hardcoded to `/bin/tar`. However on Mac it is `/usr/bin/tar`. Maybe it is a good idea to add some flexibility there.",closed,False,2017-02-15 16:06:58,2017-02-16 10:48:06
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/29,https://api.github.com/repos/kubernetes/perf-tests/issues/29,Fix small travis failures in perf-tests repo,,closed,True,2017-02-16 10:33:41,2017-02-16 10:41:32
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/30,https://api.github.com/repos/kubernetes/perf-tests/issues/30,Fix #28,"Fixes #28 

cc @zihaoyu ",closed,True,2017-02-16 10:38:09,2017-02-16 10:48:06
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/31,https://api.github.com/repos/kubernetes/perf-tests/issues/31,Create a component that can monitor our performance SLO,"I still need to get godeps working (somehow) and figure out hot to get past RBAC, but this works as a prototype.

cc @kubernetes/sig-scalability-pr-reviews @wojtek-t @timothysc @jbeda @spiffxp 
cc @deads2k for controller usage (as I have no idea what I'm doing).
",closed,True,2017-02-20 16:55:01,2017-03-10 14:37:21
perf-tests,dohnto,https://github.com/kubernetes/perf-tests/issues/32,https://api.github.com/repos/kubernetes/perf-tests/issues/32,netperf: result interpretation,"Hello, I have run the _netperf_ with following results.

```
MSS                                          , Maximum, 96, 160, 224, 288, 352, 416, 480, 544, 608, 672, 736, 800, 864, 928, 992, 1056, 1120, 1184, 1248, 1312, 1376, 1440,
1 iperf TCP. Same VM using Pod IP            ,19033.000000,15292,18193,18309,14759,16767,16466,19033,16214,15723,18003,15816,17526,17670,16205,15926,16363,16899,15639,16742,15341,16303,16823,
2 iperf TCP. Same VM using Virtual IP        ,15870.000000,14622,14634,13309,15622,13274,13683,14700,14963,13445,13520,15722,14016,14195,13502,13704,15870,13694,14258,14538,14285,13303,12895,
3 iperf TCP. Remote VM using Pod IP          ,899.000000,855,858,889,889,893,891,894,894,895,898,899,884,893,864,891,896,893,894,893,896,894,896,
4 iperf TCP. Remote VM using Virtual IP      ,903.000000,892,891,892,888,863,862,893,897,894,883,902,898,894,892,889,889,875,893,897,897,894,903,
5 iperf TCP. Hairpin Pod to own Virtual IP   ,15874.000000,15222,15131,14236,14574,13799,14207,14739,13283,14318,14943,13056,14949,15388,14740,14584,13997,14203,15874,15550,14164,15616,15016,
6 iperf UDP. Same VM using Pod IP            ,4838.000000,4838,
7 iperf UDP. Same VM using Virtual IP        ,3604.000000,3604,
8 iperf UDP. Remote VM using Pod IP          ,2934.000000,2934,
9 iperf UDP. Remote VM using Virtual IP      ,3989.000000,3989,
10 netperf. Same VM using Pod IP             ,5525.360000,5525.36,
11 netperf. Same VM using Virtual IP         ,0.000000,0.00,
12 netperf. Remote VM using Pod IP           ,897.600000,897.60,
13 netperf. Remote VM using Virtual IP       ,0.000000,0.00,
```

I struggle with result interpretation and have a few questions:

1. Why is UDP so much slower than TCP? 
2. How can UDP using Virtual IP can be faster from remote than from same VM? (lines 7 and 9)

Thank you for help",closed,False,2017-02-21 15:30:13,2018-02-19 19:15:59
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/33,https://api.github.com/repos/kubernetes/perf-tests/issues/33,Allow 2017 in boilerplate,,closed,True,2017-02-22 10:59:44,2017-02-22 11:00:12
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/34,https://api.github.com/repos/kubernetes/perf-tests/issues/34,add gitignore,,closed,True,2017-03-06 14:09:49,2017-03-07 09:46:20
perf-tests,dohnto,https://github.com/kubernetes/perf-tests/issues/35,https://api.github.com/repos/kubernetes/perf-tests/issues/35,netperf: MSS not passed to iperf3,"## How to reproduce

In 1st terminal:

```bash
cd network/benchmarks/netperf/
make runtests
```

In 2nd terminal, during the tests
```
kubectl  --namespace=netperf exec -it netperf-w1-nkbgj -- ps faux -ww
...
root       323 46.0  0.0   7408  2392 ?        S    16:28   0:00 /usr/bin/iperf3 -c 172.31.255.164 -N -i 30 -t 10 -f m -w 512M -Z -P 8 -M a
```
```
kubectl  --namespace=netperf exec -it netperf-w1-nkbgj -- ps faux -ww
...
root       345  0.0  0.0   7408  2456 ?        R    16:30   0:00 /usr/bin/iperf3 -c 172.31.255.164 -N -i 30 -t 10 -f m -w 512M -Z -P 8 -M e
```
```
kubectl  --namespace=netperf exec -it netperf-w1-nkbgj -- ps faux -ww
...
root       364  0.0  0.0   7408  2456 ?        R    16:30   0:00 /usr/bin/iperf3 -c 172.31.255.164 -N -i 30 -t 10 -f m -w 512M -Z -P 8 -M f
```

Note the last argument of  `iperf3` the `-M` argument. The value passed to iperf -M is meant to be a unsigned. `iperf` unfortunately does not fail, and silently sets MSS to default.

## Expected behaviour

Argument to `-M` is passed as an integer.",closed,False,2017-03-18 16:39:04,2017-03-22 00:03:34
perf-tests,dohnto,https://github.com/kubernetes/perf-tests/pull/36,https://api.github.com/repos/kubernetes/perf-tests/issues/36,netperf: MSS is not passed to iperf3,Fixes #35.,closed,True,2017-03-18 16:39:35,2017-03-22 00:03:35
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/37,https://api.github.com/repos/kubernetes/perf-tests/issues/37,Fix gcloud docker command in Makefile in slo-monitor,,closed,True,2017-04-05 10:02:43,2017-04-05 10:04:32
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/38,https://api.github.com/repos/kubernetes/perf-tests/issues/38,Fix a race in slo-monitor,,closed,True,2017-04-06 08:22:41,2017-04-06 08:23:47
perf-tests,jonaskint,https://github.com/kubernetes/perf-tests/issues/39,https://api.github.com/repos/kubernetes/perf-tests/issues/39,DNS perf crashing on simple test,"Hi, I'm currently trying to benchmark our internal kubernetes dns with the perf tool and play with the dnsmasq settings. A simple run crashes instantaneously and I'm not sure if it's me that misread the docutmentation or if it's a bug. Here is a sample of the output:

```
❯ ./run --params params/default.yaml --use-cluster-dns --out-dir out
INFO 04-07 12:39:49 runner.py:60] Using cluster DNS for tests
INFO 04-07 12:39:49 runner.py:64] DNS service IP is 10.0.0.10
INFO 04-07 12:39:50 runner.py:217] Client node is ip-10-2-11-248.eu-central-1.compute.internal
INFO 04-07 12:39:50 runner.py:331] Created rundir out/run-1491561590
INFO 04-07 12:39:50 runner.py:337] Updated symlink out/latest
INFO 04-07 12:39:50 runner.py:277] Starting client teardown
INFO 04-07 12:39:50 runner.py:287] Client teardown complete
INFO 04-07 12:39:50 runner.py:140] Create Pod/kube-dns-perf-client ok
INFO 04-07 12:39:51 runner.py:254] Client pod to started on ip-10-2-11-248.eu-central-1.compute.internal
INFO 04-07 12:39:53 runner.py:262] Client pod ready for execution
INFO 04-07 12:39:53 runner.py:266] Copying query files to client
INFO 04-07 12:39:53 runner.py:233] Starting server teardown
INFO 04-07 12:39:54 runner.py:300] Waiting for server to be deleted (0 pods active)
INFO 04-07 12:39:54 runner.py:240] Server teardown ok
INFO 04-07 12:39:54 runner.py:277] Starting client teardown
INFO 04-07 12:39:55 runner.py:285] Waiting for client pod to terminate
INFO 04-07 12:39:56 runner.py:285] Waiting for client pod to terminate
INFO 04-07 12:39:58 runner.py:285] Waiting for client pod to terminate
INFO 04-07 12:39:59 runner.py:285] Waiting for client pod to terminate
INFO 04-07 12:39:59 runner.py:287] Client teardown complete
Traceback (most recent call last):
  File ""py/run_perf.py"", line 87, in <module>
    sys.exit(runner.go())
  File ""/Users/jonas/Github/perf-tests/dns/py/runner.py"", line 79, in go
    self._reset_client()
  File ""/Users/jonas/Github/perf-tests/dns/py/runner.py"", line 263, in _reset_client
    self._copy_query_files()
  File ""/Users/jonas/Github/perf-tests/dns/py/runner.py"", line 268, in _copy_query_files
    ['/bin/tar', '-czf', '-', self.args.query_dir])
  File ""/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 212, in check_output
    process = Popen(stdout=PIPE, *popenargs, **kwargs)
  File ""/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 390, in __init__
    errread, errwrite)
  File ""/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 1024, in _execute_child
    raise child_exception
OSError: [Errno 2] No such file or directory
```

I see the `kube-dns-perf-client` pod spinning up but it shuts down after 2 seconds.",closed,False,2017-04-07 11:40:52,2018-02-22 03:10:35
perf-tests,sjug,https://github.com/kubernetes/perf-tests/pull/40,https://api.github.com/repos/kubernetes/perf-tests/issues/40,Dependency nightmare,All this to try and make [Travis happy](https://github.com/kubernetes/perf-tests/issues/26).,closed,True,2017-04-24 17:48:30,2017-05-04 18:50:09
perf-tests,jayunit100,https://github.com/kubernetes/perf-tests/issues/41,https://api.github.com/repos/kubernetes/perf-tests/issues/41,Outline incubation of a synthetic API component generator.,"Scheduler_perf as well as this repo use generic, opionated template based approaches to making pods.

- In scheduler_perf, we've come up w/ an initial struct idea to that can be mutated in a pipeline.

- In this repo, templates are used and modified/spread around the cluster.

A software library that generates arbitrary cluster setups w/ pods and nodes , maybe other stuff (services), that is fully configurable might be a cool project we could commonly utilize.

Thoughts @gmarek   @sjug @jeremyeder @ravisantoshgudimetla",closed,False,2017-04-25 13:27:44,2018-02-21 17:01:02
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/42,https://api.github.com/repos/kubernetes/perf-tests/issues/42,Update goversion,,closed,True,2017-04-27 16:36:23,2017-04-27 17:53:29
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/43,https://api.github.com/repos/kubernetes/perf-tests/issues/43,Update goversion,,closed,True,2017-04-27 17:14:37,2017-04-27 17:15:07
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/44,https://api.github.com/repos/kubernetes/perf-tests/issues/44,Make 'go get' in travis script only download packages,"Ref https://github.com/kubernetes/perf-tests/pull/40

This should hopefully fix the issue with `github.com/Microsoft/go-winio` dependency for benchmark, compare and clusterloader.

cc @gmarek @wojtek-t @sjug ",closed,True,2017-04-27 19:05:45,2017-04-27 19:48:19
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/45,https://api.github.com/repos/kubernetes/perf-tests/issues/45,Make 'go test' in travis script test non-vendored code only,"Ref #40 

Following my previous PR https://github.com/kubernetes/perf-tests/pull/44.
This is a short-term fix for skipping tests on vendored code, until we do something neat like flattening vendor code across the repo.
This should fix travis mostly, except for a couple of bugs in cluster_loader.go:
```
# k8s.io/perf-tests/clusterloader
clusterloader/cluster_loader.go:78: cannot use f (type *""k8s.io/perf-tests/clusterloader/vendor/k8s.io/kubernetes/test/e2e/framework"".Framework) as type *""github.com/kubernetes/perf-tests/clusterloader/vendor/k8s.io/kubernetes/test/e2e/framework"".Framework in argument to ""github.com/kubernetes/perf-tests/clusterloader/framework"".CreatePods
clusterloader/cluster_loader.go:78: cannot use config.Spec (type ""k8s.io/perf-tests/clusterloader/vendor/k8s.io/kubernetes/pkg/api/v1"".PodSpec) as type ""github.com/kubernetes/perf-tests/clusterloader/vendor/k8s.io/kubernetes/pkg/api/v1"".PodSpec in argument to ""github.com/kubernetes/perf-tests/clusterloader/framework"".CreatePods
```

cc @gmarek @wojtek-t @sjug ",closed,True,2017-04-27 20:05:40,2017-04-28 11:02:17
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/46,https://api.github.com/repos/kubernetes/perf-tests/issues/46,Fix clusterloader compile error,"@sjug 

Seems to fix the problem.",closed,True,2017-05-04 07:27:54,2018-07-03 12:53:39
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/47,https://api.github.com/repos/kubernetes/perf-tests/issues/47,Fix gofmt,,closed,True,2017-05-04 07:33:44,2018-07-03 12:53:38
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/48,https://api.github.com/repos/kubernetes/perf-tests/issues/48,Make travis happy again,"This PR is explicitly running only tests that are supposed to be run (similarly to what we are doing in the main repo).

Fix #26",closed,True,2017-05-04 11:41:29,2017-05-04 12:05:58
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/49,https://api.github.com/repos/kubernetes/perf-tests/issues/49,Add mechanism for benchmark to filter metric samples with low request count,"Ref https://github.com/kubernetes/kubernetes/issues/44701#issuecomment-297537285
The default is to filter those latency samples with less than 10 api requests.

cc @gmarek @wojtek-t ",closed,True,2017-05-05 08:52:20,2017-05-05 14:35:01
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/50,https://api.github.com/repos/kubernetes/perf-tests/issues/50,[Do not merge] Check no. of cores available on travis,"Ref #49 
Seems like `go build $(go list ./... | grep -v ""/vendor/"")` is taking too long to execute (> 10m) and hence timing out.
Let's check if we have enough cores available on jenkins for parallel execution.

cc @gmarek @wojtek-t ",closed,True,2017-05-05 09:46:55,2017-05-05 14:14:44
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/51,https://api.github.com/repos/kubernetes/perf-tests/issues/51,Add travis wait to 'go build' command for avoiding timeout,"Ref #49 #50 

Following instruction here: https://docs.travis-ci.com/user/common-build-problems/#Build-times-out-because-no-output-was-received.
This should make travis print something to stdout once every minute to ensure longer run.

cc @gmarek @wojtek-t ",closed,True,2017-05-05 10:06:24,2017-05-05 11:03:34
perf-tests,sjug,https://github.com/kubernetes/perf-tests/pull/52,https://api.github.com/repos/kubernetes/perf-tests/issues/52,Basic compile & run script,"Matches the CI filename, just build and run cluster loader.

The `/config/test.yaml` is not very useful. I will either edit this PR with the new config or have another one that follows shortly.

The run command assumes that k8s has the unencrypted port open (8080) as well as the kubeconfig at the default location of `~/.kube/config`

Nothing is parameterized at this point.",closed,True,2017-05-09 18:02:31,2017-05-09 18:46:53
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/53,https://api.github.com/repos/kubernetes/perf-tests/issues/53,Adding dockerization for benchmark tool,"First step towards adding a CI job for the tool.

cc @kubernetes/sig-scalability-misc @wojtek-t @gmarek ",closed,True,2017-05-11 12:08:58,2017-05-11 15:51:31
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/54,https://api.github.com/repos/kubernetes/perf-tests/issues/54,Fix run-e2e.sh clusterloader script,@sjug ,closed,True,2017-05-12 09:02:09,2017-05-12 09:25:18
perf-tests,sjug,https://github.com/kubernetes/perf-tests/pull/55,https://api.github.com/repos/kubernetes/perf-tests/issues/55,"RCs added, resize working, labels exposed","PR to add some of the functionality as per our design discussions a few weeks ago.

First of all, there is now a tuningset to support a delay between creation of each new defined project.
We also support creation of RCs and modification of RCs. To do this we had to be able to recognize existing namespaces, as well as existing RCs, so there's less blind creation going on now. The generic side effect is that we can now define different ""projects"" with the same name and then have different objects deployed in each.

The RC makes use of the image field which was not utilized for pod definitions. 
Labels have also been exposed to the config so the user can now set their own.",closed,True,2017-05-15 00:28:48,2017-05-27 21:18:44
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/56,https://api.github.com/repos/kubernetes/perf-tests/issues/56,Fix run-e2e.sh script in clusterloader,@sjug ,closed,True,2017-05-15 12:42:24,2017-05-15 13:04:41
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/57,https://api.github.com/repos/kubernetes/perf-tests/issues/57,Update benchmark tool to scrape metrics from JSON files,"Following from recent changes of moving all metrics data from build-log.txt to individual JSON files.

Fun fact: There are literally just 6 godeps now! Turns out all the evil was in `k8s.io/kubernetes/test/e2e/framework` package which was importing the universe.

cc @wojtek-t @gmarek ",closed,True,2017-05-15 15:13:10,2017-05-16 09:22:52
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/issues/58,https://api.github.com/repos/kubernetes/perf-tests/issues/58,Update compare tool to read metrics from JSON files,"With recent changes in our CI test framework, we now log all metrics data into individual JSON artifacts.
In PR https://github.com/kubernetes/perf-tests/pull/57 we updated benchmark tool to read metrics from JSONs, and it has eliminated almost the entire vendor code (-63 MB in size).
We should do the same for compare tool as well.

Make perf-tests small again!

cc @wojtek-t @gmarek 
",open,False,2017-05-15 15:31:27,2018-01-09 10:16:25
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/issues/59,https://api.github.com/repos/kubernetes/perf-tests/issues/59,ClusterLoader e2e tests are not uploading artifacts,"I guess these might be some permission issues.
",closed,False,2017-05-15 15:51:14,2018-02-22 12:20:08
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/60,https://api.github.com/repos/kubernetes/perf-tests/issues/60,Add alert for negative startup time in slo-monitor,,closed,True,2017-05-16 09:45:28,2017-05-16 10:00:39
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/61,https://api.github.com/repos/kubernetes/perf-tests/issues/61,Replace dockerization logic for benchmark with a runner script instead,"Seems like docker image for running the tool is not needed. All we need is a runner for dockerized compilation and then running the binary with the right args.
This seems to be the pattern for running simple binaries in CI jobs, where anyway the running of bootstrap.py is dockerized. (Eg: Job ci-cadvisor-node-kubelet (https://github.com/kubernetes/test-infra/blob/master/jobs/config.json#L10) simply calls the runner script in the cadvisor repo (https://github.com/google/cadvisor/blob/master/build/jenkins_e2e.sh))

cc @wojtek-t @gmarek ",closed,True,2017-05-16 14:07:34,2017-05-17 13:01:06
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/issues/62,https://api.github.com/repos/kubernetes/perf-tests/issues/62,ClusterLoading CI test failing,"PR https://github.com/kubernetes/perf-tests/pull/55 broke it:

```
Error parsing config, open content/pod-pause.json: no such file or directory
```

cc @sjug @wojtek-t 
",closed,False,2017-05-25 09:44:02,2017-05-31 07:07:44
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/63,https://api.github.com/repos/kubernetes/perf-tests/issues/63,Modify benchmark to work with subresource field in API call metrics,cc @gmarek @wojtek-t ,closed,True,2017-05-29 13:12:00,2017-05-30 13:27:23
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/64,https://api.github.com/repos/kubernetes/perf-tests/issues/64,Fix perf-tests,@sjug FYI: I'm fixing it for the second time.,closed,True,2017-05-30 13:41:06,2017-05-30 14:37:36
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/65,https://api.github.com/repos/kubernetes/perf-tests/issues/65,Benchmark tool prints results in a classified and sorted way,"The results printed by the tool would now be split by latency percentiles (50, 90, 99), and sorted by the avg ratio within each of those individual tables.

cc @wojtek-t ",closed,True,2017-05-30 19:26:04,2017-05-31 08:43:58
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/66,https://api.github.com/repos/kubernetes/perf-tests/issues/66,Benchmark marks metrics with too low avg values as matched & prints some more useful info,"And also NaN avg ratios are marked as matched.

/cc @gmarek",closed,True,2017-05-31 12:41:24,2017-05-31 15:03:11
perf-tests,ixdy,https://github.com/kubernetes/perf-tests/pull/67,https://api.github.com/repos/kubernetes/perf-tests/issues/67,Create slo-monitor:0.9.3 based on alpine:3.6,"I believe this fixes CVE-2016-9841 and CVE-2016-9843 present in the existing slo-monitor images (0.9.1 and 0.9.2).

Images have not yet been pushed anywhere.

@gmarek ",closed,True,2017-06-13 01:52:28,2017-06-13 18:38:29
perf-tests,alok87,https://github.com/kubernetes/perf-tests/pull/68,https://api.github.com/repos/kubernetes/perf-tests/issues/68,[DNS] Use --dns-ip as kube dns svc ip if --use-cluster-dns is enbaled,"**What?**
When you want to bechmark your running cluster `kube-dns`. The ip for the dns service is implicity sets to be `10.0.0.10`
```
parser.add_argument(
      '--dns-ip', type=str, default='10.0.0.20',
      help='IP to use for the DNS service. Note: --use-cluster-dns '
        'implicitly sets this to 10.0.0.10')
```
This PR is for using the `--dns-ip` as running kube-dns service ip,  if `--use-cluster-dns` is enabled.

```
parser.add_argument(
      '--dns-ip', type=str, default='10.0.0.20',
      help='IP to use for the DNS service. Note: --use-cluster-dns '
        'implicitly sets the service-ip of kube-dns service')
```",closed,True,2017-06-13 06:40:48,2017-06-16 20:52:42
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/69,https://api.github.com/repos/kubernetes/perf-tests/issues/69,Increase benchmark metric consideration threshold to 50ms,"We're catching too much noise with 20ms.
IMO 50ms should be good enough to spot 'real' differences.",closed,True,2017-07-19 22:15:19,2017-07-20 11:44:26
perf-tests,asifdxtreme,https://github.com/kubernetes/perf-tests/pull/70,https://api.github.com/repos/kubernetes/perf-tests/issues/70,Add Build Status and GoReportCard badge,,closed,True,2017-08-04 10:37:23,2017-08-04 12:12:39
perf-tests,fisherxu,https://github.com/kubernetes/perf-tests/pull/71,https://api.github.com/repos/kubernetes/perf-tests/issues/71,fix typo in README.md,,closed,True,2017-08-04 12:33:37,2017-08-04 13:16:16
perf-tests,jwflory,https://github.com/kubernetes/perf-tests/pull/72,https://api.github.com/repos/kubernetes/perf-tests/issues/72,Fix misspell warnings in Go Report Card,I was looking at the [Go Report Card](https://goreportcard.com/report/github.com/kubernetes/perf-tests) for the project and noticed it caught two misspellings. This PR just fixes those spelling errors so the Report Card will be 100% free of misspellings… nothing fancy.,closed,True,2017-08-07 16:02:11,2017-08-08 14:17:54
perf-tests,dohnto,https://github.com/kubernetes/perf-tests/issues/73,https://api.github.com/repos/kubernetes/perf-tests/issues/73,Network test: cannot resolve host ftp.netperf.org,"Hello, in [Dockerfile](https://github.com/kubernetes/perf-tests/blob/22b9bb6ca0595a60bb2986b6312d2fd0fc7b1476/network/benchmarks/netperf/Dockerfile#L34) of network benchmark there is a link to download `tar.gz` with netperf code, this address seems not to exists anymore.

```bash
$ host ftp.netperf.org
Host ftp.netperf.org not found: 3(NXDOMAIN)
```

Dockerfile should be updated with new location.",closed,False,2017-08-15 06:07:28,2017-10-11 06:45:09
perf-tests,mr-joshua,https://github.com/kubernetes/perf-tests/pull/74,https://api.github.com/repos/kubernetes/perf-tests/issues/74,PR: Network test cannot resolve host ftp.netperf.org,"Fixes #73 

Updated Dockerfile to reflect new location and added the rename command because they new archive untar's to netperf-netperf-2.7.0 in order to maintain further logic.",closed,True,2017-09-08 14:45:41,2017-10-11 06:45:09
perf-tests,johscheuer,https://github.com/kubernetes/perf-tests/pull/75,https://api.github.com/repos/kubernetes/perf-tests/issues/75,Allow to set different docker image,Currently the `netperfImage` is hardcoded into the code. This PR allows to use a different Docker image (e.g. self build with the provided Docker image). Otherwise you can't run the network perf-test if you only have a private registry with a different Docker image name.,closed,True,2017-09-12 18:16:48,2017-10-26 19:40:29
perf-tests,johscheuer,https://github.com/kubernetes/perf-tests/issues/76,https://api.github.com/repos/kubernetes/perf-tests/issues/76,Cluster Loader setting image fails,"Hi,

I wanted to use the cluster loader to stress test our cluster sadly I can't change the Docker image. I use the following config and just execute `./run_e2e.sh` (notice that the docs here are wrong --> no glide is needed only the `./run_e2e.sh` command)

```bash
$ cat config/test.yaml 
ClusterLoader:
  delete: true
  projects:
    - num: 1
      basename: clusterproject
      tuning: default
      pods:
        - num: 50
          image: nobody-cares
          basename: pausepods
          file: pod-pause.json
  tuningsets:
    - name: default
      pods:
        stepping:
          stepsize: 10
          pause: 30s
        ratelimit:
          delay: 100ms
```

I would now assume that the cluster loader uses the ` nobody-cares` image but instead it uses the default image `gcr.io/google_containers/pause-amd64:3.0` see:

```bash
$ kubectl -n e2e-tests-clusterproject0-94xd9 describe po pausepods-pod-0
Name: pausepods-pod-0
Namespace: e2e-tests-clusterproject0-94xd9
Node: my-node/10.240.1.10
Start Time: Wed, 13 Sep 2017 16:01:20 +0200
Labels: purpose=test
Annotations: <none>
Status: Pending
IP: 
Containers:
  pause-amd64:
    Container ID: 
    Image: gcr.io/google_containers/pause-amd64:3.0
    Image ID: 
    Port: 8080/TCP
    State: Waiting
      Reason: ImagePullBackOff
    Ready: False
    Restart Count: 0
    Environment: <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vcn44 (ro)
Conditions:
  Type Status
  Initialized True 
  Ready False 
  PodScheduled True 
Volumes:
  default-token-vcn44:
    Type: Secret (a volume populated by a Secret)
    SecretName: default-token-vcn44
    Optional: false
QoS Class: BestEffort
Node-Selectors: <none>
Tolerations: node.alpha.kubernetes.io/notReady:NoExecute for 300s
node.alpha.kubernetes.io/unreachable:NoExecute for 300s
Events:
  FirstSeen LastSeen
Count From
SubObjectPath Type
Reason Message
  --------- --------
----- ----
------------- --------
------ -------
  11m 11m
1 default-scheduler
Normal Scheduled
Successfully assigned pausepods-pod-0 to my-node
  11m 11m
1 kubelet, my-node
Normal SuccessfulMountVolumeMountVolume.SetUp succeeded for volume ""default-token-vcn44"" 
  9m 6m  2 kubelet,my-node
spec.containers{pause-amd64} Warning
Failed Failed to pull image ""gcr.io/google_containers/pause-amd64:3.0"": rpc error: code = 2 desc = Error response from daemon: {""message"":""Get https://gcr.io/v1/_ping: dial tcp 74.125.133.82:443: i/o timeout""}
  11m 1m  6 kubelet, my-node
spec.containers{pause-amd64} Normal
Pulling pulling image ""gcr.io/google_containers/pause-amd64:3.0""
  10m 56s
4 kubelet, my-node
spec.containers{pause-amd64} Warning
Failed Failed to pull image ""gcr.io/google_containers/pause-amd64:3.0"": rpc error: code = 2 desc = Error response from daemon: {""message"":""Get https://gcr.io/v1/_ping: dial tcp 66.102.1.82:443: i/o timeout""}
  10m 3s  31 kubelet, my-node
Warning FailedSync
Error syncing pod
  10m 3s  25 kubelet, my-node
spec.containers{pause-amd64} Normal
BackOff Back-off pulling image ""gcr.io/google_containers/pause-amd64:3.0""
```

I will take a look how to fix this.",closed,False,2017-09-13 14:25:01,2017-10-14 16:24:30
perf-tests,bobbytables,https://github.com/kubernetes/perf-tests/issues/77,https://api.github.com/repos/kubernetes/perf-tests/issues/77,Network README needs Usage,"There's not a clear usage section in the Network perf test. Unless you know how to write Go, it's pretty hard to understand.",closed,False,2017-10-09 14:57:38,2018-03-12 18:29:36
perf-tests,bobbytables,https://github.com/kubernetes/perf-tests/pull/78,https://api.github.com/repos/kubernetes/perf-tests/issues/78,Use namely/perfest as Docker image,"I've updated the image that this project uses to include the latest changes and published it to my companies Docker hub. It now uses the min mtu set to 96 and increments it by 40 each time. This change was made a while ago but no docker image was published for it.

I also removed a few of the tests because they rely on services that this project does not create. Only the `w2` service is actually created by this tool.",closed,True,2017-10-09 18:11:24,2018-04-14 15:53:54
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/79,https://api.github.com/repos/kubernetes/perf-tests/issues/79,Fix gce job-name for benchmark tool,"Fixes https://github.com/kubernetes/test-infra/issues/5053

/cc @gmarek ",closed,True,2017-10-23 11:59:10,2017-10-23 16:51:33
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/80,https://api.github.com/repos/kubernetes/perf-tests/issues/80,Update benchmark tool with new 'Scope' field in API call metric,"Following up changes in https://github.com/kubernetes/kubernetes/pull/52237

cc @kubernetes/sig-scalability-misc @porridge",closed,True,2017-10-23 19:39:18,2017-10-23 19:48:24
perf-tests,johscheuer,https://github.com/kubernetes/perf-tests/issues/81,https://api.github.com/repos/kubernetes/perf-tests/issues/81,Distribute pods for network-tests based on nodelabels,"For our tests cases we want to distribute the pods based on nodelabels e.g. `failure-domain=rack`. This allows us to test rack specific network performance and over rack network performance (or other combinations).

There are two possible ways to achieve this:

1.  Use the PodAntiAffinity of Kubernetes
2. Implement a simple `NodelabelSelector` routine (this keeps the programs logic)

Approach 2 should be easier to integrate in the current code.",closed,False,2017-10-26 20:30:56,2018-03-25 21:38:51
perf-tests,johscheuer,https://github.com/kubernetes/perf-tests/pull/82,https://api.github.com/repos/kubernetes/perf-tests/issues/82,Inital support to select nodes by labels,"As mentioned in https://github.com/kubernetes/perf-tests/issues/81 this is the implementation of the second approach.

This PR allows the user to specify how the network test pods should be distributed (based on nodelabels).",closed,True,2017-10-26 20:36:01,2018-03-30 10:25:52
perf-tests,spiffxp,https://github.com/kubernetes/perf-tests/pull/83,https://api.github.com/repos/kubernetes/perf-tests/issues/83,Rename OWNERS assignees: to approvers:,"They are effectively the same, assignees is deprecated

ref: kubernetes/test-infra#3851",closed,True,2017-10-31 23:52:03,2017-11-01 15:24:47
perf-tests,kozl,https://github.com/kubernetes/perf-tests/pull/84,https://api.github.com/repos/kubernetes/perf-tests/issues/84,Fixed bug in handlePulledImageEvent,"Fixed bug in handlePulledImageEvent function. It leads to negative startup time for pods, that pull images from docker registry. As a result they are not accounted.",closed,True,2017-11-22 09:34:28,2017-11-23 08:43:38
perf-tests,kozl,https://github.com/kubernetes/perf-tests/pull/85,https://api.github.com/repos/kubernetes/perf-tests/issues/85,Fixed bug in handlePulledImageEvent,"Fixed bug in handlePulledImageEvent function. It leads to negative startup time for pods, that pull images from docker registry. As a result they are not accounted.",closed,True,2017-11-23 08:53:30,2018-04-10 11:47:17
perf-tests,mozhuli,https://github.com/kubernetes/perf-tests/pull/86,https://api.github.com/repos/kubernetes/perf-tests/issues/86,Fix netperf README nits,,closed,True,2017-12-08 02:38:11,2018-02-20 18:21:59
perf-tests,spiffxp,https://github.com/kubernetes/perf-tests/pull/87,https://api.github.com/repos/kubernetes/perf-tests/issues/87,Update code-of-conduct.md,"Refer to kubernetes/community as authoritative source for code of conduct

ref: kubernetes/community#1527",closed,True,2017-12-20 18:39:46,2018-01-03 00:44:12
perf-tests,thockin,https://github.com/kubernetes/perf-tests/pull/88,https://api.github.com/repos/kubernetes/perf-tests/issues/88,Convert registry to k8s.gcr.io,"This PR was auto-generated.  Please apply human expertise to review for correctness.

Followup to https://github.com/kubernetes/kubernetes/pull/54174

xref https://github.com/kubernetes/release/issues/281",closed,True,2017-12-22 18:00:17,2018-01-17 19:42:41
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/89,https://api.github.com/repos/kubernetes/perf-tests/issues/89,Make SLO monitor publish full pod startup latency including image pul…,"…l time

@hulkholden @shyamjvs @wojtek-t ",closed,True,2018-01-16 14:04:08,2018-01-18 12:38:51
perf-tests,thockin,https://github.com/kubernetes/perf-tests/pull/90,https://api.github.com/repos/kubernetes/perf-tests/issues/90,Pushes go to staging-k8s.gcr.io,"Context: https://github.com/kubernetes/kubernetes/pull/57824

xref kubernetes/release#281",closed,True,2018-01-17 22:24:57,2018-02-02 10:01:08
perf-tests,gmarek,https://github.com/kubernetes/perf-tests/pull/91,https://api.github.com/repos/kubernetes/perf-tests/issues/91,Make SLO monitor publish full pod startup latency including image pul…,"…l time

Parts I forgot to push previously",closed,True,2018-02-02 10:56:31,2018-02-03 17:53:22
perf-tests,kevinjqiu,https://github.com/kubernetes/perf-tests/pull/92,https://api.github.com/repos/kubernetes/perf-tests/issues/92,Update README to use godep,,closed,True,2018-02-12 18:34:34,2018-08-11 18:36:23
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/93,https://api.github.com/repos/kubernetes/perf-tests/issues/93,Increase benchmark comparison threshold for more variance,/cc @wojtek-t ,closed,True,2018-02-19 13:23:43,2018-02-19 14:29:01
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/94,https://api.github.com/repos/kubernetes/perf-tests/issues/94,Update benchmark tool's design doc link,/cc @gmarek ,closed,True,2018-02-19 17:33:00,2018-02-19 17:36:28
perf-tests,normanjoyner,https://github.com/kubernetes/perf-tests/pull/95,https://api.github.com/repos/kubernetes/perf-tests/issues/95,fix misspelling of Kubernetes,Simple update to fix typos,closed,True,2018-03-09 15:44:00,2018-04-10 12:12:14
perf-tests,K7king,https://github.com/kubernetes/perf-tests/issues/96,https://api.github.com/repos/kubernetes/perf-tests/issues/96,Missing dependencies- Client-go,"I tried to perform network  performance test [module.](https://github.com/kubernetes/perf-tests/tree/master/network/benchmarks/netperf) In launch.go there were dependencies of client-go.I tried to get client-go from https://github.com/kubernetes/client-go . It has various version issues.

Can someone help to get  the correct dependencies needed to perform the test ?  ",closed,False,2018-03-14 04:54:57,2018-03-21 10:29:37
perf-tests,migueleliasweb,https://github.com/kubernetes/perf-tests/pull/97,https://api.github.com/repos/kubernetes/perf-tests/issues/97,Fixing dnsperf build,"There was a missing library, the `libxml2-dev` on the build and `libcrypto1.0` on the final image. I have also changed a little bit the apk command.

How to replicate the issue ?
```bash
$ lsb_release -a
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 17.04
Release:	17.04
Codename:	zesty

$ git clone git@github.com:kubernetes/perf-tests.git
$ cd dns/image/
$ make
[some lines omitted]
docker run --rm -v `pwd`/build/src:/src kube-dns-perf-client-build \
	/bin/sh -c ""cd /src && ./configure && make -j""
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables... 
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking for a BSD-compatible install... /usr/bin/install -c
checking for ranlib... ranlib
checking for inline... inline
checking for socket in -lsocket... no
checking for inet_ntoa in -lnsl... no
checking for isc-config.sh... /usr/bin/isc-config.sh
checking for socklen_t... yes
checking for sa_len... no
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
checking for the pthreads library -lpthreads... no
checking whether pthreads work without any flags... yes
checking for joinable pthread attribute... PTHREAD_CREATE_JOINABLE
checking if more special flags are required for pthreads... no
configure: creating ./config.status
config.status: creating Makefile
gcc -g -O2 -I/usr/include -D_REENTRANT -D_GNU_SOURCE -DPACKAGE_NAME=\""\"" -DPACKAGE_TARNAME=\""\"" -DPACKAGE_VERSION=\""\"" -DPACKAGE_STRING=\""\"" -DPACKAGE_BUGREPORT=\""\"" -DHAVE_PTHREAD=1  -c dnsperf.c
gcc -g -O2 -I/usr/include -D_REENTRANT -D_GNU_SOURCE -DPACKAGE_NAME=\""\"" -DPACKAGE_TARNAME=\""\"" -DPACKAGE_VERSION=\""\"" -DPACKAGE_STRING=\""\"" -DPACKAGE_BUGREPORT=\""\"" -DHAVE_PTHREAD=1  -c datafile.c
gcc -g -O2 -I/usr/include -D_REENTRANT -D_GNU_SOURCE -DPACKAGE_NAME=\""\"" -DPACKAGE_TARNAME=\""\"" -DPACKAGE_VERSION=\""\"" -DPACKAGE_STRING=\""\"" -DPACKAGE_BUGREPORT=\""\"" -DHAVE_PTHREAD=1  -c dns.c
gcc -g -O2 -I/usr/include -D_REENTRANT -D_GNU_SOURCE -DPACKAGE_NAME=\""\"" -DPACKAGE_TARNAME=\""\"" -DPACKAGE_VERSION=\""\"" -DPACKAGE_STRING=\""\"" -DPACKAGE_BUGREPORT=\""\"" -DHAVE_PTHREAD=1  -c log.c
gcc -g -O2 -I/usr/include -D_REENTRANT -D_GNU_SOURCE -DPACKAGE_NAME=\""\"" -DPACKAGE_TARNAME=\""\"" -DPACKAGE_VERSION=\""\"" -DPACKAGE_STRING=\""\"" -DPACKAGE_BUGREPORT=\""\"" -DHAVE_PTHREAD=1  -c net.c
gcc -g -O2 -I/usr/include -D_REENTRANT -D_GNU_SOURCE -DPACKAGE_NAME=\""\"" -DPACKAGE_TARNAME=\""\"" -DPACKAGE_VERSION=\""\"" -DPACKAGE_STRING=\""\"" -DPACKAGE_BUGREPORT=\""\"" -DHAVE_PTHREAD=1  -c opt.c
gcc -g -O2 -I/usr/include -D_REENTRANT -D_GNU_SOURCE -DPACKAGE_NAME=\""\"" -DPACKAGE_TARNAME=\""\"" -DPACKAGE_VERSION=\""\"" -DPACKAGE_STRING=\""\"" -DPACKAGE_BUGREPORT=\""\"" -DHAVE_PTHREAD=1  -c os.c
gcc -g -O2 -I/usr/include -D_REENTRANT -D_GNU_SOURCE -DPACKAGE_NAME=\""\"" -DPACKAGE_TARNAME=\""\"" -DPACKAGE_VERSION=\""\"" -DPACKAGE_STRING=\""\"" -DPACKAGE_BUGREPORT=\""\"" -DHAVE_PTHREAD=1  -c resperf.c
In file included from datafile.c:32:0:
util.h:60:0: warning: ""LOCK"" redefined
 #define LOCK(mutex) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from datafile.c:26:
/usr/include/isc/util.h:90:0: note: this is the location of the previous definition
 #define LOCK(lp) do { \
 
In file included from datafile.c:32:0:
util.h:67:0: warning: ""UNLOCK"" redefined
 #define UNLOCK(mutex) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from datafile.c:26:
/usr/include/isc/util.h:101:0: note: this is the location of the previous definition
 #define UNLOCK(lp) do { \
 
In file included from datafile.c:32:0:
util.h:81:0: warning: ""SIGNAL"" redefined
 #define SIGNAL(cond) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from datafile.c:26:
/usr/include/isc/util.h:120:0: note: this is the location of the previous definition
 #define SIGNAL(cvp) do { \
 
In file included from datafile.c:32:0:
util.h:88:0: warning: ""BROADCAST"" redefined
 #define BROADCAST(cond) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from datafile.c:26:
/usr/include/isc/util.h:113:0: note: this is the location of the previous definition
 #define BROADCAST(cvp) do { \
 
In file included from datafile.c:32:0:
util.h:95:0: warning: ""WAIT"" redefined
 #define WAIT(cond, mutex) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from datafile.c:26:
/usr/include/isc/util.h:127:0: note: this is the location of the previous definition
 #define WAIT(cvp, lp) do { \
 
In file included from resperf.c:66:0:
util.h:60:0: warning: ""LOCK"" redefined
 #define LOCK(mutex) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from resperf.c:49:
/usr/include/isc/util.h:90:0: note: this is the location of the previous definition
 #define LOCK(lp) do { \
 
In file included from resperf.c:66:0:
util.h:67:0: warning: ""UNLOCK"" redefined
 #define UNLOCK(mutex) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from resperf.c:49:
/usr/include/isc/util.h:101:0: note: this is the location of the previous definition
 #define UNLOCK(lp) do { \
 
In file included from resperf.c:66:0:
util.h:81:0: warning: ""SIGNAL"" redefined
 #define SIGNAL(cond) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from resperf.c:49:
/usr/include/isc/util.h:120:0: note: this is the location of the previous definition
 #define SIGNAL(cvp) do { \
 
In file included from resperf.c:66:0:
util.h:88:0: warning: ""BROADCAST"" redefined
 #define BROADCAST(cond) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from resperf.c:49:
/usr/include/isc/util.h:113:0: note: this is the location of the previous definition
 #define BROADCAST(cvp) do { \
 
In file included from resperf.c:66:0:
util.h:95:0: warning: ""WAIT"" redefined
 #define WAIT(cond, mutex) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from resperf.c:49:
/usr/include/isc/util.h:127:0: note: this is the location of the previous definition
 #define WAIT(cvp, lp) do { \
 
In file included from dnsperf.c:75:0:
util.h:60:0: warning: ""LOCK"" redefined
 #define LOCK(mutex) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from dnsperf.c:55:
/usr/include/isc/util.h:90:0: note: this is the location of the previous definition
 #define LOCK(lp) do { \
 
In file included from dnsperf.c:75:0:
util.h:67:0: warning: ""UNLOCK"" redefined
 #define UNLOCK(mutex) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from dnsperf.c:55:
/usr/include/isc/util.h:101:0: note: this is the location of the previous definition
 #define UNLOCK(lp) do { \
 
In file included from dnsperf.c:75:0:
util.h:81:0: warning: ""SIGNAL"" redefined
 #define SIGNAL(cond) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from dnsperf.c:55:
/usr/include/isc/util.h:120:0: note: this is the location of the previous definition
 #define SIGNAL(cvp) do { \
 
In file included from dnsperf.c:75:0:
util.h:88:0: warning: ""BROADCAST"" redefined
 #define BROADCAST(cond) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from dnsperf.c:55:
/usr/include/isc/util.h:113:0: note: this is the location of the previous definition
 #define BROADCAST(cvp) do { \
 
In file included from dnsperf.c:75:0:
util.h:95:0: warning: ""WAIT"" redefined
 #define WAIT(cond, mutex) do {      \
 
In file included from /usr/include/isc/magic.h:14:0,
                 from /usr/include/isc/buffer.h:100,
                 from dnsperf.c:55:
/usr/include/isc/util.h:127:0: note: this is the location of the previous definition
 #define WAIT(cvp, lp) do { \
 
dns.c: In function 'name_fromstring':
dns.c:187:2: warning: assignment discards 'const' qualifier from pointer target type [-Wdiscarded-qualifiers]
  isc_buffer_init(&buffer, str, len);
  ^~~~~~~~~~~~~~~
dnsperf.c: In function 'print_statistics':
dnsperf.c:352:28: warning: format '%lu' expects argument of type 'long unsigned int', but argument 3 has type 'isc_uint64_t {aka long long unsigned int}' [-Wformat=]
    printf(""#histogram %u %lu\n"", i, stats->rtt_histogram[i]);
                            ^
ar rv libperf.a datafile.o dns.o log.o net.o opt.o os.o
a - datafile.o
ar: creating libperf.a
a - dns.o
a - log.o
a - net.o
a - opt.o
a - os.o
ranlib libperf.a
gcc  resperf.o  libperf.a  -L/usr/lib -lbind9 -ldns -lcrypto -lisccfg -lisc -ldl -lcap -lpthread -lxml2 -L/lib -lz -lm  -lm -o resperf
/usr/lib/gcc/x86_64-alpine-linux-musl/6.4.0/../../../../x86_64-alpine-linux-musl/bin/ld: cannot find -lxml2
collect2: error: ld returned 1 exit status
make: *** [Makefile:32: resperf] Error 1
make: *** Waiting for unfinished jobs....
Makefile:37: recipe for target 'build/src/dnsperf' failed
make: *** [build/src/dnsperf] Error 2
```",closed,True,2018-03-21 23:28:56,2018-03-22 17:14:44
perf-tests,K7king,https://github.com/kubernetes/perf-tests/pull/98,https://api.github.com/repos/kubernetes/perf-tests/issues/98,Updating Docker Image," For this issue https://github.com/kubernetes/perf-tests/issues/21 . The docker image published by  @jcsirot [https://github.com/jcsirot]
works fine. Made changes in code to adopt this image. Thanks at @jcsirot",closed,True,2018-03-22 06:34:01,2018-03-23 19:06:29
perf-tests,listx,https://github.com/kubernetes/perf-tests/pull/99,https://api.github.com/repos/kubernetes/perf-tests/issues/99,Makefile: separate building from pushing,"Also remove usage of ""sudo"" for building.",closed,True,2018-03-24 03:47:32,2018-03-27 20:36:05
perf-tests,migueleliasweb,https://github.com/kubernetes/perf-tests/pull/100,https://api.github.com/repos/kubernetes/perf-tests/issues/100,"[dns/py] Fixed identation, added requirements.txt and other small changes","- Chaged the identation to follow pep8 patters: https://www.python.org/dev/peps/pep-0008/#indentation
- Added requirements.txt to facilitate local builds and tests
- Fixed most of warnings from `pylint`
- Python3

How to replicate:

**Master branch**
```bash
$ git checkout master 
Switched to branch 'master'
Your branch is up-to-date with 'origin/master'.
From github.com:kubernetes/perf-tests
 * branch              master     -> FETCH_HEAD
Already up-to-date.
$ make pylint 
cd py && pylint --rcfile=../pylintrc *.py
Using config file perf-tests/dns/pylintrc
************* Module data
C:176, 0: Wrong continued indentation (remove 3 spaces).
                       if r.name in results['data'] else None
                    |  ^ (bad-continuation)
E: 99,16: Undefined variable 'reduce' (undefined-variable)
C: 19, 0: standard import ""import re"" should be placed before ""import numpy"" (wrong-import-order)
C: 20, 0: standard import ""import sqlite3"" should be placed before ""import numpy"" (wrong-import-order)
************* Module data_test
W: 32, 4: Using deprecated method assertEquals() (deprecated-method)
W: 39, 4: Using deprecated method assertEquals() (deprecated-method)
************* Module params
C:232, 9: Do not use `len(SEQUENCE)` to determine if a sequence is empty (len-as-condition)
R:231, 4: Either all return statements in a function should return an expression, or none of them should. (inconsistent-return-statements)
************* Module params_test
W: 60, 4: Using deprecated method assertEquals() (deprecated-method)
W: 68, 4: Using deprecated method assertEquals() (deprecated-method)
W: 72, 4: Using deprecated method assertEquals() (deprecated-method)
W: 97, 4: Using deprecated method assertEquals() (deprecated-method)
W:108, 4: Using deprecated method assertEquals() (deprecated-method)
W:110, 4: Using deprecated m
```

**This PR**
```bash
$ git checkout feature/py-dns-small-improvements 
Switched to branch 'feature/py-dns-small-improvements'
$ make pylint 
cd py && pylint --rcfile=../pylintrc *.py
perf-tests/dns/pylintrc
************* Module params
C:236,15: Do not use `len(SEQUENCE)` to determine if a sequence is empty (len-as-condition)
R:235, 8: Either all return statements in a function should return an expression, or none of them should. (inconsistent-return-statements)
************* Module runner
C: 93, 0: Line too long (91/80) (line-too-long)
C:200, 0: Line too long (86/80) (line-too-long)
C: 74,11: Do not use `len(SEQUENCE)` to determine if a sequence is empty (len-as-condition)
W:210,12: Exception arguments suggest string formatting might be intended (raising-format-tuple)
W:248,12: Exception arguments suggest string formatting might be intended (raising-format-tuple)
W:319,16: Exception arguments suggest string formatting might be intended (raising-format-tuple)
C:325,27: Do not use `len(SEQUENCE)` to determine if a sequence is empty (len-as-condition)
C:326,31: Do not use `len(SEQUENCE)` to determine if a sequence is empty (len-as-condition)

------------------------------------------------------------------
Your code has been rated at 9.82/10 (previous run: 9.82/10, +0.00)

Makefile:19: recipe for target 'pylint' failed
make: *** [pylint] Error 28

```",closed,True,2018-03-29 03:24:56,2018-05-07 23:29:13
perf-tests,K7king,https://github.com/kubernetes/perf-tests/pull/101,https://api.github.com/repos/kubernetes/perf-tests/issues/101,"Allowing ClusterLoader,Network and DNS Tests to run from kubetest ","Similar to cluster loader, this allows netperf and DNS tests as well to run from kubetest e2e framework.
Once this PR gets merged, we will create a PR in test-infra repo as well.",closed,True,2018-04-03 07:36:34,2018-05-10 13:27:07
perf-tests,migueleliasweb,https://github.com/kubernetes/perf-tests/pull/102,https://api.github.com/repos/kubernetes/perf-tests/issues/102,[dns/py] Major improvements on dns perf tests,"A superset of changes from #100 .

In order to make the DNS perf tests work I had to change quite a bit o code that's why the ""full PR"" was broken into two.

This PR adds:

- Improved error reporting on boilerplate verification
- Integrated reporting with reporting.py (dns/py/report.py)
- Dockerfile for running python script for dns-perf",closed,True,2018-04-03 08:41:28,2018-05-07 23:28:39
perf-tests,migueleliasweb,https://github.com/kubernetes/perf-tests/pull/103,https://api.github.com/repos/kubernetes/perf-tests/issues/103,Feature/dns enhancements,"Changes:

- Added report module that outputs aggregated data from all runs
- Fixed Pylint and PyUnit
- Addded Dockerfile to run the py runner
- Added Python3 support
- Added report module

```bash
$ make all
cd py && pylint --rcfile=../pylintrc *.py
Using config file /home/msantos/Projects/perf-tests/dns/pylintrc

--------------------------------------------------------------------
Your code has been rated at 10.00/10 (previous run: 10.00/10, +0.00)

nosetests py/ -v
test_parser (data_test.DataTest) ... ok
test_result_db (data_test.DataTest) ... ok
test_TestCases (params_test.ParamsTest) ... ok
test_TestCases_attributes (params_test.ParamsTest) ... ok
test_null_params (params_test.ParamsTest) ... ok
test_params (params_test.ParamsTest) ... ok

----------------------------------------------------------------------
Ran 6 tests in 0.082s

OK
```",closed,True,2018-04-05 02:37:20,2018-05-07 23:29:39
perf-tests,mkoderer,https://github.com/kubernetes/perf-tests/pull/104,https://api.github.com/repos/kubernetes/perf-tests/issues/104,Pass a configmap to the netperf orch,"Mount a configmap volume to the netperf-orch pod in order to
control the scenarios that are executed. This makes it more
flexible and doesn't need any recompile + image push.",closed,True,2018-04-06 06:54:10,2018-10-21 11:58:14
perf-tests,mkoderer,https://github.com/kubernetes/perf-tests/issues/105,https://api.github.com/repos/kubernetes/perf-tests/issues/105,netperf Makefile builds wrong binaries under mac,"Problem:
---------
docker run girishkalele/netperf-latest
standard_init_linux.go:190: exec user process caused ""exec format error""


To make this working nptest must be crosscompiled for linux and launch.go must be compiled for Mac.",closed,False,2018-04-06 07:09:55,2018-05-16 07:59:29
perf-tests,mkoderer,https://github.com/kubernetes/perf-tests/pull/106,https://api.github.com/repos/kubernetes/perf-tests/issues/106,Adapt netperf Makefile to support MacOS,"nptest needs to be build for Linux (and potentially cross-compiled).

Fixes #105",closed,True,2018-04-06 07:14:17,2018-05-16 07:59:29
perf-tests,mkoderer,https://github.com/kubernetes/perf-tests/pull/107,https://api.github.com/repos/kubernetes/perf-tests/issues/107,Netperf: Add argument for namespace cleanup,,closed,True,2018-04-06 13:54:27,2018-05-18 07:40:51
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/108,https://api.github.com/repos/kubernetes/perf-tests/issues/108,Moving perfdash from contrib.,,closed,True,2018-04-10 11:52:55,2018-04-11 09:23:26
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/109,https://api.github.com/repos/kubernetes/perf-tests/issues/109,Updating go version.,Go version 1.7 -> 1.9,closed,True,2018-04-10 13:10:11,2018-04-11 07:34:51
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/110,https://api.github.com/repos/kubernetes/perf-tests/issues/110,Changing deployment config,"Increasing memory limit for the deployment.
Decreasing web page refresh frequency.",closed,True,2018-04-11 13:21:30,2018-04-12 12:40:29
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/111,https://api.github.com/repos/kubernetes/perf-tests/issues/111,Fix wojtek-t`s login in OWNERS file,,closed,True,2018-04-12 10:46:07,2018-07-03 12:53:34
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/112,https://api.github.com/repos/kubernetes/perf-tests/issues/112,Keeping selected test name,Refresh shouldn't change selected test name (if possible). ,closed,True,2018-04-12 12:59:56,2018-04-12 13:15:59
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/113,https://api.github.com/repos/kubernetes/perf-tests/issues/113,Correcting perfdash image repo name,,closed,True,2018-04-12 13:26:34,2018-10-10 09:25:47
perf-tests,chrisohaver,https://github.com/kubernetes/perf-tests/pull/114,https://api.github.com/repos/kubernetes/perf-tests/issues/114,dns: Add CoreDNS options,Add options to enable running the dns perf-tests tests against CoreDNS.,closed,True,2018-04-16 16:19:40,2018-05-18 06:25:53
perf-tests,mkoderer,https://github.com/kubernetes/perf-tests/pull/115,https://api.github.com/repos/kubernetes/perf-tests/issues/115,netperf: fix TODO in inline documentation,,closed,True,2018-04-23 14:58:47,2018-05-18 07:49:51
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/issues/116,https://api.github.com/repos/kubernetes/perf-tests/issues/116,Perf-dash graphs for test-phase times blank,"Taking a look at [perf-dash](http://perf-dash.k8s.io/), I'm seeing that we're not generating any graphs for `TestPhaseTimer` metric even though we have the data available as JSON files in the job's artifacts.

For e.g consider graph `gce-100Nodes-master-DensityTestPhaseTimer` which is empty. But from a run of the job, I find the data available:

- https://storage.googleapis.com/kubernetes-jenkins/logs/ci-kubernetes-e2e-gci-gce-scalability/12924/artifacts/TestPhaseTimer_density_2018-04-23T18:14:50Z.json
- https://storage.googleapis.com/kubernetes-jenkins/logs/ci-kubernetes-e2e-gci-gce-scalability/12924/artifacts/TestPhaseTimer_load_2018-04-23T18:05:23Z.json

/assign @krzysied 
Krzysiek - Could you PTAL into this when you find time? This metric is useful sometimes to spot performance regressions.

cc @kubernetes/sig-scalability-bugs @wojtek-t ",closed,False,2018-04-23 18:56:52,2018-04-27 13:59:16
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/117,https://api.github.com/repos/kubernetes/perf-tests/issues/117,undefined values workaround,"Workaround for undefined values.
Allows test phase plots to be displayed.",closed,True,2018-04-25 14:30:12,2018-04-27 13:55:05
perf-tests,AdamDang,https://github.com/kubernetes/perf-tests/pull/118,https://api.github.com/repos/kubernetes/perf-tests/issues/118,Typo fix: seperate->separate,Line 2800: seperate->separate,closed,True,2018-04-29 16:50:01,2018-05-01 02:01:56
perf-tests,AdamDang,https://github.com/kubernetes/perf-tests/pull/119,https://api.github.com/repos/kubernetes/perf-tests/issues/119,[perfdash/README.md] Typo fix kuberntes->kubernetes,Line 19: kuberntes->kubernetes,closed,True,2018-05-03 15:23:54,2018-05-03 19:18:52
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/120,https://api.github.com/repos/kubernetes/perf-tests/issues/120,ClusterLoader design,"@kubernetes/sig-scalability-feature-requests 
@sjug @countspongebob @shyamjvs ",closed,True,2018-05-10 11:00:16,2018-07-03 12:53:29
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/121,https://api.github.com/repos/kubernetes/perf-tests/issues/121,Perfdash empty entries,"Adding empty objects  as a placeholders to data series. Due to this change, perfdash will match values to corresponding builds correctly.",closed,True,2018-05-15 11:43:11,2018-05-15 12:01:46
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/122,https://api.github.com/repos/kubernetes/perf-tests/issues/122,Update README for comparison tool,,closed,True,2018-05-15 14:28:54,2018-07-03 12:53:33
perf-tests,mkoderer,https://github.com/kubernetes/perf-tests/pull/123,https://api.github.com/repos/kubernetes/perf-tests/issues/123,Add OWNERS to nptests,"As discussed with gmarek we add an OWNERS file for nptests to make
it possible to merge stuff more quickly.",closed,True,2018-05-16 10:57:45,2018-06-28 10:56:18
perf-tests,dkusidlo,https://github.com/kubernetes/perf-tests/pull/124,https://api.github.com/repos/kubernetes/perf-tests/issues/124,netperf/readme.md fix units,The iperf output is in Mbit/s not in Gbit/s as currently documented.,closed,True,2018-05-18 14:10:40,2018-05-21 10:34:51
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/125,https://api.github.com/repos/kubernetes/perf-tests/issues/125,Perfdash label refresh,"This change will prevent from changing selected label values due to data refresh.
Labels will be reset only if needed.",closed,True,2018-05-24 10:35:04,2018-10-10 09:25:49
perf-tests,jessfraz,https://github.com/kubernetes/perf-tests/issues/126,https://api.github.com/repos/kubernetes/perf-tests/issues/126,Create a SECURITY_CONTACTS file.,"As per the email sent to kubernetes-dev[1], please create a SECURITY_CONTACTS
file.

The template for the file can be found in the kubernetes-template repository[2].
A description for the file is in the steering-committee docs[3], you might need
to search that page for ""Security Contacts"".

Please feel free to ping me on the PR when you make it, otherwise I will see when
you close this issue. :)

Thanks so much, let me know if you have any questions.

(This issue was generated from a tool, apologies for any weirdness.)

[1] https://groups.google.com/forum/#!topic/kubernetes-dev/codeiIoQ6QE
[2] https://github.com/kubernetes/kubernetes-template-project/blob/master/SECURITY_CONTACTS
[3] https://github.com/kubernetes/community/blob/master/committee-steering/governance/sig-governance-template-short.md
",closed,False,2018-05-24 14:39:38,2018-12-21 09:09:55
perf-tests,dkusidlo,https://github.com/kubernetes/perf-tests/issues/127,https://api.github.com/repos/kubernetes/perf-tests/issues/127,Netperf. Gather CPU usage for each job.,When running network performance tests one bottleneck for bandwidth can be CPU. Therefor it would be helpful to gather information of CPU usage for each job to identify related issues.,closed,False,2018-05-24 16:44:27,2018-06-29 11:03:22
perf-tests,dkusidlo,https://github.com/kubernetes/perf-tests/pull/128,https://api.github.com/repos/kubernetes/perf-tests/issues/128,Add reporting of CPU usage for iperf to orchestrator,"Run iperf3 in verbose mode, parse output and report CPU usage for
sender and receiver in orchestrator log output for each job.

Fixes #127 ",closed,True,2018-05-24 16:59:50,2018-06-29 11:03:22
perf-tests,AdamDang,https://github.com/kubernetes/perf-tests/pull/129,https://api.github.com/repos/kubernetes/perf-tests/issues/129,Typo fix in returned message: formating->formatting,Line 70: formating->formatting,closed,True,2018-05-31 15:07:31,2018-05-31 15:17:56
perf-tests,dkusidlo,https://github.com/kubernetes/perf-tests/issues/130,https://api.github.com/repos/kubernetes/perf-tests/issues/130,Netperf overwrites results when running multiple iterations.,When running multiple iterations for the netperf test the results of each iteration get overwritten by the next one. Netperf only writes to one csv-file without respecting existing data in it.,closed,False,2018-06-08 13:45:34,2018-06-28 10:56:23
perf-tests,dkusidlo,https://github.com/kubernetes/perf-tests/pull/131,https://api.github.com/repos/kubernetes/perf-tests/issues/131,Create output report per iteration,"- create a new output directory per job
- create an output file with timestamp in this directory per iteration

Fixes #130 ",closed,True,2018-06-08 14:07:37,2018-06-28 10:56:23
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/issues/132,https://api.github.com/repos/kubernetes/perf-tests/issues/132,Plot scheduler throughput and latencies on perf-dash,"With some recent changes, we've now started to capture scheduler metrics ([e.g](https://storage.googleapis.com/kubernetes-jenkins/logs/ci-kubernetes-e2e-gce-scale-performance/167/artifacts/SchedulingMetrics_density_2018-06-15T23:31:48Z.json)) in our scalability tests. We need to plot those values over time.

cc @kubernetes/sig-scalability-misc @kubernetes/sig-scheduling-misc 

/assign @krzysied 
Krzysiek - Would you be able to take this up?",closed,False,2018-06-18 19:08:29,2018-07-13 14:10:12
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/133,https://api.github.com/repos/kubernetes/perf-tests/issues/133,Adding scheduler throughput and scheduling latency to perfdash,fixes #132,closed,True,2018-06-19 13:14:11,2018-06-22 11:51:37
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/134,https://api.github.com/repos/kubernetes/perf-tests/issues/134,Update Cluster Loader design,,closed,True,2018-06-19 14:05:09,2018-07-03 12:53:27
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/135,https://api.github.com/repos/kubernetes/perf-tests/issues/135,Cluster loader - API structures,New version for cluster loader.,closed,True,2018-06-21 16:34:26,2018-06-28 11:16:05
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/136,https://api.github.com/repos/kubernetes/perf-tests/issues/136,Scheduler latency update,"Updating scheduler latency metrics due to changes in kubernetes repository:
https://github.com/kubernetes/kubernetes/pull/65318",closed,True,2018-06-22 12:12:50,2018-10-10 09:26:29
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/issues/137,https://api.github.com/repos/kubernetes/perf-tests/issues/137,Take perf-dash to v1.0,"We've made several improvements to [perf-dash](http://perf-dash.k8s.io/) in the past few months (thanks a lot @krzysied for the work!). I think it's time to make some final improvements and cut the first major release (1.0). Mainly, let's make using it easier (even for non-scalability folks - for e.g release team has been asking for it). Some work-items that come to my mind:

- Split the graphs based on job-name first (i.e gce-100, kubemark-500, etc) and then metric (i.e ApiserverResponsiveness, SchedulerMetrics, etc) so that navigation is easier
- Add units to the axes in the graphs (otherwise the graphs aren't understandable)
- Load individual graphs on demand rather than pre-loading everything at start (so we don't wait for tens of seconds before we can see anything)
- sth else?

/assign @krzysied 
cc @kubernetes/sig-scalability-misc @wojtek-t ",closed,False,2018-06-22 14:36:30,2018-07-06 13:36:58
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/138,https://api.github.com/repos/kubernetes/perf-tests/issues/138,Perfdash: splitting test name selector,"Splitting test name combo box into two separate ones - one for job name and other for test name.

ref #137 ",closed,True,2018-06-22 14:54:14,2018-06-26 08:23:44
perf-tests,AdamDang,https://github.com/kubernetes/perf-tests/pull/139,https://api.github.com/repos/kubernetes/perf-tests/issues/139,Typo fix: secods->seconds,Line 257: secods->seconds,closed,True,2018-06-23 02:01:39,2018-06-23 12:26:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/140,https://api.github.com/repos/kubernetes/perf-tests/issues/140,Updating boilerplate script,Changing the way of handling years by the boilerplate script. Script will accept years from 2014 till now.,closed,True,2018-06-25 09:30:01,2018-06-25 11:41:47
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/141,https://api.github.com/repos/kubernetes/perf-tests/issues/141,Perfdash units fix,"Re-enables units being displayed on y-axis on every chart.
ref #137 ",closed,True,2018-06-26 08:47:55,2018-06-26 11:27:28
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/142,https://api.github.com/repos/kubernetes/perf-tests/issues/142,ClusterLoader - Adding api validation,Adding validation for the new clusterloader api structures. Tests included.,open,True,2018-06-26 13:52:53,2019-01-07 10:54:43
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/143,https://api.github.com/repos/kubernetes/perf-tests/issues/143,Perfdash: requesting builds data on demand,"Instead of getting all available data for every possible <job x test>, only requested data (for one selected <job x test>) will be retrieved.
ref #137 ",closed,True,2018-06-27 09:35:44,2018-09-27 12:56:32
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/144,https://api.github.com/repos/kubernetes/perf-tests/issues/144,ClusterLoader - File unmarshaling,Adding function that can unmarshal json or yaml file into go structure,closed,True,2018-06-27 16:34:42,2018-07-06 08:29:58
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/145,https://api.github.com/repos/kubernetes/perf-tests/issues/145,ClusterLoader - Adding test state,Adding structure that represents state of a running test.,closed,True,2018-06-28 14:01:43,2018-07-12 14:34:02
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/146,https://api.github.com/repos/kubernetes/perf-tests/issues/146,Mention feedback loop as future enhancement of Cluster Loader,,closed,True,2018-06-29 08:40:31,2018-07-03 12:53:26
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/147,https://api.github.com/repos/kubernetes/perf-tests/issues/147,Fixing verify_golint.sh for go1.10+ versions,Removing go version check - everyone uses 1.5+ version as default.,closed,True,2018-06-29 09:46:40,2018-06-29 10:20:25
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/148,https://api.github.com/repos/kubernetes/perf-tests/issues/148,ClusterLoader - Adding framework,Adding cluster managing framework.,closed,True,2018-07-03 08:31:28,2018-07-09 09:16:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/149,https://api.github.com/repos/kubernetes/perf-tests/issues/149,Perfdash - icon fix,ref #137,closed,True,2018-07-05 12:45:47,2018-07-05 13:01:52
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/150,https://api.github.com/repos/kubernetes/perf-tests/issues/150,ClusterLoader - removing ObjectType,Removing ObjectType from api.,closed,True,2018-07-06 09:00:43,2018-07-06 09:13:08
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/151,https://api.github.com/repos/kubernetes/perf-tests/issues/151,ClusterLoader - unmarshaling templates,,closed,True,2018-07-06 12:29:33,2018-07-10 13:00:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/152,https://api.github.com/repos/kubernetes/perf-tests/issues/152,Perfdash: adding x-axis label,ref #137 ,closed,True,2018-07-06 13:11:26,2018-07-06 13:36:38
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/153,https://api.github.com/repos/kubernetes/perf-tests/issues/153,ClusterLoader - main,Main file for cluster loader.,closed,True,2018-07-09 09:17:43,2018-07-10 12:44:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/154,https://api.github.com/repos/kubernetes/perf-tests/issues/154,ClusterLoader - adding vendor,,closed,True,2018-07-09 09:38:36,2018-07-09 10:18:13
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/155,https://api.github.com/repos/kubernetes/perf-tests/issues/155,ClusterLoader - Tuning ticker mock,,closed,True,2018-07-09 16:13:51,2018-07-27 10:00:27
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/156,https://api.github.com/repos/kubernetes/perf-tests/issues/156,Perfdash: config for build ranges,,closed,True,2018-07-11 10:30:46,2018-07-11 15:46:44
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/157,https://api.github.com/repos/kubernetes/perf-tests/issues/157,ClusterLoader - simple test implementation,"Implementation for interfaces provided by `test/`.
Test execution logic will be implemented in the next PR.",closed,True,2018-07-12 16:22:32,2018-08-01 13:48:56
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/158,https://api.github.com/repos/kubernetes/perf-tests/issues/158,Perfdash: desabling animation,"Graph animation will be removed, due to the performance issues.",closed,True,2018-07-13 11:54:29,2018-07-13 12:14:21
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/159,https://api.github.com/repos/kubernetes/perf-tests/issues/159,ClusterLoader - adding test executor interface,This PR is an alternative to PR #157,closed,True,2018-07-16 17:23:50,2018-07-17 16:47:47
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/160,https://api.github.com/repos/kubernetes/perf-tests/issues/160,Perfdash: histogram,,closed,True,2018-07-17 10:18:20,2018-07-17 16:47:19
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/161,https://api.github.com/repos/kubernetes/perf-tests/issues/161,Perfdash: category level,Adding category level selector.,closed,True,2018-07-18 11:17:58,2018-07-18 16:05:24
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/162,https://api.github.com/repos/kubernetes/perf-tests/issues/162,Update OWNERS for perf-dash,"To avoid mis-assignment of reviewers for PRs.

/cc @krzysied ",closed,True,2018-07-18 12:34:22,2018-07-18 12:47:40
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/163,https://api.github.com/repos/kubernetes/perf-tests/issues/163,Change hit radius for perfdash click,"To avoid highlighting multiple points on mouse hovering - as it's a bit annoying.

/cc @krzysied 
/hold
(for https://github.com/kubernetes/perf-tests/pull/161 to merge first and increment version to 1.4)",closed,True,2018-07-18 13:05:56,2018-07-18 17:29:48
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/164,https://api.github.com/repos/kubernetes/perf-tests/issues/164,"ClusterLoader - Adding test, step, phase execution implementations","Simple implementations for ExecuteTest, ExecuteStep, ExecutePhase.",closed,True,2018-07-18 15:27:04,2018-07-24 17:01:09
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/165,https://api.github.com/repos/kubernetes/perf-tests/issues/165,Perfdash: changing le to <=,Cosmetic change for etcd metrics charts.,closed,True,2018-07-19 09:36:27,2018-07-19 10:04:41
perf-tests,warmchang,https://github.com/kubernetes/perf-tests/pull/166,https://api.github.com/repos/kubernetes/perf-tests/issues/166,update the testgrid link for kubemark-100-benchmark perf-tests,update the testgrid link for kubemark-100-benchmark perf-tests,closed,True,2018-07-20 03:11:47,2018-07-20 05:48:53
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/167,https://api.github.com/repos/kubernetes/perf-tests/issues/167,ClusterLoader - Adding read template with cache,,closed,True,2018-07-23 17:25:08,2018-07-27 15:42:25
perf-tests,KesavanKing,https://github.com/kubernetes/perf-tests/pull/168,https://api.github.com/repos/kubernetes/perf-tests/issues/168,"Adding flags to run ClusterLoader, Netperf and  DNS","Added flags to invoke clusterloader, netperf and DNS  separately from Kubetest (e2e framework).",closed,True,2018-07-24 07:18:01,2018-07-24 07:22:01
perf-tests,KesavanKing,https://github.com/kubernetes/perf-tests/pull/169,https://api.github.com/repos/kubernetes/perf-tests/issues/169,"Adding Flags to run ClusterLoader, Netperf and DNS","Added flags to invoke clusterloader, netperf and DNS separately from Kubetest (e2e framework).",closed,True,2018-07-24 08:04:51,2018-08-07 14:39:10
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/170,https://api.github.com/repos/kubernetes/perf-tests/issues/170,ClusterLoader - Adding execute object logic,Adding handling for create and delete operations. Update operation is not a part of this PR.,closed,True,2018-07-24 16:38:57,2018-07-25 13:34:53
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/171,https://api.github.com/repos/kubernetes/perf-tests/issues/171,ClusterLoader - Resources cleanup,Removing  resources based on instances in the test state.,open,True,2018-07-25 09:26:02,2019-02-13 19:40:53
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/172,https://api.github.com/repos/kubernetes/perf-tests/issues/172,ClusterLoader - Object update,Updating object by creating patch based on already existing object and new object template.,closed,True,2018-07-25 16:43:11,2018-08-09 08:52:26
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/173,https://api.github.com/repos/kubernetes/perf-tests/issues/173,ClusterLoader - Vendor update,Dependencies for update object.,closed,True,2018-07-27 08:47:40,2018-07-27 10:00:35
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/174,https://api.github.com/repos/kubernetes/perf-tests/issues/174,ClusterLoader - Adding ticker to test execution,,closed,True,2018-07-27 11:16:56,2018-07-30 12:37:24
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/175,https://api.github.com/repos/kubernetes/perf-tests/issues/175,ClusterLoader - Implementing different timers,Tuning sets implementation,closed,True,2018-07-30 14:18:30,2018-08-08 09:14:09
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/176,https://api.github.com/repos/kubernetes/perf-tests/issues/176,ClusterLoader - Adding templating,Replacing object names + index template.,closed,True,2018-07-30 16:23:04,2018-09-27 12:57:13
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/177,https://api.github.com/repos/kubernetes/perf-tests/issues/177,ClusterLoader - Updating measurement api,"Adding new fields to Measurement API:
- Identifier - is a identifier within method scope.
Pair <Method, Identifier> makes measurement unique at global scope. The new field is needed due to possible having multiple measurements  instances that uses the same measurement method.
- Params - map of <name, value>. Optional additional method parameters. Allows measurements to be more generic.",closed,True,2018-08-01 08:58:49,2018-08-01 11:07:57
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/178,https://api.github.com/repos/kubernetes/perf-tests/issues/178,Improving clusterloader's Measurement API,"Based on my thoughts from https://github.com/kubernetes/perf-tests/pull/177#issuecomment-409530554

/cc @wojtek-t @krzysied",closed,True,2018-08-01 12:28:25,2018-08-01 13:42:26
perf-tests,shyamjvs,https://github.com/kubernetes/perf-tests/pull/179,https://api.github.com/repos/kubernetes/perf-tests/issues/179,Minor fixes in cluster-loader doc,/cc @krzysied ,closed,True,2018-08-01 13:42:11,2018-08-01 13:56:41
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/180,https://api.github.com/repos/kubernetes/perf-tests/issues/180,ClusterLoader - Adding measurement manager,"Implementation of measurement factory and measurement manager.
CloudProvider will be add in future PR.",closed,True,2018-08-01 14:10:10,2018-08-03 08:35:27
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/181,https://api.github.com/repos/kubernetes/perf-tests/issues/181,ClusterLoader - Adding json annotations to measurement api,,closed,True,2018-08-02 17:37:49,2018-08-03 08:35:37
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/182,https://api.github.com/repos/kubernetes/perf-tests/issues/182,ClusterLoader - Adding measurement manager to test context,,closed,True,2018-08-03 08:39:36,2018-08-03 09:26:26
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/183,https://api.github.com/repos/kubernetes/perf-tests/issues/183,ClusterLoader - Adding measurement manger to test execution,,closed,True,2018-08-03 09:30:14,2018-08-08 10:20:59
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/184,https://api.github.com/repos/kubernetes/perf-tests/issues/184,ClusterLoader - Adding measurement util,"Adding functions for retrieving variables from map[string]interface{} that is used for measurement params.
This will be commonly used by measurement implementation due to map[string]interface{}  being  part of measurement interface.",closed,True,2018-08-03 11:47:12,2018-08-06 14:52:40
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/185,https://api.github.com/repos/kubernetes/perf-tests/issues/185,ClusterLoader - Adding timer measurement,,closed,True,2018-08-06 15:01:11,2018-08-07 11:14:36
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/186,https://api.github.com/repos/kubernetes/perf-tests/issues/186,ClusterLoader  -  wait-for-pods measurement,,closed,True,2018-08-07 12:19:45,2018-08-08 11:57:16
perf-tests,KesavanKing,https://github.com/kubernetes/perf-tests/pull/187,https://api.github.com/repos/kubernetes/perf-tests/issues/187,"Adding Flags to run ClusterLoader, Netperf and DNS","Added flags to invoke clusterloader, netperf and DNS separately from Kubetest (e2e framework).",closed,True,2018-08-07 14:45:05,2018-08-07 15:01:58
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/188,https://api.github.com/repos/kubernetes/perf-tests/issues/188,ClusterLoader - adding e2e test framework,"Adding k8s test e2e framework to vendor.
Methods from e2e will be called by metric implementations.",closed,True,2018-08-08 15:32:38,2018-08-17 09:53:16
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/189,https://api.github.com/repos/kubernetes/perf-tests/issues/189,ClusterLoader - Renaming update to patch,,closed,True,2018-08-09 08:45:34,2018-08-09 17:06:14
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/190,https://api.github.com/repos/kubernetes/perf-tests/issues/190,ClusterLoader - API server latency,,closed,True,2018-08-09 11:52:16,2018-08-13 13:45:20
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/191,https://api.github.com/repos/kubernetes/perf-tests/issues/191,ClusterLoader - object update,,open,True,2018-08-09 17:08:49,2018-11-12 14:39:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/192,https://api.github.com/repos/kubernetes/perf-tests/issues/192,ClusterLoader - Cluster config,,closed,True,2018-08-13 11:16:45,2018-08-22 13:06:54
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/193,https://api.github.com/repos/kubernetes/perf-tests/issues/193,ClusterLoader - Scheduler latency metric,,closed,True,2018-08-13 12:53:01,2018-09-04 13:18:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/194,https://api.github.com/repos/kubernetes/perf-tests/issues/194,ClusterLoader - Adding basepath template provider,Object templates will use relative path (from test config directory).,closed,True,2018-08-13 14:39:06,2018-08-14 11:44:09
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/195,https://api.github.com/repos/kubernetes/perf-tests/issues/195,Perfdash - config location,"Updating config url in config.go.

ref https://github.com/kubernetes/test-infra/pull/8953",closed,True,2018-08-14 09:04:11,2018-08-14 09:17:30
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/196,https://api.github.com/repos/kubernetes/perf-tests/issues/196,ClusterLoader - Density test,,closed,True,2018-08-14 10:33:35,2018-08-16 10:34:42
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/197,https://api.github.com/repos/kubernetes/perf-tests/issues/197,ClusterLoader - Int and float parsing fix,,closed,True,2018-08-14 12:55:12,2018-08-14 13:10:02
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/198,https://api.github.com/repos/kubernetes/perf-tests/issues/198,ClusterLoader - Changing indexing of automanaged namespaces,Changing 0-based indexing of namespaces to 1-based.,closed,True,2018-08-14 13:10:31,2018-08-14 13:25:34
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/199,https://api.github.com/repos/kubernetes/perf-tests/issues/199,ClusterLoader - Adding running script,"Adding running script, that executes density test.
In future version, support for different tests will be added.",closed,True,2018-08-16 10:37:42,2018-08-17 09:42:28
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/200,https://api.github.com/repos/kubernetes/perf-tests/issues/200,ClusterLoader - Adding logger,,closed,True,2018-08-16 12:00:17,2018-08-17 13:04:34
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/201,https://api.github.com/repos/kubernetes/perf-tests/issues/201,ClusterLoader- Adding summary logging,,closed,True,2018-08-17 11:02:57,2018-08-17 15:12:21
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/202,https://api.github.com/repos/kubernetes/perf-tests/issues/202,ClusterLoader - Adding clusterloader2 to run-e2e.sh,,closed,True,2018-08-20 16:22:34,2018-08-21 17:50:19
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/203,https://api.github.com/repos/kubernetes/perf-tests/issues/203,Adding echo to run-e2e script,For debugging purpose. ,closed,True,2018-08-21 16:51:25,2018-08-22 15:39:37
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/204,https://api.github.com/repos/kubernetes/perf-tests/issues/204,ClusterLoader - Adding template functions,Adding generating random int functions.,closed,True,2018-08-22 12:17:41,2018-08-22 15:09:42
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/205,https://api.github.com/repos/kubernetes/perf-tests/issues/205,ClusterLoader - Load test,"Adding 3-node load test.
New measurement `WaitForRunningRCs` added.",closed,True,2018-08-22 15:23:46,2018-08-28 12:54:20
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/206,https://api.github.com/repos/kubernetes/perf-tests/issues/206,ClusterLoader - Changing basename placeholder to name,,closed,True,2018-08-22 17:11:59,2018-08-23 09:19:09
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/207,https://api.github.com/repos/kubernetes/perf-tests/issues/207,ClusterLoader - Changing file naming convention,"Changing file naming convention from ""filenameexample"" to ""file_name_example"".",closed,True,2018-08-23 09:44:58,2018-08-23 10:52:45
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/208,https://api.github.com/repos/kubernetes/perf-tests/issues/208,ClusterLoader - Adding test name to config,"In future there will be added option to run multiple tests in single clusterloader execution. Cause files will be created (for example: measurement summaries) for every test, there is a need to include test name in file name to prevent name collisions.",closed,True,2018-08-23 13:15:56,2018-08-24 13:07:11
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/209,https://api.github.com/repos/kubernetes/perf-tests/issues/209,ClusterLoader - Writing measurement summaries to files,"Writing measurement summaries to files added.
Flag `report-dir`for specifying report directory added.",closed,True,2018-08-24 14:16:08,2018-08-27 10:26:22
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/210,https://api.github.com/repos/kubernetes/perf-tests/issues/210,ClusterLoader - Allowing multiple tests,"Allowing `--testconfig` flag to be used multiple times.
Test will wait until resources are cleaned up.",closed,True,2018-08-27 11:20:10,2018-09-27 12:55:51
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/211,https://api.github.com/repos/kubernetes/perf-tests/issues/211,ClusterLoader - Api responsiveness fix,"Changing metric to have exactly the same name and the same layout as original one.
Needed due to backward compatibility. ",closed,True,2018-08-28 10:51:44,2018-08-28 15:46:09
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/212,https://api.github.com/repos/kubernetes/perf-tests/issues/212,ClusterLoader - Allowing multiple tests fix,,closed,True,2018-08-29 14:31:54,2018-08-29 15:00:02
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/213,https://api.github.com/repos/kubernetes/perf-tests/issues/213,ClusterLoader - thread-safe error list,Adding thread-safe error list.,closed,True,2018-08-29 15:46:57,2018-08-30 08:43:12
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/214,https://api.github.com/repos/kubernetes/perf-tests/issues/214,ClusterLoader - Adding templating to test configs,"Test configs will support templating. Nodes placeholder and template functions will available for test configs.
`nodes` must be provided!",closed,True,2018-08-30 10:33:43,2018-09-03 08:26:52
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/215,https://api.github.com/repos/kubernetes/perf-tests/issues/215,ClusterLoader - Adding new template functions,Adding arithmetical operations to template functions.,closed,True,2018-08-30 12:51:43,2018-09-03 08:27:24
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/216,https://api.github.com/repos/kubernetes/perf-tests/issues/216,Perfdash - updating config location,,closed,True,2018-08-30 16:54:10,2018-10-10 09:27:07
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/217,https://api.github.com/repos/kubernetes/perf-tests/issues/217,ClusterLoader - test configs update,Changing configs to templates. Configs should be now more similar to original ones.,closed,True,2018-09-03 12:14:40,2018-09-14 12:27:30
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/218,https://api.github.com/repos/kubernetes/perf-tests/issues/218,ClusterLoader - Adding parallelism,Executing object operations (namespace x replicaIndex) in parallel.,closed,True,2018-09-03 16:33:39,2018-09-05 13:07:42
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/219,https://api.github.com/repos/kubernetes/perf-tests/issues/219,ClusterLoader - Adding parallelism to wait_for_controlled_pods measurement,Making  wait_for_controlled_pods measurement be executed in parallel.,closed,True,2018-09-03 16:37:11,2018-09-26 12:04:58
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/220,https://api.github.com/repos/kubernetes/perf-tests/issues/220,ClusterLoader - Rand template functions update,,closed,True,2018-09-04 12:28:52,2018-09-04 12:51:36
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/221,https://api.github.com/repos/kubernetes/perf-tests/issues/221,ClusterLoader - e2e measurements,"Adding MetricForE2E.
Currently it vendors metric from kubernetes/test.",closed,True,2018-09-05 10:04:55,2018-09-25 12:46:23
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/222,https://api.github.com/repos/kubernetes/perf-tests/issues/222,ClusterLoader - Fixing mapping creation,Concurrency issue fix.,closed,True,2018-09-05 12:52:16,2018-09-05 13:07:25
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/223,https://api.github.com/repos/kubernetes/perf-tests/issues/223,ClusterLoader - Changing to bundle ticker,Making ticker to be blocking object bundle instead of object operation.,closed,True,2018-09-05 14:49:16,2018-09-05 15:43:19
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/224,https://api.github.com/repos/kubernetes/perf-tests/issues/224,Perfdash - etcd metrics fix,Fixing etcd metrics - structure of etcd metrics changed.,closed,True,2018-09-11 10:22:18,2018-09-11 11:12:51
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/225,https://api.github.com/repos/kubernetes/perf-tests/issues/225,Perfdash - removing kubernetes version from client label,"Due to client label (DensityRequestCountByClient/LoadRequestCountByClient) containing kubernetes version, there is no option to compere across different runs.
This version should be removed.",closed,True,2018-09-13 10:09:38,2018-09-13 10:32:40
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/226,https://api.github.com/repos/kubernetes/perf-tests/issues/226,ClusterLoader -  Pod startup latency measurement,,closed,True,2018-09-14 09:49:37,2018-10-12 11:14:23
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/227,https://api.github.com/repos/kubernetes/perf-tests/issues/227,ClusterLoader - Adding test phase timer,Adding test phase timer. This timer can create measurement summary.,closed,True,2018-09-14 11:22:54,2018-09-17 08:37:58
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/228,https://api.github.com/repos/kubernetes/perf-tests/issues/228,ClusterLoader - Adding memory and cpu profile measurement,,closed,True,2018-09-18 12:16:45,2018-10-08 08:48:40
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/229,https://api.github.com/repos/kubernetes/perf-tests/issues/229,ClusterLoader - Adding additional cluster config flags,"Added flags:
- provider",closed,True,2018-09-19 08:41:05,2018-10-16 12:44:08
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/230,https://api.github.com/repos/kubernetes/perf-tests/issues/230,ClusterLoader - Adding bool parsing from config,"Adding support for bool values.
\+ Fixing typos.",closed,True,2018-09-19 12:29:29,2018-09-20 10:37:04
perf-tests,awly,https://github.com/kubernetes/perf-tests/pull/231,https://api.github.com/repos/kubernetes/perf-tests/issues/231,Update Alpine version for slo-monitor image,Pick up RCE vulnerability fix for apk: https://alpinelinux.org/posts/Alpine-3.8.1-released.html,closed,True,2018-09-19 22:42:58,2018-09-20 22:37:56
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/232,https://api.github.com/repos/kubernetes/perf-tests/issues/232,ClusterLoader - Adding resource usage measurement,,closed,True,2018-09-20 11:12:58,2018-10-16 12:28:18
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/233,https://api.github.com/repos/kubernetes/perf-tests/issues/233,ClusterLoader - Handling cluster level objects,Adding handling for cluster level objects (when namespace range is not specified).,closed,True,2018-09-20 14:00:01,2018-10-02 13:45:32
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/234,https://api.github.com/repos/kubernetes/perf-tests/issues/234,ClusterLoader - Adding etcd metrics,,closed,True,2018-09-27 13:10:16,2018-10-08 08:47:02
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/235,https://api.github.com/repos/kubernetes/perf-tests/issues/235,ClusterLoader - README update,,closed,True,2018-09-28 10:30:10,2018-10-10 10:02:15
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/236,https://api.github.com/repos/kubernetes/perf-tests/issues/236,ClusterLoader - Adding node number computing,Adding computing number of nodes if flag is not provided.,closed,True,2018-10-01 11:17:38,2018-10-08 11:10:53
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/237,https://api.github.com/repos/kubernetes/perf-tests/issues/237,Move design for clusterloader to clusterloader2 directory,,closed,True,2018-10-02 13:13:00,2018-10-02 13:45:59
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/issues/238,https://api.github.com/repos/kubernetes/perf-tests/issues/238,ClusterLoader: Combine provider specific code in a single place,"There are multiple measurements that introduce provider specific code, e.g.:
https://github.com/kubernetes/perf-tests/blob/master/clusterloader2/pkg/measurement/common/etcd_metrics.go#L95
https://github.com/kubernetes/perf-tests/blob/master/clusterloader2/pkg/measurement/common/scheduler_latency.go#L178

Those should be extracted from measurements to a separate single location.

@shyamjvs ",open,False,2018-10-03 12:11:42,2019-02-14 19:07:23
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/239,https://api.github.com/repos/kubernetes/perf-tests/issues/239,ClusterLoader - removing old timer measurement,Replacing old timer measurement with TestPhaseTimer.,closed,True,2018-10-09 13:35:32,2018-10-09 13:56:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/240,https://api.github.com/repos/kubernetes/perf-tests/issues/240,ClusterLoader - Adding resource data types,"Copied from:
- k8s.io/kubernetes/test/e2e/framework/kubelet_stats.go
  - ContainerResourceUsage
  - ResourceUsagePerContainer
  - UsageDataPerContainer
- k8s.io/kubernetes/test/e2e/framework/resource_usage_gatherer.go
  - all other structs and funcs.",closed,True,2018-10-12 11:00:21,2018-10-12 13:24:32
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/241,https://api.github.com/repos/kubernetes/perf-tests/issues/241,Updating golint,"Changing github.com/golang/lint/golint to golang.org/x/lint/golint.
That's the proper way of installation according to https://github.com/golang/lint

Removing version check - we always use 1.5+ version.",closed,True,2018-10-12 11:51:48,2018-10-12 12:21:28
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/242,https://api.github.com/repos/kubernetes/perf-tests/issues/242,ClusterLoader - density test update,Adding multiple iterations of latency pods creation.,closed,True,2018-10-12 14:30:23,2018-11-05 12:14:39
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/243,https://api.github.com/repos/kubernetes/perf-tests/issues/243,ClusterLoader - Adding resource usage util for kubelet,,closed,True,2018-10-15 10:13:56,2018-10-15 11:02:16
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/244,https://api.github.com/repos/kubernetes/perf-tests/issues/244,ClusterLoader - Adding resource usage util for kubemark,,closed,True,2018-10-15 10:15:48,2018-10-16 08:36:38
perf-tests,AdamDang,https://github.com/kubernetes/perf-tests/pull/245,https://api.github.com/repos/kubernetes/perf-tests/issues/245,Fix typo in the warning message,Line 139: at leaste->at least,closed,True,2018-10-15 12:15:28,2018-10-15 14:37:47
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/246,https://api.github.com/repos/kubernetes/perf-tests/issues/246,ClusterLoader: HA cluster support,Currently clusterloader supports only single-master cluster. This should be changed - clusterloader should handle multiple masters.,open,False,2018-10-15 13:24:17,2019-02-14 19:07:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/247,https://api.github.com/repos/kubernetes/perf-tests/issues/247,ClusterLoader - Adding resource gatherers,,closed,True,2018-10-16 10:21:51,2018-10-16 11:20:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/248,https://api.github.com/repos/kubernetes/perf-tests/issues/248,ClusterLoader: ResourceUsageSummary should support constraints ,"ResourceUsageSummary should take resource constraints as a parameters.
Handling for constrains should be done in the same way as is original scalability tests.",closed,False,2018-10-16 11:42:51,2019-01-11 10:17:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/249,https://api.github.com/repos/kubernetes/perf-tests/issues/249,ClusterLoader: Move ClusterConfig global to MeasurementManager structure,`ClusterConfig` is currently a global variable in `pkg/measurement` package. This variable should be a `MeasurementManager` field.,closed,False,2018-10-16 12:13:23,2018-11-12 14:17:54
perf-tests,orsoly,https://github.com/kubernetes/perf-tests/pull/250,https://api.github.com/repos/kubernetes/perf-tests/issues/250,Upgrade client-go to the latest version in network project,"Upgrade from v2.0.0 to v9.0.0.

I'm a first time contributor, happy to receive feedback. Thanks.",closed,True,2018-10-16 12:32:52,2018-10-24 07:31:06
perf-tests,keontang,https://github.com/kubernetes/perf-tests/issues/251,https://api.github.com/repos/kubernetes/perf-tests/issues/251,ClusterLoader：need to suport get etcd mtrics by cert file,"I have a v1.11.2 k8s cluster with an etcd cluster which enables auth by cert file. 
When i run clusterloader2, EtcdMetrics measurement failed to get etcd metrics by http:

https://github.com/kubernetes/perf-tests/blob/f7ae8630a0d06f5ecd141d5d08d3bfdb9cec4e88/clusterloader2/pkg/measurement/common/etcd_metrics.go#L100

```
func getEtcdMetrics(provider, host string) ([]*model.Sample, error) {

	...
       cmd := ""curl http://localhost:2379/metrics""
	...

}
```

so, i think maybe we need to suport get etcd mtrics by cert file.
",open,False,2018-10-16 14:52:40,2019-02-14 19:07:12
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/252,https://api.github.com/repos/kubernetes/perf-tests/issues/252,ClusterLoader - Master IP and master name completing,Getting master name and master ip based on registered master node.,closed,True,2018-10-16 16:53:30,2018-10-17 09:12:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/253,https://api.github.com/repos/kubernetes/perf-tests/issues/253,ClusterLoader - Updating load test,"- Creating all services and then all RCs.
- Fixing tuning sets.",closed,True,2018-10-17 18:15:30,2018-11-06 14:10:49
perf-tests,orsoly,https://github.com/kubernetes/perf-tests/issues/254,https://api.github.com/repos/kubernetes/perf-tests/issues/254,Clusterloader2 is not compatible with go v1.11,"I'm trying to upgrade go version to 1.11, but the Travis CI fails. The merge of pull request #229 created this problem.

The error output of ./verify/verify-gofmt.sh
```
!!! 'gofmt -s' needs to be run on the following files: 
./clusterloader2/pkg/measurement/common/resource_usage.go
./clusterloader2/pkg/measurement/util/gatherers/resource_gather_worker.go
The command ""./verify/verify-gofmt.sh"" exited with 1
```
These two files have problem with indentation.

- resource_usage.go in line 83 and 84
- resource_gather_worker.go in line 56",closed,False,2018-10-17 21:21:29,2018-10-24 09:43:16
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/255,https://api.github.com/repos/kubernetes/perf-tests/issues/255,ClusterLoader - Deleting dependents,"- Removing dependents during object deletion
- Adding Min and Max to template functions",closed,True,2018-10-18 09:39:11,2018-10-18 10:12:21
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/256,https://api.github.com/repos/kubernetes/perf-tests/issues/256,ClusterLoader - Random automanaged namespace name,This is the fix for requests latency problem. Each test will use separate namespaces.,closed,True,2018-10-18 11:38:42,2018-10-19 08:43:03
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/257,https://api.github.com/repos/kubernetes/perf-tests/issues/257,ClusterLoader - Adding name to Step structure,,closed,True,2018-10-18 12:32:46,2018-10-18 12:52:45
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/258,https://api.github.com/repos/kubernetes/perf-tests/issues/258,ClusterLoader - Adding step timer,,closed,True,2018-10-18 14:02:25,2018-10-18 16:58:23
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/259,https://api.github.com/repos/kubernetes/perf-tests/issues/259,ClusterLoader - Tuning set rework,"`pkg/tuningset/` - tuning set executors
`pkg/ticker/` - removed
`pkg/test` - updated with new tuning sets. All wait groups replaces with appending func(){...} to actions.",closed,True,2018-10-18 18:01:11,2018-10-19 11:00:54
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/260,https://api.github.com/repos/kubernetes/perf-tests/issues/260,Verify gofmt fix,Removing go version check from verify-gofmt.sh. Go version checks have been already removed from all other verify scripts.,closed,True,2018-10-19 10:25:35,2018-10-19 11:44:44
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/issues/261,https://api.github.com/repos/kubernetes/perf-tests/issues/261,"ClusterLoader2 bundle should assume that ""bundle is bundle""",Context: https://github.com/kubernetes/perf-tests/pull/259/files#r226558746,open,False,2018-10-19 10:36:44,2019-02-14 19:06:43
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/262,https://api.github.com/repos/kubernetes/perf-tests/issues/262,ClusterLoader - Adding time limited tuning sets,"Two new tuning sets added:
- TimeLimitedLoad
Spreads action evenly over given time.
- RandomizedTimeLimitedLoad
Runs each action at random point of time (within given time limit).",closed,True,2018-10-19 12:09:26,2018-10-19 13:19:54
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/263,https://api.github.com/repos/kubernetes/perf-tests/issues/263,ClusterLoader - Removing unnecessary timers from tests,,closed,True,2018-10-19 12:28:52,2018-10-23 08:43:02
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/264,https://api.github.com/repos/kubernetes/perf-tests/issues/264,ClusterLoader - Reimplementing wait for controlled pods measurement,"Reimplementing wait for controlled pods measurement. Now it support two actions:
- start - starts to observe the controlling objects.
- gather - waits for objects to have all pods running.
- stop - stops the observation.

Minor changes:
- parallel group that limits number of routines running in parallel added.
- `waitForPods` has stop channel. Timeouts should be handled by the caller.",closed,True,2018-10-23 14:16:03,2018-10-31 13:51:50
perf-tests,AdamDang,https://github.com/kubernetes/perf-tests/pull/265,https://api.github.com/repos/kubernetes/perf-tests/issues/265,Update design.md,fix some typos,closed,True,2018-10-24 07:11:39,2018-10-24 07:24:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/266,https://api.github.com/repos/kubernetes/perf-tests/issues/266,ClusterLoader - Adding resources versions state,"- Adding resources versions state
This is a map {apiVersion, Kind} -> {resourceVersion}
File `pkg/state/resource_state.go`.
- Adding state that contains both namespaces state (previous state) and resources versions state
Files: `pkg/state/state.go`, `pkg/state/namespaces_state.go`.
- Applying changes
Files: all not listed above.",closed,True,2018-10-24 12:29:02,2018-10-25 11:04:58
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/267,https://api.github.com/repos/kubernetes/perf-tests/issues/267,ClusterLoader - Storing resources versions,"- `CreateObject` and `PatchObject` return server objects
- test executor stores resource types versions in State.",closed,True,2018-10-25 11:17:31,2018-10-26 14:12:33
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/268,https://api.github.com/repos/kubernetes/perf-tests/issues/268,Perfdash - Dropping old callbacks,"This is a handling for:
1. Requesting metric X
2. Requesting metric Y
3. Getting response Y. Drawing chart for Y.
4. Getting response X (due to X taking longer than Y). Drawing chart for X.

Point 4. is wrong. It should just omit the stale response.",closed,True,2018-10-25 11:30:01,2018-10-25 11:45:33
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/269,https://api.github.com/repos/kubernetes/perf-tests/issues/269,ClusterLoader: Using shared podStrore,Creating multiple podStores at the same time result in some podStores not being created. Measurements should use shared podStore instead of creating multiple podStores to avoid this problem.,closed,False,2018-10-26 11:48:49,2019-03-22 12:25:15
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/270,https://api.github.com/repos/kubernetes/perf-tests/issues/270,ClusterLoader - Adding runtime object util,,closed,True,2018-10-26 15:48:57,2018-10-29 11:28:41
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/271,https://api.github.com/repos/kubernetes/perf-tests/issues/271,ClusterLoader - Updating vendor,,closed,True,2018-10-29 13:57:17,2018-10-29 14:39:31
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/272,https://api.github.com/repos/kubernetes/perf-tests/issues/272,ClusterLoader - Removing duplicated functions,ref #270 ,closed,True,2018-10-29 14:30:07,2018-10-29 16:08:28
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/273,https://api.github.com/repos/kubernetes/perf-tests/issues/273,ClusterLoader - Wait for pods update,,closed,True,2018-10-29 14:37:59,2018-10-30 09:38:40
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/274,https://api.github.com/repos/kubernetes/perf-tests/issues/274,ClusterLoader - Adding retry to listing runtime objects,,closed,True,2018-10-30 13:44:43,2018-10-30 14:19:30
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/275,https://api.github.com/repos/kubernetes/perf-tests/issues/275,ClusterLoader: add String() to measurements,Measurement interface should have String() method. All measurements should implement String() method that returns string representation of a given measurement instance.,closed,False,2018-10-31 10:31:09,2018-11-28 14:54:54
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/276,https://api.github.com/repos/kubernetes/perf-tests/issues/276,ClusterLoader: Fix error propagation in measurements,"Some errors in measurement should be logged, some cause measurement to fail and some cause test to fail.

Listed measurement should have error propagation fixed before moving test from `/test/framework` to clusterloader2:
- [ ] APIResponsiveness
- [ ] EtcdMetrics
- [ ] MetricsForE2E
- [ ] Profile
- [ ] PodStartupLatency
- [ ] ResourceUsageSummary
- [ ] SchedulingMetrics
- [ ] WaitForControlledPodsRunning
- [ ] WaitForRunningPods",open,False,2018-10-31 13:18:53,2019-02-07 14:51:43
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/277,https://api.github.com/repos/kubernetes/perf-tests/issues/277,ClusterLoader - Adding custom duration,,closed,True,2018-11-05 12:50:40,2018-11-05 13:55:01
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/278,https://api.github.com/repos/kubernetes/perf-tests/issues/278,ClusterLoader - Adding measurement dispose,Adds `Dispose` method to all measurements to ensure disposing allocated resources.,closed,True,2018-11-05 14:41:56,2018-11-06 12:36:40
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/279,https://api.github.com/repos/kubernetes/perf-tests/issues/279,ClusterLoader - Implementing shared pod store,"- Implementing shared pod store. Shared pod store collects information about all pods and allows to filter pods on client side.
- Removing field selector.

ref #269 ",closed,True,2018-11-05 16:44:12,2019-02-04 07:17:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/280,https://api.github.com/repos/kubernetes/perf-tests/issues/280,ClusterLoader - Density test - PODS_PER_NODE,,closed,True,2018-11-06 12:16:38,2018-11-06 12:45:48
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/281,https://api.github.com/repos/kubernetes/perf-tests/issues/281,ClusterLoader: adding overrides to test configs,"Cluster loader test configs should support overrides:
- There should be a way to pass value to variable through the test call.
- If value is not provided, default (specified in config) should be used.",closed,False,2018-11-06 13:07:46,2018-11-13 12:40:28
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/282,https://api.github.com/repos/kubernetes/perf-tests/issues/282,ClusterLoader - Adding mapping overrides,ref #281 ,closed,True,2018-11-06 15:01:15,2018-11-07 10:28:14
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/283,https://api.github.com/repos/kubernetes/perf-tests/issues/283,ClusterLoader - Removing stop action from load config,Applying #278 changes to load test config.,closed,True,2018-11-06 16:44:27,2018-11-07 10:28:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/284,https://api.github.com/repos/kubernetes/perf-tests/issues/284,ClusterLoader - Applying default params to test configs,fixes #281 ,closed,True,2018-11-07 10:33:51,2018-11-13 12:40:52
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/285,https://api.github.com/repos/kubernetes/perf-tests/issues/285,ClusterLoader - Moving ClusterConfig global to MeasurementManager structure,fixes #249 ,closed,True,2018-11-07 10:54:00,2018-11-12 14:17:54
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/286,https://api.github.com/repos/kubernetes/perf-tests/issues/286,ClusterLoader - Test metrics measurements bundle,,closed,True,2018-11-07 16:47:29,2018-11-14 11:57:31
perf-tests,jberkus,https://github.com/kubernetes/perf-tests/issues/287,https://api.github.com/repos/kubernetes/perf-tests/issues/287,Timescale for Perf dashboards needs to be configurable,"Yesterday, we were trying to determine if the golang upgrade had adversely affected performance.  The Perf dashboard was not in any way useful for this, which was disappointing and effectively led to a 1-day delay in releasing the beta.

The primary problem is that the timescale for the perf dash is not configurable, so it's not possible to get useful information out of it to examine specific changes.  For example, look at gce-100Nodes, E2E, DensityPodStartup.  The lines are so dense that you can't read anything at all.

We should be able to choose start and end dates for the graph data, which would allow (for example) looking at the most recent 24 hours of 100nodes.
",open,False,2018-11-07 18:20:17,2019-02-05 19:27:57
perf-tests,jberkus,https://github.com/kubernetes/perf-tests/issues/288,https://api.github.com/repos/kubernetes/perf-tests/issues/288,"Need ""key metrics"" for Perf dashboard","Once #287 is resolved, the other thing we need for the Perf dashboard to be useful to the Release Team and the broad population of contributors would be a few ""key metrics"" that are things to check immediately after a merge for a snapshot of performance effects.  These would consist of a test-metric-detail combination.

Currently, there are around 900 different combinations that can produce a graph.  It's just not possible for contributors who aren't full time on scalability to know which ones to look at.",open,False,2018-11-07 18:27:01,2019-02-06 09:28:07
perf-tests,mrueg,https://github.com/kubernetes/perf-tests/pull/289,https://api.github.com/repos/kubernetes/perf-tests/issues/289,Doc & Script fixes,,closed,True,2018-11-08 13:31:17,2018-11-12 11:01:42
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/290,https://api.github.com/repos/kubernetes/perf-tests/issues/290,Dns -  Adding jsonify,"Converting dns benchmark result files to metric files.

This will create 4 metrics:
- Latency:
  - max_latency
  - avg_latency
  - min_latency
- LatencyPerc:
  - Perc50
  - Perc90
  - Perc99
- Queries:
  - queries_completed
  - queries_lost
  - queries_send
- Qps:
  - qps",closed,True,2018-11-08 19:05:43,2018-11-29 10:28:43
perf-tests,huangqg,https://github.com/kubernetes/perf-tests/pull/291,https://api.github.com/repos/kubernetes/perf-tests/issues/291,Fix some typos,"Fix some typos in the below files:

1. clusterloader/framework/util.go
2. clusterloader2/pkg/measurement/util/perftype.go
3. clusterloader2/pkg/state/namespaces_state.go
4. slo-monitor/src/monitors/pod_monitor.go",closed,True,2018-11-11 07:48:34,2018-11-12 07:11:44
perf-tests,Rychne,https://github.com/kubernetes/perf-tests/pull/292,https://api.github.com/repos/kubernetes/perf-tests/issues/292,Add networkpolicies,"Network Policy module
A module to test if network policies have any effects on the performance of the cluster",open,True,2018-11-11 18:01:48,2019-03-21 16:41:40
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/issues/293,https://api.github.com/repos/kubernetes/perf-tests/issues/293,Expose more information in clusterloader2 logs,"There are a couple things that we definitely need:
- [x] more state about pods from a given controlling object (number of pending, waiting, checking if something was deleted, etc.). Mostly copying this logic:
https://github.com/kubernetes/kubernetes/blob/master/test/utils/runners.go#L803
- [x] pod-startup-time latency should output thing that is somewhat similar to what we currently do (for debugging purposes)
- [x] show more clearly where a given test finished:
```
W1112 13:18:48.029] I1112 13:18:48.029322    9960 clusterloader.go:127] Test testing/density/config.yaml ran successfully!""
```
is not very visible in those logs
- [x] We are currently printing about the information about nodes that is extremely helpful for debugging (this is currently part of density). It would be useful to add that too (it should probably be part of initialization of cluster loader)
- [ ] You need to audit logs in measurements - a bunch of glog`s should actually be real failures and fail the test at the end (though not immediately). I can imagine this as something like: https://github.com/kubernetes/kubernetes/issues/66239#issuecomment-405255089, but also as a special measurement that inside is collecting errors (and gloging them when they happen) and at the end fails if any logs were reported (should be simpler than a separate flakes.txt file).

I guess there may be more, but let's start with those.

/assign @krzysied ",open,False,2018-11-12 14:26:41,2019-02-14 19:09:55
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/294,https://api.github.com/repos/kubernetes/perf-tests/issues/294,ClusterLoader - Adding metric violation error,Failing tests when api responsiveness metric is not satisfy.,closed,True,2018-11-13 13:49:42,2018-11-14 09:15:52
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/295,https://api.github.com/repos/kubernetes/perf-tests/issues/295,ClusterLoader - Reimplementing wait for pods measurement logs,"Reimplementing wait for pods logs, so it provides more information about pods states.
Ref #293 ",closed,True,2018-11-13 17:30:26,2018-11-15 13:26:47
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/296,https://api.github.com/repos/kubernetes/perf-tests/issues/296,"ClusterLoader: Profiles should gather periodically, instead of ""on-demand""","Currently profile measurement allows to gather cpu/memory profile on-demand. There should be also an option to gather profiles periodically, for example every 10mins.",open,False,2018-11-14 11:49:10,2019-02-14 19:07:51
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/297,https://api.github.com/repos/kubernetes/perf-tests/issues/297,ClusterLoader - Fixing test metrics bundle,"Setting `ClusterConfig` in test metric bundle, which is required by the metrics.",closed,True,2018-11-14 14:00:20,2018-11-14 14:13:43
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/298,https://api.github.com/repos/kubernetes/perf-tests/issues/298,ClusterLoader - Fixing pods status printing,,closed,True,2018-11-15 13:31:07,2018-11-15 13:45:03
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/299,https://api.github.com/repos/kubernetes/perf-tests/issues/299,ClusterLoader - Updating pod startup measurement logs,"Added:
- failing when podStartupLatencyThreshold(5s) is not satisfied.
- logging pod latencies.

ref #293 ",closed,True,2018-11-15 14:26:57,2018-11-16 09:21:11
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/300,https://api.github.com/repos/kubernetes/perf-tests/issues/300,ClusterLoader - Logging nodes,"Logging available nodes list (name, internal ip, external ip) before running tests.

ref #293 ",closed,True,2018-11-16 12:39:02,2018-11-16 15:38:07
perf-tests,sengi,https://github.com/kubernetes/perf-tests/pull/301,https://api.github.com/repos/kubernetes/perf-tests/issues/301,Custom distribution buckets for pod e2e startup time metrics,"Specify custom bucket boundaries to extend the range of these metrics
up to 1 hour while keeping the number of buckets to a minimum and
preserving exact boundaries to support existing benchmarks and SLOs,
including ""99% of pods with pre-pulled images start within 5 seconds"".

The motivation for extending the range is to measure end-to-end pod
startup time in production clusters, where startup times can be much
longer than under test conditions.",closed,True,2018-11-16 14:22:34,2018-11-16 15:17:52
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/302,https://api.github.com/repos/kubernetes/perf-tests/issues/302,ClusterLoader - Updating pod startup measurement error text,Changing error text.,closed,True,2018-11-16 15:49:16,2018-11-19 10:52:20
perf-tests,prameshj,https://github.com/kubernetes/perf-tests/pull/303,https://api.github.com/repos/kubernetes/perf-tests/issues/303,Add support to test node-local-cache dns server,"Added new test to query multiple service names
Also a flag to run large number of external hostname queries",closed,True,2018-11-19 19:01:48,2019-03-12 07:44:38
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/304,https://api.github.com/repos/kubernetes/perf-tests/issues/304,ClusterLoader - Moving errors to pkg/errors,"Moving:
- `pkg/util/error_list.go` → `pkg/errors/error_list.go`
- `pkg/measurement/errors.go` → `pkg/errors/metric_violation_error.go`",closed,True,2018-11-20 14:47:03,2018-11-22 09:38:32
perf-tests,sengi,https://github.com/kubernetes/perf-tests/pull/305,https://api.github.com/repos/kubernetes/perf-tests/issues/305,Increment version number for slo-monitor.,Changes in this version: new distribution bucket boundaries for the pod startup metrics.,closed,True,2018-11-20 15:20:37,2018-11-20 15:31:56
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/306,https://api.github.com/repos/kubernetes/perf-tests/issues/306,ClusterLoader - Adding measurement String() method,"Adding `String()` method to measurement interface.

ref #275 ",closed,True,2018-11-21 13:03:22,2018-11-22 10:11:32
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/307,https://api.github.com/repos/kubernetes/perf-tests/issues/307,ClusterLoader - handling SLOs fails,Tests will continue if there are only metric violation errors.,closed,True,2018-11-22 09:57:17,2018-11-23 09:59:00
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/308,https://api.github.com/repos/kubernetes/perf-tests/issues/308,ClusterLoader - Resource usage constrains,"Changes:
- Adding template provider to measurement config
- Resource usage constrains validation
Resource constrains can be specified with yaml file. Resource validation was moved to resource usage measurement. If constraint is violated, metric violation error will be returned.",closed,True,2018-11-22 10:47:52,2018-11-23 10:30:12
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/309,https://api.github.com/repos/kubernetes/perf-tests/issues/309,ClusterLoader - 5x100 density test update,Temporally changing test to make 5x  create latency pods iterations. Required to compare different latency pods creation approaches.,closed,True,2018-11-23 12:32:50,2018-11-23 13:43:30
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/310,https://api.github.com/repos/kubernetes/perf-tests/issues/310,CluasterLoader: Revert density test changes,With #309 density test was changed to compare pod startup time of 500 pods at once vs 5x100 pods iteration. This change should be reverted after 11/26/2018.,closed,False,2018-11-23 12:43:29,2018-11-27 13:16:06
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/311,https://api.github.com/repos/kubernetes/perf-tests/issues/311,"Revert ""ClusterLoader - 5x100 density test update""","Reverts kubernetes/perf-tests#309

fixes #310 ",closed,True,2018-11-26 11:56:43,2018-11-27 13:27:30
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/312,https://api.github.com/repos/kubernetes/perf-tests/issues/312,ClusterLoader: PodStartupLatency is flaky,"In cluster loader density test pod startup latency (99 perc.) varies from 4s to 8s. The same metric from original tests always has 99 perc = ~4s.
This problem should be fix, so cluster loader PodStartupLatency has similar results to original test ones.",closed,False,2018-11-26 14:30:38,2018-12-03 11:01:55
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/313,https://api.github.com/repos/kubernetes/perf-tests/issues/313,ClusterLoader - Adding owner file to clusterloader2,,closed,True,2018-11-27 12:51:30,2018-11-27 13:12:43
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/314,https://api.github.com/repos/kubernetes/perf-tests/issues/314,ClusterLoader - Adding bundle restriction,"Adding restriction on bundle. It's now required that all bundle objects have the some replica count.

ref #261",closed,True,2018-11-27 14:32:41,2018-11-27 17:07:55
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/315,https://api.github.com/repos/kubernetes/perf-tests/issues/315,ClusterLoader - Adding resource requests to latency pods,"Bumping up latency pods resources to reduce pod assignment variance.

ref #312 ",closed,True,2018-11-27 18:17:28,2018-11-28 14:38:38
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/316,https://api.github.com/repos/kubernetes/perf-tests/issues/316,ClusterLoader - Marking execution as failed when at least one test failed,"Failing cluster loader execution if one or more tests had error.
Fail status will be returned after each test is executed.",closed,True,2018-11-27 18:40:37,2018-11-28 14:40:57
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/317,https://api.github.com/repos/kubernetes/perf-tests/issues/317,ClusterLoader: Separate rows in testgrid,Each test case should have separate row in testgrid.,closed,False,2018-11-28 10:21:44,2018-11-29 10:33:57
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/318,https://api.github.com/repos/kubernetes/perf-tests/issues/318,Cluster loader junit log,"Adds junit.xml file that is used by the testgrid to add additional rows for tests.

ref #317 ",closed,True,2018-11-28 14:28:45,2018-11-28 14:39:49
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/319,https://api.github.com/repos/kubernetes/perf-tests/issues/319,ClusterLoader - Adding scheduling throughput,,closed,True,2018-11-29 10:29:46,2018-11-29 12:39:57
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/320,https://api.github.com/repos/kubernetes/perf-tests/issues/320,ClusterLoader - Correcting misspelled metric name,,closed,True,2018-11-29 14:12:07,2018-11-29 14:23:30
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/321,https://api.github.com/repos/kubernetes/perf-tests/issues/321,ClusterLoader - Minor measurement error fixes,,closed,True,2018-11-30 10:21:38,2018-11-30 10:36:28
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/322,https://api.github.com/repos/kubernetes/perf-tests/issues/322,ClusterLoader - Adding resource constraints to 100 nodes density test,,closed,True,2018-11-30 11:56:06,2018-12-05 10:27:32
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/323,https://api.github.com/repos/kubernetes/perf-tests/issues/323,Updating dns benchmark run script,"- dns/run takes care of running benchmark. It runs tests, creates required directories and creates metrics.
- run-e2e.sh only calls dns/run",closed,True,2018-11-30 14:59:37,2018-12-06 13:18:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/324,https://api.github.com/repos/kubernetes/perf-tests/issues/324,ClusterLoader: Pretty printing test summary,ref #293 ,closed,True,2018-12-03 14:30:23,2018-12-04 09:44:43
perf-tests,mrueg,https://github.com/kubernetes/perf-tests/pull/325,https://api.github.com/repos/kubernetes/perf-tests/issues/325,Allow to set masternode / masterip through CLI,When trying to run the benchmark locally this was helpful,closed,True,2018-12-03 22:14:20,2018-12-04 10:03:33
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/326,https://api.github.com/repos/kubernetes/perf-tests/issues/326,ClusterLoader: Investigate kube-controller-manager cpu usage,"Kube-controller-manager uses more cpu than it should. Limit is 0.8 core, however it happens that it uses ~0.9.

When this is issue is solved, clusterloader density test  kube-controller-manager constraint should be updated or at least comment explaining the reason should be added.",open,False,2018-12-04 09:53:53,2019-02-14 19:07:47
perf-tests,mrueg,https://github.com/kubernetes/perf-tests/pull/327,https://api.github.com/repos/kubernetes/perf-tests/issues/327,clusterloader2: Set etcd metrics cmd from CLI,"etcd might run on a different machine, with TLS or client certs or on a different port.
This allows to set the command via CLI.",closed,True,2018-12-04 16:30:48,2019-02-11 00:33:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/328,https://api.github.com/repos/kubernetes/perf-tests/issues/328,ClusterLoader - Fixing test metrics bundle,Summaries should be always appended.,closed,True,2018-12-05 13:50:53,2018-12-05 14:07:37
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/329,https://api.github.com/repos/kubernetes/perf-tests/issues/329,Perfdash -  Unknown job type fix,,closed,True,2018-12-06 14:36:13,2018-12-06 17:49:12
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/330,https://api.github.com/repos/kubernetes/perf-tests/issues/330,Perfdash - Scheduling throughput metrics,"- Adding multiple parser support.
If first parser fails, second is used... Required to properly handle changes in metric.
- Adding cluster loader scheduling throughput metrics.",closed,True,2018-12-07 14:00:27,2018-12-07 15:30:45
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/331,https://api.github.com/repos/kubernetes/perf-tests/issues/331,Dns benchmark - Fixing dns benchmark path,,closed,True,2018-12-10 10:23:02,2018-12-10 13:26:22
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/332,https://api.github.com/repos/kubernetes/perf-tests/issues/332,Perfdash - dns benchmark config,,closed,True,2018-12-10 12:31:14,2018-12-10 12:45:51
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/333,https://api.github.com/repos/kubernetes/perf-tests/issues/333,Dns benchmark - Adding numpy installation to run script,"Adding numpy installation to run script, due to numpy being required by `py/run_perf.py`. This command installs numpy or does nothing is numpy s already available.",closed,True,2018-12-10 14:08:34,2018-12-10 15:59:36
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/334,https://api.github.com/repos/kubernetes/perf-tests/issues/334,Perfdash - Removing empty labels,Removing empty label set. There is on point in having selectable label list when there are no value in it.,closed,True,2018-12-11 10:55:12,2018-12-12 09:43:45
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/335,https://api.github.com/repos/kubernetes/perf-tests/issues/335,ClusterLoader - Minor logging fix,Adding missing parameter.,closed,True,2018-12-12 11:04:43,2018-12-12 11:58:30
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/336,https://api.github.com/repos/kubernetes/perf-tests/issues/336,Dns benchmark - Fixing dns metrics units,,closed,True,2018-12-12 13:20:40,2018-12-12 13:33:22
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/337,https://api.github.com/repos/kubernetes/perf-tests/issues/337,ClusterLoader - Overriding resource usage gathering for 2000 nodes test,Resource usage will be gather from master and dns only.,closed,True,2018-12-12 16:42:16,2018-12-12 17:02:40
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/338,https://api.github.com/repos/kubernetes/perf-tests/issues/338,ClusterLoader - Updating 100 nodes density constraints,"- apiserver cpu: 1.7 -> 1.9
- scheduler cpu: 0.25 -> 0.35

ref https://github.com/kubernetes/kubernetes/issues/72016",closed,True,2018-12-13 10:59:02,2018-12-13 11:49:23
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/339,https://api.github.com/repos/kubernetes/perf-tests/issues/339,Add not-ready/unreachable node tolerations ot density/load rcs.,"This way, if node goes down (e.g. due to hostError), the test won't fail.",closed,True,2018-12-14 12:32:34,2018-12-14 12:42:41
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/340,https://api.github.com/repos/kubernetes/perf-tests/issues/340,ClusterLoader- Fixing measurements for kubemark,,closed,True,2018-12-17 18:49:25,2018-12-18 11:42:41
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/341,https://api.github.com/repos/kubernetes/perf-tests/issues/341,ClusterLoader - Fixing RC deletion handling,"- Waiting for pods.
Measurement will wait until desired pods are running and there are no others pods that match given labels and namespace (regardless their statuses).
- Waiting for controlled pod.
Handling of object deletion changed to waiting for pods with desired replicas equaling 0.",closed,True,2018-12-18 14:26:08,2018-12-19 10:46:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/342,https://api.github.com/repos/kubernetes/perf-tests/issues/342,Clusterloader - Measurement fixes,Fixing parameters order.,closed,True,2018-12-18 17:01:28,2018-12-18 17:43:38
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/343,https://api.github.com/repos/kubernetes/perf-tests/issues/343,Add API to configure node killing in clusterloader2.,"The idea is to add clusterloader-level feature to simulate node failures (NodeKiller in old framework). In future we may want to extend this to master component failures, pod failures and other.",closed,True,2018-12-19 08:58:45,2018-12-19 09:17:54
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/344,https://api.github.com/repos/kubernetes/perf-tests/issues/344,ClusterLoader - Kubemark flag,,closed,True,2018-12-19 11:00:38,2018-12-19 15:50:40
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/345,https://api.github.com/repos/kubernetes/perf-tests/issues/345,Migrate NodeKiller to clusterloader2.,"This is basically copy-paste of https://github.com/kubernetes/kubernetes/pull/71320.

In the next step, once we migrate -killer job to clusterloader2, I will remove NodeKiller from kubernetes/kubernetes repo to remove code duplication.

/assign @wojtek-t 
/assign @krzysied ",closed,True,2018-12-19 12:23:05,2018-12-19 12:35:00
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/346,https://api.github.com/repos/kubernetes/perf-tests/issues/346,Add a way to optionally enable chaos monkey in tests.,"Chaos monkey is disabled by default, but can be enabled by adding --testoverrides=testing/chaosmonkey/override.yaml.

/assign @wojtek-t ",closed,True,2018-12-19 13:05:22,2018-12-19 13:43:28
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/347,https://api.github.com/repos/kubernetes/perf-tests/issues/347,Don't ignore error returned by ctx.GetChaosMonkey().Init.,/assign @krzysied ,closed,True,2018-12-19 13:45:42,2018-12-19 13:56:31
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/348,https://api.github.com/repos/kubernetes/perf-tests/issues/348,Bug in chaos.Monkey: add missing go in m.nodeKiller.Run() call.,"Right now it blocks the main goroutine :|

/assign @wojtek-t 
/assign @krzysied ",closed,True,2018-12-19 14:53:00,2018-12-19 15:03:30
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/349,https://api.github.com/repos/kubernetes/perf-tests/issues/349,Reduce amount of unuseful logs,Those are redundant with what is already written from wait_for_pods.,closed,True,2018-12-19 14:59:12,2018-12-19 15:48:44
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/350,https://api.github.com/repos/kubernetes/perf-tests/issues/350,ClusterLoader - Adding env flags,Adding env flags that can read env variable if flag is not provided.,closed,True,2018-12-19 15:50:01,2019-01-02 12:05:29
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/351,https://api.github.com/repos/kubernetes/perf-tests/issues/351,ClusterLoader - Adding 5k overrides,,closed,True,2018-12-19 16:33:42,2018-12-20 09:54:59
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/352,https://api.github.com/repos/kubernetes/perf-tests/issues/352,ClusterLoader - Increasing lb-controller cpu constraint,,closed,True,2018-12-20 09:56:01,2018-12-20 10:10:13
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/353,https://api.github.com/repos/kubernetes/perf-tests/issues/353,Change operationTimeout to 15m in scalability tests,"As operationTimeout for WaitForRunningSaturationRCs was dynamically computed, I changed hard deadline to 15m and moved logic to compare perc99 in SaturationPodStartupLatency.

/assign @wojtek-t 
/assign @krzysied ",closed,True,2018-12-20 10:03:52,2018-12-20 12:20:30
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/354,https://api.github.com/repos/kubernetes/perf-tests/issues/354,Change perfdash to look for PodStartupLatency metrics in new place.,"The path changes in #353 from PodStartupLatency to PodStartupLatency_PodStartupLatency and a new metric PodStartupLatency_SaturationPodStartupLatency is added.

/assign @krzysied ",closed,True,2018-12-20 11:53:11,2018-12-20 12:07:58
perf-tests,mrueg,https://github.com/kubernetes/perf-tests/issues/355,https://api.github.com/repos/kubernetes/perf-tests/issues/355,"Clusterloader: Document purpose of load, density, chaosmonkey tests",It would be awesome to have a README for each of those tests in that explain what their test/benchmarking goal is,open,False,2018-12-20 13:00:38,2019-03-20 14:29:21
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/356,https://api.github.com/repos/kubernetes/perf-tests/issues/356,Modify pod_startup_latency not to fail in case of missing schedule event.,"Events are best effort and it can happen that some of them are missing, especially when we schedule a lot of events together.

/assign @wojtek-t ",closed,True,2018-12-20 14:38:46,2018-12-20 14:48:28
perf-tests,fejta,https://github.com/kubernetes/perf-tests/issues/357,https://api.github.com/repos/kubernetes/perf-tests/issues/357,Create a SECURITY_CONTACTS file.,"As per the email sent to kubernetes-dev[1], please create a SECURITY_CONTACTS
file.

The template for the file can be found in the kubernetes-template repository[2].
A description for the file is in the steering-committee docs[3], you might need
to search that page for ""Security Contacts"".

Please feel free to ping me on the PR when you make it, otherwise I will see when
you close this issue. :)

Thanks so much, let me know if you have any questions.

(This issue was generated from a tool, apologies for any weirdness.)

[1] https://groups.google.com/forum/#!topic/kubernetes-dev/codeiIoQ6QE
[2] https://github.com/kubernetes/kubernetes-template-project/blob/master/SECURITY_CONTACTS
[3] https://github.com/kubernetes/community/blob/master/committee-steering/governance/sig-governance-template-short.md
",closed,False,2018-12-21 09:09:55,2018-12-21 17:38:48
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/358,https://api.github.com/repos/kubernetes/perf-tests/issues/358,Add Security contacts,Fix https://github.com/kubernetes/perf-tests/issues/357,closed,True,2018-12-21 09:23:13,2018-12-21 17:38:48
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/359,https://api.github.com/repos/kubernetes/perf-tests/issues/359,Dns benchmark files rename,"Renaming benchmark files to be more generic.
Will allow easier job creation + perfdash setup.",closed,True,2018-12-24 12:17:05,2018-12-28 08:42:37
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/360,https://api.github.com/repos/kubernetes/perf-tests/issues/360,ClusterLoader - Bumping up test resources,"Bumping up density test resources:
- apiserver cpu 1.9 -> 2.0
- scheduler memory 100MB -> 110MB",closed,True,2018-12-24 12:23:15,2018-12-28 08:41:03
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/361,https://api.github.com/repos/kubernetes/perf-tests/issues/361,Change apiserver's memory limit to 1200M.,Right now the test is using approx. ~980M so we are way too close to the limit (and we are hitting the limit in -killer job).,closed,True,2019-01-02 08:38:13,2019-01-02 08:54:24
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/362,https://api.github.com/repos/kubernetes/perf-tests/issues/362,ClusterLoader - Changing to 1 svc per 2 rcs,"Changing logic of the test to:
1. Create 1 SVC per every 2 RCs (that will be created).
2. Create RCs. 
3. Scale RCs
4. Delete RCs
5. Delete SVCs",closed,True,2019-01-03 15:11:35,2019-01-04 11:51:44
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/363,https://api.github.com/repos/kubernetes/perf-tests/issues/363,ClusterLoader - Updating density 100 nodes constraints,"- apiserver cpu 2.0 -> 2.2
- controller manager cpu 0.9 -> 1.1",closed,True,2019-01-04 10:17:00,2019-01-04 11:48:39
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/364,https://api.github.com/repos/kubernetes/perf-tests/issues/364,ClusterLoader - Adding multiple clients,Changing client to multiclients. Multiclients are sets of clients with additional logic for providing single client instance.,closed,True,2019-01-04 13:59:19,2019-01-04 14:37:58
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/365,https://api.github.com/repos/kubernetes/perf-tests/issues/365,ClusterLoader - Adding ParallelismLimitedLoad tuning set,Adding new tuning set to execute operations with limited parallelism.,closed,True,2019-01-04 14:55:21,2019-01-04 15:05:31
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/366,https://api.github.com/repos/kubernetes/perf-tests/issues/366,ClusterLoader - Executing load test service operation in a sequence.,Adding and deleting services 1 by 1.,closed,True,2019-01-04 15:09:49,2019-01-08 14:58:55
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/367,https://api.github.com/repos/kubernetes/perf-tests/issues/367,ClusterLoader - Fixing multiclient,Forcing clients to no share underling transport.,closed,True,2019-01-08 18:12:08,2019-01-09 09:29:05
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/368,https://api.github.com/repos/kubernetes/perf-tests/issues/368,ClusterLoader - Adding load test rc missing config entries,,closed,True,2019-01-09 14:13:48,2019-01-09 14:25:17
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/369,https://api.github.com/repos/kubernetes/perf-tests/issues/369,Perfdash - Parsing release blocking job config,"Adding [sig-scalability-release-blocking-jobs.yaml](https://github.com/kubernetes/test-infra/blob/master/config/jobs/kubernetes/sig-scalability/sig-scalability-release-blocking-jobs.yaml) file parsing.

/ref https://github.com/kubernetes/test-infra/pull/10637",closed,True,2019-01-10 10:44:51,2019-01-10 13:29:41
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/370,https://api.github.com/repos/kubernetes/perf-tests/issues/370,Add mborsz to perfdash/OWNERS,/assign @krzysied ,closed,True,2019-01-10 11:02:46,2019-01-10 11:54:30
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/371,https://api.github.com/repos/kubernetes/perf-tests/issues/371,CLusterLoader: DNS is using more memory than it used to,"After changing tests to clusterloader's, coreDNS (and also kubeDNS) is using more memory than it used to.
![coredns_memory](https://user-images.githubusercontent.com/25119199/51028390-8e1aaf00-1593-11e9-987b-e9d73d27aaea.png)

This issue causes cordns on  5k nodes to OOM.",closed,False,2019-01-11 10:26:14,2019-01-16 14:17:13
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/372,https://api.github.com/repos/kubernetes/perf-tests/issues/372,ClusterLoader - Changing to original load RC randimized range,"Changing replicas random range to match original tests: https://github.com/kubernetes/kubernetes/blob/49891cc270019245a3d4796e84b33bf36d0bae08/test/e2e/scalability/load.go#L674

ref #371 

Should reduce pod post calls.",closed,True,2019-01-11 10:40:28,2019-01-15 12:10:59
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/373,https://api.github.com/repos/kubernetes/perf-tests/issues/373,Use os.MkdirAll instead of os.MkDir when creating report dir,"MkDirAll is an equivalent of mkdir -p command, it creates all necessary parent directories if needed.
",closed,True,2019-01-11 11:07:40,2019-01-11 11:18:24
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/374,https://api.github.com/repos/kubernetes/perf-tests/issues/374,ClusterLoader - Making every second RC use svc,"This change will make only half of pods to use SVCs. Same as in original load test.

ref #371",closed,True,2019-01-11 14:30:21,2019-01-12 11:56:24
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/375,https://api.github.com/repos/kubernetes/perf-tests/issues/375,ClusterLoader - Adding service assignment description,Adding assumptions about services and theirs assignments to replication controllers.,closed,True,2019-01-15 10:12:59,2019-01-15 10:32:10
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/376,https://api.github.com/repos/kubernetes/perf-tests/issues/376,Clusterloader - Bumping up scheduler memory constraint,"Scheduler avg memory usage (gce 100) has increased ~5MB. Bumping up constraint to prevent flakes.

Memory has increased between run 21637 and 21640, possible due to https://github.com/kubernetes/kubernetes/pull/71731 PR.",closed,True,2019-01-15 10:52:40,2019-01-21 09:22:36
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/377,https://api.github.com/repos/kubernetes/perf-tests/issues/377,ClusterLoader - Separating test throughput,Making separate variables for density test throughput and load test throughput.,closed,True,2019-01-15 14:22:29,2019-01-15 14:33:34
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/378,https://api.github.com/repos/kubernetes/perf-tests/issues/378,ClusterLoader: Move overrides to separate directory,"Overrides should be moved from clusterloader2/testing/density/ to clusterloader2/overrides.
Overrides should be split into provider category.",open,False,2019-01-15 16:46:10,2019-01-16 12:33:10
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/379,https://api.github.com/repos/kubernetes/perf-tests/issues/379,ClusterLoader - Adding override for kubemark 500,"Adding override for kubemark 500

ref #378 ",closed,True,2019-01-15 16:50:43,2019-01-16 12:36:25
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/380,https://api.github.com/repos/kubernetes/perf-tests/issues/380,"Revert ""ClusterLoader - Changing to original load RC randimized range""","The last run of ci-kubernetes-e2e-gce-scale-performance-cl was successful.
#372 shouldn't have a big impact on test execution -  this change is being reverted. 

Reverts kubernetes/perf-tests#372",closed,True,2019-01-16 09:38:28,2019-01-16 10:59:16
perf-tests,mazzy89,https://github.com/kubernetes/perf-tests/issues/381,https://api.github.com/repos/kubernetes/perf-tests/issues/381,Explanation of some constants,What does it mean `NODES_PER_NAMESPACE` in the `config.yaml` of the clusterloader2?,open,False,2019-01-16 17:37:01,2019-01-16 17:37:01
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/382,https://api.github.com/repos/kubernetes/perf-tests/issues/382,ClusterLoader - Logging profile error for gke,"Profiles will only log master sshing error instead of propagating it to caller.
Gathering profiles from apiserver is not a standard thing in gke.",closed,True,2019-01-17 14:46:17,2019-01-17 16:43:53
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/383,https://api.github.com/repos/kubernetes/perf-tests/issues/383,ClusterLoader - Bumping up controller manager memory,Controller manger memory constraint 250MB -> 300MB.,closed,True,2019-01-17 17:50:58,2019-01-17 18:01:53
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/384,https://api.github.com/repos/kubernetes/perf-tests/issues/384,ClusterLoader - Vendor update,Updating clusterloader2 vendor.,closed,True,2019-01-18 13:05:08,2019-01-18 13:45:19
perf-tests,mazzy89,https://github.com/kubernetes/perf-tests/issues/385,https://api.github.com/repos/kubernetes/perf-tests/issues/385,SSH connection issue to access the master,"I'm having this issue to run *clusterloader2.*

```sh
[ec2-user@ip-172-20-61-134 clusterloader2]$ USER=admin AWS_SSH_KEY=~/.ssh/kube_aws_rsa ./clusterloader --kubeconfig=$HOME/.kube/config --testconfig=testing/load/config.yaml --masterip=172.20.50.99 --provider=aws
E0121 22:21:31.987756   32213 clusterloader.go:98] Getting master name error: master node not found
E0121 22:22:17.975753   32213 test_metrics.go:127] TestMetrics: [unexpected error (code: 7) in ssh connection to master: <nil>]
E0121 22:22:17.978288   32213 clusterloader.go:142] --------------------------------------------------------------------------------
E0121 22:22:17.978336   32213 clusterloader.go:143] Test Finished
E0121 22:22:17.978380   32213 clusterloader.go:144]   Test: testing/load/config.yaml
E0121 22:22:17.978434   32213 clusterloader.go:145]   Status: Fail
E0121 22:22:17.978475   32213 clusterloader.go:147]   Errors: [measurement call TestMetrics - TestMetrics error: [unexpected error (code: 7) in ssh connection to master: <nil>]]
E0121 22:22:17.978521   32213 clusterloader.go:149] --------------------------------------------------------------------------------
F0121 22:22:17.978735   32213 clusterloader.go:217] 1 tests have failed!
goroutine 1 [running]:
k8s.io/perf-tests/clusterloader2/vendor/github.com/golang/glog.stacks(0xc420082100, 0xc420798600, 0x49, 0x163)
    /home/ec2-user/projects/src/k8s.io/perf-tests/clusterloader2/vendor/github.com/golang/glog/glog.go:769 +0xcf
k8s.io/perf-tests/clusterloader2/vendor/github.com/golang/glog.(*loggingT).output(0x1ff6c00, 0xc400000003, 0xc420a528f0, 0x1f643e9, 0x10, 0xd9, 0x0)
    /home/ec2-user/projects/src/k8s.io/perf-tests/clusterloader2/vendor/github.com/golang/glog/glog.go:720 +0x32d
k8s.io/perf-tests/clusterloader2/vendor/github.com/golang/glog.(*loggingT).printf(0x1ff6c00, 0xc400000003, 0x154936b, 0x15, 0xc420337be8, 0x1, 0x1)
    /home/ec2-user/projects/src/k8s.io/perf-tests/clusterloader2/vendor/github.com/golang/glog/glog.go:655 +0x14b
k8s.io/perf-tests/clusterloader2/vendor/github.com/golang/glog.Fatalf(0x154936b, 0x15, 0xc420337be8, 0x1, 0x1)
    /home/ec2-user/projects/src/k8s.io/perf-tests/clusterloader2/vendor/github.com/golang/glog/glog.go:1148 +0x67
main.main()
    /home/ec2-user/projects/src/k8s.io/perf-tests/clusterloader2/cmd/clusterloader.go:217 +0x9fa
```

My cluster is running on AWS with a private topology. Masters running in different AZs in  private subnets. I run the go bin from an instance in the same subnet. I'm sure I can reach the master via ssh because I run `ssh admin@172.20.50.99` and it connects successfully. Unfortunately the error I get back it is not very verbose so I can't go ahead. Any hints?",open,False,2019-01-22 10:07:15,2019-01-22 10:07:26
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/386,https://api.github.com/repos/kubernetes/perf-tests/issues/386,ClusterLoader - Adding timeout status for controlling objects checkers,"Adding different handling for controlling object check timeout.
WaitForControlledPodsRunningMeasurement will print number of time-outed checks.",closed,True,2019-01-24 15:07:47,2019-01-24 15:25:16
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/387,https://api.github.com/repos/kubernetes/perf-tests/issues/387,ClusterLoader - Adding high density override,Adding override for high density test.,closed,True,2019-01-25 12:09:42,2019-01-25 12:35:27
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/388,https://api.github.com/repos/kubernetes/perf-tests/issues/388,ClusterLoader - Fixing wait for controlling objects timeout,Fixing bug introduced in #386 . It caused setting timeout status even if there was no timeout.,closed,True,2019-01-25 13:58:20,2019-01-25 15:53:32
perf-tests,prameshj,https://github.com/kubernetes/perf-tests/pull/389,https://api.github.com/repos/kubernetes/perf-tests/issues/389,Adding myself to OWNERS,,closed,True,2019-01-26 00:39:40,2019-01-28 19:12:50
perf-tests,mivanovvs,https://github.com/kubernetes/perf-tests/issues/390,https://api.github.com/repos/kubernetes/perf-tests/issues/390,clusterload2: flag redefined: log_dir,"Hi there! The issue I've got on mac os and ubuntu 18.04 with GO 1.11
After all installed dependencies I've got the error:

`./run-e2e.sh
./clusterloader flag redefined: log_dir
panic: ./clusterloader flag redefined: log_dir

goroutine 1 [running]:
flag.(*FlagSet).Var(0xc0000ba180, 0x22e92e0, 0xc00034b800, 0x215c5e8, 0x7, 0x21909df, 0x2f)
	/usr/local/opt/go/libexec/src/flag/flag.go:805 +0x529
flag.(*FlagSet).StringVar(0xc0000ba180, 0xc00034b800, 0x215c5e8, 0x7, 0x0, 0x0, 0x21909df, 0x2f)
	/usr/local/opt/go/libexec/src/flag/flag.go:708 +0x8a
flag.(*FlagSet).String(0xc0000ba180, 0x215c5e8, 0x7, 0x0, 0x0, 0x21909df, 0x2f, 0xc00034b7f0)
	/usr/local/opt/go/libexec/src/flag/flag.go:721 +0x8b
flag.String(0x215c5e8, 0x7, 0x0, 0x0, 0x21909df, 0x2f, 0xe)
	/usr/local/opt/go/libexec/src/flag/flag.go:728 +0x69`

Any ideas how to solve that? ",open,False,2019-01-28 12:37:52,2019-02-27 14:02:18
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/391,https://api.github.com/repos/kubernetes/perf-tests/issues/391,ClusterLoader - Removing cmd binary,"Removing compiled clusterloader binary, that was accidentally uploaded.",closed,True,2019-01-28 13:26:12,2019-01-28 15:37:23
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/392,https://api.github.com/repos/kubernetes/perf-tests/issues/392,ClusterLoader - Increasing timeout for waiting for deletion operations,"Increasing timeout for operation related to the pod deletion.

This change is required due to the garbage collector requiring twice as much time to remove the pods as it was needed for pods creation.",closed,True,2019-01-28 16:11:14,2019-01-29 12:45:14
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/393,https://api.github.com/repos/kubernetes/perf-tests/issues/393,ClusterLoader - log which ReplicationControllers have timed-out.,This will help us debug issues like https://github.com/kubernetes/kubernetes/issues/73461,closed,True,2019-01-29 11:19:54,2019-01-29 12:38:13
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/394,https://api.github.com/repos/kubernetes/perf-tests/issues/394,ClusterLoader - Updating vendor,,closed,True,2019-01-30 14:26:08,2019-01-30 16:10:12
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/395,https://api.github.com/repos/kubernetes/perf-tests/issues/395,ClusterLoader - Updating README,"Adding info about:
- overrides
- metrics: APIResponsiveness, PodStartupLatency, ResourceUsageSummary, SchedulingThroughput",closed,True,2019-01-31 12:38:27,2019-02-01 12:04:53
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/issues/396,https://api.github.com/repos/kubernetes/perf-tests/issues/396,ClusterLoader2 assumes ssh service should be available,"**What happened?**

In our cluster, ssh is not available. However, `clusterloader2/pkg/measurement/util/ssh.go:88` assumes every master should own an available ssh service. 

Errors occurred as follow, 

```
[root@Betula-L kubernetes]# ./clusterloader --kubeconfig=""${HOME}/.kube/config"" --testconfig=testing/density/config.yaml --provider=kubemark --masterip=10.142.43.51 --mastername=localhost
E0201 11:30:17.948014   11090 test_metrics.go:127] TestMetrics: [unexpected error (code: 0) in ssh connection to master: &errors.errorString{s:""error getting signer for provider kubemark: 'error reading SSH key /root/.ssh/google_compute_engine: 'open /root/.ssh/google_compute_engine: no such file or directory''""}]
E0201 11:30:17.948183   11090 kubemark.go:50] error when trying to SSH to master machine. Skipping probe. error getting signer for provider kubemark: 'error reading SSH key /root/.ssh/google_compute_engine: 'open /root/.ssh/google_compute_engine: no such file or directory''

```
**What you expected to happen**:

We may run clusterloader on master without ssh. If parameter `masterip==localhost`, clusterloader could execute `func execLocal()`  rather than `func SSH()`",closed,False,2019-02-01 03:41:19,2019-02-14 02:02:57
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/pull/397,https://api.github.com/repos/kubernetes/perf-tests/issues/397,fix can't run clusterloader without ssh,Related to Issue: https://github.com/kubernetes/perf-tests/issues/396,closed,True,2019-02-01 03:53:45,2019-02-11 02:31:59
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/398,https://api.github.com/repos/kubernetes/perf-tests/issues/398,ClusterLoader - Density test README,,open,True,2019-02-01 11:17:17,2019-02-01 11:17:36
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/399,https://api.github.com/repos/kubernetes/perf-tests/issues/399,ClusterLoader- Allowing inactive pods,,closed,True,2019-02-04 13:46:37,2019-02-04 14:04:53
perf-tests,nemethf,https://github.com/kubernetes/perf-tests/issues/400,https://api.github.com/repos/kubernetes/perf-tests/issues/400,Extending netperf benchmark with a series of pull request,"Hi,

It seems recent improvements of perf-tests are in clusterloader2, however we are more interested in bulk data transfer benchmarks measured with netperf (located in perf-tests/network/benchmarks).  Our BSc students (@orsoly  and @Rychne) wrote a couple of improvements to netperf.  Would you be interested in receiving the improvements in small PRs?

The following diff shows the new features we have.  But we can clean the commits for better understandability.   
  https://github.com/kubernetes/perf-tests/compare/master...Rychne:bme18",open,False,2019-02-06 11:09:10,2019-02-06 11:09:10
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/401,https://api.github.com/repos/kubernetes/perf-tests/issues/401,ClusterLoader - Initializing klog,Adding klog initialization.,closed,True,2019-02-06 13:05:40,2019-02-08 13:54:53
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/402,https://api.github.com/repos/kubernetes/perf-tests/issues/402,ClusterLoader: Replace glog with klog,"Cluster loader should use klog instead glog, to be coherent with kubernetes logging.

- [ ] ~~Fix: initializing klog, so klog logs become visible. #401~~
- [x] Replcing glog with klog #403",closed,False,2019-02-06 13:10:44,2019-02-08 13:03:55
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/403,https://api.github.com/repos/kubernetes/perf-tests/issues/403,ClusterLoader - Replacing glog with klog,"Replacing glog with klog.

fixes #402 ",closed,True,2019-02-06 14:17:28,2019-02-08 13:54:58
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/404,https://api.github.com/repos/kubernetes/perf-tests/issues/404,Benchmark is failing,https://testgrid.k8s.io/sig-scalability-perf-tests#kubemark-100-benchmark ci job that runs benchmark is failing. There is issue with invalid memory address or nil pointer dereferencing.,closed,False,2019-02-07 10:12:16,2019-02-15 15:30:43
perf-tests,mborsz,https://github.com/kubernetes/perf-tests/pull/405,https://api.github.com/repos/kubernetes/perf-tests/issues/405,Add more descriptive error messages.,"The goal is to have errors that doesn't require to check build-log to see what exact object/metric is incorrect.

/assign @krzysied ",closed,True,2019-02-08 09:19:45,2019-02-08 10:01:59
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/406,https://api.github.com/repos/kubernetes/perf-tests/issues/406,Reimplementing randomized_time_limited tuning set,"Reimplementing randomized_time_limited tuning set, so it uses fewer goroutines.",closed,True,2019-02-11 11:12:52,2019-02-11 15:28:39
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/407,https://api.github.com/repos/kubernetes/perf-tests/issues/407,Add basic test for node throughput,,closed,True,2019-02-12 10:57:04,2019-02-12 11:57:52
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/408,https://api.github.com/repos/kubernetes/perf-tests/issues/408,Don't kill the same node twice in NodeKiller.,This is to address flakiness described in https://github.com/kubernetes/kubernetes/issues/73461#issuecomment-462754083,closed,True,2019-02-12 13:57:50,2019-02-12 14:29:49
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/409,https://api.github.com/repos/kubernetes/perf-tests/issues/409,ClusterLoader- Adding node killer log prefix,"Adding ""NodeKiller: "" prefix to logs.
Will make grepping logs easier.",closed,True,2019-02-12 14:33:19,2019-02-25 10:33:45
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/pull/410,https://api.github.com/repos/kubernetes/perf-tests/issues/410,add kubemark ssh key env variable,"**What this PR does / why we need it**:

This PR is a cherry pick from kubernetes/kubernetes
https://github.com/kubernetes/kubernetes/blob/9fd23b217800a312a45dbaedb70f4ffa65ec661b/test/e2e/framework/ssh.go#L36

**Additional**, this PR adds an environment variable `KUBEMARK_SSH_KEY` for provider `kubemark` SSH.
",closed,True,2019-02-13 02:44:11,2019-02-13 10:52:54
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/issues/411,https://api.github.com/repos/kubernetes/perf-tests/issues/411,ClusterLoader2 doesn't handle tombstones,"Example failure:
https://storage.googleapis.com/kubernetes-jenkins/pr-logs/pull/73959/pull-kubernetes-kubemark-e2e-gce-big/37500/build-log.txt

The interested line is this one;
```
W0212 15:57:44.517] E0212 15:57:44.515738   92745 wait_for_controlled_pods.go:275] WaitForControlledPodsRunning: uncastable old object: {test-fx0qmn-1/saturation-rc-0 &ReplicationController{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:saturation-rc-0,GenerateName:,Namespace:test-fx0qmn-1,SelfLink:/api/v1/namespaces/test-fx0qmn-1/replicationcontrollers/saturation-rc-0,UID:0e1ffe4a-2ede-11e9-b0bd-42010a280013,ResourceVersion:68593,Generation:1,CreationTimestamp:2019-02-12 15:51:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{group: saturation,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:ReplicationControllerSpec{Replicas:*3000,Selector:map[string]string{name: saturation-rc-0,},Template:&PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{group: saturation,name: saturation-rc-0,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,},Spec:PodSpec{Volumes:[],Containers:[{saturation-rc-0 k8s.gcr.io/pause:3.1 [] []  [] [] [] {map[] map[cpu:{{1 -3} {<nil>} 1m DecimalSI} memory:{{10 6} {<nil>} 10M DecimalSI}]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0136bf4d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0136bf4f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,},},MinReadySeconds:0,},Status:ReplicationControllerStatus{Replicas:3000,FullyLabeledReplicas:3000,ObservedGeneration:1,ReadyReplicas:3000,AvailableReplicas:3000,Conditions:[],},}}
```",closed,False,2019-02-13 08:28:17,2019-02-13 10:53:35
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/412,https://api.github.com/repos/kubernetes/perf-tests/issues/412,Handle tombstones in clusterloader2,Fix https://github.com/kubernetes/perf-tests/issues/411,closed,True,2019-02-13 08:34:55,2019-02-13 10:53:36
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/issues/413,https://api.github.com/repos/kubernetes/perf-tests/issues/413,Simplify load test,"With migration to CL2 being roughly done, I would like to simplify and evolve load test a bit to:
1. create a service in a bundle with RC
2. that creates a problem that we currently have a service only for half of RCs, but fortunately in new enough releases we can solve that by using the mechanism introduced here: https://github.com/kubernetes/kubernetes/pull/71355
3. switch to using Deployment instead of RC

/assign @krzysied ",open,False,2019-02-13 12:26:06,2019-03-13 09:59:01
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/issues/414,https://api.github.com/repos/kubernetes/perf-tests/issues/414,ClusterLoader2 should support controllers beside ReplicationController,"**What would you like to be added**:
1. Add parameter `apiVersion` for `type waitForControlledPodsRunningMeasurement struct `
2. Support measurement`WaitForControlledPodsRunning` for kinds in different apiVersions (different controllers)

**Why is this needed**:

**Kubernetes e2e test:** Kubernetes supports multiple controllers such as Deployment, Job, ReplicationController, etc. For kubernetes/kubernetes density test, all of them are supported.

https://github.com/kubernetes/kubernetes/blob/2b9c9154b52bdac914bf3ab37c8d349d926e6e16/test/e2e/scalability/density.go#L557


**ClusterLoad2:**  Clusterload2 only support controllers in CoreV1. Controllers `Deployment`, `Job`, etc. can't be measured by clusterload2.  

 Clusterload2 does not provides parameter `apiVersion` for measurement `WaitForControlledPodsRunning`, due to codes as followed, it can't create listwatch expect in CoreV1().

https://github.com/kubernetes/perf-tests/blob/74aa0691d943234621454aab72c180d4648f9ee6/clusterloader2/pkg/measurement/common/simple/wait_for_controlled_pods.go#L155
",closed,False,2019-02-14 03:40:54,2019-02-28 17:06:20
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/415,https://api.github.com/repos/kubernetes/perf-tests/issues/415,ClusterLoader - Fixing different kinds handling in wait_for_controlled_pods,"Adding fix for ReplicaSet, Deployment, DaemonSet and Job.

ref #414 ",closed,True,2019-02-14 13:00:09,2019-02-19 10:29:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/416,https://api.github.com/repos/kubernetes/perf-tests/issues/416,Benchmark - Vendor update,"Updating vendor with https://github.com/kubernetes/contrib/pull/2995 changes.

fixes #404",closed,True,2019-02-14 13:30:32,2019-02-14 19:48:21
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/417,https://api.github.com/repos/kubernetes/perf-tests/issues/417,ClusterLoader - Pod startup log,"- Extracting `createSelectorsString` to `mesurement/util`.
- Adding selectors string and threshold logging to `PodStartupLatency` measurement. The logging format will be consistent with `SchedulingThroughput` and `WaitForControlledPodsRunning`.

ref https://github.com/kubernetes/kubernetes/issues/74088",closed,True,2019-02-15 16:33:11,2019-02-19 10:26:18
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/418,https://api.github.com/repos/kubernetes/perf-tests/issues/418,Bump up kube-proxy cpu constraint,"This is to prevent flakes like https://github.com/kubernetes/kubernetes/issues/73461#issuecomment-464619155:
```
[measurement call TestMetrics - TestMetrics error: [resource constraints: 1 constraints violated: [container kube-proxy-e2e-big-minion-group-m4xc/kube-proxy is using 0.051962892/0.05 CPU]]]
```",closed,True,2019-02-18 07:47:37,2019-02-18 08:48:48
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/419,https://api.github.com/repos/kubernetes/perf-tests/issues/419,Allow starting prometheus stack in clusterloader2,"See https://github.com/kubernetes/kubernetes/issues/74213

The feature is flag-gated behind the --set-up-prometheus flag.
I will be gradually launching it, starting from the smallest tests/clusters.
It's probable that we will have to tune the cpu/memory limits/requests in order to make it work for the big clusters, but as the yaml as read via the template provider it shouldn't be hard to have memory/cpu as a function of # of nodes in the cluster.",closed,True,2019-02-18 16:33:24,2019-02-19 12:07:37
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/issues/420,https://api.github.com/repos/kubernetes/perf-tests/issues/420,ClusterLoader2 outputs CPUProfile in binary format to stderr,"Example log:

```
I0220 14:38:19.568335  225964 simple_test_executor.go:85] kube-apiserver_CPUProfile: ^_<8B>^H^@^@^@^@^@^D<FF><AC><BD>   \U<DB>u?<FE><D9><FB><9C><BD><CF>><E7><DE><E7>[<F7><BE><F7><92><F5>^<92><97><93><DB>L5<F3><<B4><C9>KڤI<DA><CC>m<92>6m:<A4>m<D2>&<9D><92>6<E9><9C>2
^H*<83> <A0>(<88><A2>^B""
<8A>
<88>^H<82>^C<A2><80>^C<8A>(<E2>< ^N  <A8><FF><CF><DA><E7>^\<B8><BE>)/<F9><FF>><F9><98><B7><B9><E7>{<F6><D9><C3><DA>k<AF><BD><A6><FD>Ţ<9E>3^O<AF><ED>޻<E7>^Y<C7>T^L<B8>c*^C̯o<DE>2<B0><E8>_<BE><AB><CB>^?<99><B0>q،<81>b<B8>wa2<8F>       <C5> ]^A<9B><AF>^T^C<81><U+0095>1P^\<F7><EE><BB>`ǄⰞ<E9>g^\,<B4>\^U^Ce<E0>L<E7>5zf<C0>V<EF>=^Cl<B4>]'^F<CA><C4><D2><D4>GVL(^
```
",closed,False,2019-02-20 13:49:26,2019-02-20 15:00:56
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/421,https://api.github.com/repos/kubernetes/perf-tests/issues/421,Customize pod throughput in node-throughput test,,closed,True,2019-02-20 15:03:18,2019-02-20 16:23:08
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/issues/422,https://api.github.com/repos/kubernetes/perf-tests/issues/422,100th percentile of pod-startup-latency is reported as 0 in perf-dash,"![vqrcaed2dpa](https://user-images.githubusercontent.com/2604887/53244974-b4605e00-36ac-11e9-962c-5174b7a9de4b.png)
",closed,False,2019-02-22 13:18:50,2019-02-27 08:22:57
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/pull/423,https://api.github.com/repos/kubernetes/perf-tests/issues/423,ClusterLoader - Add dynmaic client for WaitForControlledPodsRunning,"**Why we need it**:
Fix https://github.com/kubernetes/perf-tests/issues/414

**What this PR does**:
1. Add vendor k8s.io/client-go/dynamic/dynamicinformer
 (There is still a bug fix not merged https://github.com/kubernetes/kubernetes/pull/74344, but in my PR, it's the fixed version)
2. Add parameter apiVersion for `WaitForControlledPodsRunning`
3. Support dynamic informer for `WaitForControlledPodsRunning`

**Something not sure**:
1. I think my PR handle tombstone in a wrong way, but i do not what's right.
https://github.com/Betula-L/perf-tests/blob/60100ff37cf2ad366366dd7b298602da14fe602c/clusterloader2/pkg/measurement/common/simple/wait_for_controlled_pods.go#L179
2. I prefer to remove the useless `switch-case` for followed code.
https://github.com/kubernetes/perf-tests/blob/3ea5f47bceb00d54f6edb3cf36bb1ce98646577d/clusterloader2/pkg/measurement/util/runtimeobjects/runtimeobjects.go#L169

**Something need to be improved**:
It still has `switch-case` in the code. I do not modify the followed code due to the complex reference for it. 
https://github.com/Betula-L/perf-tests/blob/60100ff37cf2ad366366dd7b298602da14fe602c/clusterloader2/pkg/measurement/util/runtimeobjects/runtimeobjects.go#L34",closed,True,2019-02-25 12:19:05,2019-02-28 17:05:42
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/424,https://api.github.com/repos/kubernetes/perf-tests/issues/424,ClusterLoader - Limiting pod startup logs to worst 100 pods,"Limiting pod startup latencies listing to only 100 worst instead of 10% of all.

Ref discussion: https://github.com/kubernetes/kubernetes/issues/74088#issuecomment-464680872",closed,True,2019-02-25 12:38:14,2019-02-27 13:23:55
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/pull/425,https://api.github.com/repos/kubernetes/perf-tests/issues/425,ClusterLoader - Add unstructured support for runtimeobjects.go,"**Why we need it**:
https://github.com/kubernetes/perf-tests/issues/414

**What this PR does**:
Related to https://github.com/kubernetes/perf-tests/pull/423",closed,True,2019-02-26 08:15:00,2019-02-27 11:45:44
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/pull/426,https://api.github.com/repos/kubernetes/perf-tests/issues/426,ClusterLoader - Add dynamic clients for measurement manager,"**Why we need it**:
https://github.com/kubernetes/perf-tests/issues/414

**What this PR does**:
Related to https://github.com/kubernetes/perf-tests/pull/423",closed,True,2019-02-26 08:22:16,2019-02-26 09:11:06
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/427,https://api.github.com/repos/kubernetes/perf-tests/issues/427,Increase saturationRCHardTimeout to 20min,https://github.com/kubernetes/kubernetes/issues/73461#issuecomment-467338711 and https://github.com/kubernetes/kubernetes/issues/73461#issuecomment-467353255,closed,True,2019-02-26 09:03:03,2019-02-26 09:14:46
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/pull/428,https://api.github.com/repos/kubernetes/perf-tests/issues/428,ClusterLoader - refine wait_for_controlled_pods.go clients data structure,"**Why we need it**:
https://github.com/kubernetes/perf-tests/issues/414

**What this PR does**:
Related to https://github.com/kubernetes/perf-tests/pull/423",closed,True,2019-02-26 10:06:24,2019-02-26 11:59:51
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/429,https://api.github.com/repos/kubernetes/perf-tests/issues/429,Tune prometheus stack to make it work for 5k node clusters,https://github.com/kubernetes/kubernetes/issues/74213,closed,True,2019-02-26 10:21:55,2019-02-26 12:20:55
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/430,https://api.github.com/repos/kubernetes/perf-tests/issues/430,Recording rule for Network Programming Latency.,"The rule will be used in the Network Programming Latency dashboard.
It's recommended by Prometheus documentation to use recording rules for
dashboards, see https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/

I've also modified the Network Programming Latency dashboard to align it with the SLI/SLO definition.

I also modified the kube-proxy scrape interval, as now thanks to the recording rule we should be able to scrape the metrics more often.
",open,True,2019-02-26 12:48:46,2019-03-15 09:23:20
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/431,https://api.github.com/repos/kubernetes/perf-tests/issues/431,Disable login in Grafana.,,closed,True,2019-02-26 15:48:05,2019-02-26 16:03:35
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/432,https://api.github.com/repos/kubernetes/perf-tests/issues/432,Add ability to tear down prometheus stack.,"I cofirmed that deleting the namespace deletes the PV which in turns deletes disks in GCE.
This should help us fix the ""leaked resources"" errors, e.g. https://gubernator.k8s.io/build/kubernetes-jenkins/logs/ci-kubernetes-e2e-gci-gce-scalability-killer/1964

Putting this behind a flag, so one can disable it and leave prometheus stack for further analysis when running tests manually.",closed,True,2019-02-26 16:18:22,2019-02-27 07:44:48
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/433,https://api.github.com/repos/kubernetes/perf-tests/issues/433,Change prometheus flags to be env flags.,"It will simplify enabling the prometheus stack in all tests.

https://github.com/kubernetes/kubernetes/issues/74213",closed,True,2019-02-27 09:05:02,2019-02-27 09:49:11
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/434,https://api.github.com/repos/kubernetes/perf-tests/issues/434,ClusterLoader - ApiResponsiveness measurement,"- Adding new method for parsing method samples.
- Adding new api responsiveness measurement based on prometheus server data.",closed,True,2019-02-27 13:06:00,2019-04-01 12:46:33
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/435,https://api.github.com/repos/kubernetes/perf-tests/issues/435,Tear down prometheus stack also on failed tests.,https://github.com/kubernetes/kubernetes/issues/74213,closed,True,2019-02-28 08:58:54,2019-02-28 09:12:48
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/pull/436,https://api.github.com/repos/kubernetes/perf-tests/issues/436,Clusterloader - update vendor client-go dynamic package,"**Why we need it**:
https://github.com/kubernetes/perf-tests/issues/414

**What this PR does**:
Related to https://github.com/kubernetes/perf-tests/pull/423

This PR only update packages `k8s.io/client-go/dynamic/dynamicinformer` and `k8s.io/client-go/dynamic/dynamiclister`, so that their revisions are different from package `k8s.io/client-go/dynamic`. However, it's compatible.

**What not update `k8s.io/client-go/dynamic`**:

This commit update `k8s.io/apimachinery/pkg/apis/meta/v1`, https://github.com/kubernetes/kubernetes/commit/0e1d50e70fdc9ed838d75a7a1abbe5fa607d22a1, but i think i should not update it.
",closed,True,2019-02-28 11:10:11,2019-02-28 11:53:55
perf-tests,rus4,https://github.com/kubernetes/perf-tests/issues/437,https://api.github.com/repos/kubernetes/perf-tests/issues/437,clusterloader uses godep now obselete,"so i am trying to use clusterloader but it seems it requires godep which is now obselete ( february 2019 ), is there any plans to move to dep , or any info on how to make this work now that godep is no longer available on ubuntu.",open,False,2019-02-28 12:10:07,2019-02-28 21:09:37
perf-tests,Betula-L,https://github.com/kubernetes/perf-tests/pull/438,https://api.github.com/repos/kubernetes/perf-tests/issues/438,ClusterLoader - Replace clientset by dynamic client,"**Why we need it**:
This is the final PR for fixing https://github.com/kubernetes/perf-tests/issues/414

**What this PR does**:
Related to https://github.com/kubernetes/perf-tests/pull/423

1. Replace clientset by dynamic client.
2. Update clusterloader2 testing configs

**What is not sure for me**:
I don't know whether it handles tombstone correctly.
",closed,True,2019-02-28 12:29:12,2019-02-28 16:39:49
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/439,https://api.github.com/repos/kubernetes/perf-tests/issues/439,Wait for prometheus to become healthy.,"We shouldn't run tests until the prometheus server is healthy and collects metrics from all targets.

https://github.com/kubernetes/kubernetes/issues/74213",closed,True,2019-02-28 13:40:44,2019-03-01 08:55:36
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/440,https://api.github.com/repos/kubernetes/perf-tests/issues/440,Fix typo: Warning->Warningf,,closed,True,2019-03-01 10:28:53,2019-03-01 10:44:59
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/441,https://api.github.com/repos/kubernetes/perf-tests/issues/441,Change how CL2 waits for prometheus to be ready,"* Increase timeout to 15min - it takes about 6min in scale tests for the
  prometheus stack to become ready. Changing the deadline from 10min to
  15min should prevent flakinesss
* Change the progress logging - it's more informative to log how many
  targets are ready instead of one target that is not ready.",closed,True,2019-03-05 08:52:24,2019-03-05 09:46:04
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/442,https://api.github.com/repos/kubernetes/perf-tests/issues/442,Perfdash: Unsupported value NaN,"When running perfdash without any flags (or flag --www=false), perfdash fails with `json: unsupported value: NaN`

The error is returned by https://github.com/kubernetes/perf-tests/blob/ca4e20710bbd86321bbc93ca24189d0cc91946a0/perfdash/perfdash.go#L68",closed,False,2019-03-06 16:27:46,2019-03-07 13:45:00
perf-tests,misterikkit,https://github.com/kubernetes/perf-tests/pull/443,https://api.github.com/repos/kubernetes/perf-tests/issues/443,Add missing \n to some log messages,"/kind cleanup
/assign @krzysied ",closed,True,2019-03-06 18:12:56,2019-03-07 09:50:59
perf-tests,misterikkit,https://github.com/kubernetes/perf-tests/pull/444,https://api.github.com/repos/kubernetes/perf-tests/issues/444,Add deep links to PerfDash. ,"This change adds two-way binding between the drop-down menus of PerfDash
and the set of URL query parameters. The result is that changing the
drop-downs will change the URL, and changing the URL will update the UI.

More importantly, these URLs can be shared, causing PerfDash to load a
specific graph.

",closed,True,2019-03-07 02:31:19,2019-03-07 21:54:17
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/445,https://api.github.com/repos/kubernetes/perf-tests/issues/445,Bump l7-lb-controller cpu constraint to 0.20,This is to address the following test failure (flakiness): https://prow.k8s.io/view/gcs/kubernetes-jenkins/logs/ci-kubernetes-e2e-gci-gce-scalability-killer/2153,closed,True,2019-03-07 08:46:57,2019-03-11 09:33:16
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/446,https://api.github.com/repos/kubernetes/perf-tests/issues/446,Make Prometheus work in kubemark clusters.,Ref https://github.com/kubernetes/kubernetes/issues/74213,closed,True,2019-03-07 09:31:27,2019-03-07 09:57:27
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/447,https://api.github.com/repos/kubernetes/perf-tests/issues/447,Make Prometheus work in kubemark clusters.,Ref kubernetes/kubernetes#74213,closed,True,2019-03-07 09:44:34,2019-03-16 18:33:50
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/448,https://api.github.com/repos/kubernetes/perf-tests/issues/448,Perfdash - etcd nan fix,"Fixing empty histogram handling (`bucket[""inf+""] == 0`).

fixes #442 ",closed,True,2019-03-07 13:34:09,2019-03-07 13:49:39
perf-tests,joelsmith,https://github.com/kubernetes/perf-tests/pull/449,https://api.github.com/repos/kubernetes/perf-tests/issues/449,Update embargo doc link in SECURITY_CONTACTS and change PST to PSC,See https://github.com/kubernetes/security/issues/8 for more information,closed,True,2019-03-08 18:12:37,2019-03-11 09:13:31
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/450,https://api.github.com/repos/kubernetes/perf-tests/issues/450,ClusterLoader - Copying tests to head/ and legacy/,"Copying tests from testing/ to testing/head/ and testing/legacy.

ref #413 ",closed,True,2019-03-11 15:26:25,2019-03-14 13:56:29
perf-tests,rus4,https://github.com/kubernetes/perf-tests/issues/451,https://api.github.com/repos/kubernetes/perf-tests/issues/451,Clusterloader2 SSH an connection timeouts retries and INTERNAL_ERROR,"I seem to be getting a recurring issue when running clusterloader2 on-prem using ubuntu OS and using the skeleton providor, I am passing the master name an ip when running the load test ,on the load test runs I keep seeing messages like this:

`E0311 14:37:00.777610    3243 streamwatcher.go:109] Unable to decode an event from the watch stream: stream error: stream ID 387; INTERNAL_ERROR
E0311 14:38:00.917035    3243 streamwatcher.go:109] Unable to decode an event from the watch stream: stream error: stream ID 403; INTERNAL_ERROR
W0311 14:38:00.917164    3243 reflector.go:303] k8s.io/perf-tests/clusterloader2/pkg/measurement/common/simple/wait_for_controlled_pods.go:203: watch of <nil> ended with: very short watch: k8s.io/perf-tests/clusterloader2/pkg/measurement/common/simple/wait_for_controlled_pods.go:203: Unexpected watch close - watch lasted less than a second and no items received
error dialing rus4@172.16.20.18:22: 'dial tcp 172.16.20.18:22: connect: connection timed out', retrying
E0311 14:39:02.204236    3243 streamwatcher.go:109] Unable to decode an event from the watch stream: stream error: stream ID 407; INTERNAL_ERROR
W0311 14:39:02.204276    3243 reflector.go:303] k8s.io/perf-tests/clusterloader2/pkg/measurement/common/simple/wait_for_controlled_pods.go:203: watch of <nil> ended with: very short watch: k8s.io/perf-tests/clusterloader2/pkg/measurement/common/simple/wait_for_controlled_pods.go:203: Unexpected watch close - watch lasted less than a second and no items received
E0311 14:40:03.492289    3243 streamwatcher.go:109] Unable to decode an event from the watch stream: stream error: stream ID 411; INTERNAL_ERROR`


Can anyone verify if on-prem is supported fully? or any ideas what might be wrong?",open,False,2019-03-11 15:58:43,2019-03-11 21:14:24
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/452,https://api.github.com/repos/kubernetes/perf-tests/issues/452,ClusterLoader2 should retry retriable net errors.,"Example error is:
```
Post https://34.73.197.67/apis/rbac.authorization.k8s.io/v1/clusterrolebindings: net/http: TLS handshake timeout
```

Ref. https://github.com/kubernetes/kubernetes/issues/75284",closed,True,2019-03-12 12:18:37,2019-03-12 15:16:49
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/453,https://api.github.com/repos/kubernetes/perf-tests/issues/453,Prometheus - disable creating Kublet Endpoints,"We don't monitor kubelets via Prometheus in scale tests, thus we can disable creation of the Endpoints object for kubelets.

An alternative would be to wait for the Kubelet Endpoints object to be created before running tests. 
But, for now, disabling the Kubelet Endpoints object creation is simply a better solution.

Ref. https://github.com/kubernetes/kubernetes/issues/75284",closed,True,2019-03-12 12:27:30,2019-03-12 17:24:43
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/454,https://api.github.com/repos/kubernetes/perf-tests/issues/454,CL2 should fail on Prometheus set-up errors.,"As the Prometheus Server is going to become a standard way of measuring SLIs in scale-tests we should make the ClusterLoader2 fail if it's not able to set up the Prometheus stack. 
It doesn't make sense to run tests if we're not able to measure SLIs.

Ref. https://github.com/kubernetes/kubernetes/issues/75284",closed,True,2019-03-12 12:35:50,2019-03-12 16:08:40
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/455,https://api.github.com/repos/kubernetes/perf-tests/issues/455,Introduce KUBEMARK_ROOT_KUBECONFIG env variable.,The KUBEMARK_ROOT_KUBECONFIG variable is replacing DEFAULT_KUBECONFIG that turned out to be not propagated to clusterloader2.,closed,True,2019-03-14 13:52:43,2019-03-14 14:20:35
perf-tests,rus4,https://github.com/kubernetes/perf-tests/issues/456,https://api.github.com/repos/kubernetes/perf-tests/issues/456,SSH Connection timouts to master  in clusterloader2,"I seem to be getting a lot of connection timeouts , its to do with SSH communication to master node I enclose the command i am running along with full log output, for SSH kubernetes is using a bastion host as described here: https://github.com/freach/kubernetes-security-best-practice/blob/master/README.md so that its configured in a way so when i manually ssh to the bastion host i am automatically connected to the k8smaster, the cluster works so that all ssh communication is via the bastion host in normal cluster operation an so when using test tool clusterloader2 have used the same connection info to run-e2e.sh that I use when i ssh directly from my client this is 27 february 2019 version of clusterloader2 code am running ubuntu bionic an on-prem

I see many : error dialing rus4@192.168.20.18:22: 'dial tcp 192.168.20.18:22: connect: connection timed out', retrying , here is the full output an run command

```
rus4@BIONIC1:~/workdir/perf-tests/clusterloader2$ USER=rus4 KUBE_SSH_KEY=/home/rus4/workdir/k8s/.secrets/rus4.pem ./run-e2e.sh --testconfig=testing/load/config.yaml --mastername=k8smaster0.rus4.dev.com --masterip=192.168.20.18 --nodes=14 --report-dir=log --provider=skeleton
I0314 17:57:41.549666   28734 cluster.go:56] Listing cluster nodes:
I0314 17:57:41.550168   28734 cluster.go:68] Name: gluster0.rus4.dev.com, clusterIP: 192.168.20.9, externalIP: , isSchedulable: true
I0314 17:57:41.550185   28734 cluster.go:68] Name: gluster1.rus4.dev.com, clusterIP: 192.168.20.22, externalIP: , isSchedulable: true
I0314 17:57:41.550203   28734 cluster.go:68] Name: gluster2.rus4.dev.com, clusterIP: 192.168.20.11, externalIP: , isSchedulable: true
I0314 17:57:41.550219   28734 cluster.go:68] Name: ingress0.int.rus4.dev.com, clusterIP: 192.168.20.5, externalIP: , isSchedulable: false
I0314 17:57:41.550232   28734 cluster.go:68] Name: ingress0.rus4.dev.com, clusterIP: 192.168.20.14, externalIP: , isSchedulable: false
I0314 17:57:41.550246   28734 cluster.go:68] Name: ingress1.rus4.dev.com, clusterIP: 192.168.20.20, externalIP: , isSchedulable: false
I0314 17:57:41.550260   28734 cluster.go:68] Name: k8smaster0.rus4.dev.com, clusterIP: 192.168.20.18, externalIP: , isSchedulable: false
I0314 17:57:41.550272   28734 cluster.go:68] Name: k8smaster1.rus4.dev.com, clusterIP: 192.168.20.19, externalIP: , isSchedulable: false
I0314 17:57:41.550286   28734 cluster.go:68] Name: k8smaster2.rus4.dev.com, clusterIP: 192.168.20.8, externalIP: , isSchedulable: false
I0314 17:57:41.550298   28734 cluster.go:68] Name: k8snode0.rus4.dev.com, clusterIP: 192.168.20.16, externalIP: , isSchedulable: true
I0314 17:57:41.550312   28734 cluster.go:68] Name: k8snode1.rus4.dev.com, clusterIP: 192.168.20.21, externalIP: , isSchedulable: true
I0314 17:57:41.550325   28734 cluster.go:68] Name: k8snode2.rus4.dev.com, clusterIP: 192.168.20.13, externalIP: , isSchedulable: true
I0314 17:57:41.550341   28734 cluster.go:68] Name: k8snode3.rus4.dev.com, clusterIP: 192.168.20.7, externalIP: , isSchedulable: true
I0314 17:57:41.550355   28734 cluster.go:68] Name: k8snode4.rus4.dev.com, clusterIP: 192.168.20.12, externalIP: , isSchedulable: true
I0314 17:57:41.554283   28734 simple_test_executor.go:48] AutomanagedNamespacePrefix: testr-p7y80f
I0314 17:57:42.700091   28734 api_responsiveness.go:77] APIResponsiveness: resetting latency metrics in apiserver...
I0314 17:57:42.700102   28734 etcd_metrics.go:75] EtcdMetrics: starting etcd metrics collecting...
I0314 17:57:42.700127   28734 scheduler_latency.go:78] SchedulingMetrics: resetting latency metrics in scheduler...
error dialing rus4@192.168.20.18:22: 'dial tcp 192.168.20.18:22: connect: connection timed out', retrying

error dialing rus4@192.168.20.18:22: 'dial tcp 192.168.20.18:22: connect: connection timed out', retrying
I0314 18:02:07.558495   28734 resource_usage.go:105] ResourceUsageSummary: starting resource usage collecting...
E0314 18:02:08.722312   28734 test_metrics.go:127] TestMetrics: [unexpected error (code: 0) in ssh connection to master: &errors.errorString{s:""error getting SSH client to rus4@192.168.20.18:22: 'dial tcp 192.168.20.18:22: connect: connection timed out'""}]
I0314 18:02:09.775722   28734 simple_test_executor.go:127] Step ""Creating SVCs"" ended
I0314 18:02:09.775754   28734 wait_for_controlled_pods.go:162] WaitForControlledPodsRunning: starting wait for controlled pods measurement...
I0314 18:02:10.997108   28734 wait_for_controlled_pods.go:228] WaitForControlledPodsRunning: waiting for controlled pods measurement...
I0314 18:02:15.067694   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-1wip9v-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067718   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-vkhxde-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067694   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-skunpz-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067694   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-aud2rn-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067694   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-befoto-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067709   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-1wip9v-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067725   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-jur9am-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067787   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-hyvv54-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067787   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-skunpz-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067858   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-zdu8l9-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067860   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-befoto-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.067953   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-hyvv54-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218006   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-aud2rn-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218038   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-befoto-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218058   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-vkhxde-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218074   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-ab2q4z-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218107   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-t3e8fe-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218006   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-1wip9v-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218023   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-aud2rn-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218052   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-ab2q4z-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218053   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-aud2rn-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218086   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-zdu8l9-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218556   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-vkhxde-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.218853   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-zdu8l9-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.219249   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-og6209-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.219771   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-vkhxde-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.219785   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-jur9am-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.219773   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-t3e8fe-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.219785   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-t3e8fe-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.220015   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-1wip9v-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.220110   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-jur9am-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.220136   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-ab2q4z-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.220196   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-og6209-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.220189   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-jur9am-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.220267   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-ab2q4z-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.220291   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-t3e8fe-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.220349   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-og6209-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.220317   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-hyvv54-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.368162   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-og6209-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.370167   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-zdu8l9-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.370254   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-hyvv54-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.370442   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-befoto-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.486150   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 1 running, 2 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.615417   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 0 running, 3 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:15.700025   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 0 running, 3 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:16.145131   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 0 running, 3 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:20.486333   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 2 running, 1 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:20.615677   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 2 running, 1 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:20.712828   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 2 running, 1 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:21.145297   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 2 running, 1 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:25.486524   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 2 running, 1 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:25.615849   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 2 running, 1 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:25.714340   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 2 running, 1 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:26.145504   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 2 running, 1 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:30.486737   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-1), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:30.616085   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-2), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:30.714462   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-3), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:31.145719   28734 wait_for_pods.go:140] WaitForControlledPodsRunning: namespace(testr-p7y80f-4), labelSelector(name=small-rc-0): Pods: 3 out of 3 created, 3 running, 0 pending scheduled, 0 not scheduled, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady
I0314 18:02:31.145781   28734 wait_for_controlled_pods.go:267] WaitForControlledPodsRunning: running 46, deleted 0, timeout: 0, unknown: 0
I0314 18:02:31.145806   28734 wait_for_controlled_pods.go:281] WaitForControlledPodsRunning: 46/46 ReplicationControllers are running with all pods
I0314 18:02:31.145824   28734 simple_test_executor.go:127] Step ""Creating RCs"" ended
panic: invalid argument to Int63n

goroutine 582 [running]:
math/rand.(*Rand).Int63n(0xc0000b84b0, 0x0, 0xc0004dc200)
        /snap/go/3318/src/math/rand/rand.go:111 +0x11e
math/rand.Int63n(...)
        /snap/go/3318/src/math/rand/rand.go:319
k8s.io/perf-tests/clusterloader2/pkg/tuningset.(*randomizedTimeLimitedLoad).Execute.func1()
        /home/rus4/go/pkg/src/k8s.io/perf-tests/clusterloader2/pkg/tuningset/randomized_time_limited.go:43 +0x4d
k8s.io/perf-tests/clusterloader2/vendor/k8s.io/apimachinery/pkg/util/wait.(*Group).Start.func1(0xc000aa8640, 0xc000c535c0)
        /home/rus4/go/pkg/src/k8s.io/perf-tests/clusterloader2/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:71 +0x4f
created by k8s.io/perf-tests/clusterloader2/vendor/k8s.io/apimachinery/pkg/util/wait.(*Group).Start
        /home/rus4/go/pkg/src/k8s.io/perf-tests/clusterloader2/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:69 +0x62
panic: invalid argument to Int63n

goroutine 580 [running]:
math/rand.(*Rand).Int63n(0xc0000b84b0, 0x0, 0xc0001d4d80)
        /snap/go/3318/src/math/rand/rand.go:111 +0x11e
math/rand.Int63n(...)
        /snap/go/3318/src/math/rand/rand.go:319
k8s.io/perf-tests/clusterloader2/pkg/tuningset.(*randomizedTimeLimitedLoad).Execute.func1()
        /home/rus4/go/pkg/src/k8s.io/perf-tests/clusterloader2/pkg/tuningset/randomized_time_limited.go:43 +0x4d
k8s.io/perf-tests/clusterloader2/vendor/k8s.io/apimachinery/pkg/util/wait.(*Group).Start.func1(0xc000aa8640, 0xc000c53560)
        /home/rus4/go/pkg/src/k8s.io/perf-tests/clusterloader2/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:71 +0x4f
created by k8s.io/perf-tests/clusterloader2/vendor/k8s.io/apimachinery/pkg/util/wait.(*Group).Start
        /home/rus4/go/pkg/src/k8s.io/perf-tests/clusterloader2/vendor/k8s.io/apimachinery/pkg/util/wait/wait.go:69 +0x62
rus4@BIONIC1:~/workdir/perf-tests/clusterloader2$
```
",open,False,2019-03-14 19:02:01,2019-03-14 19:02:01
perf-tests,wenjiaswe,https://github.com/kubernetes/perf-tests/issues/457,https://api.github.com/repos/kubernetes/perf-tests/issues/457,ClusterLoader2: pull-kubernetes-e2e-gce-100-performance test fails when etcd metrics port is changed,"etcd_metrics.go is always checking ""curl http://127.0.0.1:2379/metrics"",
https://github.com/kubernetes/perf-tests/blob/38cd4ef9bff2646f63690b6137a70a3705e5148b/clusterloader2/pkg/measurement/common/simple/etcd_metrics.go#L157 however in https://github.com/kubernetes/kubernetes/pull/74690, port number 2382 is used in GCE provider, so pull-kubernetes-e2e-gce-100-performance [failed](https://gubernator.k8s.io/build/kubernetes-jenkins/pr-logs/pull/74690/pull-kubernetes-e2e-gce-100-performance/38332?log#log)",closed,False,2019-03-19 05:32:29,2019-03-20 09:38:24
perf-tests,wenjiaswe,https://github.com/kubernetes/perf-tests/pull/458,https://api.github.com/repos/kubernetes/perf-tests/issues/458,Fix etcd metrics port for GCE,"When provider is GCE, etcd metrics port will be set to 2382 in https://github.com/kubernetes/kubernetes/pull/74690. Now etcd_metrics.go is always checking on 2379 for metrics, pull-kubernetes-e2e-gce-100-performance fails. 

It's the first I make any change to perf-tests repo, I have some questions:
1. This PR only makes sense when https://github.com/kubernetes/kubernetes/pull/74690 is merged. But if this pull-kubernetes-e2e-gce-100-performance fails, I cannot check in https://github.com/kubernetes/kubernetes/pull/74690. In this case, what shall I do? Should I make change to the perf-tests locally to test it first, get #74690 merged, and then push this PR?

2. Even after https://github.com/kubernetes/kubernetes/pull/74690 is merged, this change to perf-tests PR should only work with k8s source code after the merge, is there any way for me to do the version control in this PR?

Fix: https://github.com/kubernetes/perf-tests/issues/457

Thank you very much! 
/cc @wojtek-t ",closed,True,2019-03-19 06:37:33,2019-03-20 16:33:36
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/459,https://api.github.com/repos/kubernetes/perf-tests/issues/459,ClusterLoader: Unsafe prometheus getKubemarkMasterClusterIp,"There is a problem with flaking kubemark tests.

IIUC the problem is caused by https://github.com/kubernetes/perf-tests/blob/38cd4ef9bff2646f63690b6137a70a3705e5148b/clusterloader2/pkg/prometheus/prometheus.go#L274
The requirement for this bug to happen is for example having two kubemark clusters within one project. The instance list will return two ip addresses, which generates bad manifest yaml.
I'm also guessing that naming cluster ""...-kubemark"" will result in having instances ""...-kubemark-master"" and ""...-kubemark-kubemark-master"". Both instances will satisfy the command filter. 

getKubemarkMasterClusterIp should be implemented in a different way.

ref https://github.com/kubernetes/kubernetes/issues/73105",closed,False,2019-03-19 14:56:34,2019-03-26 07:20:27
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/460,https://api.github.com/repos/kubernetes/perf-tests/issues/460,ClusterLoader - Increasing apiserver cpu limit to 2.5,ref https://github.com/kubernetes/kubernetes/issues/75509,closed,True,2019-03-20 12:53:29,2019-03-26 16:36:13
perf-tests,rus4,https://github.com/kubernetes/perf-tests/issues/461,https://api.github.com/repos/kubernetes/perf-tests/issues/461,need more explanation / information on monitoring,"So I see some prometheus work has been done with adding of config files, the README does not explain much, I feel the documentation can be improved as right now I cant understand it without spending a lot of time analysing, whereas a informative README would save a lot of time.
Maybe you can explain some an I can try an help to contribute/improve the README on that once I know it better.",open,False,2019-03-20 14:26:11,2019-03-20 14:26:11
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/462,https://api.github.com/repos/kubernetes/perf-tests/issues/462,ClusterLoader - Kubemark 5000 flakes,"Since run 1548 kubemark-5000 become flaky.

Link to testgrid: https://testgrid.k8s.io/sig-scalability-kubemark#kubemark-5000",open,False,2019-03-22 12:32:03,2019-03-22 12:58:19
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/pull/463,https://api.github.com/repos/kubernetes/perf-tests/issues/463,ClusterLoader - Adding name to pod store reflector,"Adding reflector name that will allow easy pod store identification.

ref https://github.com/kubernetes/perf-tests/issues/464",closed,True,2019-03-22 12:51:19,2019-03-22 14:02:31
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/464,https://api.github.com/repos/kubernetes/perf-tests/issues/464,ClusterLoader - Kubemark 5000 flakes - timeouts,[Run 1567](https://prow.k8s.io/view/gcs/kubernetes-jenkins/logs/ci-kubernetes-kubemark-gce-scale/1567) has multiple timed out waits on RC deletion,open,False,2019-03-22 12:57:51,2019-03-22 14:25:42
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/465,https://api.github.com/repos/kubernetes/perf-tests/issues/465,Use $MASTER_IP to scrape kubemark's apiserver metrics,"Previously we've used kubemark master's cluster ip, but I don't think there is any gain in doing that.
What's more the way we implemented getting the master's cluster ip turned out to be not safe when there are multiple clusters running in the same gcp project, see https://github.com/kubernetes/perf-tests/issues/459

Below a proof that the kubemark master can be successfully scraped over public ip
![5iggcC0AvTq](https://user-images.githubusercontent.com/2604887/54930859-56779e00-4f18-11e9-93af-fed8fb3c0d1b.png)
",closed,True,2019-03-25 15:11:51,2019-03-26 09:22:47
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/466,https://api.github.com/repos/kubernetes/perf-tests/issues/466,Retry 404 errors when creating prometheus objects,"The 404 errors during object creations may be caused by races.
E.g. when a ServiceAccount is created the associated token is created asynchronously, when creating an object that needs the token we may get a retryable 404 error if the token has not been created yet.

This should fix the issue described in https://github.com/kubernetes/kubernetes/issues/74213#issuecomment-476247400",closed,True,2019-03-25 17:15:50,2019-03-26 09:19:18
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/467,https://api.github.com/repos/kubernetes/perf-tests/issues/467,Change objects API to allow specifying options,"Options will allow stating how particular errors should be treated, e.g. which additional errors should be allowed (ignored), which should be retried.

This change is almost transparent to the existing code, e.g. the old code like

```
framework.CreateObject(item.GetNamespace(), item.GetName(), &item)
```
will be still valid and will behave as it used to, but it will be also possible to do something like

```
framework.CreateObject(item.GetNamespace(), item.GetName(), &item, client.Allow(apierrs.IsUnauthorized), client.Retry(apierrs.IsNotFound))
```

which in addition will allow IsUnauthorized errors and will retry IsNotFound.

This PR is to address https://github.com/kubernetes/perf-tests/pull/466#discussion_r268795519",closed,True,2019-03-26 08:23:22,2019-03-26 08:53:19
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/468,https://api.github.com/repos/kubernetes/perf-tests/issues/468,Don't call RetryFunction with nil.,"The bug was introduced by https://github.com/kubernetes/perf-tests/pull/467
These are two places I missed to update.",closed,True,2019-03-26 11:00:19,2019-03-26 11:11:19
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/469,https://api.github.com/repos/kubernetes/perf-tests/issues/469,Perfdash displays only one result per ci job,Perfdash displays only one result with weird number for each ci job.,open,False,2019-03-27 10:24:06,2019-03-28 20:01:34
perf-tests,krzysied,https://github.com/kubernetes/perf-tests/issues/470,https://api.github.com/repos/kubernetes/perf-tests/issues/470,ClusterLoader: Move prometheus querying to util,"The `gatherSamples` method of api_responsiveness_prometheus.go should be moved to util/prometheus.go. This method should be more generic, allowing to send any query to promethues server.",open,False,2019-04-01 12:43:55,2019-04-01 12:43:55
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/471,https://api.github.com/repos/kubernetes/perf-tests/issues/471,Extract CheckTargetsReady method.,"Checking if prometheus targets are ready will be used in other places, e.g. when setting up probes.",closed,True,2019-04-01 13:47:09,2019-04-01 14:36:36
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/472,https://api.github.com/repos/kubernetes/perf-tests/issues/472,Fix newly added CheckTargetsReady method :),,closed,True,2019-04-01 15:01:55,2019-04-01 15:12:35
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/473,https://api.github.com/repos/kubernetes/perf-tests/issues/473,Fix typo in density config.,,closed,True,2019-04-01 15:06:37,2019-04-01 17:30:36
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/474,https://api.github.com/repos/kubernetes/perf-tests/issues/474,Probes - boilerplate and first probe,"Probes are simple jobs running inside kubernetes cluster measuring SLIs that could not be measured through other means.

This PR introduces probes boilerplate and implements two probes for measuring the in-cluster network latency SLI.

Ref. https://github.com/kubernetes/kubernetes/issues/76012",open,True,2019-04-02 08:50:59,2019-04-02 09:58:11
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/475,https://api.github.com/repos/kubernetes/perf-tests/issues/475,Framework for running Probes in ClusterLoader2,"Probes definition can be found in https://github.com/kubernetes/perf-tests/pull/474

The feature is guarded by the enable-probes flag, will be enabling it gradually.

Ref. https://github.com/kubernetes/kubernetes/issues/76012",open,True,2019-04-02 08:53:26,2019-04-03 08:25:12
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/476,https://api.github.com/repos/kubernetes/perf-tests/issues/476,Pull prometheus images from gcr.io.,"This is to stop using external registries in our scalability tests.
I copied all the images used by prometheus to gcr.io/k8s-testimages",closed,True,2019-04-03 07:58:17,2019-04-03 08:09:43
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/477,https://api.github.com/repos/kubernetes/perf-tests/issues/477,Start gathering controller-manager profiles,,closed,True,2019-04-03 19:26:48,2019-04-04 09:59:07
perf-tests,wojtek-t,https://github.com/kubernetes/perf-tests/pull/478,https://api.github.com/repos/kubernetes/perf-tests/issues/478,Gather cpu and memory profiles periodically,,closed,True,2019-04-04 11:32:19,2019-04-05 08:17:20
perf-tests,jpbetz,https://github.com/kubernetes/perf-tests/issues/479,https://api.github.com/repos/kubernetes/perf-tests/issues/479,slo-monitor: Full lists of events can impact apiserver,"Currently the slo-monitor performs a full list of all events when initializing or relisting a watch: https://github.com/kubernetes/perf-tests/blob/386d9f97061e81a33a0e321eff9e07359c876509/slo-monitor/src/monitors/pod_monitor.go#L175-L181

On large scale kubernetes clusters, there can be large volumes of events (100k+) and the list requests can timeout and be retried by the slo-monitor, resulting is significant load to the apiserver and etcd.

This can be fixed by paginating the list requests, but pagination is not available in the version of client-go used by the slo-monitor, so it will need to have it's dependencies updated first.

cc @wojtek-t ",open,False,2019-04-04 23:08:54,2019-04-04 23:08:54
perf-tests,mm4tt,https://github.com/kubernetes/perf-tests/pull/480,https://api.github.com/repos/kubernetes/perf-tests/issues/480,Log prometheus-k8s events on stack set up failures,Ref. https://github.com/kubernetes/kubernetes/issues/76182,open,True,2019-04-05 09:25:22,2019-04-05 09:25:43
