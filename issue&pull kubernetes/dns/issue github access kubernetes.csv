name repository,creator user,url_html issue,url_api issue,title,body,state,pull request,data open,updated at
dns,bowei,https://github.com/kubernetes/dns/pull/1,https://api.github.com/repos/kubernetes/dns/issues/1,Move dnsmasq-metrics from contrib; rename to `sidecar`,,closed,True,2016-12-19 19:57:10,2016-12-19 21:16:29
dns,bowei,https://github.com/kubernetes/dns/pull/2,https://api.github.com/repos/kubernetes/dns/issues/2,Add README.md from dnsmasq-metrics,,closed,True,2016-12-19 21:28:13,2016-12-19 21:36:20
dns,bowei,https://github.com/kubernetes/dns/pull/3,https://api.github.com/repos/kubernetes/dns/issues/3,Small tweaks,"* add VERSION to the build stamps
* add travis build badge to the README",closed,True,2016-12-19 21:49:25,2016-12-19 21:55:25
dns,bowei,https://github.com/kubernetes/dns/pull/4,https://api.github.com/repos/kubernetes/dns/issues/4,Add record type option to --probe,"This allows for the query to be customized. kube-dns currently does
not handle ANY queries properly.",closed,True,2016-12-19 23:39:15,2016-12-19 23:42:23
dns,chentao1596,https://github.com/kubernetes/dns/pull/5,https://api.github.com/repos/kubernetes/dns/issues/5,Use formatting mode,"I think we should use formatting mode rather than plus, do you think so? thank you!",closed,True,2016-12-20 02:10:49,2016-12-21 18:19:10
dns,bowei,https://github.com/kubernetes/dns/pull/6,https://api.github.com/repos/kubernetes/dns/issues/6,Move dnsmasq image build from kubernetes/contrib to kubernetes/dns,,closed,True,2016-12-21 00:10:05,2016-12-23 00:04:01
dns,bowei,https://github.com/kubernetes/dns/pull/7,https://api.github.com/repos/kubernetes/dns/issues/7,Move dnsmasq image build from kubernetes/contrib to kubernetes/dns,This integrates the dnsmasq build process with the rest of the repo.,closed,True,2016-12-23 00:05:11,2016-12-23 00:29:53
dns,bowei,https://github.com/kubernetes/dns/pull/8,https://api.github.com/repos/kubernetes/dns/issues/8,Move dnsmasq image build from kubernetes/contrib to kubernetes/dns,This integrates the dnsmasq build process with the rest of the repo.,closed,True,2016-12-23 00:30:29,2016-12-23 00:42:58
dns,bowei,https://github.com/kubernetes/dns/issues/9,https://api.github.com/repos/kubernetes/dns/issues/9,Use glide instead of GoDep,Glide seems to be a better dependency management mechanism.,closed,False,2016-12-23 00:57:58,2017-01-04 19:45:36
dns,bowei,https://github.com/kubernetes/dns/issues/10,https://api.github.com/repos/kubernetes/dns/issues/10,Move kube-dns code over from kubernetes main repo,"Need to move the kube-dns files here. See the community proposal:

https://github.com/kubernetes/community/issues/172",closed,False,2016-12-23 00:58:53,2017-01-04 19:45:13
dns,bowei,https://github.com/kubernetes/dns/pull/11,https://api.github.com/repos/kubernetes/dns/issues/11,"Port over sidecar e2e to go, make more robust to flakes",,closed,True,2016-12-28 23:32:38,2016-12-29 01:22:19
dns,bowei,https://github.com/kubernetes/dns/pull/12,https://api.github.com/repos/kubernetes/dns/issues/12,WIP: try out gcloud,,closed,True,2016-12-29 00:39:19,2017-02-21 18:21:17
dns,bowei,https://github.com/kubernetes/dns/pull/13,https://api.github.com/repos/kubernetes/dns/issues/13,Ports sidecar e2e harness to go,,closed,True,2016-12-29 21:32:56,2016-12-29 22:24:13
dns,bowei,https://github.com/kubernetes/dns/pull/14,https://api.github.com/repos/kubernetes/dns/issues/14,Missing check for error after ReadAll,Caught by ineffassign,closed,True,2016-12-30 00:23:58,2016-12-30 00:28:21
dns,bowei,https://github.com/kubernetes/dns/pull/15,https://api.github.com/repos/kubernetes/dns/issues/15,Fix golint issue,Uneccessary `else`,closed,True,2016-12-30 00:31:01,2016-12-30 01:44:11
dns,chentao1596,https://github.com/kubernetes/dns/pull/16,https://api.github.com/repos/kubernetes/dns/issues/16,Fix some go style mistakes about fmt.Errorf,"I think we should follow this request: https://github.com/golang/go/wiki/CodeReviewComments#error-strings, thank you!",closed,True,2016-12-31 16:04:17,2017-01-04 06:35:39
dns,bowei,https://github.com/kubernetes/dns/pull/17,https://api.github.com/repos/kubernetes/dns/issues/17,Move kube-dns code to this repository,"This takes all of the git history from kubernetes repository and applies the patches to this repository.

",closed,True,2017-01-04 00:22:32,2017-01-04 00:37:02
dns,bowei,https://github.com/kubernetes/dns/pull/18,https://api.github.com/repos/kubernetes/dns/issues/18,Fix dnsmasq build (now links -static),"Also adds validation in `make test` that checks that dnsmasq can
be executed.",closed,True,2017-01-05 01:15:27,2017-01-05 01:29:57
dns,bowei,https://github.com/kubernetes/dns/pull/19,https://api.github.com/repos/kubernetes/dns/issues/19,update readme,,closed,True,2017-01-05 19:29:49,2017-01-05 19:35:09
dns,bowei,https://github.com/kubernetes/dns/pull/20,https://api.github.com/repos/kubernetes/dns/issues/20,Remove static linking -- build with alpine instead,"This really ensures that there are no issues with the build env vs
runtime environment.",closed,True,2017-01-05 21:38:00,2017-01-05 22:11:50
dns,xialonglee,https://github.com/kubernetes/dns/pull/21,https://api.github.com/repos/kubernetes/dns/issues/21,fix typo,"fix typo function comments
cc @brendandburns 

**ps:**
this pr is same with pr https://github.com/kubernetes/kubernetes/pull/38621 that not merged yet before moving codes of kube-dns to this repo.
i close the original one and open a new here",closed,True,2017-01-07 04:58:10,2017-01-07 06:05:38
dns,xialonglee,https://github.com/kubernetes/dns/pull/22,https://api.github.com/repos/kubernetes/dns/issues/22,fix kubecfg-file flag description of kube-dns,"this pr is same with https://github.com/kubernetes/kubernetes/pull/39314 that was not merged yet before moving codes of kube-dns to here.
so i open new one.",closed,True,2017-01-07 05:25:40,2017-01-09 22:36:44
dns,xialonglee,https://github.com/kubernetes/dns/pull/23,https://api.github.com/repos/kubernetes/dns/issues/23,Use const value,"same with https://github.com/kubernetes/kubernetes/pull/38955 that not merged yet.
open a new pr here.",closed,True,2017-01-07 05:40:40,2017-01-07 06:17:18
dns,bowei,https://github.com/kubernetes/dns/pull/24,https://api.github.com/repos/kubernetes/dns/issues/24,Adds DNS-schema specification,"Original patch: https://github.com/kubernetes/kubernetes/pull/38408

Add a DNS-schema spec to create a baseline for any DNS-based
service discovery component to follow.

Rewrite describing records that must exist

Re-wrote the specification to indicate the records that must exist.
This change the behavior of a few queries that were acting something
like wildcards. For example, querying for an SRV record with the
service name and no _port._proto prefix is no longer required to
return any records.

Other minor updates to link to external references and correct typos.

Fix formatting of headless SRV answer example.

Add reference to rcode

Add numbering, cleanup non-ASCII characters, address deprecation warning",closed,True,2017-01-10 06:33:47,2017-01-10 18:13:01
dns,sadlil,https://github.com/kubernetes/dns/pull/25,https://api.github.com/repos/kubernetes/dns/issues/25,Reverse DNS records for named headless services,"Add reverse DNS records for pods' IPs to named headless services' with Pod Hosts FQDN (`<podHostName>.<serviceName>.<namespace>.svc.cluster.local`).

Original PR: kubernetes/kubernetes#38376

Resolves Issues
 - kubernetes/kubernetes#26752
 - kubernetes/kubernetes#33470

Spec:
**Records for a Named Headless Service**
Type: PTR
f a ready endpoint exists with IP equal to the IP of exists, and the endpoint has a non-empty hostname with value <hostname>, then a PTR record with <hostname>.<service>.<ns>.svc.<zone> will be returned.

@thockin @bowei @smarterclayton @harryge00",closed,True,2017-01-11 06:33:01,2017-09-11 05:31:20
dns,MrHohn,https://github.com/kubernetes/dns/pull/26,https://api.github.com/repos/kubernetes/dns/issues/26,Clean up container after build/test,"Found a bunch of exited `golang:1.7-alpine` containers on my local machine.
```
$ docker ps --all
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS                     PORTS               NAMES
1bd16b284f1f        golang:1.7-alpine   ""/bin/sh -c '        ""   6 minutes ago       Exited (0) 6 minutes ago                       modest_goldwasser
a2c4ac382013        golang:1.7-alpine   ""/bin/sh -c '        ""   6 minutes ago       Exited (0) 6 minutes ago                       distracted_cray
080b878b0c86        golang:1.7-alpine   ""/bin/sh -c '        ""   6 minutes ago       Exited (0) 6 minutes ago                       prickly_mccarthy
6f1351502f77        golang:1.7-alpine   ""/bin/sh -c '        ""   12 days ago         Exited (1) 12 days ago                         stupefied_booth
f44e690a0784        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         backstabbing_jennings
703c1e56f08d        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         infallible_euler
c0ffd881b35b        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         admiring_hodgkin
5f4256b00db5        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         furious_borg
8f688a878fce        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         agitated_hopper
7e874c7bd9b2        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (2) 2 weeks ago                         lonely_snyder
0635c83c7639        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         peaceful_shannon
e62f582e1909        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (2) 2 weeks ago                         sad_ardinghelli
ac117cf78ef0        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         high_panini
d5f2b6b36ef7        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         pensive_ptolemy
35a753ca41e7        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         zen_pasteur
ac0c5b280ccc        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         clever_shockley
5025dc324cdb        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         serene_kowalevski
badfd65c04ac        golang:1.7-alpine   ""/bin/sh -c '        ""   2 weeks ago         Exited (0) 2 weeks ago                         furious_hypatia
```

Probably better to remove them after build/test.

@bowei ",closed,True,2017-01-11 22:21:13,2017-10-05 00:56:42
dns,MrHohn,https://github.com/kubernetes/dns/pull/27,https://api.github.com/repos/kubernetes/dns/issues/27,Call Parse() to avoid noisy logs.,"Saw noisy logs from kube-dns on the latest k8s cluster:
```
ERROR: logging before flag.Parse: I0113 02:27:21.529444       1 dns.go:267] New service: kubernetes-dashboard
ERROR: logging before flag.Parse: I0113 02:27:21.529467       1 dns.go:267] New service: kube-dns
ERROR: logging before flag.Parse: I0113 02:27:21.529490       1 dns.go:377] Added SRV record &{Host:kube-dns.kube-system.svc.cluster.local. Port:53 Priority:10 Weight:10 Text: Mail:false Ttl:30 TargetStrip:0 Group: Key:}
ERROR: logging before flag.Parse: I0113 02:27:21.529510       1 dns.go:377] Added SRV record &{Host:kube-dns.kube-system.svc.cluster.local. Port:53 Priority:10 Weight:10 Text: Mail:false Ttl:30 TargetStrip:0 Group: Key:}
ERROR: logging before flag.Parse: I0113 02:27:21.529533       1 dns.go:267] New service: kubernetes
ERROR: logging before flag.Parse: I0113 02:27:21.529554       1 dns.go:377] Added SRV record &{Host:kubernetes.default.svc.cluster.local. Port:443 Priority:10 Weight:10 Text: Mail:false Ttl:30 TargetStrip:0 Group: Key:}
ERROR: logging before flag.Parse: I0113 02:27:21.529579       1 dns.go:267] New service: default-http-backend
ERROR: logging before flag.Parse: I0113 02:27:21.529601       1 dns.go:377] Added SRV record &{Host:default-http-backend.kube-system.svc.cluster.local. Port:80 Priority:10 Weight:10 Text: Mail:false Ttl:30 TargetStrip:0 Group: Key:}
ERROR: logging before flag.Parse: I0113 02:27:21.529623       1 dns.go:267] New service: monitoring-grafana
```

Found a workaround from kubernetes/kubernetes#17162, also adopts it here. The noisy logs seems to be introduced by golang/glog@65d6746.

@bowei ",closed,True,2017-01-13 02:33:10,2017-10-05 00:56:43
dns,corlettb,https://github.com/kubernetes/dns/pull/28,https://api.github.com/repos/kubernetes/dns/issues/28,Adding an option to passthrough upstream nameservers to skydns.,"Currently the upstream nameservers are hardcoded to be taken from
/etc/resolv.conf.

Allowing this option to be passed in can offer greater flexibility
for varying setups where kube-dns is not run within a container.",closed,True,2017-01-13 11:51:23,2017-02-02 20:20:00
dns,johnbelamaric,https://github.com/kubernetes/dns/issues/29,https://api.github.com/repos/kubernetes/dns/issues/29,Spec: Update the spec for federation,The current spec covers only a single cluster. It needs to be updated to reflect federation records and behavior.,closed,False,2017-01-13 20:12:20,2018-02-18 21:54:59
dns,luxas,https://github.com/kubernetes/dns/pull/30,https://api.github.com/repos/kubernetes/dns/issues/30,WIP: Make manifest lists of the dns images,"... and base everything on busybox to minimize the delta between amd64 and non-amd64 images

Also I tried to make the Makefiles simpler, let me know what you think @bowei and others!

A manifest list is an image that's kind of a placeholder for other arch-specific images, so basically if we have `k8s-dns-dnsmasq:version` in a manifest and are using docker; docker will fetch the right `-arch` version for us automatically!

Tested it locally, and it seems like I got it working. I also added s390x to the list",closed,True,2017-01-13 23:21:02,2018-05-11 19:59:00
dns,GheRivero,https://github.com/kubernetes/dns/pull/31,https://api.github.com/repos/kubernetes/dns/issues/31,Fixed sidecar running group for arm arch,"The base image used to build the containers for the arm arch
(both arm and arm64) uses the pair nobody:nogroup while amd64
arch uses nobody:nobody",closed,True,2017-01-14 00:03:51,2017-01-22 18:48:50
dns,johnbelamaric,https://github.com/kubernetes/dns/pull/32,https://api.github.com/repos/kubernetes/dns/issues/32,Fix typo,,closed,True,2017-01-15 14:59:35,2017-01-15 16:36:45
dns,Blfrg,https://github.com/kubernetes/dns/issues/33,https://api.github.com/repos/kubernetes/dns/issues/33,Failed to create a kubernetes client,"Hello, this looks like the new home for kube-dns, so I hope I'm posting in the right place.
I'm getting the following error [in the kubedns container] when trying to create the kube-dns addon:

```
2017-01-18T04:12:37.756554582Z ERROR: logging before flag.Parse: F0118 04:12:37.756422       1 server.go:52] Failed to create a kubernetes client: open /var/run/secrets/kubernetes.io/serviceaccount/token: no such file or directory
```

Some details about my setup:
- Vagrant: 1.9.1
- Container Linux (CoreOS): 1235.6.0 (Stable)
- Docker: 1.12.3
- Flannel: v0.6.0
- Kubernetes: v1.5.2
- kube-dns: 1.11.0
_Note: no config-map, no federation options._

To implement kube-dns I'm using the yaml's provided in [/cluster/addons/dns](https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns)


The error suggests the token is missing so I confirmed the service-account/secret exists
(and includes ca.crt):

```
Name:		default-token-tqc73
Namespace:	kube-system
Labels:		<none>
Annotations:	kubernetes.io/service-account.name=default
		kubernetes.io/service-account.uid=6b323b3c-dd33-11e6-8e80-080027acfaf0
Type:	kubernetes.io/service-account-token

Data
====
token:		eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkZWZhdWx0LXRva2VuLXRxYzczIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImRlZmF1bHQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI2YjMyM2IzYy1kZDMzLTExZTYtOGU4MC0wODAwMjdhY2ZhZjAiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06ZGVmYXVsdCJ9.A3jyD08wFKBwBlnrVCw87uPOv-65km9H17uUgQhw6tUrJIFiISkC8FfFccz5UlqerlIgeiIqjXIP5Hf8V0QvvQMrh9gk7DEEuMUXerSJwnfMWwTWsE53BVg_ErTU0A4xsdW5f2d7WhbcW8FxbpnZNCUAOFbCI99boinFR3Zn89LSilp5f5kJNI_19WAbmXAiNNACsi9GZisD_w3rps9WiwEBU3v5CFjefu7Ph_oR0R6Zzk9LMAt_1izEXHFKb3TBVQTb7uip-Tc3m0ouMtqr7ltGRe2o7Wv_coQBB_TcXUVF2F0lBvtNa3ndO-VeW7fXKcRdOsrWz6MTSOCYiqI6uw
ca.crt:		1363 bytes
namespace:	11 bytes
```

_Note: To rule out any race condition (pod created before secret)
I booted the kubernetes cluster to idle, then manually ran create -f \<kube-dns-yamls\>_

---
Inspecting the pod shows the token mounted:

```
Name:		kube-dns-2829910835-xhtrv
Namespace:	kube-system
Node:		172.17.8.11/172.17.8.11
Start Time:	Wed, 18 Jan 2017 04:12:32 +0000
Labels:		k8s-app=kube-dns
		pod-template-hash=2829910835
Status:		Running
IP:		10.13.176.2
Controllers:	ReplicaSet/kube-dns-2829910835
Containers:
  kubedns:
    Container ID:	docker://8a657cfdc2fad409ca0075655b4bd6636899f5b68707270e3c277f772d6d7f6a
    Image:		gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.11.0
    Image ID:		docker://sha256:b1e4978ccc41b11ce1c94b95dd807c3cb8d83fc57085b83d5f80607e4d923266
    Ports:		10053/UDP, 10053/TCP, 10055/TCP
    Args:
      --domain=cluster.local.
      --dns-port=10053
      --v=2
    Limits:
      memory:	170Mi
    Requests:
      cpu:		100m
      memory:		70Mi
    State:		Waiting
      Reason:		CrashLoopBackOff
    Last State:		Terminated
      Reason:		Error
      Exit Code:	255
      Started:		Wed, 18 Jan 2017 04:12:55 +0000
      Finished:		Wed, 18 Jan 2017 04:12:56 +0000
    Ready:		False
    Restart Count:	2
    Liveness:		http-get http://:10054/healthcheck/kubedns delay=60s timeout=5s period=10s #success=1 #failure=5
    Readiness:		http-get http://:8081/readiness delay=3s timeout=5s period=10s #success=1 #failure=3
    Volume Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-tqc73 (ro)
    Environment Variables:
      PROMETHEUS_PORT:	10055
  dnsmasq:
    Container ID:	docker://42052c081c038110a6ea09888a6fc11a25f63384b52c6e6d28da8c7ed3fa7b23
    Image:		gcr.io/google_containers/k8s-dns-dnsmasq-amd64:1.11.0
    Image ID:		docker://sha256:721bf2add40b598b9deb978a7ce65c3f3e650f634ed40d0c665888e4108b72cd
    Ports:		53/UDP, 53/TCP
    Args:
      --cache-size=1000
      --no-resolv
      --server=127.0.0.1#10053
      --log-facility=-
    Requests:
      cpu:		150m
      memory:		10Mi
    State:		Running
      Started:		Wed, 18 Jan 2017 04:12:35 +0000
    Ready:		True
    Restart Count:	0
    Liveness:		http-get http://:10054/healthcheck/dnsmasq delay=60s timeout=5s period=10s #success=1 #failure=5
    Volume Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-tqc73 (ro)
    Environment Variables:	<none>
  sidecar:
    Container ID:	docker://d169091ab2d0581ade25cb6e6c5edc7da98d877ff64d3623b1f4209865475e24
    Image:		gcr.io/google_containers/k8s-dns-sidecar-amd64:1.11.0
    Image ID:		docker://sha256:cbae2d53df65429a0e131fbe140fd7c66d6d1059b3359b9e5b5e4e5b341d250b
    Port:		10054/TCP
    Args:
      --v=2
      --logtostderr
      --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,A
      --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,A
    Requests:
      cpu:		10m
      memory:		20Mi
    State:		Running
      Started:		Wed, 18 Jan 2017 04:12:35 +0000
    Ready:		True
    Restart Count:	0
    Liveness:		http-get http://:10054/metrics delay=60s timeout=5s period=10s #success=1 #failure=5
    Volume Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-tqc73 (ro)
    Environment Variables:	<none>
Conditions:
  Type		Status
  Initialized 	True
  Ready 	False
  PodScheduled 	True
Volumes:
  default-token-tqc73:
    Type:	Secret (a volume populated by a Secret)
    SecretName:	default-token-tqc73
QoS Class:	Burstable
Tolerations:	CriticalAddonsOnly=:Exists
Events:
  FirstSeen	LastSeen	Count	From			SubObjectPath			Type		Reason		Message
  ---------	--------	-----	----			-------------			--------	------		-------
  41s		41s		1	{default-scheduler }					Normal		Scheduled	Successfully assigned kube-dns-2829910835-xhtrv to 172.17.8.11
  39s		39s		1	{kubelet 172.17.8.11}	spec.containers{kubedns}	Normal		Created		Created container with docker id a39c0d802043; Security:[seccomp=unconfined]
  39s		39s		1	{kubelet 172.17.8.11}	spec.containers{kubedns}	Normal		Started		Started container with docker id a39c0d802043
  39s		39s		1	{kubelet 172.17.8.11}	spec.containers{dnsmasq}	Normal		Pulled		Container image ""gcr.io/google_containers/k8s-dns-dnsmasq-amd64:1.11.0"" already present on machine
  39s		39s		1	{kubelet 172.17.8.11}	spec.containers{dnsmasq}	Normal		Created		Created container with docker id 42052c081c03; Security:[seccomp=unconfined]
  38s		38s		1	{kubelet 172.17.8.11}	spec.containers{sidecar}	Normal		Started		Started container with docker id d169091ab2d0
  38s		38s		1	{kubelet 172.17.8.11}	spec.containers{dnsmasq}	Normal		Started		Started container with docker id 42052c081c03
  38s		38s		1	{kubelet 172.17.8.11}	spec.containers{sidecar}	Normal		Pulled		Container image ""gcr.io/google_containers/k8s-dns-sidecar-amd64:1.11.0"" already present on machine
  38s		38s		1	{kubelet 172.17.8.11}	spec.containers{sidecar}	Normal		Created		Created container with docker id d169091ab2d0; Security:[seccomp=unconfined]
  36s		36s		1	{kubelet 172.17.8.11}	spec.containers{kubedns}	Normal		Created		Created container with docker id b90d8e58c16d; Security:[seccomp=unconfined]
  36s		36s		1	{kubelet 172.17.8.11}	spec.containers{kubedns}	Normal		Started		Started container with docker id b90d8e58c16d
  35s		30s		3	{kubelet 172.17.8.11}					Warning		FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""kubedns"" with CrashLoopBackOff: ""Back-off 10s restarting failed container=kubedns pod=kube-dns-2829910835-xhtrv_kube-system(55ad8e0e-dd34-11e6-8e80-080027acfaf0)""

  40s	18s	3	{kubelet 172.17.8.11}	spec.containers{kubedns}	Normal	Pulled		Container image ""gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.11.0"" already present on machine
  18s	18s	1	{kubelet 172.17.8.11}	spec.containers{kubedns}	Normal	Created		Created container with docker id 8a657cfdc2fa; Security:[seccomp=unconfined]
  18s	18s	1	{kubelet 172.17.8.11}	spec.containers{kubedns}	Normal	Started		Started container with docker id 8a657cfdc2fa
  35s	10s	5	{kubelet 172.17.8.11}	spec.containers{kubedns}	Warning	BackOff		Back-off restarting failed docker container
  16s	10s	2	{kubelet 172.17.8.11}					Warning	FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""kubedns"" with CrashLoopBackOff: ""Back-off 20s restarting failed container=kubedns pod=kube-dns-2829910835-xhtrv_kube-system(55ad8e0e-dd34-11e6-8e80-080027acfaf0)""
```

I'm at a loss as to how to troubleshoot further.
I'm using the provided files which require minimal change.
Please let me know if you need more info, thank you!",closed,False,2017-01-18 05:16:37,2017-01-27 01:27:39
dns,ryan-ibm,https://github.com/kubernetes/dns/pull/34,https://api.github.com/repos/kubernetes/dns/issues/34,Adding s390x support,Adding s390x support,closed,True,2017-01-18 06:00:18,2017-02-15 13:09:05
dns,bowei,https://github.com/kubernetes/dns/issues/35,https://api.github.com/repos/kubernetes/dns/issues/35,kube-dns should use versioned client-go,"kube-dns should use a versioned copy of the client-go repository, rather than HEAD",closed,False,2017-01-18 07:25:43,2017-07-07 18:00:00
dns,bowei,https://github.com/kubernetes/dns/pull/36,https://api.github.com/repos/kubernetes/dns/issues/36,Godep,Adds a wrapper script for dealing with godep,closed,True,2017-01-23 07:54:58,2017-01-23 19:19:56
dns,bowei,https://github.com/kubernetes/dns/pull/37,https://api.github.com/repos/kubernetes/dns/issues/37,Godep went up a version,,closed,True,2017-01-23 19:25:57,2017-01-23 19:34:41
dns,therc,https://github.com/kubernetes/dns/issues/38,https://api.github.com/repos/kubernetes/dns/issues/38,Add support for TXT entries,"gRPC has a new proposal out for storing service configurations in TXT records:

https://github.com/grpc/proposal/pull/5

If you use gRPC under Kubernetes, you will now have two choices:

1. use parallel DNS hierarchies, one managed by kube-dns, one by a more traditional DNS server just for the TXT records
1. extend kube-dns to support custom TXT records

I would prefer the second, by far. This could be accomplished through either an annotation or a new field on the service. Since I have some experience with kube-dns, having implemented ExternalName support, I can help with some/all the code, too. Of course, gRPC is just going to be one use case for the feature.

This seems to be related to, but still independent from https://github.com/kubernetes/kubernetes/issues/6437",closed,False,2017-01-24 02:23:59,2018-02-18 17:51:02
dns,liggitt,https://github.com/kubernetes/dns/pull/39,https://api.github.com/repos/kubernetes/dns/issues/39,Add support for pulling config from a directory,"now that optional configmaps are possible, kube-dns should support pulling config from a mounted directory

this PR refactors the existing API-based configmap source and adds a directory-based source

c.f.
https://github.com/kubernetes/kubernetes/pull/36775#issuecomment-261412030
https://github.com/kubernetes/kubernetes/pull/38816
https://github.com/kubernetes/kubernetes/pull/39981",closed,True,2017-01-24 16:28:56,2017-01-25 19:20:46
dns,cmluciano,https://github.com/kubernetes/dns/pull/40,https://api.github.com/repos/kubernetes/dns/issues/40,Lock client-go at release 2.0,WIP lock client-go to release v2.0.0-alpha.1,closed,True,2017-01-24 21:37:56,2017-02-07 08:38:17
dns,bowei,https://github.com/kubernetes/dns/pull/41,https://api.github.com/repos/kubernetes/dns/issues/41,E2e,Adds rudimentary e2e testing for kube-dns,closed,True,2017-01-25 22:17:01,2017-01-26 23:56:40
dns,liggitt,https://github.com/kubernetes/dns/pull/42,https://api.github.com/repos/kubernetes/dns/issues/42,Fix initial condition with empty config dir,"Found an edge case with an empty configdir on startup. The file source returns an empty result (version="""", data={}) for an empty dir.

sync#processResult() thought it had already processed this version, since the zero-value for latestVersion is """", so it returned `nil, nil`

This meant the initial config returned from Once() was nil, rather than a default config, which makes a nil dereference possible

Once() should *always* build a config from the result in non-error cases",closed,True,2017-01-26 22:26:27,2017-01-27 01:37:58
dns,jhorwit2,https://github.com/kubernetes/dns/issues/43,https://api.github.com/repos/kubernetes/dns/issues/43,docker registry with a port breaks make script,"The make script allows you to set a registry from the env; however, if it's something like `foo:5000` it will fail with:

`rules.mk:125: *** target pattern contains no `%'.  Stop.`",closed,False,2017-01-27 00:12:35,2017-02-15 04:03:52
dns,cmluciano,https://github.com/kubernetes/dns/pull/44,https://api.github.com/repos/kubernetes/dns/issues/44,Change shebang to sh instead of bash,Bash is not available in the golang container that this script runs in.,closed,True,2017-01-31 16:03:57,2017-02-01 19:20:29
dns,cmluciano,https://github.com/kubernetes/dns/issues/45,https://api.github.com/repos/kubernetes/dns/issues/45,Add Vagrantfile to ease development on DNS,"I have a Vagrantfile that sets up a Ubuntu 16.04 box to build/test this repository. I've been using it since this repository contains scripts that don't play well on Darwin.

 I can open a PR to add this to the root path if we think that it would be beneficial. ",closed,False,2017-01-31 16:07:20,2017-02-01 18:48:34
dns,cmluciano,https://github.com/kubernetes/dns/pull/46,https://api.github.com/repos/kubernetes/dns/issues/46,add vagrantfile for local development,"This file will launch a Ubuntu 16.04 VM with virtualbox.
It install tools necessary to build/test DNS as well as some
dependencies like Kubernetes.

Closes #45",closed,True,2017-02-01 16:44:10,2017-02-01 18:48:34
dns,bowei,https://github.com/kubernetes/dns/pull/47,https://api.github.com/repos/kubernetes/dns/issues/47,Only containerize and push a subset of the binaries built,"Utility binaries used for testing should not be containerized
and pushed.",closed,True,2017-02-01 22:19:39,2017-02-21 18:15:01
dns,cmluciano,https://github.com/kubernetes/dns/issues/48,https://api.github.com/repos/kubernetes/dns/issues/48,build/dep.sh and Godeps does not properly import some dependencies,"There are 3 dependencies that are not pulled in properly with Godep. I can only get a successful build by adding the dependent libraries to [build/dep.sh required packages](https://github.com/kubernetes/dns/blob/master/build/dep.sh#L21).

```
REQUIRED_PKGS=""cloud.google.com/go/internal/... golang.org/x/text/internal/... ./pkg/... ./cmd/...""
```

Packages not pulled in:
github.com/googleapis/gax-go
golang.org/x/text/internal

Steps to reproduce:
1. Enter container ``./build/dep.sh enter -u``
2. Pull latest of a given DEP. 
3. Remove the Godep and vendor folders
4. Run ./build/dep.sh save
5. Exit container assuming no complaints from Godep
6. ``make build``

```
root@ubuntu-xenial:/vagrant# make build
building : bin/amd64/e2e
vendor/cloud.google.com/go/internal/retry.go:21:2: cannot find package ""github.com/googleapis/gax-go"" in any of:
	/go/src/k8s.io/dns/vendor/github.com/googleapis/gax-go (vendor tree)
	/usr/local/go/src/github.com/googleapis/gax-go (from $GOROOT)
	/go/src/github.com/googleapis/gax-go (from $GOPATH)
test/e2e/kubedns/kubedns.go:23:2: cannot find package ""github.com/onsi/ginkgo"" in any of:
	/go/src/k8s.io/dns/vendor/github.com/onsi/ginkgo (vendor tree)
	/usr/local/go/src/github.com/onsi/ginkgo (from $GOROOT)
	/go/src/github.com/onsi/ginkgo (from $GOPATH)
vendor/golang.org/x/text/cases/map.go:16:2: cannot find package ""golang.org/x/text/internal"" in any of:
	/go/src/k8s.io/dns/vendor/golang.org/x/text/internal (vendor tree)
	/usr/local/go/src/golang.org/x/text/internal (from $GOROOT)
	/go/src/golang.org/x/text/internal (from $GOPATH)
```",closed,False,2017-02-02 16:32:11,2017-07-07 21:16:25
dns,jbeda,https://github.com/kubernetes/dns/issues/49,https://api.github.com/repos/kubernetes/dns/issues/49,sidecar should verify that it had fully qualified DNS names,"Spent a while debugging the fact that the input was `cluster.local` and not `cluster.local.`

Or we can just fix it up.",closed,False,2017-02-02 23:21:21,2017-02-02 23:51:05
dns,jbeda,https://github.com/kubernetes/dns/pull/50,https://api.github.com/repos/kubernetes/dns/issues/50,Make sure that the probe name is a FQDN.,"Add the trailing dot if it is missing.  Fixes #49.

Not sure how to test this.  I think it should be pretty darn safe.  Here is the impl of Fqdn: https://github.com/miekg/dns/blob/master/defaults.go#L227.",closed,True,2017-02-02 23:30:55,2017-02-02 23:51:09
dns,githubvick,https://github.com/kubernetes/dns/issues/51,https://api.github.com/repos/kubernetes/dns/issues/51,kubedns nslookup: can't resolve,"I have successfully setup a Kube cluster and trying to setup KubeDNS.

Version:

kubectl version

```
Client Version: version.Info{Major:""1"", Minor:""3"", GitVersion:""v1.3.0"", GitCommit:""86dc49aa137175378ac7fba7751c3d3e7f18e5fc"", GitTreeState:""clean"", BuildDate:""2016-12-15T16:57:18Z"", GoVersion:""go1.6.3"", Compiler:""gc"", Platform:""linux/amd64""}

Server Version: version.Info{Major:""1"", Minor:""3"", GitVersion:""v1.3.0"", GitCommit:""86dc49aa137175378ac7fba7751c3d3e7f18e5fc"", GitTreeState:""clean"", BuildDate:""2016-12-15T16:57:18Z"", GoVersion:""go1.6.3"", Compiler:""gc"", Platform:""linux/amd64""}
```

When I deploy kubedns, I get this error in journalctl -xe

""Error syncing deployment kube-system/kube-dns-v20: Operation cannot be fulfilled on deployments.extensions ""kube-dns-v20"": the object has been modified; please apply your changes to the latest version and try again""

But didn't find enough info on that, so ignored it to atleast see where I could reach.

kubectl cluster-info

`Kubernetes master is running at http://192.168.6.101:8080 
KubeDNS is running at http://192.168.6.101:8080/api/v1/proxy/namespaces/kube-system/services/kube-dns`

 mongodb and webapp are my pods

```
kubectl exec mongodb cat /etc/resolv.conf
search default.svc.cluster.local svc.cluster.local cluster.local     federated.fds
nameserver 10.254.0.2
nameserver 8.8.8.8
nameserver 8.8.4.4
options ndots:5

[osboxes@kubemaster kubernetes]$ kubectl exec webapp cat /etc/resolv.conf
search default.svc.cluster.local svc.cluster.local cluster.local federated.fds
nameserver 10.254.0.2
nameserver 8.8.8.8
nameserver 8.8.4.4
options ndots:5
```

on the master and node, in etc/kubernetes/config, I have this

```
ENABLE_CLUSTER_DNS=""${KUBE_ENABLE_CLUSTER_DNS:-true}""
DNS_SERVER_IP=""10.254.0.2""
DNS_DOMAIN=""cluster.local""
DNS_REPLICAS=1
```

I have passed the required arguments in the node in kubelet on startup --cluster_dns=10.254.0.2 --cluster_domain=cluster.local

```
`kubectl exec webapp -- cat /etc/hosts
127.0.0.1   localhost
fe00::1 ip6-allnodes
fe00::2 ip6-allrouters
172.17.23.2 webapp`
```

When I do a nslookup on the container
```

kubectl exec -it webapp -- nslookup kubernetes.default.svc.cluster.local localhost
;; connection timed out; no servers could be reached

error: error executing remote command: error executing command in container: Error executing in Docker Container: 1

```

But this works,

```
kubectl --namespace=kube-system exec -ti kube-dns-v20-2502365070-2rmzl -c     kubedns --  nslookup kubernetes.default.svc.cluster.local localhost
Server:    127.0.0.1
Address 1: 127.0.0.1 localhost

Name:      kubernetes.default.svc.cluster.local
Address 1: 10.254.0.1 kubernetes.default.svc.cluster.local
```

No other errors in logs kubedns, dnsmasq or healthz. I can ",closed,False,2017-02-07 21:51:34,2017-02-07 22:17:45
dns,XiLongZheng,https://github.com/kubernetes/dns/issues/52,https://api.github.com/repos/kubernetes/dns/issues/52,images for s390x,When will the dns images for s390x ready? Along with kubentetes 1.6.0 release?,closed,False,2017-02-09 05:57:49,2017-02-17 20:58:22
dns,ronaldpetty,https://github.com/kubernetes/dns/pull/53,https://api.github.com/repos/kubernetes/dns/issues/53,Update README.md,"Changed verbiage, we build images not containers.  Didn't change the make command though as I don't fully appreciate what might go wrong if that changes (assuming automatic processes do `make containers`).",closed,True,2017-02-10 10:29:03,2018-02-19 05:01:59
dns,bowei,https://github.com/kubernetes/dns/pull/54,https://api.github.com/repos/kubernetes/dns/issues/54,Fixes pushing to registry name with ':',https://github.com/kubernetes/dns/issues/43,closed,True,2017-02-14 06:37:56,2017-02-21 18:14:52
dns,morallo,https://github.com/kubernetes/dns/issues/55,https://api.github.com/repos/kubernetes/dns/issues/55,Custom DNS entries for kube-dns,"I re-create the issue here as suggested by @bowei.

**Kubernetes version** (use `kubectl version`): v1.5.2

**Environment**:
- **Cloud provider or hardware configuration**: baremetal, 
- **OS** (e.g. from /etc/os-release): Debian GNU/Linux 8 (jessie)
- **Kernel** (e.g. `uname -a`): 3.16.7
- **Install tools**: [docker-multinode](https://github.com/kubernetes/kube-deploy/tree/master/docker-multinode).

**Current status**: entries in /etc/hosts of the nodes are not used by kube-dns. There is no straightforward way to replicate this custom DNS configuration for the cluster.

**What I would like**: Some way to easily define custom DNS entries used by kube-dns on a cluster-wide level, without deploying an additional DNS server.

Already considered solutions:
- Use a Service without selector and external Endpoint. It won't allow full DNS names and [that won't change for the time being](https://github.com/kubernetes/kubernetes/issues/3752#issuecomment-234753025).
- Deploy an additional DNS server and add it to /etc/resolv.conf in ~~all nodes~~ the node running kube-dns. This works, but it's not convenient for quick/testing deployments. Also, it requires access to the host.
- [Define a ConfigMap with the DNS entries and add them to the kube-dns dnsmasq /etc/hosts.d](http://stackoverflow.com/a/40595719/4633210). This is possible, but requires modifying kube-dns launch flags (not obvious in automated deployments like [docker-multinode](https://github.com/kubernetes/kube-deploy/pull/226).

Possible solutions:

- Implement a special ConfigMap to declare custom entries on a cluster-wide level and make kube-dns look it up.
- kube-dns imports node's `/etc/hosts` entries, like it does for /etc/resolv.conf. This is not very elegant and doesn't scale, but it replicates a capability currently existing in _non containerized_ system administration.",closed,False,2017-02-14 09:02:30,2019-01-31 22:03:47
dns,gajju26,https://github.com/kubernetes/dns/pull/56,https://api.github.com/repos/kubernetes/dns/issues/56,Making k8s-dns-kube-dns and k8s-dns-dnsmasq images available for s390x,"In this PR I have changed the version of ""gcr.io/google_containers/kube-cross"" image. The existing version has Go does not support s390x. With ""v1.7.4-1"" version it builds the dnsmasq binary and builds successfully for s390x. Also modified s390x support in ""rules.mk"" and ""images/dnsmasq/Makefile""",closed,True,2017-02-15 12:47:25,2017-02-15 19:31:23
dns,bowei,https://github.com/kubernetes/dns/pull/57,https://api.github.com/repos/kubernetes/dns/issues/57,Dnsmasq nanny,"This adds dnsmasq-nanny, a helper process that wraps dnsmasq and configures it in response to the kube-dns configmap. This implements two configuration options:
* stubDomains: a map of additional stub domains that are resolved by outside nameservers
* upstreamNameservers: a list of upstream nameservers to use in place of the one from /etc/resolv.conf",closed,True,2017-02-17 07:19:50,2017-02-21 18:14:28
dns,bowei,https://github.com/kubernetes/dns/pull/58,https://api.github.com/repos/kubernetes/dns/issues/58,Make travis test building all architectures,,closed,True,2017-02-17 22:22:04,2017-02-21 18:14:18
dns,bowei,https://github.com/kubernetes/dns/pull/59,https://api.github.com/repos/kubernetes/dns/issues/59,Add --no-resolv when upstream nameservers are specified,,closed,True,2017-02-17 23:40:32,2017-02-21 18:14:07
dns,ravilr,https://github.com/kubernetes/dns/issues/60,https://api.github.com/repos/kubernetes/dns/issues/60,stale service A records returned by dnsmasq?,"kubedns: gcr.io/google_containers/kubedns-amd64:1.8
dnsmasq: gcr.io/google_containers/kube-dnsmasq-amd64:1.4

A service resource say qa-svc1 was created and deleted after some time. the same qa-svc1, if recreated and got assigned a different ClusterIP, we are seeing kube-dns/Cluster-First dns-policy pods continue to see older ClusterIP on dns resolution of qa-svc1.  I believe this is from the dnsmasq cache. Should there be a max-cache-ttl setting set on all dnsmasq cached records? or can kube-dns invalidate the cache in dnsmasq?

@bowei @thockin ",closed,False,2017-02-18 03:31:00,2018-01-23 16:06:11
dns,XiLongZheng,https://github.com/kubernetes/dns/issues/61,https://api.github.com/repos/kubernetes/dns/issues/61,kubedns 1.13.0 failed to start on v1.6.0-alpha.3 (s390x),"Just created a new v1.6.0-alpha.3 cluster on s390x, tried to deploy kubedns to the cluster, but failed. See below kubectl get pods and describe pods out put. Also attached my kubedns-controller.yaml and my shell script to start kubernetes cluster in zip file.
[kubedns-failed-to-start-s390x.zip](https://github.com/kubernetes/dns/files/785078/kubedns-failed-to-start-s390x.zip)


root@test-k8s-16-alpha3:/etc/kubernetes/server/bin# kubectl get pods -n kube-system
NAME                        READY     STATUS             RESTARTS   AGE
kube-dns-3552530395-h7s8k   2/3       CrashLoopBackOff   3          1m
root@test-k8s-16-alpha3:/etc/kubernetes/server/bin# kubectl describe pods kube-dns-3552530395-h7s8k -n kube-system
Name:		kube-dns-3552530395-h7s8k
Namespace:	kube-system
Node:		127.0.0.1/127.0.0.1
Start Time:	Sat, 18 Feb 2017 13:54:06 +0000
Labels:		k8s-app=kube-dns
		pod-template-hash=3552530395
Status:		Running
IP:		172.17.0.2
Controllers:	ReplicaSet/kube-dns-3552530395
Containers:
  kubedns:
    Container ID:	docker://3a3462b3d280c271f141292961654a70fabf0d6ae199c31739f37b4d84c5cd67
    Image:		gcr.io/google_containers/k8s-dns-kube-dns-s390x:1.13.0
    Image ID:		docker-pullable://gcr.io/google_containers/k8s-dns-kube-dns-s390x@sha256:49a499ddc7e5ad4ef317cb7a136b033e64f55c191b511926151e344e31fc418a
    Ports:		10053/UDP, 10053/TCP, 10055/TCP
    Args:
      --domain=cluster.local.
      --dns-port=10053
      --config-dir=/kube-dns-config
      --v=2
    Limits:
      memory:	170Mi
    Requests:
      cpu:		100m
      memory:		70Mi
    State:		Waiting
      Reason:		CrashLoopBackOff
    Last State:		Terminated
      Reason:		Error
      Exit Code:	255
      Started:		Mon, 01 Jan 0001 00:00:00 +0000
      Finished:		Sat, 18 Feb 2017 13:54:50 +0000
    Ready:		False
    Restart Count:	3
    Liveness:		http-get http://:10054/healthcheck/kubedns delay=60s timeout=5s period=10s #success=1 #failure=5
    Readiness:		http-get http://:8081/readiness delay=3s timeout=5s period=10s #success=1 #failure=3
    Volume Mounts:
      /kube-dns-config from kube-dns-config (rw)
    Environment Variables from:	<none>
    Environment Variables:
      PROMETHEUS_PORT:	10055
  dnsmasq:
    Container ID:	docker://480ed642a294e518821292cb8d74645035d317f59f200d23c5cae9aa9a6a0359
    Image:		gcr.io/google_containers/k8s-dns-dnsmasq-s390x:1.13.0
    Image ID:		docker-pullable://gcr.io/google_containers/k8s-dns-dnsmasq-s390x@sha256:1eb57c914d85af5a77a9af9632ad144106b3e12f68a8e8a734c5657c917753fd
    Ports:		53/UDP, 53/TCP
    Args:
      --cache-size=1000
      --server=/cluster.local/127.0.0.1#10053
      --server=/in-addr.arpa/127.0.0.1#10053
      --server=/ip6.arpa/127.0.0.1#10053
      --log-facility=-
    Requests:
      cpu:			150m
      memory:			10Mi
    State:			Running
      Started:			Sat, 18 Feb 2017 13:54:08 +0000
    Ready:			True
    Restart Count:		0
    Liveness:			http-get http://:10054/healthcheck/dnsmasq delay=60s timeout=5s period=10s #success=1 #failure=5
    Volume Mounts:		<none>
    Environment Variables from:	<none>
    Environment Variables:	<none>
  sidecar:
    Container ID:	docker://90b09674ecc9ff3ba06701d0f5a12240cb7c685e4b8fb9430289199a22806173
    Image:		gcr.io/google_containers/k8s-dns-sidecar-s390x:1.13.0
    Image ID:		docker-pullable://gcr.io/google_containers/k8s-dns-sidecar-s390x@sha256:6b03af9d65be38542ff6df0c9a569e36e81aa9ee808dbef3a00b58d436455c02
    Port:		10054/TCP
    Args:
      --v=2
      --logtostderr
      --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,A
      --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,A
    Requests:
      cpu:			10m
      memory:			20Mi
    State:			Running
      Started:			Sat, 18 Feb 2017 13:54:08 +0000
    Ready:			True
    Restart Count:		0
    Liveness:			http-get http://:10054/metrics delay=60s timeout=5s period=10s #success=1 #failure=5
    Volume Mounts:		<none>
    Environment Variables from:	<none>
    Environment Variables:	<none>
Conditions:
  Type		Status
  Initialized 	True 
  Ready 	False 
  PodScheduled 	True 
Volumes:
  kube-dns-config:
    Type:	ConfigMap (a volume populated by a ConfigMap)
    Name:	kube-dns
    Optional:	true
QoS Class:	Burstable
Node-Selectors:	<none>
Tolerations:	CriticalAddonsOnly=:Exists
Events:
  FirstSeen	LastSeen	Count	From			SubObjectPath			Type		Reason		Message
  ---------	--------	-----	----			-------------			--------	------		-------
  1m		1m		1	kubelet, 127.0.0.1					Normal		SandboxReceived	Pod sandbox received, it will be created.
  1m		1m		1	default-scheduler					Normal		Scheduled	Successfully assigned kube-dns-3552530395-h7s8k to 127.0.0.1
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{sidecar}	Normal		Created		Created container with id 90b09674ecc9ff3ba06701d0f5a12240cb7c685e4b8fb9430289199a22806173
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{kubedns}	Normal		Created		Created container with id 78672547a5404160b7cb483dda74487fe8e32d9a43657577df99b77af8e83042
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{kubedns}	Normal		Started		Started container with id 78672547a5404160b7cb483dda74487fe8e32d9a43657577df99b77af8e83042
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{dnsmasq}	Normal		Pulled		Container image ""gcr.io/google_containers/k8s-dns-dnsmasq-s390x:1.13.0"" already present on machine
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{dnsmasq}	Normal		Created		Created container with id 480ed642a294e518821292cb8d74645035d317f59f200d23c5cae9aa9a6a0359
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{dnsmasq}	Normal		Started		Started container with id 480ed642a294e518821292cb8d74645035d317f59f200d23c5cae9aa9a6a0359
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{sidecar}	Normal		Pulled		Container image ""gcr.io/google_containers/k8s-dns-sidecar-s390x:1.13.0"" already present on machine
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{sidecar}	Normal		Started		Started container with id 90b09674ecc9ff3ba06701d0f5a12240cb7c685e4b8fb9430289199a22806173
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{kubedns}	Normal		Created		Created container with id 85fa416009ee095b281e4bdacb633346e4483c79e8727061662c7aaf25befe0e
  1m		1m		1	kubelet, 127.0.0.1	spec.containers{kubedns}	Normal		Started		Started container with id 85fa416009ee095b281e4bdacb633346e4483c79e8727061662c7aaf25befe0e
  1m		1m		3	kubelet, 127.0.0.1					Warning		FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""kubedns"" with CrashLoopBackOff: ""Back-off 10s restarting failed container=kubedns pod=kube-dns-3552530395-h7s8k_kube-system(b6b4170e-f5e1-11e6-9192-fa163ee87680)""

  1m	1m	1	kubelet, 127.0.0.1	spec.containers{kubedns}	Normal	Created		Created container with id 96ef011f27e7b00a8cdff6842228246fa29854de1f9c1a62ec0a3166cc8f1542
  1m	1m	1	kubelet, 127.0.0.1	spec.containers{kubedns}	Normal	Started		Started container with id 96ef011f27e7b00a8cdff6842228246fa29854de1f9c1a62ec0a3166cc8f1542
  59s	53s	2	kubelet, 127.0.0.1					Warning	FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""kubedns"" with CrashLoopBackOff: ""Back-off 20s restarting failed container=kubedns pod=kube-dns-3552530395-h7s8k_kube-system(b6b4170e-f5e1-11e6-9192-fa163ee87680)""

  1m	40s	4	kubelet, 127.0.0.1	spec.containers{kubedns}	Normal	Pulled		Container image ""gcr.io/google_containers/k8s-dns-kube-dns-s390x:1.13.0"" already present on machine
  40s	40s	1	kubelet, 127.0.0.1	spec.containers{kubedns}	Normal	Created		Created container with id 3a3462b3d280c271f141292961654a70fabf0d6ae199c31739f37b4d84c5cd67
  39s	39s	1	kubelet, 127.0.0.1	spec.containers{kubedns}	Normal	Started		Started container with id 3a3462b3d280c271f141292961654a70fabf0d6ae199c31739f37b4d84c5cd67
  1m	6s	9	kubelet, 127.0.0.1	spec.containers{kubedns}	Warning	BackOff		Back-off restarting failed container
  38s	6s	4	kubelet, 127.0.0.1					Warning	FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""kubedns"" with CrashLoopBackOff: ""Back-off 40s restarting failed container=kubedns pod=kube-dns-3552530395-h7s8k_kube-system(b6b4170e-f5e1-11e6-9192-fa163ee87680)""


kubectl version
Client Version: version.Info{Major:""1"", Minor:""6+"", GitVersion:""v1.6.0-alpha.3"", GitCommit:""5802799e56c7fcd1638e5848a13c5f3b0b1479ab"", GitTreeState:""clean"", BuildDate:""2017-02-16T19:27:36Z"", GoVersion:""go1.7.4"", Compiler:""gc"", Platform:""linux/s390x""}
Server Version: version.Info{Major:""1"", Minor:""6+"", GitVersion:""v1.6.0-alpha.3"", GitCommit:""5802799e56c7fcd1638e5848a13c5f3b0b1479ab"", GitTreeState:""clean"", BuildDate:""2017-02-16T19:17:01Z"", GoVersion:""go1.7.4"", Compiler:""gc"", Platform:""linux/s390x""}",closed,False,2017-02-18 14:17:12,2017-04-06 14:33:04
dns,bowei,https://github.com/kubernetes/dns/pull/62,https://api.github.com/repos/kubernetes/dns/issues/62,Use default config if none exist at startup,Also adds some glog flush() to ensure we see more of the log output,closed,True,2017-02-19 03:59:29,2017-02-21 18:14:35
dns,wojtek-t,https://github.com/kubernetes/dns/pull/63,https://api.github.com/repos/kubernetes/dns/issues/63,Use protobufs for communication with apiserver,@bowei @thockin ,closed,True,2017-02-23 11:40:45,2017-02-23 19:08:32
dns,wojtek-t,https://github.com/kubernetes/dns/pull/64,https://api.github.com/repos/kubernetes/dns/issues/64,Use protobufs for communication with apiserver,,closed,True,2017-02-23 19:07:22,2017-02-23 20:04:49
dns,RaasAhsan,https://github.com/kubernetes/dns/issues/65,https://api.github.com/repos/kubernetes/dns/issues/65,KubeDNS consistently dies,"Hi there! I'm running a vanilla Kubernetes v1.5.1 cluster inside VirtualBox with a flannel overlay network. All of that worked perfectly, so I decided to get cluster DNS working today.

I'm having a couple of issues here. First off is sometimes when KubeDNS starts it can't reach the apiserver. I have to restart it a couple of times before it reaches it correctly. The second problem is that the service seems to stop serving DNS and stop responding to the health checks, so I have to restart it again. The dnsmasq container seems to be fine, but I get this error message on the KubeDNS container around when things stop working:

```
Ignoring signal terminated (can only be terminated by SIGKILL)
```

KubeDNS does work for a couple of minutes at a time, but only for a couple of minutes.

Its gotten kind of frustrating and I've tried to hunt down any docs. I'm not pasting any logs in this issue because there's so much to sift through, so any ideas on where to start?",closed,False,2017-03-03 09:27:09,2017-03-04 02:59:29
dns,sgmiller,https://github.com/kubernetes/dns/issues/66,https://api.github.com/repos/kubernetes/dns/issues/66,kubedns dnsmasq pod fails with blank IP for the DNS host,"Can't get a cluster started using kubeadm on v1.6.0-beta1 (kube-dns v1.14.1).  The dnsmasq pod fails with:
```
I0308 16:30:25.353537       1 nanny.go:108] dnsmasq[11]: bad address at /etc/hosts line 7
I0308 16:30:25.353540       1 nanny.go:108] dnsmasq[11]: read /etc/hosts - 6 addresses
```

/etc/hosts contains:

```
127.0.0.1	localhost
::1	localhost ip6-localhost ip6-loopback
fe00::0	ip6-localnet
ff00::0	ip6-mcastprefix
ff02::1	ip6-allnodes
ff02::2	ip6-allrouters
	kube-dns-1630391940-grt67
```
So presumably it can't get the information it needs from the ConfigMap?",closed,False,2017-03-08 16:37:58,2017-03-08 21:58:03
dns,madhusudancs,https://github.com/kubernetes/dns/issues/67,https://api.github.com/repos/kubernetes/dns/issues/67,Federations config should work with or without trailing dots in the zone names,"`Federations` config either passed through a flag or a ConfigMap is validated to ensure that the zone names (the domain name suffix) are valid [RFC 1123](https://tools.ietf.org/html/rfc1123) subdomain names. Most DNS zone configurations take a trailing dot in their configuration, but the regex we use in `kube-dns` has a format that does not match trailing dots. This mismatch is a cognitive overhead for our users. We should just accept zone names in `Federations` config with or without trailing dots.",closed,False,2017-03-09 18:52:17,2018-02-22 13:21:05
dns,shashidharatd,https://github.com/kubernetes/dns/issues/68,https://api.github.com/repos/kubernetes/dns/issues/68,stubDomains should also support nameserver with port,"@bowei, Thanks for the feature to add nameserver to kubedns via [stubDomains](https://github.com/kubernetes/dns/commit/9cd64b63d9cff93f111c0fb25c5a3db13700fc19), its really useful.
I find that nameserver need to be pure ip and does not support appending  with port.

it would be really useful to support nameserver appended with port, if somebody wants to deploy dns-server in kubernetes as a NodePort service and there could be possibilities where cloud-provider may not be supporting LoadBalancer type service.

We do have a use case in federation for federating clusters on non-cloud environments.

if agree, i can send a patch to support nameserver appended with port number

cc @kubernetes/sig-federation-misc",closed,False,2017-03-10 14:46:56,2017-03-11 00:35:53
dns,shashidharatd,https://github.com/kubernetes/dns/pull/69,https://api.github.com/repos/kubernetes/dns/issues/69,Support specifying port number for nameserver in stubDomains,"Fixes: #68

cc  @bowei  @madhusudancs @kubernetes/sig-federation-misc",closed,True,2017-03-10 15:03:18,2017-03-11 00:35:53
dns,bowei,https://github.com/kubernetes/dns/issues/70,https://api.github.com/repos/kubernetes/dns/issues/70,Error with pod hostname query,"Query for the `<pod-hostname>.<ns>.pods.cluster.local` is not returning the A record for the pod

```
/ # dig customer-deployment-onuwixzygi4tkn3fgztgeylfgnrdm-62180010musmy.staging.pod.cluster.local.
```

kube-dns logs
```
I0316 16:18:30.889074       1 logs.go:41] skydns: error from backend: Invalid IP Address customer.deployment.onuwixzygi4tkn3fgztgeylfgnrdm.62180010musmy
```",closed,False,2017-03-16 18:13:35,2017-11-29 22:12:01
dns,CallMeFoxie,https://github.com/kubernetes/dns/pull/71,https://api.github.com/repos/kubernetes/dns/issues/71,Fix version on startup,"Hi,
It seems that during startup the kube-dns service is reporting (static) version of kubernetes:
$ make bin/amd64/kube-dns
building : bin/amd64/kube-dns
$ bin/amd64/kube-dns 
I0317 11:24:42.981414   27628 dns.go:49] version: v1.5.2-beta.0+$Format:%h$
...

which is defined in vendor/k8s.io/kubernetes/pkg/version/base.go and seems rather wrong/useless. We should report kube-dns version instead, which is compiled-in during compile time.

After applying this fix:
$ make bin/amd64/kube-dns
building : bin/amd64/kube-dns
$ bin/amd64/kube-dns 
I0317 11:27:32.043009   30292 dns.go:49] version: 1.14.1-dirty

which looks more appropriate.

Have a nice day,
Ashley",closed,True,2017-03-17 10:35:09,2017-04-16 07:36:51
dns,dkoshkin,https://github.com/kubernetes/dns/issues/72,https://api.github.com/repos/kubernetes/dns/issues/72,DNS flag kube-master-url is not respected,"Using `gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.1`
K8s: `v1.6.0-beta.4`

Looks like the value in the kubeconfig overrides the value provided in `kube-master-url` flag. The dns pod doesn't start up.

Settings the flags below when starting the DNS pod
```
- --kubecfg-file=/root/.kube/config
- --kube-master-url=https://34.205.140.27:6443
```

kube config content
```
apiVersion: v1
kind: Config
clusters:
- name: kubernetes
  cluster:
    certificate-authority: /etc/kubernetes/ca.pem
    server: ""https://127.0.0.1:6443""
users:
- name: admin
  user:
    username: admin
    password: ""abbazabba""
contexts:
- name: kubernetes
  context:
    cluster: kubernetes
    user: admin
current-context: kubernetes
```

```
[root@ip-10-0-3-130 specs]# docker logs e919ff944998
I0327 23:42:02.206667       1 dns.go:49] version: v1.5.2-beta.0+$Format:%h$
I0327 23:42:02.230408       1 server.go:74] ConfigMap and ConfigDir not configured, using values from command line flags
I0327 23:42:02.230455       1 server.go:112] FLAG: --alsologtostderr=""false""
I0327 23:42:02.230480       1 server.go:112] FLAG: --config-dir=""""
I0327 23:42:02.230485       1 server.go:112] FLAG: --config-map=""""
I0327 23:42:02.230488       1 server.go:112] FLAG: --config-map-namespace=""kube-system""
I0327 23:42:02.230492       1 server.go:112] FLAG: --config-period=""10s""
I0327 23:42:02.230497       1 server.go:112] FLAG: --dns-bind-address=""0.0.0.0""
I0327 23:42:02.230500       1 server.go:112] FLAG: --dns-port=""10053""
I0327 23:42:02.230506       1 server.go:112] FLAG: --domain=""cluster.local.""
I0327 23:42:02.230514       1 server.go:112] FLAG: --federations=""""
I0327 23:42:02.230519       1 server.go:112] FLAG: --healthz-port=""8081""
I0327 23:42:02.230522       1 server.go:112] FLAG: --initial-sync-timeout=""1m0s""
I0327 23:42:02.230525       1 server.go:112] FLAG: --kube-master-url=""https://34.205.140.27:6443""
I0327 23:42:02.230530       1 server.go:112] FLAG: --kubecfg-file=""/root/.kube/config""
I0327 23:42:02.230533       1 server.go:112] FLAG: --log-backtrace-at="":0""
I0327 23:42:02.230538       1 server.go:112] FLAG: --log-dir=""""
I0327 23:42:02.230543       1 server.go:112] FLAG: --log-flush-frequency=""5s""
I0327 23:42:02.230546       1 server.go:112] FLAG: --logtostderr=""true""
I0327 23:42:02.230550       1 server.go:112] FLAG: --nameservers=""""
I0327 23:42:02.230552       1 server.go:112] FLAG: --stderrthreshold=""2""
I0327 23:42:02.230556       1 server.go:112] FLAG: --v=""2""
I0327 23:42:02.230559       1 server.go:112] FLAG: --version=""false""
I0327 23:42:02.230564       1 server.go:112] FLAG: --vmodule=""""
I0327 23:42:02.230610       1 server.go:175] Starting SkyDNS server (0.0.0.0:10053)
I0327 23:42:02.230722       1 server.go:199] Skydns metrics not enabled
I0327 23:42:02.230732       1 dns.go:147] Starting endpointsController
I0327 23:42:02.230735       1 dns.go:150] Starting serviceController
I0327 23:42:02.231403       1 logs.go:41] skydns: ready for queries on cluster.local. for tcp://0.0.0.0:10053 [rcache 0]
I0327 23:42:02.231421       1 logs.go:41] skydns: ready for queries on cluster.local. for udp://0.0.0.0:10053 [rcache 0]
E0327 23:42:02.231652       1 reflector.go:199] k8s.io/dns/vendor/k8s.io/client-go/tools/cache/reflector.go:94: Failed to list *v1.Endpoints: Get https://127.0.0.1:6443/api/v1/endpoints?resourceVersion=0: dial tcp 127.0.0.1:6443: getsockopt: connection refused
E0327 23:42:02.231698       1 reflector.go:199] k8s.io/dns/vendor/k8s.io/client-go/tools/cache/reflector.go:94: Failed to list *v1.Service: Get https://127.0.0.1:6443/api/v1/services?resourceVersion=0: dial tcp 127.0.0.1:6443: getsockopt: connection refused
I0327 23:42:02.731122       1 dns.go:174] DNS server not ready, retry in 500 milliseconds
I0327 23:42:03.230954       1 dns.go:174] DNS server not ready, retry in 500 milliseconds
```
",closed,False,2017-03-27 23:57:45,2017-05-10 21:38:42
dns,djsly,https://github.com/kubernetes/dns/issues/73,https://api.github.com/repos/kubernetes/dns/issues/73,Current dnsmasq metrics seems off the hook. ,"I have started creating a dashboard for the new dnsmasq metrics and I would like to understand a bit more the different values I am getting. 

The misses and insertions are almost the same, while the hits seem very high. I have a 3 node cluster with only the kube-system namespace provisioned.


<img width=""1426"" alt=""screen shot 2017-03-28 at 12 50 44"" src=""https://cloud.githubusercontent.com/assets/4981802/24417135/31ff942e-13b5-11e7-8316-a218e46b856b.png"">



",closed,False,2017-03-28 16:52:12,2017-03-28 20:46:25
dns,r2d4,https://github.com/kubernetes/dns/pull/74,https://api.github.com/repos/kubernetes/dns/issues/74,Fix printf in cmd/kube-dns/app/server.go,"Fixes logging message
> 2017-04-07T22:56:44.901399945Z I0407 22:56:44.900224       1 server.go:70] Using configuration read from directory: /kube-dns-config%!(EXTRA time.Duration=10s)
",closed,True,2017-04-07 23:05:49,2017-04-07 23:57:16
dns,msavlani,https://github.com/kubernetes/dns/issues/75,https://api.github.com/repos/kubernetes/dns/issues/75,nslookup kubernetes.default is stuck whereas nslookup kubernetes works fine,"Hi,

I am facing weird issues Kubernetes 1.5.2

Its a single 2 nodes cluster which is setup using ""https://kubernetes.io/docs/getting-started-guides/centos/centos_manual_config/""

then i created skydns pods.

[root@masterhost ~]# kubectl get pods -n kube-system
NAME READY STATUS RESTARTS AGE
kube-dns-v20-jm7x7 3/3 Running 0 2h
kubernetes-dashboard-255567031-7dn4l 1/1 Running 44 11d

[root@mwhlvatd2d2 ~]# kubectl get services -n kube-system
NAME CLUSTER-IP EXTERNAL-IP PORT(S) AGE
kube-dns 10.254.0.10 53/UDP,53/TCP 2h
kubelet None 10250/TCP 8d
kubernetes-dashboard 10.254.25.228 80:31000/TCP 24d

I created one busybox pod and tried to do nslookup for kubernetes service as follows

It worked fine.
[root@masterhost ~]# kubectl exec -ti busybox1 -- nslookup kubernetes
Server: 10.254.0.10
Address 1: 10.254.0.10 kube-dns.kube-system.svc.cluster.local

Name: kubernetes
Address 1: 10.254.0.1 kubernetes.default.svc.cluster.local

Then i did nslookup for kubernetes.default
[root@masterhost ~]# kubectl exec -ti busybox1 -- nslookup kubernetes.default
Server: 10.254.0.10
Address 1: 10.254.0.10 kube-dns.kube-system.svc.cluster.local

---- Here it got stuck for some time and then returned following error ;

nslookup: can't resolve 'kubernetes.default'

Expected result

[root@masterhost ~]# kubectl exec -ti busybox1 -- nslookup kubernetes.default.svc.cluster.local
Server: 10.254.0.10
Address 1: 10.254.0.10 kube-dns.kube-system.svc.cluster.local

Name: kubernetes.default.svc.cluster.local
Address 1: 10.254.0.1 kubernetes.default.svc.cluster.local

Any help here is appreciated.",closed,False,2017-04-11 04:48:12,2017-05-16 21:20:13
dns,michaelajr,https://github.com/kubernetes/dns/issues/76,https://api.github.com/repos/kubernetes/dns/issues/76,dnsmasq --server flags causing upstream name server calls to hang and time out sporadically,"Hello. I had a problem recently where external name resolution, E.g., `www.google.com`, would not resolve. From the perspective of the client (`nslookup`) the call would just time out. From looking at the `dnsmasq` logs, it appears the calls were hanging. Every now and then… they would work… and cache.  Once the TTL expired… they would fail… and then sporadically work and cache again. 

I validated that calls directly to the upstream nameserver worked fine, E.g., `nslookup www.google.com <NAME_SERVER_IP>`. If fact, they never failed. I tested this from inside a pod, and on the host where the upstream name servers are configured in `~/etc/resolv.conf`. I then tried configuring the name servers using the new `ConfigMap`. Same result. 

Odd thing was, this only happened in the `1.6.x` release of K8s. Not the `1.5.4` release that we are currently using. 

I looked at the `dnsmasq` flags in the 1.6.x release and noticed there were three `--server` flags:

```
--server=/cluster.local/127.0.0.1#10053
--server=/in-addr.arpa/127.0.0.1#10053
--server=/in6.arpa/127.0.0.1#10053
```

As opposed to s single server flag in the 1.5.4 release, that just references the `kubedns` address.

```
--server=127.0.0.1#10053
```

I removed the three `--server` flags, and replaced them with the single `--server` flag which simply referenced the `kubedns` ... and suddenly everything worked!

I do not understand what those three server flags are doing differently from the single one (stubDoamins?) but they DID NOT WORK when trying to resolve names outside the cluster.

Again the workaround was to just remove them and replace them with one server flag referencing `kubedns`. 

My cluster was created using `kops 1.6.0-alpha2`. Tagging @justinsb 

Let me know if you need any other information. 

Thanks.
M

UPDATE:  Also, cluster name lookups ALWAYS worked. Regardless of number of dots. E.g., `kubernetes`, or `kubernetes.default`, or `kubernetes.detault.svc`, etc. No issues there.",closed,False,2017-04-13 13:09:32,2018-06-03 21:37:17
dns,wadee,https://github.com/kubernetes/dns/issues/77,https://api.github.com/repos/kubernetes/dns/issues/77,use flannel and add-on kube-dns， but kube-dns don't work,"####here is my procedure of setup kube cluster：
* system env: 
	* HypriotOS (Debian GNU/Linux 8)
	* use wifi iface wlan0
        * kube version:
![image](https://cloud.githubusercontent.com/assets/2749943/25163642/6bc6e414-24fe-11e7-98c3-8849b9f13cc2.png)

	
* 	On master
	* kubeadm init --pod-network-cidr 10.244.0.0/16 --apiserver-advertise-address 192.168.31.199
	* kubectl create -f kube-flannel-rbac.yml
	* kubectl create --namespace kube-system -f kube-flannel.yml
		* specially node use wifi for connected, so i modify the kube-flannel.yml configure params as below：
```
image: quay.io/coreos/flannel:v0.7.0-arm
command: [ ""/opt/bin/flanneld"", ""--ip-masq"", ""--kube-subnet-mgr"", ""--iface=wlan0""]
```

* On slaves
	* kubeadm join --token 8bbadd.3a118002a3e82964 192.168.31.199:6443

* On each node (include master)
	* use the flannel subnet.env /run/flannel/subnet.env config to restart dockerd, a example as below :
```
FLANNEL_NETWORK=10.244.0.0/16
FLANNEL_SUBNET=10.244.2.1/24
FLANNEL_MTU=1450
FLANNEL_IPMASQ=true
```
	*  so dockerd is run as : /usr/bin/dockerd --bip=10.244.2.1/24 --ip-masq=false --mtu=1450 --storage-driver overlay -H fd://		

#### question
![image](https://cloud.githubusercontent.com/assets/2749943/25163307/cf5aaa72-24fb-11e7-9e10-fcf864e7c03c.png)

upon the  above screenshots, you will notice that the kube-dns at the colunm 'ready' is always 2/3,

and kube-dns pod include 3 container： kubedns , dnsmaqs ,carside

there is logs about the kubedns container:
 
![image](https://cloud.githubusercontent.com/assets/2749943/25163390/87d0a0ca-24fc-11e7-8f48-07720e571ced.png)

so, the kube-dns pod just keep restart over and over again。

I have been struggling wiht this problem for a couple day........

is that any mistake I have make lead to this problem?
can anyone have the same issue?




",closed,False,2017-04-19 04:49:35,2017-05-19 09:22:51
dns,MrHohn,https://github.com/kubernetes/dns/pull/78,https://api.github.com/repos/kubernetes/dns/issues/78,Fix confusing logging when initialize server,"The logging we have when initializing services and endpoints is confusing:
```
DNS server not ready, retry in 500 milliseconds
```

Modify the message a bit to clarify what it is doing.",closed,True,2017-04-19 20:15:16,2017-10-05 00:56:45
dns,MrHohn,https://github.com/kubernetes/dns/pull/79,https://api.github.com/repos/kubernetes/dns/issues/79,Fix race condition in reverseRecordMap access,"Fix kubernetes/kubernetes#44711.

We don't have a explicit lock for `reverseRecordMap`, all the R/Ws are protected through `cacheLock`, so I followed the same pattern.

@bowei 
cc @etiennetremel",closed,True,2017-04-20 17:18:47,2017-10-05 00:56:46
dns,guirish03,https://github.com/kubernetes/dns/issues/80,https://api.github.com/repos/kubernetes/dns/issues/80,Extending CI support to s390x,"I need to setup Kube-DNS CI setup for s390x. I am looking for some guidelines so that I can setup Kube-DNS CI setup for s390x. 
What are the prerequisites and hardware configuration needed to do this job.
",closed,False,2017-04-24 08:40:21,2018-03-01 09:01:51
dns,chrislovecnm,https://github.com/kubernetes/dns/issues/81,https://api.github.com/repos/kubernetes/dns/issues/81,stubDomains problem - upstream server is tcp only thanks to aws elb,"My configMap, for configuring kube-dns, is loading, with a stubDomain.  Because I am working in EC2 I have to use an ELB that does not support UDP, but only support tcp.

## Layout

- k8s 1.6.1 Two clusters
- one in us-east-1, and one in us-west-2
- separate dnsmasq server is exposing internal kube-dns on and ELB
- each cluster has a ""dig"" container pod setup for testing
- clusters are setup with different domains based on the region

## Logs

```
I0504 00:03:32.944847       1 sync.go:167] Updated stubDomains to map[us-east-1-cluster.local:[52.20.35.216]]
I0504 00:03:32.945039       1 nanny.go:186] Restarting dnsmasq with new configuration
I0504 00:03:32.945063       1 nanny.go:135] Killing dnsmasq
I0504 00:03:32.945092       1 nanny.go:86] Starting dnsmasq [-k --cache-size=1000 --log-facility=- --server=/us-west-2-cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/in6.arpa/127.0.0.1#10053 --server /us-east-1-cluster.local/52.20.35.216]
I0504 00:03:32.945491       1 nanny.go:111]
W0504 00:03:32.945534       1 nanny.go:112] Got EOF from stderr
I0504 00:03:33.082404       1 nanny.go:111]
W0504 00:03:33.082500       1 nanny.go:112] Got EOF from stdout
I0504 00:03:33.082561       1 nanny.go:108] dnsmasq[11]: started, version 2.76 cachesize 1000
I0504 00:03:33.082626       1 nanny.go:108] dnsmasq[11]: compile time options: IPv6 GNU-getopt no-DBus no-i18n no-IDN DHCP DHCPv6 no-Lua TFTP no-conntrack ipset auth no-DNSSEC loop-detect inotify
I0504 00:03:33.082662       1 nanny.go:108] dnsmasq[11]: using nameserver 52.20.35.216#53 for domain us-east-1-cluster.local
I0504 00:03:33.082699       1 nanny.go:108] dnsmasq[11]: using nameserver 127.0.0.1#10053 for domain in6.arpa
I0504 00:03:33.082725       1 nanny.go:108] dnsmasq[11]: using nameserver 127.0.0.1#10053 for domain in-addr.arpa
I0504 00:03:33.082749       1 nanny.go:108] dnsmasq[11]: using nameserver 127.0.0.1#10053 for domain us-west-2-cluster.local
I0504 00:03:33.082822       1 nanny.go:108] dnsmasq[11]: reading /etc/resolv.conf
I0504 00:03:33.082851       1 nanny.go:108] dnsmasq[11]: using nameserver 52.20.35.216#53 for domain us-east-1-cluster.local
I0504 00:03:33.082885       1 nanny.go:108] dnsmasq[11]: using nameserver 127.0.0.1#10053 for domain in6.arpa
I0504 00:03:33.082910       1 nanny.go:108] dnsmasq[11]: using nameserver 127.0.0.1#10053 for domain in-addr.arpa
I0504 00:03:33.082958       1 nanny.go:108] dnsmasq[11]: using nameserver 127.0.0.1#10053 for domain us-west-2-cluster.local
I0504 00:03:33.082985       1 nanny.go:108] dnsmasq[11]: using nameserver 172.60.0.205#53
I0504 00:03:33.083012       1 nanny.go:108] dnsmasq[11]: using nameserver 172.60.0.2#53
I0504 00:03:33.083073       1 nanny.go:108] dnsmasq[11]: read /etc/hosts - 7 addresses
```

## Diagnostics

1. login to the dig pod in west
1. dig us-east-1-cluster.local - fails
1. dig +tcp @52.20.35.216 elb - success (52.20.35.216 is an elb / LoadBalancer service in east fronting dnsmasq)

Ideas?",open,False,2017-05-04 00:55:58,2018-01-03 07:08:45
dns,bdimcheff,https://github.com/kubernetes/dns/issues/82,https://api.github.com/repos/kubernetes/dns/issues/82,kube-dns doesn't support using service name in stubDomains as docs and code seem to suggest,"According to the [announcement](http://blog.kubernetes.io/2017/04/configuring-private-dns-zones-upstream-nameservers-kubernetes.html) blog post, I should be able to use a service as an upstream for stubDomains (note the note):

```
stubDomains (optional)

    Format: a JSON map using a DNS suffix key (e.g.; “acme.local”) and a value consisting of a JSON array of DNS IPs.
    Note: The target nameserver may itself be a Kubernetes service. For instance, you can run your own copy of dnsmasq to export custom DNS names into the ClusterDNS namespace.
```

However if I try to point at our unbound service, the dnsmasq container crashes:

```
I0505 21:26:49.795586       1 main.go:76] opts: {{/usr/sbin/dnsmasq [-k --cache-size=1000 --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/ip6.arpa/127.0.0.1#10053] true} /etc/k8s/dns/dnsmasq-nanny 10000000000}
I0505 21:26:49.795988       1 sync.go:167] Updated stubDomains to map[example.com:[unbound]]
I0505 21:26:49.796066       1 nanny.go:86] Starting dnsmasq [-k --cache-size=1000 --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/ip6.arpa/127.0.0.1#10053 --server /example.com/unbound]
I0505 21:26:49.797178       1 nanny.go:111]
W0505 21:26:49.797301       1 nanny.go:112] Got EOF from stdout
F0505 21:26:49.797341       1 nanny.go:182] dnsmasq exited: exit status 1
I0505 21:26:49.797283       1 nanny.go:115]
E0505 21:26:49.797501       1 nanny.go:116] Error reading from stderr: read |0: bad file descriptor
```

[This test](https://github.com/kubernetes/dns/blob/1.14.1/pkg/dns/config/config_test.go#L32) also seems to indicate that names are allowed in stubDomains, but from what I can tell, dnsmasq doesn't allow a name in a `--server` parameter (in the above example, it's sending `--server /example.com/unbound`)

We can currently use the clusterIP of a service as upstream DNS, but that seems pretty error prone.  Is there something else we should be doing here, or am I misinterpreting the documentation?",closed,False,2017-05-05 21:52:39,2019-01-05 06:38:11
dns,dpgeekzero,https://github.com/kubernetes/dns/issues/83,https://api.github.com/repos/kubernetes/dns/issues/83,Unable to use port numbers for stubDomain servers,"When trying to setup a stubDomain to resolve to my consul cluster, I'm getting ""invalid nameserver"" messages

configMap data:
```
data:
  stubDomains: {""service.consul"": [""100.71.68.61:8600""]}
```

The `IsDNS1123Subdomain` check on line  104 in config/config.go looks unnecessary to me.",closed,False,2017-05-06 06:11:14,2017-09-06 20:22:06
dns,alexbrand,https://github.com/kubernetes/dns/pull/84,https://api.github.com/repos/kubernetes/dns/issues/84,Support kube-master-url flag without kubeconfig,"When the `client-go` package was introduced, the `kube-master-url` flag was rendered unusable. With this PR, the user can now specify the master URL without having to provide a kubeconfig file.

Fixes #72 ",closed,True,2017-05-09 17:25:42,2017-05-10 21:38:42
dns,jkinkead,https://github.com/kubernetes/dns/issues/85,https://api.github.com/repos/kubernetes/dns/issues/85,DNS failures for internal AWS URLs,"I'm seeing intermittent DNS failures, but only for the URLs that AWS assigns my machines (e.g. ` ip-10-16-25-61.us-west-2.compute.internal`).

External URLs (e.g. `google.com`) resolve fine, as do URLs for services (e.g. `kubernetes.default`).

Setup:
Two-replica DNS behind a service IP, configured with `kops`. Each pod is running using [this template](https://github.com/kubernetes/kops/blob/6201e924c7559148cdd10e54a11c6479a9e95a60/upup/models/cloudup/resources/addons/kube-dns.addons.k8s.io/k8s-1.6.yaml.template#L55-L210), which contains `kubedns`, `dnsmasq`, and `dns-sidecar`. All are using version `1.14.1` of the kube-dns images.

The cluster is running Kubernetes version 1.6.0.

Problem description:

The system seems to end up in one of three states:

1. Lookups succeed 100% of the time.

2. The lookup resolves, returning the correct TTL (20). Typically, the first lookup after `kubedns` logs new entries will succeed (each time `kubedns` runs a work cycle, every 5 minutes). Lookups will continue to succeed until the TTL of the entry expires, and will start to fail after that.

3. Lookups fail 100% of the time.

When I've restarted the DNS services, they seem to progress from state 1, through state 2, into state 3, occasionally jumping back to state 1 or 2.

The logs for the containers aren't displaying any errors or other interesting information.",closed,False,2017-05-09 23:49:39,2018-12-07 03:10:53
dns,jkinkead,https://github.com/kubernetes/dns/issues/86,https://api.github.com/repos/kubernetes/dns/issues/86,dnsmasq container fails to build on OS X (incompatible with BSD sed),"The Makefile for the dnsmasq container contains invocations in the style of:

```bash
sed -i ""s/pattern/replacement/"" Dockerfile
```
This is incompatible with BSD `sed`, whose `-i` flag takes a required argument. It generates the following:
```
sed: 1: ""Dockerfile"": extra characters at the end of D command
```
Note that it's trying to parse the string `Dockerfile` as a `sed` command.

I'll have a patch shortly.",closed,False,2017-05-10 18:49:50,2017-05-10 22:13:13
dns,jkinkead,https://github.com/kubernetes/dns/pull/87,https://api.github.com/repos/kubernetes/dns/issues/87,Use BSD-compatible sed command in dnsmasq Makefile.,"Fixes #86 .

This invocation should work in both BSD & Linux `sed`. Note that I remove the backup file being created.",closed,True,2017-05-10 18:50:57,2017-05-10 22:13:13
dns,SleepyBrett,https://github.com/kubernetes/dns/issues/88,https://api.github.com/repos/kubernetes/dns/issues/88,"kubedns panic ""fatal error: concurrent map writes""","See linked issue for stacktraces:
https://github.com/kubernetes/kubernetes/issues/45593

For my case my cluster is very quiet, it's just a test cluster with no other users, my kubedns is a bit overscaled atm, however over two days I'm seeing several crashing (I've maybe applied half a dozen services a few times)

```
kube-dns-1251125892-0172d                                       3/3       Running   4          2d
kube-dns-1251125892-bmbm7                                       3/3       Running   1          2d
kube-dns-1251125892-ns3qg                                       3/3       Running   4          2d
kube-dns-1251125892-xrm3p                                       3/3       Running   7          2d
```",closed,False,2017-05-10 21:23:06,2017-05-16 21:17:19
dns,johnbelamaric,https://github.com/kubernetes/dns/pull/89,https://api.github.com/repos/kubernetes/dns/issues/89,Add missing ExternalName service,,closed,True,2017-05-11 20:32:20,2017-09-26 07:10:55
dns,cmluciano,https://github.com/kubernetes/dns/pull/90,https://api.github.com/repos/kubernetes/dns/issues/90,Update Godeps to client-go 3,"These commits now track the release-3 branch of
client-go. The code changes are mostly related to
swapping client-go functions with apimachinery.

Closes #35",closed,True,2017-05-15 18:13:49,2017-07-07 18:00:00
dns,alok87,https://github.com/kubernetes/dns/issues/91,https://api.github.com/repos/kubernetes/dns/issues/91,Are these peaks normal ?,"We are seeing in newrelic high response time for kube-dns under transactions. Its around 4-5 seconds for lookup.

Please see below graph
How to debug and fix these kube dns issues. We are running around 8-10 pods of kube-dns with replication controller.

@bowei  Added details below - 
We are running kubernetes 1.4.5 in aws cloud. Kubernetes was installed using `kube-up.sh` in our production. That time we did not have expertise on using kops private cluster. It uses aws routing as networking. Issue happens only when the rpm is high and when we switch traffic to our newly deployed pods(its a blue green deployment)

<img width=""1255"" alt=""screen shot 2017-05-20 at 10 10 37 am"" src=""https://cloud.githubusercontent.com/assets/9006763/26273162/bb9c7524-3d47-11e7-909f-8172723122ef.png"">
<img width=""1258"" alt=""screen shot 2017-05-20 at 10 11 01 am"" src=""https://cloud.githubusercontent.com/assets/9006763/26273164/bbb28daa-3d47-11e7-9dbb-1964f0cb7a9e.png"">
<img width=""1236"" alt=""screen shot 2017-05-20 at 10 11 14 am"" src=""https://cloud.githubusercontent.com/assets/9006763/26273163/bba692ac-3d47-11e7-832f-82b5b96f70b2.png"">
",closed,False,2017-05-20 05:03:36,2017-05-24 18:41:22
dns,alok87,https://github.com/kubernetes/dns/issues/92,https://api.github.com/repos/kubernetes/dns/issues/92,[Question] Documentation on contributing to dns,Is there any document telling how to setup kube dns locally for contribution and debugging ?,closed,False,2017-05-20 07:01:53,2017-05-26 10:07:44
dns,mintzhao,https://github.com/kubernetes/dns/issues/93,https://api.github.com/repos/kubernetes/dns/issues/93,fatal error: concurrent map writes,"## version
1.14.1

## fatal output
```
fatal error: concurrent map writes

goroutine 69 [running]:
runtime.throw(0x162294a, 0x15)
	/usr/local/go/src/runtime/panic.go:566 +0x95 fp=0xc4206335c8 sp=0xc4206335a8
runtime.mapassign1(0x1465c20, 0xc4202ada10, 0xc420633820, 0xc4206337d8)
	/usr/local/go/src/runtime/hashmap.go:458 +0x8ef fp=0xc4206336b0 sp=0xc4206335c8
k8s.io/dns/pkg/dns.(*KubeDNS).generateRecordsForHeadlessService(0xc42018c100, 0xc420675798, 0xc420044cb0, 0x0, 0x0)
	/go/src/k8s.io/dns/pkg/dns/dns.go:504 +0x860 fp=0xc420633850 sp=0xc4206336b0
k8s.io/dns/pkg/dns.(*KubeDNS).addDNSUsingEndpoints(0xc42018c100, 0xc420675798, 0xc420122a50, 0xc420122a48)
	/go/src/k8s.io/dns/pkg/dns/dns.go:420 +0xc2 fp=0xc420633890 sp=0xc420633850
k8s.io/dns/pkg/dns.(*KubeDNS).handleEndpointAdd(0xc42018c100, 0x15e9060, 0xc420675798)
	/go/src/k8s.io/dns/pkg/dns/dns.go:319 +0x52 fp=0xc4206338c0 sp=0xc420633890
k8s.io/dns/pkg/dns.(*KubeDNS).handleEndpointUpdate(0xc42018c100, 0x15e9060, 0xc420675798, 0x15e9060, 0xc420675798)
	/go/src/k8s.io/dns/pkg/dns/dns.go:382 +0x4f8 fp=0xc420633b28 sp=0xc4206338c0
k8s.io/dns/pkg/dns.(*KubeDNS).(k8s.io/dns/pkg/dns.handleEndpointUpdate)-fm(0x15e9060, 0xc420675798, 0x15e9060, 0xc420675798)
	/go/src/k8s.io/dns/pkg/dns/dns.go:246 +0x52 fp=0xc420633b60 sp=0xc420633b28
k8s.io/dns/vendor/k8s.io/client-go/tools/cache.ResourceEventHandlerFuncs.OnUpdate(0xc4204ad310, 0xc4204ad320, 0xc4204ad330, 0x15e9060, 0xc420675798, 0x15e9060, 0xc420675798)
	/go/src/k8s.io/dns/vendor/k8s.io/client-go/tools/cache/controller.go:180 +0x5d fp=0xc420633b90 sp=0xc420633b60
k8s.io/dns/vendor/k8s.io/client-go/tools/cache.(*ResourceEventHandlerFuncs).OnUpdate(0xc4203db280, 0x15e9060, 0xc420675798, 0x15e9060, 0xc420675798)
	<autogenerated>:51 +0x8c fp=0xc420633bd8 sp=0xc420633b90
k8s.io/dns/vendor/k8s.io/client-go/tools/cache.NewInformer.func1(0x148db60, 0xc4201a92a0, 0xc4201a92a0, 0x148db60)
	/go/src/k8s.io/dns/vendor/k8s.io/client-go/tools/cache/controller.go:246 +0x335 fp=0xc420633ca8 sp=0xc420633bd8
k8s.io/dns/vendor/k8s.io/client-go/tools/cache.(*DeltaFIFO).Pop(0xc420132370, 0xc4202adb60, 0x0, 0x0, 0x0, 0x0)
	/go/src/k8s.io/dns/vendor/k8s.io/client-go/tools/cache/delta_fifo.go:420 +0x22a fp=0xc420633d80 sp=0xc420633ca8
k8s.io/dns/vendor/k8s.io/client-go/tools/cache.(*Controller).processLoop(0xc420462150)
	/go/src/k8s.io/dns/vendor/k8s.io/client-go/tools/cache/controller.go:131 +0x3c fp=0xc420633dc0 sp=0xc420633d80
k8s.io/dns/vendor/k8s.io/client-go/tools/cache.(*Controller).(k8s.io/dns/vendor/k8s.io/client-go/tools/cache.processLoop)-fm()
	/go/src/k8s.io/dns/vendor/k8s.io/client-go/tools/cache/controller.go:102 +0x2a fp=0xc420633dd8 sp=0xc420633dc0
k8s.io/dns/vendor/k8s.io/client-go/pkg/util/wait.JitterUntil.func1(0xc420633f70)
	/go/src/k8s.io/dns/vendor/k8s.io/client-go/pkg/util/wait/wait.go:96 +0x5e fp=0xc420633e10 sp=0xc420633dd8
k8s.io/dns/vendor/k8s.io/client-go/pkg/util/wait.JitterUntil(0xc420633f70, 0x3b9aca00, 0x0, 0x13e8501, 0xc4203f02a0)
	/go/src/k8s.io/dns/vendor/k8s.io/client-go/pkg/util/wait/wait.go:97 +0xad fp=0xc420633ed8 sp=0xc420633e10
k8s.io/dns/vendor/k8s.io/client-go/pkg/util/wait.Until(0xc420633f70, 0x3b9aca00, 0xc4203f02a0)
	/go/src/k8s.io/dns/vendor/k8s.io/client-go/pkg/util/wait/wait.go:52 +0x4d fp=0xc420633f10 sp=0xc420633ed8
k8s.io/dns/vendor/k8s.io/client-go/tools/cache.(*Controller).Run(0xc420462150, 0xc4203f02a0)
	/go/src/k8s.io/dns/vendor/k8s.io/client-go/tools/cache/controller.go:102 +0x1af fp=0xc420633f90 sp=0xc420633f10
runtime.goexit()
	/usr/local/go/src/runtime/asm_amd64.s:2086 +0x1 fp=0xc420633f98 sp=0xc420633f90
created by k8s.io/dns/pkg/dns.(*KubeDNS).Start
	/go/src/k8s.io/dns/pkg/dns/dns.go:148 +0x9f
```

## cause
```
func (kd *KubeDNS) generateRecordsForHeadlessService(e *v1.Endpoints, svc *v1.Service) error {
	subCache := treecache.NewTreeCache()
	glog.V(4).Infof(""Endpoints Annotations: %v"", e.Annotations)
	for idx := range e.Subsets {
		for subIdx := range e.Subsets[idx].Addresses {
			address := &e.Subsets[idx].Addresses[subIdx]
			endpointIP := address.IP
			recordValue, endpointName := util.GetSkyMsg(endpointIP, 0)
			if hostLabel, exists := getHostname(address); exists {
				endpointName = hostLabel
			}
			subCache.SetEntry(endpointName, recordValue, kd.fqdn(svc, endpointName))
			for portIdx := range e.Subsets[idx].Ports {
				endpointPort := &e.Subsets[idx].Ports[portIdx]
				if endpointPort.Name != """" && endpointPort.Protocol != """" {
					srvValue := kd.generateSRVRecordValue(svc, int(endpointPort.Port), endpointName)
					glog.V(2).Infof(""Added SRV record %+v"", srvValue)

					l := []string{""_"" + strings.ToLower(string(endpointPort.Protocol)), ""_"" + endpointPort.Name}
					subCache.SetEntry(endpointName, srvValue, kd.fqdn(svc, append(l, endpointName)...), l...)
				}
			}

			// Generate PTR records only for Named Headless service.
			if _, has := getHostname(address); has {
				reverseRecord, _ := util.GetSkyMsg(kd.fqdn(svc, endpointName), 0)
				kd.reverseRecordMap[endpointIP] = reverseRecord // concurrent map writes
			}
		}
	}
	subCachePath := append(kd.domainPath, serviceSubdomain, svc.Namespace)
	kd.cacheLock.Lock()
	defer kd.cacheLock.Unlock()
	kd.cache.SetSubCache(svc.Name, subCache, subCachePath...)
	return nil
}

```",closed,False,2017-05-22 08:26:50,2017-05-22 16:02:27
dns,zihaoyu,https://github.com/kubernetes/dns/issues/94,https://api.github.com/repos/kubernetes/dns/issues/94,Publish metrics of cached entries,"It would be helpful if we can get dnsmasq cached entries number from its metrics endpoint. 

If this metric is already published, I apologize and please let me know the name of it. 

Thank you. ",closed,False,2017-05-23 21:27:27,2017-05-24 00:10:44
dns,SleepyBrett,https://github.com/kubernetes/dns/pull/95,https://api.github.com/repos/kubernetes/dns/issues/95,better latency buckets 0.5ms to 9.78s,The current state of latency buckets is a linear progression from 10ms to 5s. I think the bottom end of the latencies are more important especially when probing dnsmasq. This pull request uses exponential buckets starting at 0.5ms and proceeding (with a factor of 1.02) to about 10s.,closed,True,2017-05-24 15:33:27,2018-02-24 17:11:51
dns,alok87,https://github.com/kubernetes/dns/issues/96,https://api.github.com/repos/kubernetes/dns/issues/96,Kube DNS Latency,"We have dns pods running in our cluster (cluster details below)
Issue is every 2-3 requests out of 5 is having a latency of 5 seconds because of the dns.

```
root@my-nginx-858393261-m3bnl:/# time curl http://myservice.central:8080/status
{
  ""host"": ""myservice-3af719a-805113283-x35p1"",
  ""status"": ""OK""
}

real	0m5.523s
user	0m0.004s
sys	0m0.000s
root@my-nginx-858393261-m3bnl:/# time curl http://myservice.central:8080/status
{
  ""host"": ""myservice-3af719a-805113283-x35p1"",
  ""status"": ""OK""
}

real	0m0.013s
user	0m0.000s
sys	0m0.004s
```

**Cluster details**: We are running Kubernetes latest version 1.6.4 installed using `kops`.  Its mutli AZ cluster in aws. 

Below are the kube dns details
- kubedns: gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.1
- dnsmaq: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.1
- sidecar: gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.1

Our Kube dns is running with below requests 
```
cpu	:	200m	
memory	:	70Mi
```

Please let us know the issue and how to fix this",closed,False,2017-05-25 05:20:59,2018-05-25 21:44:13
dns,mindw,https://github.com/kubernetes/dns/issues/97,https://api.github.com/repos/kubernetes/dns/issues/97,Wrong version reported for 1.14.2 (1.14.1-16-gff416ee),"All containers (dnsmask, kubedns & sidecar) report the wrong version.

```
gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.2
gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.2
gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.2

$ kubectl logs kube-dns-1578267200-z2ptk -c sidecar
ERROR: logging before flag.Parse: I0525 13:43:00.569730       1 main.go:48] Version v1.14.1-16-gff416ee
```
",closed,False,2017-05-25 14:06:57,2017-12-25 05:04:17
dns,mindw,https://github.com/kubernetes/dns/issues/98,https://api.github.com/repos/kubernetes/dns/issues/98,Noisy Logs in sidecar 1.14.2 logs,"seems to be missing the fix applied in dns.go
```$ kubectl logs kube-dns-1578267200-z2ptk -c sidecar
ERROR: logging before flag.Parse: I0525 13:43:00.569730       1 main.go:48] Version v1.14.1-16-gff416ee
ERROR: logging before flag.Parse: I0525 13:43:00.570013       1 server.go:45] Starting server (options {DnsMasqPort:53 DnsMasqAddr:127.0.0.1 DnsMasqPollIntervalMs:5000 Probes:[{Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:1} {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:1}] PrometheusAddr:0.0.0.0 PrometheusPort:10054 PrometheusPath:/metrics PrometheusNamespace:kubedns})
ERROR: logging before flag.Parse: I0525 13:43:00.570090       1 dnsprobe.go:75] Starting dnsProbe {Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:1}
ERROR: logging before flag.Parse: I0525 13:43:00.570258       1 dnsprobe.go:75] Starting dnsProbe {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:1}
```",closed,False,2017-05-25 14:10:58,2017-09-25 14:38:18
dns,alok87,https://github.com/kubernetes/dns/issues/99,https://api.github.com/repos/kubernetes/dns/issues/99,How to contribute to dns ?,Documentation on how to contribute to kube-dns.,closed,False,2017-05-26 10:06:17,2017-12-25 07:29:30
dns,alok87,https://github.com/kubernetes/dns/issues/100,https://api.github.com/repos/kubernetes/dns/issues/100,How to debug dns issues ?,Documentation on how to go about debugging issues in kube-dns,closed,False,2017-05-26 10:07:17,2017-12-26 05:19:06
dns,sadlil,https://github.com/kubernetes/dns/pull/101,https://api.github.com/repos/kubernetes/dns/issues/101,Fix PTR Record generation,Ref : https://github.com/kubernetes/dns/pull/25#issuecomment-304734753,closed,True,2017-05-30 08:24:58,2018-03-11 04:52:32
dns,fgimenez,https://github.com/kubernetes/dns/issues/102,https://api.github.com/repos/kubernetes/dns/issues/102,dns diagnosis tool proposal: test,"Hello everyone, this is a first proposal for implementing the idea suggested in kubernetes/kubernetes#45934, describing the tests to be implemented by the tool. I probably will miss things to check, any ideas are more than welcome! :)  I'm a newbie on the internals of kubernetes' DNS, but very keen to learn, please do not hesitate to correct me if I propose silly things :)

**Tests to be run**

* **Related to endpoints**
  * Number of endpoints
  *  Replicas behind each endpoint
  * Restarts of each replica

* **Related to lookups**
  * In-cluster
    * For each service (without port associated) and endpoint query for A record and measure latency and dropped packages
    * For each service (with port associated) and endpoint query for SRV record and measure latency and dropped packages
    * For each service and endpoint do a reverse IP adress lookup and measure latency and dropped packages

  * Out-of-cluster
    * For each domain name in a predetermined external set and endpoint measure latency and dropped packages

Questions:

* In order to make sure that SRV records are checked, should specific services with named ports be created and removed after the test is done? In general, if any of the items to be checked is not present, should the tool setup the check conditions and teardown them after the checks finish?
* Should pod's A records be checked?

So, what do you thing? Should any of these be done differently, or totally removed? Are there any relevant checks missing? 

Cheers,",closed,False,2017-05-31 11:28:52,2018-06-03 21:37:16
dns,DavadDi,https://github.com/kubernetes/dns/pull/103,https://api.github.com/repos/kubernetes/dns/issues/103,fix assertIsService return result,"
```go
func assertIsService(obj interface{}) (*v1.Service, bool) {
	if service, ok := obj.(*v1.Service); ok {
		return service, ok
	} else {
		glog.Errorf(""Type assertion failed! Expected 'Service', got %T"", service)
		return nil, ok   // should return false
	}
}
```
calling function:

```go
func (kd *KubeDNS) newService(obj interface{}) {
	if service, ok := assertIsService(obj); ok { // if obj is not service object，service is nil, 
        // ....
	
        // if service is nil, but ok is true, service.Spec.Type will panic
        if service.Spec.Type == v1.ServiceTypeExternalName {
		kd.newExternalNameService(service)
		return
	}

       // ....
}
```",closed,True,2017-06-01 01:37:31,2017-06-01 01:51:55
dns,DavadDi,https://github.com/kubernetes/dns/pull/104,https://api.github.com/repos/kubernetes/dns/issues/104,fix assertIsService result,"```go
func assertIsService(obj interface{}) (*v1.Service, bool) {
	if service, ok := obj.(*v1.Service); ok {
		return service, ok
	} else {
		glog.Errorf(""Type assertion failed! Expected 'Service', got %T"", service)
		return nil, ok   // should return false
	}
}
```
calling function:

```go
func (kd *KubeDNS) newService(obj interface{}) {
	if service, ok := assertIsService(obj); ok { // if obj is not service object，service is nil, 
        // ....
	
        // if service is nil, but ok is true, service.Spec.Type will panic
        if service.Spec.Type == v1.ServiceTypeExternalName {
		kd.newExternalNameService(service)
		return
	}

       // ....
}
```",closed,True,2017-06-01 02:00:13,2017-06-02 01:39:50
dns,cmluciano,https://github.com/kubernetes/dns/pull/105,https://api.github.com/repos/kubernetes/dns/issues/105,Bump to Go version 1.8,Signed-off-by: Christopher M. Luciano <cmluciano@us.ibm.com>,closed,True,2017-06-12 15:41:34,2017-06-16 20:03:53
dns,cmluciano,https://github.com/kubernetes/dns/pull/106,https://api.github.com/repos/kubernetes/dns/issues/106,Update dep script to support darwin,Signed-off-by: Christopher M. Luciano <cmluciano@us.ibm.com>,closed,True,2017-06-12 17:02:20,2017-06-16 13:13:40
dns,ixdy,https://github.com/kubernetes/dns/pull/107,https://api.github.com/repos/kubernetes/dns/issues/107,Always --pull during docker build,"Without --pull, it's possible to use old base images which may have fixed vulnerabilities upstream.

x-ref kubernetes/kubernetes#47386

After merging this, we should probably re-tag and rebuild the dns images with updated base images.

@bowei ",closed,True,2017-06-13 02:00:48,2017-06-13 22:04:23
dns,ixdy,https://github.com/kubernetes/dns/pull/108,https://api.github.com/repos/kubernetes/dns/issues/108,Update dnsmasq image to use go1.7.6 and alpine:3.6,"Updated golang dependency includes the fix for https://github.com/golang/go/issues/20040.
Updated alpine dependency includes fixes for CVE-2016-9841 and CVE-2016-9843.

Note that we should probably build a new dnsmasq image before building the rest, since dnsmasq-nanny depends on it.

@MrHohn @bowei 

x-ref https://github.com/kubernetes/kubernetes/issues/47386",closed,True,2017-06-13 21:13:31,2017-06-14 19:41:21
dns,jwfang,https://github.com/kubernetes/dns/issues/109,https://api.github.com/repos/kubernetes/dns/issues/109,short-form dns query *nslookup kubernetes.default* not working,"in case someone encounter the same problem, i write my finding here.

kube-dns behaviour:
1. kube-dns POD's /etc/resolv.conf is usually the same as the host;
2. kubedns will forward *unknown domain* to name server in its resolv.conf;
    NOTE: *short-form* query such as *kubernetes.default* is *unknown* to kubedns 
3. kubedns seem to be use only the first nameserver.
EDIT: from https://github.com/skynetservices/skydns/blob/f694f5637b31e2b9c9871fb396773d5d18b9309e/server/exchange.go#L29, it's not doing *NSRotate*. when no *NSRotate*, it always use the first name server first, and it only retry on connection error, for application error it just directly forward upstream error code.

so the short-form query works like this:
1. client send short-form query to kube-dns;
2. kube-dns know nothing about it, forward to external nameserver in resolv.conf;
3. external name server return ERROR to kube-dns;
4. kube-dns forward failure to client;
5. client append *search domain* in its resolv.conf and goto 1 to retry.

client behaviour:
for 5, different client seem to have differnt behaviour regards to differnt error from 3.
for *busybox*, it seem to be only append *search* for NXDOMAIN, and not append *search* for REFUSED;
and for *alpine* and *tutum/dnsutils*, it will append *search* for both NXDOMAIN and REFUSED.

my installation it's a bit unusually, although they have idential /etc/resolv.conf, the first name server behaviour *differently* on different node: some are not recusive and will return REFUSED, and the other
will return NXDOMAIN.

so i got this weird behaviour:
when kube-dns is on NXDOMAIN node,  *busybox* nslookup testing works;
when kube-dns is on REFUSED node,  *busybox* nslookup testing fails.
and *alpine*/*tutum/dnsutils* always works regards which node kube-dns is on.

so, **when deploy kube-dns, you should ensure the first nameserver in your host /etc/resolv.conf works as expected.**













=============== BELOW are original question ===============================
i enabled RBAC for my on-premise k8s cluster, but found cross-name space DNS query different from non-RBAC. 
i didn't find any document for this behaviour, so this issue.

for *no-RBAC*:
1. i can do cross-namespace DNS query for service in ns1 from ns2 using ```svc1.ns1```;
2. i can query service in the *same* namespace using ```svc1.ns1``` with namespace.

but in *RBAC*, i have to use the FQDN:
1. can't do cross-namespace query using ```svc1.ns1``` from ns2;
2. can't query service in the *same* namespace using ```svc1.ns1``` with namespace;

from a busybox in *default* namespace, i got the following output:
```
/ # nslookup nginx-deployment
Server:    10.233.0.3
Address 1: 10.233.0.3 kubedns.kube-system.svc.cluster.local

Name:      nginx-deployment
Address 1: 10.233.33.138 nginx-deployment.default.svc.cluster.local
/ # nslookup nginx-deployment.default
Server:    10.233.0.3
Address 1: 10.233.0.3 kubedns.kube-system.svc.cluster.local

nslookup: can't resolve 'nginx-deployment.default'
/ # nslookup nginx-deployment.kube-system
Server:    10.233.0.3
Address 1: 10.233.0.3 kubedns.kube-system.svc.cluster.local

nslookup: can't resolve 'nginx-deployment.kube-system'
/ # nslookup nginx-deployment.kube-system.svc.cluster.local
Server:    10.233.0.3
Address 1: 10.233.0.3 kubedns.kube-system.svc.cluster.local

Name:      nginx-deployment.kube-system.svc.cluster.local
Address 1: 10.233.18.29 nginx-deployment.kube-system.svc.cluster.local
```

here is my container info:
```
  Containers:
   kubedns:
    Image:      gcr.io/google_containers/kubedns-amd64:1.9
   dnsmasq:
    Image:      gcr.io/google_containers/kube-dnsmasq-amd64:1.3
   healthz:
    Image:      gcr.io/google_containers/exechealthz-amd64:1.1
```",closed,False,2017-06-19 07:53:03,2017-06-23 09:39:05
dns,kcao3,https://github.com/kubernetes/dns/issues/110,https://api.github.com/repos/kubernetes/dns/issues/110,Unable to build Kubernetes DNS,"Hello,
Currently, I receive the following errors while attempting to run the make build target:
 ...
fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/main/x86_64/APKINDEX.tar.gz
ERROR: http://dl-cdn.alpinelinux.org/alpine/v3.6/main: temporary error (try again later)
WARNING: Ignoring APKINDEX.84815163.tar.gz: No such file or directory
fetch http://dl-cdn.alpinelinux.org/alpine/v3.6/community/x86_64/APKINDEX.tar.gz
v3.6.1-61-gc32140e9a2 [http://dl-cdn.alpinelinux.org/alpine/v3.6/community]
1 errors; 2892 distinct packages available
make[3]: *** [_output/amd64/dnsmasq] Error 1
make[3]: Leaving directory `/tmp/dns/images/dnsmasq'
make[2]: *** [build-dnsmasq] Error 2
make[2]: Leaving directory `/tmp/dns/images'
make[1]: *** [build] Error 2
make[1]: Leaving directory `/tmp/dns/images'
make: *** [images-build] Error 2

Does anyone have any idea how to resolve this problem? Thank you for your help!",closed,False,2017-06-20 20:34:51,2017-06-20 20:54:50
dns,asac,https://github.com/kubernetes/dns/issues/111,https://api.github.com/repos/kubernetes/dns/issues/111,k8s-dns-dnsmasq-nanny-arm:1.14.3 broken for 'arm',"/ # uname -a
Linux 26e00a3161d1 4.9.20-std-1 #1 SMP Wed Apr 5 15:38:34 UTC 2017 armv7l GNU/Linux

```
# docker run -it   --entrypoint=/bin/sh gcr.io/google_containers/k8s-dns-dnsmasq-nanny-arm:1.14.3
/ # /dnsmasq-nanny 
F0622 23:21:33.323491       7 nanny.go:173] Could not start dnsmasq with initial configuration: fork/exec /usr/sbin/dnsmasq: no such file or directory
goroutine 1 [running]:
k8s.io/dns/vendor/github.com/golang/glog.stacks(0x131b000, 0x0, 0x97, 0xcb)
	/go/src/k8s.io/dns/vendor/github.com/golang/glog/glog.go:769 +0x84
k8s.io/dns/vendor/github.com/golang/glog.(*loggingT).output(0x130a968, 0x3, 0x11698dc0, 0x12a53d1, 0x8, 0xad, 0x0)
	/go/src/k8s.io/dns/vendor/github.com/golang/glog/glog.go:720 +0x2f8
k8s.io/dns/vendor/github.com/golang/glog.(*loggingT).printf(0x130a968, 0x3, 0xcb7f76, 0x36, 0x1171bee4, 0x1, 0x1)
	/go/src/k8s.io/dns/vendor/github.com/golang/glog/glog.go:655 +0x10c
k8s.io/dns/vendor/github.com/golang/glog.Fatalf(0xcb7f76, 0x36, 0x1171bee4, 0x1, 0x1)
	/go/src/k8s.io/dns/vendor/github.com/golang/glog/glog.go:1148 +0x4c
k8s.io/dns/pkg/dnsmasq.RunNanny(0x12c4560, 0x118d12a0, 0xc90bb1, 0x11, 0x131b138, 0x0, 0x0, 0x0)
	/go/src/k8s.io/dns/pkg/dnsmasq/nanny.go:173 +0x1dc
main.main()
	/go/src/k8s.io/dns/cmd/dnsmasq-nanny/main.go:80 +0x21c
```",closed,False,2017-06-22 23:22:52,2017-07-02 20:59:30
dns,asac,https://github.com/kubernetes/dns/pull/112,https://api.github.com/repos/kubernetes/dns/issues/112,use armhf instead of armel for ARCH=arm busybox base images (Fixes #111),signed CLA...,closed,True,2017-06-25 13:27:45,2017-06-25 14:48:10
dns,asac,https://github.com/kubernetes/dns/pull/113,https://api.github.com/repos/kubernetes/dns/issues/113,use armhf instead of armel for ARCH=arm busybox base images (Fixes #111),(resubmit after signing CLA)...,closed,True,2017-06-25 14:34:42,2017-06-25 14:48:10
dns,asac,https://github.com/kubernetes/dns/pull/114,https://api.github.com/repos/kubernetes/dns/issues/114,use armhf instead of armel for ARCH=arm busybox base images (Fixes #111),(last attempt after double checking email in github etc... if CLA is still an issue i have to give on this for now :/) .. and sorry for the noise :),closed,True,2017-06-25 14:50:34,2017-06-25 16:54:10
dns,bowei,https://github.com/kubernetes/dns/pull/115,https://api.github.com/repos/kubernetes/dns/issues/115,Make record processing logging to V(3) to avoid log spam,Log level was V(2),closed,True,2017-06-25 17:23:22,2017-06-26 05:39:05
dns,spil-dennis,https://github.com/kubernetes/dns/issues/116,https://api.github.com/repos/kubernetes/dns/issues/116,Only one A record set for headless service with pods having single hostname.,"/kind bug

**What happened**
When a headless service is created to point to pods which share a single hostname, (which happens, for example, when the hostname field was set in the template of a deployment/replicaset)
- Only one A record is returned for the service DNS name
- A pod DNS name is generated based on this host name, which points to a single pod

**What was expected to happen**
- Return A records for all available endpoints on the service DNS name
- Not sure what the correct behaviour should be for the pod dns name, either also return multiple A records, or don't create at all.

Seems this has to do with the following code:
https://github.com/kubernetes/dns/blob/master/pkg/dns/dns.go#L490

Then the endpointName will be equal for any pod in the service which has the same hostname, so the entry in subCache will be overwritten.

**How to reproduce**

Apply the following spec:

```
apiVersion: v1
kind: List
items:
- apiVersion: extensions/v1beta1
  kind: Deployment
  metadata:
    name: depl-1
  spec:
    replicas: 2
    template:
      metadata:
        labels:
          app: depl-1
      spec:
        hostname: depl-1-host
        subdomain: depl-1-service
        containers:
        - name: test
          args:
          - bash
          stdin: true
          tty: true
          image: debian:jessie
- apiVersion: v1
  kind: Service
  metadata:
    name: depl-1-service
  spec:
    clusterIP: None
    selector:
      app: depl-1
    ports:
    - port: 5000

```

Resolving the hostnames gives back but a single A record.
```
# host depl-1-host.depl-1-service.default.svc.cluster.local
depl-1-host.depl-1-service.default.svc.cluster.local has address 10.56.0.140
# host depl-1-service.default.svc.cluster.local
depl-1-service.default.svc.cluster.local has address 10.56.0.140
```

PTR records ARE being created for all the pods, all resolving back to the single hostname. This is expected behaviour.

",open,False,2017-06-26 11:28:56,2018-05-17 17:43:49
dns,spil-dennis,https://github.com/kubernetes/dns/issues/117,https://api.github.com/repos/kubernetes/dns/issues/117,No PTR records generated for headless service if hostname was not set.,"If there is no hostname entry on an endpoint of a headless service, a DNS record is created with a hostname part based on some sort of hash, ultimately derived from the pod ip:
https://github.com/kubernetes/dns/blob/master/pkg/dns/dns.go#L486

The PTR record is then explicitly not generated:
https://github.com/kubernetes/dns/blob/master/pkg/dns/dns.go#L503

The spec states:
>Given a _ready_ endpoint with _hostname_ of &lt;hostname&gt; and IP address &lt;a&gt;.&lt;b&gt;.&lt;c&gt;.&lt;d&gt;, a PTR record of the following form must exist.

_hostname_ is defined earlier as the value of the hostname field on the endpoint or a ""unique, system-assigned identifier"", which in this case is the hash generated on line 486.

I would expect either of the following:
- A PTR records is always generated, dropping the conditional on line 503, satisfying the spec.
- No DNS records are generated in these cases and the spec is updated to reflect this behaviour.

",open,False,2017-06-26 11:45:41,2018-01-30 05:45:33
dns,ronanquillevere,https://github.com/kubernetes/dns/issues/118,https://api.github.com/repos/kubernetes/dns/issues/118,nslookup: can't resolve 'kubernetes.default',"Hello I hope this is the right place to post my issue. Forgive me if this isnt and please redirect me to the right place.

I am trying to install a cluster with one master (`server-1`) and one minion (`server-2`) running on `ubuntu` and using `flannel` for networking and using `kubeadm` to install master and minion. And I am trying to run the dashboard from the minion `server-2` as discussed [here](https://github.com/kubernetes/dashboard/issues/916). I am very new to kubernetes and not an expert on linux networking setup, so any help would be appreciated. Dashboard is not working and after some investigation seems to be a DNS issue.

`kubectl` and `kubeadm` : 1.6.6
`Docker`: 17.03.1-ce

My DNS service is up and exposing endpoints

```
ubuntu@server-1:~$ kubectl get svc --all-namespaces
NAMESPACE     NAME                   CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE
default       kubernetes             10.96.0.1       <none>        443/TCP         20h
kube-system   kube-dns               10.96.0.10      <none>        53/UDP,53/TCP   20h
kube-system   kubernetes-dashboard   10.97.135.242   <none>        80/TCP          3h
```

```
ubuntu@server-1:~$ kubectl get ep kube-dns --namespace=kube-system
NAME       ENDPOINTS                     AGE
kube-dns   10.244.0.4:53,10.244.0.4:53   17h
```

I created a busy-box pod and when I do a nslookup from it I got the following errors. Note that the command hang for some time before returning the error.

```
ubuntu@server-1:~$ kubectl exec -ti busybox -- nslookup kubernetes.default
Server:    10.96.0.10
Address 1: 10.96.0.10

nslookup: can't resolve 'kubernetes.default'

ubuntu@server-1:~$ kubectl exec -ti busybox -- nslookup kubernetes.local
Server:    10.96.0.10
Address 1: 10.96.0.10

nslookup: can't resolve 'kubernetes.local'

ubuntu@server-1:~$ kubectl exec -ti busybox -- nslookup kubernetes
Server:    10.96.0.10
Address 1: 10.96.0.10

nslookup: can't resolve 'kubernetes'

ubuntu@server-1:~$ kubectl exec -ti busybox -- nslookup 10.96.0.1
Server:    10.96.0.10
Address 1: 10.96.0.10

Name:      10.96.0.1
Address 1: 10.96.0.1
```

Resolv.conf seems properly configured
```
ubuntu@server-1:~$ kubectl exec busybox cat /etc/resolv.conf
nameserver 10.96.0.10
search default.svc.cluster.local svc.cluster.local cluster.local local
options ndots:5
```

DNS pod is running
```
ubuntu@server-1:~$ kubectl get pods --namespace=kube-system -l k8s-app=kube-dns
NAME                       READY     STATUS    RESTARTS   AGE
kube-dns-692378583-5zj21   3/3       Running   0          17h
```



Here is iptables from server 1

```
Chain INPUT (policy ACCEPT)
target     prot opt source               destination         
KUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */
KUBE-FIREWALL  all  --  anywhere             anywhere            

Chain FORWARD (policy DROP)
target     prot opt source               destination         
DOCKER-ISOLATION  all  --  anywhere             anywhere            
DOCKER     all  --  anywhere             anywhere            
ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED
ACCEPT     all  --  anywhere             anywhere            
ACCEPT     all  --  anywhere             anywhere            

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         
KUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */
KUBE-FIREWALL  all  --  anywhere             anywhere            

Chain DOCKER (1 references)
target     prot opt source               destination         

Chain DOCKER-ISOLATION (1 references)
target     prot opt source               destination         
RETURN     all  --  anywhere             anywhere            

Chain KUBE-FIREWALL (2 references)
target     prot opt source               destination         
DROP       all  --  anywhere             anywhere             /* kubernetes firewall for dropping marked packets */ mark match 0x8000/0x8000

Chain KUBE-SERVICES (2 references)
target     prot opt source               destination         
REJECT     tcp  --  anywhere             10.103.141.154       /* kube-system/kubernetes-dashboard: has no endpoints */ tcp dpt:http reject-with icmp-port-unreachable
```


here are iptables from server-2

```
Chain INPUT (policy ACCEPT)
target     prot opt source               destination         
KUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */
KUBE-FIREWALL  all  --  anywhere             anywhere            

Chain FORWARD (policy DROP)
target     prot opt source               destination         
DOCKER-ISOLATION  all  --  anywhere             anywhere            
DOCKER     all  --  anywhere             anywhere            
ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED
ACCEPT     all  --  anywhere             anywhere            
ACCEPT     all  --  anywhere             anywhere            

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         
KUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */
KUBE-FIREWALL  all  --  anywhere             anywhere            

Chain DOCKER (1 references)
target     prot opt source               destination         

Chain DOCKER-ISOLATION (1 references)
target     prot opt source               destination         
RETURN     all  --  anywhere             anywhere            

Chain KUBE-FIREWALL (2 references)
target     prot opt source               destination         
DROP       all  --  anywhere             anywhere             /* kubernetes firewall for dropping marked packets */ mark match 0x8000/0x8000

Chain KUBE-SERVICES (2 references)
target     prot opt source               destination         
REJECT     tcp  --  anywhere             10.103.141.154       /* kube-system/kubernetes-dashboard: has no endpoints */ tcp dpt:http reject-with icmp-port-unreachable
```
",closed,False,2017-06-28 11:00:58,2018-11-11 20:25:22
dns,jpap,https://github.com/kubernetes/dns/issues/119,https://api.github.com/repos/kubernetes/dns/issues/119,External queries fail with Cloudflare domain in DNS search list,"My domain's DNS is hosted with Cloudflare.  I am using a bare metal cluster that has the domain in the `/etc/resolv.conf` search list.

DNS queries for external domains (e.g. `www.yahoo.com`) fail under the above conditions on some containers (e.g. Alpine-based):
```
/ # ping www.yahoo.com
ping: bad address 'www.yahoo.com'
```

When I manually remove my domain from the `/etc/resolv.conf` search list in the container the query works as expected.

With Wireshark, I was able to determine that Cloudflare's NS returns RCODE = 0 with no RRs when queried with a nonexistent domain (e.g. `www.yahoo.com.mydomain.com`).  Most other NSs I've tried return RCODE = 3 in this case.  (This issue never came up until I moved to Cloudflare; my domain registry's nameservers return RCODE = 3 for nonexistent domains.)

Could the RCODE = 0 result code on the search list be preventing Kubernetes DNS from performing a FQDN lookup (e.g. just `www.yahoo.com`) in this case, resulting in the ultimate failure of the query?

I've raised the RCODE issue with Cloudflare, and had a quick look at the SkyDNS and miekg/dns project source code, but it wasn't not immediately clear to me what the code path is here.",closed,False,2017-06-29 00:23:24,2018-04-09 22:28:51
dns,zhxcai,https://github.com/kubernetes/dns/pull/120,https://api.github.com/repos/kubernetes/dns/issues/120,Add some error and info log for debug,,closed,True,2017-06-29 12:23:59,2017-07-18 16:46:44
dns,ahmetb,https://github.com/kubernetes/dns/issues/121,https://api.github.com/repos/kubernetes/dns/issues/121,kube-dns never resolves if a domain returns NOERROR with 0 answer records once,"tl;dr If a nameserver replies status=NOERROR with no answer section to a DNS A question, kube-dns always caches this result. If the domain name actually gets an A record _after_ it's queried through kube-dns, it never (I waited a few days) resolves from the pods, but does resolve outside the container (e.g. on my laptop) just fine.

## Repro steps

#### Prerequisites

- Have a domain name `alp.im` and the nameservers are pointed to CloudFlare.
- Have nslookup/dig installed on your workstation.
- Have a minikube cluster ready on your workstation
    - running kubernetes v1.6.0
    - kube-dns comes by default, running `gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.1`

#### Step 1: Domain does not exist, query from your laptop

Note `ANSWER: 0`, and `status: NOERROR`

```
$ dig A z.alp.im

; <<>> DiG 9.8.3-P1 <<>> A z.alp.im
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 64978
;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;z.alp.im.			IN	A

;; AUTHORITY SECTION:
alp.im.			1799	IN	SOA	ivan.ns.cloudflare.com. dns.cloudflare.com. 2025042470 10000 2400 604800 3600

;; Query time: 196 msec
;; SERVER: 2401:fa00:fa::1#53(2401:fa00:fa::1)
;; WHEN: Thu Jun 29 10:51:35 2017
;; MSG SIZE  rcvd: 99
```

#### Step 2: Domain does not exist, query from Pod on Kubernetes

Start a toolbelt/dig container with shell and run the same query:

> ⚠️ Do not exit this container as you will reuse it later. 

Note the response is the same, `ANSWER: 0` and `NOERROR`.

```
$ kubectl run -i -t --rm --image=toolbelt/dig dig --command -- sh
If you don't see a command prompt, try pressing enter.
/ # dig A z.alp.im

; <<>> DiG 9.11.1-P1 <<>> A z.alp.im
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 11209
;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;z.alp.im.			IN	A

;; AUTHORITY SECTION:
alp.im.			1724	IN	SOA	ivan.ns.cloudflare.com. dns.cloudflare.com. 2025042470 10000 2400 604800 3600

;; Query time: 74 msec
;; SERVER: 10.0.0.10#53(10.0.0.10)
;; WHEN: Thu Jun 29 17:55:46 UTC 2017
;; MSG SIZE  rcvd: 99
```

(Also note that `SERVER: 10.0.0.10#53` which is kube-dns.)

#### Step 3: Create an A record for the domain

Here I use CloudFlare as it manages my DNS. 

![image](https://user-images.githubusercontent.com/159209/27702492-16f4ce86-5cb9-11e7-9cf3-bda59ef18660.png)

#### Step 4: Test DNS record from your laptop

Run `dig` on your laptop (note `;; ANSWER SECTION:` and `8.8.8.8` answer):

```
$ dig A z.alp.im

; <<>> DiG 9.8.3-P1 <<>> A z.alp.im
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 37570
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;z.alp.im.			IN	A

;; ANSWER SECTION:
z.alp.im.		299	IN	A	8.8.8.8

;; Query time: 196 msec
;; SERVER: 2401:fa00:fa::1#53(2401:fa00:fa::1)
;; WHEN: Thu Jun 29 10:54:44 2017
;; MSG SIZE  rcvd: 53
```

#### Step 5: Test DNS record from Pod on Kubernetes

Run the same command again:

```
/ # dig A z.alp.im

; <<>> DiG 9.11.1-P1 <<>> A z.alp.im
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 45420
;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;z.alp.im.			IN	A

;; Query time: 0 msec
;; SERVER: 10.0.0.10#53(10.0.0.10)
;; WHEN: Thu Jun 29 18:00:24 UTC 2017
;; MSG SIZE  rcvd: 37
```

Note the [diff](https://www.diffchecker.com/l2GTkuBd):

- still `ANSWER: 0` and `status: NOERROR` (but it resolves just fine outside the cluster)
- `;; AUTHORITY SECTION:` disappeared and `AUTHORITY:` changed to `0` from the previous time we ran this. 
- `;; Query time: 0 msec` (was 79 ms) –I assume it means it's just a cached response.
    - Query time stays as 0 ms no matter how many times I run the same command.


## What else I tried

- **Try it on GKE**: I tried with k8s v1.5.x and v1.6.4.  &rarr; Same issue. (cc: @bowei)
- **Query from a different pod** on minikube: I started a new Pod and queried from there  &rarr; Same issue.
- **Restart kube-dns Pod** &rarr; This **worked** on GKE, but **not** on minikube.

      $ kubectl delete pods -n kube-system -l k8s-app=kube-dns
      pod ""kube-dns-268032401-69xk5"" deleted


## Impact

I am not sure why this has not been discovered before. I noticed this behavior while using kube-lego on GKE. Once kube-lego applies for a TLS certificate, it polls the domain name of the service (e.g. `example.com/.well-known/<token>`) before asking Let's Encrypt to validate it. Before I create an Ingress with kube-lego annotation, I don't have the external IP yet so I can't configure the domain, but the kube-lego Pod already picks it up and starts querying my domain in an infinite loop. It never succeeds because first time it looked up the hostname, the A record didn't exist, so that result is cached forever. After I add A record, it still can't resolve. The moment I delete kube-dns Pods and they get recreated, it immediately starts working and resolves the hostname and completes the kube-lego challenge.
",closed,False,2017-06-29 18:21:13,2018-02-23 13:54:39
dns,dElogics,https://github.com/kubernetes/dns/issues/122,https://api.github.com/repos/kubernetes/dns/issues/122,Please document how kube-dns works.,"Currently kubedns is a black box and no one knows how it works (for e.g. the --kube-master-url= switch). As a result, except for a static set of cloud based infrastructure, it's practically impossible to get it working any place else.

So please document how kubedns works at the daemon level so the ecosystem can be created on a physical machine or custom containers based on custom OS can be build for those daemons.",closed,False,2017-07-05 08:52:56,2019-01-10 09:39:52
dns,guillaumerose,https://github.com/kubernetes/dns/pull/123,https://api.github.com/repos/kubernetes/dns/issues/123,Handle same hostname for multiple pods in a headless service,"This code improves the handling of headless services pointing at pods sharing
the same hostname.

 + For each hostname, A records should point at the list of pods IPs.
   Currently, only the last pod gets its A record.
 + For the service, a A record should be created for each pod.

Fixes https://github.com/kubernetes/dns/issues/116

cc @dgageot",closed,True,2017-07-07 12:51:26,2018-03-19 08:54:40
dns,thockin,https://github.com/kubernetes/dns/issues/124,https://api.github.com/repos/kubernetes/dns/issues/124,PTR records can collide,"As pointed out at the end of #25, it's possible to make PTR records collide with manual endpoints, in which case someone can hijack the PTR record, even across namespaces.

```
apiVersion: v1
kind: Service
metadata:
  name: manual-1
spec:
  clusterIP: None
  ports:
  - port: 80
```

```
apiVersion: v1
kind: Service
metadata:
  name: manual-2
spec:
  clusterIP: None
  ports:
  - port: 80
```

```
apiVersion: v1
kind: Endpoints
metadata:
  name: manual-1
subsets:
- addresses:
  - ip: 10.10.10.10
    hostname: foo
  ports:
  - port: 80
```

```
apiVersion: v1
kind: Endpoints
metadata:
  name: manual-2
subsets:
- addresses:
  - ip: 10.10.10.10
    hostname: bar
  ports:
  - port: 80
```

This sort of makes PTR records, as implemented, useless.  @sadlil offers #101, but I am worried about the impact of that when there are many DNS replicas.  I don't think it will fly, and we really really do not want DNS to watch Pods (some crazy people run DNS on every node, and it will CRUSH the apiserver).

There's also an issue of adding PTR records for IPs that are not pods, I will open a different issue.

We need to find a solution to this ASAP or revert #25 and eat some crow.

We need some authoritative place that can confirm IP->pod mapping, but that seems impossible to do without creating an O(num-pods) watch, or else trusting Endpoints to not hijack.
",closed,False,2017-07-07 17:14:50,2018-03-11 04:52:33
dns,thockin,https://github.com/kubernetes/dns/issues/125,https://api.github.com/repos/kubernetes/dns/issues/125,PTR records are created and served for non-cluster IPs,"```
apiVersion: v1
kind: Service
metadata:
  name: manual-1
spec:
  clusterIP: None
  ports:
  - port: 80
```

```
apiVersion: v1
kind: Endpoints
metadata:
  name: manual-1
subsets:
- addresses:
  - ip: 8.8.8.8
    hostname: foo
  ports:
  - port: 80
```

Reverse lookups for 8.8.8.8 now return `foo.manual-1.default.svc.cluster.local.`

We should probably never create reverse records except for service IPs and real pod IPs.",open,False,2017-07-07 17:17:18,2018-01-02 22:34:05
dns,feiskyer,https://github.com/kubernetes/dns/pull/126,https://api.github.com/repos/kubernetes/dns/issues/126,Fix dnsmasq-nanny dockerfile,dnsmasq-nanny dockerfile should honor user-specified REGISTRY instead of always using `gcr.io/google_containers`.,closed,True,2017-07-14 10:38:07,2017-07-14 22:27:16
dns,MrHohn,https://github.com/kubernetes/dns/pull/127,https://api.github.com/repos/kubernetes/dns/issues/127,Use alpine as base image on all platforms,"Ack https://github.com/kubernetes/contrib/pull/2670#issuecomment-315712954.

@guirish Would you be able to test the s390x image? Thanks.

/assign @bowei 

cc @GheRivero @gajju26 ",closed,True,2017-07-17 17:53:29,2017-10-05 00:53:58
dns,allencloud,https://github.com/kubernetes/dns/pull/128,https://api.github.com/repos/kubernetes/dns/issues/128,enable http pprof in kube-dns,"I think it is useful for a webserver to have a pprof debug functionality.
So I add this to kube-dns.

Signed-off-by: allencloud <allen.sun@daocloud.io>",closed,True,2017-07-24 09:53:10,2017-08-01 17:33:59
dns,fgimenez,https://github.com/kubernetes/dns/pull/129,https://api.github.com/repos/kubernetes/dns/issues/129,diagnoser's initial implementation,"This is an initial and unfinished implementation of the tool described in kubernetes/kubernetes#45934 and #102, the aim is to validate the approach before implementing all the suggested checks.",closed,True,2017-07-25 06:57:34,2018-03-11 16:03:34
dns,MrHohn,https://github.com/kubernetes/dns/pull/130,https://api.github.com/repos/kubernetes/dns/issues/130,Avoid noisy logs in sidecar,"Fixes #98.

This is the same fix as #27, but in sidecar this time.",closed,True,2017-07-26 20:29:13,2017-08-30 23:13:54
dns,iamrandys,https://github.com/kubernetes/dns/issues/131,https://api.github.com/repos/kubernetes/dns/issues/131,externalName not using stubDomains settings,"When creating an externalName and the hostname provided is only resolvable when using stubDomains, the new service is not resolvable.

For example, if we setup stubDomains using the kube-dns config map, we are able to resolve subdomains of my-domain.com (such as xyz.my-domain.com) in our applications.  This works great.

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-dns
  namespace: kube-system
data:
  stubDomains: |
    {""my-domain.com"": [""172.111.111.111"", ""172.111.111.111""]}
```

When we try to create an externalName service using a domain that is only resolvable with the help of stubDomains, the service is created, but the service is not resolvable.

`
kubectl create service externalname my-service --external-name xyz.my-domain.com
`
`
kubectl exec -ti busybox -- nslookup my-service
`
```
Server:    100.64.0.10
Address 1: 100.64.0.10 kube-dns.kube-system.svc.cluster.local

nslookup: can't resolve 'my-service'
```

When I add the domain, xyz.my-domain.com, to the VPCs Route53 then the service is resolved and the externalName service works as expected.

`
kubectl create service externalname my-service --external-name xyz.my-domain.com
`
`
kubectl exec -ti busybox -- nslookup my-service
`
```
Server:    100.64.0.10
Address 1: 100.64.0.10 kube-dns.kube-system.svc.cluster.local

Name:      my-service
Address 1: 10.xxx.xxx.xxx
```

I'm would expect that the same stubDomains setting be used when creating externalName services.",closed,False,2017-08-04 19:59:51,2018-09-24 23:02:52
dns,feiskyer,https://github.com/kubernetes/dns/issues/132,https://api.github.com/repos/kubernetes/dns/issues/132,Add support for serving on specified namespaces,"kube-dns is serving on all namespaces today. As we are moving on to support multiple networks, pods on different networks may not access each other, e.g. in a multi-tenant environment. 

So I propose to support serving on specified namespace in kube-dns, so as to conform such use cases.

cc/ @bowei ",closed,False,2017-08-07 01:12:41,2018-03-10 04:28:35
dns,feiskyer,https://github.com/kubernetes/dns/pull/133,https://api.github.com/repos/kubernetes/dns/issues/133,[POC] Support specifying namespace,Closes #132.,closed,True,2017-08-07 01:16:30,2018-01-03 01:29:07
dns,andyxning,https://github.com/kubernetes/dns/pull/134,https://api.github.com/repos/kubernetes/dns/issues/134,fix go switch,"This PR will remove `break` statement from `switch` as it is useless in go. The default behavior is to `break` after a `case`.

/cc @bowei  ",closed,True,2017-08-08 15:53:35,2017-08-09 00:57:12
dns,andyxning,https://github.com/kubernetes/dns/pull/135,https://api.github.com/repos/kubernetes/dns/issues/135,code refactor,"This PR refactor the code to use `metricsClient` struct field instead of a local variable `client`.

/cc @bowei ",closed,True,2017-08-11 14:21:41,2017-08-30 00:09:43
dns,fisherxu,https://github.com/kubernetes/dns/pull/136,https://api.github.com/repos/kubernetes/dns/issues/136,Fix: update `kube2sky` to `kube-dns` in comment of server.go ,"I think the  `kube2sky` should be  `kube-dns`, so I fix it.",closed,True,2017-08-12 09:40:12,2017-08-15 03:39:14
dns,mbssaiakhil,https://github.com/kubernetes/dns/pull/137,https://api.github.com/repos/kubernetes/dns/issues/137,Fix Typo in Events Code of Conduct,,closed,True,2017-08-13 10:19:25,2017-08-14 03:38:08
dns,feiskyer,https://github.com/kubernetes/dns/issues/138,https://api.github.com/repos/kubernetes/dns/issues/138,kube-dns failed to start,"kube-dns on master branch failed to start:

```sh
# kubectl logs kube-dns-1476438210-rzf6r -c kubedns
...
I0814 09:53:28.164431     104 server.go:130] Setting up Healthz Handler (/readiness)
I0814 09:53:28.164449     104 server.go:135] Setting up cache handler (/cache)
I0814 09:53:28.164455     104 server.go:146] Setting up pprof handler (/debug/pprof)
panic: http: multiple registrations for /debug/pprof/

goroutine 1 [running]:
net/http.(*ServeMux).Handle(0x2022de0, 0x1713f52, 0xd, 0x1fc3120, 0x1780750)
	/usr/local/go/src/net/http/server.go:2254 +0x610
net/http.(*ServeMux).HandleFunc(0x2022de0, 0x1713f52, 0xd, 0x1780750)
	/usr/local/go/src/net/http/server.go:2286 +0x55
net/http.HandleFunc(0x1713f52, 0xd, 0x1780750)
	/usr/local/go/src/net/http/server.go:2298 +0x4b
k8s.io/dns/cmd/kube-dns/app.(*KubeDNSServer).setupHandlers(0xc420014b40)
	/go/src/k8s.io/dns/cmd/kube-dns/app/server.go:147 +0x1a5
k8s.io/dns/cmd/kube-dns/app.(*KubeDNSServer).Run(0xc420014b40)
	/go/src/k8s.io/dns/cmd/kube-dns/app/server.go:119 +0x7b
main.main()
	/go/src/k8s.io/dns/cmd/kube-dns/dns.go:51 +0x2f8
```

The problem is introduced in #128.  we have imported ""net/http/pprof"" in cmd/kube-dns/app/options/options.go, which have already registered handlers for `/debug/pprof/`.",closed,False,2017-08-14 10:04:55,2017-08-24 02:55:02
dns,feiskyer,https://github.com/kubernetes/dns/pull/139,https://api.github.com/repos/kubernetes/dns/issues/139,"Revert ""enable http pprof in kube-dns""",Reverts kubernetes/dns#128 for fixing #138.,closed,True,2017-08-14 10:05:30,2017-08-24 01:20:39
dns,johnbelamaric,https://github.com/kubernetes/dns/issues/140,https://api.github.com/repos/kubernetes/dns/issues/140,SRV records for external services,"The spec (at least with #89) says to return a CNAME for an external service. This is fine for A records. The question is what to do about SRV records. There are four scenarios:

1. There *is not* an SRV record for the name in the upstream, and port info *is not* specified in the external service definition. I think return no data.
2. There *is* an SRV record in the upstream for that name, and port info *is not* specified in the external service definition. I think return the upstream SRV (which would be the normal DNS thing to do)
3. There *is not* an SRV record for the name in the upstream, and port info *is* specified in the external service definition. I think return a synthetic SRV based on external service definition.
4. There *is* an SRV record for the name in the upstream, and port info *is* specified in the external service definition. Umm...not sure here. Probably prefer the K8s external service definition. Or maybe return both.

We should specify the correct result in each of these scenarios.

Here's what `kube-dns` (using `minikube` with K8s v1.7.0) does today in each of these scenarios.

*Scenario 1*
```
dnstools# host ext-svc-no-port.test-1.svc.cluster.local.
ext-svc-no-port.test-1.svc.cluster.local is an alias for example.com.
example.COM has address 93.184.216.34
example.COM has IPv6 address 2606:2800:220:1:248:1893:25c8:1946
dnstools# host -t srv ext-svc-no-port.test-1.svc.cluster.local.
ext-svc-no-port.test-1.svc.cluster.local has SRV record 10 100 0 example.com.
dnstools#
```

WTH? It just made up a bogus SRV record.

*Scenario 2*
Here is an example of a CNAME whose target has an SRV, using records in the upstream DNS (i.e., `kube-dns` is forwarding this query):

```
dnstools# host -t srv foo.kops.belamaric.com
foo.kops.belamaric.COM is an alias for kops.belamaric.com.
kops.belamaric.com has SRV record 1 10 9876 kops.belamaric.com.
dnstools#
```

In K8s, I have defined an external name service without any port specified, and pointing to `kops.belamaric.com` which holds an SRV record. The first query here shows that the normal A record lookup for the external name works; the second shows what you get for the SRV query:

```
dnstools# host ext-svc-srv-no-port.test-1.svc.cluster.local.
ext-svc-srv-no-port.test-1.svc.cluster.local is an alias for kops.belamaric.com.
dnstools# host -t srv ext-svc-srv-no-port.test-1.svc.cluster.local.
ext-svc-srv-no-port.test-1.svc.cluster.local has SRV record 10 100 0 kops.belamaric.com.
dnstools#
```

Again, the same bogus SRV record. 

*Scenario 3*
Same thing:

```
dnstools# host ext-svc.test-1.svc.cluster.local.
ext-svc.test-1.svc.cluster.local is an alias for example.net.
example.net has address 93.184.216.34
example.net has IPv6 address 2606:2800:220:1:248:1893:25c8:1946
dnstools# host -t srv ext-svc.test-1.svc.cluster.local.
ext-svc.test-1.svc.cluster.local has SRV record 10 100 0 example.net.
dnstools#
```

*Scenario 4*
```
dnstools# host ext-svc-srv.test-1.svc.cluster.local.
ext-svc-srv.test-1.svc.cluster.local is an alias for kops.belamaric.com.
dnstools# host -t srv ext-svc-srv.test-1.svc.cluster.local.
ext-svc-srv.test-1.svc.cluster.local has SRV record 10 100 0 kops.belamaric.com.
dnstools#
```

Same thing again.

So today it looks like `kube-dns` just creates a fake, incorrect SRV record in all these cases. Today in CoreDNS, I think we return nodata in most of these cases.
",closed,False,2017-08-16 21:09:48,2018-03-12 14:25:35
dns,aanm,https://github.com/kubernetes/dns/issues/141,https://api.github.com/repos/kubernetes/dns/issues/141,"no RRs for domain ""kubernetes.default.svc.cluster.local.""","I'm getting a weird error from kube-dns that is preventing it from starting.

Apparently the livenessProbe is returning this error:

`{""IsOk"":false,""LatencySeconds"":0,""Err"":""no RRs for domain \""kubernetes.default.svc.cluster.local.\""""}`

What does it mean? It seems kube-dns can't find the endpoint address of the kubernetes service, is that correct? If yes, how can I debug the reason for `that?

`kubectl describe endpoints kubernetes` shows the endpoints addresses on a ready state.",closed,False,2017-08-17 10:32:53,2017-11-03 10:55:25
dns,glennschmidt,https://github.com/kubernetes/dns/issues/142,https://api.github.com/repos/kubernetes/dns/issues/142,"""New service:"" log messages","For the past several days, my cluster config has been stable (no pods being created/deleted, no nodes going up/down). Yet kube-dns is logging hundreds of messages every hour about ""new services"".

For example:
```
I0818 05:08:18.445594       1 dns.go:264] New service: elasticsearch-logging
I0818 05:08:18.446497       1 dns.go:264] New service: kube-dns
I0818 05:08:18.446159       1 dns.go:264] New service: kubernetes
I0818 05:08:18.446427       1 dns.go:264] New service: heapster
```
It seems to be looping through all the services that exist in the cluster and reporting them as 'new' every 2-3 minutes.

My questions are

1. Is this normal, and
2. If not, does anyone know what could be causing this behavior?
",closed,False,2017-08-18 05:29:40,2018-01-03 07:54:31
dns,andyxning,https://github.com/kubernetes/dns/pull/143,https://api.github.com/repos/kubernetes/dns/issues/143,code clean for e2e,"Code clean for e2e test logic. There is no functionality change. 

/cc @bowei ",closed,True,2017-08-21 04:16:58,2017-08-21 21:47:46
dns,Rajadeepan,https://github.com/kubernetes/dns/pull/144,https://api.github.com/repos/kubernetes/dns/issues/144,Fix Broken link,Fix Broken link,closed,True,2017-08-21 19:01:53,2018-01-31 07:05:32
dns,andyxning,https://github.com/kubernetes/dns/pull/145,https://api.github.com/repos/kubernetes/dns/issues/145,fix kube-dns e2e test for health check service,"Fix #138 .

Add health check service validation before doing a query in kube-dns e2e query.

As for now, #139 has not been merged, so this PR will definitely does not pass the CI. But after #139 is merged, i will rebase this PR.

/cc @bowei @feiskyer @MrHohn ",closed,True,2017-08-23 10:31:36,2017-08-24 03:20:26
dns,andyxning,https://github.com/kubernetes/dns/pull/146,https://api.github.com/repos/kubernetes/dns/issues/146,fix make file,"remove useless build volume mapping when build binaries.

By removing `-v $$(pwd)/bin/$(ARCH):/go/bin`, we can avoid an empty dir  `bin/ARCH/linux_ARCH`.

/cc @bowei ",closed,True,2017-08-24 06:50:56,2017-09-24 17:19:04
dns,leblancd,https://github.com/kubernetes/dns/issues/147,https://api.github.com/repos/kubernetes/dns/issues/147,Add support for nameservers with IPv6 addresses,"If kube-dns is run on a minion that has a nameserver listed in
/etc/resolv.conf with an IPv6 address, then the dnsmasq nanny container
dies shortly after reading this resolv.conf file, and the liveness probe
never indicates a healthy pod (pod is restarted after a few minutes).
",closed,False,2017-09-01 22:29:01,2017-10-23 17:30:59
dns,leblancd,https://github.com/kubernetes/dns/pull/148,https://api.github.com/repos/kubernetes/dns/issues/148,Add support for nameservers with IPv6 addresses,"This change fixes a couple of places in the kube-dns code where
IPv6 addresses are not being handled correctly for nameservers found
in a minion's resolv.conf file.

This change is needed in order to get kube-dns to operate in a
Kubernetes cluster that is IPv6-only. See Kubernetes issue 51371
(https://github.com/kubernetes/kubernetes/issues/51371).

fixes #147",closed,True,2017-09-01 22:41:21,2017-10-23 21:42:50
dns,bboreham,https://github.com/kubernetes/dns/issues/149,https://api.github.com/repos/kubernetes/dns/issues/149,Questioning probe_latency_ms buckets,"In `pkg/sidecar/dnsprobe.go` the code calls `prometheus.LinearBuckets(0, 10, 500)`, which creates 500 buckets at 0ms, 10ms, 20ms, ...

My kube-dns manages to serve nearly everything in under 10ms, so these buckets are (a) very numerous and (b) telling me nothing.

I would be interested to know what the thinking was - why not use `ExponentialBuckets()` to save space and start at a lower interval?",closed,False,2017-09-04 14:59:13,2018-01-08 17:15:59
dns,leblancd,https://github.com/kubernetes/dns/issues/150,https://api.github.com/repos/kubernetes/dns/issues/150,Add support for SRV probes to be agnostic of IPv4 vs IPv6 operation,"If a kubernetes cluster is running in IPv6-only mode, then service IPs will be
IPv6 addresses, and kube-dns will resolve kubernetes services to these IPv6
addresses (i.e. will only return AAAA records for those services). In this case, a kube-dns
sidecar probe that is configured to do DNS queries of type A will fail, since no A records
will be returned. If you modify such a probe to use DNS queries of type ANY instead of A,
the probe will still fail because skyDNS rejects queries of type ANY.

A SkyDNS issue was filed, and PR was made to request support for type ANY requests:
    https://github.com/skynetservices/skydns/issues/323
    https://github.com/skynetservices/skydns/pull/324
However, the lead maintainer of SkyDNS thought that using request of type SRV
might be a better approach (see comments in issue 323 above).

So what is being proposed with this kubernetes/dns issue is that kube-dns sidecar
probes like the following be supported:
        - --probe=kubedns,[127.0.0.1]:10053,kubernetes.default.svc.cluster.local,5,SRV
        - --probe=dnsmasq,[127.0.0.1]:53,kubernetes.default.svc.cluster.local,5,SRV

Once support is added to kube-dns for probes that use queries of type SRV,
then the following kubeadm issue/PR can be modified to use probes
of type SRV (instead of ANY as originally proposed):
    https://github.com/kubernetes/kubernetes/issues/51371
    https://github.com/kubernetes/kubernetes/pull/51378

",closed,False,2017-09-04 16:50:14,2017-09-19 18:06:11
dns,leblancd,https://github.com/kubernetes/dns/pull/151,https://api.github.com/repos/kubernetes/dns/issues/151,Add support for SRV probes to be IPv4/IPv6 agnostic,"This change adds support for kube-dns sidecar probes that use
DNS type SRV queries.  This will allow kube-dns sidecar probes
to be configured using SRV queries such that the
configuration/manifest will be agnostic of whether kube-proxy
is operating in IPv4 vs IPv6 mode (i.e. whether kube-dns
is resolving kubernetes services to IPv4 vs IPv6 addresses).

This change will help resolve a kubeadm issue/PR that has been
filed:
    kubernetes/kubernetes#51371
    kubernetes/kubernetes#51378
although the approach in the above issue/PR will need to be
changed to use SRV rather than ANY type sidecar probes, since
the SkyDNS software that kube-dns uses does not support queries
of type ANY, and the maintainer believes that using SRV type
queries is a better approach. See:
    skynetservices/skydns#323

Changes included in this PR:
- Add support for sidecar probes of type SRV.
- Add a unit test for the probeOptions Set() method.
- Minor tweak to regexp used to check configured probe labels
  so that it looks at the entire configured label.
- Fixed an index out of bounds bug for ""invalid type for DNS""
  error messages.

fixes #150",closed,True,2017-09-08 15:04:00,2017-09-19 18:06:11
dns,bowei,https://github.com/kubernetes/dns/pull/152,https://api.github.com/repos/kubernetes/dns/issues/152,Add ability to apply custom patches to the dnsmasq build,"Patches in the patches/* are applied to the dnsmasq code in
lexigraphical order.",closed,True,2017-09-22 19:58:40,2017-09-23 20:32:52
dns,mindw,https://github.com/kubernetes/dns/issues/153,https://api.github.com/repos/kubernetes/dns/issues/153,1.14.5 version is missing,"kubernetes 1.7.7 released with the above version.
Where can the changelog and release be found?",closed,False,2017-09-30 20:13:56,2017-10-02 23:56:20
dns,bowei,https://github.com/kubernetes/dns/pull/154,https://api.github.com/repos/kubernetes/dns/issues/154,Update dnsmasq to version 2.78,This fixes externally exploitable security vulnerabilities in dnsmasq.,closed,True,2017-10-02 22:48:47,2017-10-02 23:48:49
dns,SleepyBrett,https://github.com/kubernetes/dns/issues/155,https://api.github.com/repos/kubernetes/dns/issues/155,1.14.5 vs 1.15.6,"After hearing about the CVE fixes to dnsmasq yesterday I upgrade my kubedns to 1.14.5 which uses the following dnsmasq:

    / # dnsmasq --version
    Dnsmasq version 2.78-security-prerelease  Copyright (c) 2000-2017 Simon Kelley 
    Compile time options: IPv6 GNU-getopt no-DBus no-i18n no-IDN DHCP DHCPv6 no-Lua TFTP no-conntrack ipset auth no-DNSSEC loop-detect inotify

This morning I see a new release of 1.14.6 but the commit looks the same as 1.14.5? Is there any difference?",closed,False,2017-10-03 14:54:32,2017-10-03 17:48:13
dns,wheestermans,https://github.com/kubernetes/dns/issues/156,https://api.github.com/repos/kubernetes/dns/issues/156,Not able to access external resources outside pod (docker container),"I know it is not really DNS related, but didn't find other group fro this question.

When I telnet aaa.bbb.ccc.ddd 3202 on host node the connection is working fine, acceptance (DB2 connection) . Now when I do exactly the same outside running pod (docker container), the connectivity is not working.

From the host:

_telnet 150.45.92.41 3200
Trying 150.45.92.41...
Connected to 150.45.92.41.
Escape character is '^]'_

From the pod (docker container)

_sh-4.2$ telnet 150.45.92.41 3200
Trying 150.45.92.41..._

 **kubectl describe pod npaqit-service-2193241535-8f3x6**
Name:           npaqit-service-2193241535-8f3x6
Namespace:      default
Node:           lxdocapt14/150.45.89.109
Start Time:     Mon, 09 Oct 2017 14:55:52 +0200
Labels:         io.kompose.service=npaqit-service
                pod-template-hash=2193241535
Annotations:    kubernetes.io/created-by={""kind"":""SerializedReference"",""apiVersion"":""v1"",""reference"":{""kind"":""ReplicaSet"",""namespace"":""default"",""name"":""npaqit-service-2193241535"",""uid"":""2e3d351c-acf1-11e7-9138-005056...
Status:         Running
IP:             10.244.3.30
Created By:     ReplicaSet/npaqit-service-2193241535
Controlled By:  ReplicaSet/npaqit-service-2193241535
Containers:
  npaqit-service:
    Container ID:       docker://dd6e7226ba757f310051645129bf2650bb537da219abba16113492143d3ba637
    Image:              dockerdtrtest.toyota-europe.com/toyota/npaqit:2.5
    Image ID:           docker-pullable://dockerdtrtest.toyota-europe.com/toyota/npaqit@sha256:d216922feb0a625e282b50bc2a5582bb6f4336262c45eebb57142eae97d1794a
    Port:               <none>
    State:              Running
      Started:          Mon, 09 Oct 2017 14:55:55 +0200
    Ready:              True
    Restart Count:      0
    Environment:
      ENVIRONMENT:      uat
      SERVICE_NAME:     npaqit
    Mounts:
      /opt/apps-logs from volume-appslogs (rw)
      /opt/data/npaa from volume-npaa (rw)
      /opt/secrets from admin-confidential (ro)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-5mzdh (ro)
Conditions:
  Type          Status
  Initialized   True 
  Ready         True 
  PodScheduled  True 
Volumes:
  volume-appslogs:
    Type:       HostPath (bare host directory volume)
    Path:       /opt/apps-logs
  volume-npaa:
    Type:       HostPath (bare host directory volume)
    Path:       /opt/data/npaa
  admin-confidential:
    Type:       Secret (a volume populated by a Secret)
    SecretName: npaqit-admin-confidential
    Optional:   false
  default-token-5mzdh:
    Type:       Secret (a volume populated by a Secret)
    SecretName: default-token-5mzdh
    Optional:   false
QoS Class:      BestEffort
Node-Selectors: <none>
Tolerations:    node.alpha.kubernetes.io/notReady:NoExecute for 300s
                node.alpha.kubernetes.io/unreachable:NoExecute for 300s
Events:
  FirstSeen     LastSeen        Count   From                    SubObjectPath                   Type            Reason                  Message
  ---------     --------        -----   ----                    -------------                   --------        ------                  -------
  22m           22m             1       default-scheduler                                       Normal          Scheduled               Successfully assigned npaqit-service-2193241535-8f3x6 to lxdocapt14
  22m           22m             1       kubelet, lxdocapt14                                     Normal          SuccessfulMountVolume   MountVolume.SetUp succeeded for volume ""volume-npaa"" 
  22m           22m             1       kubelet, lxdocapt14                                     Normal          SuccessfulMountVolume   MountVolume.SetUp succeeded for volume ""volume-appslogs"" 
  22m           22m             1       kubelet, lxdocapt14                                     Normal          SuccessfulMountVolume   MountVolume.SetUp succeeded for volume ""admin-confidential"" 
  22m           22m             1       kubelet, lxdocapt14                                     Normal          SuccessfulMountVolume   MountVolume.SetUp succeeded for volume ""default-token-5mzdh"" 
  22m           22m             1       kubelet, lxdocapt14     spec.containers{npaqit-service} Normal          Pulled                  Container image ""dockerdtrtest.toyota-europe.com/toyota/npaqit:2.5"" already present on machine
  22m           22m             1       kubelet, lxdocapt14     spec.containers{npaqit-service} Normal          Created                 Created container
  22m           22m             1       kubelet, lxdocapt14     spec.containers{npaqit-service} Normal          Started                 Started container

**docker inspect dd6e7226ba75**
[
    {
        ""Id"": ""dd6e7226ba757f310051645129bf2650bb537da219abba16113492143d3ba637"",
        ""Created"": ""2017-10-09T12:55:53.512971109Z"",
        ""Path"": ""/docker-entrypoint.bash"",
        ""Args"": [
            ""java"",
            ""-jar"",
            ""/opt/jetty/start.jar""
        ],
        ""State"": {
            ""Status"": ""running"",
            ""Running"": true,
            ""Paused"": false,
            ""Restarting"": false,
            ""OOMKilled"": false,
            ""Dead"": false,
            ""Pid"": 15345,
            ""ExitCode"": 0,
            ""Error"": """",
            ""StartedAt"": ""2017-10-09T12:55:55.589943142Z"",
            ""FinishedAt"": ""0001-01-01T00:00:00Z""
        },
        ""Image"": ""sha256:f937f9fd70a140d8c9a1d806a998a5444d9ac50ba659f00c4a5e16502ced8c95"",
        ""ResolvConfPath"": ""/var/lib/docker/containers/8bdcbe05986ac06eff4c70720cd252706acd744b4c6e6e289007abf5d6104e07/resolv.conf"",
        ""HostnamePath"": ""/var/lib/docker/containers/8bdcbe05986ac06eff4c70720cd252706acd744b4c6e6e289007abf5d6104e07/hostname"",
        ""HostsPath"": ""/var/lib/kubelet/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/etc-hosts"",
        ""LogPath"": ""/var/lib/docker/containers/dd6e7226ba757f310051645129bf2650bb537da219abba16113492143d3ba637/dd6e7226ba757f310051645129bf2650bb537da219abba16113492143d3ba637-json.log"",
        ""Name"": ""/k8s_npaqit-service_npaqit-service-2193241535-8f3x6_default_2e3e59dd-acf1-11e7-9138-005056800b9d_0"",
        ""RestartCount"": 0,
        ""Driver"": ""devicemapper"",
        ""MountLabel"": """",
        ""ProcessLabel"": """",
        ""AppArmorProfile"": """",
        ""ExecIDs"": null,
        ""HostConfig"": {
            ""Binds"": [
                ""/opt/apps-logs:/opt/apps-logs"",
                ""/opt/data/npaa:/opt/data/npaa"",
                ""/var/lib/kubelet/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/volumes/kubernetes.io~secret/admin-confidential:/opt/secrets:ro"",
                ""/var/lib/kubelet/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/volumes/kubernetes.io~secret/default-token-5mzdh:/var/run/secrets/kubernetes.io/serviceaccount:ro"",
                ""/var/lib/kubelet/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/etc-hosts:/etc/hosts"",
                ""/var/lib/kubelet/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/containers/npaqit-service/8dec9878:/dev/termination-log""
            ],
            ""ContainerIDFile"": """",
            ""LogConfig"": {
                ""Type"": ""json-file"",
                ""Config"": {}
            },
            ""NetworkMode"": ""container:8bdcbe05986ac06eff4c70720cd252706acd744b4c6e6e289007abf5d6104e07"",
            ""PortBindings"": null,
            ""RestartPolicy"": {
                ""Name"": """",
                ""MaximumRetryCount"": 0
            },
            ""AutoRemove"": false,
            ""VolumeDriver"": """",
            ""VolumesFrom"": null,
            ""CapAdd"": null,
            ""CapDrop"": null,
            ""Dns"": null,
            ""DnsOptions"": null,
            ""DnsSearch"": null,
            ""ExtraHosts"": null,
            ""GroupAdd"": null,
            ""IpcMode"": ""container:8bdcbe05986ac06eff4c70720cd252706acd744b4c6e6e289007abf5d6104e07"",
            ""Cgroup"": """",
            ""Links"": null,
            ""OomScoreAdj"": 1000,
            ""PidMode"": ""container:8bdcbe05986ac06eff4c70720cd252706acd744b4c6e6e289007abf5d6104e07"",
            ""Privileged"": false,
            ""PublishAllPorts"": false,
            ""ReadonlyRootfs"": false,
            ""SecurityOpt"": [
                ""seccomp=unconfined""
            ],
            ""UTSMode"": """",
            ""UsernsMode"": """",
            ""ShmSize"": 67108864,
            ""Runtime"": ""runc"",
            ""ConsoleSize"": [
                0,
                0
            ],
            ""Isolation"": """",
            ""CpuShares"": 2,
            ""Memory"": 0,
            ""NanoCpus"": 0,
            ""CgroupParent"": ""/kubepods/besteffort/pod2e3e59dd-acf1-11e7-9138-005056800b9d"",
            ""BlkioWeight"": 0,
            ""BlkioWeightDevice"": null,
            ""BlkioDeviceReadBps"": null,
            ""BlkioDeviceWriteBps"": null,
            ""BlkioDeviceReadIOps"": null,
            ""BlkioDeviceWriteIOps"": null,
            ""CpuPeriod"": 0,
            ""CpuQuota"": 0,
            ""CpuRealtimePeriod"": 0,
            ""CpuRealtimeRuntime"": 0,
            ""CpusetCpus"": """",
            ""CpusetMems"": """",
            ""Devices"": [],
            ""DiskQuota"": 0,
            ""KernelMemory"": 0,
            ""MemoryReservation"": 0,
            ""MemorySwap"": 0,
            ""MemorySwappiness"": -1,
            ""OomKillDisable"": false,
            ""PidsLimit"": 0,
            ""Ulimits"": null,
            ""CpuCount"": 0,
            ""CpuPercent"": 0,
            ""IOMaximumIOps"": 0,
            ""IOMaximumBandwidth"": 0
        },
        ""GraphDriver"": {
            ""Name"": ""devicemapper"",
            ""Data"": {
                ""DeviceId"": ""8103"",
                ""DeviceName"": ""docker-251:0-264590-5b4f9f315a9a70957ea2468813b7c97d249f44d86281593b6551e3b5b6ac13ba"",
                ""DeviceSize"": ""10737418240""
            }
        },
        ""Mounts"": [
            {
                ""Type"": ""bind"",
                ""Source"": ""/opt/apps-logs"",
                ""Destination"": ""/opt/apps-logs"",
                ""Mode"": """",
                ""RW"": true,
                ""Propagation"": """"
            },
            {
                ""Type"": ""bind"",
                ""Source"": ""/opt/data/npaa"",
                ""Destination"": ""/opt/data/npaa"",
                ""Mode"": """",
                ""RW"": true,
                ""Propagation"": """"
            },
            {
                ""Type"": ""bind"",
                ""Source"": ""/var/lib/kubelet/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/volumes/kubernetes.io~secret/admin-confidential"",
                ""Destination"": ""/opt/secrets"",
                ""Mode"": ""ro"",
                ""RW"": false,
                ""Propagation"": """"
            },
            {
                ""Type"": ""bind"",
                ""Source"": ""/var/lib/kubelet/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/volumes/kubernetes.io~secret/default-token-5mzdh"",
                ""Destination"": ""/var/run/secrets/kubernetes.io/serviceaccount"",
                ""Mode"": ""ro"",
                ""RW"": false,
                ""Propagation"": """"
            },
            {
                ""Type"": ""bind"",
                ""Source"": ""/var/lib/kubelet/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/etc-hosts"",
                ""Destination"": ""/etc/hosts"",
                ""Mode"": """",
                ""RW"": true,
                ""Propagation"": """"
            },
            {
                ""Type"": ""bind"",
                ""Source"": ""/var/lib/kubelet/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/containers/npaqit-service/8dec9878"",
                ""Destination"": ""/dev/termination-log"",
                ""Mode"": """",
                ""RW"": true,
                ""Propagation"": """"
            }
        ],
        ""Config"": {
            ""Hostname"": ""npaqit-service-2193241535-8f3x6"",
            ""Domainname"": """",
            ""User"": ""jetty"",
            ""AttachStdin"": false,
            ""AttachStdout"": false,
            ""AttachStderr"": false,
            ""ExposedPorts"": {
                ""8080/tcp"": {}
            },
            ""Tty"": false,
            ""OpenStdin"": false,
            ""StdinOnce"": false,
            ""Env"": [
                ""ENVIRONMENT=uat"",
                ""SERVICE_NAME=npaqit"",
                ""KUBERNETES_SERVICE_PORT=443"",
                ""KUBERNETES_SERVICE_PORT_HTTPS=443"",
                ""KUBERNETES_PORT=tcp://10.96.0.1:443"",
                ""KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443"",
                ""KUBERNETES_PORT_443_TCP_PROTO=tcp"",
                ""KUBERNETES_PORT_443_TCP_PORT=443"",
                ""KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1"",
                ""KUBERNETES_SERVICE_HOST=10.96.0.1"",
                ""PATH=/opt/jetty/bin:/opt/jdk8/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"",
                ""REFRESHED_AT=2017-09-04"",
                ""http_proxy=150.45.87.133:8080"",
                ""https_proxy=150.45.87.133:8080"",
                ""JAVA_HOME=/opt/jdk8"",
                ""JETTY_HOME=/opt/jetty"",
                ""JETTY_VERSION=9.3.21.v20170918"",
                ""JETTY_TGZ_URL=https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-distribution/9.3.21.v20170918/jetty-distribution-9.3.21.v20170918.tar.gz"",
                ""JETTY_GPG_KEYS=AED5EE6C45D0FE8D5D1B164F27DED4BF6216DB8F \t2A684B57436A81FA8706B53C61C3351A438A3B7D \t5989BAF76217B843D66BE55B2D0E1FB8FE4B68B4 \tB59B67FD7904984367F931800818D9D68FB67BAC \tBFBB21C246D7776836287A48A04E0C74ABB35FEA \t8B096546B1A8F02656B15D3B1677D141BCF3584D \tFBA2B18D238AB852DF95745C76157BDF03D0DCD6 \t5C9579B3DB2E506429319AAEF33B071B29559E1E"",
                ""JETTY_BASE=/opt/jetty-toyota"",
                ""TMPDIR=/tmp/jetty""
            ],
            ""Cmd"": [
                ""java"",
                ""-jar"",
                ""/opt/jetty/start.jar""
            ],
            ""ArgsEscaped"": true,
            ""Image"": ""dockerdtrtest.toyota-europe.com/toyota/npaqit@sha256:d216922feb0a625e282b50bc2a5582bb6f4336262c45eebb57142eae97d1794a"",
            ""Volumes"": null,
            ""WorkingDir"": ""/opt/jetty-toyota"",
            ""Entrypoint"": [
                ""/docker-entrypoint.bash""
            ],
            ""OnBuild"": null,
            ""Labels"": {
                ""annotation.io.kubernetes.container.hash"": ""3aae2497"",
                ""annotation.io.kubernetes.container.restartCount"": ""0"",
                ""annotation.io.kubernetes.container.terminationMessagePath"": ""/dev/termination-log"",
                ""annotation.io.kubernetes.container.terminationMessagePolicy"": ""File"",
                ""annotation.io.kubernetes.pod.terminationGracePeriod"": ""30"",
                ""io.kubernetes.container.logpath"": ""/var/log/pods/2e3e59dd-acf1-11e7-9138-005056800b9d/npaqit-service_0.log"",
                ""io.kubernetes.container.name"": ""npaqit-service"",
                ""io.kubernetes.docker.type"": ""container"",
                ""io.kubernetes.pod.name"": ""npaqit-service-2193241535-8f3x6"",
                ""io.kubernetes.pod.namespace"": ""default"",
                ""io.kubernetes.pod.uid"": ""2e3e59dd-acf1-11e7-9138-005056800b9d"",
                ""io.kubernetes.sandbox.id"": ""8bdcbe05986ac06eff4c70720cd252706acd744b4c6e6e289007abf5d6104e07""
            }
        },
        ""NetworkSettings"": {
            ""Bridge"": """",
            ""SandboxID"": """",
            ""HairpinMode"": false,
            ""LinkLocalIPv6Address"": """",
            ""LinkLocalIPv6PrefixLen"": 0,
            ""Ports"": null,
            ""SandboxKey"": """",
            ""SecondaryIPAddresses"": null,
            ""SecondaryIPv6Addresses"": null,
            ""EndpointID"": """",
            ""Gateway"": """",
            ""GlobalIPv6Address"": """",
            ""GlobalIPv6PrefixLen"": 0,
            ""IPAddress"": """",
            ""IPPrefixLen"": 0,
            ""IPv6Gateway"": """",
            ""MacAddress"": """",
            ""Networks"": {}
        }
    }
]

What can be the issue

Regards

",closed,False,2017-10-09 14:55:08,2017-10-19 06:20:08
dns,rramkumar1,https://github.com/kubernetes/dns/pull/157,https://api.github.com/repos/kubernetes/dns/issues/157,Dns probe metric refactor,,closed,True,2017-10-09 15:28:20,2017-10-10 20:17:28
dns,cjcullen,https://github.com/kubernetes/dns/issues/158,https://api.github.com/repos/kubernetes/dns/issues/158,Alternative to dnsmasq?,"Should we replace dnsmasq w/ something memory safe?

Following up on the CVE-2017-14491 discussion, we should think about what it would take to replace dnsmasq.",closed,False,2017-10-10 17:42:18,2018-01-31 16:22:45
dns,lghinet,https://github.com/kubernetes/dns/issues/159,https://api.github.com/repos/kubernetes/dns/issues/159,<namespace>.svc.cluster.local. duplicated ,"dns not found because kafka-cluster.svc.cluster.local appear twice 
any ideas 

thanks 

```
I1013 11:24:46.558591       1 dns.go:581] Query for ""zk-1.zk-svc.kafka-cluster.svc.cluster.local.kafka-cluster.svc.cluster.local."", exact: false
I1013 11:24:46.558687       1 dns.go:810] Not a federation query: len([""zk-1"" ""zk-svc"" ""kafka-cluster"" ""svc"" ""cluster"" ""local"" ""kafka-cluster"" ""svc"" ""cluster"" ""local""]) != 4+len([""local"" ""cluster""])
I1013 11:24:46.558743       1 dns.go:701] Found 0 records for [local cluster svc kafka-cluster local cluster svc kafka-cluster zk-svc zk-1] in the cache
I1013 11:24:46.558779       1 dns.go:708] getRecordsForPath retval=[], path=[local cluster svc kafka-cluster local cluster svc kafka-cluster zk-svc zk-1]
I1013 11:24:46.558792       1 dns.go:614] No record found for zk-1.zk-svc.kafka-cluster.svc.cluster.local.kafka-cluster.svc.cluster.local.
```",closed,False,2017-10-13 11:31:24,2018-03-13 22:57:01
dns,felipejfc,https://github.com/kubernetes/dns/issues/160,https://api.github.com/repos/kubernetes/dns/issues/160,DNSMasq cache has low cache hit rate for some reason,"Hi, I'm running a k8s cluster in production with ~ 60 nodes, it has 870 pods on it.

Currently, 40 of these pods are kube-dns pods, each with 150m requests of CPU. (Yes, I had to scale it a lot)

I'm currently trying to figure out why I do need so much of them, one thing that I did today was to take a look at prometheus metrics exposed by the sidecar container and observed that:

![image](https://user-images.githubusercontent.com/285782/32076090-8c25fd48-ba7d-11e7-92a5-d0a3fa7e347c.png)

The ratio between hits/total number of requests is too low (around 21%), any hints on why it is too low? seeing dnsmasq requests it seems that some of the addresses it is resolving are never being cached for some reason.

just for reference, this is the number of requests that kubedns is receiving per minute (I guess)

![image](https://user-images.githubusercontent.com/285782/32076044-64673498-ba7d-11e7-8779-e4f30d29f46d.png)
",closed,False,2017-10-26 21:42:43,2018-05-21 12:54:11
dns,spiffxp,https://github.com/kubernetes/dns/pull/161,https://api.github.com/repos/kubernetes/dns/issues/161,Rename OWNERS assignees: to approvers:,"They are effectively the same, assignees is deprecated

ref: kubernetes/test-infra#3851",closed,True,2017-10-31 23:24:11,2017-11-01 02:49:08
dns,feiskyer,https://github.com/kubernetes/dns/issues/162,https://api.github.com/repos/kubernetes/dns/issues/162,Release notes,"There is no release notes for every releases, and no CHANGELOG either. Should add them for easily tracking changes for each release.

cc @bowei @thockin ",closed,False,2017-11-02 02:41:51,2018-04-01 05:07:52
dns,weiwei04,https://github.com/kubernetes/dns/pull/163,https://api.github.com/repos/kubernetes/dns/issues/163,set user-agent,"set user-agent for client-go

before

```
client=""kube-dns/v0.0.0 (linux/amd64) kubernetes/$Format""
```

after

```
client=""kube-dns/1.14.4-2-g5584e04""
```

Signed-off-by: Wei Wei <weiwei.inf@gmail.com>",closed,True,2017-11-07 11:05:55,2017-11-09 05:26:04
dns,SchoIsles,https://github.com/kubernetes/dns/issues/164,https://api.github.com/repos/kubernetes/dns/issues/164,can add PTR & A record support for pod in deployment?,"In my case, some services(mysql) is out of k8s cluster,  applications in cluster access the service need a authorization.

With pod's ip is not static and continuously, cant't grant privileges to a CIDR subnet.
So I wan't to grant to a wild domain, looks like `*.<service>.<namespace>.svc.<domain>`, all pod in this service will be granted by dns reverse.

now I tested on headless service & statefulset, all pod with name `<set-name>-{id}` has an A record, and this pod's ip has a PTR record.

But pod in deployments doesn't have a hostname field, can't be resolved",closed,False,2017-11-09 13:54:34,2018-04-11 15:42:59
dns,MOZGIII,https://github.com/kubernetes/dns/issues/165,https://api.github.com/repos/kubernetes/dns/issues/165,Insecure downloads in dnsmasq Makefile,"Found this: https://github.com/kubernetes/dns/blob/7d0bfdc04b9a1f659becb7b184f53b1df7c996de/images/dnsmasq/Makefile#L49
Plus there's no hashsum for file integrity checking after download.

Not sure how relevan it is to this project, but it's bad practice in general.
What do you think? I'd say this has to be taken seriously and fixed by adding a hashsum near the `DNSMASQ_VERSION` var.",closed,False,2017-11-12 03:03:51,2018-03-26 21:22:13
dns,stewart-yu,https://github.com/kubernetes/dns/issues/166,https://api.github.com/repos/kubernetes/dns/issues/166,"the `kube-apiserver.log `have the literal string ""(dollar_sign)Format"" ","When i set up cluster with local up, the `kube-apiserver.log `have the literal string ""(dollar_sign)Format"" ,look like that:
```
I1113 10:09:54.443872   68028 wrap.go:42] GET /api/v1/services?resourceVersion=136&timeoutSeconds=355&watch=true: (5m55.000894913s) 200 [[kube-dns/v1.6.7 (linux/amd64) kubernetes/$Format] 172.17.0.2:58794]
I1113 10:12:05.443724   68028 wrap.go:42] GET /api/v1/endpoints?resourceVersion=256&timeoutSeconds=486&watch=true: (8m6.00068201s) 200 [[kube-dns/v1.6.7 (linux/amd64) kubernetes/$Format] 172.17.0.2:58794]
I1113 10:16:27.446941   68028 wrap.go:42] GET /api/v1/services?resourceVersion=136&timeoutSeconds=393&watch=true: (6m33.002267473s) 200 [[kube-dns/v1.6.7 (linux/amd64) kubernetes/$Format] 172.17.0.2:58794]
```
I think it related to `kube-dns` images, does anyone can help me to fix it?",closed,False,2017-11-13 07:19:52,2017-11-13 08:02:38
dns,wu8685,https://github.com/kubernetes/dns/pull/167,https://api.github.com/repos/kubernetes/dns/issues/167,enable skyDNS round robin A/AAAA records,"After issue #116 fixed, I hope we can enable skyDNS round robin to support load balance for headless service.",closed,True,2017-11-20 11:56:13,2019-03-11 11:30:27
dns,bboreham,https://github.com/kubernetes/dns/pull/168,https://api.github.com/repos/kubernetes/dns/issues/168,Better buckets for DNS probe latency,"Use exponential-sized buckets and start at a much lower interval: instead of 500 buckets from 10ms to 500ms, use 16 buckets from 0.25ms to 8 seconds.  Much more precise data with 30 times less storage.

Fixes #149 

From an offline conversation with one of the Prometheus maintainers I am told that changing the bucket set will disrupt results for one averaging period, i.e. if you display `rate(...[5m])` then your chart will be wrong for the five minutes covering the change.  But with a minimum resolution of 10ms the old data is only useful when your DNS is a bit broken, so I think this one-time loss is OK.",closed,True,2017-11-28 12:16:13,2018-01-08 17:15:59
dns,tuminoid,https://github.com/kubernetes/dns/issues/169,https://api.github.com/repos/kubernetes/dns/issues/169,kube-dns 1.14.7 does not resolve cluster services without external dns,"If host does not have working DNS nameserver in `/etc/resolv.conf`, kube-dns fails to resolve cluster services.

I created a single-machine k8s cluster (1.7.4, kube-dns 1.14.7) in a VM for a machine that has no internet/intranet connectivity for a hack lab. Thus, it has no working DNS on the host, but the DNS IP in the `/etc/resolv.conf` is blocked by firewall.

In this case, kube-dns fails to resolve any cluster service in any namespace, including `kube-dns` itself, unless queried using FQDN, `kube-dns.kube-system.svc.cluster.local`, despite `/etc/resolv.conf` in container pointing correctly to kube-dns, and containing correct `search` options (`kube-system.svc.cluster.local svc.cluster.local cluster.local`).",closed,False,2017-11-29 14:49:03,2019-01-13 07:47:48
dns,tuminoid,https://github.com/kubernetes/dns/issues/170,https://api.github.com/repos/kubernetes/dns/issues/170,kube-dns 1.14.7 fails to resolve cluster services with 2 search domains on host's resolv.conf,"If host does have two `search` domains in `/etc/resolv.conf`, kube-dns fails to resolve cluster services.

I created a single-machine k8s cluster (1.7.4, kube-dns 1.14.7) in a OpenStack VM. This VM has `search localdomain openstacklocal` in `/etc/resolv.conf`.

In this case, kube-dns fails to resolve any cluster service in any namespace, including `kube-dns` itself, unless queried using FQDN, `kube-dns.kube-system.svc.cluster.local`, despite `/etc/resolv.conf` in container pointing correctly to kube-dns, and containing correct `search` options (`kube-system.svc.cluster.local svc.cluster.local cluster.local`).

If either search domain is removed from host, and kube-dns pod recreated, kube-dns starts immediately resolving cluster services correctly.",closed,False,2017-11-29 14:53:33,2018-04-28 17:25:06
dns,r7vme,https://github.com/kubernetes/dns/issues/171,https://api.github.com/repos/kubernetes/dns/issues/171,kube-dns can stuck,"Hello, we are using kube-dns 1.14.5 in 3 replicas. Recently we saw that one replica stuck for 2 days and did not update dnsmasq config. So 1/3 of our dns requests were responede with outdated ip address for service. As workaround we restarted this replica.

Stalled pod had latest logs from Nov. 27. 
```
E1127 20:32:25.274991       1 reflector.go:199] k8s.io/dns/vendor/k8s.io/client-go/tools/cache/reflector.go:94: Failed to list *v1.Endpoints: Get https://api.1htkh.g8s.kc.cg.internal/api/v1/endpoints?resourceVersion=0: EOF
E1127 20:32:26.074275       1 reflector.go:199] k8s.io/dns/vendor/k8s.io/client-go/tools/cache/reflector.go:94: Failed to list *v1.Service: Get https://api.1htkh.g8s.kc.cg.internal/api/v1/services?resourceVersion=0: EOF
E1127 20:32:26.278864       1 reflector.go:199] k8s.io/dns/vendor/k8s.io/client-go/tools/cache/reflector.go:94: Failed to list *v1.Endpoints: Get https://api.1htkh.g8s.kc.cg.internal/api/v1/endpoints?resourceVersion=0: EOF
```

Here is the [kube-dns deployment](https://pastebin.com/W5rvLVXK).

For context, k8s-apiserver was restarted few times and can be unavailable. This is probably one of the causes of issue.

Do you have any idea why pod can just stuck?",closed,False,2017-11-29 14:54:52,2018-04-28 16:24:06
dns,rramkumar1,https://github.com/kubernetes/dns/pull/172,https://api.github.com/repos/kubernetes/dns/issues/172,Metric refactor,"Refactor to use Prometheus Counter instead of Gauge for metrics defined in pkg/sidecar/metrics.go
Also adds a new test server_test.go in sidecar package.",closed,True,2017-11-29 20:01:04,2017-11-29 20:18:41
dns,rramkumar1,https://github.com/kubernetes/dns/pull/173,https://api.github.com/repos/kubernetes/dns/issues/173,Refactor to use Prometheus Counter instead of Gauge,Refactors package sidecar to use Prometheus Counters instead of Gauges. Metrics can be found in pkg/sidecar/metrics.go. Also adds a new test called server_test.go in package sidecar,closed,True,2017-11-29 20:16:43,2017-12-05 20:00:33
dns,seh,https://github.com/kubernetes/dns/issues/174,https://api.github.com/repos/kubernetes/dns/issues/174,Pods and headless Services don't get DNS A records without at least one service port,"# Observation
Per [earlier discussion](https://github.com/kubernetes/dns/issues/70#issuecomment-339064124) in #70, [the documentation for _kube-dns_ says](https://github.com/kubernetes/website/blame/master/docs/concepts/services-networking/dns-pod-service.md#L109) that it will publish A records for pods so long as a headless _Service_ named with the same subdomain exists in the same namespace. However, if the _Service_ has no ports, _kube-dns_ publishes no such records.

What follows is an example to demonstrate this discrepancy.

# Example
We create the following objects in a given namespace:
- A headless _Service_ named ""sub""  
  Initially, the _Service_ exposes one port with value 80 and called ""nonexistent,"" since the image used here doesn't have any servers listening, to point out that it doesn't matter whether the advertised port actually allows connecting to anything insider the container.
- Some number of pods.  
  Though a single pod is sufficient, here we create three pods selected by the aforementioned _Service_, each with a single container running the _busybox_ image, each also situated within the subdomain ""sub,"" matching the name of the _Service_:
  - _busybox-1_
  - _busybox-2_
  - _busybox-3_
```yaml
apiVersion: v1
kind: List
items:
- apiVersion: v1
  kind: Pod
  metadata: &metadata
    name: busybox-1
    labels:
      app: &app busybox
  spec: &spec
    hostname: host-1
    subdomain: &subdomain sub
    containers:
    - name: busybox
      image: busybox
      command:
      - sleep
      - ""3600""
- apiVersion: v1
  kind: Pod
  metadata:
    <<: *metadata
    name: busybox-2
  spec:
    <<: *spec
    hostname: host-2
- apiVersion: v1
  kind: Pod
  metadata:
    <<: *metadata
    name: busybox-3
  spec:
    <<: *spec
    hostname: host-3
- apiVersion: v1
  kind: Service
  metadata:
    name: *subdomain
  spec:
    clusterIP: None
    selector:
      app: *app
    ports:
    # NB: Here the Service has at least one port.
    - name: nonexistent
      port: 80
```
Assuming that YAML document is available in a file called _manifests.yaml_, create these objects in some namespace:
```shell
kubectl apply -f manifests.yaml
```
Now run a container using an image with _dig_ available in that same namespace, probing first for DNS A records for our subdomain ""sub"":
```shell
kubectl run dig --image=tutum/dnsutils \
  --restart=Never --rm=true --tty --stdin --command -- \
  dig sub a +search +noall +answer
; <<>> DiG 9.10.2 <<>> sub a +search +noall +answer
;; global options: +cmd
sub.my-ns.svc.cluster.local. 30	IN A	172.30.48.142
sub.my-ns.svc.cluster.local. 30	IN A	172.30.48.83
sub.my-ns.svc.cluster.local. 30	IN A	172.30.98.82
```
Next, confirm that records exist for all three of our pod host names:
```shell
for i in $(seq 3); do \
  kubectl run dig --image=tutum/dnsutils \
    --restart=Never --rm=true --tty --stdin --command -- \
    dig ""host-${i}.sub"" a +search +noall +answer \
done
; <<>> DiG 9.10.2 <<>> host-1.sub a +search +noall +answer
;; global options: +cmd
host-1.sub.my-ns.svc.cluster.local. 30 IN A 172.30.98.82
; <<>> DiG 9.10.2 <<>> host-2.sub a +search +noall +answer
;; global options: +cmd
host-2.sub.my-ns.svc.cluster.local. 30 IN A 172.30.48.83
; <<>> DiG 9.10.2 <<>> host-3.sub a +search +noall +answer
;; global options: +cmd
host-3.sub.my-ns.svc.cluster.local. 30 IN A 172.30.48.142
```
Next, amend the _Service_ ""sub"" to remove all of its service ports:
```yaml
apiVersion: v1
kind: Service
metadata:
  name: *subdomain
spec:
  clusterIP: None
  selector:
    app: *app
  ports:
  # NB: Here the Service has no ports.
```
With that change applied, we repeat our earlier invocations of _dig_:
```shell
kubectl run dig --image=tutum/dnsutils \
  --restart=Never --rm=true --tty --stdin --command -- \
  dig sub a +search +noall +answer
; <<>> DiG 9.10.2 <<>> sub a +search +noall +answer
;; global options: +cmd
for i in $(seq 3); do \
  kubectl run dig --image=tutum/dnsutils \
    --restart=Never --rm=true --tty --stdin --command -- \
    dig ""host-${i}.sub"" a +search +noall +answer \
done
; <<>> DiG 9.10.2 <<>> host-1.sub a +search +noall +answer
;; global options: +cmd
; <<>> DiG 9.10.2 <<>> host-2.sub a +search +noall +answer
;; global options: +cmd
; <<>> DiG 9.10.2 <<>> host-3.sub a +search +noall +answer
;; global options: +cmd
```
Note there how there are no DNS A records available for the _Service_ or any of the pods it selects.

# Cause
Why is this so? In method `(*KubeDNS.generateRecordsForHeadlessService)`, it [iterates over the `Endpoints.Subsets` sequence](https://github.com/kubernetes/dns/blob/b519b7983f931ccd7f5fa6a92a5be416abdf10c6/pkg/dns/dns.go#L484-L510), which is only populated for ports that exist on the related _Service_ object. If the _Service_ defines no ports, the _Endpoints_ object has no subsets for any of the selected pods.
```shell
kubectl get endpoints sub --output=jsonpath='{.subsets}'
[]
```
So long as _kube-dns_ is implemented this way, we need a port to notice the pods backing the _Service_. Hence, we should either adjust the documentation to match the implementation's constraints, or reconsider the implementation (much harder, duplicating some of the monitoring and [filtering work done by the endpoints controller](https://github.com/kubernetes/kubernetes/blob/master/pkg/controller/endpoint/endpoints_controller.go#L567-L580)).

# Environment
```shell
kubectl version
Client Version: version.Info{Major:""1"", Minor:""8"", GitVersion:""v1.8.4"", GitCommit:""9befc2b8928a9426501d3bf62f72849d5cbcd5a3"", GitTreeState:""clean"", BuildDate:""2017-11-20T19:11:02Z"", GoVersion:""go1.9.2"", Compiler:""gc"", Platform:""darwin/amd64""}
Server Version: version.Info{Major:""1"", Minor:""7+"", GitVersion:""v1.7.4-30+6c97db85c5ab05"", GitCommit:""6c97db85c5ab0586c15be39b3e88c7a425b96947"", GitTreeState:""clean"", BuildDate:""2017-11-21T09:07:18Z"", GoVersion:""go1.8.3"", Compiler:""gc"", Platform:""linux/amd64""}
```",closed,False,2017-11-29 22:11:42,2018-08-22 14:21:59
dns,xiaosadexiaohai,https://github.com/kubernetes/dns/issues/175,https://api.github.com/repos/kubernetes/dns/issues/175,dns设置问题,"情况是这样的:有1个域名外网解析了指到外部ip,然后内部dns也解析指到内部ip,pods ping的时候有时候是外网有时候是内网,没有办法跟宿主机一致,老是跑到外网ip去
宿主机访问的情况下是这样的:
![image](https://user-images.githubusercontent.com/18409309/33474238-b2072e6c-d6b4-11e7-9ccf-dad1d68253ec.png)
容器访问这个域名情况是这样的:
![image](https://user-images.githubusercontent.com/18409309/33474251-c172c96a-d6b4-11e7-9c81-47f3326819b8.png)
环境:
k8s1.8.4
flannel
",closed,False,2017-12-01 08:29:42,2018-05-05 01:55:05
dns,woshihaoren,https://github.com/kubernetes/dns/issues/176,https://api.github.com/repos/kubernetes/dns/issues/176,"when cni use ipvlan plugin, can't work with kube-dns","container use  iptables nat to transfer traffic,when pod use ipvlan ,it can't use node iptables rules.

I think  kube-dns  use hostNetwork:true and scheduling to  specify nodes, let ip unchanged,
whole pods 's /etc/resolv.conf uses these ip.

Is it a good idea? 
Give me some advice.",closed,False,2017-12-03 08:32:39,2018-07-26 12:57:42
dns,rramkumar1,https://github.com/kubernetes/dns/issues/177,https://api.github.com/repos/kubernetes/dns/issues/177,Kube-dns uses workaround for Prometheus Counters ,"In order to stay compatible with Stackdriver API's, #173 made the change to start using Prometheus Counter instead of Gauge for dnsmasq metrics. In order to facilitate this change, some caching logic was introduced in order to ensure that the value set to the Counter was consistent with the way the Gauge set the value.

Once Prometheus provides support within the Counter API to set a value directly, stop using the caching logic introduced in #173. 

",closed,False,2017-12-05 19:53:24,2018-08-16 17:33:37
dns,tuminoid,https://github.com/kubernetes/dns/issues/178,https://api.github.com/repos/kubernetes/dns/issues/178,upstreamNameservers does not allow custom port number,"While debugging #169 I found out that `upstreamNameservers` in `kube-dns` configmap does not allow port numbers for upstream servers.

Port numbers are accepted if you give them as `--nameserver=server:port` argument for kube-dns container, but it would be nice to have them accepted via configmap as well.",closed,False,2017-12-12 06:40:24,2018-01-23 19:17:44
dns,lcfang,https://github.com/kubernetes/dns/pull/179,https://api.github.com/repos/kubernetes/dns/issues/179,delete some unused parameters,delete some unused parameters,closed,True,2017-12-12 08:56:23,2018-02-28 01:18:35
dns,kidiyoor,https://github.com/kubernetes/dns/issues/180,https://api.github.com/repos/kubernetes/dns/issues/180,can kubedns return non-cluster IP (endpoint IP),"Is there a standard way to setup a selector less service (or equivalent) so that kubedns return endpoint IP and not clusterIP.

Usecase bellow - 

If we use kubedns as DNS for istio mesh outside kubernetes. When envoy running in a VM makes a discovery call to pilot **ie** istio-pilot.istio-system.svc.cluster.local, kubedns can(possibly) return IP of VM that runs pilot.

Currently I have a selector less service for pilot and respective endpoint pointing to VM running pilot. But kubedns return cluster IP of the service(which is default behavior) but envoy can't reach pilot via cluster IP it needs VM IP.

More context on what I mean by running istio mesh outside kubernetes - 
Running Kube apiserver (backed with ETCD) standalone in a VM. 
Pointing pilot to talk to apiserver for configuration and service registry(optional).
Workload runs in bare VM. All workload registration in apiserver is via selectorless service and kube endpoints.",closed,False,2017-12-16 19:29:58,2017-12-20 20:32:09
dns,spiffxp,https://github.com/kubernetes/dns/pull/181,https://api.github.com/repos/kubernetes/dns/issues/181,Update code-of-conduct.md,"Refer to kubernetes/community as authoritative source for code of conduct

ref: kubernetes/community#1527",closed,True,2017-12-20 18:31:59,2018-01-08 19:13:42
dns,DaiHao,https://github.com/kubernetes/dns/issues/182,https://api.github.com/repos/kubernetes/dns/issues/182,dnsmasq container exists random port,"In dnsmasq container, it somtime opens a random port on listen , what does it use for?
",closed,False,2017-12-22 03:43:13,2018-01-02 13:50:16
dns,thockin,https://github.com/kubernetes/dns/pull/183,https://api.github.com/repos/kubernetes/dns/issues/183,Convert registry to k8s.gcr.io,"This PR was auto-generated.  Please apply human expertise to review for correctness.

Followup to https://github.com/kubernetes/kubernetes/pull/54174 and https://github.com/kubernetes/kubernetes/pull/57824

xref https://github.com/kubernetes/release/issues/281",closed,True,2017-12-22 18:01:22,2018-02-02 05:01:02
dns,thockin,https://github.com/kubernetes/dns/issues/184,https://api.github.com/repos/kubernetes/dns/issues/184,Spec allows for SRV on headless Services but not on individual hostnames.,"From our spec I observe:

We allow A lookups like ""pod2.hostnames.default.svc.cluster.local""
* pod.spec.hostname = pod2
* pod.spec.subdomain = hostnames
* pod.namespace = default

We allow SRV lookups like ""_http._tcp.hostnames.default.svc.cluster.local""
* service.spec.ports[0].name = http
* service.spec.ports[0].protocol = TCP
* pod.spec.subdomain = hostnames
* pod.namespace = default

We DO NOT allow SRV lookups like ""_http._tcp.pod2.hostnames.default.svc.cluster.local"" - this was somewhat surprising to me.  It sort of feels like any name we have an A record for, we should allow SRV records for, no?",closed,False,2017-12-28 20:06:26,2018-05-28 20:14:05
dns,rramkumar1,https://github.com/kubernetes/dns/pull/185,https://api.github.com/repos/kubernetes/dns/issues/185,Add validation for upstreamNameserver port,Fixes #178. Add validation for a port number for upstream nameservers specified in the config map.,closed,True,2018-01-02 23:41:11,2018-01-23 19:17:44
dns,thockin,https://github.com/kubernetes/dns/issues/186,https://api.github.com/repos/kubernetes/dns/issues/186,kube-dns returns NXDOMAIN when not yet synced with apiserver,"From https://github.com/kubernetes/kubernetes/issues/57111

**What happened**:
when kube-dns has not yet synced with the apiserver, it return NXDOMAIN for all cluster names

**What you expected to happen**:
It should return SERVFAIL

**Anything else we need to know?**:
NXDOMAIN is the wrong status. It even can be cached by downstream DNS servers.

**Environment**:
- Kubernetes version (use `kubectl version`): 1.8.4


@bowei @rramkumar1 @johnbelamaric ",closed,False,2018-01-03 00:57:15,2018-03-23 00:37:31
dns,tommyknows,https://github.com/kubernetes/dns/issues/187,https://api.github.com/repos/kubernetes/dns/issues/187,Unreachable Backend after changing backend,"Hi,
I've got a really weird issue with CoreDNS. I use it as a DNS for the federation, and set it up like described here:
https://github.com/ufcg-lsd/k8s-onpremise-federation#-deploy-coredns
I then created another etcd-backend, with the service-name ""etcd-dns-cluster-client.default"".
I can execute the following inside one of the containers of the etcd-cluster:
```
/ # etcdctl ls -r
/skydns
/skydns/local
/skydns/local/federation
/skydns/local/federation/svc
/skydns/local/federation/svc/federation
/skydns/local/federation/svc/federation/default
/skydns/local/federation/svc/federation/default/hello-world
/skydns/local/federation/svc/federation/default/hello-world/9502f681
...
```

My Corefile for the DNS server looks like this, after changing it to the new endpoint:
```
.:53 {
    cache 30
    errors stdout
    etcd federation.local., custom.domain. {
      path /skydns
      endpoint http://etcd-dns-cluster-client.default:2379
      debug
    }
    health
    loadbalance round_robin
    prometheus 0.0.0.0:9153
    proxy . /etc/resolv.conf
}
```

And getting a key from the etcd-server works (from inside the CoreDNS Container):
```
/ # wget http://etcd-dns-cluster-client.default:2379/v2/keys/skydns/local/federation/svc/federation/default/hello-world/9502f681
Connecting to etcd-dns-cluster-client.default:2379 (10.109.101.247:2379)
9502f681             100% |*******************************************************************************************************************************************************************************************************************************|   258   0:00:00 ETA
/ # cat 9502f681 
{""action"":""get"",""node"":{""key"":""/skydns/local/federation/svc/federation/default/hello-world/9502f681"",""value"":""{\""host\"":\""192.168.1.129\"",\""ttl\"":180,\""group\"":\""hello-world.default.federation.svc.federation.local.\""}"",""modifiedIndex"":30,""createdIndex"":30}}
```

However, when trying to resolve a hostname:
```
# dig -p 32680 @192.168.1.41 hello-world.default.federation.svc.federation.local.

; <<>> DiG 9.10.3-P4-Ubuntu <<>> -p 32680 @192.168.1.41 hello-world.default.federation.svc.federation.local.
; (1 server found)
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: SERVFAIL, id: 45817
;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1
;; WARNING: recursion requested but not available

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;hello-world.default.federation.svc.federation.local. IN	A

;; Query time: 0 msec
;; SERVER: 192.168.1.41#32680(192.168.1.41)
;; WHEN: Wed Jan 03 15:20:14 UTC 2018
;; MSG SIZE  rcvd: 8
```

And the logfile of the CoreDNS Container contains the following line (multiple times):
```
03/Jan/2018:15:20:14 +0000 [ERROR 2 hello-world.default.federation.svc.federation.local. A] unreachable backend: no upstream host
```

Some help would be greatly appreciated, as I do not know how to debug this further.",closed,False,2018-01-03 15:24:21,2018-05-07 11:02:36
dns,adriancooney,https://github.com/kubernetes/dns/pull/188,https://api.github.com/repos/kubernetes/dns/issues/188,Ignore.,Send metrics to Datadog rather than updating Prometheus endpoints.,closed,True,2018-01-11 12:13:29,2018-01-11 14:07:22
dns,relyt0925,https://github.com/kubernetes/dns/issues/189,https://api.github.com/repos/kubernetes/dns/issues/189,Question: Kube DNS Behavior when api server is down for extended period of time,"In our managed Kuberentes offering, customers have been reporting that DNS resolution fails when the API server goes down for an extended period of time (1-2 minutes). I thought Kube DNS will keep the current cached values for all it's DNS entries until it can successfully update the entries after contacting the API Server. 

This issue is just a question: What is the behavior of kube dns when the API Server is down for an extended period of time? Will it keep the snapshot of all the DNS entries it has currently and continue to resolve requests successfully or will the entries expire and all DNS resolutions will fail?",closed,False,2018-01-20 18:41:18,2018-02-04 02:36:28
dns,diegs,https://github.com/kubernetes/dns/issues/190,https://api.github.com/repos/kubernetes/dns/issues/190,kube-dns cannot run as non-root user,"I attempted to run kube-dns as a non-root user by modifying the example YAML files to:

- have dnsmasq serve on a high port using the `--port` flag
- fix the service to point at the high port
- add a non-root security context to the pod

This seems like it would be sufficient, but then I found that there are several hard-coded assumptions in the container image that dnsmasq will run as root:

https://github.com/kubernetes/dns/blob/master/images/dnsmasq/Dockerfile.cross
https://github.com/kubernetes/dns/blob/master/images/dnsmasq/dnsmasq.conf

Unless there is a strong reason why dnsmasq needs to run as root, I think it would be a better practice to run it as non-root.",closed,False,2018-01-23 21:15:20,2018-09-28 14:58:55
dns,langyenan,https://github.com/kubernetes/dns/pull/191,https://api.github.com/repos/kubernetes/dns/issues/191,"Support DNS A record in the form of ""podName.namespace.pod.cluster.local""","This PR assigns a DNS A record for EVERY Pod in the form of ""podName.namespace.pod.cluster.local"" without needing of service.

**Special notes for your reviewer**:
Before this PR, every pod has a DNS entry based on pod IP, which is kind of inconvenient. (why would I use DNS if I already know other's IP)

**Release note**:
```release-note
assign a DNS A record for EVERY Pod in the form of ""podName.namespace.pod.cluster.local"" without needing of service.
``` ",closed,True,2018-01-25 12:31:17,2018-02-01 07:34:29
dns,oilbeater,https://github.com/kubernetes/dns/pull/192,https://api.github.com/repos/kubernetes/dns/issues/192,reduce binary size,"remove symbol tables and debug info to reduce binary size, see https://golang.org/cmd/link/",closed,True,2018-01-29 15:34:47,2018-03-26 15:22:59
dns,oilbeater,https://github.com/kubernetes/dns/pull/193,https://api.github.com/repos/kubernetes/dns/issues/193,update go version to 1.9.3,As kubernetes already updated to 1.9.3,closed,True,2018-02-01 09:12:03,2018-02-06 00:41:18
dns,Nefelim4ag,https://github.com/kubernetes/dns/pull/194,https://api.github.com/repos/kubernetes/dns/issues/194,Replace sha1 hash with ~x5 faster spooky hash,"Time for hashing 100000 Int s
sha1:  44.198325ms
spooky:  7.308553ms",closed,True,2018-02-05 15:47:50,2018-02-06 12:12:47
dns,Stono,https://github.com/kubernetes/dns/issues/195,https://api.github.com/repos/kubernetes/dns/issues/195,kube-dns crashing on GKE 1.9.2 (panic: counter cannot decrease in value),"See the title really, the sidecar pod is crashing every few minutes on the recent release GKE 1.9.2 release:

```
❯ kks logs kube-dns-6cdf767cb8-ht7fr -p sidecar
I0208 20:59:53.889088       1 main.go:51] Version v1.14.8
I0208 20:59:53.889223       1 server.go:45] Starting server (options {DnsMasqPort:53 DnsMasqAddr:127.0.0.1 DnsMasqPollIntervalMs:5000 Probes:[{Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33} {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33}] PrometheusAddr:0.0.0.0 PrometheusPort:10054 PrometheusPath:/metrics PrometheusNamespace:kubedns})
I0208 20:59:53.889281       1 dnsprobe.go:75] Starting dnsProbe {Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33}
I0208 20:59:53.889359       1 dnsprobe.go:75] Starting dnsProbe {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33}
panic: counter cannot decrease in value

goroutine 1 [running]:
k8s.io/dns/vendor/github.com/prometheus/client_golang/prometheus.(*counter).Add(0xc42040ef40, 0xc062c00000000000)
        /go/src/k8s.io/dns/vendor/github.com/prometheus/client_golang/prometheus/counter.go:71 +0xa7
k8s.io/dns/pkg/sidecar.exportMetrics(0xc420156150)
        /go/src/k8s.io/dns/pkg/sidecar/server.go:86 +0x1c3
k8s.io/dns/pkg/sidecar.(*server).runMetrics(0xc420234c90, 0xc4202ec3f0)
        /go/src/k8s.io/dns/pkg/sidecar/server.go:68 +0x1d6
k8s.io/dns/pkg/sidecar.(*server).Run(0xc420234c90, 0xc4202ec3f0)
        /go/src/k8s.io/dns/pkg/sidecar/server.go:53 +0x244
main.main()
        /go/src/k8s.io/dns/cmd/sidecar/main.go:56 +0x209
```",closed,False,2018-02-08 21:09:04,2018-12-31 04:39:27
dns,oomichi,https://github.com/kubernetes/dns/issues/196,https://api.github.com/repos/kubernetes/dns/issues/196,"difficult to investigate which is problematic on the initialization, services or endpoints","As the issue report of https://github.com/kubernetes/kubernetes/issues/55471 we are facing a problem during the dns initialization and the error log is like:

I0117 00:44:06.332308 1 dns.go:173] Waiting for services and endpoints to be initialized from apiserver...
F0117 00:44:06.832362 1 dns.go:167] Timeout waiting for initialization

The dns is waiting for both services and endpoints to be initialized, but we cannot distinguish which is problematic if facing this log. It would be better to say which cannot be initialized on the log.",closed,False,2018-02-09 03:18:52,2018-03-25 05:29:03
dns,oomichi,https://github.com/kubernetes/dns/pull/197,https://api.github.com/repos/kubernetes/dns/issues/197,Separate the initialization logs for each resource,"To investigate issues easily when facing it, this commit separates
the log for each resource, services and endpoints.

fixes: #196 ",closed,True,2018-02-09 03:25:19,2018-03-25 05:29:03
dns,RochesterinNYC,https://github.com/kubernetes/dns/issues/198,https://api.github.com/repos/kubernetes/dns/issues/198,Reverse IP lookup of external IPs not working with kube-dns upstreamNameservers,"**What happened**:

We’re trying to do reverse IP lookups from a GKE container (ex. `dig +short -t PTR x.x.x.x.in-addr.arpa`)  and this doesn’t seem to be working. `kube-dns` is set with `upstreamNameservers` via the `kube-dns` ConfigMap in the `kube-system` namespace.

**What you expected to happen**:

I would expect the reverse IP lookups to be passed along to the specified upstream nameservers similar to regular DNS lookups but it doesn’t seem like this is the case.

From within a running container in k8s:

```
root@debugging-65cb9f5b47-rbf99:/# dig +short -t PTR y.y.y.y.in-addr.arpa
root@debugging-65cb9f5b47-rbf99:/# dig @x.x.x.x +short -t PTR y.y.y.y.in-addr.arpa
hostname.company.net.
```

where `x.x.x.x` is the IP address of one of the `upstreamNameserver`s we set in the `kube-dns` configmap in the `kube-system` namespace (this is on GKE).",closed,False,2018-02-14 18:38:21,2018-04-05 20:17:53
dns,GaryH21,https://github.com/kubernetes/dns/issues/199,https://api.github.com/repos/kubernetes/dns/issues/199,DNS failing on pods looking up external resources - timeout (getaddrinfo),"I've recently started getting lots of errors with getaddrinfo timing out when trying to access external databases from my pods.

Sometimes (but not always) seeing dnsmasq error with ""Maximum number of concurrent DNS queries reached (max: 150)"" - I can't see how we would be reaching 150 concurrent connections though.

I receive an error of 'EAI_AGAIN' from getaddrinfo.

I'm running Kubernetes 1.9.2 on Google Cloud.

Please let me know what other information would be useful.

[logs-from-dnsmasq-in-kube-dns-77ddcc5dfb-8dzln (1).txt](https://github.com/kubernetes/dns/files/1754366/logs-from-dnsmasq-in-kube-dns-77ddcc5dfb-8dzln.1.txt)
",closed,False,2018-02-24 12:48:18,2019-03-22 10:49:38
dns,tomwilkie,https://github.com/kubernetes/dns/issues/200,https://api.github.com/repos/kubernetes/dns/issues/200,rest_client_requests_total metric missing,"The rest_client_requests_total is missing:
- it is included in client-go
- but the prometheus metric itself is dependency injected from `k8s.io/kubernetes/pkg/client/metrics/prometheus`, which is an old version on head and refers to `k8s.io/kubernetes/pkg/client/metrics` and not `k8s.io/client-go/tools/metrics`",closed,False,2018-02-27 18:42:11,2018-07-27 20:46:54
dns,tomwilkie,https://github.com/kubernetes/dns/issues/201,https://api.github.com/repos/kubernetes/dns/issues/201,rest_client_requests_total metric missing,"The rest_client_requests_total is missing:
- it is included in client-go
- but the prometheus metric itself is dependency injected from `k8s.io/kubernetes/pkg/client/metrics/prometheus`, which is an old version on head and refers to `k8s.io/kubernetes/pkg/client/metrics` and not `k8s.io/client-go/tools/metrics`",closed,False,2018-02-27 18:43:27,2018-02-27 18:43:37
dns,tomwilkie,https://github.com/kubernetes/dns/pull/202,https://api.github.com/repos/kubernetes/dns/issues/202,Update vendored k8s to 1.9,"Update the vendored kubernetes to 1.9, the client-go code to a matching version etc.

Also switch from godep to dep.  Godep is **dep**recated.

Fixes #200 ",closed,True,2018-02-27 20:37:24,2018-08-22 07:45:37
dns,MrHohn,https://github.com/kubernetes/dns/issues/203,https://api.github.com/repos/kubernetes/dns/issues/203,Travis build is failing on HEAD and PRs,"Ref https://travis-ci.org/kubernetes/dns/builds/346993176:
```
$ cd ${GOPATH}/src/k8s.io/dns && bin/amd64/ginkgo test/e2e
/home/travis/.travis/job_stages: line 57: bin/amd64/ginkgo: No such file or directory

The command ""cd ${GOPATH}/src/k8s.io/dns && bin/amd64/ginkgo test/e2e"" exited with 127.
```

/assign",closed,False,2018-02-27 21:51:01,2018-03-21 23:56:57
dns,dynek,https://github.com/kubernetes/dns/issues/204,https://api.github.com/repos/kubernetes/dns/issues/204,DNS stops working for addresses outside of the cluster,"Hello,

From time to time we have a DNS resolution issue with one of our k8s cluster.
It's isolated to the cluster ifself because the same resolutions work from outside the cluster.
Also, only resolution belonging to outside the cluster is impacted, intra-cluster dns works (services).

We are running k8s 1.5.2 with kubedns 1.9 and dnsmasq 1.14.5.

10.1.0.1 is one of the dns serving dns for the whole company.

When query doesn't work, here the output:
```
/ # dig www.google.ch @10.1.0.1

; <<>> DiG 9.11.2-P1 <<>> www.google.ch @10.1.0.1
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: FORMERR, id: 64173
;; flags: qr rd; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 1
;; WARNING: recursion requested but not available

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
; COOKIE: 7f524c0a6acfe7e1 (echoed)
;; QUESTION SECTION:
;www.google.ch.                 IN      A

;; Query time: 1 msec
;; SERVER: 10.1.0.1#53(10.1.0.1)
;; WHEN: Wed Feb 28 15:17:14 UTC 2018
;; MSG SIZE  rcvd: 54
```
Odd thing is, if I add ```+nocookie``` at the end, I get the expected answer:
```
/ # dig www.google.ch @10.1.0.1 +nocookie

; <<>> DiG 9.11.2-P1 <<>> www.google.ch @10.1.0.1 +nocookie
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 51261
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4000
;; QUESTION SECTION:
;www.google.ch.                 IN      A

;; ANSWER SECTION:
www.google.ch.          281     IN      A       209.85.202.94

;; Query time: 1 msec
;; SERVER: 10.1.0.1#53(10.1.0.1)
;; WHEN: Wed Feb 28 15:17:38 UTC 2018
;; MSG SIZE  rcvd: 58
```
And here's a query without ```+nocookie``` from a machine outside the cluster:
```
$ dig www.google.ch @10.1.0.1

; <<>> DiG 9.9.4-RedHat-9.9.4-38.el7_3.3 <<>> www.google.ch @10.1.0.1
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 34675
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4000
;; QUESTION SECTION:
;www.google.ch.                 IN      A

;; ANSWER SECTION:
www.google.ch.          267     IN      A       209.85.202.94

;; Query time: 0 msec
;; SERVER: 10.1.0.1#53(10.1.0.1)
;; WHEN: Wed Feb 28 16:17:52 CET 2018
;; MSG SIZE  rcvd: 58
```
Does anyone have a clue?

Thank you!",closed,False,2018-02-28 15:24:26,2018-03-12 12:47:06
dns,nhoughto,https://github.com/kubernetes/dns/issues/205,https://api.github.com/repos/kubernetes/dns/issues/205,dnsmasq times out resolving external names without query-port,"We are using KOPS 1.8 to setup a kube 1.8 cluster in AWS with a DHCP Option Sets set upstream resolver that is owned by another team, we have subnet NACLs that only allow 1024-65535 ports to communicate between the kube nodes and the resolver (in a different VPC).

With this setup we have been seeing intermittent DNS resolution failures in the form of timeouts from our Java apps a few times per hour when under a small amount of load, we have been scratching our heads for a few days tracing DNS requests through pod -> kubedns -> dnsmasq -> upstream resolver and back again. For successful requests we can see the requests and correct reply in each component, but for failed requests only the request logging is visible and the eventual timeout in the calling component (java app).

Our theory is that `dnsmasq` is using an ephemeral query port outside the expect range of 1024-65535, and the response is being blocked intermittently by the subnet NACL we have in place between the node subnet and the resolver subnet. We have worked around the problem by explicitly setting the `--query-port` on the dnsmasq container to a known-good value and this has solved our problem.

`dnsmasq` appears to use a default min-port of `1024` and a max of `65535` so in theory our NACL shouldn't block anything and should work as expect, that isn't however the behaviour we are seeing, and setting the `query-port` explicitly fixes our problem pointing to `dnsmasq` misbehaving. Further evidence from the upstream resolver shows use of an ephemeral port below `1024` in this case using `793`.

upstream resolver logs:
```
...
28-Feb-2018 19:19:48.765 queries: info: client 10.100.156.151#8012: view forwarding: query: proxy.com.zone IN A + (10.100.110.137)
28-Feb-2018 19:19:48.771 queries: info: client 10.100.116.184#793: view forwarding: query: proxy.com IN A + (10.100.110.137)
...
```

kubedns describe:
```
Name:		kube-dns-69b98fb674-mtm2x
Namespace:	kube-system
Node:		node.internal/10.100.156.151
Start Time:	Thu, 01 Mar 2018 08:26:20 +1100
Labels:		k8s-app=kube-dns
		pod-template-hash=2565496230
Annotations:	kubernetes.io/created-by={""kind"":""SerializedReference"",""apiVersion"":""v1"",""reference"":{""kind"":""ReplicaSet"",""namespace"":""kube-system"",""name"":""kube-dns-69b98fb674"",""uid"":""f9d2da7e-1ccd-11e8-a9e3-0618bed1...
		scheduler.alpha.kubernetes.io/critical-pod=
		scheduler.alpha.kubernetes.io/tolerations=[{""key"":""CriticalAddonsOnly"", ""operator"":""Exists""}]
Status:		Running
IP:		100.96.8.39
Controllers:	ReplicaSet/kube-dns-69b98fb674
Containers:
  kubedns:
    Container ID:	docker://4f0002fef202646e7f4a1e812b57447dee2fce4138790e50602478236781080d
    Image:		gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.5
    Image ID:		docker-pullable://gcr.io/google_containers/k8s-dns-kube-dns-amd64@sha256:1a3fc069de481ae690188f6f1ba4664b5cc7760af37120f70c86505c79eea61d
    Ports:		10053/UDP, 10053/TCP, 10055/TCP
    Args:
      --domain=cluster.local.
      --dns-port=10053
      --config-dir=/kube-dns-config
      --v=3
    State:		Running
      Started:		Thu, 01 Mar 2018 08:26:23 +1100
    Ready:		True
    Restart Count:	0
    Limits:
      memory:	170Mi
    Requests:
      cpu:	100m
      memory:	70Mi
    Liveness:	http-get http://:10054/healthcheck/kubedns delay=60s timeout=5s period=10s #success=1 #failure=5
    Readiness:	http-get http://:8081/readiness delay=3s timeout=5s period=10s #success=1 #failure=3
    Environment:
      PROMETHEUS_PORT:	10055
    Mounts:
      /kube-dns-config from kube-dns-config (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-dns-token-jrcw7 (ro)
  dnsmasq:
    Container ID:	docker://e3e1944ef60c33ecdf9235de4de8f09cedc23e2bafb7224e80b8c990854b0e9b
    Image:		gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.5
    Image ID:		docker-pullable://gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64@sha256:46b933bb70270c8a02fa6b6f87d440f6f1fce1a5a2a719e164f83f7b109f7544
    Ports:		53/UDP, 53/TCP
    Args:
      -v=2
      -logtostderr
      -configDir=/etc/k8s/dns/dnsmasq-nanny
      -restartDnsmasq=true
      --
      -k
      -q
      --query-port=32767
      --cache-size=1000
      --log-facility=-
      --server=/cluster.local/127.0.0.1#10053
      --server=/in-addr.arpa/127.0.0.1#10053
      --server=/in6.arpa/127.0.0.1#10053
    State:		Running
      Started:		Thu, 01 Mar 2018 08:26:25 +1100
    Ready:		True
    Restart Count:	0
    Requests:
      cpu:		150m
      memory:		20Mi
    Liveness:		http-get http://:10054/healthcheck/dnsmasq delay=60s timeout=5s period=10s #success=1 #failure=5
    Environment:	<none>
    Mounts:
      /etc/k8s/dns/dnsmasq-nanny from kube-dns-config (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-dns-token-jrcw7 (ro)
  sidecar:
    Container ID:	docker://8b9ae4323be46f841f3b8cbcc3a1fd9080097536790eb0f94c94c804adcab743
    Image:		gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.5
    Image ID:		docker-pullable://gcr.io/google_containers/k8s-dns-sidecar-amd64@sha256:9aab42bf6a2a068b797fe7d91a5d8d915b10dbbc3d6f2b10492848debfba6044
    Port:		10054/TCP
    Args:
      --v=2
      --logtostderr
      --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,A
      --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,A
    State:		Running
      Started:		Thu, 01 Mar 2018 08:26:27 +1100
    Ready:		True
    Restart Count:	0
    Requests:
      cpu:		10m
      memory:		20Mi
    Liveness:		http-get http://:10054/metrics delay=60s timeout=5s period=10s #success=1 #failure=5
    Environment:	<none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-dns-token-jrcw7 (ro)
Conditions:
  Type		Status
  Initialized 	True 
  Ready 	True 
  PodScheduled 	True 
Volumes:
  kube-dns-config:
    Type:	ConfigMap (a volume populated by a ConfigMap)
    Name:	kube-dns
    Optional:	true
  kube-dns-token-jrcw7:
    Type:	Secret (a volume populated by a Secret)
    SecretName:	kube-dns-token-jrcw7
    Optional:	false
QoS Class:	Burstable
Node-Selectors:	<none>
Tolerations:	node.alpha.kubernetes.io/notReady=:Exists:NoExecute for 300s
		node.alpha.kubernetes.io/unreachable=:Exists:NoExecute for 300s
Events:		<none>
```",closed,False,2018-03-01 00:09:08,2018-07-29 04:17:52
dns,MrHohn,https://github.com/kubernetes/dns/pull/206,https://api.github.com/repos/kubernetes/dns/issues/206,Fix travis: include vendor folder in build.sh,"Did a bit digging and found the CI build was broken after bumping to Go 1.9+ (https://github.com/kubernetes/dns/pull/193).

From Go 1.9 release notes, looks like command `go install ./...` will no longer matches package in vendor folder (https://golang.org/doc/go1.9#vendor-dotdotdot), which breaks our CI build because we are expecting `bin/amd64/ginkgo`.

This PR adds the vendor folder back for installing. Might not be the best choice but I think it at least works.

Fix https://github.com/kubernetes/dns/issues/203.",closed,True,2018-03-02 01:18:04,2018-03-21 23:56:57
dns,rakidu,https://github.com/kubernetes/dns/issues/207,https://api.github.com/repos/kubernetes/dns/issues/207,dns resolution issues,"Hi All,

We are unable to resolve the pods(IP) from master when we are trying to connect to pods from Master.

we used acs-engine to deploy the kubernetes cluster in Azure.

we are trying to ssh in to the pod from master but it is unable to resolve the pod IP
as of now we are logging in to the node machine and trying to ssh in to that pod.

Please help me why the dns resolution is not happening
",closed,False,2018-03-02 06:13:28,2018-05-15 07:15:10
dns,xuejipeng,https://github.com/kubernetes/dns/issues/208,https://api.github.com/repos/kubernetes/dns/issues/208,dnsmasq --addrss args can't reslove,"I add parameters '--address = / test.com / 10.0.1.215' on  dnsmasq service, i have to service,
when i ping www.test.com，one can resolve to ip address(10.0.1.215) but one can't resolve to.
The file  /etc/resolv.conf content is the same
<img width=""587"" alt=""2018-03-05 10 36 16"" src=""https://user-images.githubusercontent.com/18901031/36955097-42d736f8-2061-11e8-9b82-315487f7bd5b.png"">
<img width=""1255"" alt=""2018-03-05 10 37 44"" src=""https://user-images.githubusercontent.com/18901031/36955099-444215c6-2061-11e8-97af-eb196b6ffa2d.png"">
Who can tell me where the problem will be
thanks.

",closed,False,2018-03-05 02:40:26,2018-08-02 04:52:31
dns,josdotso,https://github.com/kubernetes/dns/issues/209,https://api.github.com/repos/kubernetes/dns/issues/209,Trying to create a headless-like SRV result from discrete static ClusterIPs,"Hi.

I'm working on making etcdv3 run better in Kubernetes, the results of which should come in a PR to kubernetes/charts. 

Etcdv3 basically requires consistency of IP address.  Although previously hostnames were supported for ""peer-urls"", this bug was fixed and so IP addresses are again the currency of etcd clustering. 

What I'm looking for is: https://github.com/kubernetes/kubernetes/issues/28969

However, I'm trying to hack together a similar functionality with the intent on making etcdv3 StatefulSet pod IPs consistent across: cluster reboots, kubernetes node addition and subtraction, service removal/addition (think `helm delete --purge` + `helm install`).

I'm thinking that one service per etcd pod, each with static ClusterIP (calculated from starting IP/subnet in helm chart) might do the trick.  However, with this multi-service approach, I believe service discover via SRV records would suffer, provided that would work at all given etcd's SRV expectations: https://coreos.com/etcd/docs/latest/op-guide/clustering.html#dns-discovery

So anyway, the question is: how can I achieve (logically speaking) Sticky IP addresses for these StatefulSet Pods with the above constraints, while generating SRV records as etcd would expect?  One idea I have is to create a boilerplate headless service and use initcontainers to add pod endpoints.

Am I completely lost? lol",closed,False,2018-03-08 17:58:06,2018-03-12 04:56:36
dns,sergeylanzman,https://github.com/kubernetes/dns/pull/210,https://api.github.com/repos/kubernetes/dns/issues/210,fix bug with delete externalName service,"On delete service from namespace kube-dns get event  EndpointAdd. 
Func addDNSUsingEndpoints generate RecordsForHeadlessService in cache to service type externalName. 
After this delete from a cache, it's deleted an empty record, but a record of Entries for externalName stuck forever.
Solution: don't generate the empty record for externalName",closed,True,2018-03-08 22:29:55,2018-03-25 17:31:05
dns,AdamDang,https://github.com/kubernetes/dns/pull/211,https://api.github.com/repos/kubernetes/dns/issues/211,"Typo fix ""...is use to ...""->""...is used to ...""",a grammatical error in line 326.,closed,True,2018-03-11 07:32:45,2018-04-19 04:04:06
dns,AdamDang,https://github.com/kubernetes/dns/pull/212,https://api.github.com/repos/kubernetes/dns/issues/212,"Typo fix delete duplicated ""the the""","""the"" is duplicated in line 40.",closed,True,2018-03-11 12:11:44,2018-03-18 15:45:47
dns,timbyr,https://github.com/kubernetes/dns/issues/213,https://api.github.com/repos/kubernetes/dns/issues/213,Unable to update dependencies with godep,"Godep is EOL'd and should be replaced with active dependency tool.

Managing dependencies is made increasingly difficult by won't fix issues on godep tool.",closed,False,2018-03-12 17:53:24,2018-08-09 19:51:03
dns,Nefelim4ag,https://github.com/kubernetes/dns/pull/214,https://api.github.com/repos/kubernetes/dns/issues/214,Delete docker pull from Makefiles,"That fixув building on closed clusters,
where for security reasons no internet connection are available
and needed images are unpacked to build machine

Docker will pull missing images self

For dnsmasq --pull useless because specific version of image
are set in file, so no new images will come.

Signed-off-by: Timofey Titovets <nefelim4ag@gmail.com>",open,True,2018-03-20 16:38:35,2019-01-02 19:41:33
dns,rramkumar1,https://github.com/kubernetes/dns/pull/215,https://api.github.com/repos/kubernetes/dns/issues/215,Implement HasSynced() of skydns Backend interface,"This PR fixes #186. 

We implement the HasSynced() interface that skydns defines. In the case that the endpoints and services have not been initally synced from the API server, skydns will now refuse the connection instead of returning NXDOMAIN.
",closed,True,2018-03-20 17:39:47,2018-03-22 22:22:47
dns,rramkumar1,https://github.com/kubernetes/dns/pull/216,https://api.github.com/repos/kubernetes/dns/issues/216,Fix dnsmasq metric panic,"Fixes an issue that arises when the dnsmasq container is restarted on ConfigMap updated. In that case, the previous value of a metric is greater than the current value, which results in us adding a negative delta to the Prometheus Counter. This fix ensures that if the delta is negative, we add 0 to avoid a panic.

/assign @bowei ",closed,True,2018-03-20 17:41:15,2018-03-21 22:16:11
dns,fanzy618,https://github.com/kubernetes/dns/pull/217,https://api.github.com/repos/kubernetes/dns/issues/217,Switch from godep to dep ,"Switch from godep to dep.

Fixes #213",closed,True,2018-03-21 13:09:53,2018-03-21 13:26:22
dns,MrHohn,https://github.com/kubernetes/dns/pull/218,https://api.github.com/repos/kubernetes/dns/issues/218,[TEST] Update vendor skydns,,closed,True,2018-03-22 20:54:06,2018-03-22 22:17:01
dns,rramkumar1,https://github.com/kubernetes/dns/pull/219,https://api.github.com/repos/kubernetes/dns/issues/219,Implement HasSynced() of skydns Backend interface,"This PR fixes #186.

We implement the HasSynced() interface that skydns defines. In the case that the endpoints and services have not been initally synced from the API server, skydns will now refuse the connection instead of returning NXDOMAIN.
",closed,True,2018-03-22 22:23:49,2018-05-04 22:48:26
dns,grayluck,https://github.com/kubernetes/dns/pull/220,https://api.github.com/repos/kubernetes/dns/issues/220,Forward PTR record lookup from kubedns to upstream server.,"Fixes #198

Approach: Let kubedns sync config to skydns nameservers, allowing skydns to do the request forwarding. ",closed,True,2018-03-23 00:19:13,2018-04-09 18:19:40
dns,bowei,https://github.com/kubernetes/dns/pull/221,https://api.github.com/repos/kubernetes/dns/issues/221,Add check hash of downloaded dnsmasq source,Fixes https://github.com/kubernetes/dns/issues/165,closed,True,2018-03-26 20:48:41,2018-03-26 21:25:32
dns,YEXINGZHE54,https://github.com/kubernetes/dns/pull/222,https://api.github.com/repos/kubernetes/dns/issues/222,Update cache.go,"currently, EvictRandom will clean up all cached entries when cache is full. fix it, only clean additional ones",closed,True,2018-03-31 09:20:33,2018-04-01 17:50:59
dns,thockin,https://github.com/kubernetes/dns/pull/223,https://api.github.com/repos/kubernetes/dns/issues/223,Pass 2: k8s GCR vanity URL,,closed,True,2018-04-06 15:47:30,2018-04-09 16:56:11
dns,ApsOps,https://github.com/kubernetes/dns/issues/224,https://api.github.com/repos/kubernetes/dns/issues/224,DNS resolution for externalName services broken in v1.14.9,"After updating to v1.14.9, externalName services are not resolving anymore. I tested with v1.14.8 and it works.

```
/ # dig @100.102.0.17 mysql-external.default.svc.cluster.local

; <<>> DiG 9.11.2-P1 <<>> @100.102.0.17 mysql-external.default.svc.cluster.local
; (1 server found)
;; global options: +cmd
;; Got answer:
;; WARNING: .local is reserved for Multicast DNS
;; You are currently testing what happens when an mDNS query is leaked to DNS
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 45659
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 0

;; QUESTION SECTION:
;mysql-external.default.svc.cluster.local.	IN A

;; AUTHORITY SECTION:
cluster.local.		60	IN	SOA	ns.dns.cluster.local. hostmaster.cluster.local. 1523602800 28800 7200 604800 60

;; Query time: 1 msec
;; SERVER: 100.102.0.17#53(100.102.0.17)
;; WHEN: Fri Apr 13 07:58:15 UTC 2018
;; MSG SIZE  rcvd: 110
```

kube-dns pod logs (I've replaced the correct domain with example.com but it exists and resolves normally in v1.14.8):

```
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197655       1 dns.go:612] Query for ""mysql-external.default.svc.cluster.local."", exact: false
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197682       1 dns.go:841] Not a federation query: len([""mysql-external"" ""default"" ""svc"" ""cluster"" ""local""]) != 4+len([""local"" ""cluster""])
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197700       1 dns.go:732] Found 1 records for [local cluster svc default mysql-external] in the cache
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197715       1 dns.go:739] getRecordsForPath retval=[{Host:db.aurora.external.x.example.com Port:0 Priority:10 Weight:10 Text: Mail:false Ttl:30 TargetStrip:0 Group: Key:/skydns/local/cluster/svc/default/mysql-external}], path=[local cluster svc default mysql-external]
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197739       1 dns.go:641] Records for mysql-external.default.svc.cluster.local.: [{db.aurora.external.x.example.com 0 10 10  false 30 0  /skydns/local/cluster/svc/default/mysql-external}]
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197754       1 dns.go:612] Query for ""db.aurora.external.x.example.com."", exact: false
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197789       1 dns.go:860] Not a federation query: ""x"" != ""svc"" (serviceSubdomain)
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197797       1 dns.go:732] Found 0 records for [com example x external aurora db] in the cache
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197807       1 dns.go:739] getRecordsForPath retval=[], path=[com example x external aurora db]
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197816       1 dns.go:645] No record found for db.aurora.external.x.example.com.
[kube-dns-aps-78b75f775c-b2j8p kubedns] I0413 08:12:22.197830       1 logs.go:41] skydns: incomplete CNAME chain from ""db.aurora.external.x.example.com."": no nameservers configured can not lookup name
```


I initially thought it's regression from #210 but I'm not sure. Please let me know how I can help with any more debug info.",closed,False,2018-04-13 08:23:03,2018-04-18 06:00:49
dns,grayluck,https://github.com/kubernetes/dns/pull/225,https://api.github.com/repos/kubernetes/dns/issues/225,Fix external name not solving by reloading resolv.conf.,"Now skydns will be configured with resolv.conf when nameserver is empty.

Fixes#224 (https://github.com/kubernetes/dns/issues/224)

\assign @MrHohn ",closed,True,2018-04-14 00:10:55,2018-04-16 21:56:10
dns,MrHohn,https://github.com/kubernetes/dns/issues/226,https://api.github.com/repos/kubernetes/dns/issues/226,Add an e2e test that goes through dnsmasq -> kubedns -> upstream servers path,"Ref https://github.com/kubernetes/dns/issues/224, a recent regression was introduced without being caught by any of the tests. The dnsmasq -> kubedns -> upstream servers path is currently a blindspot in test and we should surely include that to prevent future regression.

cc @grayluck ",closed,False,2018-04-16 18:08:13,2018-04-20 01:40:10
dns,MrHohn,https://github.com/kubernetes/dns/issues/227,https://api.github.com/repos/kubernetes/dns/issues/227,CI jobs for kube-dns,"coredns will soon be enabled by default in k8s (https://github.com/kubernetes/kubernetes/pull/62147), after that there will be no test coverage for kube-dns anymore. We should probably create separate CI jobs that explicitly enable kube-dns (similar to https://k8s-testgrid.appspot.com/sig-network-gce#gci-gce-coredns), and maintain that for couple more releases.",closed,False,2018-04-24 17:59:52,2018-10-25 18:52:30
dns,aandryashin,https://github.com/kubernetes/dns/issues/228,https://api.github.com/repos/kubernetes/dns/issues/228,Update miekg/dns up to v1.0.5,Please update miekg/dns up to v1.0.5 due this [#642](https://github.com/miekg/dns/pull/642) issue. When resolv.conf contains option attempts kube-dns crashes with panic.,closed,False,2018-05-03 16:55:13,2018-05-04 22:26:52
dns,grayluck,https://github.com/kubernetes/dns/pull/229,https://api.github.com/repos/kubernetes/dns/issues/229,Update miekg/dns to v1.0.5,"Due to this issue https://github.com/miekg/dns/pull/642, dep miekg/dns is upgraded to v1.0.5 to prevent kubedns from panic when resolv.conf contains `attempt`. golang.org/x/net is upgraded to release-branch.go1.9.

Fixes #228
/assign @MrHohn ",closed,True,2018-05-04 04:49:52,2018-05-04 22:26:53
dns,igorvpcleao,https://github.com/kubernetes/dns/issues/230,https://api.github.com/repos/kubernetes/dns/issues/230,High latency for kube-dns 1.14.9 and 1.14.10,"Hi there, 
I noticed a high latency when I starting using _kube-dns_ `1.14.9` and `1.14.10`.

Images below show _kube-dns_ response time after upgrading _kube-dns_ from `1.14.6` to `1.14.10`

![screen shot 2018-05-09 at 15 13 57](https://user-images.githubusercontent.com/3065657/39832035-887dd036-539c-11e8-8872-eafbd3889a88.png)

![screen shot 2018-05-09 at 15 14 02](https://user-images.githubusercontent.com/3065657/39832037-8a438302-539c-11e8-845d-231769baf4a7.png)

Logs:

**kubectl logs kube-dns-7c8767566d-55jts -n kube-system -c kubedns**
I0509 18:24:33.037379       1 dns.go:48] version: 1.14.10
I0509 18:24:33.037981       1 server.go:69] Using configuration read from directory: /kube-dns-config with period 10s
I0509 18:24:33.038044       1 server.go:121] FLAG: --alsologtostderr=""false""
I0509 18:24:33.038057       1 server.go:121] FLAG: --config-dir=""/kube-dns-config""
I0509 18:24:33.038064       1 server.go:121] FLAG: --config-map=""""
I0509 18:24:33.038083       1 server.go:121] FLAG: --config-map-namespace=""kube-system""
I0509 18:24:33.038087       1 server.go:121] FLAG: --config-period=""10s""
I0509 18:24:33.038109       1 server.go:121] FLAG: --dns-bind-address=""0.0.0.0""
I0509 18:24:33.038113       1 server.go:121] FLAG: --dns-port=""10053""
I0509 18:24:33.038132       1 server.go:121] FLAG: --domain=""cluster.local.""
I0509 18:24:33.038137       1 server.go:121] FLAG: --federations=""""
I0509 18:24:33.038141       1 server.go:121] FLAG: --healthz-port=""8081""
I0509 18:24:33.038145       1 server.go:121] FLAG: --initial-sync-timeout=""1m0s""
I0509 18:24:33.038177       1 server.go:121] FLAG: --kube-master-url=""""
I0509 18:24:33.038181       1 server.go:121] FLAG: --kubecfg-file=""""
I0509 18:24:33.038206       1 server.go:121] FLAG: --log-backtrace-at="":0""
I0509 18:24:33.038221       1 server.go:121] FLAG: --log-dir=""""
I0509 18:24:33.038229       1 server.go:121] FLAG: --log-flush-frequency=""5s""
I0509 18:24:33.038233       1 server.go:121] FLAG: --logtostderr=""true""
I0509 18:24:33.038245       1 server.go:121] FLAG: --nameservers=""""
I0509 18:24:33.038253       1 server.go:121] FLAG: --stderrthreshold=""2""
I0509 18:24:33.038256       1 server.go:121] FLAG: --v=""2""
I0509 18:24:33.038269       1 server.go:121] FLAG: --version=""false""
I0509 18:24:33.038283       1 server.go:121] FLAG: --vmodule=""""
I0509 18:24:33.038491       1 server.go:169] Starting SkyDNS server (0.0.0.0:10053)
I0509 18:24:33.038715       1 server.go:179] Skydns metrics enabled (/metrics:10055)
I0509 18:24:33.038728       1 dns.go:188] Starting endpointsController
I0509 18:24:33.038732       1 dns.go:191] Starting serviceController
I0509 18:24:33.038777       1 dns.go:184] Configuration updated: {TypeMeta:{Kind: APIVersion:} Federations:map[] StubDomains:map[] UpstreamNameservers:[]}
I0509 18:24:33.038914       1 logs.go:41] skydns: ready for queries on cluster.local. for tcp://0.0.0.0:10053 [rcache 0]
I0509 18:24:33.038922       1 logs.go:41] skydns: ready for queries on cluster.local. for udp://0.0.0.0:10053 [rcache 0]
I0509 18:24:33.538991       1 dns.go:222] Initialized services and endpoints from apiserver
I0509 18:24:33.539018       1 server.go:137] Setting up Healthz Handler (/readiness)
I0509 18:24:33.539030       1 server.go:142] Setting up cache handler (/cache)
I0509 18:24:33.539098       1 server.go:128] Status HTTP port 8081

**kubectl logs kube-dns-7c8767566d-55jts -n kube-system -c dnsmasq**
I0509 18:24:33.152179       1 main.go:74] opts: {{/usr/sbin/dnsmasq [-k --cache-size=1000 --neg-ttl=300 --min-cache-ttl=60 --max-cache-ttl=60 --local-ttl=60 --dns-forward-max=150 --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/in6.arpa/127.0.0.1#10053] true} /etc/k8s/dns/dnsmasq-nanny 10000000000}
I0509 18:24:33.152263       1 nanny.go:94] Starting dnsmasq [-k --cache-size=1000 --neg-ttl=300 --min-cache-ttl=60 --max-cache-ttl=60 --local-ttl=60 --dns-forward-max=150 --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/in6.arpa/127.0.0.1#10053]
I0509 18:24:33.242916       1 nanny.go:116] dnsmasq[10]: started, version 2.78 cachesize 1000
I0509 18:24:33.242992       1 nanny.go:116] dnsmasq[10]: compile time options: IPv6 GNU-getopt no-DBus no-i18n no-IDN DHCP DHCPv6 no-Lua TFTP no-conntrack ipset auth no-DNSSEC loop-detect inotify
I0509 18:24:33.243005       1 nanny.go:116] dnsmasq[10]: using nameserver 127.0.0.1#10053 for domain in6.arpa
I0509 18:24:33.243008       1 nanny.go:116] dnsmasq[10]: using nameserver 127.0.0.1#10053 for domain in-addr.arpa
I0509 18:24:33.243012       1 nanny.go:116] dnsmasq[10]: using nameserver 127.0.0.1#10053 for domain cluster.local
I0509 18:24:33.243016       1 nanny.go:116] dnsmasq[10]: reading /etc/resolv.conf
I0509 18:24:33.243021       1 nanny.go:116] dnsmasq[10]: using nameserver 127.0.0.1#10053 for domain in6.arpa
I0509 18:24:33.243043       1 nanny.go:116] dnsmasq[10]: using nameserver 127.0.0.1#10053 for domain in-addr.arpa
I0509 18:24:33.243052       1 nanny.go:116] dnsmasq[10]: using nameserver 127.0.0.1#10053 for domain cluster.local
I0509 18:24:33.243055       1 nanny.go:116] dnsmasq[10]: using nameserver 172.22.0.2#53
I0509 18:24:33.243058       1 nanny.go:116] dnsmasq[10]: read /etc/hosts - 7 addresses
I0509 18:24:33.242916       1 nanny.go:119]
W0509 18:24:33.243067       1 nanny.go:120] Got EOF from stdout

**kubectl logs kube-dns-7c8767566d-55jts -n kube-system -c sidecar**
I0509 18:24:33.319908       1 main.go:51] Version v1.14.8.3
I0509 18:24:33.319944       1 server.go:45] Starting server (options {DnsMasqPort:53 DnsMasqAddr:127.0.0.1 DnsMasqPollIntervalMs:5000 Probes:[{Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:1} {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:1}] PrometheusAddr:0.0.0.0 PrometheusPort:10054 PrometheusPath:/metrics PrometheusNamespace:kubedns})
I0509 18:24:33.319970       1 dnsprobe.go:75] Starting dnsProbe {Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:1}
I0509 18:24:33.320035       1 dnsprobe.go:75] Starting dnsProbe {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:1}

Deployment:
```
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    k8s-addon: kube-dns.addons.k8s.io
    k8s-app: kube-dns
    kubernetes.io/cluster-service: ""true""
  name: kube-dns
  namespace: kube-system
spec:
  replicas: 2
  selector:
    matchLabels:
      k8s-app: kube-dns
  strategy:
    rollingUpdate:
      maxSurge: 10%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: """"
        scheduler.alpha.kubernetes.io/tolerations: '[{""key"":""CriticalAddonsOnly"",
          ""operator"":""Exists""}]'
        service-discovery.datadoghq.com/sidecar.check_names: '[""sidecar-check""]'
        service-discovery.datadoghq.com/sidecar.init_configs: '[{}]'
        service-discovery.datadoghq.com/sidecar.instances: '[[{""prometheus_endpoint"":
          ""http://%%host%%:10054/metrics""}]]'
      creationTimestamp: null
      labels:
        k8s-app: kube-dns
    spec:
      containers:
      - args:
        - --domain=cluster.local.
        - --dns-port=10053
        - --config-dir=/kube-dns-config
        - --v=2
        env:
        - name: PROMETHEUS_PORT
          value: ""10055""
        image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.10
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthcheck/kubedns
            port: 10054
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        name: kubedns
        ports:
        - containerPort: 10053
          name: dns-local
          protocol: UDP
        - containerPort: 10053
          name: dns-tcp-local
          protocol: TCP
        - containerPort: 10055
          name: metrics
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /readiness
            port: 8081
            scheme: HTTP
          initialDelaySeconds: 3
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        resources:
          limits:
            memory: 170Mi
          requests:
            cpu: 100m
            memory: 70Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /kube-dns-config
          name: kube-dns-config
      - args:
        - -v=2
        - -logtostderr
        - -configDir=/etc/k8s/dns/dnsmasq-nanny
        - -restartDnsmasq=true
        - --
        - -k
        - --cache-size=1000
        - --neg-ttl=300
        - --min-cache-ttl=60
        - --max-cache-ttl=60
        - --local-ttl=60
        - --dns-forward-max=150
        - --log-facility=-
        - --server=/cluster.local/127.0.0.1#10053
        - --server=/in-addr.arpa/127.0.0.1#10053
        - --server=/in6.arpa/127.0.0.1#10053
        image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.10
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthcheck/dnsmasq
            port: 10054
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        name: dnsmasq
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        resources:
          requests:
            cpu: 150m
            memory: 20Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /etc/k8s/dns/dnsmasq-nanny
          name: kube-dns-config
      - args:
        - --v=2
        - --logtostderr
        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,A
        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,A
        image: gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.10
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /metrics
            port: 10054
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        name: sidecar
        ports:
        - containerPort: 10054
          name: metrics
          protocol: TCP
        resources:
          requests:
            cpu: 10m
            memory: 20Mi
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
      dnsPolicy: Default
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      serviceAccount: kube-dns
      serviceAccountName: kube-dns
      terminationGracePeriodSeconds: 30
      volumes:
      - configMap:
          defaultMode: 420
          name: kube-dns
          optional: true
        name: kube-dns-config
```",closed,False,2018-05-09 18:57:48,2018-10-13 17:56:11
dns,xiaosadexiaohai,https://github.com/kubernetes/dns/issues/231,https://api.github.com/repos/kubernetes/dns/issues/231,Grafana Dashboard,Does anyone have a working Grafana Dashbaord for kube-dns metrics using Prometheus as a data source?,closed,False,2018-05-15 01:38:50,2018-12-30 14:25:27
dns,krmayankk,https://github.com/kubernetes/dns/pull/232,https://api.github.com/repos/kubernetes/dns/issues/232,fix pod hostname to be podname for dns srv records,"Fixes https://github.com/kubernetes/dns/issues/116 and https://github.com/kubernetes/kubernetes/issues/47992

Verified this works now 
```
/ # nslookup my-service.new-hire
Server:    10.254.208.255
Address 1: 10.254.208.255 kube-dns.kube-system.svc.cluster.local

Name:      my-service.new-hire
Address 1: 10.251.156.52 nginx-deployment-6fc8cd7954-q8p99.my-service.new-hire.svc.cluster.local
Address 2: 10.251.156.7 nginx-deployment-6fc8cd7954-w44gr.my-service.new-hire.svc.cluster.local
```",closed,True,2018-05-18 07:59:10,2019-02-03 22:14:44
dns,ZhengRongTan,https://github.com/kubernetes/dns/issues/233,https://api.github.com/repos/kubernetes/dns/issues/233,kube dns restart frequently!!,"k8s - 1.8. 5

kube dns  restart frequently , help!!",closed,False,2018-05-18 11:24:55,2018-05-21 08:45:14
dns,chrisohaver,https://github.com/kubernetes/dns/issues/234,https://api.github.com/repos/kubernetes/dns/issues/234,response for a headless service with no ready endpoints,"kube-dns replies with NXDOMAIN, for a headless service that has no ready endpoints.
But the [spec](https://github.com/kubernetes/dns/blob/master/docs/specification.md#241---a-records) says that the response should be NODATA, ""because the service exists"".

Presumably the spec wrong, since the spec was originally based off of kube-dns behavior at the time.
Or, in this case, is the spec behavior preferred?",closed,False,2018-05-18 15:33:01,2018-08-21 16:15:48
dns,sppadic17,https://github.com/kubernetes/dns/issues/235,https://api.github.com/repos/kubernetes/dns/issues/235,kube-dns resolution for external domains slow due to external PTR record lookup failure,"Hi there
  Currently running a 1.7.0 K8 cluster on Ubuntu 16.04 LTS with kube-dns v1.14.10. Seeing issues with slow nslookup responses (avg 7- 10 seconds) within application pods , when going to an external  endpoint which does not have PTR record  assinged to it

Seeing the same behaviour on pods using both dnsPolicy Default as well as for ClusterFirst

pod1 > nslookup xx.yy.zz.com
nslookup: can't resolve '(null)': Name does not resolve

After 6-10 seconds

Name: xx.yy.zz.com
Address1: xx.xxx.xxx.xx


Doing a tcpdump on the docker bridge interface from the VM  where the pod is running shows the following PTR record lookups failing at the end of tcpdump trace, which seem to be cause of the slowness from what best can gather 

Can see a few  repeats of the same message as below for each of the nameservers on the Host resolv.conf  (10.xx being the nameserves listed in the Host resolv.conf)
 
192.168.95.6.36491 > 10.xx.xxx.xxx.domain: [bad udp cksum 0x74a3 -> 0x4fcd!] 22902+ PTR? xx.xxx.xxx.xx.in-addr.arpa. (44)
12:48:17.630267 IP (tos 0x0, ttl 64, id 34551, offset 0, flags [DF], proto UDP (17), length 72)
    192.168.95.6.36491 > 10.xx.xx.xxx.domain: [bad udp cksum 0x74a4 -> 0x4fcc!] 22902+ PTR? xx.xxx.xxx.xx.in-addr.arpa. (44)
10.xx.xx.xxx.domain > 192.168.95.6.59068: [udp sum ok] 10889 ServFail q: PTR? xx.xxx.xxx.xx.in-addr.arpa. 0/0/0 (44)
12:31:13.616369 IP (tos 0x0, ttl 62, id 43144, offset 0, flags [none], proto UDP (17), length 72)




[sppadictest.yaml.txt](https://github.com/kubernetes/dns/files/2017641/sppadictest.yaml.txt)

The kube-dns deployment being used is attached here

Please could you advise if there's an option to disable PTR lookups as a flag or option within kube-dns container args. Have tried a few options with dnsmasq container as well but having no luck so far. Any help would be greatly appreciated

Cheers
Sppadic

",closed,False,2018-05-18 16:19:20,2018-12-16 11:55:11
dns,davidkarlsen,https://github.com/kubernetes/dns/issues/236,https://api.github.com/repos/kubernetes/dns/issues/236,kube-dns goes into CrashLoop on fresh install,"Install with kubeadm:
```
cat install.sh 
#!/bin/bash

swapoff -a
systemctl start docker.service

kubeadm init --pod-network-cidr=10.244.0.0/16 > /root/kubeinfo

mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

kubectl taint nodes main.davidkarlsen.com node-role.kubernetes.io/master-

kubectl apply -f rbac-kdd.yaml
kubectl apply -f calico.yaml 

kubectl get pods --namespace kube-system
```

Then add calico CNI as described here: 
https://docs.projectcalico.org/v3.1/getting-started/kubernetes/installation/calico#installing-with-the-kubernetes-api-datastore50-nodes-or-less
(setting the CIDR range to 10.244.0.0/16 to match kubeadm settings)

kube-dns goes into a crashloop on
```
W0522 23:30:43.131582    4695 docker_sandbox.go:353] failed to read pod IP from plugin/docker: NetworkPlugin cni failed on the st
atus hook for pod ""kube-dns-86f4d74b45-th84j_kube-system"": Unexpected command output nsenter: loadlocale.c:129: _nl_intern_locale_data: Assertion `cnt < (sizeof (_nl
_value_type_LC_TIME) / sizeof (_nl_value_type_LC_TIME[0]))' failed.
May 22 23:30:43 main kubelet[4695]:  with error: signal: aborted (core dumped)
```

Full log:

```
May 22 23:30:42 main kubelet[4695]: 2018-05-22 23:30:42.756 [INFO][25581] calico.go 167: Calico CNI found existing endpoint: &{{WorkloadEndpoint projectcalico.org/v3
} {main.davidkarlsen.com-k8s-kube--dns--86f4d74b45--th84j-eth0  kube-system  0c9044e7-5e05-11e8-a0e7-00902755ddee 1510 0 2018-05-22 23:14:01 +0200 CEST <nil> <nil> m
ap[projectcalico.org/orchestrator:k8s k8s-app:kube-dns pod-template-hash:4290830601 projectcalico.org/namespace:kube-system] map[] [] nil [] } {k8s  main.davidkarlse
n.com  kube-dns-86f4d74b45-th84j eth0 [10.244.0.9/32] []   [kns.kube-system] cali8e9732cd211  [{dns-local UDP 10053} {dns-tcp-local TCP 10053} {metrics TCP 10055} {d
ns UDP 53} {dns-tcp TCP 53} {metrics TCP 10054}]}} ContainerID=""c99834964a88891167edcde748d8b3b602e5642896cf62c5679fbe1a5d050f37"" Namespace=""kube-system"" Pod=""kube-d
ns-86f4d74b45-th84j"" WorkloadEndpoint=""main.davidkarlsen.com-k8s-kube--dns--86f4d74b45--th84j-""
May 22 23:30:42 main kubelet[4695]: 2018-05-22 23:30:42.756 [INFO][25581] k8s.go 59: Extracted identifiers for CmdAddK8s ContainerID=""c99834964a88891167edcde748d8b3b
602e5642896cf62c5679fbe1a5d050f37"" Namespace=""kube-system"" Pod=""kube-dns-86f4d74b45-th84j"" WorkloadEndpoint=""main.davidkarlsen.com-k8s-kube--dns--86f4d74b45--th84j-e
th0""
May 22 23:30:42 main kubelet[4695]: Calico CNI using IPs: [10.244.0.9/32]
May 22 23:30:42 main kubelet[4695]: 2018-05-22 23:30:42.756 [INFO][25581] network.go 31: Setting the host side veth name to cali8e9732cd211 ContainerID=""c99834964a88
891167edcde748d8b3b602e5642896cf62c5679fbe1a5d050f37"" Namespace=""kube-system"" Pod=""kube-dns-86f4d74b45-th84j"" WorkloadEndpoint=""main.davidkarlsen.com-k8s-kube--dns--
86f4d74b45--th84j-eth0""
May 22 23:30:42 main kubelet[4695]: 2018-05-22 23:30:42.757 [INFO][25581] network.go 326: Disabling IPv4 forwarding ContainerID=""c99834964a88891167edcde748d8b3b602e5
642896cf62c5679fbe1a5d050f37"" Namespace=""kube-system"" Pod=""kube-dns-86f4d74b45-th84j"" WorkloadEndpoint=""main.davidkarlsen.com-k8s-kube--dns--86f4d74b45--th84j-eth0""
May 22 23:30:42 main systemd-udevd[25588]: link_config: autonegotiation is unset or enabled, the speed and duplex are not writable.
May 22 23:30:42 main kubelet[4695]: 2018-05-22 23:30:42.773 [INFO][25581] k8s.go 303: Added Mac, interface name, and active container ID to endpoint ContainerID=""c99
834964a88891167edcde748d8b3b602e5642896cf62c5679fbe1a5d050f37"" Namespace=""kube-system"" Pod=""kube-dns-86f4d74b45-th84j"" WorkloadEndpoint=""main.davidkarlsen.com-k8s-ku
be--dns--86f4d74b45--th84j-eth0"" endpoint=&v3.WorkloadEndpoint{TypeMeta:v1.TypeMeta{Kind:""WorkloadEndpoint"", APIVersion:""projectcalico.org/v3""}, ObjectMeta:v1.Object
Meta{Name:""main.davidkarlsen.com-k8s-kube--dns--86f4d74b45--th84j-eth0"", GenerateName:"""", Namespace:""kube-system"", SelfLink:"""", UID:""0c9044e7-5e05-11e8-a0e7-00902755
ddee"", ResourceVersion:""1510"", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63662620441, loc:(*time.Location)(0x1ec5320)}}, DeletionTimestamp
:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{""pod-template-hash"":""4290830601"", ""projectcalico.org/namespace"":""kube-system"", ""
projectcalico.org/orchestrator"":""k8s"", ""k8s-app"":""kube-dns""}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initial
izers)(nil), Finalizers:[]string(nil), ClusterName:""""}, Spec:v3.WorkloadEndpointSpec{Orchestrator:""k8s"", Workload:"""", Node:""main.davidkarlsen.com"", ContainerID:""c998
34964a88891167edcde748d8b3b602e5642896cf62c5679fbe1a5d050f37"", Pod:""kube-dns-86f4d74b45-th84j"", Endpoint:""eth0"", IPNetworks:[]string{""10.244.0.9/32""}, IPNATs:[]v3.IP
NAT(nil), IPv4Gateway:"""", IPv6Gateway:"""", Profiles:[]string{""kns.kube-system""}, InterfaceName:""cali8e9732cd211"", MAC:""ae:cd:7a:ae:fd:f0"", Ports:[]v3.EndpointPort{v3.
EndpointPort{Name:""dns-local"", Protocol:numorstring.Protocol{Type:1, NumVal:0x0, StrVal:""UDP""}, Port:0x2745}, v3.EndpointPort{Name:""dns-tcp-local"", Protocol:numorstr
ing.Protocol{Type:1, NumVal:0x0, StrVal:""TCP""}, Port:0x2745}, v3.EndpointPort{Name:""metrics"", Protocol:numorstring.Protocol{Type:1, NumVal:0x0, StrVal:""TCP""}, Port:0
x2747}, v3.EndpointPort{Name:""dns"", Protocol:numorstring.Protocol{Type:1, NumVal:0x0, StrVal:""UDP""}, Port:0x35}, v3.EndpointPort{Name:""dns-tcp"", Protocol:numorstring
.Protocol{Type:1, NumVal:0x0, StrVal:""TCP""}, Port:0x35}, v3.EndpointPort{Name:""metrics"", Protocol:numorstring.Protocol{Type:1, NumVal:0x0, StrVal:""TCP""}, Port:0x2746
}}}}
May 22 23:30:42 main kubelet[4695]: 2018-05-22 23:30:42.780 [INFO][25581] k8s.go 311: Wrote updated endpoint to datastore ContainerID=""c99834964a88891167edcde748d8b3
b602e5642896cf62c5679fbe1a5d050f37"" Namespace=""kube-system"" Pod=""kube-dns-86f4d74b45-th84j"" WorkloadEndpoint=""main.davidkarlsen.com-k8s-kube--dns--86f4d74b45--th84j-
eth0""
May 22 23:30:43 main kubelet[4695]: W0522 23:30:43.131582    4695 docker_sandbox.go:353] failed to read pod IP from plugin/docker: NetworkPlugin cni failed on the st
atus hook for pod ""kube-dns-86f4d74b45-th84j_kube-system"": Unexpected command output nsenter: loadlocale.c:129: _nl_intern_locale_data: Assertion `cnt < (sizeof (_nl
_value_type_LC_TIME) / sizeof (_nl_value_type_LC_TIME[0]))' failed.
May 22 23:30:43 main kubelet[4695]:  with error: signal: aborted (core dumped)
May 22 23:30:43 main kubelet[4695]: I0522 23:30:43.132302    4695 kuberuntime_manager.go:757] checking backoff for container ""kubedns"" in pod ""kube-dns-86f4d74b45-th
84j_kube-system(0c9044e7-5e05-11e8-a0e7-00902755ddee)""
```

versions:
```
kubeadm version
kubeadm version: &version.Info{Major:""1"", Minor:""10"", GitVersion:""v1.10.3"", GitCommit:""2bba0127d85d5a46ab4b778548be28623b32d0b0"", GitTreeState:""clean"", BuildDate:""2018-05-21T09:05:37Z"", GoVersion:""go1.9.3"", Compiler:""gc"", Platform:""linux/amd64""}
root@main:~# kubectl version
Client Version: version.Info{Major:""1"", Minor:""10"", GitVersion:""v1.10.3"", GitCommit:""2bba0127d85d5a46ab4b778548be28623b32d0b0"", GitTreeState:""clean"", BuildDate:""2018-05-21T09:17:39Z"", GoVersion:""go1.9.3"", Compiler:""gc"", Platform:""linux/amd64""}
Server Version: version.Info{Major:""1"", Minor:""10"", GitVersion:""v1.10.3"", GitCommit:""2bba0127d85d5a46ab4b778548be28623b32d0b0"", GitTreeState:""clean"", BuildDate:""2018-05-21T09:05:37Z"", GoVersion:""go1.9.3"", Compiler:""gc"", Platform:""linux/amd64""}
```
",closed,False,2018-05-22 21:41:37,2018-05-23 12:52:09
dns,jessfraz,https://github.com/kubernetes/dns/issues/237,https://api.github.com/repos/kubernetes/dns/issues/237,Create a SECURITY_CONTACTS file.,"As per the email sent to kubernetes-dev[1], please create a SECURITY_CONTACTS
file.

The template for the file can be found in the kubernetes-template repository[2].
A description for the file is in the steering-committee docs[3], you might need
to search that page for ""Security Contacts"".

Please feel free to ping me on the PR when you make it, otherwise I will see when
you close this issue. :)

Thanks so much, let me know if you have any questions.

(This issue was generated from a tool, apologies for any weirdness.)

[1] https://groups.google.com/forum/#!topic/kubernetes-dev/codeiIoQ6QE
[2] https://github.com/kubernetes/kubernetes-template-project/blob/master/SECURITY_CONTACTS
[3] https://github.com/kubernetes/community/blob/master/committee-steering/governance/sig-governance-template-short.md
",closed,False,2018-05-24 14:42:59,2018-06-07 18:20:50
dns,hzjdyf,https://github.com/kubernetes/dns/issues/238,https://api.github.com/repos/kubernetes/dns/issues/238,Can not resolve 'mongdb-0.mongodb.default.svc.cluster.local',"I'm running a mongodb by statefulsets,but i can't resolve FQDN in busybox.

#kubectl get sts
NAME      DESIRED   CURRENT   AGE
mongodb   2         2         10m

#kubectl get po -l app=mongodb
NAME        READY     STATUS    RESTARTS   AGE
mongodb-0   1/1       Running   0          10m
mongodb-1   1/1       Running   0          10m

#kubectl exec busybox-78cd9bd6c7-vjflh -- nslookup mongodb-0.mongodb.default.svc.cluster.local
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

nslookup: can't resolve 'mongodb-0.mongodb.default.svc.cluster.local'
command terminated with exit code 1",closed,False,2018-05-29 01:42:05,2018-05-29 06:23:37
dns,joekohlsdorf,https://github.com/kubernetes/dns/issues/239,https://api.github.com/repos/kubernetes/dns/issues/239,Set low dnsmasq --neg-ttl instead of --no-negcache,"The following PR disabled caching of negative responses: https://github.com/kubernetes/kubernetes/pull/53604

I instead propose to have a negative response cache with a very low TTL. In our environment setting just `--neg-ttl=5` reduced the amount of queries to the upstream DNS server by a factor of 10. I think 5-10s is a reasonable tradeoff between speed of service-discovery, performance and cache effectiveness.

Reasoning: Every major cloud provider has a limit for the number of queries to their DNS servers, kube-dns should do as much as possible to reduce the number of queries hitting these. One kube-dns instance could be serving hundreds of containers and none of them are doing DNS caching.
Imagine an application which doesn't have database connection pooling, this leads to a query for every connection attempt to the upstream DNS servers because the resolver will always try to also look up AAAA records which in most cases don't exist. You could argue that the app is broken but traditionally the argument has always been that you should implement DNS caching, in Kubernetes the right place to do this is kube-dns.

I'll follow this issue up with a PR.",closed,False,2018-05-30 22:10:56,2018-10-28 00:32:14
dns,sgolightly,https://github.com/kubernetes/dns/issues/240,https://api.github.com/repos/kubernetes/dns/issues/240,Dnsmasq v2.79,"Very quick, and very simple query.  Is there any timescale for updating the version of dnsmasq to v2.79 ?
",closed,False,2018-06-01 12:12:55,2018-11-20 10:43:12
dns,MrHohn,https://github.com/kubernetes/dns/pull/241,https://api.github.com/repos/kubernetes/dns/issues/241,Add SECURITY_CONTACTS file,"Fixed https://github.com/kubernetes/dns/issues/237.

/assign @rramkumar1 
cc @bowei @jessfraz ",closed,True,2018-06-04 16:56:42,2018-06-07 18:20:57
dns,mat1010,https://github.com/kubernetes/dns/issues/242,https://api.github.com/repos/kubernetes/dns/issues/242,Resolve external IP addresses,"We'd like to access kube-dns from outside the k8s cluster to use it as discovery service also for services outside of the cluster. We were able to achive this by exposing kube-dns through a dedicated service with an external ip address (which is a zone internal GCP address).

A drawback is that it seems not possible to resolve the external ip of an service through kube-dns.

Would it be feasible to have an additional zone to resolve the external ip address of a service?",closed,False,2018-06-05 10:58:20,2018-11-02 23:52:38
dns,thockin,https://github.com/kubernetes/dns/issues/243,https://api.github.com/repos/kubernetes/dns/issues/243,kube-dns disregards stubDomains option while resolving externalName service,"Was https://github.com/kubernetes/kubernetes/issues/63821  @driusha

/kind bug

**What happened**:
I have:
* internal DNS ""10.2.2.10"" with zone ""example.com"" on it,
* stubDomains: {""example.com"": [""10.2.2.10""]}
* externalName service ""foo"" which points to domain ""foo.example.com""

When i try to resolve name ""foo"", i get NXDOMAIN.
If i try to create externalName (ex. mail -> mail.google.com) without stubDomains, everything works.

**Environment**:
- Kubernetes version v1.8.5
- kube-dns version 1.14.5
",open,False,2018-06-06 21:20:27,2019-01-02 18:15:26
dns,geosword,https://github.com/kubernetes/dns/issues/244,https://api.github.com/repos/kubernetes/dns/issues/244,"x509: certificate signed by unknown authority (possibly because of ""crypto/rsa: verification error"" while trying to verify candidate authority certificate","This is happening on version 1.14.8 and potentially others.

Its running in a container, specifically gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.8 as part of a kubernetes cluster.
I have a self signed certificate on the apiserver, which understandably throws the usual verification errors if accessed with curl (from the command line of anything), without -k. The output from kube-dns however seems to imply that -k is used, although I can find no evidence of curl actually existing on the container, which leads me to believe that the binary curl is not actually being called, but the curl command is just being output to ""help"". The existence of toCurl in round_trippers.go seems to back this theory up.

The problem I am facing is this error message:

```
I0610 06:47:06.051414       1 round_trippers.go:398] curl -k -v -XGET  -H ""User-Agent: kube-dns/1.14.10 (linux/amd64)"" -H ""Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6Ikp... rest of barer token"" -H ""Accept: application/vnd.kubernetes.protobuf, */*"" https://172.17.0.1:443/api/v1/services?resourceVersion=0
`E0610 06:47:05.058513       1 reflector.go:201] k8s.io/dns/pkg/dns/dns.go:189: Failed to list *v1.Endpoints: Get https://172.17.0.1:443/api/v1/endpoints?resourceVersion=0: x509: certificate signed by unknown authority (possibly because of ""crypto/rsa: verification error"" while trying to verify candidate authority certificate ""10.16.23.40"")`
```
10.16.23.40 is the ""real"" address of my master, 172.17.0.1 is the service address of the master.

Yes, the certificate is self-signed, and therefore ""signed by an unknown authority"" but if its making the call with -k (or whatever its equivalent is within the code) Then that should not be an issue. 

I have attached the output of openssh x509 on the certificate served by 172.17.0.1 / 10.16.23.40 for review. Please let me know if you need more information. 

How can I get around this problem? Thanks in advance.

Dylan
[certinfo.txt](https://github.com/kubernetes/dns/files/2087616/certinfo.txt)


",closed,False,2018-06-10 07:24:12,2018-11-09 18:32:31
dns,chrisohaver,https://github.com/kubernetes/dns/pull/245,https://api.github.com/repos/kubernetes/dns/issues/245,DNS Spec: Headless service with no ready endpoints ,"Proposing that a headless service without any ready endpoints should return `NXDOMAIN`, to match current behavior of kube-dns and CoreDNS.

I'm proposing we update the spec to match the implementation of kube-dns, because the spec was initially based on kube-dns behavior.

If we don't update the spec, then we should open bugs for kube-dns (and CoreDNS) and fix.

see #234",closed,True,2018-06-12 15:20:41,2018-08-21 15:40:45
dns,AwkwardBen,https://github.com/kubernetes/dns/issues/246,https://api.github.com/repos/kubernetes/dns/issues/246,Failed to create pod sandbox with cannot convert: no valid IP addresses warning,"Hi all, let me know if this is the right place to make this issue. I'm not sure if this is strictly a kube-dns fault, might be just kubernetes, so happy to go somewhere else.

So I've been trying to build a single node kubernetes cluster from scratch. I've essentially built from a base linux kernel, installed kuberetes packages (kubelet, kubeadm, kubectl) and ran kubelet and kubeadm with the following config:

```
kubelet --kubeconfig=/etc/kubernetes/kubelet.conf \
	      --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf \
	      --pod-manifest-path=/etc/kubernetes/manifests \
	      --allow-privileged=true \
	      --cluster-dns=10.200.0.10 \
	      --cluster-domain=cluster.local \
	      --cgroups-per-qos=false \
	      --enforce-node-allocatable= \
	      --network-plugin=cni \
	      --cni-conf-dir=/etc/cni/net.d \
	      --cni-bin-dir=/opt/cni/bin \
	      --cadvisor-port=0 \
	      --kube-reserved-cgroup=podruntime \
	      --system-reserved-cgroup=systemreserved \
	      --cgroup-root=kubepods
```
```
kubeadm init --ignore-preflight-errors=all --kubernetes-version @KUBERNETES_VERSION@ --pod-network-cidr=10.244.0.0/24 --service-cidr 10.200.0.0/16
```
Everything looks to run fine however by the end the `kube-dns` pod is in a perpetual ContainerCreating loop. When describing the pod I get the following events:

```
....
Warning  FailedCreatePodSandBox  15m                kubelet, linuxkit-080027862cb5  Failed create pod sandbox: rpc error: code = Unknown desc = failed to setup network for sandbox ""fda56a8c8d210e703633cf31e2c41db5ab4a5fc736f311a75fec8ce3a381b109"": cannot convert: no valid IP addresses
Warning  FailedCreatePodSandBox  2m (x60 over 15m)  kubelet, linuxkit-080027862cb5  (combined from similar events): Failed create pod sandbox: rpc error: code = Unknown desc = failed to setup network for sandbox ""a458f8d42510a985a9103d86dd51febc0a4987070e73038c40682798661212e8"": cannot convert: no valid IP addresses
...
```
I'm using canal to do my nextworking, my ip links address and iptables are the following:
```
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 brd 127.255.255.255 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
2: tunl0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000
    link/ipip 0.0.0.0 brd 0.0.0.0
3: ip6tnl0@NONE: <NOARP> mtu 1452 qdisc noop state DOWN group default qlen 1000
    link/tunnel6 :: brd ::
4: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:86:2c:b5 brd ff:ff:ff:ff:ff:ff
    inet 192.168.57.2/24 brd 192.167.57.255 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::a00:27ff:fe86:2cb5/64 scope link
       valid_lft forever preferred_lft forever
5: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:db:86:a4 brd ff:ff:ff:ff:ff:ff
    inet 10.0.3.15/24 brd 10.0.3.255 scope global eth1
       valid_lft forever preferred_lft forever
    inet6 fe80::9369:8f21:8839:f419/64 scope link
       valid_lft forever preferred_lft forever
6: flannel.1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1450 qdisc noqueue state UNKNOWN group default
    link/ether be:f0:4d:88:f0:f3 brd ff:ff:ff:ff:ff:ff
    inet 10.244.0.0/32 scope global flannel.1
       valid_lft forever preferred_lft forever
    inet6 fe80::bcf0:4dff:fe88:f0f3/64 scope link
       valid_lft forever preferred_lft forever
```
```
Chain INPUT (policy ACCEPT)
target     prot opt source               destination
cali-INPUT  all  --  anywhere             anywhere             /* cali:Cz_u1IQiXIMmKD4c */
KUBE-EXTERNAL-SERVICES  all  --  anywhere             anywhere             ctstate NEW /* kubernetes externally-visible service portals */
KUBE-FIREWALL  all  --  anywhere             anywhere

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination
cali-FORWARD  all  --  anywhere             anywhere             /* cali:wUHhoiAYhphO9Mso */
KUBE-FORWARD  all  --  anywhere             anywhere             /* kubernetes forwarding rules */

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
cali-OUTPUT  all  --  anywhere             anywhere             /* cali:tVnHkvAo15HuiPy0 */
KUBE-SERVICES  all  --  anywhere             anywhere             ctstate NEW /* kubernetes service portals */
KUBE-FIREWALL  all  --  anywhere             anywhere

Chain KUBE-EXTERNAL-SERVICES (1 references)
target     prot opt source               destination

Chain KUBE-FIREWALL (2 references)
target     prot opt source               destination
DROP       all  --  anywhere             anywhere             /* kubernetes firewall for dropping marked packets */ mark match 0x8000/0x8000

Chain KUBE-FORWARD (1 references)
target     prot opt source               destination
ACCEPT     all  --  anywhere             anywhere             /* kubernetes forwarding rules */ mark match 0x4000/0x4000
ACCEPT     all  --  10.244.0.0/24        anywhere             /* kubernetes forwarding conntrack pod source rule */ ctstate RELATED,ESTABLISHED
ACCEPT     all  --  anywhere             10.244.0.0/24        /* kubernetes forwarding conntrack pod destination rule */ ctstate RELATED,ESTABLISHED

Chain KUBE-SERVICES (1 references)
target     prot opt source               destination
REJECT     udp  --  anywhere             10.200.0.10          /* kube-system/kube-dns:dns has no endpoints */ udp dpt:domain reject-with icmp-port-unreachable
REJECT     tcp  --  anywhere             10.200.0.10          /* kube-system/kube-dns:dns-tcp has no endpoints */ tcp dpt:domain reject-with icmp-port-unreachable

Chain cali-FORWARD (1 references)
target     prot opt source               destination
cali-from-wl-dispatch  all  --  anywhere             anywhere             /* cali:X3vB2lGcBrfkYquC */
cali-to-wl-dispatch  all  --  anywhere             anywhere             /* cali:UtJ9FnhBnFbyQMvU */
ACCEPT     all  --  anywhere             anywhere             /* cali:Tt19HcSdA5YIGSsw */
ACCEPT     all  --  anywhere             anywhere             /* cali:9LzfFCvnpC5_MYXm */
MARK       all  --  anywhere             anywhere             /* cali:7AofLLOqCM5j36rM */ MARK and 0xf1ffffff
cali-from-host-endpoint  all  --  anywhere             anywhere             /* cali:QM1_joSl7tL76Az7 */ mark match 0x0/0x1000000
cali-to-host-endpoint  all  --  anywhere             anywhere             /* cali:C1QSog3bk0AykjAO */
ACCEPT     all  --  anywhere             anywhere             /* cali:DmFiPAmzcisqZcvo */ /* Host endpoint policy accepted packet. */ mark match 0x1000000/0x1000000

Chain cali-INPUT (1 references)
target     prot opt source               destination
ACCEPT     all  --  anywhere             anywhere             /* cali:i7okJZpS8VxaJB3n */ mark match 0x1000000/0x1000000
cali-wl-to-host  all  --  anywhere             anywhere            [goto]  /* cali:JaoDb6CLdcGw8g0Y */
MARK       all  --  anywhere             anywhere             /* cali:c5eKVW2VdKQ_LiSM */ MARK and 0xf0ffffff
cali-from-host-endpoint  all  --  anywhere             anywhere             /* cali:hwQKYSlSCkpE_9uN */
ACCEPT     all  --  anywhere             anywhere             /* cali:ttp8-serzKCP-bKZ */ /* Host endpoint policy accepted packet. */ mark match 0x1000000/0x1000000

Chain cali-OUTPUT (1 references)
target     prot opt source               destination
ACCEPT     all  --  anywhere             anywhere             /* cali:YQSSJIsRcHjFbXaI */ mark match 0x1000000/0x1000000
RETURN     all  --  anywhere             anywhere             /* cali:KRjBsKsBcFBYKCEw */
MARK       all  --  anywhere             anywhere             /* cali:3VKAQBcyUUW5kS_j */ MARK and 0xf0ffffff
cali-to-host-endpoint  all  --  anywhere             anywhere             /* cali:Z1mBCSH1XHM6qq0k */
ACCEPT     all  --  anywhere             anywhere             /* cali:N0jyWt2RfBedKw3L */ /* Host endpoint policy accepted packet. */ mark match 0x1000000/0x1000000

Chain cali-failsafe-in (0 references)
target     prot opt source               destination
ACCEPT     tcp  --  anywhere             anywhere             /* cali:wWFQM43tJU7wwnFZ */ multiport dports ssh
ACCEPT     udp  --  anywhere             anywhere             /* cali:LwNV--R8MjeUYacw */ multiport dports bootpc

Chain cali-failsafe-out (0 references)
target     prot opt source               destination
ACCEPT     tcp  --  anywhere             anywhere             /* cali:73bZKoyDfOpFwC2T */ multiport dports 2379
ACCEPT     tcp  --  anywhere             anywhere             /* cali:QMFuWo6o-d9yOpNm */ multiport dports 2380
ACCEPT     tcp  --  anywhere             anywhere             /* cali:Kup7QkrsdmfGX0uL */ multiport dports 4001
ACCEPT     tcp  --  anywhere             anywhere             /* cali:xYYr5PEqDf_Pqfkv */ multiport dports afs3-callback
ACCEPT     udp  --  anywhere             anywhere             /* cali:nbWBvu4OtudVY60Q */ multiport dports domain
ACCEPT     udp  --  anywhere             anywhere             /* cali:UxFu5cDK5En6dT3Y */ multiport dports bootps

Chain cali-from-host-endpoint (2 references)
target     prot opt source               destination

Chain cali-from-wl-dispatch (2 references)
target     prot opt source               destination
DROP       all  --  anywhere             anywhere             /* cali:zTj6P0TIgYvgz-md */ /* Unknown interface */

Chain cali-to-host-endpoint (2 references)
target     prot opt source               destination

Chain cali-to-wl-dispatch (1 references)
target     prot opt source               destination
DROP       all  --  anywhere             anywhere             /* cali:7KNphB1nNHw80nIO */ /* Unknown interface */

Chain cali-wl-to-host (1 references)
target     prot opt source               destination
cali-from-wl-dispatch  all  --  anywhere             anywhere             /* cali:Ee9Sbo10IpVujdIY */
ACCEPT     all  --  anywhere             anywhere             /* cali:nSZbcOoG1xPONxb8 */ /* Configured DefaultEndpointToHostAction */
```

Please ask any questions and I'll update with more information below.",closed,False,2018-06-28 08:59:40,2018-06-28 21:29:08
dns,jingslunt,https://github.com/kubernetes/dns/issues/247,https://api.github.com/repos/kubernetes/dns/issues/247,what's my problem whith kube-dns? i can't fix it,"logs:
```
[root@localhost kube-dns]# kubectl logs --namespace=kube-system $(kubectl get pods --namespace=kube-system -l k8s-app=kube-dns -o name) -c kubedns
error: You must be logged in to the server (the server has asked for the client to provide credentials ( pods/log kube-dns-b7b8648f8-8zgb8))
[root@localhost kube-dns]# 
[root@localhost kube-dns]# 
[root@localhost kube-dns]# 
[root@localhost kube-dns]# docker ps -a |grep kube-dns|awk '{print $1}'|head -n 4|xargs -i docker logs {}
I0713 08:46:48.133840       1 dns.go:48] version: 1.14.6-3-gc36cb11
I0713 08:46:48.134135       1 server.go:69] Using configuration read from directory: /kube-dns-config with period 10s
I0713 08:46:48.134163       1 server.go:112] FLAG: --alsologtostderr=""false""
I0713 08:46:48.134167       1 server.go:112] FLAG: --config-dir=""/kube-dns-config""
I0713 08:46:48.134170       1 server.go:112] FLAG: --config-map=""""
I0713 08:46:48.134171       1 server.go:112] FLAG: --config-map-namespace=""kube-system""
I0713 08:46:48.134173       1 server.go:112] FLAG: --config-period=""10s""
I0713 08:46:48.134176       1 server.go:112] FLAG: --dns-bind-address=""0.0.0.0""
I0713 08:46:48.134178       1 server.go:112] FLAG: --dns-port=""10053""
I0713 08:46:48.134180       1 server.go:112] FLAG: --domain=""cluster.local.""
I0713 08:46:48.134183       1 server.go:112] FLAG: --federations=""""
I0713 08:46:48.134186       1 server.go:112] FLAG: --healthz-port=""8081""
I0713 08:46:48.134188       1 server.go:112] FLAG: --initial-sync-timeout=""1m0s""
I0713 08:46:48.134189       1 server.go:112] FLAG: --kube-master-url=""http://192.168.1.234:8080""
I0713 08:46:48.134192       1 server.go:112] FLAG: --kubecfg-file=""""
I0713 08:46:48.134194       1 server.go:112] FLAG: --log-backtrace-at="":0""
I0713 08:46:48.134197       1 server.go:112] FLAG: --log-dir=""""
I0713 08:46:48.134199       1 server.go:112] FLAG: --log-flush-frequency=""5s""
I0713 08:46:48.134200       1 server.go:112] FLAG: --logtostderr=""true""
I0713 08:46:48.134202       1 server.go:112] FLAG: --nameservers=""""
I0713 08:46:48.134204       1 server.go:112] FLAG: --stderrthreshold=""2""
I0713 08:46:48.134205       1 server.go:112] FLAG: --v=""2""
I0713 08:46:48.134207       1 server.go:112] FLAG: --version=""false""
I0713 08:46:48.134210       1 server.go:112] FLAG: --vmodule=""""
I0713 08:46:48.134246       1 server.go:194] Starting SkyDNS server (0.0.0.0:10053)
I0713 08:46:48.134413       1 server.go:213] Skydns metrics enabled (/metrics:10055)
I0713 08:46:48.134419       1 dns.go:146] Starting endpointsController
I0713 08:46:48.134421       1 dns.go:149] Starting serviceController
I0713 08:46:48.134479       1 sync.go:167] Updated stubDomains to map[baidu.com:[114.114.114.114]]
I0713 08:46:48.134518       1 sync.go:177] Updated upstreamNameservers to [114.114.114.114 8.8.4.4]
I0713 08:46:48.134718       1 logs.go:41] skydns: ready for queries on cluster.local. for tcp://0.0.0.0:10053 [rcache 0]
I0713 08:46:48.134722       1 logs.go:41] skydns: ready for queries on cluster.local. for udp://0.0.0.0:10053 [rcache 0]
I0713 08:46:48.645028       1 dns.go:170] Initialized services and endpoints from apiserver
I0713 08:46:48.645064       1 server.go:128] Setting up Healthz Handler (/readiness)
I0713 08:46:48.645087       1 server.go:133] Setting up cache handler (/cache)
I0713 08:46:48.645226       1 server.go:119] Status HTTP port 8081
I0713 08:48:24.129845       1 server.go:153] Ignoring signal terminated (can only be terminated by SIGKILL)
I0713 08:46:16.193236       1 main.go:76] opts: {{/usr/sbin/dnsmasq [-k --cache-size=1000 --no-negcache --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/ip6.arpa/127.0.0.1#10053] true} /etc/k8s/dns/dnsmasq-nanny 10000000000}
I0713 08:46:16.193363       1 sync.go:167] Updated stubDomains to map[baidu.com:[114.114.114.114]]
I0713 08:46:16.193372       1 sync.go:177] Updated upstreamNameservers to [114.114.114.114 8.8.4.4]
I0713 08:46:16.193387       1 nanny.go:94] Starting dnsmasq [-k --cache-size=1000 --no-negcache --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/ip6.arpa/127.0.0.1#10053 --server /baidu.com/114.114.114.114 --server 114.114.114.114 --server 8.8.4.4 --no-resolv]
I0713 08:46:16.200118       1 nanny.go:119] 
W0713 08:46:16.200126       1 nanny.go:120] Got EOF from stdout
I0713 08:46:16.200135       1 nanny.go:116] dnsmasq[8]: started, version 2.78 cachesize 1000
I0713 08:46:16.200142       1 nanny.go:116] dnsmasq[8]: compile time options: IPv6 GNU-getopt no-DBus no-i18n no-IDN DHCP DHCPv6 no-Lua TFTP no-conntrack ipset auth no-DNSSEC loop-detect inotify
I0713 08:46:16.200145       1 nanny.go:116] dnsmasq[8]: using nameserver 8.8.4.4#53
I0713 08:46:16.200146       1 nanny.go:116] dnsmasq[8]: using nameserver 114.114.114.114#53
I0713 08:46:16.200148       1 nanny.go:116] dnsmasq[8]: using nameserver 114.114.114.114#53 for domain baidu.com 
I0713 08:46:16.200150       1 nanny.go:116] dnsmasq[8]: using nameserver 127.0.0.1#10053 for domain ip6.arpa 
I0713 08:46:16.200152       1 nanny.go:116] dnsmasq[8]: using nameserver 127.0.0.1#10053 for domain in-addr.arpa 
I0713 08:46:16.200154       1 nanny.go:116] dnsmasq[8]: using nameserver 127.0.0.1#10053 for domain cluster.local 
I0713 08:46:16.200156       1 nanny.go:116] dnsmasq[8]: read /etc/hosts - 7 addresses
I0713 08:44:35.167554       1 main.go:51] Version v1.14.6-3-gc36cb11
I0713 08:44:35.167602       1 server.go:45] Starting server (options {DnsMasqPort:53 DnsMasqAddr:127.0.0.1 DnsMasqPollIntervalMs:5000 Probes:[{Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33} {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33}] PrometheusAddr:0.0.0.0 PrometheusPort:10054 PrometheusPath:/metrics PrometheusNamespace:kubedns})
I0713 08:44:35.167620       1 dnsprobe.go:75] Starting dnsProbe {Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33}
I0713 08:44:35.167648       1 dnsprobe.go:75] Starting dnsProbe {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33}
W0713 08:44:35.169894       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:49292->127.0.0.1:53: read: connection refused
W0713 08:44:40.170611       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:39291->127.0.0.1:53: read: connection refused
W0713 08:44:45.171372       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:49098->127.0.0.1:53: read: connection refused
W0713 08:44:50.172549       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:42922->127.0.0.1:53: read: connection refused
W0713 08:44:55.173747       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:50798->127.0.0.1:53: read: connection refused
W0713 08:45:00.174531       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:50285->127.0.0.1:53: read: connection refused
W0713 08:45:05.175497       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:56338->127.0.0.1:53: read: connection refused
W0713 08:45:10.176479       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:36572->127.0.0.1:53: read: connection refused
W0713 08:45:15.177405       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:34295->127.0.0.1:53: read: connection refused
W0713 08:45:20.178143       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:43430->127.0.0.1:53: read: connection refused
```


- and my kube-dns.yml
```
# Copyright 2016 The Kubernetes Authors.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Should keep target in cluster/addons/dns-horizontal-autoscaler/dns-horizontal-autoscaler.yaml
# in sync with this file.

# Warning: This is a file generated from the base underscore template file: kube-dns.yaml.base

apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: ""true""
    addonmanager.kubernetes.io/mode: Reconcile
    kubernetes.io/name: ""KubeDNS""
spec:
  selector:
    k8s-app: kube-dns
  clusterIP: 10.0.244.1
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: EnsureExists
data:
  stubDomains: |
    {""baidu.com"": [""114.114.114.114""]}
  upstreamNameservers: |
    [""114.114.114.114"", ""8.8.4.4""]
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: kube-dns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: ""true""
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  # replicas: not specified here:
  # 1. In order to make Addon Manager do not reconcile this replicas parameter.
  # 2. Default is 1.
  # 3. Will be tuned in real time if DNS horizontal auto-scaling is turned on.
  strategy:
    rollingUpdate:
      maxSurge: 10%
      maxUnavailable: 0
  selector:
    matchLabels:
      k8s-app: kube-dns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      tolerations:
      - key: ""CriticalAddonsOnly""
        operator: ""Exists""
      volumes:
      - name: kube-dns-config
        configMap:
          name: kube-dns
          optional: true
      #imagePullSecrets:
      containers:
      - name: kubedns
        image: gcr.io/google_containers/k8s-dns-kube-dns-amd64:1.14.7
        resources:
          # TODO: Set memory limits when we've profiled the container for large
          # clusters, then set request = limit to keep this container in
          # guaranteed class. Currently, this container falls into the
          # ""burstable"" category so the kubelet doesn't backoff from restarting it.
          limits:
            memory: 170Mi
          requests:
            cpu: 100m
            memory: 70Mi
        livenessProbe:
          httpGet:
            path: /healthcheck/kubedns
            port: 10054
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
        readinessProbe:
          httpGet:
            path: /readiness
            port: 8081
            scheme: HTTP
          # we poll on pod startup for the Kubernetes master service and
          # only setup the /readiness HTTP server once that's available.
          initialDelaySeconds: 3
          timeoutSeconds: 5
        args:
        - --domain=cluster.local
        - --dns-port=10053
        - --config-dir=/kube-dns-config
        - --kube-master-url=http://192.168.1.234:8080
        - --v=2
        env:
        - name: PROMETHEUS_PORT
          value: ""10055""
        ports:
        - containerPort: 10053
          name: dns-local
          protocol: UDP
        - containerPort: 10053
          name: dns-tcp-local
          protocol: TCP
        - containerPort: 10055
          name: metrics
          protocol: TCP
        volumeMounts:
        - name: kube-dns-config
          mountPath: /kube-dns-config
      - name: dnsmasq
        image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.7
        livenessProbe:
          httpGet:
            path: /healthcheck/dnsmasq
            port: 10054
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
        args:
        - -v=2
        - -logtostderr
        - -configDir=/etc/k8s/dns/dnsmasq-nanny
        - -restartDnsmasq=true
        - --
        - -k
        - --cache-size=1000
        - --no-negcache
        - --log-facility=-
        - --server=/cluster.local/127.0.0.1#10053
        - --server=/in-addr.arpa/127.0.0.1#10053
        - --server=/ip6.arpa/127.0.0.1#10053
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        # see: https://github.com/kubernetes/kubernetes/issues/29055 for details
        resources:
          requests:
            cpu: 150m
            memory: 20Mi
        volumeMounts:
        - name: kube-dns-config
          mountPath: /etc/k8s/dns/dnsmasq-nanny
      - name: sidecar
        image: gcr.io/google_containers/k8s-dns-sidecar-amd64:1.14.7
        livenessProbe:
          httpGet:
            path: /metrics
            port: 10054
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
        args:
        - --v=2
        - --logtostderr
        - --probe=kubedns,127.0.0.1:10053,kubernetes.default.svc.cluster.local,5,SRV
        - --probe=dnsmasq,127.0.0.1:53,kubernetes.default.svc.cluster.local,5,SRV
        ports:
        - containerPort: 10054
          name: metrics
          protocol: TCP
        resources:
          requests:
            memory: 20Mi
            cpu: 10m
      dnsPolicy: Default  # Don't use cluster DNS.

```

 Installed whith Binaries file
> https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.10.md
Not kube-dns Binaries file ",closed,False,2018-07-13 08:58:48,2018-10-08 04:13:12
dns,visokoo,https://github.com/kubernetes/dns/issues/248,https://api.github.com/repos/kubernetes/dns/issues/248,DNS resolution uses resolv.conf nameserver even though upstreamNameserver is specified...,"**What happened**
We're planning to use consul as a DNS server for internal services and also as a forwarder for external domains.
 
Following this [article](https://kubernetes.io/blog/2017/04/configuring-private-dns-zones-upstream-nameservers-kubernetes/) it looks like all we need to do is specify the `upstreamNameservers` in the kube-dns config map with our consul box IP. 
```
apiVersion: v1
data:
  upstreamNameservers: |
    [""10.255.0.6""]
kind: ConfigMap
metadata:
  creationTimestamp: 2018-07-21T00:14:39Z
  name: kube-dns
  namespace: kube-system
  resourceVersion: ""333414""
  selfLink: /api/v1/namespaces/kube-system/configmaps/kube-dns
  uid: 0f01cb8d-8c7b-11e8-ab6c-000d3af949c9
```
After doing this and ssh-ing into a pod to do an `nslookup active.vault.service.<mydomain>.int`, I get 
```Server:		10.0.0.10
Address:	10.0.0.10#53

** server can't find vault.service.<mydomain>.int: NXDOMAIN
```
Doing a tcpdump on the consul box yields intermittent activity:
```
08:27:54.337823 IP (tos 0x0, ttl 64, id 50796, offset 0, flags [DF], proto UDP (17), length 99)
    10.2.20.4.47202 > 10.255.0.6.53: [udp sum ok] 7008+ A? vault.service.<mydomain>.int.default.svc.cluster.local. (71)
08:27:54.338063 IP (tos 0x0, ttl 64, id 62340, offset 0, flags [DF], proto UDP (17), length 99)
    10.255.0.6.36954 > 8.8.8.8.53: [bad udp cksum 0x1b75 -> 0x3ab1!] 7008+ A? vault.service.<mydomain>.int.default.svc.cluster.local. (71)
08:27:54.339406 IP (tos 0x0, ttl 64, id 12324, offset 0, flags [DF], proto UDP (17), length 91)
    10.2.20.35.27387 > 10.255.0.6.53: [udp sum ok] 48234+ A? vault.service.<mydomain>.int.svc.cluster.local. (63)
08:27:54.339564 IP (tos 0x0, ttl 64, id 62341, offset 0, flags [DF], proto UDP (17), length 91)
    10.255.0.6.51761 > 8.8.8.8.53: [bad udp cksum 0x1b6d -> 0x9a93!] 48234+ A? vault.service.<mydomain>.int.svc.cluster.local. (63)
08:27:54.359153 IP (tos 0x0, ttl 117, id 36005, offset 0, flags [none], proto UDP (17), length 174)
    8.8.8.8.53 > 10.255.0.6.36954: [udp sum ok] 7008 NXDomain q: A? vault.service.<mydomain>.int.default.svc.cluster.local. 0/1/0 ns: . [23h59m4s] SOA a.root-servers.net. nstld.verisign-grs.com. 2018072100 1800 900 604800 86400 (146)
08:27:54.359283 IP (tos 0x0, ttl 64, id 3375, offset 0, flags [DF], proto UDP (17), length 174)
    10.255.0.6.53 > 10.2.20.4.47202: [bad udp cksum 0x29b6 -> 0xf7be!] 7008 NXDomain q: A? vault.service.<mydomain>.int.default.svc.cluster.local. 0/1/0 ns: . [23h59m4s] SOA a.root-servers.net. nstld.verisign-grs.com. 2018072100 1800 900 604800 86400 (146)
08:27:54.360847 IP (tos 0x0, ttl 117, id 37226, offset 0, flags [none], proto UDP (17), length 166)
    8.8.8.8.53 > 10.255.0.6.51761: [udp sum ok] 48234 NXDomain q: A? vault.service.<mydomain>.int.svc.cluster.local. 0/1/0 ns: . [23h59m44s] SOA a.root-servers.net. nstld.verisign-grs.com. 2018072100 1800 900 604800 86400 (138)
08:27:54.360922 IP (tos 0x0, ttl 64, id 29473, offset 0, flags [DF], proto UDP (17), length 166)
    10.255.0.6.53 > 10.2.20.35.27387: [bad udp cksum 0x29cd -> 0xde98!] 48234 NXDomain q: A? vault.service.<mydomain>.int.svc.cluster.local. 0/1/0 ns: . [23h59m44s] SOA a.root-servers.net. nstld.verisign-grs.com. 2018072100 1800 900 604800 86400 (138)
```

Question here...why does my query have the kubernetes search domains appended to it?

Looking at the tcpdump on the dnsmasq container, if I try to nslookup the consul domain, it never forwards to the upstream:
```
08:45:50.100471 IP (tos 0x0, ttl 64, id 60390, offset 0, flags [none], proto UDP (17), length 80)
    10.2.20.35.36683 > 10.2.20.49.53: [udp sum ok] 36502+ A? active.vault.service.<mydomain>.int. (52)
08:45:50.100566 IP (tos 0x0, ttl 64, id 32274, offset 0, flags [DF], proto UDP (17), length 80)
    10.2.20.49.53 > 10.2.20.35.36683: [bad udp cksum 0x3ca5 -> 0xd711!] 36502 NXDomain q: A? active.vault.service.<mydomain>.int. 0/0/0 (52)
08:45:50.102796 IP (tos 0x0, ttl 64, id 60392, offset 0, flags [none], proto UDP (17), length 80)
    10.2.20.35.55995 > 10.2.20.49.53: [udp sum ok] 37264+ A? active.vault.service.<mydomain>.int. (52)
08:45:50.102846 IP (tos 0x0, ttl 64, id 32275, offset 0, flags [DF], proto UDP (17), length 80)
    10.2.20.49.53 > 10.2.20.35.55995: [bad udp cksum 0x3ca5 -> 0x88a7!] 37264 NXDomain q: A? active.vault.service.<mydomain>.int. 0/0/0 (52)
08:45:50.103696 IP (tos 0x0, ttl 64, id 60393, offset 0, flags [none], proto UDP (17), length 80)
    10.2.20.35.43475 > 10.2.20.49.53: [udp sum ok] 14640+ A? active.vault.service.<mydomain>.int. (52)
08:45:50.103753 IP (tos 0x0, ttl 64, id 32276, offset 0, flags [DF], proto UDP (17), length 80)
    10.2.20.49.53 > 10.2.20.35.43475: [bad udp cksum 0x3ca5 -> 0x11f0!] 14640 NXDomain q: A? active.vault.service.<mydomain>.int. 0/0/0 (52)
```

If I look up an external DNS, I do see that it eventually forwards to the resolv.conf azure nameserver (168.63.129.16.53). Since I have upstreamNameservers specified, should it not that instead of what's in resolv.conf?

If I add a separate `stubDomain` just for the consul stuff, resolution works, but the article above seems to be worded in a way that indicates as long as your dnsPolicy is ClusterFirst and you're specifying an upstreamNameserver... if the domain isn't cluster.local, it should forward to your specified upstream. Is this not the case?  Just need some clarity here...

**Env**
Azure
Kubernetes 1.9.6
KubeDNS 1.14.8
dnsPolicy: ClusterFirst
",closed,False,2018-07-21 09:04:56,2018-07-26 23:08:10
dns,Grigsuv,https://github.com/kubernetes/dns/issues/249,https://api.github.com/repos/kubernetes/dns/issues/249,How make all this ??,"I need some docs,guide on how to build/create or smt else,I need internal dns addresses,In repo I can't find full info",closed,False,2018-07-31 13:38:58,2018-08-01 12:48:10
dns,dnivra26,https://github.com/kubernetes/dns/issues/250,https://api.github.com/repos/kubernetes/dns/issues/250,Kubernetes DNS failure - invalid argument,"**Is this a BUG REPORT or FEATURE REQUEST?**:
bug


**What happened**:
Seeing errors in kube dns logs. Happens randomly for a minute and things start working fine after that. Happens atleast twice a day.

**Logs**
```
I0804 04:55:03.399155       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:49635: sendmsg: invalid argument""
I0804 04:55:03.402151       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:31592: sendmsg: invalid argument""
I0804 04:55:03.406972       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:19990: sendmsg: invalid argument""
I0804 04:55:03.453005       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:34728: sendmsg: invalid argument""
I0804 04:55:03.455250       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:3617: sendmsg: invalid argument""
I0804 04:55:03.468915       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:54000: sendmsg: invalid argument""
I0804 04:55:03.469263       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:35533: sendmsg: invalid argument""
I0804 04:55:03.470293       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:25813: sendmsg: invalid argument""
I0804 04:55:03.470475       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:16582: sendmsg: invalid argument""
I0804 04:55:03.470565       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:62002: sendmsg: invalid argument""
I0804 04:55:03.506093       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:60521: sendmsg: invalid argument""
I0804 04:55:03.510177       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:37393: sendmsg: invalid argument""
I0804 04:55:03.564147       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:32353: sendmsg: invalid argument""
I0804 04:55:03.580297       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:55905: sendmsg: invalid argument""
I0804 04:55:06.015029       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:7143: sendmsg: invalid argument""
I0804 04:55:10.636486       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:7779: sendmsg: invalid argument""
I0804 04:55:15.924357       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:5195: sendmsg: invalid argument""
I0804 04:55:16.765978       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:15989: sendmsg: invalid argument""
I0804 04:55:16.780439       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:12029: sendmsg: invalid argument""
I0804 04:55:18.837547       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:39970: sendmsg: invalid argument""
I0804 04:55:18.865663       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:18862: sendmsg: invalid argument""
I0804 04:55:18.866104       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:56815: sendmsg: invalid argument""
I0804 04:55:18.893371       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:4536: sendmsg: invalid argument""
I0804 04:55:18.894658       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:55537: sendmsg: invalid argument""
I0804 04:55:18.932111       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:161: sendmsg: invalid argument""
I0804 04:55:19.029197       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:33997: sendmsg: invalid argument""
I0804 04:55:19.029372       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:56742: sendmsg: invalid argument""
I0804 04:55:19.068999       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:30626: sendmsg: invalid argument""
I0804 04:55:19.110199       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:42366: sendmsg: invalid argument""
I0804 04:55:19.466510       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:14503: sendmsg: invalid argument""
I0804 04:55:19.580178       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:30803: sendmsg: invalid argument""
I0804 04:55:20.303912       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:38595: sendmsg: invalid argument""
I0804 04:55:20.365553       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:18429: sendmsg: invalid argument""
I0804 04:55:20.496254       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:65267: sendmsg: invalid argument""
I0804 04:55:20.516153       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:13379: sendmsg: invalid argument""
I0804 04:55:20.516526       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:20739: sendmsg: invalid argument""
I0804 04:55:21.460120       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:30874: sendmsg: invalid argument""
I0804 04:55:21.947945       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:7724: sendmsg: invalid argument""
I0804 04:55:21.948293       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:19903: sendmsg: invalid argument""
I0804 04:55:22.904167       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:15352: sendmsg: invalid argument""
I0804 04:55:23.340715       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:20510: sendmsg: invalid argument""
I0804 04:55:23.342416       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:21115: sendmsg: invalid argument""
I0804 04:55:23.423019       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:56761: sendmsg: invalid argument""
I0804 04:55:23.660406       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:38829: sendmsg: invalid argument""
I0804 04:55:23.726401       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:20048: sendmsg: invalid argument""
I0804 04:55:24.449319       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:31621: sendmsg: invalid argument""
I0804 04:55:24.450190       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:44880: sendmsg: invalid argument""
I0804 04:55:24.560103       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:6849: sendmsg: invalid argument""
I0804 04:55:25.364517       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:42442: sendmsg: invalid argument""
I0804 04:55:25.394284       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:9213: sendmsg: invalid argument""
I0804 04:55:25.429932       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:48128: sendmsg: invalid argument""
I0804 04:55:25.434229       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:18101: sendmsg: invalid argument""
I0804 04:55:25.507033       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:56883: sendmsg: invalid argument""
I0804 04:55:25.522550       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:35154: sendmsg: invalid argument""
I0804 04:55:25.661197       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:19350: sendmsg: invalid argument""
I0804 04:55:25.789038       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:63863: sendmsg: invalid argument""
I0804 04:55:25.832095       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:56343: sendmsg: invalid argument""
I0804 04:55:26.284651       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:28496: sendmsg: invalid argument""
I0804 04:55:26.302618       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:9511: sendmsg: invalid argument""
I0804 04:55:26.304897       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:37873: sendmsg: invalid argument""
I0804 04:55:26.326724       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:60144: sendmsg: invalid argument""
I0804 04:55:26.383892       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:50620: sendmsg: invalid argument""
I0804 04:55:26.384188       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:32704: sendmsg: invalid argument""
I0804 04:55:26.385760       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:50973: sendmsg: invalid argument""
I0804 04:55:27.108174       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:23276: sendmsg: invalid argument""
I0804 04:55:28.296847       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:26517: sendmsg: invalid argument""
I0804 04:55:31.111761       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:58953: sendmsg: invalid argument""
I0804 04:55:33.147370       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:23397: sendmsg: invalid argument""
I0804 04:55:33.653036       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:18414: sendmsg: invalid argument""
I0804 04:55:33.653640       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:15393: sendmsg: invalid argument""
I0804 04:55:34.761104       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:818: sendmsg: invalid argument""
I0804 04:55:35.828137       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:3787: sendmsg: invalid argument""
I0804 04:57:00.075034       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:2673: sendmsg: invalid argument""
I0804 04:57:00.075521       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:28538: sendmsg: invalid argument""
I0804 04:57:00.101002       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:8660: sendmsg: invalid argument""
I0804 04:57:00.112520       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:62788: sendmsg: invalid argument""
I0804 04:57:00.501127       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:22822: sendmsg: invalid argument""
I0804 04:57:00.541720       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:4451: sendmsg: invalid argument""
I0804 04:57:00.717337       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:49397: sendmsg: invalid argument""
I0804 04:57:00.746221       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:25338: sendmsg: invalid argument""
I0804 04:57:02.760103       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:23124: sendmsg: invalid argument""
I0804 04:57:02.768237       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:48346: sendmsg: invalid argument""
I0804 04:57:02.768460       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:58815: sendmsg: invalid argument""
I0804 04:57:02.773147       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:39351: sendmsg: invalid argument""
I0804 04:57:02.799109       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:36304: sendmsg: invalid argument""
I0804 04:57:02.903055       1 logs.go:41] skydns: failure to return reply ""write udp [::]:10053->127.0.0.1:45889: sendmsg: invalid argument""

```

**Environment**:
- Kubernetes version : v1.10.5-gke.0
- Cloud provider or hardware configuration: GKE

/sig network
@kubernetes/sig-network",closed,False,2018-08-08 05:28:55,2019-01-05 19:52:32
dns,cmluciano,https://github.com/kubernetes/dns/pull/251,https://api.github.com/repos/kubernetes/dns/issues/251,Bump build image to go 1.10.3,Signed-off-by: Christopher M. Luciano <cmluciano@us.ibm.com>,closed,True,2018-08-08 20:14:29,2018-08-09 16:59:57
dns,gabrielfsousa,https://github.com/kubernetes/dns/issues/252,https://api.github.com/repos/kubernetes/dns/issues/252,querying service wont show pods ,"kubernetes version 1.11.0

shouldn't the query return the pods ?

```
[root@app197 gabriel]$ dig @10.96.0.10  -t SRV _vaultport._tcp.vault.vault.svc.cluster.local

; <<>> DiG 9.9.4-RedHat-9.9.4-61.el7 <<>> @10.96.0.10 -t SRV _vaultport._tcp.vault.vault.svc.cluster.local
; (1 server found)
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 60739
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 2

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;_vaultport._tcp.vault.vault.svc.cluster.local. IN SRV

;; ANSWER SECTION:
_vaultport._tcp.vault.vault.svc.cluster.local. 5 IN SRV 0 100 8200 vault.vault.svc.cluster.local.

;; ADDITIONAL SECTION:
vault.vault.svc.cluster.local. 5 IN     A       10.107.214.96

;; Query time: 0 msec
;; SERVER: 10.96.0.10#53(10.96.0.10)
;; WHEN: Fri Aug 10 13:34:26 CEST 2018
;; MSG SIZE  rcvd: 213
```",closed,False,2018-08-10 11:36:17,2019-01-07 20:40:29
dns,geosword,https://github.com/kubernetes/dns/issues/253,https://api.github.com/repos/kubernetes/dns/issues/253,Kubedns returns NXDOMAIN from inside PODs but works from outside,"image: gcr.io/google_containers/k8s-dns-(kube-dns|dnsmasq-nanny|sidecar)-amd64:1.14.8

I've run through: https://kubernetes.io/docs/tasks/administer-cluster/dns-debugging-resolution/
Everything is correct (apart from performing nslookups from the busybox pod). 

```
bddcbpkbn1:~ # kubectl exec -ti busybox-5ccc978d8d-x87kb -- nslookup kubernetes
Server:         172.17.0.10
Address:        172.17.0.10:53

** server can't find kubernetes: NXDOMAIN

*** Can't find kubernetes: No answer
```

However:

```
bddcbpkbn1:~ # kubectl exec -ti busybox-5ccc978d8d-x87kb -- nslookup kubernetes.default.svc.cluster.local
Server:         172.17.0.10
Address:        172.17.0.10:53

Non-authoritative answer:
Name:   kubernetes.default.svc.cluster.local
Address: 172.17.0.1

*** Can't find kubernetes.default.svc.cluster.local: No answer
```

The resolve.conf of busybox:

```
bddcbpkbn1:~ # kubectl exec -ti busybox-5ccc978d8d-x87kb -- cat /etc/resolv.conf 
nameserver 172.17.0.10
search default.svc.cluster.local svc.cluster.local cluster.local my.local.domain
options ndots:5
```


Aside from busybox not being able to resolve ""Kubernetes"" on its own. ""Non-authoritative answer:"" Seems incorrect as well.

Just for the removal of doubt. Im expecting 

`bddcbpkbn1:~ # kubectl exec -ti busybox-5ccc978d8d-x87kb -- nslookup kubernetes`

To return ""172.17.0.1""

",closed,False,2018-08-11 06:42:24,2018-08-13 19:11:57
dns,fturib,https://github.com/kubernetes/dns/issues/254,https://api.github.com/repos/kubernetes/dns/issues/254,coreDNS deployment is not compatible with PodSecurityPolicy,"## IMPACT - Blocker

Right now this issue is blocking the PR ""CoreDNS as ""default"" in kube-up deployment"".
See several PR that have the same ""pull-kubernetes-e2e-gce"".

https://github.com/kubernetes/kubernetes/pull/67569
https://github.com/kubernetes/kubernetes/pull/66309
https://github.com/kubernetes/kubernetes/pull/62147


## Description

CoreDNS Deployment uses SecurityContext.
Basically this context tells  that CoreDNS needs admin privileges to be able to listen on port 53 (which is below 1024).

 ```
      securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - all
          readOnlyRootFilesystem: true
```

But when this deployment is running in a cluster that has PodSecurityPolicy enabled, the replicaSet is unable to create the CoreDNS Pods:

```
admin@francois-test-infra:~$ kubectl describe -n=kube-system replicasets coredns
Name:           coredns-77cd44d8df
Namespace:      kube-system
...
Conditions:
  Type             Status  Reason
  ----             ------  ------
  ReplicaFailure   True    FailedCreate
Events:
  Type     Reason        Age               From                   Message
  ----     ------        ----              ----                   -------
  Warning  FailedCreate  3m (x80 over 3h)  replicaset-controller  Error creating: pods ""coredns-77cd44d8df-"" is forbidden: unable to validate against any pod security policy: [spec.containers[0].securityContext.capabilities.add: Invalid value: ""NET_BIND_SERVICE"": capability may not be added]

```

## Actions to fix

Here we have two options:
### Abandon securityContext

and listen on port >= 1024. It needs adaptation of the Deployment and the Service. 
NOTE: It was so far expected to not change the service (from kube-dns definition) in order to allow upgrade without interruption of the DNS service.

### Ensure the right Security definition for CoreDNS.
Here we are not sure what needs to be done (under investigations)
Most likely, following other services that complies with PodSecurityPolicy, that would mean 
- create a ""podsecuritypolicies"" folder
- declare in that folder a manifest for a RoleBinding between coredns' ServiceAccount, and gce.privileged ClusterRole.

**RoleBinding to add in a dedicated podsecuritypolicies folder - will work for kube-up only:**
```
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: gce:podsecuritypolicy:coredns
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
    kubernetes.io/cluster-service: ""true""
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: gce:podsecuritypolicy:privileged
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
```

#### Questions 
- that would work for kube-up deployment, what about kubeadm ?
- why is that tied to GCE only ? 
- How do we deploy PSP in other platforms ?




",closed,False,2018-08-20 22:45:22,2018-08-22 02:51:07
dns,liyinda246,https://github.com/kubernetes/dns/issues/255,https://api.github.com/repos/kubernetes/dns/issues/255,Failed to list *v1.Endpoints: Get https://10.96.0.1:443/api/v1/endpoints?limit=500&resourceVersion=0: dial tcp 10.96.0.1:443: i/o timeout,"kubernetes version 1.11.1
docker version 1.13.1

more coredns.yml

apiVersion: v1
kind: ServiceAccount
metadata:
  name: coredns
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
rules:
- apiGroups:
  - """"
  resources:
  - endpoints
  - services
  - pods
  - namespaces
  verbs:
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: ""true""
  labels:
    kubernetes.io/bootstrapping: rbac-defaults
  name: system:coredns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:coredns
subjects:
- kind: ServiceAccount
  name: coredns
  namespace: kube-system
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: coredns
  namespace: kube-system
data:
  Corefile: |
    .:53 {
        errors
        health
        kubernetes cluster.local in-addr.arpa ip6.arpa {
          pods insecure
          upstream
          fallthrough in-addr.arpa ip6.arpa
        }
        prometheus :9153
        proxy . /etc/resolv.conf
        cache 30
        reload
        loadbalance
    }
---
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: coredns
  namespace: kube-system
  labels:
    k8s-app: kube-dns
    kubernetes.io/name: ""CoreDNS""
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  selector:
    matchLabels:
      k8s-app: kube-dns
  template:
    metadata:
      labels:
        k8s-app: kube-dns
    spec:
      serviceAccountName: coredns
      tolerations:
        #- key: node-role.kubernetes.io/master
        #  effect: NoSchedule
        - key: ""CriticalAddonsOnly""
          operator: ""Exists""
      containers:
      - name: coredns
        image: coredns/coredns:1.2.0
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            memory: 170Mi
          requests:
            cpu: 100m
            memory: 70Mi
        args: [ ""-conf"", ""/etc/coredns/Corefile"" ]
        volumeMounts:
        - name: config-volume
          mountPath: /etc/coredns
          readOnly: true
        ports:
        - containerPort: 53
          name: dns
          protocol: UDP
        - containerPort: 53
          name: dns-tcp
          protocol: TCP
        - containerPort: 9153
          name: metrics
          protocol: TCP
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - NET_BIND_SERVICE
            drop:
            - all
          readOnlyRootFilesystem: true
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
            scheme: HTTP
          initialDelaySeconds: 60
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 5
      dnsPolicy: Default
      volumes:
        - name: config-volume
          configMap:
            name: coredns
            items:
            - key: Corefile
              path: Corefile
---
apiVersion: v1
kind: Service
metadata:
  name: kube-dns
  namespace: kube-system
  annotations:
    prometheus.io/port: ""9153""
    prometheus.io/scrape: ""true""
  labels:
    k8s-app: kube-dns
    kubernetes.io/cluster-service: ""true""
    kubernetes.io/name: ""CoreDNS""
spec:
  selector:
    k8s-app: kube-dns
  clusterIP: 10.96.0.10
  ports:
  - name: dns
    port: 53
    protocol: UDP
  - name: dns-tcp
    port: 53
    protocol: TCP",closed,False,2018-08-27 06:42:43,2019-04-02 16:24:47
dns,ans-cst,https://github.com/kubernetes/dns/issues/256,https://api.github.com/repos/kubernetes/dns/issues/256,KubeDNS - Not adding Stable Network IDs for StatefulSet,"I am hoping someone can assist me with an issue i am having with kubedns adding endpoints for stable networks IDs within a service.

When i deploy my service and stateful set i see the below error in the kube-dns logs:
_Could not find endpoints for service ""mongo-svc"" in namespace ""default"". DNS records will be created once endpoints show up._
I can see the IPs are added but the stateful network IDs are not:
_root$ kubectl get ep
NAME ENDPOINTS AGE
kubernetes 172.31.10.57:443 3d
mongo-svc 10.0.0.27:27017,10.0.0.63:27017,10.0.0.69:27017 3d_

From within one of the mongo pods in stateful set i can see IP resolution for the service DNS is working:
_root@mongo-0:/# nslookup mongo-svc.default.svc.cluster.local
Server: 10.0.1.10
Address: 10.0.1.10#53
Name: mongo-svc.default.svc.cluster.local
Address: 10.0.0.27
Name: mongo-svc.default.svc.cluster.local
Address: 10.0.0.63
Name: mongo-svc.default.svc.cluster.local
Address: 10.0.0.69_

When pinging the service DNS name the stable network ID is resolved when directed to the local pod but the IP is used when targeting an external pod in the stateful set:
_root@mongo-0:/# ping mongo-svc.default.svc.cluster.local
PING mongo-svc.default.svc.cluster.local (10.0.0.63) 56(84) bytes of data.
64 bytes from mongo-0.mongo.default.svc.cluster.local (10.0.0.63): icmp_seq=1 ttl=64 time=0.018 ms
--- mongo-svc.default.svc.cluster.local ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 4083ms_

_root@mongo-0:/# ping mongo-svc.default.svc.cluster.local
PING mongo-svc.default.svc.cluster.local (10.0.0.27) 56(84) bytes of data.
64 bytes from 10.0.0.27*: icmp_seq=1 ttl=64 time=0.578 ms*
--- mongo-svc.default.svc.cluster.local ping statistics ---
1 packets transmitted, 1 received, 0% packet loss, time 3054ms_

I am running Kubernetes 1.11.2 and kubedns 1.14.10 on Azure Kubernetes Service with RBAC enabled.

Any help with this is appreciated as it is critical we use stable network IDs for our mongodb replica set!",closed,False,2018-08-28 12:41:16,2018-08-28 14:06:35
dns,bamb00,https://github.com/kubernetes/dns/issues/257,https://api.github.com/repos/kubernetes/dns/issues/257,kube-dns goes into CrashLoopBackOff consistently,"I'm running into an issue where kube-dns pod goes into CrashLoopBackOff.  There are 1 master and 4 minion node.  Also there are 1 kube-dns pod and 5 kube-proxy pod.  Each kube-proxy pod is running on the master and minions node.  I didn't see any error in the kube-proxy logs (below) to cause the kube-dns CrashLoopBackOff.

K8s: v1.9.5
Cent OS 7.5, 3.10.0-862.9.1.el7.x86_64

Master Node:

	        # kubectl get po -n kube-system -o wide
	        NAME                      READY      STATUS   RESTARTS AGE   IP        NODE
            kube-dns-6f4fd4bdf-szpbf   2/3  CrashLoopBackOff 28    34m 10.0.0.22 multinode1-master-01  

            # kubectl exec -ti cassandra-0 -- nslookup kubernetes
            ;; connection timed out; no servers could be reached

            command terminated with exit code 1

		# kubectl logs kube-dns-6f4fd4bdf-szpbf -n kube-system kubedns
		I0901 16:13:08.997496       1 dns.go:48] version: 1.14.6-3-gc36cb11
		I0901 16:13:08.998592       1 server.go:69] Using configuration read from directory: /kube-dns-config with period 10s
		I0901 16:13:08.998658       1 server.go:112] FLAG: --alsologtostderr=""false""
		I0901 16:13:08.998673       1 server.go:112] FLAG: --config-dir=""/kube-dns-config""
		I0901 16:13:08.998680       1 server.go:112] FLAG: --config-map=""""
		I0901 16:13:08.998684       1 server.go:112] FLAG: --config-map-namespace=""kube-system""
		I0901 16:13:08.998689       1 server.go:112] FLAG: --config-period=""10s""
		I0901 16:13:08.998694       1 server.go:112] FLAG: --dns-bind-address=""0.0.0.0""
		I0901 16:13:08.998699       1 server.go:112] FLAG: --dns-port=""10053""
		I0901 16:13:08.998709       1 server.go:112] FLAG: --domain=""cluster.local.""
		I0901 16:13:08.998715       1 server.go:112] FLAG: --federations=""""
		I0901 16:13:08.998721       1 server.go:112] FLAG: --healthz-port=""8081""
		I0901 16:13:08.998726       1 server.go:112] FLAG: --initial-sync-timeout=""1m0s""
		I0901 16:13:08.998733       1 server.go:112] FLAG: --kube-master-url=""""
		I0901 16:13:08.998738       1 server.go:112] FLAG: --kubecfg-file=""""
		I0901 16:13:08.998742       1 server.go:112] FLAG: --log-backtrace-at="":0""
		I0901 16:13:08.998751       1 server.go:112] FLAG: --log-dir=""""
		I0901 16:13:08.998756       1 server.go:112] FLAG: --log-flush-frequency=""5s""
		I0901 16:13:08.998761       1 server.go:112] FLAG: --logtostderr=""true""
		I0901 16:13:08.998766       1 server.go:112] FLAG: --nameservers=""""
		I0901 16:13:08.998770       1 server.go:112] FLAG: --stderrthreshold=""2""
		I0901 16:13:08.998775       1 server.go:112] FLAG: --v=""2""
		I0901 16:13:08.998779       1 server.go:112] FLAG: --version=""false""
		I0901 16:13:08.998787       1 server.go:112] FLAG: --vmodule=""""
		I0901 16:13:08.998935       1 server.go:194] Starting SkyDNS server (0.0.0.0:10053)
		I0901 16:13:08.999419       1 server.go:213] Skydns metrics enabled (/metrics:10055)
		I0901 16:13:08.999440       1 dns.go:146] Starting endpointsController
		I0901 16:13:08.999448       1 dns.go:149] Starting serviceController
		I0901 16:13:08.999603       1 logs.go:41] skydns: ready for queries on cluster.local. for tcp://0.0.0.0:10053 [rcache 0]
		I0901 16:13:08.999629       1 logs.go:41] skydns: ready for queries on cluster.local. for udp://0.0.0.0:10053 [rcache 0]
		I0901 16:13:09.020861       1 dns.go:555] Could not find endpoints for service ""kafka"" in namespace ""default"". DNS records will be created once endpoints show up.
		I0901 16:13:09.499764       1 dns.go:170] Initialized services and endpoints from apiserver
		I0901 16:13:09.499808       1 server.go:128] Setting up Healthz Handler (/readiness)
		I0901 16:13:09.499829       1 server.go:133] Setting up cache handler (/cache)
		I0901 16:13:09.499839       1 server.go:119] Status HTTP port 8081
		I0901 16:14:48.663106       1 server.go:153] Ignoring signal terminated (can only be terminated by SIGKILL)

		# kubectl logs kube-dns-6f4fd4bdf-szpbf -n kube-system dnsmasq
		I0901 16:52:00.722875       1 main.go:76] opts: {{/usr/sbin/dnsmasq [-k --cache-size=1000 --no-negcache --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/ip6.arpa/127.0.0.1#10053] true} /etc/k8s/dns/dnsmasq-nanny 10000000000}
		I0901 16:52:00.723145       1 nanny.go:94] Starting dnsmasq [-k --cache-size=1000 --no-negcache --log-facility=- --server=/cluster.local/127.0.0.1#10053 --server=/in-addr.arpa/127.0.0.1#10053 --server=/ip6.arpa/127.0.0.1#10053]
		I0901 16:52:00.745233       1 nanny.go:116] dnsmasq[23]: started, version 2.78 cachesize 1000
		I0901 16:52:00.745287       1 nanny.go:116] dnsmasq[23]: compile time options: IPv6 GNU-getopt no-DBus no-i18n no-IDN DHCP DHCPv6 no-Lua TFTP no-conntrack ipset auth no-DNSSEC loop-detect inotify
		I0901 16:52:00.745303       1 nanny.go:116] dnsmasq[23]: using nameserver 127.0.0.1#10053 for domain ip6.arpa
		I0901 16:52:00.745311       1 nanny.go:116] dnsmasq[23]: using nameserver 127.0.0.1#10053 for domain in-addr.arpa
		I0901 16:52:00.745318       1 nanny.go:116] dnsmasq[23]: using nameserver 127.0.0.1#10053 for domain cluster.local
		I0901 16:52:00.745333       1 nanny.go:116] dnsmasq[23]: reading /etc/resolv.conf
		I0901 16:52:00.745341       1 nanny.go:116] dnsmasq[23]: using nameserver 127.0.0.1#10053 for domain ip6.arpa
		I0901 16:52:00.745305       1 nanny.go:119]
		W0901 16:52:00.745359       1 nanny.go:120] Got EOF from stdout
		I0901 16:52:00.745348       1 nanny.go:116] dnsmasq[23]: using nameserver 127.0.0.1#10053 for domain in-addr.arpa
		I0901 16:52:00.745406       1 nanny.go:116] dnsmasq[23]: using nameserver 127.0.0.1#10053 for domain cluster.local
		I0901 16:52:00.745414       1 nanny.go:116] dnsmasq[23]: using nameserver 171.70.168.183#53
		I0901 16:52:00.745425       1 nanny.go:116] dnsmasq[23]: read /etc/hosts - 7 addresses

		# kubectl logs kube-dns-6f4fd4bdf-szpbf -n kube-system sidecar
		I0901 16:54:41.807122       1 main.go:51] Version v1.14.6-3-gc36cb11
		I0901 16:54:41.807246       1 server.go:45] Starting server (options {DnsMasqPort:53 DnsMasqAddr:127.0.0.1 DnsMasqPollIntervalMs:5000 Probes:[{Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33} {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33}] PrometheusAddr:0.0.0.0 PrometheusPort:10054 PrometheusPath:/metrics PrometheusNamespace:kubedns})
		I0901 16:54:41.807287       1 dnsprobe.go:75] Starting dnsProbe {Label:kubedns Server:127.0.0.1:10053 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33}
		I0901 16:54:41.807359       1 dnsprobe.go:75] Starting dnsProbe {Label:dnsmasq Server:127.0.0.1:53 Name:kubernetes.default.svc.cluster.local. Interval:5s Type:33}
		W0901 16:56:21.836491       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:34697->127.0.0.1:53: read: connection refused
		W0901 16:56:26.837159       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:54448->127.0.0.1:53: read: connection refused
		W0901 16:56:31.837665       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:39194->127.0.0.1:53: read: connection refused
		W0901 16:56:36.838207       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:55747->127.0.0.1:53: read: connection refused
		W0901 16:56:41.838592       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:60362->127.0.0.1:53: read: connection refused
		W0901 16:56:46.839026       1 server.go:64] Error getting metrics from dnsmasq: read udp 127.0.0.1:32842->127.0.0.1:53: read: connection refused


All logs from kube-proxy pods:

		# kubectl logs kube-proxy-mpzmk -n kube-system
		I0901 15:29:41.973192       1 feature_gate.go:190] feature gates: map[]
		time=""2018-09-01T15:29:41Z"" level=warning msg=""Running modprobe ip_vs failed with message: `modprobe: ERROR: could not insert 'ip_vs': Exec format error\ninsmod /lib/modules/3.10.0-862.9.1.el7.x86_64/kernel/net/netfilter/ipvs/ip_vs.ko.xz`, error: exit status 1""
		time=""2018-09-01T15:29:41Z"" level=error msg=""Could not get ipvs family information from the kernel. It is possible that ipvs is not enabled in your kernel. Native loadbalancing will not work until this is fixed.""
		W0901 15:29:41.983221       1 server_others.go:289] Flag proxy-mode="""" unknown, assuming iptables proxy
		I0901 15:29:41.984612       1 server_others.go:138] Using iptables Proxier.
		W0901 15:29:41.997328       1 proxier.go:468] clusterCIDR not specified, unable to distinguish between internal and external traffic
		I0901 15:29:41.997428       1 server_others.go:171] Tearing down inactive rules.
		E0901 15:29:42.022009       1 proxier.go:792] Failed to execute iptables-restore for nat: exit status 1 (iptables-restore: line 7 failed
		)
		I0901 15:29:42.032606       1 server.go:426] Version: v1.9.5
		I0901 15:29:42.044610       1 conntrack.go:98] Set sysctl 'net/netfilter/nf_conntrack_max' to 524288
		I0901 15:29:42.044673       1 conntrack.go:52] Setting nf_conntrack_max to 524288
		I0901 15:29:42.044722       1 conntrack.go:98] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400
		I0901 15:29:42.044770       1 conntrack.go:98] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600
		I0901 15:29:42.046499       1 config.go:102] Starting endpoints config controller
		I0901 15:29:42.046529       1 controller_utils.go:1019] Waiting for caches to sync for endpoints config controller
		I0901 15:29:42.046634       1 config.go:202] Starting service config controller
		I0901 15:29:42.046642       1 controller_utils.go:1019] Waiting for caches to sync for service config controller
		I0901 15:29:42.146799       1 controller_utils.go:1026] Caches are synced for service config controller
		I0901 15:29:42.146862       1 controller_utils.go:1026] Caches are synced for endpoints config controller

dnsmasq args:

	  - args:
	    - -v=2
	    - -logtostderr
	    - -configDir=/etc/k8s/dns/dnsmasq-nanny
	    - -restartDnsmasq=true
	    - --
	    - -k
	    - --cache-size=1000
	    - --no-negcache
	    - --log-facility=-
	    - --server=/cluster.local/127.0.0.1#10053
	    - --server=/in-addr.arpa/127.0.0.1#10053
	    - --server=/ip6.arpa/127.0.0.1#10053
	    image: gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64:1.14.7

Any insights would be appreciated.",closed,False,2018-09-01 16:39:51,2018-09-02 20:44:27
dns,pedrosland,https://github.com/kubernetes/dns/pull/258,https://api.github.com/repos/kubernetes/dns/issues/258,Fix DNS query to get metrics from Dnsmasq,"This PR fixes the DNS queries to get metrics such as `hits.bind.`

Without this change, the sidecar doesn't report `kubedns_dnsmasq_hits` or similar metrics and it produces logs like:

```
W0910 16:07:40.684579   18427 server.go:64] Error getting metrics from dnsmasq: invalid number of Answer records for hits.bind.: 0
```

It seems that Dnsmasq requires the recursive flag to respond to these queries. Using dig confirms this. 

Working:
```
dig chaos txt hits.bind.
```
Not working:
```
dig +norecurse chaos txt hits.bind.
```
",closed,True,2018-09-10 21:28:20,2018-10-06 01:09:19
dns,dims,https://github.com/kubernetes/dns/pull/259,https://api.github.com/repos/kubernetes/dns/issues/259,Build and push manifests for container images,"We build and push images for various architectures, but are not
publishing a single manifest that can be used to look up the images.
test/images in main k/k repository and kube images in k/release already
publish manifests for all the image we need for e2e testing, so we
should do the same as the 2 images in this repository are part of the
conformance e2e test suite.

Change-Id: I3f923e6246fc04e4c36cb29cb5be1f40fbdcd8a4",closed,True,2018-09-11 00:21:21,2018-09-14 21:35:52
dns,stepyu,https://github.com/kubernetes/dns/pull/260,https://api.github.com/repos/kubernetes/dns/issues/260,fix parameter description,,closed,True,2018-09-13 07:55:39,2018-09-13 16:52:31
dns,dims,https://github.com/kubernetes/dns/pull/261,https://api.github.com/repos/kubernetes/dns/issues/261,Publish manifests for all 3 sets of images,"Previous attempt pushed just one image. Now we iterate over
and push manifests for all 3 images, dnsmasq-nanny, kube-dns, sidecar.

problem was reported in https://github.com/kubernetes/dns/pull/259#issuecomment-421448697

cc @MrHohn @bowei ",closed,True,2018-09-15 22:40:47,2018-09-19 00:49:20
dns,matt-potter,https://github.com/kubernetes/dns/pull/262,https://api.github.com/repos/kubernetes/dns/issues/262,update dnsmasq to 2.79,"Specifically this provides min-port at a sane default (1024), which would aid our deployments with kube-aws, where are are unable to pass custom flags to the dnsmasq process",open,True,2018-09-19 14:00:23,2019-02-19 19:16:04
dns,awly,https://github.com/kubernetes/dns/issues/263,https://api.github.com/repos/kubernetes/dns/issues/263,Rebuild docker images to pick up Alpine 3.8.1,"Alpine 3.8.1 fixes a RCE vulnerability (see https://alpinelinux.org/posts/Alpine-3.8.1-released.html).
Rebuild and push the image to pick up the new base image.",closed,False,2018-09-19 22:32:24,2018-09-20 22:34:43
dns,MrHohn,https://github.com/kubernetes/dns/pull/264,https://api.github.com/repos/kubernetes/dns/issues/264,Bump alpine base image to 3.8.1,"Fixes #263 .

/assign @prameshj",closed,True,2018-09-20 18:07:39,2018-09-20 18:30:56
dns,briantopping,https://github.com/kubernetes/dns/issues/265,https://api.github.com/repos/kubernetes/dns/issues/265,Downed upstream named causes pod requests to hang,"With a clean v1.11.2 deployment on CentOS Linux release 7.5.1804, coredns fails to resolve addresses when one of the upstream named instances are unresponsive. 

The only use case that I have tested this with is that the upstream instance is completely down and the address the server runs on is dead. I have not tested the case where the upstream host is live but the port is dead.

When this happens, pod requests for name resolution hang. Full logs follow:

```
[root@centos01 freeipa]# kc logs -n kube-system coredns-78fcdf6894-p9mw6
.:53
CoreDNS-1.1.3
2018/09/20 02:14:56 [INFO] CoreDNS-1.1.3
2018/09/20 02:14:56 [INFO] linux/amd64, go1.10.1, b0fd575c
2018/09/20 02:14:56 [INFO] plugin/reload: Running configuration MD5 = 2a066f12ec80aeb2b92740dd74c17138
linux/amd64, go1.10.1, b0fd575c
2018/09/20 16:43:53 [ERROR] 2 foo.example.com. A: unreachable backend: read udp 10.16.0.123:51087->95.96.97.11:53: i/o timeout
2018/09/20 17:32:28 [ERROR] 2 master.hndc1.example.com. A: unreachable backend: read udp 10.16.0.123:58532->95.96.97.11:53: i/o timeout
```

The behavior I would have expected is to blacklist the unresponsive node and not remove it from the blacklist until a recurring probe in some kind of exponential backoff was successful.",closed,False,2018-09-20 19:20:46,2018-09-20 19:26:01
dns,scrwr,https://github.com/kubernetes/dns/issues/266,https://api.github.com/repos/kubernetes/dns/issues/266,POD DNS reverse lookup,"We have an increasing problem with Apache Hadoop-like services like Spark, Flink and co. These are trying to communicate via their hostnames in the cluster instead of their IPs. So they look up their own hostname and hence come up with the unresolvable podname. We see now two incomplete solutions:

a) Pod A records are created in a format like 1-2-3-4.namespace.pod.cluster.local variant. But the pod itself cannot be spec’ed to use this A record as its own hostname.

b) one can use hostname and subdomain together with a headless service in order to create an FQDN in the KubeDNS + in pods hostname, but this requires static hostnames and won’t work with Replicasets or Daemonsets.

We are looking for a complete solution, e.g. via optionally switch the pod hostname to its KubeDNS A Record, or injecting the A record as first entry in /etc/hosts etc. The type of pods which are heavily effected by the issue are Jobs. In the Spark context, these are driver pods / jobs. But the problem is not limited to Spark. We see the same effects all over in recent apache projects. E.g. Flink has a similar issue.",open,False,2018-09-25 09:09:30,2019-02-12 19:27:03
dns,mkumatag,https://github.com/kubernetes/dns/pull/267,https://api.github.com/repos/kubernetes/dns/issues/267,Purge the manifest after the push,Triggered by https://github.com/kubernetes/kubernetes/issues/69104#issuecomment-424799217,closed,True,2018-09-27 14:54:51,2018-09-27 19:06:05
dns,ixdy,https://github.com/kubernetes/dns/pull/268,https://api.github.com/repos/kubernetes/dns/issues/268,Remove unused NOBODY/ARG_NOBODY arg from docker build,"`NOBODY` and `ARG_NOBODY` were added in #31 because amd64 and the other architectures were using different base images, but its need was basically but removed in #127 when all architectures were converted to use alpine.

The names were also confusing (they apply to the group, not the user), so let's just remove them and hardcode the group in the Dockerfile again.",closed,True,2018-10-01 18:17:55,2018-10-01 23:04:44
dns,prameshj,https://github.com/kubernetes/dns/pull/269,https://api.github.com/repos/kubernetes/dns/issues/269,Migrate from Godep to dep for managing dependencies.,,closed,True,2018-10-30 18:38:25,2018-10-31 06:10:15
dns,prameshj,https://github.com/kubernetes/dns/pull/270,https://api.github.com/repos/kubernetes/dns/issues/270,Run coredns as a nodelocal dnscache,This change introduces a dnscache program that runs coredns and sets up iptables rules and interface for connectivity.,closed,True,2018-11-01 17:28:36,2018-11-09 18:03:30
dns,prameshj,https://github.com/kubernetes/dns/pull/271,https://api.github.com/repos/kubernetes/dns/issues/271,Update go-dependencies.md,,closed,True,2018-11-05 22:43:23,2018-11-05 23:07:08
dns,prameshj,https://github.com/kubernetes/dns/pull/272,https://api.github.com/repos/kubernetes/dns/issues/272,Follow up changes to node-cache PR,Addressed review comments from https://github.com/kubernetes/dns/pull/270,closed,True,2018-11-07 23:26:41,2018-11-08 00:10:45
dns,maktouch,https://github.com/kubernetes/dns/issues/273,https://api.github.com/repos/kubernetes/dns/issues/273,Kube-DNS pod is being scheduled with the same IP as its service,"This is the content of /etc/resolv.conf
```
nameserver 172.26.0.10
search rev-master.svc.cluster.local svc.cluster.local cluster.local c.playerdotme-1121.internal google.internal
options ndots:5
```

These are my kube-dns pods

```
kube-system     kube-dns-788979dc8f-4fg6m                                   4/4       Running   0          4h        172.26.24.7     gke-plr-web-prd-01-web-00-3b7b1e67-6mdr
kube-system     kube-dns-788979dc8f-8rq2l                                   4/4       Running   0          2h        172.26.13.4     gke-plr-web-prd-01-web-00-3b7b1e67-33jb
kube-system     kube-dns-788979dc8f-gg79n                                   4/4       Running   0          5h        172.26.21.6     gke-plr-web-prd-01-web-00-3b7b1e67-qr6t
kube-system     kube-dns-788979dc8f-gmlvf                                   4/4       Running   0          16h       172.26.20.10    gke-plr-web-prd-01-web-00-3b7b1e67-p4s4
kube-system     kube-dns-788979dc8f-njthl                                   4/4       Running   0          22h       172.26.0.10     gke-plr-web-prd-01-web-00-3b7b1e67-42lx
kube-system     kube-dns-788979dc8f-rp4w6                                   4/4       Running   0          16h       172.26.20.5     gke-plr-web-prd-01-web-00-3b7b1e67-p4s4
kube-system     kube-dns-788979dc8f-zqg4q                                   4/4       Running   0          6h        172.26.4.16     gke-plr-web-prd-01-web-00-3b7b1e67-0bpb
```

This is the service

```
kube-system     kube-dns                                      ClusterIP      172.26.0.10      <none>          53/UDP,53/TCP                                                                  49d
```

We're having a lot of DNS issues because it seems like every DNS requests is being routed to that single pod instead of being load balanced by the service. 

At first, I thought this was a single fluke, but this is the 2nd time it's happening and it seems to only happening with kube-dns. 

Anyone has any ideas? ",closed,False,2018-11-08 07:16:04,2018-11-12 05:50:08
dns,prameshj,https://github.com/kubernetes/dns/pull/274,https://api.github.com/repos/kubernetes/dns/issues/274,Upgrade CoreDNS to 1.2.6,"this contains a fix in the loop plugin that was incorrectly detecting a loop when upstream dns was unavailable.
coredns/coredns#2255",closed,True,2018-11-11 21:56:28,2018-11-12 18:41:58
dns,xichengliudui,https://github.com/kubernetes/dns/pull/275,https://api.github.com/repos/kubernetes/dns/issues/275,Delete the redundant code,These 'else {}' is not needed,closed,True,2018-11-12 06:03:39,2018-11-14 01:43:38
dns,amykang2020,https://github.com/kubernetes/dns/issues/276,https://api.github.com/repos/kubernetes/dns/issues/276,intermittent nslookup service fails in pod,"Hi, would like to know if any known issue in kubernetes 1.7.6 could be the cause (unfortunately the kubernetes cluster running in the environment in AWS is still using 1.7.6).
1. A statefulset is deployed with replica =1 and 1 headless service and 2 regular services all with selector for a label defined in the statefulset.  The services type is ClusterIP.
2. A cronjob is deployed to the same cluster that periodically connect to the statefulset exposed port.  However intermittently connecting to the statefulset pod fails with error
>""error: lookup xxx on 11.1.2.10:53 .. Unable to connect to xxx:6565
where xxx is 1 of the regular service's name and 6565 is the exposed port by that service, 11.1.2.10 is the nameserver shown in the /etc/resolv.conf the cron job pod
and kubectl exec into any pod to run nslookup xxx periodically will at one moment successful and another moment unable to resolve:
```
$ kubectl exec -it someapp-1704812857-gx5md -- sh
$ nslookup xxx
Name:      xxx
Address 1: 11.1.2.206 xxx.default.svc.cluster.local
$ nc -vz xxx 6565
nc: bad address 'xxx'
$ nslookup xxx
nslookup: can't resolve 'xxx': Try again
$ nc -vz xxx 6565
xxx (11.1.2.206:6565) open
$ nslookup xxx
Name:      xxx
Address 1: 11.1.2.206 xxx.default.svc.cluster.local
```
Client Version: version.Info{Major:""1"", Minor:""7"", GitVersion:""v1.7.6"", GitCommit:""4bc5e7f9a6c25dc4c03d4d656f2cefd21540e28c"", GitTreeState:""clean"", BuildDate:""2017-09-14T06:55:55Z"", GoVersion:""go1.8.3"", Compiler:""gc"", Platform:""darwin/amd64""}
Server Version: version.Info{Major:""1"", Minor:""7"", GitVersion:""v1.7.6+coreos.0"", GitCommit:""e14ebed378d5380b9936455584fa454daa67f23b"", GitTreeState:""clean"", BuildDate:""2017-09-14T21:52:44Z"", GoVersion:""go1.8.3"", Compiler:""gc"", Platform:""linux/amd64""}

",closed,False,2018-11-17 03:30:30,2018-11-18 01:43:44
dns,mmingorance-dh,https://github.com/kubernetes/dns/issues/277,https://api.github.com/repos/kubernetes/dns/issues/277,Kube-DNS service seems to keep sending traffic to a terminating/ed pod,"Hi all,
I have a question about a certain issue we are facing.
We have recently change to Kubernetes 1.10.6 with kops 1.10 and we started to use IPVS instead of IPtables. We have created our own AMI for this purpose. Everything seems to be working fine with this setup however we experience some issues in the kube-dns issue (managed by kube-dns instead of coreDNS).
Whenever a kube-dns pod gets terminated, the service seems to still be sending traffic to this pod and therefore we start to have resolution's issues in our cluster. This resolution issue happens for exactly 5 minutes right after the pod starts to be deleted.

Do you have any idea why the service is still sending this traffic even though the pod is terminating? As far as I know, the service should immediately disrupt the connection with this pod.",closed,False,2018-11-21 15:38:45,2019-02-27 09:06:39
dns,cricketliu,https://github.com/kubernetes/dns/pull/278,https://api.github.com/repos/kubernetes/dns/issues/278,Update specification.md,Simple grammatical fix (subject-verb agreement).,closed,True,2018-11-27 00:03:09,2019-03-27 23:26:49
dns,andy2046,https://github.com/kubernetes/dns/pull/279,https://api.github.com/repos/kubernetes/dns/issues/279,allow service name for stubDomains,"Fixes #82 

it should work for not only kubernetes service name but also private dns record (e.g. dns.my.domain defined in GKE private dns) ",closed,True,2018-12-02 17:02:27,2019-01-05 06:39:16
dns,justinsb,https://github.com/kubernetes/dns/pull/280,https://api.github.com/repos/kubernetes/dns/issues/280,Create script to run node-local-dns cache without kubelet support,This enables node-local-dns to be used experimentally prior to kubelet support.,open,True,2018-12-06 03:44:06,2019-01-25 23:39:35
dns,justinsb,https://github.com/kubernetes/dns/pull/281,https://api.github.com/repos/kubernetes/dns/issues/281,Add dns-stress-test tool,"This performs DNS queries (~100 per second per pod), reporting timing
results to StackDriver.  It demonstrates the significant improvements
attainable with the node-local-dns cache.",open,True,2018-12-06 04:29:52,2019-01-14 17:22:49
dns,negz,https://github.com/kubernetes/dns/issues/282,https://api.github.com/repos/kubernetes/dns/issues/282,Node local DNS creates dummy interface without IP address,"Hello,

I've just started experimenting with the new node local DNS cache. For reasons I haven't yet determined the `NetIfManager` manages to create the `nodelocaldns` dummy IP in my setup, but fails to allocate it an IP address. `NetIfManager` [does not check the error return value](https://github.com/kubernetes/dns/blob/401314d/pkg/netif/netif.go#L26) when assigning IPs, so this manifests as follows:

```bash
$ kubectl --kubeconfig=/Users/negz/tfk-negz.kubecfg -n kube-system logs nodelocaldns-ltlfp --previous
2018/12/21 03:22:52 2018-12-21T03:22:52.066Z [INFO] Tearing down
2018/12/21 03:22:53 2018-12-21T03:22:53.064Z [INFO] Setting up networking for node cache
listen tcp 169.254.20.10:8080: bind: cannot assign requested address
```

I see when inspect the dummy interface that it's missing an IP:
```bash
# ip address show dev nodelocaldns
23: nodelocaldns: <BROADCAST,NOARP,UP,LOWER_UP> mtu 1300 qdisc noqueue state UNKNOWN group default 
    link/ether 72:b5:c3:81:f6:2f brd ff:ff:ff:ff:ff:ff
    inet6 fe80::70b5:c3ff:fe81:f62f/64 scope link 
       valid_lft forever preferred_lft forever
```",closed,False,2018-12-21 03:27:08,2019-01-28 09:57:55
dns,thebag25,https://github.com/kubernetes/dns/issues/283,https://api.github.com/repos/kubernetes/dns/issues/283,kube-dns pod crashing with panic error,"Hi all.
I got follow problem - after i restart kubernetes server I got error with kube-dns - it stops with CrashLoopback error. I check container logs and found that kubedns container itself crashig with panic error. Look like this is happened when it got first dns request - I try to disable sidecar and dnsmasq containers and kubedns itself run OK. But when it get any DNS request- it crashed with  panic. Everything worked fine before restart.

Kube DSN 1.14.7 and 1.14.10, kubernetes 1.9.2 on RedHat 7.5

I1226 13:11:22.640901 1 server.go:119] Status HTTP port 8081
I1226 13:11:23.256656 1 dns.go:436] No service for endpoint ""kube-scheduler"" in namespace ""kube-system""
I1226 13:11:23.256675 1 dns.go:436] No service for endpoint ""kube-scheduler"" in namespace ""kube-system""
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x9b74b3]

goroutine 130 [running]:
k8s.io/dns/vendor/github.com/skynetservices/skydns/server.(*server).ServeDNS(0xc420019dc0, 0x1fd63a0, 0xc4202bc000, 0xc4200903f0)
/go/src/k8s.io/dns/vendor/github.com/skynetservices/skydns/server/server.go:202 +0x293
k8s.io/dns/vendor/github.com/miekg/dns.(*ServeMux).ServeDNS(0xc420444010, 0x1fd63a0, 0xc4202bc000, 0xc4200903f0)
/go/src/k8s.io/dns/vendor/github.com/miekg/dns/server.go:210 +0x65
k8s.io/dns/vendor/github.com/miekg/dns.(*Server).serve(0xc420656000, 0x1fc6260, 0xc42023e1b0, 0x1fbb6e0, 0xc420444010, 0xc4200fac00, 0x36, 0x200, 0xc4206ca000, 0xc4204f61c0, ...)
/go/src/k8s.io/dns/vendor/github.com/miekg/dns/server.go:577 +0x2fb
created by k8s.io/dns/vendor/github.com/miekg/dns.(*Server).serveUDP
/go/src/k8s.io/dns/vendor/github.com/miekg/dns/server.go:531 +0x2d5_",closed,False,2019-01-02 20:52:26,2019-01-08 17:45:07
dns,MrHohn,https://github.com/kubernetes/dns/pull/284,https://api.github.com/repos/kubernetes/dns/issues/284,Check error for SetDefaults(),"Ref https://github.com/kubernetes/dns/issues/283#issuecomment-451000345, we should check the error returned by `SetDefaults()`. Error in `SetDefaults()` might lead to a broken DNS server.

/assign @bowei 
cc @thebag25",closed,True,2019-01-02 22:19:20,2019-01-03 18:34:31
dns,thebag25,https://github.com/kubernetes/dns/issues/285,https://api.github.com/repos/kubernetes/dns/issues/285,Not all services added to DNS,"kubernetes 1.9.6 
DNS 1.14.7
dns.go version: 1.14.6-3-gc36cb11

After startup fix I found that not all services added to DNS. We got 35 but only 21 was added.
For example kubernet-vaults related log, I see that service was returned from API but no related ""Added SVC"" log:

I0109 08:03:14.154489       1 dns.go:436] No service for endpoint ""kubernetes-vault"" in namespace ""core""
I0109 08:03:14.155692       1 dns.go:257] New service: kubernetes-vault
I0109 08:03:14.155695       1 dns.go:258] Service details: &Service{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:kubernetes-vault,GenerateName:,Namespace:core,SelfLink:/api/v1/namespaces/core/services/k
ubernetes-vault,UID:b6224357-0aa0-11e9-b668-0050569d00ae,ResourceVersion:3713136,Generation:0,CreationTimestamp:2018-12-28 13:01:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string
{run: kubernetes-vault,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,},Spec:ServiceSpec{Ports:[{port TCP 80 {0 80 } 0} {refresh TCP 8898 {0 8898 } 0}],Selector:map[string]string{run: kube
rnetes-vault,},ClusterIP:None,Type:ClusterIP,ExternalIPs:[],DeprecatedPublicIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingr
ess:[],},},}
I0109 08:03:28.806489       1 dns.go:584] Query for ""kubernetes-vault.core.svc.cluster.local."", exact: false
I0109 08:03:28.806521       1 dns.go:813] Not a federation query: len([""kubernetes-vault"" ""core"" ""svc"" ""cluster"" ""local""]) != 4+len([""local"" ""cluster""])
I0109 08:03:28.806544       1 dns.go:704] Found 0 records for [local cluster svc core kubernetes-vault] in the cache
I0109 08:03:28.806562       1 dns.go:711] getRecordsForPath retval=[], path=[local cluster svc core kubernetes-vault]
I0109 08:03:28.806581       1 dns.go:617] No record found for kubernetes-vault.core.svc.cluster.local.

",closed,False,2019-01-09 09:00:23,2019-01-10 06:38:18
dns,prameshj,https://github.com/kubernetes/dns/pull/286,https://api.github.com/repos/kubernetes/dns/issues/286,Run checks before starting CoreDNS,"https://github.com/kubernetes/dns/issues/282
There is sometimes a race in link creation and ip assignment.
If ip assignment is done too soon, the ip address does not persist.",closed,True,2019-01-23 20:14:18,2019-01-23 20:41:57
dns,prameshj,https://github.com/kubernetes/dns/pull/287,https://api.github.com/repos/kubernetes/dns/issues/287,Adding myself to OWNERS,,closed,True,2019-01-23 22:17:37,2019-01-23 22:21:28
dns,mailrocketsystems,https://github.com/kubernetes/dns/issues/288,https://api.github.com/repos/kubernetes/dns/issues/288,coredns crashloopbackoff in kubernetes 1.13.1 in Ubuntu 16.04,"I have setup `kubernetes` in `ubuntu 16.04`. I am using kube version `1.13.1` and using weave for networking. I have initialized the cluster using :

    sudo kubeadm init --token-ttl=0 --apiserver-advertise-address=192.168.88.142

and weave:

    kubectl apply -f ""https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')""

All the pods seems to be running fine but `coredns` always remains in `CrashLoopBackOff` status. I have read mostly all the solution available for this. 

    NAME                                READY   STATUS             RESTARTS   AGE
    coredns-86c58d9df4-h5plc            0/1     CrashLoopBackOff   7          18m
    coredns-86c58d9df4-l77rw            0/1     CrashLoopBackOff   7          18m
    etcd-tx-g1-209                      1/1     Running            0          17m
    kube-apiserver-tx-g1-209            1/1     Running            0          17m
    kube-controller-manager-tx-g1-209   1/1     Running            0          17m
    kube-proxy-2jdpp                    1/1     Running            0          18m
    kube-scheduler-tx-g1-209            1/1     Running            0          17m
    weave-net-npgnc                     2/2     Running            0          13m


I initially started by editing the cordens file and deleting the loop. It resolves the issue but then later I realized that I wasn't able to ping `www.google.com` from within the container but I was able to ping the ip address of google.com. Thus deleting the loop is not a perfect solution.

Next I tried looking at the `/etc/resolv.conf` and found below contents:

    # Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)
    #     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN
    nameserver 127.0.1.1
    search APSDC.local

Here is the [workaround](https://github.com/coredns/coredns/tree/master/plugin/loop#troubleshooting-loops-in-kubernetes-clusters) provided on kubernetes page which says that any type IP address like 127.0.0.1 should be avoided. I am not able to understand this line as this file is automatically generated. How can make changes to the file so that coredns can work fine. Below is the logs of coredns:

    $ kubectl logs coredns-86c58d9df4-h5plc -n kube-system

    .:53
    2019-01-31T17:26:43.665Z [INFO] CoreDNS-1.2.6
    2019-01-31T17:26:43.666Z [INFO] linux/amd64, go1.11.2, 756749c
    CoreDNS-1.2.6
    linux/amd64, go1.11.2, 756749c
    [INFO] plugin/reload: Running configuration MD5 = f65c4821c8a9b7b5eb30fa4fbc167769
    [FATAL] plugin/loop: Forwarding loop detected in ""."" zone. Exiting. See https://coredns.io/plugins/loop#troubleshooting. Probe query: ""HINFO 1423429973721138313.4523734933111484351."".

Can anyone please point me to right direction in order to resolve this issue. ",closed,False,2019-02-01 08:53:00,2019-02-01 14:57:25
dns,chenk008,https://github.com/kubernetes/dns/issues/289,https://api.github.com/repos/kubernetes/dns/issues/289,why kube-dns service is sessionAffinity?,"I install kubernetes by using kubeadm.The kube-dns service config is

`{
  ""kind"": ""Service"",
  ""apiVersion"": ""v1"",
  ""metadata"": {
    ""name"": ""kube-dns"",
    ""namespace"": ""kube-system"",
    ""labels"": {
      ""k8s-app"": ""kube-dns"",
      ""kubernetes.io/cluster-service"": ""true"",
      ""kubernetes.io/name"": ""KubeDNS""
    }
  },
  ""spec"": {
    ""ports"": [
      {
        ""name"": ""dns"",
        ""protocol"": ""UDP"",
        ""port"": 53,
        ""targetPort"": 53
      },
      {
        ""name"": ""dns-tcp"",
        ""protocol"": ""TCP"",
        ""port"": 53,
        ""targetPort"": 53
      }
    ],
    ""selector"": {
      ""k8s-app"": ""kube-dns""
    },
    ""clusterIP"": ""172.21.0.10"",
    ""type"": ""ClusterIP"",
    ""sessionAffinity"": ""ClientIP"",
    ""sessionAffinityConfig"": {
      ""clientIP"": {
        ""timeoutSeconds"": 10800
      }
    }
  },
  ""status"": {
    ""loadBalancer"": {}
  }
}`

why kube-dns need sessionAffinity?",closed,False,2019-02-14 03:15:48,2019-02-14 03:47:12
dns,joelsmith,https://github.com/kubernetes/dns/pull/290,https://api.github.com/repos/kubernetes/dns/issues/290,Update embargo doc link in SECURITY_CONTACTS and change PST to PSC,See https://github.com/kubernetes/security/issues/8 for more information,closed,True,2019-03-08 18:04:20,2019-03-09 00:18:48
dns,prameshj,https://github.com/kubernetes/dns/pull/291,https://api.github.com/repos/kubernetes/dns/issues/291,Add retry logic when iptables checks fail,"Nodelocaldns runs background checks to ensure its custom iptables rules are present. On failure, the pod restarts.
When deployed in an environment with other pods also using iptables heavily, there can be xtables lock contention. Adding a retry logic instead of exiting on first failure. 
Fixes #292 ",open,True,2019-03-09 01:00:46,2019-04-03 23:29:49
dns,JaveriaK,https://github.com/kubernetes/dns/issues/292,https://api.github.com/repos/kubernetes/dns/issues/292,node-local-dns crashes on failing to obtain iptables access,"The upstream node-local-dns implementation (https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dns/nodelocaldns) version `k8s.gcr.io/k8s-dns-node-cache:1.15.0` crashes frequently when used in a setup that has another application that also modifies iptables rules. 

I see this in my 1.10 cluster using weave-net cni that also runs on hostNetwork. Details of my setup are below:

```
$ weave version: 2.5.0 / 2.5.1

$ docker version
Client:
 Version:      17.03.2-ce
 API version:  1.27
 Go version:   go1.7.5
 Git commit:   f5ec1e2
 Built:        Tue Jun 27 02:09:56 2017
 OS/Arch:      linux/amd64

Server:
 Version:      17.03.2-ce
 API version:  1.27 (minimum version 1.12)
 Go version:   go1.7.5
 Git commit:   f5ec1e2
 Built:        Tue Jun 27 02:09:56 2017
 OS/Arch:      linux/amd64
 Experimental: false

$ uname -a
Linux ip-172-31-42-248 4.4.121-k8s #1 SMP Sun Mar 11 19:39:47 UTC 2018 x86_64 GNU/Linux

$ kubectl version
Server Version: version.Info{Major:""1"", Minor:""10"", GitVersion:""v1.10.3"", GitCommit:""2bba0127d85d5a46ab4b778548be28623b32d0b0"", GitTreeState:""clean"", BuildDate:""2018-05-21T09:05:37Z"", GoVersion:""go1.9.3"", Compiler:""gc"", Platform:""linux/amd64""}
```
With @prameshj 's help, we were able to see that when the nodelocaldns pod has issues with obtaining access to iptables it gives up too quickly with a locking error and then crashes:

```Failed to add back non-existent rule {raw PREROUTING [-p tcp -d 169.254.20.10 --dport 53 -j NOTRACK]} - error checking rule: exit status 4: Another app is currently holding the xtables lock. Stopped waiting after 2s.```",open,False,2019-03-09 01:14:03,2019-03-15 22:01:15
dns,cjwagner,https://github.com/kubernetes/dns/issues/293,https://api.github.com/repos/kubernetes/dns/issues/293,This repo should not require 'strict' status contexts.,"This repo currently has strict status context requirements enabled: https://github.com/kubernetes/test-infra/blob/b6737faf9879cba0aed01b782057aee47ad2664c/prow/config.yaml#L120

The `strict` setting corresponds to ""Require branches to be up to date before merging"" below:
![image](https://user-images.githubusercontent.com/5334145/54947756-4fd92e80-4ef8-11e9-8f94-d882c6a2a58a.png)

This setting requires that PR branches be rebased off the latest base branch commit meaning that if multiple PRs are open and one merges, other PRs must always rebase before merging. This is a simplistic method that GitHub provides for ensuring that PRs are tested against the most recent base branch commit before merging.

Tide uses a strictly superior method to provide the same guarantees without requiring PRs to be rebased whenever something else merges. This is possible because ProwJobs don't run on the PR head commits, they run on the merge commits and the base branch commit used in the merge is recorded. Tide can use this information to ensure that PRs are tested against the most recent changes without requiring PRs to be rebased unless there is an actual merge conflict.

Enabling the `strict` context requirements in a repo managed by Tide forces PR authors to rebase their PRs whenever something else merges even though this provides no benefit at all. Additionally, it is causing Tide to get stuck trying to merge some PRs because Tide doesn't know how to properly handle this merge requirement (since it doesn't makes sense to ever use this requirement with Tide).

Please remove this `strict: true` configuration ASAP:
https://github.com/kubernetes/test-infra/blob/b6737faf9879cba0aed01b782057aee47ad2664c/prow/config.yaml#L120 ",closed,False,2019-03-25 20:39:49,2019-03-25 21:59:30
dns,yuwenma,https://github.com/kubernetes/dns/pull/294,https://api.github.com/repos/kubernetes/dns/issues/294,Rebase container images from alpine to distroless.,"Updated containers:kube-dns, sidecar
Context:[KEP: Rebase k8s images to distroless](https://github.com/kubernetes/enhancements/pull/900)
Test: 
1. `make images` can create the following images
staging-k8s.gcr.io/k8s-dns-sidecar-amd64 
staging-k8s.gcr.io/k8s-dns-node-cache-amd64
staging-k8s.gcr.io/k8s-dns-kube-dns-amd64
staging-k8s.gcr.io/k8s-dns-dnsmasq-nanny-amd64
staging-k8s.gcr.io/k8s-dns-dnsmasq-amd64 

2. `docker run -e <with required flags like service host/port> <Kube-DNS-IMAGE-ID>`
can successfully upstart a container.",open,True,2019-03-28 19:57:28,2019-04-02 23:34:58
dns,lvthillo,https://github.com/kubernetes/dns/issues/295,https://api.github.com/repos/kubernetes/dns/issues/295,nslookup kubernetes.default fails from within pods #1476 ,"## Versions

**kubeadm version** (use `kubeadm version`):
`kubeadm version: &version.Info{Major:""1"", Minor:""14"", GitVersion:""v1.14.0"", GitCommit:""641856db18352033a0d96dbc99153fa3b27298e5"", GitTreeState:""clean"", BuildDate:""2019-03-25T15:51:21Z"", GoVersion:""go1.12.1"", Compiler:""gc"", Platform:""linux/amd64""}`

**Environment**: Ubuntu 18.04
- **Kubernetes version** (use `kubectl version`):
```
Client Version: version.Info{Major:""1"", Minor:""14"", GitVersion:""v1.14.0"", GitCommit:""641856db18352033a0d96dbc99153fa3b27298e5"", GitTreeState:""clean"", BuildDate:""2019-03-25T15:53:57Z"", GoVersion:""go1.12.1"", Compiler:""gc"", Platform:""linux/amd64""}
Server Version: version.Info{Major:""1"", Minor:""14"", GitVersion:""v1.14.0"", GitCommit:""641856db18352033a0d96dbc99153fa3b27298e5"", GitTreeState:""clean"", BuildDate:""2019-03-25T15:45:25Z"", GoVersion:""go1.12.1"", Compiler:""gc"", Platform:""linux/amd64""}
```
- **Cloud provider or hardware configuration**: Vagrant
- **OS** (e.g. from /etc/os-release): 
```
NAME=""Ubuntu""
VERSION=""18.04.1 LTS (Bionic Beaver)""
```
- **Kernel** (e.g. `uname -a`): Linux k8s-master 4.15.0-29-generic #31-Ubuntu SMP Tue Jul 17 15:39:52 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
- **Others**:


## What happened?
An nslookup to kubernetes.default fails from withtin a pod. I did try busybox but also others.
```
# nslookup kubernetes.default
Server:		10.0.2.3
Address:	10.0.2.3#53

** server can't find kubernetes.default: NXDOMAIN
```
From within pod:
```
 # cat /etc/resolv.conf
nameserver 10.96.0.10
search default.svc.cluster.local svc.cluster.local cluster.local 
options ndots:5
```

## What you expected to happen?
I expected it to succeed. I found this issue when I was debugging why my Kubernetes dashboard didn't work when it was running on a node (different than master).

## Anything else we need to know?
```
sudo ufw status
Status: inactive
```

I've added the following entries in `/etc/resolv.conf`
```
net.bridge.bridge-nf-call-iptables=1
net.ipv4.ip_forward=1
```

Rest of pods seem to run okay:
```
kubectl get pods -n kube-system
NAME                                    READY   STATUS             RESTARTS   AGE
calico-node-jjk6s                       1/1     Running            0          5m14s
calico-node-srw9m                       1/1     Running            0          3m4s
coredns-fb8b8dccf-j7cpz                 1/1     Running            0          5m14s
coredns-fb8b8dccf-k952q                 1/1     Running            0          5m14s
etcd-k8s-master                         1/1     Running            0          4m17s
kube-apiserver-k8s-master               1/1     Running            0          4m20s
kube-controller-manager-k8s-master      1/1     Running            0          4m15s
kube-proxy-6ld4f                        1/1     Running            0          3m4s
kube-proxy-ksgpk                        1/1     Running            0          5m14s
kube-scheduler-k8s-master               1/1     Running            0          4m32s
kubernetes-dashboard-5f7b999d65-9mtjj   0/1     CrashLoopBackOff   2          2m16s
```

dashboard logs:
```
kubectl logs kubernetes-dashboard-5f7b999d65-9mtjj -n kube-system
2019/03/31 16:14:49 Starting overwatch
2019/03/31 16:14:49 Using in-cluster config to connect to apiserver
2019/03/31 16:14:49 Using service account token for csrf signing
2019/03/31 16:15:19 Error while initializing connection to Kubernetes apiserver. This most likely means that the cluster is misconfigured (e.g., it has invalid apiserver certificates or service account's configuration) or the --apiserver-host param points to a server that does not exist. Reason: Get https://10.96.0.1:443/version: dial tcp 10.96.0.1:443: i/o timeout
Refer to our FAQ and wiki pages for more information: https://github.com/kubernetes/dashboard/wiki/FAQ
```

Telnet on master and node seems to work:telnet 10.96.0.10 53
```
Trying 10.96.0.10...
Connected to 10.96.0.10.
Escape character is '^]'.
```",closed,False,2019-03-31 16:18:42,2019-04-01 15:42:16
