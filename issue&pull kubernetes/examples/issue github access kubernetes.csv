name repository,creator user,url_html issue,url_api issue,title,body,state,pull request,data open,updated at
examples,sebgoa,https://github.com/kubernetes/examples/pull/1,https://api.github.com/repos/kubernetes/examples/issues/1,Migrate kubernetes/kubernetes/examples,"PR to migrate the examples to dedicated kubernetes/examples repo.

This preserves history.

Cleanup of source in kubernetes/kubernetes will happen after this gets merged.",closed,True,2017-05-01 14:40:51,2017-05-19 20:42:17
examples,sebgoa,https://github.com/kubernetes/examples/pull/2,https://api.github.com/repos/kubernetes/examples/issues/2,Migration,"This a copy of the the kubernetes/kubernetes /examples directory
Keeping the history intact.

It moves all current examples into a /staging directory to prepare for a cleanup .",closed,True,2017-05-19 21:05:56,2017-05-22 21:27:35
examples,sebgoa,https://github.com/kubernetes/examples/issues/3,https://api.github.com/repos/kubernetes/examples/issues/3,Handle existing issues in kubernetes/kubernetes,"Do we declared bankruptcy on existing issues in main repo ?
Or try to move things over ?",closed,False,2017-05-23 10:26:30,2018-02-25 15:33:50
examples,sebgoa,https://github.com/kubernetes/examples/issues/4,https://api.github.com/repos/kubernetes/examples/issues/4,Handle existing PR in kubernetes/kubernetes ,Do we close all existing PRs in main repo ? or try to move/redirect them ?,closed,False,2017-05-23 10:27:09,2018-02-23 02:33:52
examples,ahmetb,https://github.com/kubernetes/examples/pull/5,https://api.github.com/repos/kubernetes/examples/issues/5,"Move maintained examples to root, update README",Signed-off-by: Ahmet Alp Balkan <ahmetb@google.com>,closed,True,2017-05-24 17:21:06,2017-05-24 17:30:59
examples,ahmetb,https://github.com/kubernetes/examples/pull/6,https://api.github.com/repos/kubernetes/examples/issues/6,Fix broken cassandra link in README,/assign @sebgoa,closed,True,2017-05-24 17:35:19,2017-05-24 18:24:35
examples,chrislovecnm,https://github.com/kubernetes/examples/issues/7,https://api.github.com/repos/kubernetes/examples/issues/7,Update Cassandra Example,I have a PR in the core repo that I need to move over to here.  Also how are we doing owners here?,closed,False,2017-05-26 18:56:15,2018-03-09 08:08:33
examples,nikhita,https://github.com/kubernetes/examples/pull/8,https://api.github.com/repos/kubernetes/examples/issues/8,Fix links in guidelines,It used relative links before migration. Now they need to be updated.,closed,True,2017-05-28 12:27:59,2017-06-15 12:45:55
examples,mikeplavsky,https://github.com/kubernetes/examples/pull/9,https://api.github.com/repos/kubernetes/examples/issues/9,missing `create` for kubectl,,closed,True,2017-06-11 19:29:25,2017-06-13 08:53:28
examples,saturnism,https://github.com/kubernetes/examples/issues/10,https://api.github.com/repos/kubernetes/examples/issues/10,Example Cassandra Daemon set fails to deploy,"**What keywords did you search in Kubernetes issues before filing this one?** cassandra
**Is this a BUG REPORT or FEATURE REQUEST?** (choose one): BUG REPORT

**Kubernetes version** (use `kubectl version`):
BuildDate:""2017-05-19T18:44:27Z"", GoVersion:""go1.7.5"", Compiler:""gc"", Platform:""linux/amd64""}
Server Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.4"", GitCommit:""d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae"", GitTreeState:""clean"", 
BuildDate:""2017-05-19T18:33:17Z"", GoVersion:""go1.7.5"", Compiler:""gc"", Platform:""linux/amd64""}


**Environment**:
- **Cloud provider or hardware configuration**: GKE 1.6.4
- **OS** (e.g. from /etc/os-release): COS
- **Kernel** (e.g. `uname -a`): Linux gke-guestbook-default-pool-38a0d458-0gjw 4.4.35+ #1 SMP Wed Apr 5 13:00:57 PDT 2017 x86_64 Intel(R) Xeon(R) CPU @ 2.30GHz GenuineIntel GNU/Linux
- **Install tools**: GKE
- **Others**:

**What happened**:
Tried to deploy Cassandra daemon set example:
`kubectl create -f  https://raw.githubusercontent.com/kubernetes/kubernetes/master/examples/storage/cassandra/cassandra-daemonset.yaml`

**What you expected to happen**:
Cassandra starts on every node.

**How to reproduce it** (as minimally and precisely as possible):
`kubectl create -f  https://raw.githubusercontent.com/kubernetes/kubernetes/master/examples/storage/cassandra/cassandra-daemonset.yaml`

**Anything else we need to know**:
`kubectl  logs -f cassandra-t531v`

```
Starting Cassandra on 10.0.5.4
CASSANDRA_CONF_DIR /etc/cassandra
CASSANDRA_CFG /etc/cassandra/cassandra.yaml
CASSANDRA_AUTO_BOOTSTRAP true
CASSANDRA_BROADCAST_ADDRESS 10.0.5.4
CASSANDRA_BROADCAST_RPC_ADDRESS 10.0.5.4
CASSANDRA_CLUSTER_NAME 'Test Cluster'
CASSANDRA_COMPACTION_THROUGHPUT_MB_PER_SEC
CASSANDRA_CONCURRENT_COMPACTORS
CASSANDRA_CONCURRENT_READS
CASSANDRA_CONCURRENT_WRITES
CASSANDRA_COUNTER_CACHE_SIZE_IN_MB
CASSANDRA_DC
CASSANDRA_DISK_OPTIMIZATION_STRATEGY ssd
CASSANDRA_ENDPOINT_SNITCH SimpleSnitch
CASSANDRA_GC_WARN_THRESHOLD_IN_MS
CASSANDRA_INTERNODE_COMPRESSION
CASSANDRA_KEY_CACHE_SIZE_IN_MB
CASSANDRA_LISTEN_ADDRESS 10.0.5.4
CASSANDRA_LISTEN_INTERFACE
CASSANDRA_MEMTABLE_ALLOCATION_TYPE
CASSANDRA_MEMTABLE_CLEANUP_THRESHOLD
CASSANDRA_MEMTABLE_FLUSH_WRITERS
CASSANDRA_MIGRATION_WAIT 1
CASSANDRA_NUM_TOKENS 32
CASSANDRA_RACK
CASSANDRA_RING_DELAY 30000
CASSANDRA_RPC_ADDRESS 0.0.0.0
CASSANDRA_RPC_INTERFACE
CASSANDRA_SEEDS cassandra-t531v
CASSANDRA_SEED_PROVIDER io.k8s.cassandra.KubernetesSeedProvider
changed ownership of '/etc/cassandra/cassandra-env.sh' from root to cassandra
changed ownership of '/etc/cassandra/cassandra.yaml' from root to cassandra
changed ownership of '/etc/cassandra/jvm.options' from root to cassandra
changed ownership of '/etc/cassandra/logback.xml' from root to cassandra
changed ownership of '/etc/cassandra' from root to cassandra
OpenJDK 64-Bit Server VM warning: Cannot open file /usr/local/apache-cassandra-3.9/logs/gc.log due to No such file or directory

INFO  22:52:14 Configuration location: file:/etc/cassandra/cassandra.yaml
INFO  22:52:15 Node configuration:[allocate_tokens_for_keyspace=null; authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_bootstrap=true; auto_snapshot=true; batch_size_fail_threshold_in_kb=50; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; broadcast_address=10.0.5.4; broadcast_rpc_address=10.0.5.4; buffer_pool_use_heap_if_exhausted=true; cas_contention_timeout_in_ms=1000; cdc_enabled=false; cdc_free_space_check_interval_ms=250; cdc_raw_directory=null; cdc_total_space_in_mb=null; client_encryption_options=<REDACTED>; cluster_name=Test Cluster; column_index_cache_size_in_kb=2; column_index_size_in_kb=64; commit_failure_policy=stop; commitlog_compression=null; commitlog_directory=/cassandra_data/commitlog; commitlog_max_compression_buffers_in_pool=3; commitlog_periodic_queue_size=-1; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_batch_window_in_ms=null; commitlog_sync_period_in_ms=10000; commitlog_total_space_in_mb=null; compaction_large_partition_warning_threshold_mb=100; compaction_throughput_mb_per_sec=16; concurrent_compactors=null; concurrent_counter_writes=32; concurrent_materialized_view_writes=32; concurrent_reads=32; concurrent_replicates=null; concurrent_writes=32; counter_cache_keys_to_save=2147483647; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; credentials_cache_max_entries=1000; credentials_update_interval_in_ms=-1; credentials_validity_in_ms=2000; cross_node_timeout=false; data_file_directories=[Ljava.lang.String;@11dc3715; disk_access_mode=auto; disk_failure_policy=stop; disk_optimization_estimate_percentile=0.95; disk_optimization_page_cross_chance=0.1; disk_optimization_strategy=ssd; dynamic_snitch=true; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; enable_scripted_user_defined_functions=false; enable_user_defined_functions=false; enable_user_defined_functions_threads=true; encryption_options=null; endpoint_snitch=SimpleSnitch; file_cache_size_in_mb=null; gc_log_threshold_in_ms=200; gc_warn_threshold_in_ms=1000; hinted_handoff_disabled_datacenters=[]; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_compression=null; hints_directory=/cassandra_data/hints; hints_flush_period_in_ms=10000; incremental_backups=false; index_interval=null; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_token=null; inter_dc_stream_throughput_outbound_megabits_per_sec=200; inter_dc_tcp_nodelay=false; internode_authenticator=null; internode_compression=all; internode_recv_buff_size_in_bytes=null; internode_send_buff_size_in_bytes=null; key_cache_keys_to_save=2147483647; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=10.0.5.4; listen_interface=null; listen_interface_prefer_ipv6=false; listen_on_broadcast_address=false; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; max_hints_file_size_in_mb=128; max_mutation_size_in_kb=null; max_streaming_retries=3; max_value_size_in_mb=256; memtable_allocation_type=heap_buffers; memtable_cleanup_threshold=null; memtable_flush_writers=1; memtable_heap_space_in_mb=null; memtable_offheap_space_in_mb=null; min_free_space_per_drive_in_mb=50; native_transport_max_concurrent_connections=-1; native_transport_max_concurrent_connections_per_ip=-1; native_transport_max_frame_size_in_mb=256; native_transport_max_threads=128; native_transport_port=9042; native_transport_port_ssl=null; num_tokens=32; otc_coalescing_strategy=TIMEHORIZON; otc_coalescing_window_us=200; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_cache_max_entries=1000; permissions_update_interval_in_ms=-1; permissions_validity_in_ms=2000; phi_convict_threshold=8.0; prepared_statements_cache_size_mb=null; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_scheduler_id=null; request_scheduler_options=null; request_timeout_in_ms=10000; role_manager=CassandraRoleManager; roles_cache_max_entries=1000; roles_update_interval_in_ms=-1; roles_validity_in_ms=2000; row_cache_class_name=org.apache.cassandra.cache.OHCProvider; row_cache_keys_to_save=2147483647; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=0.0.0.0; rpc_interface=null; rpc_interface_prefer_ipv6=false; rpc_keepalive=true; rpc_listen_backlog=50; rpc_max_threads=2147483647; rpc_min_threads=16; rpc_port=9160; rpc_recv_buff_size_in_bytes=null; rpc_send_buff_size_in_bytes=null; rpc_server_type=sync; saved_caches_directory=/cassandra_data/saved_caches; seed_provider=io.k8s.cassandra.KubernetesSeedProvider{seeds=cassandra-t531v}; server_encryption_options=<REDACTED>; snapshot_before_compaction=false; ssl_storage_port=7001; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; start_rpc=false; storage_port=7000; stream_throughput_outbound_megabits_per_sec=200; streaming_socket_timeout_in_ms=86400000; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; thrift_prepared_statements_cache_size_mb=null; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; tracetype_query_ttl=86400; tracetype_repair_ttl=604800; transparent_data_encryption_options=org.apache.cassandra.config.TransparentDataEncryptionOptions@69930714; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; unlogged_batch_across_partitions_warn_threshold=10; user_defined_function_fail_timeout=1500; user_defined_function_warn_timeout=500; user_function_timeout_policy=die; windows_timer_interval=1; write_request_timeout_in_ms=2000]
INFO  22:52:15 DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
INFO  22:52:15 Global memtable on-heap threshold is enabled at 128MB
INFO  22:52:15 Global memtable off-heap threshold is enabled at 128MB
Exception (org.apache.cassandra.exceptions.ConfigurationException) encountered during startup: io.k8s.cassandra.KubernetesSeedProvider
Fatal configuration error; unable to start server.  See log for stacktrace.
org.apache.cassandra.exceptions.ConfigurationException: io.k8s.cassandra.KubernetesSeedProvider
Fatal configuration error; unable to start server.  See log for stacktrace.
        at org.apache.cassandra.config.DatabaseDescriptor.applyConfig(DatabaseDescriptor.java:782)
        at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:125)
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:576)
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:730)
ERROR 22:52:15 Exception encountered during startup
org.apache.cassandra.exceptions.ConfigurationException: io.k8s.cassandra.KubernetesSeedProvider
Fatal configuration error; unable to start server.  See log for stacktrace.
        at org.apache.cassandra.config.DatabaseDescriptor.applyConfig(DatabaseDescriptor.java:782) ~[apache-cassandra-3.9.jar:3.9]
        at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:125) ~[apache-cassandra-3.9.jar:3.9]
        at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:576) [apache-cassandra-3.9.jar:3.9]
        at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:730) [apache-cassandra-3.9.jar:3.9]
```",closed,False,2017-06-12 20:23:49,2017-07-27 19:29:42
examples,chrislovecnm,https://github.com/kubernetes/examples/issues/11,https://api.github.com/repos/kubernetes/examples/issues/11,Clarification about container policy,"I am reading this:

> Docker images are pre-built, and source is contained in a subfolder.
> Source is the Dockerfile and any custom files needed beyond the upstream app being packaged.
> Images are pushed to gcr.io/google-samples. Contact @jeffmendoza to have an image pushed
> Images are tagged with a version (not latest) that is referenced in the example config.

This has been a challenge in the past, since getting an update in takes way too long.  Are we going to implement a system to automatically push new containers?  Are we going to force all containers Dockerfiles to exist in this repo?",closed,False,2017-06-12 20:30:28,2018-02-27 17:22:52
examples,ahmetb,https://github.com/kubernetes/examples/issues/12,https://api.github.com/repos/kubernetes/examples/issues/12,Move tutorials out of this repository,"I am planning to move README.md files of the maintained examples to the docs repository and replace the contents here to link to the tutorial on kubernetes.io website.

The detailed plan can be found at https://github.com/kubernetes/kubernetes.github.io/issues/4134.

/assign",closed,False,2017-06-20 04:01:51,2017-07-11 17:10:09
examples,chrislovecnm,https://github.com/kubernetes/examples/pull/13,https://api.github.com/repos/kubernetes/examples/issues/13,[WIP] cassandra: Clean-up removing old examples,"I am working on getting some changes pushed to our container.  Once that is done I can test with a stable container.

Fixes https://github.com/kubernetes/examples/issues/10, https://github.com/kubernetes/examples/issues/7

TODO

- [ ] add new container to manifest
- [ ] update docs with new container
- [ ] some testing",closed,True,2017-06-22 19:24:40,2018-03-10 05:29:34
examples,chrislovecnm,https://github.com/kubernetes/examples/pull/14,https://api.github.com/repos/kubernetes/examples/issues/14,"We do not have a git ignore, modified version from core",,closed,True,2017-06-22 19:28:24,2017-06-27 12:44:53
examples,chrislovecnm,https://github.com/kubernetes/examples/issues/15,https://api.github.com/repos/kubernetes/examples/issues/15,Removing example labels out of core,Since C* example is over here can we remove https://github.com/kubernetes/kubernetes/issues?q=is%3Aissue+is%3Aopen+Cassandra+label%3Aarea%2Fexample%2Fcassandra labels?,closed,False,2017-06-22 19:41:20,2018-02-28 21:50:51
examples,ahmetb,https://github.com/kubernetes/examples/pull/16,https://api.github.com/repos/kubernetes/examples/issues/16,Move tutorial contents out of examples repo,"The tutorials are now migrated to kubernetes.io website. Setting up redirection
pointers from the README files here to keep maintaining these tutorials at a
single place.

/assign @jeffmendoza
cc: @sebgoa

Fixes #12.

Signed-off-by: Ahmet Alp Balkan <ahmetb@google.com>",closed,True,2017-06-26 19:25:51,2017-07-05 23:14:24
examples,erikschlegel,https://github.com/kubernetes/examples/pull/17,https://api.github.com/repos/kubernetes/examples/issues/17,Adding security support for cassandra container. Published revised co…,…ntainer to .,closed,True,2017-06-30 02:13:57,2017-06-30 04:01:28
examples,farcaller,https://github.com/kubernetes/examples/pull/18,https://api.github.com/repos/kubernetes/examples/issues/18,Updated rbd volume example to use yaml configs with better readability,"This PR turns barely-readable poorly formatted json to more compact yaml in the examples, that are supposed to be consumed by humans.

(moved from https://github.com/kubernetes/kubernetes/pull/48032)",closed,True,2017-07-01 08:18:05,2017-07-17 17:08:29
examples,maisem,https://github.com/kubernetes/examples/pull/19,https://api.github.com/repos/kubernetes/examples/issues/19,Adding cassandra test-server image,"@mml 
This is required for kubernetes/kubernetes#47200.",closed,True,2017-07-05 19:36:40,2017-07-11 17:10:51
examples,ahmetb,https://github.com/kubernetes/examples/pull/20,https://api.github.com/repos/kubernetes/examples/issues/20,Add redirection notices to tutorials,"This adds an EXCLUDE_FROM_DOCS section (removed by docs script, to be added on https://github.com/kubernetes/kubernetes.github.io/pull/4291) to the
tutorials and fixes relative-link issues in the tutorial contents.

/cc @sebgoa",closed,True,2017-07-05 23:49:27,2017-07-08 23:33:34
examples,zouyee,https://github.com/kubernetes/examples/pull/21,https://api.github.com/repos/kubernetes/examples/issues/21,update url for cluster build,,closed,True,2017-07-11 06:13:26,2017-07-13 21:07:58
examples,ahmetb,https://github.com/kubernetes/examples/pull/22,https://api.github.com/repos/kubernetes/examples/issues/22,Fix relative links in cassandra/README.md,/assign @sebgoa,closed,True,2017-07-11 17:09:20,2017-07-11 20:05:25
examples,andybrucenet,https://github.com/kubernetes/examples/issues/23,https://api.github.com/repos/kubernetes/examples/issues/23,Openshift: use of external Kubernetes is no longer supported,"Can no longer use the openshift-origin recipe to deploy openshift over existing kubernetes.

```
docker run --privileged -v /Users/l.abruce/proj/git/lmgitlab.hlsdev.local/l.lmil/lmil_sysadmin/demos/JMorenz/2017-03-MDE-ATO/poc/localdata/openshift/config:/config --name default-mde-ato-openshift-origin-openshift-master-run openshift/origin start master --kubeconfig=/config/kubeconfig --master=https://localhost:8443 --public-master=https://192.168.98.100:17082 --etcd=http://etcd:2379

W0715 18:12:48.465226       1 start_master.go:294] Warning: assetConfig.loggingPublicURL: Invalid value: """": required to view aggregated container logs in the console, master start will continue.
W0715 18:12:48.465357       1 start_master.go:294] Warning: assetConfig.metricsPublicURL: Invalid value: """": required to view cluster metrics in the console, master start will continue.
W0715 18:12:48.465371       1 start_master.go:294] Warning: serviceAccountConfig.publicKeyFiles: Invalid value: """": no service account tokens will be accepted by the API, which will prevent builds and deployments from working, master start will continue.
W0715 18:12:48.465381       1 start_master.go:294] Warning: auditConfig.auditFilePath: Required value: audit can not be logged to a separate file, master start will continue.
F0715 18:12:48.465397       1 start_master.go:115] KubernetesMasterConfig is required to start this server - use of external Kubernetes is no longer supported.

```",closed,False,2017-07-15 18:15:22,2018-03-10 22:46:35
examples,mbtamuli,https://github.com/kubernetes/examples/issues/24,https://api.github.com/repos/kubernetes/examples/issues/24,MySQL Wordpress PV example giving errors.,"**What happened**:
I was following the Stateful Applications example - [Wordpress MySQL persistent volume](https://kubernetes.io/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/)
In the [Deploy MySQL](https://kubernetes.io/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/#deploy-mysql) step, I encountered an error. I did `describe` on the pod. It was showing this error. 
```
SchedulerPredicates failed due to PersistentVolumeClaim is not bound: ""mysql-pv-claim"", which is unexpected.
```
The full output of `kubectl describe pod` is [here](http://sprunge.us/jeHQ). I also checked whether the PersistentVolume was created and whether a PersistentVolumeClaim was created - [here](http://sprunge.us/JWfP)

**What you expected to happen**:
I expected the MySQL pod to be up as the tutorial suggested. At least the tutorial should mention any such issues if they are known and link to an explanation, if possible.

**How to reproduce it (as minimally and precisely as possible)**:
```
gcloud container clusters create wp --num-nodes=3
gcloud compute disks create --size=20GB wordpress-1 wordpress-2
export KUBE_REPO=https://raw.githubusercontent.com/kubernetes/examples/master
kubectl create -f $KUBE_REPO/mysql-wordpress-pd/gce-volumes.yaml
tr --delete '\n' <password.txt >.strippedpassword.txt && mv .strippedpassword.txt password.txt
kubectl create secret generic mysql-pass --from-file=password.txt
kubectl create -f $KUBE_REPO/mysql-wordpress-pd/mysql-deployment.yaml
```
Now running `kubectl get pods` will show status as _CrashLoopBackOff_ or _Error_ in a few minutes.

**Environment**:
- Kubernetes version (use `kubectl version`): 
```Client Version: version.Info{Major:""1"", Minor:""7"", GitVersion:""v1.7.0"", GitCommit:""d3ada0119e776222f11ec7945e6d860061339aad"", GitTreeState:""clean"", BuildDate:""2017-06-29T23:15:59Z"", GoVersion:""go1.8.3"", Compiler:""gc"", Platform:""linux/amd64""}
Server Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.4"", GitCommit:""d6f433224538d4f9ca2f7ae19b252e6fcb66a3ae"", GitTreeState:""clean"", BuildDate:""2017-05-19T18:33:17Z"", GoVersion:""go1.7.5"", Compiler:""gc"", Platform:""linux/amd64""}
```
- Cloud provider or hardware configuration: GKE
- OS (e.g. from /etc/os-release): 
```
BUILD_ID=9202.64.0
NAME=""Container-Optimized OS""
GOOGLE_CRASH_ID=Lakitu
VERSION_ID=57
BUG_REPORT_URL=https://crbug.com/new
PRETTY_NAME=""Container-Optimized OS from Google""
VERSION=57
GOOGLE_METRICS_PRODUCT_ID=26
HOME_URL=""https://cloud.google.com/compute/docs/containers/vm-image/""
ID=cos
```
- Kernel (e.g. `uname -a`): 
```
Linux gke-wp-default-pool-a7a7b2f3-0cbs 4.4.35+ #1 SMP Wed Apr 5 13:00:57 PDT 2017 x86_64 Intel(R) Xeon(R) CPU @ 2.50GHz GenuineIntel GNU/Linux
```
",closed,False,2017-07-15 19:39:27,2018-03-09 16:16:40
examples,humblec,https://github.com/kubernetes/examples/pull/25,https://api.github.com/repos/kubernetes/examples/issues/25,Add `volumeoptions` Storageclass parameter to README.,Ref# https://github.com/kubernetes/kubernetes/pull/44174,closed,True,2017-07-18 06:22:23,2017-07-30 08:44:48
examples,jianglingxia,https://github.com/kubernetes/examples/pull/26,https://api.github.com/repos/kubernetes/examples/issues/26,the page link unused,"the link outdate ,then update it!",closed,True,2017-07-19 06:27:54,2017-07-19 16:31:40
examples,jianglingxia,https://github.com/kubernetes/examples/pull/27,https://api.github.com/repos/kubernetes/examples/issues/27,outdated link,outdated link,closed,True,2017-07-19 06:34:43,2017-07-19 16:28:27
examples,codablock,https://github.com/kubernetes/examples/pull/28,https://api.github.com/repos/kubernetes/examples/issues/28,Add fsType parameters to persistent volume provisioning examples,Adds examples for the fsType parameter added by https://github.com/kubernetes/kubernetes/pull/45345,closed,True,2017-07-19 11:33:31,2017-07-30 08:44:18
examples,ahmetb,https://github.com/kubernetes/examples/issues/29,https://api.github.com/repos/kubernetes/examples/issues/29,Import latest commits from kubernetes/kubernetes,"We have some of the changes merged to https://github.com/kubernetes/kubernetes/tree/master/examples after we moved the content here. In order to not to lose the changes, we should import the latest commits again, preferably with commit history.

/assign @sebgoa 
",closed,False,2017-07-19 16:30:38,2018-03-02 06:22:14
examples,colindev,https://github.com/kubernetes/examples/pull/30,https://api.github.com/repos/kubernetes/examples/issues/30,"fix miss properties ""storageClassName"" and change nfs-server",,closed,True,2017-07-20 09:21:43,2017-07-30 19:19:31
examples,php-coder,https://github.com/kubernetes/examples/pull/31,https://api.github.com/repos/kubernetes/examples/issues/31,staging/podsecuritypolicy/rbac: sync example with kubernetes repo,"This PR imports changes from https://github.com/kubernetes/kubernetes/pull/45975 and https://github.com/kubernetes/kubernetes/pull/48862

CC @simo5",closed,True,2017-07-20 16:53:40,2017-07-30 10:59:11
examples,enisoc,https://github.com/kubernetes/examples/pull/32,https://api.github.com/repos/kubernetes/examples/issues/32,Remove unnecessary `initialized` annotation.,"The `pod.alpha.kubernetes.io/initialized` annotation is deprecated and the default in StatefulSet is `true` so it is unnecessary.

ref https://github.com/kubernetes/kubernetes/issues/41605",closed,True,2017-07-20 22:14:07,2017-07-24 02:56:20
examples,charrywanganthony,https://github.com/kubernetes/examples/pull/33,https://api.github.com/repos/kubernetes/examples/issues/33,Fix a wrong hyperlink,Fix a wrong hyperlink. It should be directed to redis-master-service.yaml.,closed,True,2017-07-22 02:43:58,2017-07-24 02:16:49
examples,afoerster,https://github.com/kubernetes/examples/pull/34,https://api.github.com/repos/kubernetes/examples/issues/34,Fix spark example links,Links were broken after spark example move to 'staging' dir,closed,True,2017-07-22 11:46:50,2017-07-22 11:51:00
examples,afoerster,https://github.com/kubernetes/examples/pull/35,https://api.github.com/repos/kubernetes/examples/issues/35,Fix spark example links,Links were broken after spark example move to 'staging' dir,closed,True,2017-07-22 11:51:16,2017-07-30 08:39:54
examples,charrywanganthony,https://github.com/kubernetes/examples/pull/36,https://api.github.com/repos/kubernetes/examples/issues/36,Fix a wrong link,Fix a wrong hyperlink. It should be directed to redis-master-service.yaml.,closed,True,2017-07-24 02:17:15,2017-07-24 02:55:47
examples,php-coder,https://github.com/kubernetes/examples/issues/37,https://api.github.com/repos/kubernetes/examples/issues/37,staging/psp/rbac: update usage of local-up-cluster.sh,"I see that example of using `local-up-cluster.sh` could be updated:
- we don't need to specify `ALLOW_ANY_TOKEN=true` variable because it was removed: https://github.com/kubernetes/kubernetes/pull/49045 (RBAC example ""relies on the ALLOW_ANY_TOKEN setting"" so perhaps it doesn't work at this time. Here is the PR message about what to use instead: ""users of the flag should use impersonation headers instead for debugging"")
- we don't need to specify `ENABLE_RBAC=true` variable anymore as it's enabled by default: https://github.com/kubernetes/kubernetes/pull/49323
- we don't need to specify `RUNTIME_CONFIG=""extensions/v1beta1=true,extensions/v1beta1/podsecuritypolicy=true""` anymore as it's enabled by default since 1.6: https://github.com/kubernetes/kubernetes/pull/39743
- we should note that now default PSP policies are created by default: https://github.com/kubernetes/kubernetes/pull/39301

CC @pweil- @liggitt ",closed,False,2017-07-25 14:06:26,2017-11-27 21:36:02
examples,cody-clark,https://github.com/kubernetes/examples/pull/38,https://api.github.com/repos/kubernetes/examples/issues/38,Polishing the Cassandra Tutorial,"- Tutorial template applied
- Per [issue #7](https://github.com/kubernetes/examples/issues/7) and [issue #10](https://github.com/kubernetes/examples/issues/10) Replication Controller and DaemonSet sections and `.yaml` files deleted.
- Edited steps to be more task-oriented ",closed,True,2017-07-25 19:29:03,2017-11-27 22:53:42
examples,Pensu,https://github.com/kubernetes/examples/pull/39,https://api.github.com/repos/kubernetes/examples/issues/39,Adding Dockerfile for ppc64le for cluster-dns example,This PR adds the dockerfile for ppc64le for frontend and backend pod.,closed,True,2017-07-26 09:32:01,2017-09-21 09:41:18
examples,andrewcheny,https://github.com/kubernetes/examples/issues/40,https://api.github.com/repos/kubernetes/examples/issues/40,CrashLoopBackOff for mysql-deployment.yaml,"Following instructions to create wordpress-mysql statefulset. The only difference from the instruction is that I created persistentvolume with NFS. I can see the persistentvolumeclaim successfully bound to the persistentvolumes. But 'describe pod' shows CrashLoopBackOff. The following is the console output:

```
Name:		wordpress-mysql-1894417608-vljsm
Namespace:	default
Node:		rh4/8.0.0.8
Start Time:	Thu, 27 Jul 2017 14:59:02 +0000
Labels:		app=wordpress
		pod-template-hash=1894417608
		tier=mysql
Annotations:	kubernetes.io/created-by={""kind"":""SerializedReference"",""apiVersion"":""v1"",""reference"":{""kind"":""ReplicaSet"",""namespace"":""default"",""name"":""wordpress-mysql-1894417608"",""uid"":""2071b96d-72dc-11e7-aafb-001dd...
Status:		Running
IP:		10.233.109.6
Controllers:	ReplicaSet/wordpress-mysql-1894417608
Containers:
  mysql:
    Container ID:	docker://586fb71c34351a58504629aa59457620c418273bb8e00751f02e9095bdf7ae45
    Image:		mysql:5.6
    Image ID:		docker-pullable://mysql@sha256:2897982d4c086b03586a1423d0cbf33688960ef7534b7bb51b9bcfdb6c3597e7
    Port:		3306/TCP
    State:		Waiting
      Reason:		CrashLoopBackOff
    Last State:		Terminated
      Reason:		Error
      Exit Code:	1
      Started:		Thu, 27 Jul 2017 15:25:23 +0000
      Finished:		Thu, 27 Jul 2017 15:25:24 +0000
    Ready:		False
    Restart Count:	10
    Environment:
      MYSQL_ROOT_PASSWORD:	<set to the key 'password.txt' in secret 'mysql-pass'>	Optional: false
    Mounts:
      /var/lib/mysql from mysql-persistent-storage (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-n94rj (ro)
Conditions:
  Type		Status
  Initialized 	True 
  Ready 	False 
  PodScheduled 	True 
Volumes:
  mysql-persistent-storage:
    Type:	PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:	mysql-pv-claim
    ReadOnly:	false
  default-token-n94rj:
    Type:	Secret (a volume populated by a Secret)
    SecretName:	default-token-n94rj
    Optional:	false
QoS Class:	BestEffort
Node-Selectors:	<none>
Tolerations:	<none>
Events:
  FirstSeen	LastSeen	Count	From			SubObjectPath		Type		Reason		Message
  ---------	--------	-----	----			-------------		--------	------		-------
  29m		29m		1	default-scheduler				Normal		Scheduled	Successfully assigned wordpress-mysql-1894417608-vljsm to rh4
  29m		29m		1	kubelet, rh4		spec.containers{mysql}	Normal		Created		Created container with docker id 9f305c7fe737; Security:[seccomp=unconfined]
  29m		29m		1	kubelet, rh4		spec.containers{mysql}	Normal		Started		Started container with docker id 9f305c7fe737
  29m		29m		1	kubelet, rh4		spec.containers{mysql}	Normal		Created		Created container with docker id ba26b6fb0afc; Security:[seccomp=unconfined]
  29m		29m		1	kubelet, rh4		spec.containers{mysql}	Normal		Started		Started container with docker id ba26b6fb0afc
  29m		29m		2	kubelet, rh4					Warning		FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""mysql"" with CrashLoopBackOff: ""Back-off 10s restarting failed container=mysql pod=wordpress-mysql-1894417608-vljsm_default(2074c5c0-72dc-11e7-aafb-001dd8008f63)""

  28m	28m	1	kubelet, rh4	spec.containers{mysql}	Normal	Started		Started container with docker id d76e629b9548
  28m	28m	1	kubelet, rh4	spec.containers{mysql}	Normal	Created		Created container with docker id d76e629b9548; Security:[seccomp=unconfined]
  28m	28m	2	kubelet, rh4				Warning	FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""mysql"" with CrashLoopBackOff: ""Back-off 20s restarting failed container=mysql pod=wordpress-mysql-1894417608-vljsm_default(2074c5c0-72dc-11e7-aafb-001dd8008f63)""

  28m	28m	1	kubelet, rh4	spec.containers{mysql}	Normal	Started		Started container with docker id fcae4f1e7f86
  28m	28m	1	kubelet, rh4	spec.containers{mysql}	Normal	Created		Created container with docker id fcae4f1e7f86; Security:[seccomp=unconfined]
  28m	28m	3	kubelet, rh4				Warning	FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""mysql"" with CrashLoopBackOff: ""Back-off 40s restarting failed container=mysql pod=wordpress-mysql-1894417608-vljsm_default(2074c5c0-72dc-11e7-aafb-001dd8008f63)""

  27m	27m	1	kubelet, rh4	spec.containers{mysql}	Normal	Started		Started container with docker id 5ab0b825b247
  27m	27m	1	kubelet, rh4	spec.containers{mysql}	Normal	Created		Created container with docker id 5ab0b825b247; Security:[seccomp=unconfined]
  27m	26m	6	kubelet, rh4				Warning	FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""mysql"" with CrashLoopBackOff: ""Back-off 1m20s restarting failed container=mysql pod=wordpress-mysql-1894417608-vljsm_default(2074c5c0-72dc-11e7-aafb-001dd8008f63)""

  26m	26m	1	kubelet, rh4	spec.containers{mysql}	Normal	Created		Created container with docker id 1fd6c0d3ac9d; Security:[seccomp=unconfined]
  26m	26m	1	kubelet, rh4	spec.containers{mysql}	Normal	Started		Started container with docker id 1fd6c0d3ac9d
  26m	23m	13	kubelet, rh4				Warning	FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""mysql"" with CrashLoopBackOff: ""Back-off 2m40s restarting failed container=mysql pod=wordpress-mysql-1894417608-vljsm_default(2074c5c0-72dc-11e7-aafb-001dd8008f63)""

  23m	23m	1	kubelet, rh4	spec.containers{mysql}	Normal	Created		Created container with docker id 10d68e7ac5b3; Security:[seccomp=unconfined]
  23m	23m	1	kubelet, rh4	spec.containers{mysql}	Normal	Started		Started container with docker id 10d68e7ac5b3
  18m	18m	1	kubelet, rh4	spec.containers{mysql}	Normal	Started		Started container with docker id 06848eb5a40d
  18m	18m	1	kubelet, rh4	spec.containers{mysql}	Normal	Created		Created container with docker id 06848eb5a40d; Security:[seccomp=unconfined]
  13m	13m	1	kubelet, rh4	spec.containers{mysql}	Normal	Started		Started container with docker id b685ed1a8f06
  13m	13m	1	kubelet, rh4	spec.containers{mysql}	Normal	Created		Created container with docker id b685ed1a8f06; Security:[seccomp=unconfined]
  8m	2m	2	kubelet, rh4	spec.containers{mysql}	Normal	Started		(events with common reason combined)
  8m	2m	2	kubelet, rh4	spec.containers{mysql}	Normal	Created		(events with common reason combined)
  29m	2m	11	kubelet, rh4	spec.containers{mysql}	Normal	Pulled		Container image ""mysql:5.6"" already present on machine
  23m	1s	109	kubelet, rh4				Warning	FailedSync	Error syncing pod, skipping: failed to ""StartContainer"" for ""mysql"" with CrashLoopBackOff: ""Back-off 5m0s restarting failed container=mysql pod=wordpress-mysql-1894417608-vljsm_default(2074c5c0-72dc-11e7-aafb-001dd8008f63)""

  29m	1s	135	kubelet, rh4	spec.containers{mysql}	Warning	BackOff	Back-off restarting failed docker container
```",closed,False,2017-07-27 15:35:24,2018-03-09 07:07:36
examples,ahmetb,https://github.com/kubernetes/examples/pull/41,https://api.github.com/repos/kubernetes/examples/issues/41,Fix relative link in guestbook/README.md,,closed,True,2017-07-27 21:10:25,2017-07-27 21:10:45
examples,cody-clark,https://github.com/kubernetes/examples/pull/42,https://api.github.com/repos/kubernetes/examples/issues/42,Fixed links and formatting,,closed,True,2017-07-27 21:54:28,2017-08-01 18:36:41
examples,mkumatag,https://github.com/kubernetes/examples/pull/43,https://api.github.com/repos/kubernetes/examples/issues/43,Multi arch guestbook example,Guestbook example is part of [Conformance tests](https://github.com/kubernetes/kubernetes/blob/master/test/e2e/kubectl/kubectl.go#L354). So this PR is for converting this example multi architecture to support conformance tests on all possible architectures.,closed,True,2017-07-28 15:57:46,2017-09-07 18:20:23
examples,kingdonb,https://github.com/kubernetes/examples/issues/44,https://api.github.com/repos/kubernetes/examples/issues/44,NFS example needs updates,"Is this now the best place to raise: kubernetes/kubernetes#48161

The NFS example is not on the list of supported examples, but if you're looking for maintainer volunteers... I am pretty sure I am going to need this NFS example to work personally, and I hope to keep up with Kubernetes upgrades with several dev/prod environments, so I might be a good fit for supporting maintainer.",closed,False,2017-07-29 22:12:09,2017-10-23 14:28:09
examples,rfay,https://github.com/kubernetes/examples/pull/45,https://api.github.com/repos/kubernetes/examples/issues/45,Switch from annotations to storageClassName in minio example,"I was running through the minio example and note that it uses the deprecated `volume.alpha.kubernetes.io/storage-class: anything` annotation instead of the newer `storageClassName: standard`

This PR just switches to `storageClassName: standard`",closed,True,2017-08-01 16:17:12,2017-08-04 17:39:49
examples,cody-clark,https://github.com/kubernetes/examples/pull/46,https://api.github.com/repos/kubernetes/examples/issues/46,Guestbook revisions + Minikube Default Frontend Service,,closed,True,2017-08-01 22:01:26,2017-08-04 21:15:44
examples,laurilehmijoki,https://github.com/kubernetes/examples/pull/47,https://api.github.com/repos/kubernetes/examples/issues/47,Fix typo,,closed,True,2017-08-03 07:13:59,2017-10-22 13:43:50
examples,ashwinipatankar,https://github.com/kubernetes/examples/issues/48,https://api.github.com/repos/kubernetes/examples/issues/48,Cassandra Statefulset: How to expose the cluster?,"I am trying out the cassandra -statefulset example. And can see all the three pods joined the cluster:
```
kubectl exec cassandra-0 -- nodetool status
Datacenter: DC1-K8Demo
======================
Status=Up/Down
|/ State=Normal/Leaving/Joining/Moving
--  Address    Load       Tokens       Owns (effective)  Host ID                               Rack
UN  10.44.0.4  65.63 KiB  32           59.3%             91152a3e-c802-45bf-a4a9-33187a97b4c4  Rack1-K8Demo
UN  10.45.0.1  65.63 KiB  32           68.9%             ca7d39f4-341a-43d6-a180-23f89b124334  Rack1-K8Demo
UN  10.44.0.3  65.59 KiB  32           71.9%             b9075133-61ed-4fde-97c7-c2fd8d2b4234  Rack1-K8Demo
```


The out put of kubectl get service is:

```
kubectl get services
NAME         CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE
cassandra    None         <none>        9042/TCP   10s
kubernetes   10.96.0.1    <none>        443/TCP    50m

```
Now, I want to expose it and use from out side the cluster. 

Any help will be highly appreciated.

",closed,False,2017-08-03 11:23:36,2017-08-03 18:04:47
examples,liggitt,https://github.com/kubernetes/examples/pull/49,https://api.github.com/repos/kubernetes/examples/issues/49,Namespaced PSP permissions,,closed,True,2017-08-03 20:09:36,2017-08-30 18:17:47
examples,ahmetb,https://github.com/kubernetes/examples/issues/50,https://api.github.com/repos/kubernetes/examples/issues/50,guestbook: consider splitting service file into two,"Currently we're telling people:

```yaml
spec:
  # comment or delete the following line if you want to use a LoadBalancer
  type: NodePort 
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ...
```

Instead of this we should have 2 files that are ready to be deployed, configured with NodePort and LoadBalancer respectively.

This way we can say ""if you're on minikube, deploy `frontend-service.yaml`, if you're on a cloud provider, deploy `frontend-service-external.yaml`.

cc: @cody-clark 
",closed,False,2017-08-04 16:52:22,2018-03-09 15:15:33
examples,ahmetb,https://github.com/kubernetes/examples/issues/51,https://api.github.com/repos/kubernetes/examples/issues/51,guestbook: consider using single-instance redis deployment,"Currently guestbook deployment consists of:

- frontend, 3 replicas (+service)
- redis-master, 1 replica (+service)
- redis-slave, 2 replicas (+service)

Redis reads go to slaves, writes go to master. However it seems like an overkill to me to have slave/master in this tutorial:

- it makes the tutorial ~30% longer and we have to explain why we have slave/master setup
- we have to maintain a custom redis image with entrypoint pointing to a custom script
- same story can be told with a single-instance redis image from Docker Hub.

cc: @jeffmendoza do you have any context you can provide?",closed,False,2017-08-04 16:55:48,2018-03-09 15:15:34
examples,netroby,https://github.com/kubernetes/examples/pull/52,https://api.github.com/repos/kubernetes/examples/issues/52,Update wordpress to 4.8.1,,closed,True,2017-08-05 00:55:45,2017-08-10 17:50:46
examples,fisherxu,https://github.com/kubernetes/examples/pull/53,https://api.github.com/repos/kubernetes/examples/issues/53,Fix typo,"I think the 'kubernets' should be start with 'K', so I fix it.",closed,True,2017-08-05 05:37:36,2017-08-08 16:54:07
examples,Jim-Lin,https://github.com/kubernetes/examples/pull/54,https://api.github.com/repos/kubernetes/examples/issues/54,Update Elasticsearch to 5.6.2,"- fix example file path and some log information
- modify yaml file in order to run 5.5.1",closed,True,2017-08-07 17:43:06,2017-10-02 22:04:53
examples,ahmetb,https://github.com/kubernetes/examples/pull/55,https://api.github.com/repos/kubernetes/examples/issues/55,guestbook: Fix code import links,"merging directly to unblock
https://github.com/kubernetes/kubernetes.github.io/pull/4631",closed,True,2017-08-07 21:02:13,2017-08-07 21:02:24
examples,cody-clark,https://github.com/kubernetes/examples/pull/56,https://api.github.com/repos/kubernetes/examples/issues/56,Working download links for manifest files,,closed,True,2017-08-07 22:18:39,2017-08-07 22:57:56
examples,cody-clark,https://github.com/kubernetes/examples/pull/57,https://api.github.com/repos/kubernetes/examples/issues/57,Adding callouts ,"removing {start=""#""}, and minor edits for consistency with other tutorials",closed,True,2017-08-08 19:48:02,2017-08-17 19:42:24
examples,JuneZhao,https://github.com/kubernetes/examples/issues/58,https://api.github.com/repos/kubernetes/examples/issues/58,https will be supported in the k8s example,How to configure a SSL for the wordpress website in the docker image,closed,False,2017-08-09 13:26:03,2017-08-09 19:46:04
examples,leifmadsen,https://github.com/kubernetes/examples/pull/59,https://api.github.com/repos/kubernetes/examples/issues/59,Clean up the example GlusterFS README,"Clean up the GlusterFS example volume README markdown file by
word wrapping long paragraphs to 80 chars, fixing the first
bullet list markdown syntax, and adding a 'json' code block
type mark.

Signed-off-by: Leif Madsen <lmadsen@redhat.com>",closed,True,2017-08-11 20:48:24,2017-08-11 21:00:19
examples,hzxuzhonghu,https://github.com/kubernetes/examples/pull/60,https://api.github.com/repos/kubernetes/examples/issues/60,Update guidelines.md,,closed,True,2017-08-12 08:26:49,2017-08-15 03:03:38
examples,seeekr,https://github.com/kubernetes/examples/pull/61,https://api.github.com/repos/kubernetes/examples/issues/61,fix typo in staging/storage/mysql-galera/README.md,,closed,True,2017-08-12 14:00:35,2017-08-14 17:05:18
examples,mbssaiakhil,https://github.com/kubernetes/examples/pull/62,https://api.github.com/repos/kubernetes/examples/issues/62,Fix typo and grammatical issue,Fix typo and grammatical issue in Example Guidelines,closed,True,2017-08-13 10:16:40,2017-08-14 16:37:20
examples,ianchakeres,https://github.com/kubernetes/examples/pull/63,https://api.github.com/repos/kubernetes/examples/issues/63,Added imageFormat and imageFeatures for rbd,"In https://github.com/kubernetes/kubernetes/pull/45805 two additional parameters were added to rbd.

This PR adds those two parameters to the README and rbd example. ",closed,True,2017-08-13 16:17:19,2017-08-18 07:59:22
examples,cody-clark,https://github.com/kubernetes/examples/pull/64,https://api.github.com/repos/kubernetes/examples/issues/64,Adding Callouts and Fixing Links,"Adding callout formatting and other small fixes to Cassandra tutorial.
Fixing download links for Guestbook.",closed,True,2017-08-14 18:32:45,2017-08-14 21:08:04
examples,cody-clark,https://github.com/kubernetes/examples/pull/65,https://api.github.com/repos/kubernetes/examples/issues/65,Polishing MySQL / WordPress Tutorial,,closed,True,2017-08-16 00:02:46,2017-08-17 22:47:19
examples,cody-clark,https://github.com/kubernetes/examples/pull/66,https://api.github.com/repos/kubernetes/examples/issues/66,Updating to reflect new Secret creation,,closed,True,2017-08-17 18:13:31,2017-08-17 19:41:19
examples,cody-clark,https://github.com/kubernetes/examples/pull/67,https://api.github.com/repos/kubernetes/examples/issues/67,Updating to reflect new Secret creation,,closed,True,2017-08-17 18:13:45,2017-08-17 19:41:00
examples,islinwb,https://github.com/kubernetes/examples/pull/68,https://api.github.com/repos/kubernetes/examples/issues/68,Update README.md,fix typos,closed,True,2017-08-18 16:55:25,2017-08-20 02:44:53
examples,islinwb,https://github.com/kubernetes/examples/pull/69,https://api.github.com/repos/kubernetes/examples/issues/69,Fix typos,,closed,True,2017-08-18 18:21:48,2017-08-20 02:44:55
examples,ahmetb,https://github.com/kubernetes/examples/pull/70,https://api.github.com/repos/kubernetes/examples/issues/70,Fix includecode syntax in wordpress/README,Will directly commit as trivial change.,closed,True,2017-08-18 20:17:25,2017-08-18 20:17:40
examples,ahmetb,https://github.com/kubernetes/examples/pull/71,https://api.github.com/repos/kubernetes/examples/issues/71,Fix broken include code path on wordpress/README,"This stuff takes A LOT OF back and forth between this repo and docs repo to
figure out something that works right. I'll move tutorial content to the docs
repo ASAP.",closed,True,2017-08-18 20:27:05,2017-08-18 20:27:30
examples,ahmetb,https://github.com/kubernetes/examples/pull/72,https://api.github.com/repos/kubernetes/examples/issues/72,guestbook: Move image build instructions out,"This section does not belong to the README.md which gets rendered at
https://kubernetes.io/docs/tutorials/stateless-application/guestbook/.
Moving these instructions to MAINTENANCE.md.

My bad for missing this during the review.

I will merge this directly to unblock the import to the docs site. Let me know
if you have any objections later on.
/cc @sebgoa @mkumatag
",closed,True,2017-08-18 22:17:23,2017-08-18 22:17:42
examples,islinwb,https://github.com/kubernetes/examples/pull/73,https://api.github.com/repos/kubernetes/examples/issues/73,Update docs in cassandra/,"fix typos in cassandra/README.md, cassandra/java/README.md.",closed,True,2017-08-19 01:43:52,2017-08-19 08:08:20
examples,islinwb,https://github.com/kubernetes/examples/pull/74,https://api.github.com/repos/kubernetes/examples/issues/74,Fixed misspelling and typos in staging/spark/README.md,,closed,True,2017-08-19 02:19:34,2017-08-20 02:42:54
examples,islinwb,https://github.com/kubernetes/examples/pull/75,https://api.github.com/repos/kubernetes/examples/issues/75,Fix typo in  staging/javaee/README.md,"Line 81: ""it's"" --> ""its""",closed,True,2017-08-20 02:50:32,2017-08-20 12:41:20
examples,islinwb,https://github.com/kubernetes/examples/pull/76,https://api.github.com/repos/kubernetes/examples/issues/76,Update staging/spark/README.md,"Line 26: removed the redundant ""installed"";
Line 114: fixed misspelling of ""necessary"".",closed,True,2017-08-20 06:33:17,2017-08-20 12:43:06
examples,islinwb,https://github.com/kubernetes/examples/pull/77,https://api.github.com/repos/kubernetes/examples/issues/77,Fix typos in /staging/volumes/flocker/README.md,,closed,True,2017-08-20 07:27:40,2017-08-20 12:44:56
examples,islinwb,https://github.com/kubernetes/examples/pull/78,https://api.github.com/repos/kubernetes/examples/issues/78,Update README.md,fixed typos,closed,True,2017-08-21 02:29:40,2017-08-21 17:59:25
examples,Miyurz,https://github.com/kubernetes/examples/pull/79,https://api.github.com/repos/kubernetes/examples/issues/79,Fixed README with the correct results and added the role to redis master,"A couple of fixes in README.md. For instance, when you delete the redis-master pod , the sentinel pods do not decrease to 2. Infact, its just the reds server pods that loses its pod. 

Also, added a word of caution for the newbies and the impatient to not run all commands consecutively but rather wait for th redid-master pod to come up and then delete it.",closed,True,2017-08-21 19:36:49,2017-08-31 04:41:42
examples,bamb00,https://github.com/kubernetes/examples/issues/80,https://api.github.com/repos/kubernetes/examples/issues/80,minio distributed service stuck and failed to load,"Kubernetes v1.6.6

https://github.com/kubernetes/examples/tree/master/staging/storage/minio#step-1-create-minio-headless-service

Minio Distributed Server Deployment: The non-headless service failed to load causes the pod failed to load and eventually the pvc failed to load.

     $ kubectl get svc minio-service
     NAME                       CLUSTER-IP     EXTERNAL-IP       PORT(S)             AGE
     minio-service             10.45.215.47     pending       9000:31852/TCP         24m


Create the two services and deployment using the yaml below,
kubectl create -f https://github.com/kubernetes/kubernetes/blob/master/examples/storage/minio/minio-distributed-headless-service.yaml?raw=true
kubectl create -f https://github.com/kubernetes/kubernetes/blob/master/examples/storage/minio/minio-distributed-statefulset.yaml?raw=true
kubectl create -f https://github.com/kubernetes/kubernetes/blob/master/examples/storage/minio/minio-distributed-service.yaml?raw=true",closed,False,2017-08-21 21:41:06,2018-03-10 09:33:36
examples,kaustavha,https://github.com/kubernetes/examples/pull/81,https://api.github.com/repos/kubernetes/examples/issues/81,fix(wordpress): Fix link and displayed document in section on wordpress,"Found a small bug on the kubernetes docs site, the displayed code was for mysql a second time instead of the wordpress deployment yaml. This fixes that. 
Will i have to run ` ./update-imported-tutorials.sh ` as stated here https://github.com/kubernetes/kubernetes.github.io/edit/master/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume.md after this gets merged or is there a CI/CD thing thatll handle that?
",closed,True,2017-08-21 23:07:59,2017-09-05 19:25:32
examples,islinwb,https://github.com/kubernetes/examples/pull/82,https://api.github.com/repos/kubernetes/examples/issues/82,fix typos in staging/runtime-constraints/README.md,,closed,True,2017-08-22 01:47:14,2017-09-18 11:02:12
examples,mbssaiakhil,https://github.com/kubernetes/examples/pull/83,https://api.github.com/repos/kubernetes/examples/issues/83,Fix Minor Typo,Fix Minor Typo in Using Persistent Volumes with MySQL and WordPress,closed,True,2017-08-22 15:17:39,2017-08-25 11:28:20
examples,luciferksh,https://github.com/kubernetes/examples/issues/84,https://api.github.com/repos/kubernetes/examples/issues/84,How to pass access token in spark-submit to connect to k8s cluster,"I have tried to submit spark job using spark-submit in our k8s cluster. The authentication was failed. I have tried with kubectl proxy also. It was not working. Is anyone try to add access token in spark-submit for k8s.
```shell
bin/spark-submit  --deploy-mode cluster   --class org.apache.spark.examples.SparkPi   --master k8s://http://127.0.0.1:8003 & KUBERNETES_TRUST_CERTIFICATES=true.  --kubernetes-namespace sidartha-spark-cluster   --conf spark.executor.instances=2   --conf spark.app.name=spark-pi   --conf spark.kubernetes.driver.docker.image=kubespark/spark-driver:v2.1.0-kubernetes-0.1.0-rc1   --conf spark.kubernetes.executor.docker.image=kubespark/spark-executor:v2.1.0-kubernetes-0.1.0-rc1   examples/jars/spark-examples_2.11-2.1.0-k8s-0.1.0-SNAPSHOT.jar 1000
```

getting this error 
```shell
Exception in thread ""main"" io.fabric8.kubernetes.client.KubernetesClientException: Failure executing: POST at: http://127.0.0.1:8003/api/v1/namespaces/sidartha-spark-cluster/pods. Message: Forbidden! User sidartha-spark-cluster doesn't have permission..
```",closed,False,2017-08-23 08:44:40,2017-08-23 08:51:38
examples,ahmetb,https://github.com/kubernetes/examples/pull/85,https://api.github.com/repos/kubernetes/examples/issues/85,Redirect tutorials to the docs site,/assign @sebgoa,closed,True,2017-08-23 20:46:58,2017-08-26 19:42:11
examples,gtaylor,https://github.com/kubernetes/examples/pull/86,https://api.github.com/repos/kubernetes/examples/issues/86,Correct aws_ebs README.md's IAM instructions,"/assign @sebgoa

The masters manage EBS volumes for the nodes, so only they need the IAM permissions mentioned in the README.",closed,True,2017-08-25 15:36:50,2017-08-25 17:14:45
examples,andyzhangx,https://github.com/kubernetes/examples/pull/87,https://api.github.com/repos/kubernetes/examples/issues/87,Azure disk examples,"**What this PR does / why we need it**:
This PR shows examples for mounting azure disk from v1.7.2, including managed disk support.

Original PR is https://github.com/kubernetes/kubernetes/pull/49468, per @sebgoa request, I have created this new PR. Original PR has already been reviewed by azure team.",closed,True,2017-08-28 03:03:03,2017-10-10 15:39:57
examples,dillaman,https://github.com/kubernetes/examples/pull/88,https://api.github.com/repos/kubernetes/examples/issues/88,rbd: default image format to v2 instead of deprecated v1,"Image format v1 has been deprecated since the Infernalis release of
Ceph over two years ago.",closed,True,2017-08-30 00:18:17,2018-02-27 18:30:54
examples,Miouge1,https://github.com/kubernetes/examples/issues/89,https://api.github.com/repos/kubernetes/examples/issues/89,Cassandra: seed provider lists no seeds.,"Hi,

Following the instruction of the Cassandra example leads to the following error message:
```
The seed provider lists no seeds.
WARN  14:15:51 Seed provider couldn't lookup host cassandra-0.cassandra.default.svc.cluster.local
Exception (org.apache.cassandra.exceptions.ConfigurationException) encountered during startup: The seed provider lists no seeds.
ERROR 14:15:51 Exception encountered during startup: The seed provider lists no seeds.
```

It looks like a chicken an egg situation:
- Container starts
- readiness probe shows cassandra-0 is not ready
- Cassandra checks the seed, cassandra-0.cassandra.default.svc.cluster.local does not resolve
- Container stops with fatal error

If I comment the readinessProbe then the stateful set works.

Shouldn't this use the KubernetesSeedProvider?

> Client Version: version.Info{Major:""1"", Minor:""6"", GitVersion:""v1.6.3"", GitCommit:""0480917b552be33e2dba47386e51decb1a211df6"", GitTreeState:""clean"", BuildDate:""2017-05-10T15:48:59Z"", GoVersion:""go1.7.5"", Compiler:""gc"", Platform:""darwin/amd64""}
> Server Version: version.Info{Major:""1"", Minor:""5"", GitVersion:""v1.5.2"", GitCommit:""269f928217957e7126dc87e6adfa82242bfe5b1e"", GitTreeState:""clean"", BuildDate:""2017-07-03T15:31:10Z"", GoVersion:""go1.7.4"", Compiler:""gc"", Platform:""linux/amd64""}",closed,False,2017-08-30 14:37:12,2018-11-21 18:35:26
examples,luciferksh,https://github.com/kubernetes/examples/issues/90,https://api.github.com/repos/kubernetes/examples/issues/90,Not able to run spark-submit iteractively on zeppelin container.,"I have setup spark cluster in our k8s infrastructure. And i was trying to submit spark program through spark-submit in zepelin container as follow -
```shell
kubectl exec zeppelin-controller-nqz79 -it spark-submit --class com.ibm.cedp.spark.JavaSparkPi /home/sidartha/bazel/bazel-bin/java/com/ibm/cedp/spark/SparkPi_deploy.jar

```
And getting follwing error -
```shell
Error: unknown flag: --class

```",closed,False,2017-08-31 09:27:37,2018-08-30 07:13:23
examples,vladimirvivien,https://github.com/kubernetes/examples/pull/91,https://api.github.com/repos/kubernetes/examples/issues/91,ScaleIO - documentation update ,This PR is for documenting changes and updates for the ScaleIO volume plugin.,closed,True,2017-09-01 15:29:08,2017-09-05 17:00:08
examples,Gcastelo,https://github.com/kubernetes/examples/issues/92,https://api.github.com/repos/kubernetes/examples/issues/92,OMS dameonset takes a long time to get heartbeat success,"Hi,

I've deployed the OMS Agent dameonset to a k8 cluster and configured with the correct OMS Id and key, after following this [OMS Agent setup](https://github.com/kubernetes/examples/tree/master/staging/oms)

`omsagent-f35cw                          1/1       Running   0          15m       10.244.0.189   k8s-agentpool1-41733846-0`
`omsagent-v9dr1                          1/1       Running   0          18m       10.244.1.10    k8s-master-41733846-0`

After deploying the pod running in the k8 agentpool1 takes around 1h to get a successful heartbeat:

`2017-09-07 10:44:34 +0000 [error]: Unable to resolve the IP of ‘omsagent-f35cw’: getaddrinfo: Servname not supported for ai_socktype`
`2017-09-07 10:44:34 +0000 [warn]: Failed to get the IP for omsagent-f35cw.`
`2017-09-07 11:58:21 +0000 [info]: Heartbeat success`

Sometimes ssh'ing into the cluster and doing 
`docker restart k8s_omsagent_omsagent-w48t1_default_d3d99e53-9312-11e7-99dd-000d3a260024_0` 
solves the issue and the logs start to show on OMS.

Any help on what might be going on?

Thank you",closed,False,2017-09-07 13:00:28,2018-03-12 18:29:36
examples,kairen,https://github.com/kubernetes/examples/issues/93,https://api.github.com/repos/kubernetes/examples/issues/93,[Feature request] Add Ethereum private chain example,Could I add a blockchain example to run the Ethereum private chain cluster on Kubernetes? It will be like this repos [Kubereum](https://github.com/kairen/kubereum). ,closed,False,2017-09-10 17:43:53,2017-09-11 09:57:20
examples,Lion-Wei,https://github.com/kubernetes/examples/pull/94,https://api.github.com/repos/kubernetes/examples/issues/94,fix broken link ,,closed,True,2017-09-12 11:12:34,2017-09-12 16:12:28
examples,OguzPastirmaci,https://github.com/kubernetes/examples/pull/95,https://api.github.com/repos/kubernetes/examples/issues/95,Update OMS example with the link to the latest instructions,,closed,True,2017-09-12 20:39:28,2017-09-30 23:01:32
examples,BaluDontu,https://github.com/kubernetes/examples/pull/96,https://api.github.com/repos/kubernetes/examples/issues/96,"Add ""Storage Policy Management for containers"" to vSphere docs",Add content for using Storage Policy Management for containers using vSphere Cloud Provider.,closed,True,2017-09-14 23:37:37,2017-09-18 17:02:07
examples,Pensu,https://github.com/kubernetes/examples/pull/97,https://api.github.com/repos/kubernetes/examples/issues/97,Making targets for multi-arch for cluster-dns example,This PR ensures multi-arch targets for both frontend and backend images for cluster-dns examples. ,closed,True,2017-09-19 08:25:50,2018-03-12 15:26:34
examples,php-coder,https://github.com/kubernetes/examples/pull/98,https://api.github.com/repos/kubernetes/examples/issues/98,staging/podsecuritypolicy/rbac/README.md: update paths to YAML files,"Update paths in examples to reflect the current place of the YAML files.

CC @simo5",closed,True,2017-09-20 12:59:47,2017-10-19 20:45:57
examples,php-coder,https://github.com/kubernetes/examples/pull/99,https://api.github.com/repos/kubernetes/examples/issues/99,Update privileged PSP to allow all capabilities,"kubernetes/kubernetes#51337 adds support for using `*` as a value in the `allowedCapabilities` field. This PR updates examples to use a this feature for the ""privileged"" PSP.

PTAL @pweil-
CC @simo5",closed,True,2017-09-20 13:03:05,2017-10-01 10:00:07
examples,Pensu,https://github.com/kubernetes/examples/pull/100,https://api.github.com/repos/kubernetes/examples/issues/100,Making targets for multi-arch for https-nginx example,"This PR aims to push a image for https-nginx example in gcr repo. 
It also ensures to make targets for multi-arch deployment.",closed,True,2017-09-21 07:11:41,2018-03-11 20:07:33
examples,Pensu,https://github.com/kubernetes/examples/pull/101,https://api.github.com/repos/kubernetes/examples/issues/101,Making targets for multi-arch for explorer,This PR ensures multi-arch targets for explorer example.,closed,True,2017-09-21 10:06:00,2018-03-11 20:07:33
examples,vasiliyb,https://github.com/kubernetes/examples/issues/102,https://api.github.com/repos/kubernetes/examples/issues/102,https-nginx go issue,"Following [httpd-nginx docs](https://github.com/kubernetes/examples/tree/master/staging/https-nginx)

Getting a golang error.  
```

> $ make keys secret KEY=/tmp/nginx.key CERT=/tmp/nginx.crt SECRET=/tmp/secret.json                                                      ⬡ 6.10.2 [±master ●]
# The CName used here is specific to the service specified in nginx-app.yaml.
openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /tmp/nginx.key -out /tmp/nginx.crt -subj ""/CN=nginxsvc/O=nginxsvc""
Generating a 2048 bit RSA private key
......+++
..+++
unable to write 'random state'
writing new private key to '/tmp/nginx.key'
-----
go run make_secret.go -crt /tmp/nginx.crt -key /tmp/nginx.key > /tmp/secret.json
# command-line-arguments
./make_secret.go:63: cannot use ""k8s.io/apimachinery/pkg/apis/meta/v1"".ObjectMeta literal (type ""k8s.io/apimachinery/pkg/apis/meta/v1"".ObjectMeta) as type ""k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/apis/meta/v1"".ObjectMeta in field value
./make_secret.go:69: cannot use api.Codecs.LegacyCodec(api.Registry.EnabledVersions()...) (type ""k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/runtime"".Codec) as type ""k8s.io/apimachinery/pkg/runtime"".Encoder in argument to ""k8s.io/apimachinery/pkg/runtime"".EncodeOrDie:
	""k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/runtime"".Codec does not implement ""k8s.io/apimachinery/pkg/runtime"".Encoder (wrong type for Encode method)
		have Encode(""k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/runtime"".Object, io.Writer) error
		want Encode(""k8s.io/apimachinery/pkg/runtime"".Object, io.Writer) error
./make_secret.go:69: cannot use secret (type *api.Secret) as type ""k8s.io/apimachinery/pkg/runtime"".Object in argument to ""k8s.io/apimachinery/pkg/runtime"".EncodeOrDie:
	*api.Secret does not implement ""k8s.io/apimachinery/pkg/runtime"".Object (wrong type for DeepCopyObject method)
		have DeepCopyObject() ""k8s.io/kubernetes/vendor/k8s.io/apimachinery/pkg/runtime"".Object
		want DeepCopyObject() ""k8s.io/apimachinery/pkg/runtime"".Object
make: *** [secret] Error 2
```",closed,False,2017-09-22 04:12:43,2018-03-11 21:08:38
examples,wchao1241,https://github.com/kubernetes/examples/issues/103,https://api.github.com/repos/kubernetes/examples/issues/103,redis-sentinel didn't completed the election,"After execute “kubectl delete pods redis-master”
kubectl logs -f redis-sentinel：
12:X 26 Sep 01:10:02.266 # +monitor master mymaster 172.17.109.163 6379 quorum 2
12:X 26 Sep 01:10:02.267 * +slave slave 192.168.250.49:6379 192.168.250.49 6379 @ mymaster 172.17.109.163 6379
12:X 26 Sep 01:10:03.401 * +sentinel sentinel 489c70f345a51146d384a39830b0b7c069605f59 172.17.109.145 26379 @ mymaster 172.17.109.163 6379
12:X 26 Sep 01:10:03.742 * +sentinel sentinel aa7ee4d01c938fca50204f49e3f9a2a8dd73b537 172.17.109.163 26379 @ mymaster 172.17.109.163 6379
12:X 26 Sep 01:10:05.243 * +sentinel sentinel 5f5328394e1ba2ddbe002d2b3d35cc244a4b16f6 172.17.109.110 26379 @ mymaster 172.17.109.163 6379
12:X 26 Sep 01:11:02.337 # +sdown slave 192.168.250.49:6379 192.168.250.49 6379 @ mymaster 172.17.109.163 6379
12:X 26 Sep 01:12:44.216 # +sdown master mymaster 172.17.109.163 6379
12:X 26 Sep 01:12:44.217 # +sdown sentinel aa7ee4d01c938fca50204f49e3f9a2a8dd73b537 172.17.109.163 26379 @ mymaster 172.17.109.163 6379
12:X 26 Sep 01:12:44.367 # +new-epoch 1
12:X 26 Sep 01:12:44.420 # +vote-for-leader 489c70f345a51146d384a39830b0b7c069605f59 1
12:X 26 Sep 01:12:45.296 # +odown master mymaster 172.17.109.163 6379 #quorum 3/2
12:X 26 Sep 01:12:45.296 # Next failover delay: I will not start a failover before Tue Sep 26 01:18:44 2017
12:X 26 Sep 01:18:44.691 # +new-epoch 2
12:X 26 Sep 01:18:44.691 # +try-failover master mymaster 172.17.109.163 6379
12:X 26 Sep 01:18:44.733 # +vote-for-leader 67c6de61fc6be502e9fd0b2ae1be056ddc192aea 2
12:X 26 Sep 01:18:44.822 # 489c70f345a51146d384a39830b0b7c069605f59 voted for 67c6de61fc6be502e9fd0b2ae1be056ddc192aea 2
12:X 26 Sep 01:18:44.840 # 5f5328394e1ba2ddbe002d2b3d35cc244a4b16f6 voted for 67c6de61fc6be502e9fd0b2ae1be056ddc192aea 2
12:X 26 Sep 01:18:44.850 # +elected-leader master mymaster 172.17.109.163 6379
12:X 26 Sep 01:18:44.850 # +failover-state-select-slave master mymaster 172.17.109.163 6379
12:X 26 Sep 01:18:44.914 # -failover-abort-no-good-slave master mymaster 172.17.109.163 6379
12:X 26 Sep 01:18:44.985 # Next failover delay: I will not start a failover before Tue Sep 26 01:24:45 2017
12:X 26 Sep 01:24:45.127 # +new-epoch 3
12:X 26 Sep 01:24:45.187 # +vote-for-leader 489c70f345a51146d384a39830b0b7c069605f59 3
12:X 26 Sep 01:24:45.187 # Next failover delay: I will not start a failover before Tue Sep 26 01:30:45 2017

kubectl logs -f redis-td4wq：
14:S 26 Sep 01:24:57.030 * MASTER <-> SLAVE sync started
14:S 26 Sep 01:25:58.153 # Timeout connecting to the MASTER...
14:S 26 Sep 01:25:58.153 * Connecting to MASTER 172.17.109.163:6379
14:S 26 Sep 01:25:58.153 * MASTER <-> SLAVE sync started

redis-sentinel didn't  completed the election",closed,False,2017-09-26 01:36:13,2018-05-11 05:50:19
examples,warent,https://github.com/kubernetes/examples/issues/104,https://api.github.com/repos/kubernetes/examples/issues/104,Guestbook tutorial doesn't work,"https://kubernetes.io/docs/tutorials/stateless-application/guestbook/

Following the guestbook tutorial line for line results in the following error:
```
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'php_network_getaddresses: getaddrinfo failed: Name or service not known [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:168
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(97): Predis\Connection\AbstractConnection-&gt;onConnectionError('php_network_get...', 0)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(58): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#2 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(94): Predis\Connection\StreamConnection-&gt;createResource()
#3 /usr/local/lib/php/Predis/Connection/StreamConnection.php(158): Predis\Connection\AbstractConnection-&gt;connect()
#4 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(193): Predis\Connection\StreamConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/StreamConnection.php(184): Predis\Connection\AbstractConnection-&gt;getResour in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>168</b><br />
```",closed,False,2017-09-29 02:45:08,2017-09-29 02:51:10
examples,meshfields,https://github.com/kubernetes/examples/issues/105,https://api.github.com/repos/kubernetes/examples/issues/105,"HTTP 403 User ""system:serviceaccount:default:elasticsearch"" cannot get endpoints in the namespace ""default"".","Regarding: https://github.com/kubernetes/examples/tree/master/staging/elasticsearch

I get:

`Exception caught during discovery javax.ws.rs.WebApplicationException : HTTP 403 User ""system:serviceaccount:default:elasticsearch"" cannot get endpoints in the namespace ""default"".`

Full:
```
tyrion@Stephans-MBP ~/d/s/s/elastic> kubectl logs -f elastic-f7qxr
log4j:WARN No such property [maxBackupIndex] in org.apache.log4j.DailyRollingFileAppender.
log4j:WARN No such property [maxBackupIndex] in org.apache.log4j.DailyRollingFileAppender.
log4j:WARN No such property [maxBackupIndex] in org.apache.log4j.DailyRollingFileAppender.
[2017-10-02 13:26:23,995][INFO ][node                     ] [D'Ken] version[1.7.1], pid[7], build[b88f43f/2015-07-29T09:54:16Z]
[2017-10-02 13:26:23,995][INFO ][node                     ] [D'Ken] initializing ...
[2017-10-02 13:26:24,219][INFO ][plugins                  ] [D'Ken] loaded [cloud-kubernetes], sites []
[2017-10-02 13:26:24,280][INFO ][env                      ] [D'Ken] using [1] data paths, mounts [[/data (/dev/xvda9)]], net usable_space [11.6gb], net total_space [28.6gb], types [ext4]
[2017-10-02 13:26:27,985][INFO ][node                     ] [D'Ken] initialized
[2017-10-02 13:26:27,985][INFO ][node                     ] [D'Ken] starting ...
[2017-10-02 13:26:28,186][INFO ][transport                ] [D'Ken] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/10.2.6.148:9300]}
[2017-10-02 13:26:28,215][INFO ][discovery                ] [D'Ken] myesdb/EUCn0wAqQjSOUVpqrC4lZQ
[2017-10-02 13:26:30,737][WARN ][io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider] [D'Ken] Exception caught during discovery javax.ws.rs.WebApplicationException : HTTP 403 User ""system:serviceaccount:default:elasticsearch"" cannot get endpoints in the namespace ""default"".
```

I have no idea how to fix this. I did everything as on the GitHub Readme.",closed,False,2017-10-04 01:18:56,2017-10-05 07:57:30
examples,antoineco,https://github.com/kubernetes/examples/pull/106,https://api.github.com/repos/kubernetes/examples/issues/106,elasticsearch: Add Role and RoleBinding for RBAC,"Adds example Role and RoleBinding needed by [io.fabric8:elasticsearch-cloud-kubernetes](https://github.com/fabric8io/elasticsearch-cloud-kubernetes).

Fixes #105",closed,True,2017-10-04 14:19:58,2017-10-05 07:57:30
examples,atomantic,https://github.com/kubernetes/examples/issues/107,https://api.github.com/repos/kubernetes/examples/issues/107,Redis needs a service?,"I just setup redis in my cluster using this guide: https://github.com/kubernetes/examples/tree/master/staging/storage/redis#tl-dr

The only service this creates is the sentinel at port 26379.
So when connecting to redis via the application pods, should they be referecing redis-sentinel:26379, or should we be creating a second service like the following to use for our applications to connect to redis?

```
apiVersion: v1
kind: Service
metadata:
  labels:
    name: redis
    role: service
  name: redis
spec:
  ports:
    - port: 6379
      targetPort: 6379
  selector:
    name: redis
    role: master
```",closed,False,2017-10-04 22:19:24,2018-03-12 17:28:45
examples,kingdonb,https://github.com/kubernetes/examples/pull/108,https://api.github.com/repos/kubernetes/examples/issues/108,WIP: convert to a very basic Helm chart,with only one parameter (the clusterIP of the NFS service),closed,True,2017-10-08 17:12:51,2017-10-23 01:19:46
examples,pranshuverma,https://github.com/kubernetes/examples/issues/109,https://api.github.com/repos/kubernetes/examples/issues/109,Statefulset Casssandra not able to mount pvc at /cassandra_data.,"/kind bug
/sig apps
/area example

In Cassandra Statefulsets example not able to mount PVC at /cassandra_data but able to mount at say /cassandra_test location.

Getting below error in logs.
```
kubectl logs cassandra-33dl9
Starting Cassandra on 172.16.30.2
CASSANDRA_CONF_DIR /etc/cassandra
CASSANDRA_CFG /etc/cassandra/cassandra.yaml
CASSANDRA_AUTO_BOOTSTRAP true
CASSANDRA_BROADCAST_ADDRESS 172.16.30.2
CASSANDRA_BROADCAST_RPC_ADDRESS 172.16.30.2
CASSANDRA_CLUSTER_NAME 'Test Cluster'
CASSANDRA_COMPACTION_THROUGHPUT_MB_PER_SEC
CASSANDRA_CONCURRENT_COMPACTORS
CASSANDRA_CONCURRENT_READS
CASSANDRA_CONCURRENT_WRITES
CASSANDRA_COUNTER_CACHE_SIZE_IN_MB
CASSANDRA_DC
CASSANDRA_DISK_OPTIMIZATION_STRATEGY ssd
CASSANDRA_ENDPOINT_SNITCH SimpleSnitch
CASSANDRA_GC_WARN_THRESHOLD_IN_MS
CASSANDRA_INTERNODE_COMPRESSION
CASSANDRA_KEY_CACHE_SIZE_IN_MB
CASSANDRA_LISTEN_ADDRESS 172.16.30.2
CASSANDRA_LISTEN_INTERFACE
CASSANDRA_MEMTABLE_ALLOCATION_TYPE
CASSANDRA_MEMTABLE_CLEANUP_THRESHOLD
CASSANDRA_MEMTABLE_FLUSH_WRITERS
CASSANDRA_MIGRATION_WAIT 1
CASSANDRA_NUM_TOKENS 32
CASSANDRA_RACK
CASSANDRA_RING_DELAY 30000
CASSANDRA_RPC_ADDRESS 0.0.0.0
CASSANDRA_RPC_INTERFACE
CASSANDRA_SEEDS cassandra-33dl9
CASSANDRA_SEED_PROVIDER io.k8s.cassandra.KubernetesSeedProvider
changed ownership of '/etc/cassandra/cassandra-env.sh' from root to cassandra
changed ownership of '/etc/cassandra/cassandra.yaml' from root to cassandra
changed ownership of '/etc/cassandra/jvm.options' from root to cassandra
changed ownership of '/etc/cassandra/logback.xml' from root to cassandra
changed ownership of '/etc/cassandra' from root to cassandra
OpenJDK 64-Bit Server VM warning: Cannot open file /usr/local/apache-cassandra-3.9/logs/gc.log due to No such file or directory
INFO  16:46:04 Configuration location: file:/etc/cassandra/cassandra.yaml
INFO  16:46:05 Node configuration:[allocate_tokens_for_keyspace=null; authenticator=AllowAllAuthenticator; authorizer=AllowAllAuthorizer; auto_bootstrap=true; auto_snapshot=true; batch_size_fail_threshold_in_kb=50; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; broadcast_address=172.16.30.2; broadcast_rpc_address=172.16.30.2; buffer_pool_use_heap_if_exhausted=true; cas_contention_timeout_in_ms=1000; cdc_enabled=false; cdc_free_space_check_interval_ms=250; cdc_raw_directory=null; cdc_total_space_in_mb=null; client_encryption_options=<REDACTED>; cluster_name=Test Cluster; column_index_cache_size_in_kb=2; column_index_size_in_kb=64; commit_failure_policy=stop; commitlog_compression=null; commitlog_directory=/cassandra_data/commitlog; commitlog_max_compression_buffers_in_pool=3; commitlog_periodic_queue_size=-1; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_batch_window_in_ms=null; commitlog_sync_period_in_ms=10000; commitlog_total_space_in_mb=null; compaction_large_partition_warning_threshold_mb=100; compaction_throughput_mb_per_sec=16; concurrent_compactors=null; concurrent_counter_writes=32; concurrent_materialized_view_writes=32; concurrent_reads=32; concurrent_replicates=null; concurrent_writes=32; counter_cache_keys_to_save=2147483647; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; credentials_cache_max_entries=1000; credentials_update_interval_in_ms=-1; credentials_validity_in_ms=2000; cross_node_timeout=false; data_file_directories=[Ljava.lang.String;@11dc3715; disk_access_mode=auto; disk_failure_policy=stop; disk_optimization_estimate_percentile=0.95; disk_optimization_page_cross_chance=0.1; disk_optimization_strategy=ssd; dynamic_snitch=true; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; enable_scripted_user_defined_functions=false; enable_user_defined_functions=false; enable_user_defined_functions_threads=true; encryption_options=null; endpoint_snitch=SimpleSnitch; file_cache_size_in_mb=null; gc_log_threshold_in_ms=200; gc_warn_threshold_in_ms=1000; hinted_handoff_disabled_datacenters=[]; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_compression=null; hints_directory=/cassandra_data/hints; hints_flush_period_in_ms=10000; incremental_backups=false; index_interval=null; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_token=null; inter_dc_stream_throughput_outbound_megabits_per_sec=200; inter_dc_tcp_nodelay=false; internode_authenticator=null; internode_compression=all; internode_recv_buff_size_in_bytes=null; internode_send_buff_size_in_bytes=null; key_cache_keys_to_save=2147483647; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=172.16.30.2; listen_interface=null; listen_interface_prefer_ipv6=false; listen_on_broadcast_address=false; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; max_hints_file_size_in_mb=128; max_mutation_size_in_kb=null; max_streaming_retries=3; max_value_size_in_mb=256; memtable_allocation_type=heap_buffers; memtable_cleanup_threshold=null; memtable_flush_writers=1; memtable_heap_space_in_mb=null; memtable_offheap_space_in_mb=null; min_free_space_per_drive_in_mb=50; native_transport_max_concurrent_connections=-1; native_transport_max_concurrent_connections_per_ip=-1; native_transport_max_frame_size_in_mb=256; native_transport_max_threads=128; native_transport_port=9042; native_transport_port_ssl=null; num_tokens=32; otc_coalescing_strategy=TIMEHORIZON; otc_coalescing_window_us=200; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_cache_max_entries=1000; permissions_update_interval_in_ms=-1; permissions_validity_in_ms=2000; phi_convict_threshold=8.0; prepared_statements_cache_size_mb=null; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_scheduler_id=null; request_scheduler_options=null; request_timeout_in_ms=10000; role_manager=CassandraRoleManager; roles_cache_max_entries=1000; roles_update_interval_in_ms=-1; roles_validity_in_ms=2000; row_cache_class_name=org.apache.cassandra.cache.OHCProvider; row_cache_keys_to_save=2147483647; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=0.0.0.0; rpc_interface=null; rpc_interface_prefer_ipv6=false; rpc_keepalive=true; rpc_listen_backlog=50; rpc_max_threads=2147483647; rpc_min_threads=16; rpc_port=9160; rpc_recv_buff_size_in_bytes=null; rpc_send_buff_size_in_bytes=null; rpc_server_type=sync; saved_caches_directory=/cassandra_data/saved_caches; seed_provider=io.k8s.cassandra.KubernetesSeedProvider{seeds=cassandra-33dl9}; server_encryption_options=<REDACTED>; snapshot_before_compaction=false; ssl_storage_port=7001; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; start_rpc=false; storage_port=7000; stream_throughput_outbound_megabits_per_sec=200; streaming_socket_timeout_in_ms=86400000; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; thrift_prepared_statements_cache_size_mb=null; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; tracetype_query_ttl=86400; tracetype_repair_ttl=604800; transparent_data_encryption_options=org.apache.cassandra.config.TransparentDataEncryptionOptions@69930714; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; unlogged_batch_across_partitions_warn_threshold=10; user_defined_function_fail_timeout=1500; user_defined_function_warn_timeout=500; user_function_timeout_policy=die; windows_timer_interval=1; write_request_timeout_in_ms=2000]
INFO  16:46:05 DiskAccessMode 'auto' determined to be mmap, indexAccessMode is mmap
INFO  16:46:06 Global memtable on-heap threshold is enabled at 128MB
INFO  16:46:06 Global memtable off-heap threshold is enabled at 128MB
Exception (java.lang.IllegalArgumentException) encountered during startup: Out of range: 2199023255551
java.lang.IllegalArgumentException: Out of range: 2199023255551
	at com.google.common.primitives.Ints.checkedCast(Ints.java:91)
	at org.apache.cassandra.config.DatabaseDescriptor.applyConfig(DatabaseDescriptor.java:553)
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:125)
	at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:576)
	at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:730)
ERROR 16:46:06 Exception encountered during startup
java.lang.IllegalArgumentException: Out of range: 2199023255551
	at com.google.common.primitives.Ints.checkedCast(Ints.java:91) ~[guava-18.0.jar:na]
	at org.apache.cassandra.config.DatabaseDescriptor.applyConfig(DatabaseDescriptor.java:553) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.config.DatabaseDescriptor.<clinit>(DatabaseDescriptor.java:125) ~[apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:576) [apache-cassandra-3.9.jar:3.9]
	at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:730) [apache-cassandra-3.9.jar:3.9]
```

Environment Details:
```
kubectl version
Client Version: version.Info{Major:""1"", Minor:""8"", GitVersion:""v1.8.0"", GitCommit:""0b9efaeb34a2fc51ff8e4d34ad9bc6375459c4a4"", GitTreeState:""clean"", BuildDate:""2017-09-29T05:56:06Z"", GoVersion:""go1.9"", Compiler:""gc"", Platform:""darwin/amd64""}
Server Version: version.Info{Major:""1"", Minor:""5"", GitVersion:""v1.5.2"", GitCommit:""269f928217957e7126dc87e6adfa82242bfe5b1e"", GitTreeState:""clean"", BuildDate:""2017-07-03T15:31:10Z"", GoVersion:""go1.7.4"", Compiler:""gc"", Platform:""linux/amd64""}
```",closed,False,2017-10-16 17:05:38,2017-11-30 16:56:02
examples,jaytaylor,https://github.com/kubernetes/examples/pull/110,https://api.github.com/repos/kubernetes/examples/issues/110,Fixed paths in Elasticsearch production cluster README.,Fixed paths in Elasticsearch production cluster README.,closed,True,2017-10-16 20:37:02,2017-10-16 21:00:27
examples,jaytaylor,https://github.com/kubernetes/examples/issues/111,https://api.github.com/repos/kubernetes/examples/issues/111,"Elasticsearch production cluster ""403: cannot get endpoints"" errors","Following the docs for creating a [production cluster](https://github.com/kubernetes/examples/tree/master/staging/elasticsearch/production_cluster), I get the following 403 endpoints errors from the master, client, and data pod logs:

```
[2017-10-16 20:59:07,180][WARN ][io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider] [Annihilus] Exception caught during discovery javax.ws.rs.WebApplicationException : HTTP 403 User ""system:serviceaccount:default:elasticsearch"" cannot get endpoints in the namespace ""default"".
javax.ws.rs.WebApplicationException: HTTP 403 User ""system:serviceaccount:default:elasticsearch"" cannot get endpoints in the namespace ""default"".
	at io.fabric8.kubernetes.api.ExceptionResponseMapper.fromResponse(ExceptionResponseMapper.java:25)
	at io.fabric8.kubernetes.api.ExceptionResponseMapper.fromResponse(ExceptionResponseMapper.java:16)
	at org.apache.cxf.jaxrs.client.ClientProxyImpl.checkResponse(ClientProxyImpl.java:302)
	at org.apache.cxf.jaxrs.client.ClientProxyImpl.handleResponse(ClientProxyImpl.java:725)
	at org.apache.cxf.jaxrs.client.ClientProxyImpl.doChainedInvocation(ClientProxyImpl.java:683)
	at org.apache.cxf.jaxrs.client.ClientProxyImpl.invoke(ClientProxyImpl.java:224)
	at com.sun.proxy.$Proxy29.endpointsForService(Unknown Source)
	at io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider.getNodesFromKubernetesSelector(K8sUnicastHostsProvider.java:123)
	at io.fabric8.elasticsearch.discovery.k8s.K8sUnicastHostsProvider.buildDynamicNodes(K8sUnicastHostsProvider.java:106)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.sendPings(UnicastZenPing.java:313)
	at org.elasticsearch.discovery.zen.ping.unicast.UnicastZenPing.ping(UnicastZenPing.java:219)
	at org.elasticsearch.discovery.zen.ping.ZenPingService.ping(ZenPingService.java:146)
	at org.elasticsearch.discovery.zen.ping.ZenPingService.pingAndWait(ZenPingService.java:124)
	at org.elasticsearch.discovery.zen.ZenDiscovery.findMaster(ZenDiscovery.java:1007)
	at org.elasticsearch.discovery.zen.ZenDiscovery.innerJoinCluster(ZenDiscovery.java:361)
	at org.elasticsearch.discovery.zen.ZenDiscovery.access$6100(ZenDiscovery.java:86)
	at org.elasticsearch.discovery.zen.ZenDiscovery$JoinThreadControl$1.run(ZenDiscovery.java:1384)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
```

This seems related to #105, but this cluster doesn't use [RBAC](https://kubernetes.io/docs/admin/authorization/rbac/). I decided to go ahead and try applying the [rbac.yaml](https://github.com/kubernetes/examples/blob/202271d18dc1387f516214d599c47155720f8ab7/staging/elasticsearch/rbac.yaml) anyways and now everything is working happily!

```
kubectl create -f staging/elasticsearch/rbac.yaml
```

```
[2017-10-16 21:04:27,542][INFO ][cluster.service          ] [X-Cutioner] detected_master [Magik][lL30c9mgShuRPZuJZXMB7Q][es-master-0blnl][inet[/10.244.1.195:9300]]{data=false, master=true}, added {[Magik][lL30c9mgShuRPZuJZXMB7Q][es-master-0blnl][inet[/10.244.1.195:9300]]{data=false, master=true},}, reason: zen-disco-receive(from master [[Magik][lL30c9mgShuRPZuJZXMB7Q][es-master-0blnl][inet[/10.244.1.195:9300]]{data=false, master=true}])
[2017-10-16 21:04:27,560][INFO ][cluster.service          ] [X-Cutioner] added {[Annihilus][7pHiQCwuSX6tD4t_TqG1Lg][es-client-6kxsj][inet[/10.244.1.196:9300]]{data=false, master=false},}, reason: zen-disco-receive(from master [[Magik][lL30c9mgShuRPZuJZXMB7Q][es-master-0blnl][inet[/10.244.1.195:9300]]{data=false, master=true}])
```

This leads me to suspect that the current production cluster example may be broken.

### Questions

1. Why does applying rbac.yaml fix the production cluster example when RBAC is not installed on the cluster?

2. Should the application of rbac.yaml be added to the production cluster example?

Thank you!
Jay",closed,False,2017-10-16 21:27:46,2018-01-23 21:22:41
examples,chenhonggc,https://github.com/kubernetes/examples/pull/112,https://api.github.com/repos/kubernetes/examples/issues/112,Modified version for .yaml,For k8s version(1.8),closed,True,2017-10-19 02:49:01,2017-10-19 10:00:22
examples,vladimirvivien,https://github.com/kubernetes/examples/pull/113,https://api.github.com/repos/kubernetes/examples/issues/113,ScaleIO update for changes to secret and namespace,"This PR documents the changes implemented to the way the ScaleIO Kubernetes volume plugin handles secret and secret namespace in PVs.

See https://github.com/kubernetes/kubernetes/pull/54013",closed,True,2017-10-19 20:21:09,2018-03-04 16:09:53
examples,fleeto,https://github.com/kubernetes/examples/issues/114,https://api.github.com/repos/kubernetes/examples/issues/114,Selenium example,"It seems that there is no geckodriver installed in the image `google/python-hello`, so the python code won't work as expected

Another image inodb/python-selenium can support the example.",closed,False,2017-10-23 06:39:57,2018-03-23 18:48:52
examples,todaywasawesome,https://github.com/kubernetes/examples/pull/115,https://api.github.com/repos/kubernetes/examples/issues/115,"Fix ""front-end"" grammar","""front-end"" only applies as an adjective to some thing like ""front-end developer"" though, ""frontend developer"" is pretty well accepted. Talking about a front end (noun) means there's no need for a hyphen. See this discussion for a full breadth of usage guideline POVs. https://english.stackexchange.com/questions/34447/is-it-front-end-frontend-or-front-end",closed,True,2017-10-24 23:31:54,2017-10-25 04:35:29
examples,php-coder,https://github.com/kubernetes/examples/pull/116,https://api.github.com/repos/kubernetes/examples/issues/116,podsecuritypolicy/rbac: update instruction,"Overhaul of the instruction that includes:
- remove `ALLOW_ANY_TOKEN=true` that doesn't exist
- remove `ENABLE_RBAC=true` that doesn't exist (and enabled by default)
- remove `RUNTIME_CONFIG=""extensions/v1beta1=true,extensions/v1beta1/podsecuritypolicy=true""` as it's enabled by default
- mention that `local-up-cluster.sh` creates PSP policies, roles, and binding by default
- fix names of the roles, policies, and bindings
- mention about the latest changes that affects PSPs ordering

Fixes https://github.com/kubernetes/examples/issues/37

PTAL @liggitt @pweil- @tallclair 
CC @simo5",closed,True,2017-10-25 17:40:40,2017-11-27 21:46:06
examples,zouyee,https://github.com/kubernetes/examples/pull/117,https://api.github.com/repos/kubernetes/examples/issues/117,Update storage to v1,Update storage to v1,closed,True,2017-10-26 07:24:19,2017-10-27 04:13:38
examples,zouyee,https://github.com/kubernetes/examples/pull/118,https://api.github.com/repos/kubernetes/examples/issues/118,sync from kubernetes/kubernetes,"/cc @ahmetb
ref https://github.com/kubernetes/kubernetes/pull/54577",closed,True,2017-10-27 05:01:12,2017-10-30 02:53:59
examples,zouyee,https://github.com/kubernetes/examples/pull/119,https://api.github.com/repos/kubernetes/examples/issues/119,[staging/storage.vitess]update youtube/vitess/example/kubernetes,"sync from youtube/vitess/example/kubernetes
/cc @ahmetb",closed,True,2017-10-28 09:08:18,2017-12-01 06:31:37
examples,zouyee,https://github.com/kubernetes/examples/pull/120,https://api.github.com/repos/kubernetes/examples/issues/120,[staging/exaplem.minio]update minio apps apigroupversion,/cc @ahmetb PTAL,closed,True,2017-10-28 13:06:36,2017-11-02 03:37:51
examples,zouyee,https://github.com/kubernetes/examples/pull/121,https://api.github.com/repos/kubernetes/examples/issues/121,[guestbook]update guestbook apps apigroupversion,,closed,True,2017-10-28 15:49:00,2017-10-30 07:50:15
examples,zouyee,https://github.com/kubernetes/examples/pull/122,https://api.github.com/repos/kubernetes/examples/issues/122,[staging/elasticsearch] update rbac apiversion,,closed,True,2017-10-28 16:02:41,2017-10-30 07:56:44
examples,zouyee,https://github.com/kubernetes/examples/pull/123,https://api.github.com/repos/kubernetes/examples/issues/123,[staging/newrelic-infrastructure]move newrelic-infrastructure from k8s core repo,"move newrelic-infrastructure from k8s core repo
 @roberthbailey PTAL",closed,True,2017-10-28 16:03:11,2017-12-01 06:31:50
examples,zouyee,https://github.com/kubernetes/examples/pull/124,https://api.github.com/repos/kubernetes/examples/issues/124,[staging/storageos] move storageos to examples,@ahmetb PTAL,closed,True,2017-10-28 16:43:46,2018-03-06 01:34:24
examples,zouyee,https://github.com/kubernetes/examples/pull/125,https://api.github.com/repos/kubernetes/examples/issues/125,[staging/storage.hazelcast]Update hazelcast-deployment apiversion,Update hazelcast-deployment.yaml,closed,True,2017-10-28 17:17:06,2017-10-30 07:56:20
examples,zouyee,https://github.com/kubernetes/examples/pull/126,https://api.github.com/repos/kubernetes/examples/issues/126,[staging/cloud-controller-manager] move cloud-controller-manager to ex,move cloud-controller-manager to examples,closed,True,2017-10-28 17:18:07,2017-12-01 06:32:10
examples,zouyee,https://github.com/kubernetes/examples/pull/127,https://api.github.com/repos/kubernetes/examples/issues/127,[staging/cpu-manager] move cpu-mnagaer to examples,move cpu-mnagaer to examples,closed,True,2017-10-28 17:18:28,2017-12-01 06:32:31
examples,zouyee,https://github.com/kubernetes/examples/pull/128,https://api.github.com/repos/kubernetes/examples/issues/128,[staging/newrelic]update daemonset apiversion,,closed,True,2017-10-28 17:52:57,2017-10-30 07:54:25
examples,zouyee,https://github.com/kubernetes/examples/pull/129,https://api.github.com/repos/kubernetes/examples/issues/129,[staging/openshift-origin]update deploy apiversion,,closed,True,2017-10-28 17:55:40,2017-10-30 07:54:54
examples,zouyee,https://github.com/kubernetes/examples/pull/130,https://api.github.com/repos/kubernetes/examples/issues/130,[staging/podssecuritypolicy]update rbac apiversion,,closed,True,2017-10-28 18:02:08,2017-10-30 07:54:05
examples,zouyee,https://github.com/kubernetes/examples/pull/131,https://api.github.com/repos/kubernetes/examples/issues/131,[staging/sysdig-cloud]update apps apiversion,/assgin @roberthbailey,closed,True,2017-10-28 18:02:58,2017-10-30 07:53:31
examples,fatg1988,https://github.com/kubernetes/examples/issues/132,https://api.github.com/repos/kubernetes/examples/issues/132,elasticsearch: No up-and-running site-local (private) addresses found,"k8s 1.6.4
flannel


 [2017-10-30T09:35:24,499][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [397f514e-3be8-4d89-9256-f1f215d0dbd8] uncaught exception in thread [main]
org.elasticsearch.bootstrap.StartupException: java.lang.IllegalArgumentException: No up-and-running site-local (private) addresses found, got [name:lo (lo), name:eth0 (eth0)]
	at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:136) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:123) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:67) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:134) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.cli.Command.main(Command.java:90) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:91) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:84) ~[elasticsearch-5.6.2.jar:5.6.2]
Caused by: java.lang.IllegalArgumentException: No up-and-running site-local (private) addresses found, got [name:lo (lo), name:eth0 (eth0)]
	at org.elasticsearch.common.network.NetworkUtils.getSiteLocalAddresses(NetworkUtils.java:187) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.common.network.NetworkService.resolveInternal(NetworkService.java:246) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.common.network.NetworkService.resolveInetAddresses(NetworkService.java:220) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.common.network.NetworkService.resolveBindHostAddresses(NetworkService.java:130) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.transport.TcpTransport.bindServer(TcpTransport.java:720) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.transport.netty4.Netty4Transport.doStart(Netty4Transport.java:173) ~[?:?]
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:69) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.transport.TransportService.doStart(TransportService.java:209) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:69) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.node.Node.start(Node.java:694) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:278) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:351) ~[elasticsearch-5.6.2.jar:5.6.2]
	at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:132) ~[elasticsearch-5.6.2.jar:5.6.2]",closed,False,2017-10-30 10:02:47,2018-03-29 20:11:52
examples,RochesterinNYC,https://github.com/kubernetes/examples/pull/133,https://api.github.com/repos/kubernetes/examples/issues/133,[staging/elasticsearch] Fix README.md broken links,- Fixes broken links and images ,closed,True,2017-10-30 21:29:24,2017-10-31 17:29:45
examples,cookingcodewithme,https://github.com/kubernetes/examples/pull/134,https://api.github.com/repos/kubernetes/examples/issues/134,[staging/storage/redis] update scripts for redis to be able to use statefulset.,"update run.sh for improving reliability and performance.
- Disabling AOF and SAVE will improve performance of redis on k8s. 
- AOF and SAVE will be disabled if volumeMounts(redis-master-data) is not defined.
- AOF and SAVE can be manually turn on and off thru env variables.
- StatefulSet is an easy way to setup redis-sentinel test environment on k8s.
- Restarted master node will be a slave node properly with StatefulSet.
",closed,True,2017-10-31 06:29:50,2018-04-01 07:09:50
examples,bottkars,https://github.com/kubernetes/examples/pull/135,https://api.github.com/repos/kubernetes/examples/issues/135,changed errata in Thin / Thick provisionned,,closed,True,2017-10-31 08:52:50,2017-10-31 17:30:49
examples,ahmetb,https://github.com/kubernetes/examples/pull/136,https://api.github.com/repos/kubernetes/examples/issues/136,delete kubectl-container,"This is not an example and was here when we were releasing the
gcr.io/google_containers/kubectl image actively (stopped doing that in 2015).
This is now unused and does not work, therefore removing.

/cc @sebgoa",closed,True,2017-11-09 00:46:04,2017-12-20 08:17:30
examples,ahmetb,https://github.com/kubernetes/examples/issues/137,https://api.github.com/repos/kubernetes/examples/issues/137,Enable OWNERS enforcement for this repository,"We should probably start using the OWNERS file.

/cc @sebgoa  
do you know how we can enable this?",closed,False,2017-11-09 03:11:55,2018-05-28 11:47:29
examples,jhvhs,https://github.com/kubernetes/examples/pull/138,https://api.github.com/repos/kubernetes/examples/issues/138,Improve guestbook usability,Clear the input box after successful entry submission.,closed,True,2017-11-14 00:16:25,2019-03-20 15:27:37
examples,zhangzikang1992,https://github.com/kubernetes/examples/issues/139,https://api.github.com/repos/kubernetes/examples/issues/139,when create examples redis cluster ,"hi，when i create redis cluster use step like this:

kubectl scale rc redis --replicas=3
kubectl scale rc redis-sentinel --replicas=3
This will create two additional replicas of the redis server and two additional replicas of the redis sentinel.

but it  create two additional replicas of the redis server and three additional replicas of the redis sentinel.",closed,False,2017-11-15 10:07:14,2018-03-16 01:29:24
examples,chenhonggc,https://github.com/kubernetes/examples/pull/140,https://api.github.com/repos/kubernetes/examples/issues/140,fix some invalid links,I think some links of concepts are invalid.,closed,True,2017-11-17 08:35:48,2017-11-17 19:47:01
examples,myguddy,https://github.com/kubernetes/examples/issues/141,https://api.github.com/repos/kubernetes/examples/issues/141,How to access mysql(statefulsets) from outside of cluster,"Hi Thanks for ur sharing info.

Is there any way to access to mysql from outside of cluster?
For developers, they need to access mysql directly for design and debugging.

I tried port-forward and using sql workbench on 3306 client port only, 
unfortunately it doesn't work well.

Please give me an idea to support developers.
Thanks in advance.

For your Info

This is my yaml on working on
=============================
```
#
# MariaDB 10.1 Galera Cluster
#
apiVersion: v1
kind: Service
metadata:
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: ""true""
  name: galera
  labels:
    app: mysql
spec:
  ports:
  - port: 3306
    name: mysql
  clusterIP: None
  selector:
    app: mysql
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: mysql-config-vol
data:
  galera.cnf: |
    [galera]
    user = mysql
    bind-address = 0.0.0.0

    default_storage_engine = InnoDB
    binlog_format = ROW
    innodb_autoinc_lock_mode = 2
    innodb_flush_log_at_trx_commit = 0
    query_cache_size = 0
    query_cache_type = 0

    # MariaDB Galera settings
    wsrep_on=ON
    wsrep_provider=/usr/lib/galera/libgalera_smm.so
    wsrep_sst_method=rsync

    # Cluster settings (automatically updated)
    wsrep_cluster_address=gcomm://
    wsrep_cluster_name=galera
    wsrep_node_address=127.0.0.1
  mariadb.cnf: |
    [client]
    default-character-set = utf8
    [mysqld]
    character-set-server  = utf8
    collation-server      = utf8_general_ci
    # InnoDB tuning
    innodb_log_file_size  = 50M
---
apiVersion: apps/v1beta1
kind: StatefulSet
metadata:
  name: mysql
spec:
  serviceName: ""galera""
  replicas: 3
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
      - name: mysql
        image: ausov/k8s-mariadb-cluster
        ports:
        - containerPort: 3306
          name: mysql
        - containerPort: 4444
          name: sst
        - containerPort: 4567
          name: replication
        - containerPort: 4568
          name: ist
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
        - name: MYSQL_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysql
              key: password
        readinessProbe:
          exec:
            command: [""bash"", ""-c"", ""mysql -uroot -p\""${MYSQL_ROOT_PASSWORD}\"" -e 'show databases;'""]
          initialDelaySeconds: 20
          timeoutSeconds: 5
        volumeMounts:
        - name: config
          mountPath: /etc/mysql/conf.d
        - name: datadir
          mountPath: /var/lib/mysql
      volumes:
      - name: config
        configMap:
          name: mysql-config-vol
          items:
            - path: ""galera.cnf""
              key: galera.cnf
            - path: ""mariadb.cnf""
              key: mariadb.cnf
  volumeClaimTemplates:
  - metadata:
      name: datadir
    spec:
      accessModes: [ ""ReadWriteOnce"" ]
      resources:
        requests:
          storage: 2Gi
```
",closed,False,2017-11-20 13:40:51,2018-04-19 14:50:53
examples,apupier,https://github.com/kubernetes/examples/pull/142,https://api.github.com/repos/kubernetes/examples/issues/142,Remove unused Java import package,Signed-off-by: Aurélien Pupier <apupier@redhat.com>,closed,True,2017-11-21 16:31:27,2018-02-21 08:01:28
examples,apupier,https://github.com/kubernetes/examples/pull/143,https://api.github.com/repos/kubernetes/examples/issues/143,Provide xsd configuration for pom files,"it allows to provide completion and validation when editing the files in
most IDEs

Signed-off-by: Aurélien Pupier <apupier@redhat.com>",closed,True,2017-11-21 16:45:46,2018-02-20 07:00:41
examples,joshlemer,https://github.com/kubernetes/examples/issues/144,https://api.github.com/repos/kubernetes/examples/issues/144,Broken Link in Spark Readme,"The [Spark example](https://github.com/kubernetes/examples/blob/master/staging/spark/README.md#step-two-start-your-master-service ) tutorial contains a link in the ""Start your Master Service"" section"" which points to [here](https://github.com/kubernetes/examples/blob/master/docs/user-guide/replication-controller.md), titled ""replication controller"", but the link is now dead.",closed,False,2017-11-21 21:18:59,2018-03-22 14:53:29
examples,like-inspur,https://github.com/kubernetes/examples/issues/145,https://api.github.com/repos/kubernetes/examples/issues/145,ceph rbd support multi storageclass,"I test pod mount volume through pvc on storageclass ceph must exist in the same namespace with secret. Now I want mutil namespace environment, so each namespace need to create its own storageclass.
kubectl create ns like
ceph osd pool create like 128
ceph auth get-or-create client.like mon 'allow r' osd 'allow class-read object_prefix rbd_children, allow rwx pool=like'
I creaet ceph-secret-like in namespace like and storageclass ceph-like use pool like and secret ceph-secret-like
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: ceph-like
provisioner: kubernetes.io/rbd
parameters:
  monitors: 10.110.17.56:6789,10.110.17.57:6789,10.110.17.58:6789
  adminId: admin
  adminSecretName: ceph-secret
  adminSecretNamespace: default
  pool: like
  userId: like
  userSecretName: ceph-secret-like
  imageFormat: ""1""
When I create pvc in namespace like，its status is pending, and log show like this:
  Warning  ProvisioningFailed  3m (x17 over 7m)  persistentvolume-controller  (combined from similar events): Failed to provision volume with StorageClass ""ceph-like"": failed to create rbd image: exit status 1, command output: 2017-11-24 03:08:55.020934 7fe5c270d780 -1 did not load config file, using default settings.
2017-11-24 03:08:55.032621 7fe5c270d780  0 librados: client.admin authentication error (1) Operation not permitted
rbd: couldn't connect to the cluster!",closed,False,2017-11-24 03:13:06,2018-04-23 05:15:50
examples,monotek,https://github.com/kubernetes/examples/issues/146,https://api.github.com/repos/kubernetes/examples/issues/146,Flocker example is deprecated as flocker does not exists anymore,"The Website (https://clusterhq.com/flocker) linked in the Readme (https://github.com/kubernetes/examples/blob/master/staging/volumes/flocker/README.md) does not exist anymore.

Reason: https://techcrunch.com/2016/12/22/clusterhq-hits-the-deadpool/

Imho the example can be removed, as its obsolete.",closed,False,2017-11-24 13:40:51,2018-04-24 18:52:52
examples,VinceMD,https://github.com/kubernetes/examples/issues/147,https://api.github.com/repos/kubernetes/examples/issues/147,Cassandra: example does not use KubernetesSeedProvider while doc says it does,"From the Kubernetes documentation (https://kubernetes.io/docs/tutorials/stateful-application/cassandra/), we can read this statement:

` In this instance, a custom Cassandra SeedProvider enables Cassandra to discover new Cassandra nodes as they join the cluster.`

However the example does not seem to use the KubernetesSeedProvider.

On the KubernetesSeedProvider Readme:

` This provider is bundled with the Docker provided in this example.`

Therefore I set the environment variable as follow in the statefulset.yaml, to try to force it to use KubernetesSeedProvider:

`          - name: CASSANDRA_SEED_PROVIDER
            value: ""org.apache.cassandra.locator.KubernetesSeedProvider""`

I got this error:

`java.lang.ClassNotFoundException: org.apache.cassandra.locator.KubernetesSeedProvider`

Can we either fix the documentation or fix the code so that it uses the KubernetesSeedProvider? Seems we are not making use of it",closed,False,2017-11-27 02:34:12,2018-04-12 16:26:56
examples,BishoyDemian,https://github.com/kubernetes/examples/issues/148,https://api.github.com/repos/kubernetes/examples/issues/148,Examples of how to use azure managed disk volumes without PVC,Currently the documentation for using azure managed disks only show how to configure the volume using a PVC. But I need to understand the other scenario of directly configuring a volume in the POD or ReplicaSet yaml file.,closed,False,2017-11-28 02:45:27,2018-04-27 04:49:06
examples,VinceMD,https://github.com/kubernetes/examples/issues/149,https://api.github.com/repos/kubernetes/examples/issues/149,Cassandra: statefulset and volume constraint prevents Cassandra pods from healing,"Running Cassandra in AWS but I imagine the same applies elsewhere (Kubernetes 1.7.4). Consider:

3 Cassandra nodes as defined by the Statefulset.

- cassandra-0 is in AZ ""a""
- cassandra-1 is in AZ ""b""
- cassandra-2 is in AZ ""c""

AZ stands for a Availability Zone (same as Google Zone I heard). It's like a rack (although we don't have Kubernetes Cassandra snitch so for Cassandra it looks like everything is in one rack)

I shutdown all Kubernetes nodes in AZ ""a"" and prevent creating new nodes in AZ ""a""
Therefore cassandra-0 cannot start as its EBS Volume (PV) is tight to the AZ ""a"".

This simulates 1 Availability Zone (zone) down. 

During this time cassandra-2 fails and needs to be restarted elsewhere. 
A statefulset won't self-heal cassandra-2 and also prevents creating further cassandra-3,  cassandra-4, etc.
If we also loose cassandra-1 (maybe the host is gone because of AWS/Cloud autoscaling), then we have no Cassandra node left. The more time the first zone is down, the more we risk having to re-create the other Cassandra nodes (infra is elastic and hosts can go wrong), which is not working unless AZ ""a"" goes back online. For a 30minutes outage of AZ ""a"", it will be fine. But then the clock is ticking...

From Statefulset doc:
""Before a scaling operation is applied to a Pod, all of its predecessors must be Running and Ready.""

Some questions

- Is that expected behaviour?
- shouldn't we allow Cassandra to scale nodes in other AZ even if the first one is down?
- Is Statefulset the right choice then? would deployment + replica work better? (as far as I know we need the seeds to start first, thereafter we don't care about the order).
- Should we use 3 statefulset (1 per zone/rack) joining the same cluster? How to do that? How do Cassandra node recognise they are in the same cluster? Is there any issue with this approach?

",closed,False,2017-11-28 05:08:14,2018-05-04 17:47:05
examples,abrarshivani,https://github.com/kubernetes/examples/pull/150,https://api.github.com/repos/kubernetes/examples/issues/150,Fix link for pod yaml in vSphere Volumes README,"This PR fixes the link in vSphere Volumes README file for pod yaml and also adds the yaml file.
Fixes https://github.com/vmware/kubernetes/issues/342

//cc @divyenpatel 
",closed,True,2017-11-28 05:15:03,2017-11-30 20:09:42
examples,howinator,https://github.com/kubernetes/examples/pull/151,https://api.github.com/repos/kubernetes/examples/issues/151,Fix syntax highlighting of YAML in java side car,"Github supports YAML syntax highlighting.
This PR adds that formatting to the code blocks in the Java side car
example.",closed,True,2017-11-28 17:25:41,2017-11-28 19:02:14
examples,Arnold1,https://github.com/kubernetes/examples/issues/152,https://api.github.com/repos/kubernetes/examples/issues/152,issue with spark-ui-proxy,"Hi,

I followed all steps until Step 2:
```
$ kubectl create -f staging/spark/spark-ui-proxy-controller.yaml
replicationcontroller ""spark-ui-proxy-controller"" created

$ kubectl create -f staging/spark/spark-ui-proxy-service.yaml
service ""spark-ui-proxy"" created

$ kubectl get svc spark-ui-proxy -o wide
NAME             TYPE           CLUSTER-IP   EXTERNAL-IP   PORT(S)        AGE       SELECTOR
spark-ui-proxy   LoadBalancer   10.0.0.38    <pending>     80:31945/TCP   9m        component=spark-ui-proxy
```

i dont get the external IP, why is that? i waited 10 min between spark-ui-proxy and kubectl get svc spark-ui-proxy -o wide...",closed,False,2017-11-30 22:12:38,2018-07-31 05:05:27
examples,rbtcollins,https://github.com/kubernetes/examples/issues/153,https://api.github.com/repos/kubernetes/examples/issues/153,Cassandra image v12 still has Cassandra 3.9,"Running `nodetool version` against gcr.io/google-samples/cassandra:v12 gets me ```
nodetool version
ReleaseVersion: 3.9
```

I'm wondering if perhaps a bad build was put up and then it hasn't been refreshed?",closed,False,2017-11-30 22:14:46,2018-02-21 02:35:29
examples,abonillasuse,https://github.com/kubernetes/examples/issues/154,https://api.github.com/repos/kubernetes/examples/issues/154,pv doc additional text,"is this correct?
--from-literal=key=

https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning

might there be an additional key= or is that expected?",closed,False,2017-12-04 23:55:41,2017-12-04 23:56:56
examples,dahaian,https://github.com/kubernetes/examples/issues/155,https://api.github.com/repos/kubernetes/examples/issues/155,How to setup a hadoop cluster in a kubernetes cluster?,"I would like to setup a hadoop cluster in a kubernetes cluster.There are 4 nodes for kubernetes cluster.
I create a pod for hadoop master in a kubernetes cluster node.And I create three pods for hadoop slaves in the other 3 nodes.I have to do that all the pods in a intranet each other.I want to do that multiple pods in different nodes in a intranet. What should I do?Any help is appreciated!",closed,False,2017-12-06 09:19:57,2017-12-07 23:03:29
examples,chanchikwan,https://github.com/kubernetes/examples/pull/156,https://api.github.com/repos/kubernetes/examples/issues/156,Minor typesetting fix,,closed,True,2017-12-08 23:20:59,2018-02-07 17:54:56
examples,bainim,https://github.com/kubernetes/examples/issues/157,https://api.github.com/repos/kubernetes/examples/issues/157,How can I customize elasticsearch.yaml,"Hello every one ,
i'm working on kubernetes and elasticsearch
i followed this link :https://github.com/kubernetes/examples/tree/master/staging/elasticsearch
what i want is to add a volume to be like this on :
folder_path/config/elasticsearch.yml:/root/config/elasticsearch.yml",closed,False,2017-12-12 07:47:31,2017-12-12 08:13:06
examples,toddysm,https://github.com/kubernetes/examples/issues/158,https://api.github.com/repos/kubernetes/examples/issues/158,Using the Azure Disk example with AKS results in PersistentVolumeClaim is not bound,"We are trying the Azure Disk example on Azure Managed Kubernetes and it fails with `PersistentVolumeClaim is not bound`
Also, it is not clear from the example documentation what storage account and what credentials are used by the Kubernetes cluster to create the disk.",closed,False,2017-12-13 01:49:16,2018-08-09 03:35:02
examples,pashok2398,https://github.com/kubernetes/examples/pull/159,https://api.github.com/repos/kubernetes/examples/issues/159,Fix yaml path based on the new location,,closed,True,2017-12-13 12:26:47,2017-12-18 07:13:07
examples,kovyrin,https://github.com/kubernetes/examples/pull/160,https://api.github.com/repos/kubernetes/examples/issues/160,Small typo fix,Trivial typo fix in a README.,closed,True,2017-12-17 14:52:22,2018-02-07 18:12:42
examples,spiffxp,https://github.com/kubernetes/examples/pull/161,https://api.github.com/repos/kubernetes/examples/issues/161,Add code-of-conduct.md,"Refer to kubernetes/community as authoritative source for code of conduct

ref: kubernetes/community#1527",closed,True,2017-12-20 18:32:04,2018-01-04 16:42:43
examples,adrianRiobo,https://github.com/kubernetes/examples/issues/162,https://api.github.com/repos/kubernetes/examples/issues/162,Location not ignored for kubernetes.io/azure-disk,"Accordint to [azure-disk provisioner](https://github.com/kubernetes/examples/tree/master/staging/persistent-volume-provisioning#azure-disk)

If storage account is provided (same resource group as the cluster) location should be ignored but creating a storage class like this:

``
kind: StorageClass 
``
``
apiVersion: storage.k8s.io/v1
``
``
metadata:
``
  ``
      name: azuredisk-low
  ``
``
provisioner: kubernetes.io/azure-disk
``
``
parameters:
``
``
  storageAccount: my-account (same rg as acs)
``

And a persistent volume claim using this storage class:

``
kind: PersistentVolumeClaim
``
``
apiVersion: v1
``
``
metadata:
``
``
  name: volume-claim-name
``
``
  namespace: my-namespace
``
``
  annotations:
``
``
    volume.beta.kubernetes.io/storage-class: azuredisk-low
``
``
spec:
``
``
  accessModes:
``
``
    - ReadWriteOnce
``
``
  resources:
``
``
    requests:
``
``
      storage: 5Gi
``

Persistent volume claim fails with:

> Failed to provision volume with StorageClass ""azuredisk-low"": AzureDisk - location() and account(my-account) must be both empty or specified for dedicated kind, only one value specified is not allowed",closed,False,2017-12-21 12:01:31,2018-05-20 15:01:10
examples,thockin,https://github.com/kubernetes/examples/pull/163,https://api.github.com/repos/kubernetes/examples/issues/163,Convert registry to k8s.gcr.io,"This PR was auto-generated.  Please apply human expertise to review for correctness.

Followup to https://github.com/kubernetes/kubernetes/pull/54174

xref https://github.com/kubernetes/release/issues/281",closed,True,2017-12-22 18:00:55,2017-12-23 18:22:36
examples,huxiaoliang,https://github.com/kubernetes/examples/pull/164,https://api.github.com/repos/kubernetes/examples/issues/164,Improve k8s DNS example usability,"the command in example should be straightforward asap, user just
do copy and paste to move on. This change is align with spark
example to set CLUSTER_NAME and USER_NAME, refer to below link for
the defails:

https://github.com/kubernetes/examples/tree/master/staging/spark",closed,True,2017-12-25 08:23:11,2018-01-31 06:19:21
examples,BezVezeE,https://github.com/kubernetes/examples/issues/165,https://api.github.com/repos/kubernetes/examples/issues/165,Redis: READONLY You can't write against a read only slave.,"Hi, can someone help me with a problem on the redis cluster, 

for example i use google cloud and i have created the redis cluster with the redis sentinel svc, also deleted the master pod an recreated again by it self, (as told in the example) 

but can someone have any idea how to use this cluster,

i created a internal loadbalancer svc 

```
apiVersion: v1
kind: Service
metadata:
  name: redis-loadbalancer
  annotations:
    cloud.google.com/load-balancer-type: ""Internal""
  labels:
    name: redis
spec:
  type: LoadBalancer
  loadBalancerIP:
  ports:
  - port: 6379
    protocol: TCP
  selector:
    name: redis
```

and the good thing is i can connect to the cluster  
but when i try to insert some data it gives me an error

```
redis-cli -h 10.128.0.11 -p 6379
10.128.0.11:6379> set test test
(error) READONLY You can't write against a read only slave.
10.128.0.11:6379> 
```",closed,False,2017-12-28 13:31:50,2018-07-13 22:18:13
examples,barbarosalp,https://github.com/kubernetes/examples/issues/166,https://api.github.com/repos/kubernetes/examples/issues/166,Redis Example: Which host to use as Sentinel IP?,"https://github.com/kubernetes/examples/tree/master/staging/storage/redis

I am following the example above, but something I couldn't understand which I am confused.
We create a redis-sentinel service but without type=NodePort so this service is not open to outside world. Is it because of the redis sentinel non-authentication to keep it internal ?

When I try the ""redis-sentinel""'s ClusterIp (which is the default type for a service) It works!
Is this the standard way to do this?

What if the clusterIP changes during scaling or something happened that changes the clusterIp, what should I do? 

For live scenario, there will be a DNS so it won't be an issue but for local development environment every time I restart the PC, I got a new IP address, with this the clusterIP also changes and I need to update the code to connect the new redis-sentinel cluster IP.

```
    try:
        sentinel = Sentinel([('10.100.111.64', 26379)], socket_timeout=1)
        master = sentinel.master_for('mymaster', socket_timeout=1)
        slave = sentinel.slave_for('mymaster', socket_timeout=1)
        visits = master.incr(""counter"")
    except RedisError as e:
        visits = ""<i>cannot connect to Redis, counter disabled</i>""
        print(e)
```

  ",closed,False,2018-01-03 11:26:01,2018-06-02 13:05:18
examples,misterikkit,https://github.com/kubernetes/examples/pull/167,https://api.github.com/repos/kubernetes/examples/issues/167,Update scheduler code locations,"The scheduler code was moved in [kubernetes #57852](https://github.com/kubernetes/kubernetes/pull/57852), and we should update docs do reflect the new location.

/sig scheduling
/sig docs",closed,True,2018-01-05 00:51:11,2018-02-07 17:53:19
examples,misterikkit,https://github.com/kubernetes/examples/pull/168,https://api.github.com/repos/kubernetes/examples/issues/168,Delete all BUILD files.,"As discussed in #167.

There is no CI set up for the examples repo, so BUILD files are not
needed. They can be easily regenerated in the future, and it's one less
thing to keep up to date.

/assign @ahmetb ",closed,True,2018-01-09 21:03:48,2018-01-18 23:31:57
examples,jbauza1984,https://github.com/kubernetes/examples/issues/169,https://api.github.com/repos/kubernetes/examples/issues/169,Change in redis-master.yaml,line 12 -> image: gcr.io/google-containers/redis:latest,closed,False,2018-01-10 19:00:00,2018-01-10 21:13:28
examples,humblec,https://github.com/kubernetes/examples/pull/170,https://api.github.com/repos/kubernetes/examples/issues/170,Add `volumenameprefix` storageclass parameter in GlusterFS dynamic PV provisioning example section.,"
Signed-off-by: Humble Chirammal <hchiramm@redhat.com>",closed,True,2018-01-15 07:24:10,2018-01-16 16:45:00
examples,jason-tian,https://github.com/kubernetes/examples/issues/171,https://api.github.com/repos/kubernetes/examples/issues/171,Elasticsearch example: KeyUsage does not allow digital signatures,"I followed the production_cluster to setup elasticsearch, but I get the error KeyUsage does not allow digital signatures from es-master pod logs. 
How do I fix it?",closed,False,2018-01-16 15:28:04,2018-06-15 17:15:24
examples,humblec,https://github.com/kubernetes/examples/pull/172,https://api.github.com/repos/kubernetes/examples/issues/172,Correct GlusterFS description with proper upstream URLs.,Signed-off-by: Humble Chirammal <hchiramm@redhat.com>,closed,True,2018-01-16 17:02:39,2018-01-16 17:09:33
examples,deitch,https://github.com/kubernetes/examples/issues/173,https://api.github.com/repos/kubernetes/examples/issues/173,Redis without bootstrap master and sentinel,"There are several issues with the Redis example:

* It uses a bootstrap pod for sentinel and first master, because of Redis's need to bootstrap with fixed IP. This makes it hard to just have it applied to a cluster (or restarted) and run automatically
* If a sentinel pod goes away, it will come back with a new IP. Since Sentinel uses IPs internally to track everything, and does not remove any Sentinels unless explicitly told to do so, it quickly will have stale IPs/Sentinels and be unable to reach quorum for anything.

I had to resolve these issues for a cloud-native (self-bootstrapping and healing) Redis with Sentinel in a Kubernetes cluster (and proposed a talk on it for CNCF Copenhagen). I am happy to contribute it.

Would a PR with a `Service`s + `StatefulSet`s only and self-bootstrapping/self-healing be of interest?",closed,False,2018-01-17 07:58:03,2018-12-15 06:26:14
examples,thockin,https://github.com/kubernetes/examples/pull/174,https://api.github.com/repos/kubernetes/examples/issues/174,Pushes go to staging-k8s.gcr.io,"Context: https://github.com/kubernetes/kubernetes/pull/57824

xref kubernetes/release#281",closed,True,2018-01-17 22:24:06,2018-01-19 17:25:41
examples,rbtcollins,https://github.com/kubernetes/examples/issues/175,https://api.github.com/repos/kubernetes/examples/issues/175,Cassandra example will serve bad data to clients,"https://github.com/kubernetes/examples/blob/master/cassandra/cassandra-statefulset.yaml#L54 sets CASSANDRA_AUTO_BOOTSTRAP to false, which leads to data inconsistency when clients are reading shortly after a node has join:  a new node advertises itself as available before it has synchronised all the data it owns, rather than fully synchronising and then accepting reads. Quoting http://thelastpickle.com/blog/2017/05/23/auto-bootstrapping-part1.html 

""""""Setting auto_bootstrap to false when bootstrapping a new node exposes the cluster to huge inconsistencies. This is because all the other steps in the process are carried out but no data is streamed to the node. Hence, the node would be in the UN state without having any data for the token ranges it has been allocated! Furthermore, the new node without data will be serving reads and nodes that previously owned the tokens will no longer be serving reads. Effectively, the token ranges for that replica would be replaced with no data.""""""

Its clearly trivial to submit a PR for  this, but I'm not sure how many places this needs to be changed in - the main k8s repo too? etc. So I'm hoping this ticket will get discussion.",closed,False,2018-01-18 01:02:41,2018-02-21 17:45:27
examples,zioproto,https://github.com/kubernetes/examples/pull/176,https://api.github.com/repos/kubernetes/examples/issues/176,There is now a easier solution to create TLS certs.,https://github.com/kubernetes/kubernetes/issues/14017,closed,True,2018-01-18 12:58:02,2018-01-18 21:46:47
examples,humblec,https://github.com/kubernetes/examples/pull/177,https://api.github.com/repos/kubernetes/examples/issues/177,Update README with changes introduced by PR#58513,Signed-off-by: Humble Chirammal <hchiramm@redhat.com>,closed,True,2018-01-24 11:00:52,2018-01-25 18:44:14
examples,vincenzodnp,https://github.com/kubernetes/examples/issues/178,https://api.github.com/repos/kubernetes/examples/issues/178,Openshift 3.6 / K8s 1.6 - no volume plugin matched,"Hello there.
I followed the example to integrate Openshift 3.6 / K8S 1.6 with ScaleIO.
I'm able to create the secret, the storageclass and a pod with a ScaleIO volume attached, but when I try to create a pvc, it stays in pending state and I get the errore in title (""no volume plugin matched"")

Following system info:
OS: Centos7
Kernel: 3.10.0-514.el7.x86_64
ScaleIO: 2.0.13
Openshift: Origin 3.6
K8s: v1.6.1+5115d708d7

```
kubectl get pvc
NAME             STATUS    VOLUME    CAPACITY   ACCESSMODES   STORAGECLASS   AGE
pvc-sio-small  Pending                                                                            sio-k8s        15m
```

```
kubectl describe sc sio-k8s
Name:		sio-k8s
IsDefaultClass:	No
Annotations:	<none>
Provisioner:	kubernetes.io/scaleio
Parameters:	fsType=xfs,gateway=https://192.168.20.254/api,protectionDomain=default,secretRef=sio-secret,storagePool=default,system=scaleio
Events:		<none>
```
```
oc get event pvc-sio-small.150cced22d69293b 
LASTSEEN   FIRSTSEEN   COUNT     NAME            KIND                    SUBOBJECT   TYPE      REASON               SOURCE                        MESSAGE
4m         19m         62        pvc-sio-small   PersistentVolumeClaim               Warning   ProvisioningFailed   persistentvolume-controller   no volume plugin matched
```",closed,False,2018-01-24 17:42:53,2018-06-23 19:25:30
examples,taoyu27,https://github.com/kubernetes/examples/pull/179,https://api.github.com/repos/kubernetes/examples/issues/179,typo error in 'RBD Ceph' segment of README,,closed,True,2018-01-26 02:52:31,2018-01-26 03:12:27
examples,taoyu27,https://github.com/kubernetes/examples/pull/180,https://api.github.com/repos/kubernetes/examples/issues/180,typo error in 'Ceph RBD' segment of readme,Signed-off-by: yutao <yutao@chinacloud.com.cn>,closed,True,2018-01-26 03:44:26,2018-02-07 17:51:35
examples,cimomo,https://github.com/kubernetes/examples/pull/181,https://api.github.com/repos/kubernetes/examples/issues/181,Update the workloads API version for the Guestbook example to 1.9,Update the workloads API version for the Guestbook example to 1.9.,closed,True,2018-01-26 08:58:11,2018-02-01 20:34:09
examples,liubin,https://github.com/kubernetes/examples/pull/182,https://api.github.com/repos/kubernetes/examples/issues/182,Fix typo,,closed,True,2018-01-26 10:42:45,2018-01-26 18:14:52
examples,Rcluoyi,https://github.com/kubernetes/examples/pull/183,https://api.github.com/repos/kubernetes/examples/issues/183,Update apiversion of deployment in v1.9 for openshift-origin example,"Update apiversion of deployment in v1.9 for openshift-origin example
Signed-off-by: renchao <renchao@chinacloud.com.cn>",closed,True,2018-01-31 15:48:57,2018-02-01 00:51:46
examples,jeis2497052,https://github.com/kubernetes/examples/pull/184,https://api.github.com/repos/kubernetes/examples/issues/184,Propose small spelling changes,are these changes OK ?,closed,True,2018-01-31 16:27:40,2018-01-31 17:17:26
examples,Davidchinacloud,https://github.com/kubernetes/examples/pull/185,https://api.github.com/repos/kubernetes/examples/issues/185,[https-nginx] broken link in readme,Signed-off-by: LinWengang <linwengang@chinacloud.com.cn>,closed,True,2018-02-01 01:17:34,2018-02-01 02:08:32
examples,Davidchinacloud,https://github.com/kubernetes/examples/pull/186,https://api.github.com/repos/kubernetes/examples/issues/186,Dev,,closed,True,2018-02-01 02:12:09,2018-02-01 02:14:45
examples,Davidchinacloud,https://github.com/kubernetes/examples/pull/187,https://api.github.com/repos/kubernetes/examples/issues/187,[https-nginx] broken link in readme,Signed-off-by: LinWengang <linwengang@chinacloud.com.cn>,closed,True,2018-02-01 03:17:53,2018-02-02 03:16:54
examples,JounQin,https://github.com/kubernetes/examples/pull/188,https://api.github.com/repos/kubernetes/examples/issues/188,fix broken and outdated links,,closed,True,2018-02-01 06:42:29,2018-02-03 22:53:00
examples,Davidchinacloud,https://github.com/kubernetes/examples/pull/189,https://api.github.com/repos/kubernetes/examples/issues/189,[https-nginx and spark ] broken link in readme,Signed-off-by: LinWengang <linwengang@chinacloud.com.cn>,closed,True,2018-02-02 03:45:31,2018-02-05 04:21:21
examples,gkumar7,https://github.com/kubernetes/examples/issues/190,https://api.github.com/repos/kubernetes/examples/issues/190,KubernetesSeedProvider: endpoints null for first node,"https://github.com/kubernetes/examples/blob/8774c894fa623dcc7a43bdfdc4fbf5668074fadf/cassandra/java/src/main/java/io/k8s/cassandra/KubernetesSeedProvider.java#L134-L137

Regarding this comment, are there any other scenarios in which ```endpoints``` can be null? If not, possibly the local ip could be placed in the seed list instead of using the default seeds list.

",closed,False,2018-02-02 20:53:30,2018-04-12 16:26:56
examples,Davidchinacloud,https://github.com/kubernetes/examples/pull/191,https://api.github.com/repos/kubernetes/examples/issues/191,[storm] fix broken and outdated links in readme,Signed-off-by: LinWengang <linwengang@chinacloud.com.cn>,closed,True,2018-02-05 04:22:16,2018-02-09 03:37:28
examples,Davidchinacloud,https://github.com/kubernetes/examples/pull/192,https://api.github.com/repos/kubernetes/examples/issues/192,[cassandra staging ] update workloads API version to apps/v1 in k8s v1.9.0,Signed-off-by: LinWengang <linwengang@chinacloud.com.cn>,closed,True,2018-02-05 08:34:49,2018-02-09 03:40:43
examples,Davidchinacloud,https://github.com/kubernetes/examples/pull/193,https://api.github.com/repos/kubernetes/examples/issues/193,update all Deployment API version to apps/v1 in k8s v1.9.0 and add ac…,"update all Deployment API version to apps/v1 in k8s v1.9.0 and add accurate annotations for the old version of k8s how to use API version。

Signed-off-by: LinWengang <linwengang@chinacloud.com.cn>",closed,True,2018-02-09 06:11:51,2018-02-12 02:24:00
examples,mau21mau,https://github.com/kubernetes/examples/issues/194,https://api.github.com/repos/kubernetes/examples/issues/194,Incompatible certificate name,"Your `nginx.conf` file points the certs to `nginx.cert` and `nginx.key`, while your inside the mount point they are called `tls.cert` and `tls.key`.",closed,False,2018-02-12 12:53:56,2018-03-20 20:00:48
examples,jheyduk,https://github.com/kubernetes/examples/pull/195,https://api.github.com/repos/kubernetes/examples/issues/195,add missing comment,I just added a missing comment sign,closed,True,2018-02-12 17:52:23,2018-02-24 21:47:30
examples,humblec,https://github.com/kubernetes/examples/pull/196,https://api.github.com/repos/kubernetes/examples/issues/196,Update README with new supported SC parameters.,Signed-off-by: Humble Chirammal <hchiramm@redhat.com>,closed,True,2018-02-16 05:05:12,2018-02-16 17:54:19
examples,sivakumaris,https://github.com/kubernetes/examples/issues/197,https://api.github.com/repos/kubernetes/examples/issues/197,Connecting cassandra instance running in kuberentes,"My Cassandra instance is running on Kubernetes. 
From my desktop i use to connect it with the below command ""kubectl exec -it cassandra-0 cqlsh --namespace cassandra""

I want to know how to do the same with java.


 


 ",closed,False,2018-02-17 05:19:03,2018-02-17 05:55:44
examples,aledbf,https://github.com/kubernetes/examples/pull/198,https://api.github.com/repos/kubernetes/examples/issues/198,cassandra: Replace deprecated ubuntu-slim image with debian-base from k8s,"**What this PR does / why we need it**:

Replaces the deprecated ubuntu-slim image with ` k8s.gcr.io/debian-base-amd64:0.3`.
Also adds a script for the build process to improve the legibility of the process and better error messages.

**Release note**:
<!--  Write your release note:
1. Enter your extended release note in the below block. If the PR requires additional action from users switching to the new release, include the string ""action required"".
2. If no release note is required, just write ""NONE"".
-->
```release-note
NONE
```

closes #153",closed,True,2018-02-20 19:11:02,2018-02-21 04:56:13
examples,aledbf,https://github.com/kubernetes/examples/pull/199,https://api.github.com/repos/kubernetes/examples/issues/199,Improve cassandra deployment,"This PR ports two fixes that ""disappear"" in the migration from `kubernetes/kubernetes`
- https://github.com/kubernetes/kubernetes/commit/c165e9084ff0710ec54095d69c86eb3594f2f0f9#diff-a21f09fe308ab1a86e11b8330930566b
- https://github.com/kubernetes/kubernetes/commit/82241e4c0d2f73b03d8d4bd0cfe73860fca62b06#diff-a21f09fe308ab1a86e11b8330930566b

Also removes the `CASSANDRA_AUTO_BOOTSTRAP` setting. I cannot found a PR that changed the default.

fixes #175",closed,True,2018-02-21 17:03:00,2018-02-21 17:45:28
examples,aledbf,https://github.com/kubernetes/examples/pull/200,https://api.github.com/repos/kubernetes/examples/issues/200,Add controller required for tests in kubernetes/kubernetes,This file is used in several tests in kubernetes/kubernetes,closed,True,2018-02-22 00:03:04,2018-02-23 03:47:13
examples,aledbf,https://github.com/kubernetes/examples/pull/201,https://api.github.com/repos/kubernetes/examples/issues/201,Use docker to build cassandra jar file,"Test image: `aledbf/cassandra:v15`

This PR also replaces the java code with a go shared library.

fixes #190 
fixes #147",closed,True,2018-02-22 01:53:47,2018-11-27 17:29:54
examples,aledbf,https://github.com/kubernetes/examples/pull/202,https://api.github.com/repos/kubernetes/examples/issues/202,Add owners file to cassandra example,,closed,True,2018-02-23 03:28:07,2018-02-26 20:00:53
examples,ahmetb,https://github.com/kubernetes/examples/pull/203,https://api.github.com/repos/kubernetes/examples/issues/203,Update owners for k/examples,cc: @sebgoa  @idvoretskyi ,closed,True,2018-02-26 19:30:50,2018-02-26 22:53:52
examples,ahmetb,https://github.com/kubernetes/examples/issues/204,https://api.github.com/repos/kubernetes/examples/issues/204,Consideration for removal: staging/sharing-clusters,"@bprashanth  do you still intend to maintain https://github.com/kubernetes/examples/tree/master/staging/sharing-clusters

I'm inclined to delete it:

- I think these sort of articles should ideally go to kubernetes.io.
- I don't think there's a lot of users of it. This one in particular did not get any particular updates since it's contributed https://github.com/kubernetes/kubernetes/commits/master/examples/sharing-clusters/README.md
- IMO the name sharing-clusters is kind of misleading in this context (it made me think it's about giving someone access to your cluster).
- kube-up.sh is deprecated for many environments, especially for managed Kubernetes services it's not possible.",closed,False,2018-02-27 20:09:26,2018-07-28 07:57:53
examples,resouer,https://github.com/kubernetes/examples/pull/205,https://api.github.com/repos/kubernetes/examples/issues/205,Add preempt verb for scheduler,"Ref: https://github.com/kubernetes/kubernetes/pull/58717

More configure examples should be added later.",closed,True,2018-02-27 22:55:01,2018-04-09 17:10:48
examples,php-coder,https://github.com/kubernetes/examples/pull/206,https://api.github.com/repos/kubernetes/examples/issues/206,staging/podsecuritypolicy/rbac: use PSP from policy API group,"This PR updates PSP examples to use `policy/v1beta1` API group. This make them identical to what we already have in the kubernetes `examples/` directory.

Related PRs in k8s repo: https://github.com/kubernetes/kubernetes/pull/54933 and https://github.com/kubernetes/kubernetes/pull/60145

PTAL @liggitt @tallclair 
CC @simo5",closed,True,2018-02-28 17:44:44,2018-03-02 17:19:22
examples,gsacavdm,https://github.com/kubernetes/examples/pull/207,https://api.github.com/repos/kubernetes/examples/issues/207,elasticsearch prod: Add Role and RoleBinding for RBAC,Replicating #106 for the elastic search production cluster.,closed,True,2018-03-02 12:58:07,2018-03-05 22:47:43
examples,php-coder,https://github.com/kubernetes/examples/pull/208,https://api.github.com/repos/kubernetes/examples/issues/208,podsecuritypolicy/rbac/README.md: update to use PSP from policy API group,"This is a follow-up to https://github.com/kubernetes/examples/pull/206 where I forgot to update `README.md` file.

PTAL @liggitt @tallclair
CC @simo5",closed,True,2018-03-02 17:26:24,2018-03-22 09:56:48
examples,jpiper,https://github.com/kubernetes/examples/pull/209,https://api.github.com/repos/kubernetes/examples/issues/209,Fix PodSecurityPolicy Examples,I discovered that the PSP examples weren't working and it turned out to be a simple fix - PSP objects are under extensions/v1beta1 so the ClusterRole wasn't actually granting anything.,closed,True,2018-03-07 08:02:23,2018-03-07 09:07:59
examples,serathius,https://github.com/kubernetes/examples/pull/210,https://api.github.com/repos/kubernetes/examples/issues/210,Import kubernetes updates,"examples directory state from https://github.com/kubernetes/kubernetes/commit/b79fe1073017907a59a869413d659f74e90b0443

Process:
* start with kubernetes master
* remove all content and history for all directories beside `examples` directory using `git filter-branch --filter-subdirectory`
* remove all commits that overwrite README with references to this repo
* find newest common commit in history and following it commit to move examples to staging directory
* rebase kubernetes repo for `examples` to this commit
* merge with this repo master

Strategy for merge:
* Remove all BUILD files
* Move new examples to staging directory
* Remove changes to main directory 
* Try to fix files based on git blame, and which links work which not

First stage for https://github.com/kubernetes/kubernetes/issues/60887",closed,True,2018-03-08 00:07:21,2018-03-14 18:26:27
examples,serathius,https://github.com/kubernetes/examples/pull/211,https://api.github.com/repos/kubernetes/examples/issues/211,[guestbook-go] Use multi-stage build,"Makes building images more streamlined and removes requirement to handle separate build image.

cc @ahmetb ",closed,True,2018-03-08 09:18:43,2018-03-20 16:10:36
examples,noelbundick,https://github.com/kubernetes/examples/pull/212,https://api.github.com/repos/kubernetes/examples/issues/212,Add details on mounting existing Azure Managed Disks,"This PR adds examples for how to use preexisting Managed Disks with Pods

The information was gathered from the following sources:
* [AzureDiskVolumeSource](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.9/#azurediskvolumesource-v1-core)
* [validation.go](https://github.com/kubernetes/kubernetes/blob/ae1fc13aee81e66b9b74a5fb881ff3f90463ff4e/pkg/apis/core/validation/validation.go#L1291)
* [types.go](https://github.com/kubernetes/kubernetes/blob/master/pkg/apis/core/types.go#L1365)
* [Volumes with Azure Disks](https://docs.microsoft.com/en-us/azure/aks/azure-disk-volume)
",closed,True,2018-03-10 00:41:32,2018-04-02 20:38:17
examples,jonyhy96,https://github.com/kubernetes/examples/pull/213,https://api.github.com/repos/kubernetes/examples/issues/213,fix yaml file  format,"fix the format of dns-backend-service.yaml
```release-note
NONE
```",closed,True,2018-03-15 02:51:34,2018-03-27 01:28:33
examples,serathius,https://github.com/kubernetes/examples/issues/214,https://api.github.com/repos/kubernetes/examples/issues/214,Migrate tests from main repo,"I'm working on PR that removes `examples` directory from main repo.
I found more advanced tests in https://github.com/kubernetes/kubernetes/blob/67be0a90f44a82985e6f926c102d2427a887a893/test/e2e/examples.go
Maybe they could be used as a base for testing examples.",closed,False,2018-03-19 16:36:08,2018-09-02 20:16:54
examples,Raab70,https://github.com/kubernetes/examples/pull/215,https://api.github.com/repos/kubernetes/examples/issues/215,Fix NFS tutorial README links,The commands/links in the README for the NFS tutorial were stale since moving stuff to staging. ,closed,True,2018-03-20 01:47:33,2018-03-28 04:42:14
examples,foo0x29a,https://github.com/kubernetes/examples/pull/216,https://api.github.com/repos/kubernetes/examples/issues/216,change the order of objects' creation,"Even though the ReplicationController object is not the recommended way to set up replication in the current version of Kubernetes (v1.9), following the configuration best practices present in the documentation of Kubernetes v1.6 (https://v1-6.docs.kubernetes.io/docs/concepts/configuration/overview/), ""It’s typically best to create a service before corresponding replication controllers"".",closed,True,2018-03-20 03:59:04,2018-03-20 18:30:40
examples,ahmetb,https://github.com/kubernetes/examples/pull/217,https://api.github.com/repos/kubernetes/examples/issues/217,https-nginx: Correct tls.[crt|key] mount,Fixes #194.,closed,True,2018-03-20 16:04:44,2018-03-20 21:18:36
examples,idvoretskyi,https://github.com/kubernetes/examples/issues/218,https://api.github.com/repos/kubernetes/examples/issues/218,Enable auto-merging for the k/examples repo,"Adding `/lgtm` and `/approve` labels to the PR in the current repo doesn't auto-merge the PR - auto-merging has to be enabled.

cc @ahmetb ",closed,False,2018-03-20 21:05:04,2018-03-28 20:06:05
examples,ilievlad,https://github.com/kubernetes/examples/pull/219,https://api.github.com/repos/kubernetes/examples/issues/219,Update selenium examples to use deployments and newer selenium,I've updated the selenium examples with to use deployments and selenium:3.11.,closed,True,2018-03-23 14:21:05,2018-04-04 08:01:08
examples,do-web,https://github.com/kubernetes/examples/issues/220,https://api.github.com/repos/kubernetes/examples/issues/220,nfs mount failed on other nodes,"I tried https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs

I have running two nodes if i start the nginx server the pod on the server where the nfs-server is running, can connect to the nfs. But on the other node the pod throws an error:

`
MountVolume.SetUp failed for volume ""nfs"" : mount failed: exit status 32 Mounting command: systemd-run Mounting arguments: -description=Kubernetes transient mount for /var/lib/kubelet/pods/4df483ce-2eb4-11e8-b73c-02f3569a6c30/volumes/kubernetes.io~nfs/nfs --scope - mount -t nfs 10.43.103.112:/ /var/lib/kubelet/pods/4df483ce-2eb4-11e8-b73c-02f3569a6c30/volumes/kubernetes.io~nfs/nfs Output: Running scope as unit run-r7f98d0cc28f24eea92d7ab1eaaac6312.scope. 
mount.nfs: access denied by server while mounting 10.43.103.112:/
`

What is here wrong?",closed,False,2018-03-23 16:38:45,2018-09-01 04:37:54
examples,chenpengdev,https://github.com/kubernetes/examples/pull/221,https://api.github.com/repos/kubernetes/examples/issues/221,fix typo,,closed,True,2018-03-27 10:54:45,2018-03-28 17:29:18
examples,DonMartin76,https://github.com/kubernetes/examples/pull/222,https://api.github.com/repos/kubernetes/examples/issues/222,Add a sample for using azureFile for PVs,"The example for azureFile previously just had a sample of how to directly mount an Azure Files storage into a Pod. I thought it would be nice to also have an example which uses a persistent volume/persistent volume claim, which can be done in the same way. I also added how to get the storage account key via code (using the az command line), and how to create a secret using `kubectl` directly instead of via a `Secret` manifest (which is somewhat clunky).",closed,True,2018-04-03 14:18:21,2018-04-14 02:27:00
examples,TonyCMCC,https://github.com/kubernetes/examples/issues/223,https://api.github.com/repos/kubernetes/examples/issues/223,what's wrong with mount nfs volume by kube？,"there is error info：Invalid argument @ chown_internal
it's like mount nfs volume to docker forgot “-o  vers=3”
my config is here：
apiVersion: v1
kind: ReplicationController
metadata:
  name: gitlab-ce-test
  labels:
    name: gitlab-ce-test
spec:
  replicas: 1
  selector:
    name: gitlab-ce-test
  template:
    metadata:
      labels:
        name: gitlab-ce-test
    spec:
      containers:
      - name: gitlab-ce-test
        image: registry.paas/devops/gitlab-ce
        ports:
        - containerPort: 80
        - containerPort: 443
        - containerPort: 22
        volumeMounts:
        - mountPath: /etc/gitlab
          name: gitlab-config-pv
          readOnly: false
      volumes:
      - name: gitlab-config-pv
        nfs:
           server: 192.195.29.2
           path: /git_DMCK/data/gitlab/config
there are logs:
  * directory[/etc/gitlab] action create
    
    ================================================================================
    Error executing action `create` on resource 'directory[/etc/gitlab]'
    ================================================================================
    
    Errno::EINVAL
    -------------
    Invalid argument @ chown_internal - /etc/gitlab",closed,False,2018-04-04 02:50:18,2018-04-08 03:05:30
examples,mindprince,https://github.com/kubernetes/examples/pull/224,https://api.github.com/repos/kubernetes/examples/issues/224,Provide a more ideal example for scheduler extender policy.,"We now use default predicates/priorities if they are unspecified in the policy
config (kubernetes/kubernetes#59363).

The other example in ./scheduler-policy-config.json shows how to use priorities
and predicates.

Let's use this example to show how to use extenders. When you are using
extenders you don't necessarily want to mess with priorities and predicates
(kubernetes/kubernetes#45188).

This was previously kubernetes/kubernetes#62186",closed,True,2018-04-09 21:48:04,2018-04-09 23:01:18
examples,didip,https://github.com/kubernetes/examples/issues/225,https://api.github.com/repos/kubernetes/examples/issues/225,Cassandra StatefulSet: Pod errors: Unschedulable,"Tested on GCP Kubernetes:
```
Master version                         1.9.6-gke.0
Endpoint	                                 35.184.206.250
Client certificate	                 Enabled
Kubernetes alpha features	Disabled
Total size	                                 3
Master zone	                         us-central1-a
Node zones	                         us-central1-a
Network	                                 default
Subnet	                                 default
Alias IP ranges	                Disabled
Container address range	10.12.0.0/14
Stackdriver Logging	        Enabled
Stackdriver Monitoring	        Enabled
Private cluster                         Disabled
Master authorized networks	Disabled
Network policy	                Disabled
Legacy authorization	        Disabled
Maintenance window	        Any time
```

I followed the following tutorial:

* https://kubernetes.io/docs/tutorials/stateful-application/cassandra/

* https://github.com/kubernetes/examples/tree/master/cassandra

The `cassandra-data-cassandra-0` volume continuously spins in pending phase.

How can I fix it? I don't see other events to clue me in.
",closed,False,2018-04-10 05:16:49,2018-11-22 19:39:15
examples,ahmetb,https://github.com/kubernetes/examples/pull/226,https://api.github.com/repos/kubernetes/examples/issues/226,cassandra: fix the broken build,"Also udpated gcloud docker with --project so that I don't have to do
""gcloud config set core/project"" every time. Also ""gcloud docker --"" is going
away soon, so the Makefile will likely require updating again.

/assign @aledbf",closed,True,2018-04-12 19:17:53,2018-09-09 22:02:44
examples,foo0x29a,https://github.com/kubernetes/examples/pull/227,https://api.github.com/repos/kubernetes/examples/issues/227,Fix cloud-dns README links,The links and paths used as argument in the `kubectl` command were outdated.,closed,True,2018-04-17 03:10:29,2018-05-02 08:53:58
examples,humblec,https://github.com/kubernetes/examples/pull/228,https://api.github.com/repos/kubernetes/examples/issues/228,Add `snapfactor` readme for glusterfs provisioner examples.,"Ref PR# https://github.com/kubernetes/kubernetes/pull/62378

Signed-off-by: Humble Chirammal <hchiramm@redhat.com>",closed,True,2018-04-18 17:33:02,2018-04-27 19:11:21
examples,carlossscastro,https://github.com/kubernetes/examples/pull/229,https://api.github.com/repos/kubernetes/examples/issues/229,Update New Relic Infrastructure Readme,"We noticed a deprecated link on this doc to the old server monitor.

Did a few other small changes to align the verbiage with New Relic naming conventions.",closed,True,2018-04-19 10:11:13,2018-05-02 08:52:29
examples,nilesh32,https://github.com/kubernetes/examples/pull/230,https://api.github.com/repos/kubernetes/examples/issues/230,Add guestbook-telemetry.yaml,Required for the guestbook-go to work,closed,True,2018-04-19 22:30:38,2018-04-19 22:31:21
examples,nktaushanov,https://github.com/kubernetes/examples/pull/231,https://api.github.com/repos/kubernetes/examples/issues/231,Add CASSANDRA_TRICKLE_FSYNC config to the Cassandra docker image,,closed,True,2018-04-26 13:52:39,2018-10-27 18:26:13
examples,adelton,https://github.com/kubernetes/examples/pull/232,https://api.github.com/repos/kubernetes/examples/issues/232,Creation of PSP by hack/local-up-cluster.sh is not as automatic as the README suggests.,"Without the symlinks, `hack/local-up-cluster.sh` reports

```
Create podsecuritypolicy policies for RBAC.
error: the path ""/home/test/kubernetes/examples/podsecuritypolicy/rbac/policies.yaml"" does not exist
error: the path ""/home/test/kubernetes/examples/podsecuritypolicy/rbac/roles.yaml"" does not exist
error: the path ""/home/test/kubernetes/examples/podsecuritypolicy/rbac/bindings.yaml"" does not exist
```",closed,True,2018-05-03 20:12:11,2018-05-24 16:16:36
examples,adelton,https://github.com/kubernetes/examples/issues/233,https://api.github.com/repos/kubernetes/examples/issues/233,README.md uses tokens without showing how users should be created and how tokens should be obtained,"https://github.com/kubernetes/examples/blob/master/staging/podsecuritypolicy/rbac/README.md says

```
--token=<token>: this allows to make requests from a different users during testing.
```

and

```
$ kubectl --server=https://127.0.0.1:6443 --token=foo/restricted-psp-users create -f staging/podsecuritypolicy/rbac/pod.yaml
```

but it does not explain how the users can be created and token obtained. The README document should be self-contained that users could follow without additional information.",closed,False,2018-05-04 05:22:31,2018-10-01 07:02:05
examples,yangwenmai,https://github.com/kubernetes/examples/issues/234,https://api.github.com/repos/kubernetes/examples/issues/234,"Build staging Elasticsearch example, But I always have one node.","When I exec `kubectl scale --replicas=3 rc es`.

I got:

```
[root@k8s-master examples]# kubectl get pods
NAME                        READY     STATUS    RESTARTS   AGE
es-2bd9r                    1/1       Running   0          7m
es-pgvvc                    1/1       Running   0          13m
es-qmgg7                    1/1       Running   0          7m
```

```
$ kubectl logs es-pgvvc
...
(no added {{8bcf8744 ...}
```

and I `curl 10.100.165.121:9200/_cluster/health?pretty`

```
{
cluster_name: ""myesdb"",
status: ""green"",
timed_out: false,
number_of_nodes: 1,
number_of_data_nodes: 1,
active_primary_shards: 0,
active_shards: 0,
relocating_shards: 0,
initializing_shards: 0,
unassigned_shards: 0,
delayed_unassigned_shards: 0,
number_of_pending_tasks: 0,
number_of_in_flight_fetch: 0,
task_max_waiting_in_queue_millis: 0,
active_shards_percent_as_number: 100
}
```

Always have 1 node.

Plz give me a help.",closed,False,2018-05-09 11:51:32,2018-10-07 13:30:07
examples,mikep-locol-media,https://github.com/kubernetes/examples/issues/235,https://api.github.com/repos/kubernetes/examples/issues/235,Cassandra Example:,"I am encountering this problem when loading v14 of the example. I don' know if this relates to #89 

Exception (org.apache.cassandra.exceptions.ConfigurationException) encountered during startup: io.k8s.cassandra.KubernetesSeedProvider
Fatal configuration error; unable to start server.  See log for stacktrace.
org.apache.cassandra.exceptions.ConfigurationException: io.k8s.cassandra.KubernetesSeedProvider

Attached is the startup log.

[logs-from-cassandra-in-cassandra-0.txt](https://github.com/kubernetes/examples/files/1997238/logs-from-cassandra-in-cassandra-0.txt)
",closed,False,2018-05-12 03:11:44,2018-11-27 16:52:05
examples,jessfraz,https://github.com/kubernetes/examples/issues/236,https://api.github.com/repos/kubernetes/examples/issues/236,Create a SECURITY_CONTACTS file.,"As per the email sent to kubernetes-dev[1], please create a SECURITY_CONTACTS
file.

The template for the file can be found in the kubernetes-template repository[2].
A description for the file is in the steering-committee docs[3], you might need
to search that page for ""Security Contacts"".

Please feel free to ping me on the PR when you make it, otherwise I will see when
you close this issue. :)

Thanks so much, let me know if you have any questions.

(This issue was generated from a tool, apologies for any weirdness.)

[1] https://groups.google.com/forum/#!topic/kubernetes-dev/codeiIoQ6QE
[2] https://github.com/kubernetes/kubernetes-template-project/blob/master/SECURITY_CONTACTS
[3] https://github.com/kubernetes/community/blob/master/committee-steering/governance/sig-governance-template-short.md
",closed,False,2018-05-24 14:43:06,2018-06-28 17:38:59
examples,day1118,https://github.com/kubernetes/examples/issues/237,https://api.github.com/repos/kubernetes/examples/issues/237,NFS example using hard coded IP rather than service,"Why does the NFS example use a hard coded IP rather than a service. Can you please add a note of why this is the case?

Thanks",open,False,2018-05-25 08:18:36,2019-02-02 18:37:18
examples,rvernica,https://github.com/kubernetes/examples/issues/238,https://api.github.com/repos/kubernetes/examples/issues/238,staging/volumes/cephfs mention base64,"For setting up the Sectret for Ceph, it might be worth mentioning that `ceph-authtool -p /etc/ceph/ceph.client.admin.keyring` returns a Base64 string, but one needs to re-encode that with Base64. So, in the Kubernetes Secret you put the output of:
```
ceph-authtool -p /etc/ceph/ceph.client.admin.keyring | base64
```
Otherwise, one will get a strange `fork/exec nsenter: invalid argument` error.",closed,False,2018-06-15 22:44:33,2018-11-13 00:49:46
examples,idvoretskyi,https://github.com/kubernetes/examples/pull/239,https://api.github.com/repos/kubernetes/examples/issues/239,SECURITY_CONTACTS added,"cc @jessfraz @ahmetb @sebgoa 

Signed-off-by: Ihor Dvoretskyi <ihor@linux.com>",closed,True,2018-06-19 14:48:47,2018-06-19 18:09:33
examples,ww110052181,https://github.com/kubernetes/examples/issues/240,https://api.github.com/repos/kubernetes/examples/issues/240,redis namespace,"i have succeeded  install redis cluster in k8s according the following steps:
kubectl create -f examples/staging/storage/redis/redis-master.yaml

# Create a service to track the sentinels
kubectl create -f examples/staging/storage/redis/redis-sentinel-service.yaml

# Create a replication controller for redis servers
kubectl create -f examples/staging/storage/redis/redis-controller.yaml

# Create a replication controller for redis sentinels
kubectl create -f examples/staging/storage/redis/redis-sentinel-controller.yaml

# Scale both replication controllers
kubectl scale rc redis --replicas=3
kubectl scale rc redis-sentinel --replicas=3

# Delete the original master pod
# Note: If you are running all the above commands consecutively including this one in a shell script, it may NOT work out. When you run the above commands, let the pods first come up, especially the redis-master pod. Else, the sentinel pods would never be able to know the master redis server and establish a connection with it. 
kubectl delete pods redis-master

$ kubectl get pods -o wide --all-namespaces

default       redis-dzz6b                                 1/1       Running            0          8d       
default       redis-hkbzh                                 1/1       Running            0          8d        
default       redis-sentinel-47d2g                     1/1       Running            0          8d        
default       redis-sentinel-9gw65                        1/1       Running            0          8d        
default       redis-sentinel-p4wnc                        1/1       Running            0          8d        
default       redis-wrxtv    				 1/1       Running            0          8d    

but the namespace is default ,I want to modify the namespace ,eg. redisnamespace.but i don't konw what should i modify the official files ?
",closed,False,2018-06-20 12:13:25,2018-11-18 08:55:00
examples,jcmiao,https://github.com/kubernetes/examples/issues/241,https://api.github.com/repos/kubernetes/examples/issues/241,"why call ""defer C.free(unsafe.Pointer(rc))"" with ""return rc""? Please explain, I don't understand","func buildEndpoints(ips []string) *C.char {
	b, err := json.Marshal(&endpoints{ips})
	if err != nil {
		log.Printf(""unexpected error serializing JSON response: %v\n"", err)
		rc := C.CString(`{""ips"":[]}`)
		defer C.free(unsafe.Pointer(rc))
		return rc
	}

	rc := C.CString(string(b))
        // Is there any difference between C-shared and Golang?
	defer C.free(unsafe.Pointer(rc))
	return rc
}
",closed,False,2018-06-21 04:00:18,2018-11-18 05:52:01
examples,AdamDang,https://github.com/kubernetes/examples/pull/242,https://api.github.com/repos/kubernetes/examples/issues/242,Typo fix: Endpont->Endpoint,Line 28: Endpont->Endpoint,closed,True,2018-06-22 09:02:55,2018-06-22 10:41:07
examples,hosungsmsft,https://github.com/kubernetes/examples/pull/243,https://api.github.com/repos/kubernetes/examples/issues/243,Add Azure Disk-based NFS volume option,"We'd like this example to include an option to do the same on Azure with an Azure Disk-based persistent volume, so here goes this PR.

Sorry that I haven't looked how CI works here, and I'll fix any issues as this PR goes along.

Thanks,
Hosung Song
",closed,True,2018-06-29 19:11:15,2018-06-30 05:16:20
examples,comxd,https://github.com/kubernetes/examples/pull/244,https://api.github.com/repos/kubernetes/examples/issues/244,fix README links,,closed,True,2018-07-03 23:43:21,2018-07-04 07:34:23
examples,comxd,https://github.com/kubernetes/examples/issues/245,https://api.github.com/repos/kubernetes/examples/issues/245,Meteor: You are attempting to run Meteor as the 'root' superuser,"Hi,

I have tested the meteor image, here the full error:

```
You are attempting to run Meteor as the 'root' superuser. If you are
developing, this is almost certainly *not* what you want to do and will likely
result in incorrect file permissions. However, if you are running this command
in a build process (CI, etc.), or you are absolutely sure you know what you are
doing, set the METEOR_ALLOW_SUPERUSER environment variable or pass
--allow-superuser to proceed.

Even with METEOR_ALLOW_SUPERUSER or --allow-superuser, permissions in your app
directory will be incorrect if you ever attempt to perform any Meteor tasks as
a normal user. If you need to fix your permissions, run the following command
from the root of your project:

  sudo chown -Rh <username> .meteor/local

The command '/bin/sh -c curl https://install.meteor.com/ | sh &&     meteor build ../app --directory --architecture os.linux.x86_64 &&     rm -rf /appsrc' returned a non-zero code: 1
```

Docker version 18.03.1-ce, build 9ee9f40
4.15.0-24-generic #26-Ubuntu SMP Wed Jun 13 08:44:47 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux",closed,False,2018-07-04 08:53:44,2018-12-01 11:02:31
examples,Haleygo,https://github.com/kubernetes/examples/pull/246,https://api.github.com/repos/kubernetes/examples/issues/246,Update README.md,"missing ""pod""",closed,True,2018-07-06 16:04:10,2018-07-19 09:14:11
examples,Haleygo,https://github.com/kubernetes/examples/pull/247,https://api.github.com/repos/kubernetes/examples/issues/247,Update README.md,content mistake,closed,True,2018-07-06 16:09:25,2018-07-19 09:13:59
examples,Haleygo,https://github.com/kubernetes/examples/pull/248,https://api.github.com/repos/kubernetes/examples/issues/248,Update README.md,content mistake,closed,True,2018-07-06 16:21:48,2018-07-07 16:18:18
examples,DazWilkin,https://github.com/kubernetes/examples/issues/249,https://api.github.com/repos/kubernetes/examples/issues/249,NFS Example: Challenged executing scripts|binaries stored on shared volumes,"**What happened**:

I'm using the NFS volume backed by PD SSD to share read-write volumes across multiple nodes. This appeared to  have been working (and still does for executale) files but, on shared volumes, I'm able to reliably kill a shell by attempting to execute a script and receive ""file not found errors"".

**What you expected to happen**:

I expect to be able to create executable files on volumes shared read-write by the NFS volume, execute these and not crash. I've tried both PD Standard and SSD. I've tried different container OSs (Debian, Ubuntu, Alpine) but the behavior is consistent and repro's.

**How to reproduce it (as minimally and precisely as possible)**:

* Use the sample as provided.
* Create PV|PVCs against the NFS service

PV:
```
kind: PersistentVolume
apiVersion: v1
metadata:
  name: shared-pv
  labels:
    component: volume
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
  nfs:
    server: nfs.imkm.svc.cluster.local
    path: ""/""
```
PVC:
```
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: shared-pvc
  labels:
    component: claim
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: """"
  resources:
    requests:
      storage: 1Gi
  volumeName: shared-pv
```
Shell into a debug container:
```
apiVersion: v1
kind: Pod
metadata:
  labels:
    component: debug
  name: debug-cfd5489df-rjvmp
  namespace: imkm
spec:
  containers:
  - command:
    - sh
    - -c
    - |
      while true; do
        sleep 15s
      done
    image: alpine
    imagePullPolicy: IfNotPresent
    name: debug
    volumeMounts:
    - mountPath: /shared
      name: shared-pvc
  volumes:
  - name: shared-pvc
    persistentVolumeClaim:
      claimName: shared-pvc
```
and:
```
/ # echo ""echo Hello Henry!"" > /tmp/test.sh
/ # echo ""echo Hello Henry!"" > /shared/test.sh

/ # more /tmp/test.sh
echo Hello Henry!
/ # more /shared/test.sh
echo Hello Henry!

/ # chmod +x /tmp/test.sh
/ # chmod +x /shared/test.sh

/ # /tmp/test.sh
Hello Henry!
/ # /shared/test.sh
```
The shell will hang attempting to run the script from the `/shared` directory. This also fails attempting to run binaries that are copied to (and even from!) the volume or downloaded to it.

**Anything else we need to know?**:

Attempting to run binaries is curious. I receive ""file not found"" errors for files that demonstrably exist:
```
/shared/bin # ls -l
-rwxrwxr-x    1 1001     1001      23653336 Mar 15 22:13 configtxgen
-rwxrwxr-x    1 1001     1001      12473976 Mar 15 22:13 cryptogen
-rwxrwxr-x    1 1001     1001      31536304 Mar 15 22:14 orderer
-rwxrwxr-x    1 1001     1001      39016824 Mar 15 22:14 peer

/shared/bin # ./configtxgen
ash: ./configtxgen: not found

/shared/bin # ./peer
ash: ./peer: not found

/shared/bin # cp peer /tmp
/shared/bin # cd /tmp
/tmp # ./peer
ash: ./peer: not found
```
The binaries are the correct size.
I tried `chown`'ing the binaries to `root:root` for want of another idea and that made no difference.

**Environment**: Debian, Ubuntu, Alpine container images all appear to fail consistently
- Kubernetes version (use `kubectl version`): 1.10.5-gke.0

```
kubectl version
Client Version: version.Info{Major:""1"", Minor:""10"", GitVersion:""v1.10.5"", GitCommit:""32ac1c9073b132b8ba18aa830f46b77dcceb0723"", GitTreeState:""clean"", BuildDate:""2018-06-21T11:46:00Z"", GoVersion:""go1.9.3"", Compiler:""gc"", Platform:""linux/amd64""}
Server Version: version.Info{Major:""1"", Minor:""10+"", GitVersion:""v1.10.5-gke.0"", GitCommit:""f4c74e18e57148052c59cc0467bb7e99dcc46399"", GitTreeState:""clean"", BuildDate:""2018-06-21T14:11:26Z"", GoVersion:""go1.9.3b4"", Compiler:""gc"", Platform:""linux/amd64""}
```

- Cloud provider or hardware configuration: Google | Kubernetes Engine
- OS (e.g. from /etc/os-release):
- Kernel (e.g. `uname -a`):
- Install tools:
- Others:
```
mount | grep nfs
10.43.245.114:/ on /usr/share/nginx/html type nfs4 (rw,relatime,vers=4.0,rsize=1048576,wsize=1048576,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=10.138.0.2,local_lock=none,addr=10.43.245.114)
```",open,False,2018-07-09 15:40:30,2019-03-26 21:46:02
examples,madireddyr,https://github.com/kubernetes/examples/issues/250,https://api.github.com/repos/kubernetes/examples/issues/250,"Google image V14 ,Kubernetes /KOPS Cluster on AWS is very slow ","we were able to use above example KOPS cluster and able to bring up the cluster( 6 ec2 nodes), we tried with both EBS & EC2 Instance storage but writing data to root  and  they both work . but when we we do a stress test on this performance seems  very low. 
using both instance storage & EBS storage,

few stats : queue length is very low ""0.06""

and OPS Stats
Results:
Op rate                   :      966 op/s  [WRITE: 966 op/s]
Partition rate            :      966 pk/s  [WRITE: 966 pk/s]
Row rate                  :      966 row/s [WRITE: 966 row/s]
Latency mean              :   51.2 ms [WRITE: 51.2 ms]
Latency median            :    7.8 ms [WRITE: 7.8 ms]
Latency 95th percentile   :  103.2 ms [WRITE: 103.2 ms]
Latency 99th percentile   :  198.3 ms [WRITE: 198.3 ms]
Latency 99.9th percentile :  298.3 ms [WRITE: 298.3 ms]
Latency max               :  601.4 ms [WRITE: 601.4 ms]
Total partitions          :    100,000 [WRITE: 100,000]
Total errors              :          0 [WRITE: 0]
Total GC count            : 0
Total GC memory           : 0.000 KiB
Total GC time             :    0.0 seconds
Avg GC time               :    NaN ms
StdDev GC time            :    0.0 ms
Total operation time      : 00:01:43

we tried to compare the performance kubernetes 1.4.8 & Cassandra 3.9 which is our current working cluster which give 20,000 OP/sec

our KOPS statefulset cluster capacity is same as Above Kuberentes 1.4.8 with  same cassandra.yaml settings 

but cassandra performance on kubernetes 1.4.8 Perf seems much better than 1.9 KOPS
anybody faced similar issue ?
also is there a way to benchmark network performance of KOPS cluster vs kubernetes 1.4.8 

",closed,False,2018-07-10 20:06:06,2018-12-07 22:41:15
examples,aojea,https://github.com/kubernetes/examples/issues/251,https://api.github.com/repos/kubernetes/examples/issues/251,Missing CONTRIBUTING.md file,"All K8s subrepositories should have a CONTRIBUTING.md file, which at the minimum should point to https://github.com/kubernetes/community/blob/master/contributors/guide/README.md. Care should be taken that all information is in sync with the contributor guide.

Subrepositories may also have contributing guidelines specific to that repository. They should be explicitly documented and explained in the CONTRIBUTING.md

Ref:  https://github.com/kubernetes/community/issues/1832",closed,False,2018-07-16 09:23:27,2018-07-19 09:13:42
examples,nikhita,https://github.com/kubernetes/examples/pull/252,https://api.github.com/repos/kubernetes/examples/issues/252,Add CONTRIBUTING.md,"Fixes #251 
xref https://github.com/kubernetes/community/issues/1832

/cc idvoretskyi ahmetb sebgoa ",closed,True,2018-07-19 05:27:36,2018-07-20 04:29:26
examples,bgiorgini,https://github.com/kubernetes/examples/pull/253,https://api.github.com/repos/kubernetes/examples/issues/253,Update README.md,Include the `staging` folder in the paths.,closed,True,2018-07-25 03:30:08,2018-08-23 21:03:16
examples,anonshellsllc,https://github.com/kubernetes/examples/pull/254,https://api.github.com/repos/kubernetes/examples/issues/254,Update owners for k/examples,,closed,True,2018-07-26 13:59:43,2018-08-19 03:42:30
examples,dims,https://github.com/kubernetes/examples/pull/255,https://api.github.com/repos/kubernetes/examples/issues/255,guestbook : Remove explicit install for php-pear,"Looks like `pear` is installed by default and there is no separate package named `php-pear` anymore

Fixes #256",closed,True,2018-07-30 15:22:06,2018-07-30 15:54:59
examples,dims,https://github.com/kubernetes/examples/issues/256,https://api.github.com/repos/kubernetes/examples/issues/256,make all-container in guestbook/php-redis fails,"```
[dims@dims-mac 11:27] ~/go/src/k8s.io/examples/guestbook/php-redis ⟩ make all-container
/Applications/Xcode.app/Contents/Developer/usr/bin/make ARCH=amd64 container
cp ./* /var/folders/wr/8hznwwy91lqbbt8b2k99hxtw0000gn/T/tmp.qgOIGGRI
docker build -t gcr.io/google-samples/gb-frontend-amd64:v5 /var/folders/wr/8hznwwy91lqbbt8b2k99hxtw0000gn/T/tmp.qgOIGGRI
Sending build context to Docker daemon  10.75kB
Step 1/10 : FROM php:5-apache
 ---> 12398af6f4de
Step 2/10 : RUN apt-get update
 ---> Using cache
 ---> 9163d32c08a1
Step 3/10 : RUN apt-get install -y php-pear
 ---> Running in 393a8ccd0c49
Reading package lists...
Building dependency tree...
Reading state information...
Package php-pear is not available, but is referred to by another package.
This may mean that the package is missing, has been obsoleted, or
is only available from another source

E: Package 'php-pear' has no installation candidate
The command '/bin/sh -c apt-get install -y php-pear' returned a non-zero code: 100
make[1]: *** [.container-amd64] Error 100
make: *** [sub-container-amd64] Error 2
```",closed,False,2018-07-30 15:28:10,2018-07-30 15:54:59
examples,dims,https://github.com/kubernetes/examples/pull/257,https://api.github.com/repos/kubernetes/examples/issues/257,Build and push manifests for container images,"We build and push images for various architectures, but are not
publishing a single manifest that can be used to look up the images.
test/images in main k/k repository and kube images in k/release already
publish manifests for all the image we need for e2e testing, so we
should do the same as the 2 images in this repository are part of the
conformance e2e test suite.

Bumping version numbers as well.

Change-Id: I5f87af9e5ad15da86b9e99bcb7a60a81870d0836",closed,True,2018-08-02 20:42:47,2018-08-02 22:29:08
examples,dims,https://github.com/kubernetes/examples/pull/258,https://api.github.com/repos/kubernetes/examples/issues/258,oops! fix the image name when we run docker push,Change-Id: I1533e8be7a6292830c0a9eacc545d8fddd897b26,closed,True,2018-08-02 22:28:44,2018-08-02 23:02:28
examples,dims,https://github.com/kubernetes/examples/pull/259,https://api.github.com/repos/kubernetes/examples/issues/259,Remove stray debug echo from Makefile,"oops #2

Change-Id: Ief434608f87afeb956a471ae35217b106a763739",closed,True,2018-08-03 02:20:28,2018-08-03 18:38:04
examples,kmarokas,https://github.com/kubernetes/examples/issues/260,https://api.github.com/repos/kubernetes/examples/issues/260,fsGroup securityContext does not apply to nfs mount,"The example https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs works fine if the container using nfs mount is running as root user. If I use securityContext to run not as root user then I have no write access to the mounted volume.

How to reproduce:
here is the nfs-busybox-rc.yaml with securityContext:
```
# This mounts the nfs volume claim into /mnt and continuously
# overwrites /mnt/index.html with the time and hostname of the pod.

apiVersion: v1
kind: ReplicationController
metadata:
  name: nfs-busybox
spec:
  replicas: 2
  selector:
    name: nfs-busybox
  template:
    metadata:
      labels:
        name: nfs-busybox
    spec:
      securityContext:
        runAsUser: 10000
        fsGroup: 10000
      containers:
      - image: busybox
        command:
          - sh
          - -c
          - 'while true; do date > /mnt/index.html; hostname >> /mnt/index.html; sleep $(($RANDOM % 5 + 5)); done'
        imagePullPolicy: IfNotPresent
        name: busybox
        securityContext:
          runAsUser: 10000
        volumeMounts:
          # name must match the volume name below
          - name: nfs
            mountPath: ""/mnt""
      volumes:
      - name: nfs
        persistentVolumeClaim:
          claimName: nfs
```

Actual result:
```
kubectl exec nfs-busybox-2w9bp -t -- id
uid=10000 gid=0(root) groups=10000

kubectl exec nfs-busybox-2w9bp -t -- ls -l /
total 48
<..>
drwxr-xr-x    3 root     root          4096 Aug  2 12:27 mnt
```
Expected result:
the group ownership of /mnt folder should be user 10000

The mount  options in nfs pv are not allowed except rw
```
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfs
spec:
  capacity:
    storage: 5Gi
  accessModes:
    - ReadWriteMany
  nfs:
    # FIXME: use the right IP
    server: 10.23.137.115
    path: ""/""
  mountOptions:
#    - rw // is allowed
#    - root_squash // error during pod scheduling: mount.nfs: an incorrect mount option was specified
#    - all_squash // error during pod scheduling: mount.nfs: an incorrect mount option was specified
#    - anonuid=10000 // error during pod scheduling: mount.nfs: an incorrect mount option was specified
#    - anongid=10000 // error during pod scheduling: mount.nfs: an incorrect mount option was specified
```

```
kubectl version
Client Version: version.Info{Major:""1"", Minor:""10"", GitVersion:""v1.10.3"", GitCommit:""2bba0127d85d5a46ab4b778548be28623b32d0b0"", GitTreeState:""clean"", BuildDate:""2018-05-21T09:17:39Z"", GoVersion:""go1.9.3"", Compiler:""gc"", Platform:""windows/amd64""}
Server Version: version.Info{Major:""1"", Minor:""10+"", GitVersion:""v1.10.3-rancher1"", GitCommit:""f6320ca7027d8244abb6216fbdb73a2b3eb2f4f9"", GitTreeState:""clean"", BuildDate:""2018-05-29T22:28:56Z"", GoVersion:""go1.9.3"", Compiler:""gc"", Platform:""linux/amd64""}
```

",closed,False,2018-08-03 07:56:33,2019-03-14 16:19:21
examples,fqsghostcloud,https://github.com/kubernetes/examples/pull/261,https://api.github.com/repos/kubernetes/examples/issues/261,fix README.md,fix README.md,closed,True,2018-08-14 01:41:35,2018-08-16 23:47:09
examples,wangxy518,https://github.com/kubernetes/examples/pull/262,https://api.github.com/repos/kubernetes/examples/issues/262,Update jvm.options,a url has been changed.,closed,True,2018-08-17 07:00:55,2018-08-17 11:10:13
examples,hrishin,https://github.com/kubernetes/examples/pull/263,https://api.github.com/repos/kubernetes/examples/issues/263,added liveness probes to mysql deployment,Added `livenessProbe` for mysql deployment.,closed,True,2018-08-26 08:18:34,2018-08-31 16:02:57
examples,yjl-lgx,https://github.com/kubernetes/examples/pull/264,https://api.github.com/repos/kubernetes/examples/issues/264,updete,,closed,True,2018-09-01 07:06:51,2019-02-01 21:26:48
examples,mmsakura,https://github.com/kubernetes/examples/pull/265,https://api.github.com/repos/kubernetes/examples/issues/265,Correct documentation formatting standards,,closed,True,2018-09-01 07:37:55,2019-02-01 21:26:47
examples,yjl-lgx,https://github.com/kubernetes/examples/pull/266,https://api.github.com/repos/kubernetes/examples/issues/266,Yjl lgx patch tow,,closed,True,2018-09-01 09:49:59,2019-01-10 16:41:45
examples,benjamink,https://github.com/kubernetes/examples/pull/267,https://api.github.com/repos/kubernetes/examples/issues/267,Use init-containers instead of sidecar model,"Converted the example to use an [init-container](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/) instead of the sidecar model as the init-container is a bit cleaner & light-weight.  The container that exclusively copies a war file into place does not have to continue running after its job is done.  Therefore using an init-container allows the container with the war file to run, copy its payload into place & then terminate.

Also, using an init-container ensures that the copying of the payload _must_ complete _before_ the Tomcat container can start.  This removes the chance for a race condition (however unlikely) in which Tomcat starts before the war file is copied in place.",closed,True,2018-09-06 20:34:16,2018-09-07 14:50:19
examples,purpletech77,https://github.com/kubernetes/examples/issues/268,https://api.github.com/repos/kubernetes/examples/issues/268,spark controller error,"18/09/07 23:44:09 INFO Utils: Successfully started service 'sparkMaster' on port 7077.
18/09/07 23:44:09 INFO Master: Starting Spark master at spark://spark-master:7077
18/09/07 23:44:09 INFO Master: Running Spark version 1.5.2
/start-master: line 22:    11 Killed                  /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --ip spark-master --port 7077 --webui-port 8080",closed,False,2018-09-07 23:45:09,2019-02-05 01:41:45
examples,cod-y,https://github.com/kubernetes/examples/pull/269,https://api.github.com/repos/kubernetes/examples/issues/269,Cod y patch 2,,closed,True,2018-09-10 20:24:31,2018-09-10 20:25:06
examples,wangxy518,https://github.com/kubernetes/examples/pull/270,https://api.github.com/repos/kubernetes/examples/issues/270,Update cassandra.yaml,these urls have been updated.,closed,True,2018-09-13 06:31:22,2018-10-29 12:08:29
examples,ldx,https://github.com/kubernetes/examples/pull/271,https://api.github.com/repos/kubernetes/examples/issues/271,Fix javaweb examples,,closed,True,2018-09-18 23:15:48,2018-09-19 17:39:37
examples,ArWeder,https://github.com/kubernetes/examples/issues/272,https://api.github.com/repos/kubernetes/examples/issues/272,Azure File Shares cannot see mongo data,"Hi ,
I have mounted an Azure file share volume to a mongoDb pod on the path /data. Everything seems to work as expected. When I exec into the pod, I can see mongo data in /data/db. But on the Azure File Shares I can only see the folders /db and /dbconfig, not the files. 

This is my yaml files

StorageClass

```
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: azurefile
provisioner: kubernetes.io/azure-file
mountOptions:
  - dir_mode=0777
  - file_mode=0777
  - uid=999
  - gid=999
parameters:
  storageAccount: ACCOUNT_NAME
  skuName: Standard_LRS
```

PVC 
```
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: azurefile
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: azurefile
  resources:
    requests:
      storage: 20Gi
```

Mongo deployement file

```
apiVersion: apps/v1beta2
kind: Deployment
metadata:
  name: mongo
  labels:
    app: mongo
  namespace: development
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mongo
  template:
    metadata:
      labels:
        app: mongo
    spec:
      containers:
        - name: mongo
          image: ""mongo""
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 27017
            protocol: TCP
          volumeMounts:
          - mountPath: /data
            name: mongovolume
            subPath: mongo
      imagePullSecrets:
        - name: secret-acr
      volumes:
        - name: mongovolume
          persistentVolumeClaim:
            claimName: azurefile
```

Kubernetes version

```
Client Version: version.Info{Major:""1"", Minor:""10"", GitVersion:""v1.10.3"", GitCommit:""2bba0127d85d5a46ab4b778548be28623b32d0b0"", GitTreeState:""clean"", BuildDate:""2018-05-21T09:17:39Z"", GoVersion:""go1.9.3"", Compiler:""gc"", Platform:""windows/amd64""}
Server Version: version.Info{Major:""1"", Minor:""10"", GitVersion:""v1.10.6"", GitCommit:""a21fdbd78dde8f5447f5f6c331f7eb6f80bd684e"", GitTreeState:""clean"", BuildDate:""2018-07-26T10:04:08Z"", GoVersion:""go1.9.3"", Compiler:""gc"", Platform:""linux/amd64""}
```",closed,False,2018-09-24 13:59:45,2019-02-21 15:44:37
examples,wangxy518,https://github.com/kubernetes/examples/pull/273,https://api.github.com/repos/kubernetes/examples/issues/273,Update cassandra.yaml,some urls have been changed.,closed,True,2018-09-25 01:52:01,2019-02-13 10:30:18
examples,mkumatag,https://github.com/kubernetes/examples/pull/274,https://api.github.com/repos/kubernetes/examples/issues/274,Purge the manifest after the push,"Triggered by https://github.com/kubernetes/kubernetes/issues/69104#issuecomment-424799217

/cc @ixdy @dims ",closed,True,2018-09-27 15:05:58,2018-10-04 12:41:43
examples,oz123,https://github.com/kubernetes/examples/pull/275,https://api.github.com/repos/kubernetes/examples/issues/275,Update alpine linux version in Dockerfile,"Alpine version 3.4 is EOL since 2018-05-01.
See https://wiki.alpinelinux.org/wiki/Alpine_Linux:Releases

Signed-off-by: Oz N Tiram <oz.tiram@gmail.com>",closed,True,2018-10-05 02:41:45,2018-10-05 18:53:52
examples,oz123,https://github.com/kubernetes/examples/issues/276,https://api.github.com/repos/kubernetes/examples/issues/276,how often are images built?,"After updating the alpine linux version in https://github.com/kubernetes/examples/blob/master/staging/storage/redis/image/Dockerfile I realized it might take a while to the correct Docker image to appear in the docker hub registry. 
So the question is, who is responsible for building images and pushing them to

https://hub.docker.com/u/kubernetes/ ?

Does it make sense to add some CI here?

",closed,False,2018-10-08 12:21:32,2019-03-07 14:12:22
examples,ipuustin,https://github.com/kubernetes/examples/issues/277,https://api.github.com/repos/kubernetes/examples/issues/277,Simple-nginx example should be updated to use 'kubectl create',"Running the first deployment command on the nginx example page (https://github.com/kubernetes/examples/blob/master/staging/simple-nginx.md) gives me a warning about using deprecated run generator:

    $ kubectl run my-nginx --image=nginx --replicas=2 --port=80
    kubectl run --generator=deployment/apps.v1beta1 is DEPRECATED and will be removed in a future version. Use kubectl create instead.

See https://github.com/kubernetes/kubernetes/pull/68132 for context. I'm using kubernetes 1.12.1.",closed,False,2018-10-08 16:03:44,2018-10-13 13:30:52
examples,foo0x29a,https://github.com/kubernetes/examples/pull/278,https://api.github.com/repos/kubernetes/examples/issues/278,Fix cpu-manager README links,The links and paths used as argument in the ```kubectl``` command were outdated.,closed,True,2018-10-10 03:37:38,2018-10-13 13:32:09
examples,disrani-px,https://github.com/kubernetes/examples/pull/279,https://api.github.com/repos/kubernetes/examples/issues/279,Fix mountpath for cassandra,,closed,True,2018-10-11 04:50:33,2018-10-11 20:02:02
examples,ebriand,https://github.com/kubernetes/examples/pull/280,https://api.github.com/repos/kubernetes/examples/issues/280,change simple nginx example to use kubectl create instead of kubectl run,"Fix #277 

I updated the simple nginx example to only use not deprecated commands.",closed,True,2018-10-12 12:45:03,2018-10-13 13:30:53
examples,AdamDang,https://github.com/kubernetes/examples/pull/281,https://api.github.com/repos/kubernetes/examples/issues/281,Update README.md,Fix some typos to improve this document.,closed,True,2018-10-25 12:18:16,2018-10-25 14:34:02
examples,gouki777,https://github.com/kubernetes/examples/issues/282,https://api.github.com/repos/kubernetes/examples/issues/282,How to write data?,"hi 
i look you kubernetes-redis-controller. but I have a question.
how do read redis-data?   how do write redis-master data? 

I write same data in kubernetes-redis-master.
set key1 111;

[root ~]# kubectl get po,svc
NAME                             READY     STATUS    RESTARTS   AGE
pod/redis-6zgld                  1/1       Running   0          16m
pod/redis-ldbzl                  1/1       Running   0          2h
pod/redis-sentinel-4dgwc         1/1       Running   0          2h
pod/redis-sentinel-7bxsh         1/1       Running   0          2h
pod/redis-sentinel-nzbjs         1/1       Running   0          2h
pod/redis-wj8kj                  1/1       Running   0          13m
NAME                     TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)     AGE
service/kubernetes       ClusterIP   10.96.0.1      <none>        443/TCP     138d
service/redis-sentinel   ClusterIP   10.98.6.156    <none>        26379/TCP   2h

[root ~]# telnet 10.98.6.156 26379
Trying 10.98.6.156...
Connected to 10.98.6.156.
Escape character is '^]'.
ping
+PONG
SET eee 444
-ERR unknown command 'SET'
SELECT index
-ERR unknown command 'SELECT'
keys *
-ERR unknown command 'keys'



",closed,False,2018-10-26 10:09:45,2018-11-12 07:15:15
examples,reegnz,https://github.com/kubernetes/examples/pull/283,https://api.github.com/repos/kubernetes/examples/issues/283,Use new env vars to parameterize selenium nodes,"The new variable names got introduced about 10 months ago and it was
indicated that they will be used in the ling term instead of the older,
less descriptive variable names.",closed,True,2018-10-30 16:57:47,2019-03-08 11:51:30
examples,reegnz,https://github.com/kubernetes/examples/pull/284,https://api.github.com/repos/kubernetes/examples/issues/284,Bump image versions in selenium example,,closed,True,2018-10-30 17:01:50,2019-01-31 09:47:42
examples,reegnz,https://github.com/kubernetes/examples/issues/285,https://api.github.com/repos/kubernetes/examples/issues/285,Inconsistent indenting of yaml files,"Looking all over the repository, there are various styles of yaml found.
My concern is not the validity of those files, but one of consistency.

There are tools like yamllint that can be used to keep yaml style consistent.

I suggest using yamllint with it's default ruleset to check for style consistency.
An alternative style config would also be acceptable, but for readabilities sake a consistent style should be used in all examples.

I would be up for the task of providing build-time checks of such a linting setup.",closed,False,2018-10-30 17:17:37,2019-03-29 18:53:25
examples,reegnz,https://github.com/kubernetes/examples/pull/286,https://api.github.com/repos/kubernetes/examples/issues/286,Remove trailing whitespaces,,closed,True,2018-10-30 18:35:35,2019-01-10 18:26:50
examples,rroopreddy,https://github.com/kubernetes/examples/issues/287,https://api.github.com/repos/kubernetes/examples/issues/287,Cassandra GetEndPoints fails with return value Java_com_sun_jna_Native_getStringBytes,"I seem to get 2 out of 3 cassandra nodes start but the 3rd one fails with the following. Seems to be a problem with the 'main.go' code. Any help is appreciated

```
INFO  17:32:35 get endpoint params: default, cassandra, cassandra-0.cassandra.default.svc.cluster.local
**INFO  17:32:35 cassandra endpoint data: Java_com_sun_jna_Native_getStringBytes**
ERROR 17:32:35 unexpected error building cassandra seeds: Unexpected character ('J' (code 74)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: java.io.StringReader@5fd4f8f5; line: 1, column: 2]
Exception (org.apache.cassandra.exceptions.ConfigurationException) encountered during startup: The seed provider lists no seeds.
The seed provider lists no seeds.
ERROR 17:32:35 Exception encountered during startup: The seed provider lists no seeds.
```

other two have the correct data

```
INFO  17:30:57 get endpoint params: default, cassandra, cassandra-0.cassandra.default.svc.cluster.local
**INFO  17:30:58 cassandra endpoint data: {""ips"":[""cassandra-0.cassandra.default.svc.cluster.local""]}**
```

I instrumented the 'KubernetesSeedProvider.java' with two additional 'logger.info' lines to get this data

``` java
logger.info(""get endpoint params: "" + namespace + "", "" + service + "", "" + initialSeeds);
String data = go.GetEndpoints(namespace, service, initialSeeds);
logger.info(""cassandra endpoint data: "" + data);
```",open,False,2018-11-04 17:50:48,2019-03-22 02:51:09
examples,mooncak,https://github.com/kubernetes/examples/pull/288,https://api.github.com/repos/kubernetes/examples/issues/288,"Fix typos: conecepts->concepts, lauched->launched","Fix typos: conecepts->concepts, lauched->launched",closed,True,2018-11-10 12:42:22,2018-11-10 18:10:55
examples,mario-mazo,https://github.com/kubernetes/examples/pull/289,https://api.github.com/repos/kubernetes/examples/issues/289,Updated selenium hub health probes to recommended endpoints,"Probing the hub on `/grid/console` might end up in constant restarts due to locks.
the recommended way is using `/wd/hub/status`.
Even the helm chart updated this
https://github.com/helm/charts/pull/7554
",closed,True,2018-11-10 19:47:03,2018-11-10 19:56:48
examples,mario-mazo,https://github.com/kubernetes/examples/pull/290,https://api.github.com/repos/kubernetes/examples/issues/290,Updated selenium hub health probes to recommended endpoints,"Probing the hub on `/grid/console` might end up in constant restarts due to locks.
the recommended way is using `/wd/hub/status`.
Even the helm chart updated this
https://github.com/helm/charts/pull/7554",closed,True,2018-11-10 20:07:25,2019-01-10 16:44:59
examples,humblec,https://github.com/kubernetes/examples/pull/291,https://api.github.com/repos/kubernetes/examples/issues/291,Add `customepnameprefix` storage class option.,"customepnameprefix has been added to glusterfs storage class
via PR# https://github.com/kubernetes/kubernetes/pull/69419
This patch add its documentation to example files and README.

Signed-off-by: hchiramm <hchiramm@redhat.com>",closed,True,2018-11-12 06:17:44,2018-11-26 21:04:56
examples,toshiiw,https://github.com/kubernetes/examples/issues/292,https://api.github.com/repos/kubernetes/examples/issues/292,example/staging/mysql-cinder-pd is outdated,"It says to start kubelet with --cloud-provider=openstack but that option is deprecated.

The prerequisites section can just refer to 
https://github.com/kubernetes/cloud-provider-openstack/blob/master/docs/

The example section may still hold true. (I have no idea)",open,False,2018-11-13 07:50:54,2019-03-14 06:49:57
examples,meirhazonAnyVision,https://github.com/kubernetes/examples/issues/293,https://api.github.com/repos/kubernetes/examples/issues/293,Redis SVC Question,"Hello,
Can you please explain how should application connect to the redis?
There is no service for connecting to port 6379 on the redis nodes?
Can you please explain?
Thanks so much,
Meir ",open,False,2018-12-11 09:56:01,2019-03-27 10:33:47
examples,runzexia,https://github.com/kubernetes/examples/pull/294,https://api.github.com/repos/kubernetes/examples/issues/294,update redis image address,,closed,True,2019-01-18 03:47:31,2019-01-22 15:57:56
examples,IronPan,https://github.com/kubernetes/examples/pull/295,https://api.github.com/repos/kubernetes/examples/issues/295,Use fixed NFS dns name,,closed,True,2019-01-18 09:05:53,2019-02-13 12:12:34
examples,rlenferink,https://github.com/kubernetes/examples/pull/296,https://api.github.com/repos/kubernetes/examples/issues/296,Update OWNERS files to include link to docs,Included a link to the OWNERS docs in the OWNERS file itself,closed,True,2019-01-30 19:23:38,2019-01-30 23:45:01
examples,AlexProfi,https://github.com/kubernetes/examples/issues/297,https://api.github.com/repos/kubernetes/examples/issues/297,Redis sentinel example,"Hi
I try to run redis sentinel by this tutor
https://github.com/kubernetes/examples/tree/master/staging/storage/redis

and get that there is no master after I delete pod redis-master

```
redis-9kmr9                            1/1       Running   1          4m
redis-p2thm                            1/1       Running   2          4m
redis-sentinel-8ghzb                   1/1       Running   0          4m
redis-sentinel-lwhhs                   1/1       Running   0          4m
redis-sentinel-nwrlc                   1/1       Running   0          4m
redis-xq2td                            1/1       Running   0          2m
reloader-b4c8c8954-dc8l5               1/1       Running   1          1d
rsyslog-example-app-86d86589bc-mlgp7   1/1       Running   5          3d
rsyslog-server-86f8bfcf9-d2x72         1/1       Running   5          3d
web-0                                  1/1       Running   0          9h
web-1                                  1/1       Running   1          9h
root@hb-master01:/home/master01/configs/host/k8s# kubectl exec -it redis-xq2td  -- redis-cli info|grep ^role
role:slave
```
I use this configmaps

```
apiVersion: v1
kind: ConfigMap
data:
  redis-config: |
   
    daemonize no

   
    pidfile /var/run/redis.pid

 
    port 6379

  
    tcp-backlog 65536

 

    bind 0.0.0.0

 
    timeout 0

    # TCP keepalive.
 
    tcp-keepalive 60

  
    loglevel notice

   
    databases 16
    save 900 1
    save 300 10
    save 60 10000 
    stop-writes-on-bgsave-error yes

    rdbcompression yes

    rdbchecksum yes

    # The filename where to dump the DB
    dbfilename dump.rdb

  
    dir ""./""

   
    slaveof %master-ip% %master-port%

  
    slave-serve-stale-data yes

   
    slave-read-only yes

    repl-diskless-sync no

   
    repl-diskless-sync-delay 5

  
    # repl-ping-slave-period 10

  
    repl-disable-tcp-nodelay no

  
    slave-priority 100

 
    # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory
    # is reached. You can select among five behaviors:
  
    appendonly yes

    # The name of the append only file (default: ""appendonly.aof"")

    appendfilename ""appendonly.aof""


    no-appendfsync-on-rewrite no

  

    auto-aof-rewrite-percentage 100
    auto-aof-rewrite-min-size 64mb

    aof-load-truncated yes

    ################################ LUA SCRIPTING  ###############################


    lua-time-limit 5000

 
    slowlog-log-slower-than 10000

    # There is no limit to this length. Just be aware that it will consume memory.
    # You can reclaim memory used by the slow log with SLOWLOG RESET.
    slowlog-max-len 128

    latency-monitor-threshold 0

    notify-keyspace-events """"

    hash-max-ziplist-entries 512
    hash-max-ziplist-value 64
    list-max-ziplist-entries 512
    list-max-ziplist-value 64
    set-max-intset-entries 512

    zset-max-ziplist-entries 128
    zset-max-ziplist-value 64
    hll-sparse-max-bytes 3000
    activerehashing yes
    client-output-buffer-limit normal 0 0 0
    client-output-buffer-limit slave 256mb 64mb 60
    client-output-buffer-limit pubsub 32mb 8mb 60
    hz 10

    # When a child rewrites the AOF file, if the following option is enabled
    # the file will be fsync-ed every 32 MB of data generated. This is useful
    # in order to commit the file to the disk more incrementally and avoid
    # big latency spikes.
    aof-rewrite-incremental-fsync yes
    logfile /data/log.log
    maxmemory-policy allkeys-lru

metadata:
   name: redis-slave-conf
   namespace: default


apiVersion: v1
kind: ConfigMap
data:
  redis-config: |
    daemonize no

    pidfile /var/run/redis.pid
    port 6379
    tcp-backlog 65536

    bind 0.0.0.0
    timeout 0
    tcp-keepalive 60
    loglevel notice
    databases 16

    save 900 1
    save 300 10
    save 60 10000
    stop-writes-on-bgsave-error yes
    rdbcompression yes
    rdbchecksum yes

    # The filename where to dump the DB
    dbfilename dump.rdb
    dir /redis-master-data

    slave-serve-stale-data yes

    slave-read-only yes
    repl-diskless-sync no

    repl-diskless-sync-delay 5
    # If you select ""yes"" Redis will use a smaller number of TCP packets and
    repl-disable-tcp-nodelay no
    slave-priority 100
    appendonly yes

    # The name of the append only file (default: ""appendonly.aof"")

    appendfilename ""appendonly.aof""
    appendfsync everysec
    no-appendfsync-on-rewrite no

    auto-aof-rewrite-percentage 100
    auto-aof-rewrite-min-size 64mb

    aof-load-truncated yes

    lua-time-limit 5000

    slowlog-log-slower-than 10000
    slowlog-max-len 128
    latency-monitor-threshold 0

    notify-keyspace-events """"

    hash-max-ziplist-entries 512
    hash-max-ziplist-value 64
    list-max-ziplist-entries 512
    list-max-ziplist-value 64
    set-max-intset-entries 512
    zset-max-ziplist-entries 128
    zset-max-ziplist-value 64
    hll-sparse-max-bytes 3000
    activerehashing yes

    client-output-buffer-limit normal 0 0 0
    client-output-buffer-limit slave 256mb 64mb 60
    client-output-buffer-limit pubsub 32mb 8mb 60
    hz 10
    aof-rewrite-incremental-fsync yes
    logfile /data/log.log
    maxmemory-policy allkeys-lru

metadata:
   name: redis-master-conf
   namespace: default
```


And this yaml files for describe redis configs
```
apiVersion: v1
kind: Pod
metadata:
  labels:
    name: redis
    redis-sentinel: ""true""
    role: master
  name: redis-master
spec:
  volumes:
    - name: master-config
      configMap:
        name: redis-master-conf
        items:
        - key: redis-config
          path: redis.conf
    - name: slave-config
      configMap:
        name: redis-slave-conf
        items:
        - key: redis-config
          path: redis.conf
    - name: data
      emptyDir: {}
  containers:
    - name: master
      image: k8s.gcr.io/redis:v1
      env:
        - name: MASTER
          value: ""true""
      ports:
        - containerPort: 6379
#      resources:
#        limits:
#          cpu: ""90""
      volumeMounts:
        - mountPath: /redis-master-data
          name: data
        - name: master-config
          mountPath: /redis-master
        - name: slave-config
          mountPath: /redis-slave
    - name: sentinel
      image: k8s.gcr.io/redis:v1
      env:
        - name: SENTINEL
          value: ""true""
      ports:
        - containerPort: 26379


apiVersion: v1
kind: ReplicationController
metadata:
  name: redis
spec:
  replicas: 1
  selector:
    name: redis
  template:
    metadata:
      labels:
        name: redis
        role: master
    spec:
      containers:
      - name: redis
        image: k8s.gcr.io/redis:v1
        ports:
        - containerPort: 6379
#        resources:
#          limits:
#            cpu: ""90""
        volumeMounts:
        - mountPath: /redis-master-data
          name: data
        - name: master-config
          mountPath: /redis-master
        - name: slave-config
          mountPath: /redis-slave
      volumes:
        - name: data
        - name: master-config
          configMap:
            name: redis-master-conf
            items:
            - key: redis-config
              path: redis.conf
        - name: slave-config
          configMap:
            name: redis-slave-conf
            items:
            - key: redis-config
              path: redis.conf

```

How to fix it?
And how connect to this master to set data ? I need permanent name for it for programming access by host name or name of service",open,False,2019-01-30 21:00:59,2019-01-30 21:32:55
examples,diemtvu,https://github.com/kubernetes/examples/issues/298,https://api.github.com/repos/kubernetes/examples/issues/298,Allow setting CASSANDRA_LISTEN_ADDRESS via environment,"In some set up, we want to set `listen_address` to use localhost. Is this possible to allow setting it via environment variable. 

For example, this change in `run.sh` should be sufficient:
```
CASSANDRA_LISTEN_ADDRESS=${CASSANDRA_LISTEN_ADDRESS:-""localhost""}
```

or , if we want to be backward compatible

```
CASSANDRA_LISTEN_ADDRESS=${CASSANDRA_LISTEN_ADDRESS:-${POD_ID:--$HOSTNAME}}
```",open,False,2019-01-31 17:53:44,2019-01-31 17:53:44
examples,ahmetb,https://github.com/kubernetes/examples/pull/299,https://api.github.com/repos/kubernetes/examples/issues/299,Remove ahmetb from OWNERS,"Sadly I no longer have time to help maintain this repo and have not been able
to return to the review requests timely. It's better I don't get assigned to
these.",closed,True,2019-02-13 22:01:34,2019-02-13 22:49:34
examples,AnuragkAnkur,https://github.com/kubernetes/examples/issues/300,https://api.github.com/repos/kubernetes/examples/issues/300,What is the user name of vnc server?,"Hi ,

I have got following deployment configuration  and i am running it on a kubernetes pod. I am trying to connect to the VNC server in the pod to view the activity of my running test. 
I have enabled the port forwarding : kubectl port-forward $POD_NAME 5900:5900 
and trying to connect to it using VNCViewer. It is asking me for the username. What could be the user name ? 
Password is mentioned on the website:  'secret'

Yaml: 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: selenium-node-chrome
  labels:
    app: selenium-node-chrome
spec:
  replicas: 2
  selector:
    matchLabels:
      app: selenium-node-chrome
  template:
    metadata:
      labels:
        app: selenium-node-chrome
    spec:
      containers:
      - name: selenium-node-chrome
        image: selenium/node-chrome-debug:3.141
        ports:
          - containerPort: 5900
        env:
          - name: HUB_PORT_4444_TCP_ADDR
            value: ""selenium-hub""
          - name: HUB_PORT_4444_TCP_PORT
            value: ""4444""
        resources:
          limits:
            memory: ""1000Mi""
            cpu: "".5""


",closed,False,2019-03-07 08:47:54,2019-03-07 11:15:51
examples,joelsmith,https://github.com/kubernetes/examples/pull/301,https://api.github.com/repos/kubernetes/examples/issues/301,Update embargo doc link in SECURITY_CONTACTS and change PST to PSC,See https://github.com/kubernetes/security/issues/8 for more information,closed,True,2019-03-08 18:04:54,2019-03-09 11:25:28
examples,bclau,https://github.com/kubernetes/examples/pull/302,https://api.github.com/repos/kubernetes/examples/issues/302,Fixes python 3 support for cluster-dns images scripts,"The cluster-dns images' scripts are only working with Python 2.

Considering that Python 2 support will be dropped in 2020, it
would be a good idea to transition towards Python 3 support.

This commit the cluster-dns Python scripts to work on both
Python versions.",closed,True,2019-03-20 10:52:29,2019-03-20 11:12:25
examples,bclau,https://github.com/kubernetes/examples/pull/303,https://api.github.com/repos/kubernetes/examples/issues/303,cluster-dns: Writes bytes on response,"In Python3, strings are unicode, while in Python2 they're bytes. This causes an issue when writing the request response, since it expects bytes.",open,True,2019-03-20 14:20:22,2019-03-20 17:17:15
examples,mmumshad,https://github.com/kubernetes/examples/pull/304,https://api.github.com/repos/kubernetes/examples/issues/304,Fix service dns name,Should be http://dns-backend.development.svc.cluster.local:8000 instead of http://dns-backend.development.cluster.local:8000,open,True,2019-03-21 04:10:34,2019-03-21 15:36:46
examples,bsalamat,https://github.com/kubernetes/examples/pull/305,https://api.github.com/repos/kubernetes/examples/issues/305,Improve scheduler policy configuration examples,"
/sig scheduling",open,True,2019-03-25 19:20:02,2019-03-25 19:21:37
examples,rdxmb,https://github.com/kubernetes/examples/issues/306,https://api.github.com/repos/kubernetes/examples/issues/306,FeatureRequest: StatefulSet for Redis-Cluster,"Hi,

the redis-example works very fine for me. However, I just changed it to a statefulSet, which has redis and sentinel in one pod.
The master in my case is defined by hostname `redis-0`, so a manual bootstrap is not necessary. If you like to have this for an official example, I could create a PR.
(This will also change the condition for the Master in [Dockerfile](https://github.com/kubernetes/examples/blob/master/staging/storage/redis/image/run.sh#L75) - do not know if it is built by this repo and what to use as tag for the [image](https://github.com/kubernetes/examples/blob/master/staging/storage/redis/redis-master.yaml#L12) then.)

(follow up https://github.com/kubernetes/examples/issues/173)",open,False,2019-03-27 10:42:07,2019-03-27 10:43:53
examples,Stono,https://github.com/kubernetes/examples/issues/307,https://api.github.com/repos/kubernetes/examples/issues/307,NFS mounts are broken when NFS pod restarts,"Hey, 
We've been following this example to run nfs but we have a situation when the nfs pod restarts, the clients have stale mounts and those pods need restarting too.

Please see: https://github.com/kubernetes/kubernetes/issues/75918 

Any advice would be great.",open,False,2019-03-30 16:23:20,2019-03-30 16:27:58
