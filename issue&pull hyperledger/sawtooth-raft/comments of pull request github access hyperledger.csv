pull request url html,pull request url,body,commit_id,create at,id,diff_hunk,position,update at,url,html url,user
https://github.com/hyperledger/sawtooth-raft/pull/65,https://github.com/hyperledger/sawtooth-raft/pull/65,2019,8537fd01254688861ae474ab1dfb4dc3d9574d07,2019-03-28 17:06:59,270107306,"@@ -0,0 +1,362 @@
+# Copyright 2018 Intel Corporation",,2019-04-02 05:22:07,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/270107306,https://github.com/hyperledger/sawtooth-raft/pull/65#discussion_r270107306,agunde406
https://github.com/hyperledger/sawtooth-raft/pull/65,https://github.com/hyperledger/sawtooth-raft/pull/65,2019,8537fd01254688861ae474ab1dfb4dc3d9574d07,2019-03-28 17:07:16,270107457,"@@ -0,0 +1,37 @@
+# Copyright 2018 Intel Corporation",,2019-04-02 05:22:07,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/270107457,https://github.com/hyperledger/sawtooth-raft/pull/65#discussion_r270107457,agunde406
https://github.com/hyperledger/sawtooth-raft/pull/63,https://github.com/hyperledger/sawtooth-raft/pull/63,"Instead of making this mutable and setting it later, you can combine some of this code:
`let leader_state_publishing_this_block = match self.leader_state { ... };`
`if leader_state_publishing_this_block { ... }`
`if leader_state_publishing_this_block || self.follower_state.is_some() { ... }`",5f8a2c7f4fa8846e76c8fd50e8fa468ee791a4b5,2019-03-26 14:14:22,269123693,"@@ -99,6 +99,7 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
     }
 
     pub fn on_block_new(&mut self, block: Block) {
+        let mut leader_state_publishing_this_block = false;",4,2019-03-26 14:15:46,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/269123693,https://github.com/hyperledger/sawtooth-raft/pull/63#discussion_r269123693,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/63,https://github.com/hyperledger/sawtooth-raft/pull/63,"This could be done. Do you see any problem in using mutable variable. Or do you mean the approach you suggested above is more idiomatic in rust.
This fix was done in order to handle a case where a follower becomes a leader (Node 1) and previous leader (Node 2) had sent a new block (say Block 1)  just before changing to follower. Node 2 received Block 1 later. At same time Node 2 also has started building a block (Block 2) on top of previous head same as Block 1 previous head. So in this scenario Node 2  will have 2 blocks (Block 1 and Block 2) added to queue with same block number but different block_id , both pointing to same previous head. Leader node should accept only those blocks published by the leader
",5f8a2c7f4fa8846e76c8fd50e8fa468ee791a4b5,2019-03-26 14:28:12,269131361,"@@ -99,6 +99,7 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
     }
 
     pub fn on_block_new(&mut self, block: Block) {
+        let mut leader_state_publishing_this_block = false;",4,2019-03-26 14:31:52,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/269131361,https://github.com/hyperledger/sawtooth-raft/pull/63#discussion_r269131361,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/63,https://github.com/hyperledger/sawtooth-raft/pull/63,"So the issue is that a leader node publishes a new block before stepping down, and the new leader also publishes a block at the same height. Is that correct? If so, then I think the better way to solve this problem is to not publish (finalize) a block until after the node's state is updated. This should be pretty simple to accomplish by moving the call to `node.check_publish` out of the `node.tick` method and instead call it from `engine.rs` after the call to `process_ready`.",5f8a2c7f4fa8846e76c8fd50e8fa468ee791a4b5,2019-03-26 14:35:52,269135545,"@@ -99,6 +99,7 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
     }
 
     pub fn on_block_new(&mut self, block: Block) {
+        let mut leader_state_publishing_this_block = false;",4,2019-03-26 14:35:52,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/269135545,https://github.com/hyperledger/sawtooth-raft/pull/63#discussion_r269135545,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/63,https://github.com/hyperledger/sawtooth-raft/pull/63,"That's right. I think its good for leader node to accept only the blocks it publishes. So making this explicit check in code is better. Even if we rely on order of calling ```node.check_publish``` after ```process_ready```,  can the new block arrive other nodes at any time based on the network delays ? What if block was published and then leader changed to follower in next round and block took long time to reach another node which became leader.",5f8a2c7f4fa8846e76c8fd50e8fa468ee791a4b5,2019-03-26 14:49:16,269143070,"@@ -99,6 +99,7 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
     }
 
     pub fn on_block_new(&mut self, block: Block) {
+        let mut leader_state_publishing_this_block = false;",4,2019-03-26 14:52:03,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/269143070,https://github.com/hyperledger/sawtooth-raft/pull/63#discussion_r269143070,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/63,https://github.com/hyperledger/sawtooth-raft/pull/63,"I agree that implementing checks for received blocks is a good idea. But I think there should probably be a broader fix for this issue. There are various situations where multiple blocks could be received at the same block height: network delays, bad-actors (e.g. some random follower publishes a block), etc. Also, part of the consensus engine's job is to decide on **all** blocks it receives, to either accept or reject them. So if the node gets a bad block, it needs to tell the validator to reject it. These things should all be considered as a complete solution.",5f8a2c7f4fa8846e76c8fd50e8fa468ee791a4b5,2019-03-26 15:22:20,269161504,"@@ -99,6 +99,7 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
     }
 
     pub fn on_block_new(&mut self, block: Block) {
+        let mut leader_state_publishing_this_block = false;",4,2019-03-26 15:22:20,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/269161504,https://github.com/hyperledger/sawtooth-raft/pull/63#discussion_r269161504,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/63,https://github.com/hyperledger/sawtooth-raft/pull/63,"See the ""API contracts"" section of the consensus API RFC: https://github.com/hyperledger/sawtooth-rfcs/blob/master/text/0004-consensus-api.md",5f8a2c7f4fa8846e76c8fd50e8fa468ee791a4b5,2019-03-26 15:25:10,269163056,"@@ -99,6 +99,7 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
     }
 
     pub fn on_block_new(&mut self, block: Block) {
+        let mut leader_state_publishing_this_block = false;",4,2019-03-26 15:25:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/269163056,https://github.com/hyperledger/sawtooth-raft/pull/63#discussion_r269163056,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/63,https://github.com/hyperledger/sawtooth-raft/pull/63,"I thought we are not solving for all bad actor cases as Raft is not BFT though we can still consider cases where it can be handled with minimal checks. I've considered only case where block is received at same block height due to network delays. Do you mean we should also call fail_block() when leader receives block at same height not published by it (to avoid any kind of memory leaks in validator).  And I guess same should be done at follower end when it receives updated log entry from leader. So if a follower commits a log entry, fail all blocks which is not yet committed and whose height is less than recent committed block ? ",5f8a2c7f4fa8846e76c8fd50e8fa468ee791a4b5,2019-03-26 16:18:19,269193039,"@@ -99,6 +99,7 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
     }
 
     pub fn on_block_new(&mut self, block: Block) {
+        let mut leader_state_publishing_this_block = false;",4,2019-03-26 16:18:19,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/269193039,https://github.com/hyperledger/sawtooth-raft/pull/63#discussion_r269193039,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,This can be rewritten more simply: `if let Some(FollowerState::Committing(ref block_id)) = self.follower_state { ... }`,3b360adae448649faceace5f9242c2226003c542,2019-03-20 13:57:30,267350651,"@@ -244,6 +244,18 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
+            //check if we stepped up as leader from follower state
+            if self.follower_state.is_some() {",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267350651,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267350651,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,"Minor issue, but please keep comment formatting consistent (space after `//`, start with capital letter)",3b360adae448649faceace5f9242c2226003c542,2019-03-20 13:58:19,267351104,"@@ -244,6 +244,18 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
+            //check if we stepped up as leader from follower state",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267351104,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267351104,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,Updated the commit,3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:07:47,267420663,"@@ -244,6 +244,18 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
+            //check if we stepped up as leader from follower state
+            if self.follower_state.is_some() {",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267420663,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267420663,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,Updated the commit,3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:07:54,267420718,"@@ -244,6 +244,18 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
+            //check if we stepped up as leader from follower state",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267420718,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267420718,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,"This can probably also be combined with the block below. Basically if the leader state is none, you need to set the leader state and unset the follower state. So what you should end up with is `if self.leader_state.is_none() { if let Some(FollowerState::Committing(ref block_id)) = self.follower_state { set leader state to committing; } else { set leader state to building; init block; } set follower state to none; }`",3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:14:06,267423915,"@@ -244,10 +244,17 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
+            // Check if we stepped up as leader from follower state
+            if let Some(FollowerState::Committing(ref block_id)) = self.follower_state {",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267423915,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267423915,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,Yes. This could be combined. Updated the commit,3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:28:54,267431140,"@@ -244,10 +244,17 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
+            // Check if we stepped up as leader from follower state
+            if let Some(FollowerState::Committing(ref block_id)) = self.follower_state {",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267431140,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267431140,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,Does the other `FollowerState` values require any special actions? Or is it safe to just start a new block in those cases?,3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:31:20,267432293,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state
+                if let Some(FollowerState::Committing(ref block_id)) = self.follower_state {",9,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267432293,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267432293,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,Follower states is either Idle or Committing or None. No other cases I came across yet which needs special handling other than when follower transitions to leader when it is in Committing state.  ,3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:36:22,267434776,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state
+                if let Some(FollowerState::Committing(ref block_id)) = self.follower_state {",9,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267434776,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267434776,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,"I think you mean ""committing state""",3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:42:46,267437793,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267437793,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267437793,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,"The other FollowerState is Idle. There's a case where the node received raft log entry, added it to the log, but is not committed. Log entry is not committed because leader which proposed the block has not yet confirmed about its commit status.
The new leader election can safely change leader status in this case.  Because raft will take care if the log entry needs consideration.",3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:42:49,267437823,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state
+                if let Some(FollowerState::Committing(ref block_id)) = self.follower_state {",9,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267437823,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267437823,arsulegai
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,There are two spaces after the `else`,3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:43:03,267437919,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state
+                if let Some(FollowerState::Committing(ref block_id)) = self.follower_state {
+                    debug!(""Follower({:?}) became leader while it was in committing state"",
+                        self.peer_id);
+                    self.leader_state = Some(LeaderState::Committing(block_id.clone()));
+                } else  {",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267437919,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267437919,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,"I meant ""Check if we stepped up as leader from follower while in committing state"".  I can udpate the comment if its fine ?",3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:51:31,267441648,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267441648,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267441648,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,Will Update. Does lint (rust fmt) complain on this ?,3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:53:47,267442770,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state
+                if let Some(FollowerState::Committing(ref block_id)) = self.follower_state {
+                    debug!(""Follower({:?}) became leader while it was in committing state"",
+                        self.peer_id);
+                    self.leader_state = Some(LeaderState::Committing(block_id.clone()));
+                } else  {",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267442770,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267442770,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,"I believe rustfmt does, yes",3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:55:46,267443719,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state
+                if let Some(FollowerState::Committing(ref block_id)) = self.follower_state {
+                    debug!(""Follower({:?}) became leader while it was in committing state"",
+                        self.peer_id);
+                    self.leader_state = Some(LeaderState::Committing(block_id.clone()));
+                } else  {",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267443719,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267443719,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,"Yep, that's fine",3b360adae448649faceace5f9242c2226003c542,2019-03-20 16:55:58,267443796,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state",,2019-03-20 17:04:45,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267443796,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267443796,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,Updated commit,3b360adae448649faceace5f9242c2226003c542,2019-03-20 17:06:47,267448710,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state",,2019-03-20 17:06:48,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267448710,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267448710,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/61,https://github.com/hyperledger/sawtooth-raft/pull/61,Updated commit,3b360adae448649faceace5f9242c2226003c542,2019-03-20 17:06:55,267448790,"@@ -244,12 +244,20 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
         let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
         if is_leader {
-            // We just became the leader, so we need to start building a block
+            // We just became the leader
             if self.leader_state.is_none() {
-                debug!(""Leader({:?}) became leader, intializing block"", self.peer_id);
+                // Check if we stepped up as leader from follower state
+                if let Some(FollowerState::Committing(ref block_id)) = self.follower_state {
+                    debug!(""Follower({:?}) became leader while it was in committing state"",
+                        self.peer_id);
+                    self.leader_state = Some(LeaderState::Committing(block_id.clone()));
+                } else  {",,2019-03-20 17:06:56,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267448790,https://github.com/hyperledger/sawtooth-raft/pull/61#discussion_r267448790,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/60,https://github.com/hyperledger/sawtooth-raft/pull/60,This `if let Some(block) = status.block.clone()` can probably be removed since `block` doesn't get used at all with this change.,54e5a3b1e27ca50956f71186fd7c052c48e78ce4,2019-03-20 14:01:14,267352751,"@@ -93,7 +93,7 @@ impl BlockQueue {
         if let Some(&(ref block_id, _)) = self.commit_queue.front() {
             if let Some(status) = self.validator_backlog.get(block_id) {
                 if let Some(block) = status.block.clone() {",,2019-03-20 15:56:09,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267352751,https://github.com/hyperledger/sawtooth-raft/pull/60#discussion_r267352751,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/60,https://github.com/hyperledger/sawtooth-raft/pull/60,"Yes, and also chain_head is no more used in this function.",54e5a3b1e27ca50956f71186fd7c052c48e78ce4,2019-03-20 14:40:33,267373575,"@@ -93,7 +93,7 @@ impl BlockQueue {
         if let Some(&(ref block_id, _)) = self.commit_queue.front() {
             if let Some(status) = self.validator_backlog.get(block_id) {
                 if let Some(block) = status.block.clone() {",,2019-03-20 15:56:09,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/267373575,https://github.com/hyperledger/sawtooth-raft/pull/60#discussion_r267373575,arsulegai
https://github.com/hyperledger/sawtooth-raft/pull/58,https://github.com/hyperledger/sawtooth-raft/pull/58,"Can we use just 'rustfmt' and 'clippy' here instead of the *-preview versions? Historically we needed the preview versions, but it probably is no longer necessary.",0c9fe110513561ba98bbe9d04a17be7e7dae6fc9,2019-03-18 17:10:16,266548783,"@@ -33,12 +33,14 @@ RUN curl -OLsS https://github.com/google/protobuf/releases/download/v3.5.1/proto
  && unzip protoc-3.5.1-linux-x86_64.zip -d protoc3 \
  && rm protoc-3.5.1-linux-x86_64.zip
 
+ENV PATH=$PATH:/protoc3/bin:/project/sawtooth-raft/bin:/root/.cargo/bin \
+    CARGO_INCREMENTAL=0
+
 RUN curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init \
  && chmod +x /usr/bin/rustup-init \
- && rustup-init -y
-
-ENV PATH=$PATH:/protoc3/bin:/project/sawtooth-core/bin:/root/.cargo/bin \
-    CARGO_INCREMENTAL=0
+ && rustup-init -y \
+ && rustup component add rustfmt-preview \",,2019-03-28 09:51:51,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/266548783,https://github.com/hyperledger/sawtooth-raft/pull/58#discussion_r266548783,vaporos
https://github.com/hyperledger/sawtooth-raft/pull/58,https://github.com/hyperledger/sawtooth-raft/pull/58,Ok,0c9fe110513561ba98bbe9d04a17be7e7dae6fc9,2019-03-18 17:25:18,266555311,"@@ -33,12 +33,14 @@ RUN curl -OLsS https://github.com/google/protobuf/releases/download/v3.5.1/proto
  && unzip protoc-3.5.1-linux-x86_64.zip -d protoc3 \
  && rm protoc-3.5.1-linux-x86_64.zip
 
+ENV PATH=$PATH:/protoc3/bin:/project/sawtooth-raft/bin:/root/.cargo/bin \
+    CARGO_INCREMENTAL=0
+
 RUN curl https://sh.rustup.rs -sSf > /usr/bin/rustup-init \
  && chmod +x /usr/bin/rustup-init \
- && rustup-init -y
-
-ENV PATH=$PATH:/protoc3/bin:/project/sawtooth-core/bin:/root/.cargo/bin \
-    CARGO_INCREMENTAL=0
+ && rustup-init -y \
+ && rustup component add rustfmt-preview \",,2019-03-28 09:51:51,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/266555311,https://github.com/hyperledger/sawtooth-raft/pull/58#discussion_r266555311,arsulegai
https://github.com/hyperledger/sawtooth-raft/pull/58,https://github.com/hyperledger/sawtooth-raft/pull/58,Should this be fixed instead of allowed?,0c9fe110513561ba98bbe9d04a17be7e7dae6fc9,2019-03-22 19:48:30,268316370,"@@ -93,78 +88,95 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             leader_state: None,
             follower_state: Some(FollowerState::Idle),
             block_queue: BlockQueue::new(),
-            raft_id_to_peer_id: peers.into_iter().map(|peer_id| (peer_id_to_raft_id(&peer_id), peer_id)).collect(),
+            raft_id_to_peer_id: peers
+                .into_iter()
+                .map(|peer_id| (peer_id_to_raft_id(&peer_id), peer_id))
+                .collect(),
             period,
         }
     }
 
     pub fn on_block_new(&mut self, block: Block) {
         if match self.leader_state {
-            Some(LeaderState::Publishing(ref block_id)) => {
-                block_id == &block.block_id
-            },
+            Some(LeaderState::Publishing(ref block_id)) => block_id == &block.block_id,
             _ => false,
         } {
-            debug!(""Leader({:?}) transition to Validating block {:?}"", self.peer_id, block.block_id);
+            debug!(
+                ""Leader({:?}) transition to Validating block {:?}"",
+                self.peer_id, block.block_id
+            );
             self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
         }
 
         debug!(""Block has been received: {:?}"", &block);
         self.block_queue.block_new(block.clone());
 
-        self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
+        self.service
+            .check_blocks(vec![block.block_id])
+            .expect(""Failed to send check blocks"");
     }
 
     pub fn on_block_valid(&mut self, block_id: BlockId) {
         // Handle out of order new/valid updates
         debug!(""Block has been validated: {:?}"", &block_id);
         self.block_queue.block_valid(&block_id);
         if match self.leader_state {
-            Some(LeaderState::Publishing(ref expected)) => {
-                expected == &block_id
-            },
-            Some(LeaderState::Validating(ref expected)) => {
-                expected == &block_id
-            },
+            Some(LeaderState::Publishing(ref expected)) => expected == &block_id,
+            Some(LeaderState::Validating(ref expected)) => expected == &block_id,
             _ => false,
         } {
-            debug!(""Leader({:?}) transition to Proposing block {:?}"", self.peer_id, block_id);
+            debug!(
+                ""Leader({:?}) transition to Proposing block {:?}"",
+                self.peer_id, block_id
+            );
             info!(""Leader({:?}) proposed block {:?}"", self.peer_id, block_id);
-            self.raw_node.propose(vec![], block_id.clone().into()).expect(""Failed to propose block to Raft"");
+            self.raw_node
+                .propose(vec![], block_id.clone())
+                .expect(""Failed to propose block to Raft"");
             self.leader_state = Some(LeaderState::Proposing(block_id));
         }
     }
 
+    #[allow(clippy::ptr_arg)]",103,2019-03-28 09:51:51,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/268316370,https://github.com/hyperledger/sawtooth-raft/pull/58#discussion_r268316370,vaporos
https://github.com/hyperledger/sawtooth-raft/pull/58,https://github.com/hyperledger/sawtooth-raft/pull/58,"Warning is because of BlockId Vec![], and here we have &Vec![] instead of &[...]. Allowing clippy warning here seems to be fine. I am open for suggestions.",0c9fe110513561ba98bbe9d04a17be7e7dae6fc9,2019-03-28 09:29:47,269916626,"@@ -93,78 +88,95 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             leader_state: None,
             follower_state: Some(FollowerState::Idle),
             block_queue: BlockQueue::new(),
-            raft_id_to_peer_id: peers.into_iter().map(|peer_id| (peer_id_to_raft_id(&peer_id), peer_id)).collect(),
+            raft_id_to_peer_id: peers
+                .into_iter()
+                .map(|peer_id| (peer_id_to_raft_id(&peer_id), peer_id))
+                .collect(),
             period,
         }
     }
 
     pub fn on_block_new(&mut self, block: Block) {
         if match self.leader_state {
-            Some(LeaderState::Publishing(ref block_id)) => {
-                block_id == &block.block_id
-            },
+            Some(LeaderState::Publishing(ref block_id)) => block_id == &block.block_id,
             _ => false,
         } {
-            debug!(""Leader({:?}) transition to Validating block {:?}"", self.peer_id, block.block_id);
+            debug!(
+                ""Leader({:?}) transition to Validating block {:?}"",
+                self.peer_id, block.block_id
+            );
             self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
         }
 
         debug!(""Block has been received: {:?}"", &block);
         self.block_queue.block_new(block.clone());
 
-        self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
+        self.service
+            .check_blocks(vec![block.block_id])
+            .expect(""Failed to send check blocks"");
     }
 
     pub fn on_block_valid(&mut self, block_id: BlockId) {
         // Handle out of order new/valid updates
         debug!(""Block has been validated: {:?}"", &block_id);
         self.block_queue.block_valid(&block_id);
         if match self.leader_state {
-            Some(LeaderState::Publishing(ref expected)) => {
-                expected == &block_id
-            },
-            Some(LeaderState::Validating(ref expected)) => {
-                expected == &block_id
-            },
+            Some(LeaderState::Publishing(ref expected)) => expected == &block_id,
+            Some(LeaderState::Validating(ref expected)) => expected == &block_id,
             _ => false,
         } {
-            debug!(""Leader({:?}) transition to Proposing block {:?}"", self.peer_id, block_id);
+            debug!(
+                ""Leader({:?}) transition to Proposing block {:?}"",
+                self.peer_id, block_id
+            );
             info!(""Leader({:?}) proposed block {:?}"", self.peer_id, block_id);
-            self.raw_node.propose(vec![], block_id.clone().into()).expect(""Failed to propose block to Raft"");
+            self.raw_node
+                .propose(vec![], block_id.clone())
+                .expect(""Failed to propose block to Raft"");
             self.leader_state = Some(LeaderState::Proposing(block_id));
         }
     }
 
+    #[allow(clippy::ptr_arg)]",103,2019-03-28 09:51:51,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/269916626,https://github.com/hyperledger/sawtooth-raft/pull/58#discussion_r269916626,arsulegai
https://github.com/hyperledger/sawtooth-raft/pull/57,https://github.com/hyperledger/sawtooth-raft/pull/57,"This shouldn't be removed, but an evaluation of what messages are being logged as ""debug"" and what are logged as ""trace"".",1f595cd308063fa4cc65d85d0268e57647d83fa3,2019-03-14 15:51:41,265638723,"@@ -128,8 +128,7 @@ fn parse_args() -> RaftCliArgs {
     let log_level = match matches.occurrences_of(""verbose"") {
         0 => log::LevelFilter::Warn,
         1 => log::LevelFilter::Info,
-        2 => log::LevelFilter::Debug,",4,2019-03-14 15:52:46,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/265638723,https://github.com/hyperledger/sawtooth-raft/pull/57#discussion_r265638723,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/57,https://github.com/hyperledger/sawtooth-raft/pull/57,"This change should be made in a separate commit (and possibly a separate PR, as it is less controversial than the logging change.",1f595cd308063fa4cc65d85d0268e57647d83fa3,2019-03-14 15:52:18,265639017,"@@ -103,7 +103,7 @@ services:
     volumes:
       - ${SAWOOTH_RAFT:-..}:/project/sawtooth-raft
     working_dir: /project/sawtooth-raft/
-    command: ./target/debug/raft-engine --connect tcp://validator:5050 -v
+    command: ./target/release/raft-engine --connect tcp://validator:5050 -v",5,2019-03-14 15:52:46,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/265639017,https://github.com/hyperledger/sawtooth-raft/pull/57#discussion_r265639017,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/54,https://github.com/hyperledger/sawtooth-raft/pull/54,"This should be in a separate commit, with a justification for the change in the commit message.",95a688683f2af149f910a80c6f86bf01c7a18d3e,2019-03-22 19:39:48,268313719,"@@ -42,6 +42,7 @@ services:
         --key-file /shared_data/keys/workload.priv \
         --rate ${RATE:-1} \
         --urls $$TARGETS \
+        --batch-size ${BATCH:-1} \",4,2019-03-28 10:24:32,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/268313719,https://github.com/hyperledger/sawtooth-raft/pull/54#discussion_r268313719,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/54,https://github.com/hyperledger/sawtooth-raft/pull/54,Ok,95a688683f2af149f910a80c6f86bf01c7a18d3e,2019-03-28 09:53:17,269925160,"@@ -42,6 +42,7 @@ services:
         --key-file /shared_data/keys/workload.priv \
         --rate ${RATE:-1} \
         --urls $$TARGETS \
+        --batch-size ${BATCH:-1} \",4,2019-03-28 10:24:32,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/269925160,https://github.com/hyperledger/sawtooth-raft/pull/54#discussion_r269925160,arsulegai
https://github.com/hyperledger/sawtooth-raft/pull/54,https://github.com/hyperledger/sawtooth-raft/pull/54,I see this change is in a separate commit: _Allow limiting number of transactions in a batch for workload_ ,95a688683f2af149f910a80c6f86bf01c7a18d3e,2019-03-28 15:15:12,270055034,"@@ -42,6 +42,7 @@ services:
         --key-file /shared_data/keys/workload.priv \
         --rate ${RATE:-1} \
         --urls $$TARGETS \
+        --batch-size ${BATCH:-1} \",4,2019-03-28 15:19:53,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/270055034,https://github.com/hyperledger/sawtooth-raft/pull/54#discussion_r270055034,danintel
https://github.com/hyperledger/sawtooth-raft/pull/52,https://github.com/hyperledger/sawtooth-raft/pull/52,"Instead of panicking, it would be better if the engine could reset itself to an appropriate state.",466a841b7dacac47544d84a59acec4479c1e81d7,2019-02-01 20:42:17,253193076,"@@ -193,6 +193,16 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             }
             _ => false,
         } {
+            match self.service.summarize_block() {
+                //Ignore Ok condition
+                Ok(_) => {},
+                Err(Error::BlockNotReady) => {
+                    debug!(""Leader({:?}) tried to summarize block but block not ready"", self.peer_id);
+                    return;
+                },
+                Err(err) => panic!(""Failed to summarize block: {:?}"", err),",11,2019-02-01 20:42:17,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/253193076,https://github.com/hyperledger/sawtooth-raft/pull/52#discussion_r253193076,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/52,https://github.com/hyperledger/sawtooth-raft/pull/52,Raft engine shouldn't get into this state ideally.  Currently summarize_block() error handling is done in the same manner as finalize_block() i.e panic if error is anything than BlockNotReady. We would need to investigate more to see how can we reset raft engine for all other error cases. May be it require changes in consensus SDK/Validator. Can we merge this PR in current state. We could raise a separate PR if we find better ways to handle other errors.,466a841b7dacac47544d84a59acec4479c1e81d7,2019-02-04 08:33:21,253377530,"@@ -193,6 +193,16 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             }
             _ => false,
         } {
+            match self.service.summarize_block() {
+                //Ignore Ok condition
+                Ok(_) => {},
+                Err(Error::BlockNotReady) => {
+                    debug!(""Leader({:?}) tried to summarize block but block not ready"", self.peer_id);
+                    return;
+                },
+                Err(err) => panic!(""Failed to summarize block: {:?}"", err),",11,2019-02-05 11:46:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/253377530,https://github.com/hyperledger/sawtooth-raft/pull/52#discussion_r253377530,manojgop
https://github.com/hyperledger/sawtooth-raft/pull/46,https://github.com/hyperledger/sawtooth-raft/pull/46,"How about extern crate declaration and use statements?
I guess build might fail without that change.",0925faa126c90aa5d1bec9bbde381be8b31fff09,2018-11-09 17:11:32,232327092,"@@ -22,7 +22,7 @@ log4rs = ""0.8""
 log4rs-syslog = ""3.0""
 protobuf = ""2""
 raft = ""0.3.1""
-sawtooth_sdk = { git = ""https://github.com/hyperledger/sawtooth-core.git"" }
+sawtooth-sdk = ""^0.1""",5,2018-11-09 17:11:54,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/232327092,https://github.com/hyperledger/sawtooth-raft/pull/46#discussion_r232327092,arsulegai
https://github.com/hyperledger/sawtooth-raft/pull/46,https://github.com/hyperledger/sawtooth-raft/pull/46,"If you mean due to the crate's coordinate change (`""sawtooth_sdk"" -> ""sawtooth-sdk""), those don't need to change.  Rust automatically translates those the dashes to the underscores.

(See https://github.com/rust-lang/rust/issues/23533 for details)",0925faa126c90aa5d1bec9bbde381be8b31fff09,2018-11-09 20:07:18,232378555,"@@ -22,7 +22,7 @@ log4rs = ""0.8""
 log4rs-syslog = ""3.0""
 protobuf = ""2""
 raft = ""0.3.1""
-sawtooth_sdk = { git = ""https://github.com/hyperledger/sawtooth-core.git"" }
+sawtooth-sdk = ""^0.1""",5,2018-11-09 20:07:19,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/232378555,https://github.com/hyperledger/sawtooth-raft/pull/46#discussion_r232378555,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/46,https://github.com/hyperledger/sawtooth-raft/pull/46,Thanks for the link. It clarifies my question.,0925faa126c90aa5d1bec9bbde381be8b31fff09,2018-11-10 05:51:41,232442965,"@@ -22,7 +22,7 @@ log4rs = ""0.8""
 log4rs-syslog = ""3.0""
 protobuf = ""2""
 raft = ""0.3.1""
-sawtooth_sdk = { git = ""https://github.com/hyperledger/sawtooth-core.git"" }
+sawtooth-sdk = ""^0.1""",5,2018-11-10 05:51:41,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/232442965,https://github.com/hyperledger/sawtooth-raft/pull/46#discussion_r232442965,arsulegai
https://github.com/hyperledger/sawtooth-raft/pull/43,https://github.com/hyperledger/sawtooth-raft/pull/43,There should not be license information in this file.,3ff480d4c170f3e48d213ce5f4e6680c3e67a378,2018-10-25 02:12:07,228015304,"@@ -4,3 +4,13 @@
 | Dan Middleton | dcmiddle | Dan |
 | Logan Seeley | ltseeley | ltseeley |
 | Peter Schwarz | peterschwarz | pschwarz |
+",4,2018-10-26 16:45:44,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/228015304,https://github.com/hyperledger/sawtooth-raft/pull/43#discussion_r228015304,vaporos
https://github.com/hyperledger/sawtooth-raft/pull/43,https://github.com/hyperledger/sawtooth-raft/pull/43,There should not be license information in this file.,3ff480d4c170f3e48d213ce5f4e6680c3e67a378,2018-10-25 02:13:02,228015430,"@@ -1 +1,16 @@
+# Copyright 2018 Intel Corporation",,2018-10-26 16:45:44,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/228015430,https://github.com/hyperledger/sawtooth-raft/pull/43#discussion_r228015430,vaporos
https://github.com/hyperledger/sawtooth-raft/pull/43,https://github.com/hyperledger/sawtooth-raft/pull/43,This file contains auto-generated content and this header may be inappropriate.,3ff480d4c170f3e48d213ce5f4e6680c3e67a378,2018-10-25 02:13:33,228015494,"@@ -1,3 +1,18 @@
+# Copyright 2018 Intel Corporation",,2018-10-26 16:45:44,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/228015494,https://github.com/hyperledger/sawtooth-raft/pull/43#discussion_r228015494,vaporos
https://github.com/hyperledger/sawtooth-raft/pull/43,https://github.com/hyperledger/sawtooth-raft/pull/43,make.bat should just be removed.,3ff480d4c170f3e48d213ce5f4e6680c3e67a378,2018-10-25 02:13:44,228015519,"@@ -1,3 +1,18 @@
+REM Copyright 2018 Intel Corporation",,2018-10-26 16:45:44,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/228015519,https://github.com/hyperledger/sawtooth-raft/pull/43#discussion_r228015519,vaporos
https://github.com/hyperledger/sawtooth-raft/pull/43,https://github.com/hyperledger/sawtooth-raft/pull/43,This empty line should be removed from the commit.,3ff480d4c170f3e48d213ce5f4e6680c3e67a378,2018-11-13 15:39:36,233090568,"@@ -4,3 +4,13 @@
 | Dan Middleton | dcmiddle | Dan |
 | Logan Seeley | ltseeley | ltseeley |
 | Peter Schwarz | peterschwarz | pschwarz |
+",4,2018-11-13 15:39:36,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/233090568,https://github.com/hyperledger/sawtooth-raft/pull/43#discussion_r233090568,vaporos
https://github.com/hyperledger/sawtooth-raft/pull/41,https://github.com/hyperledger/sawtooth-raft/pull/41,"Given that this dependency is for tests only, does this need to be included here?",ee4cbaa5bbf06a062ebcd6e75c21dd72e8b7f7ac,2018-10-05 19:06:07,223111543,"@@ -11,7 +11,7 @@ These components are released under separate copyright notices and license terms
 => libc for Rust
 => log for Rust
 => pingcap raft-rs
-=> rust-lang tempdir
+=> rust-lang tempfile",5,2018-10-05 19:06:07,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/223111543,https://github.com/hyperledger/sawtooth-raft/pull/41#discussion_r223111543,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/41,https://github.com/hyperledger/sawtooth-raft/pull/41,Yes. @TomBarnes can clarify more.,ee4cbaa5bbf06a062ebcd6e75c21dd72e8b7f7ac,2018-10-08 09:44:42,223304741,"@@ -11,7 +11,7 @@ These components are released under separate copyright notices and license terms
 => libc for Rust
 => log for Rust
 => pingcap raft-rs
-=> rust-lang tempdir
+=> rust-lang tempfile",5,2018-10-08 09:44:43,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/223304741,https://github.com/hyperledger/sawtooth-raft/pull/41#discussion_r223304741,askmish
https://github.com/hyperledger/sawtooth-raft/pull/36,https://github.com/hyperledger/sawtooth-raft/pull/36,"The ""Reading the Logs/Output"" content should be merged into the content above where appropriate, instead of starting a new section here. For example, you could merge the content about the Raft process starting but not actually connecting into the ""Connecting to the validator"" section of ""Starting a Raft Engine"".",d932b8911e9abd58a39948c6fee01826b690ea46,2018-09-27 17:42:17,221015145,"@@ -307,3 +307,117 @@ setting has been updated to no longer include the old node's public key, the
 leader will stop sending messages to the node and ignore any messages from it.
 Once this happens, the node can be shutdown safely since it is no longer
 participating in the network.
+
+
+Reading the Logs/Output
+=======================",,2018-10-01 20:02:27,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/221015145,https://github.com/hyperledger/sawtooth-raft/pull/36#discussion_r221015145,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/36,https://github.com/hyperledger/sawtooth-raft/pull/36,This should be a new top-level item at the same level as the Introduction and Configuration documents.,d932b8911e9abd58a39948c6fee01826b690ea46,2018-09-27 17:42:43,221015303,"@@ -307,3 +307,117 @@ setting has been updated to no longer include the old node's public key, the
 leader will stop sending messages to the node and ignore any messages from it.
 Once this happens, the node can be shutdown safely since it is no longer
 participating in the network.
+
+
+Reading the Logs/Output
+=======================
+
+This section explains what to look for in the Raft logs to verify that the
+network is running properly and to identify any issues. The location of the logs
+will vary based on the logging configuration provided to Raft; by default, Raft
+will log to stdout (see `Logging Configuration`_ for more details). This section
+assumes that Raft is set to log with at least ``INFO`` level logging.
+
+When the Sawtooth Raft process starts initially, you will see a message that
+indicates the version of the Raft engine and the validator endpoint that it is
+attempting to connect to:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft:84     | Sawtooth Raft Engine (X.Y.Z)
+  INFO  | sawtooth_raft:90     | Raft Node connecting to 'tcp://validator:5050'
+
+This indicates that the Raft process has started; however, it does not indicate
+that the Raft engine itself is running. The Raft engine waits until the genesis
+block has been received and committed by the validator before running. Once the
+genesis block has been committed, you will see a message in the validator's logs
+indicating that the Raft engine has been registered:
+
+.. code-block:: console
+
+  Consensus engine registered: sawtooth-raft X.Y.Z
+
+You will also see a message in the Raft log that displays the configuration
+values that are being used by the Raft engine, similar to this one:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft::engin | Raft Engine Config Loaded: RaftEngineConfig { peers: [026c49c05b153ca92e2fae01fea85663ae397eb435cc7744907edfe839e84fb288, 0396f274c14f4a73c12300b718facce13834fead83e1afafe3b19a2bc31c3462c5], period: 3s, raft: { election_tick: 20, heartbeat_tick: 2, applied: 0 }, storage: cached storage: file-system backed persistent storage }
+
+If the Raft engine is peered properly, you should also see a group of messages
+that indicate if the node has been elected leader or if it has voted for another
+node as leader. On a leader node, the logs will look similar to this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 0
+  INFO  | raft::raft:433       | [12797589408118497989] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 1
+  INFO  | raft::raft:1120      | [12797589408118497989] is starting a new election at term 1
+  INFO  | raft::raft:848       | [12797589408118497989] became candidate at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 12797589408118497989 at term 2
+  INFO  | raft::raft:927       | [12797589408118497989] [logterm: 1, index: 2] sent MsgRequestVote request to 9142281103993713288 at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 9142281103993713288 at term 2
+  INFO  | raft::raft:1648      | [12797589408118497989] [quorum:2] has received 2 MsgRequestVoteResponse votes and 0 vote rejections
+  INFO  | raft::raft:891       | [12797589408118497989] became leader at term 2
+
+On a node that becomes a follower and votes for another node, the logs will look
+like this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 0
+  INFO  | raft::raft:433       | [9142281103993713288] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 1
+  INFO  | raft::raft:1014      | [9142281103993713288] [term: 1] received a MsgRequestVote message with higher term from 12797589408118497989 [term: 2]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 2
+  INFO  | raft::raft:1181      | [9142281103993713288] [logterm: 1, index: 2, vote: 0] cast MsgRequestVote for 12797589408118497989 [logterm: 1, index: 2] at term 2
+
+At this point, the Raft engine is running and ready to handle blocks.
+
+
+Troubleshooting and Common Issues
+=================================",,2018-10-01 20:02:27,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/221015303,https://github.com/hyperledger/sawtooth-raft/pull/36#discussion_r221015303,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/36,https://github.com/hyperledger/sawtooth-raft/pull/36,The link to the consensus channel is broken on the community page (should be `#sawtooth-consensus-dev`),d932b8911e9abd58a39948c6fee01826b690ea46,2018-09-27 17:43:23,221015510,"@@ -307,3 +307,117 @@ setting has been updated to no longer include the old node's public key, the
 leader will stop sending messages to the node and ignore any messages from it.
 Once this happens, the node can be shutdown safely since it is no longer
 participating in the network.
+
+
+Reading the Logs/Output
+=======================
+
+This section explains what to look for in the Raft logs to verify that the
+network is running properly and to identify any issues. The location of the logs
+will vary based on the logging configuration provided to Raft; by default, Raft
+will log to stdout (see `Logging Configuration`_ for more details). This section
+assumes that Raft is set to log with at least ``INFO`` level logging.
+
+When the Sawtooth Raft process starts initially, you will see a message that
+indicates the version of the Raft engine and the validator endpoint that it is
+attempting to connect to:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft:84     | Sawtooth Raft Engine (X.Y.Z)
+  INFO  | sawtooth_raft:90     | Raft Node connecting to 'tcp://validator:5050'
+
+This indicates that the Raft process has started; however, it does not indicate
+that the Raft engine itself is running. The Raft engine waits until the genesis
+block has been received and committed by the validator before running. Once the
+genesis block has been committed, you will see a message in the validator's logs
+indicating that the Raft engine has been registered:
+
+.. code-block:: console
+
+  Consensus engine registered: sawtooth-raft X.Y.Z
+
+You will also see a message in the Raft log that displays the configuration
+values that are being used by the Raft engine, similar to this one:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft::engin | Raft Engine Config Loaded: RaftEngineConfig { peers: [026c49c05b153ca92e2fae01fea85663ae397eb435cc7744907edfe839e84fb288, 0396f274c14f4a73c12300b718facce13834fead83e1afafe3b19a2bc31c3462c5], period: 3s, raft: { election_tick: 20, heartbeat_tick: 2, applied: 0 }, storage: cached storage: file-system backed persistent storage }
+
+If the Raft engine is peered properly, you should also see a group of messages
+that indicate if the node has been elected leader or if it has voted for another
+node as leader. On a leader node, the logs will look similar to this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 0
+  INFO  | raft::raft:433       | [12797589408118497989] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 1
+  INFO  | raft::raft:1120      | [12797589408118497989] is starting a new election at term 1
+  INFO  | raft::raft:848       | [12797589408118497989] became candidate at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 12797589408118497989 at term 2
+  INFO  | raft::raft:927       | [12797589408118497989] [logterm: 1, index: 2] sent MsgRequestVote request to 9142281103993713288 at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 9142281103993713288 at term 2
+  INFO  | raft::raft:1648      | [12797589408118497989] [quorum:2] has received 2 MsgRequestVoteResponse votes and 0 vote rejections
+  INFO  | raft::raft:891       | [12797589408118497989] became leader at term 2
+
+On a node that becomes a follower and votes for another node, the logs will look
+like this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 0
+  INFO  | raft::raft:433       | [9142281103993713288] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 1
+  INFO  | raft::raft:1014      | [9142281103993713288] [term: 1] received a MsgRequestVote message with higher term from 12797589408118497989 [term: 2]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 2
+  INFO  | raft::raft:1181      | [9142281103993713288] [logterm: 1, index: 2, vote: 0] cast MsgRequestVote for 12797589408118497989 [logterm: 1, index: 2] at term 2
+
+At this point, the Raft engine is running and ready to handle blocks.
+
+
+Troubleshooting and Common Issues
+=================================
+
+Below is a list of common issues that are seen when attempting to start and run
+a Sawtooth Raft network. If you encounter any problems, please consult this list
+to see if your issue is discussed. If you are still having problems, find out
+how to get help in the :doc:`/community/join_the_discussion` section.",,2018-10-01 20:02:27,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/221015510,https://github.com/hyperledger/sawtooth-raft/pull/36#discussion_r221015510,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/36,https://github.com/hyperledger/sawtooth-raft/pull/36,Can you include example logs of what this looks like?,d932b8911e9abd58a39948c6fee01826b690ea46,2018-09-27 17:43:46,221015629,"@@ -307,3 +307,117 @@ setting has been updated to no longer include the old node's public key, the
 leader will stop sending messages to the node and ignore any messages from it.
 Once this happens, the node can be shutdown safely since it is no longer
 participating in the network.
+
+
+Reading the Logs/Output
+=======================
+
+This section explains what to look for in the Raft logs to verify that the
+network is running properly and to identify any issues. The location of the logs
+will vary based on the logging configuration provided to Raft; by default, Raft
+will log to stdout (see `Logging Configuration`_ for more details). This section
+assumes that Raft is set to log with at least ``INFO`` level logging.
+
+When the Sawtooth Raft process starts initially, you will see a message that
+indicates the version of the Raft engine and the validator endpoint that it is
+attempting to connect to:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft:84     | Sawtooth Raft Engine (X.Y.Z)
+  INFO  | sawtooth_raft:90     | Raft Node connecting to 'tcp://validator:5050'
+
+This indicates that the Raft process has started; however, it does not indicate
+that the Raft engine itself is running. The Raft engine waits until the genesis
+block has been received and committed by the validator before running. Once the
+genesis block has been committed, you will see a message in the validator's logs
+indicating that the Raft engine has been registered:
+
+.. code-block:: console
+
+  Consensus engine registered: sawtooth-raft X.Y.Z
+
+You will also see a message in the Raft log that displays the configuration
+values that are being used by the Raft engine, similar to this one:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft::engin | Raft Engine Config Loaded: RaftEngineConfig { peers: [026c49c05b153ca92e2fae01fea85663ae397eb435cc7744907edfe839e84fb288, 0396f274c14f4a73c12300b718facce13834fead83e1afafe3b19a2bc31c3462c5], period: 3s, raft: { election_tick: 20, heartbeat_tick: 2, applied: 0 }, storage: cached storage: file-system backed persistent storage }
+
+If the Raft engine is peered properly, you should also see a group of messages
+that indicate if the node has been elected leader or if it has voted for another
+node as leader. On a leader node, the logs will look similar to this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 0
+  INFO  | raft::raft:433       | [12797589408118497989] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 1
+  INFO  | raft::raft:1120      | [12797589408118497989] is starting a new election at term 1
+  INFO  | raft::raft:848       | [12797589408118497989] became candidate at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 12797589408118497989 at term 2
+  INFO  | raft::raft:927       | [12797589408118497989] [logterm: 1, index: 2] sent MsgRequestVote request to 9142281103993713288 at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 9142281103993713288 at term 2
+  INFO  | raft::raft:1648      | [12797589408118497989] [quorum:2] has received 2 MsgRequestVoteResponse votes and 0 vote rejections
+  INFO  | raft::raft:891       | [12797589408118497989] became leader at term 2
+
+On a node that becomes a follower and votes for another node, the logs will look
+like this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 0
+  INFO  | raft::raft:433       | [9142281103993713288] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 1
+  INFO  | raft::raft:1014      | [9142281103993713288] [term: 1] received a MsgRequestVote message with higher term from 12797589408118497989 [term: 2]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 2
+  INFO  | raft::raft:1181      | [9142281103993713288] [logterm: 1, index: 2, vote: 0] cast MsgRequestVote for 12797589408118497989 [logterm: 1, index: 2] at term 2
+
+At this point, the Raft engine is running and ready to handle blocks.
+
+
+Troubleshooting and Common Issues
+=================================
+
+Below is a list of common issues that are seen when attempting to start and run
+a Sawtooth Raft network. If you encounter any problems, please consult this list
+to see if your issue is discussed. If you are still having problems, find out
+how to get help in the :doc:`/community/join_the_discussion` section.
+
+
+No Leader Is Elected
+--------------------
+
+When a Sawtooth Raft network is unable to elect a leader, one or more nodes will
+continuously start new elections. This is usually a sign that the nodes are not
+peering properly. If you encounter this problem, see `Troubleshooting",,2018-10-01 20:02:27,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/221015629,https://github.com/hyperledger/sawtooth-raft/pull/36#discussion_r221015629,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/36,https://github.com/hyperledger/sawtooth-raft/pull/36,Is there anything in the logs that would indicate that a node cannot communicate? Such as repeatedly trying to send a message?,d932b8911e9abd58a39948c6fee01826b690ea46,2018-09-27 17:45:08,221016084,"@@ -307,3 +307,117 @@ setting has been updated to no longer include the old node's public key, the
 leader will stop sending messages to the node and ignore any messages from it.
 Once this happens, the node can be shutdown safely since it is no longer
 participating in the network.
+
+
+Reading the Logs/Output
+=======================
+
+This section explains what to look for in the Raft logs to verify that the
+network is running properly and to identify any issues. The location of the logs
+will vary based on the logging configuration provided to Raft; by default, Raft
+will log to stdout (see `Logging Configuration`_ for more details). This section
+assumes that Raft is set to log with at least ``INFO`` level logging.
+
+When the Sawtooth Raft process starts initially, you will see a message that
+indicates the version of the Raft engine and the validator endpoint that it is
+attempting to connect to:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft:84     | Sawtooth Raft Engine (X.Y.Z)
+  INFO  | sawtooth_raft:90     | Raft Node connecting to 'tcp://validator:5050'
+
+This indicates that the Raft process has started; however, it does not indicate
+that the Raft engine itself is running. The Raft engine waits until the genesis
+block has been received and committed by the validator before running. Once the
+genesis block has been committed, you will see a message in the validator's logs
+indicating that the Raft engine has been registered:
+
+.. code-block:: console
+
+  Consensus engine registered: sawtooth-raft X.Y.Z
+
+You will also see a message in the Raft log that displays the configuration
+values that are being used by the Raft engine, similar to this one:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft::engin | Raft Engine Config Loaded: RaftEngineConfig { peers: [026c49c05b153ca92e2fae01fea85663ae397eb435cc7744907edfe839e84fb288, 0396f274c14f4a73c12300b718facce13834fead83e1afafe3b19a2bc31c3462c5], period: 3s, raft: { election_tick: 20, heartbeat_tick: 2, applied: 0 }, storage: cached storage: file-system backed persistent storage }
+
+If the Raft engine is peered properly, you should also see a group of messages
+that indicate if the node has been elected leader or if it has voted for another
+node as leader. On a leader node, the logs will look similar to this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 0
+  INFO  | raft::raft:433       | [12797589408118497989] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 1
+  INFO  | raft::raft:1120      | [12797589408118497989] is starting a new election at term 1
+  INFO  | raft::raft:848       | [12797589408118497989] became candidate at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 12797589408118497989 at term 2
+  INFO  | raft::raft:927       | [12797589408118497989] [logterm: 1, index: 2] sent MsgRequestVote request to 9142281103993713288 at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 9142281103993713288 at term 2
+  INFO  | raft::raft:1648      | [12797589408118497989] [quorum:2] has received 2 MsgRequestVoteResponse votes and 0 vote rejections
+  INFO  | raft::raft:891       | [12797589408118497989] became leader at term 2
+
+On a node that becomes a follower and votes for another node, the logs will look
+like this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 0
+  INFO  | raft::raft:433       | [9142281103993713288] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 1
+  INFO  | raft::raft:1014      | [9142281103993713288] [term: 1] received a MsgRequestVote message with higher term from 12797589408118497989 [term: 2]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 2
+  INFO  | raft::raft:1181      | [9142281103993713288] [logterm: 1, index: 2, vote: 0] cast MsgRequestVote for 12797589408118497989 [logterm: 1, index: 2] at term 2
+
+At this point, the Raft engine is running and ready to handle blocks.
+
+
+Troubleshooting and Common Issues
+=================================
+
+Below is a list of common issues that are seen when attempting to start and run
+a Sawtooth Raft network. If you encounter any problems, please consult this list
+to see if your issue is discussed. If you are still having problems, find out
+how to get help in the :doc:`/community/join_the_discussion` section.
+
+
+No Leader Is Elected
+--------------------
+
+When a Sawtooth Raft network is unable to elect a leader, one or more nodes will
+continuously start new elections. This is usually a sign that the nodes are not
+peering properly. If you encounter this problem, see `Troubleshooting
+Connectivity`_ for tips on how to resolve it.
+
+
+Troubleshooting Connectivity
+----------------------------
+
+
+Validator Peering Configuration
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+If you are experiencing network peering problems, the first thing to do is to
+verify that the validators are configured to peer properly. If the validators
+are not started up with static peering or the list of all existing validator
+endpoints is not supplied to a validator, some nodes will not be able to
+communicate. See the section on `Validator Peering Requirements`_ to ensure that",,2018-10-01 20:02:27,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/221016084,https://github.com/hyperledger/sawtooth-raft/pull/36#discussion_r221016084,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/36,https://github.com/hyperledger/sawtooth-raft/pull/36,Can you include an example of this log message?,d932b8911e9abd58a39948c6fee01826b690ea46,2018-09-27 17:46:00,221016354,"@@ -307,3 +307,117 @@ setting has been updated to no longer include the old node's public key, the
 leader will stop sending messages to the node and ignore any messages from it.
 Once this happens, the node can be shutdown safely since it is no longer
 participating in the network.
+
+
+Reading the Logs/Output
+=======================
+
+This section explains what to look for in the Raft logs to verify that the
+network is running properly and to identify any issues. The location of the logs
+will vary based on the logging configuration provided to Raft; by default, Raft
+will log to stdout (see `Logging Configuration`_ for more details). This section
+assumes that Raft is set to log with at least ``INFO`` level logging.
+
+When the Sawtooth Raft process starts initially, you will see a message that
+indicates the version of the Raft engine and the validator endpoint that it is
+attempting to connect to:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft:84     | Sawtooth Raft Engine (X.Y.Z)
+  INFO  | sawtooth_raft:90     | Raft Node connecting to 'tcp://validator:5050'
+
+This indicates that the Raft process has started; however, it does not indicate
+that the Raft engine itself is running. The Raft engine waits until the genesis
+block has been received and committed by the validator before running. Once the
+genesis block has been committed, you will see a message in the validator's logs
+indicating that the Raft engine has been registered:
+
+.. code-block:: console
+
+  Consensus engine registered: sawtooth-raft X.Y.Z
+
+You will also see a message in the Raft log that displays the configuration
+values that are being used by the Raft engine, similar to this one:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft::engin | Raft Engine Config Loaded: RaftEngineConfig { peers: [026c49c05b153ca92e2fae01fea85663ae397eb435cc7744907edfe839e84fb288, 0396f274c14f4a73c12300b718facce13834fead83e1afafe3b19a2bc31c3462c5], period: 3s, raft: { election_tick: 20, heartbeat_tick: 2, applied: 0 }, storage: cached storage: file-system backed persistent storage }
+
+If the Raft engine is peered properly, you should also see a group of messages
+that indicate if the node has been elected leader or if it has voted for another
+node as leader. On a leader node, the logs will look similar to this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 0
+  INFO  | raft::raft:433       | [12797589408118497989] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 1
+  INFO  | raft::raft:1120      | [12797589408118497989] is starting a new election at term 1
+  INFO  | raft::raft:848       | [12797589408118497989] became candidate at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 12797589408118497989 at term 2
+  INFO  | raft::raft:927       | [12797589408118497989] [logterm: 1, index: 2] sent MsgRequestVote request to 9142281103993713288 at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 9142281103993713288 at term 2
+  INFO  | raft::raft:1648      | [12797589408118497989] [quorum:2] has received 2 MsgRequestVoteResponse votes and 0 vote rejections
+  INFO  | raft::raft:891       | [12797589408118497989] became leader at term 2
+
+On a node that becomes a follower and votes for another node, the logs will look
+like this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 0
+  INFO  | raft::raft:433       | [9142281103993713288] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 1
+  INFO  | raft::raft:1014      | [9142281103993713288] [term: 1] received a MsgRequestVote message with higher term from 12797589408118497989 [term: 2]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 2
+  INFO  | raft::raft:1181      | [9142281103993713288] [logterm: 1, index: 2, vote: 0] cast MsgRequestVote for 12797589408118497989 [logterm: 1, index: 2] at term 2
+
+At this point, the Raft engine is running and ready to handle blocks.
+
+
+Troubleshooting and Common Issues
+=================================
+
+Below is a list of common issues that are seen when attempting to start and run
+a Sawtooth Raft network. If you encounter any problems, please consult this list
+to see if your issue is discussed. If you are still having problems, find out
+how to get help in the :doc:`/community/join_the_discussion` section.
+
+
+No Leader Is Elected
+--------------------
+
+When a Sawtooth Raft network is unable to elect a leader, one or more nodes will
+continuously start new elections. This is usually a sign that the nodes are not
+peering properly. If you encounter this problem, see `Troubleshooting
+Connectivity`_ for tips on how to resolve it.
+
+
+Troubleshooting Connectivity
+----------------------------
+
+
+Validator Peering Configuration
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+If you are experiencing network peering problems, the first thing to do is to
+verify that the validators are configured to peer properly. If the validators
+are not started up with static peering or the list of all existing validator
+endpoints is not supplied to a validator, some nodes will not be able to
+communicate. See the section on `Validator Peering Requirements`_ to ensure that
+you are providing the correct parameters for the validators to peer properly.
+
+
+Max Peers Exceeded
+~~~~~~~~~~~~~~~~~~
+
+If you are running a large Raft network (around 10 nodes), you might see an
+error in one or more of the validators' logs indicating that a peering request
+was rejected because the validator has reached its maximum number of peers. To",,2018-10-01 20:02:27,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/221016354,https://github.com/hyperledger/sawtooth-raft/pull/36#discussion_r221016354,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/36,https://github.com/hyperledger/sawtooth-raft/pull/36,I think we should also include a section on what happens when the `sawtooth.consensus.raft.peers` setting is incorrect and how to check it.,d932b8911e9abd58a39948c6fee01826b690ea46,2018-09-27 17:47:08,221016674,"@@ -307,3 +307,117 @@ setting has been updated to no longer include the old node's public key, the
 leader will stop sending messages to the node and ignore any messages from it.
 Once this happens, the node can be shutdown safely since it is no longer
 participating in the network.
+
+
+Reading the Logs/Output
+=======================
+
+This section explains what to look for in the Raft logs to verify that the
+network is running properly and to identify any issues. The location of the logs
+will vary based on the logging configuration provided to Raft; by default, Raft
+will log to stdout (see `Logging Configuration`_ for more details). This section
+assumes that Raft is set to log with at least ``INFO`` level logging.
+
+When the Sawtooth Raft process starts initially, you will see a message that
+indicates the version of the Raft engine and the validator endpoint that it is
+attempting to connect to:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft:84     | Sawtooth Raft Engine (X.Y.Z)
+  INFO  | sawtooth_raft:90     | Raft Node connecting to 'tcp://validator:5050'
+
+This indicates that the Raft process has started; however, it does not indicate
+that the Raft engine itself is running. The Raft engine waits until the genesis
+block has been received and committed by the validator before running. Once the
+genesis block has been committed, you will see a message in the validator's logs
+indicating that the Raft engine has been registered:
+
+.. code-block:: console
+
+  Consensus engine registered: sawtooth-raft X.Y.Z
+
+You will also see a message in the Raft log that displays the configuration
+values that are being used by the Raft engine, similar to this one:
+
+.. code-block:: console
+
+  INFO  | sawtooth_raft::engin | Raft Engine Config Loaded: RaftEngineConfig { peers: [026c49c05b153ca92e2fae01fea85663ae397eb435cc7744907edfe839e84fb288, 0396f274c14f4a73c12300b718facce13834fead83e1afafe3b19a2bc31c3462c5], period: 3s, raft: { election_tick: 20, heartbeat_tick: 2, applied: 0 }, storage: cached storage: file-system backed persistent storage }
+
+If the Raft engine is peered properly, you should also see a group of messages
+that indicate if the node has been elected leader or if it has voted for another
+node as leader. On a leader node, the logs will look similar to this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 0
+  INFO  | raft::raft:433       | [12797589408118497989] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [12797589408118497989] became follower at term 1
+  INFO  | raft::raft:1120      | [12797589408118497989] is starting a new election at term 1
+  INFO  | raft::raft:848       | [12797589408118497989] became candidate at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 12797589408118497989 at term 2
+  INFO  | raft::raft:927       | [12797589408118497989] [logterm: 1, index: 2] sent MsgRequestVote request to 9142281103993713288 at term 2
+  INFO  | raft::raft:950       | [12797589408118497989] received MsgRequestVoteResponse from 9142281103993713288 at term 2
+  INFO  | raft::raft:1648      | [12797589408118497989] [quorum:2] has received 2 MsgRequestVoteResponse votes and 0 vote rejections
+  INFO  | raft::raft:891       | [12797589408118497989] became leader at term 2
+
+On a node that becomes a follower and votes for another node, the logs will look
+like this:
+
+.. code-block:: console
+
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 0
+  INFO  | raft::raft:433       | [9142281103993713288] newRaft [peers: [9142281103993713288, 12797589408118497989], term: 0, commit: 0, applied: 0, last_index: 0, last_term: 0]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 1
+  INFO  | raft::raft:1014      | [9142281103993713288] [term: 1] received a MsgRequestVote message with higher term from 12797589408118497989 [term: 2]
+  INFO  | raft::raft:833       | [9142281103993713288] became follower at term 2
+  INFO  | raft::raft:1181      | [9142281103993713288] [logterm: 1, index: 2, vote: 0] cast MsgRequestVote for 12797589408118497989 [logterm: 1, index: 2] at term 2
+
+At this point, the Raft engine is running and ready to handle blocks.
+
+
+Troubleshooting and Common Issues
+=================================
+
+Below is a list of common issues that are seen when attempting to start and run
+a Sawtooth Raft network. If you encounter any problems, please consult this list
+to see if your issue is discussed. If you are still having problems, find out
+how to get help in the :doc:`/community/join_the_discussion` section.
+
+
+No Leader Is Elected
+--------------------
+
+When a Sawtooth Raft network is unable to elect a leader, one or more nodes will
+continuously start new elections. This is usually a sign that the nodes are not
+peering properly. If you encounter this problem, see `Troubleshooting
+Connectivity`_ for tips on how to resolve it.
+
+
+Troubleshooting Connectivity
+----------------------------
+
+
+Validator Peering Configuration
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+If you are experiencing network peering problems, the first thing to do is to
+verify that the validators are configured to peer properly. If the validators
+are not started up with static peering or the list of all existing validator
+endpoints is not supplied to a validator, some nodes will not be able to
+communicate. See the section on `Validator Peering Requirements`_ to ensure that
+you are providing the correct parameters for the validators to peer properly.
+
+
+Max Peers Exceeded
+~~~~~~~~~~~~~~~~~~
+
+If you are running a large Raft network (around 10 nodes), you might see an
+error in one or more of the validators' logs indicating that a peering request
+was rejected because the validator has reached its maximum number of peers. To
+resolve this issue, you will need to increase the peer limit for all validators.
+If you are starting the validator from the command line, you can specify the
+maximum number of peer connections with the ``--maximum_peer_connectivity``
+option (see the `sawtooth-validator documentation`_ for more details).",,2018-10-01 20:02:27,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/221016674,https://github.com/hyperledger/sawtooth-raft/pull/36#discussion_r221016674,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/36,https://github.com/hyperledger/sawtooth-raft/pull/36,"typo, ""If all the nodes""",d932b8911e9abd58a39948c6fee01826b690ea46,2018-10-01 19:22:14,221726303,"@@ -252,6 +303,43 @@ After you have stopped a node, you can use ``docker-compose start`` with the
 appropriate ``-p`` flag to restart the stopped node.
 
 
+Verifying the Network Is Ready
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+When the network is setup correctly, Raft will elect a node as leader. If the
+all nodes are peered properly, you should also see a group of messages in the",,2018-10-01 20:02:27,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/221726303,https://github.com/hyperledger/sawtooth-raft/pull/36#discussion_r221726303,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/35,https://github.com/hyperledger/sawtooth-raft/pull/35,"It would be better to use an `enum` here to clarify what is being returned and support additional actions in the future. Something like:
```
enum ReadyStatus {
  Continue,
  Shutdown,
}
```

For example, if we add support later for changing raft settings while the network is running, we could add a `Reload` variant here.",6f501251c8f61c00410e1204c5d452b2069e9a37,2018-09-24 16:57:43,219911783,"@@ -220,9 +220,9 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
         }
     }
 
-    pub fn process_ready(&mut self) {
+    pub fn process_ready(&mut self) -> bool {",,2018-09-24 19:33:41,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219911783,https://github.com/hyperledger/sawtooth-raft/pull/35#discussion_r219911783,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/35,https://github.com/hyperledger/sawtooth-raft/pull/35,"Here is a better write up on why this is a good idea: https://rust-lang-nursery.github.io/api-guidelines/type-safety.html?highlight=enum#arguments-convey-meaning-through-types-not-bool-or-option-c-custom-type

I highly recommend reading through that doc as it is full of good design ideas.",6f501251c8f61c00410e1204c5d452b2069e9a37,2018-09-24 16:59:56,219912541,"@@ -220,9 +220,9 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
         }
     }
 
-    pub fn process_ready(&mut self) {
+    pub fn process_ready(&mut self) -> bool {",,2018-09-24 19:33:41,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219912541,https://github.com/hyperledger/sawtooth-raft/pull/35#discussion_r219912541,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/31,https://github.com/hyperledger/sawtooth-raft/pull/31,Won't the new node pick up the setting change as it plays forward state?,e2d04656e384bdff1dc9bb55101cd7bb6e68d081,2018-09-20 20:42:43,219311027,"@@ -0,0 +1,298 @@
+***************************************
+Configuring and Deploying Sawtooth Raft
+***************************************
+
+This guide assumes previous experience with creating and deploying Sawtooth
+networks; if you are unfamiliar with Sawtooth, please see the `Application
+Developer's Guide`_ and `System Administrator's Guide`_ in the Sawtooth Core
+documentation.
+
+.. _Application Developer's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/app_developers_guide.html
+.. _System Administrator's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/sysadmin_guide.html
+
+This guide also requires a basic understanding of the Raft consensus algorithm;
+if you are not familiar with Raft, please see the `Raft`_ webpage.
+
+.. _Raft: https://raft.github.io/
+
+
+Validator Peering Requirements
+==============================
+
+Sawtooth Raft requires a fully-peered network where all nodes are able to
+communicate with all other nodes. This is necessary to establish a leader
+through the election process, as well as to maintain leadership through regular
+heartbeat messages. If a Raft network is not fully-peered, leadership election
+may fail due to some nodes being unable to communicate with one another.
+
+In order to achieve a fully-peered network, the list of peers that comprise the
+network will need to be known and maintained at all times. This means that Raft
+networks do not support open membership; an administrator must explicitly add or
+remove nodes to change membership (see `Changing Network Membership`_ for more
+details).
+
+To setup a fully-peered network, all validators must be started with the
+following two options:
+
+* ``--peering static`` - Informs the validator to connect with all of the
+  specified peers.
+* ``--peers {peers_list}`` - Provides the list of peers for the validator to
+  connect to, where `{peers_list}` is the list of public endpoints for all other
+  previously started validators.
+
+For example, if there are two validators already running with public endpoints
+``203.0.113.1:8800`` and ``203.0.113.2:8800``, a new validator would be started
+with the options ``--peering static --peers
+tcp://203.0.113.1:8800,tcp://203.0.113.2:8800``. Since peering is
+bi-directional, when the new validator connects with the existing validators,
+the existing validators will be fully peered as well.
+
+
+On-Chain Settings
+=================
+
+When starting a fresh network with the Sawtooth Raft consensus engine, the
+required settings below (and the desired optional settings) should be set in the
+genesis block.
+
+
+Required Settings
+-----------------
+
+* ``sawtooth.consensus.algorithm`` - Tells the network which consensus engine to
+  use. Must be set to ``raft``.
+* ``sawtooth.consensus.raft.peers`` - A JSON list of public keys of all
+  validators in the network, formatted as hex strings.
+
+The ``sawtooth.consensus.raft.peers`` setting is extremely important, since the
+Raft engine uses it as its source-of-truth for which nodes to communicate with.
+When a Raft engine starts initially, it checks the setting to determine which
+nodes are in the network. This setting is also used to add or remove nodes from
+the Raft network as covered in the `Changing Network Membership`_ section. As an
+example, the value of ``sawtooth.consensus.raft.peers`` would be formatted like
+this:
+
+.. code-block:: json
+
+  [
+    ""dc26a7099e81bb02869cc8ae57da030fbe4cf276b38ab37d2cc815fec63a14ab"",
+    ""df8e8388ced559bd35c2b05199ca9f8fbebb420979715003355dcb7363016c1d""
+  ]
+
+
+Optional Settings
+-----------------
+
+* ``sawtooth.consensus.raft.heartbeat_tick`` - Determines the interval at which
+  the leader sends heartbeat messages to all other nodes. Default is ``2``.
+* ``sawtooth.consensus.raft.election_tick`` - Determines the timeout after which
+  nodes can start new elections if no messages have been received from the
+  leader. Default is ``20``.
+* ``sawtooth.consensus.raft.period`` - Determines the length of time (in
+  milliseconds) that the consensus engine will wait between initializing and
+  finalizing a block. Default is ``3000``.
+
+These optional settings should only be set `before` any Raft engines have
+started up; if they are changed on a running network and a new node is started,
+these values will be different on the new engine than the rest of the network,
+which could result in unpredictable behavior.",106,2018-09-21 17:07:22,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219311027,https://github.com/hyperledger/sawtooth-raft/pull/31#discussion_r219311027,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/31,https://github.com/hyperledger/sawtooth-raft/pull/31,"Maybe easier to just pick one and use that command in its entirety i.e. 
```docker-compose -f workload.yaml down```
Ambiguity in directions tends to translate into questions on :rocket: chat. ",e2d04656e384bdff1dc9bb55101cd7bb6e68d081,2018-09-20 20:48:32,219312686,"@@ -0,0 +1,298 @@
+***************************************
+Configuring and Deploying Sawtooth Raft
+***************************************
+
+This guide assumes previous experience with creating and deploying Sawtooth
+networks; if you are unfamiliar with Sawtooth, please see the `Application
+Developer's Guide`_ and `System Administrator's Guide`_ in the Sawtooth Core
+documentation.
+
+.. _Application Developer's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/app_developers_guide.html
+.. _System Administrator's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/sysadmin_guide.html
+
+This guide also requires a basic understanding of the Raft consensus algorithm;
+if you are not familiar with Raft, please see the `Raft`_ webpage.
+
+.. _Raft: https://raft.github.io/
+
+
+Validator Peering Requirements
+==============================
+
+Sawtooth Raft requires a fully-peered network where all nodes are able to
+communicate with all other nodes. This is necessary to establish a leader
+through the election process, as well as to maintain leadership through regular
+heartbeat messages. If a Raft network is not fully-peered, leadership election
+may fail due to some nodes being unable to communicate with one another.
+
+In order to achieve a fully-peered network, the list of peers that comprise the
+network will need to be known and maintained at all times. This means that Raft
+networks do not support open membership; an administrator must explicitly add or
+remove nodes to change membership (see `Changing Network Membership`_ for more
+details).
+
+To setup a fully-peered network, all validators must be started with the
+following two options:
+
+* ``--peering static`` - Informs the validator to connect with all of the
+  specified peers.
+* ``--peers {peers_list}`` - Provides the list of peers for the validator to
+  connect to, where `{peers_list}` is the list of public endpoints for all other
+  previously started validators.
+
+For example, if there are two validators already running with public endpoints
+``203.0.113.1:8800`` and ``203.0.113.2:8800``, a new validator would be started
+with the options ``--peering static --peers
+tcp://203.0.113.1:8800,tcp://203.0.113.2:8800``. Since peering is
+bi-directional, when the new validator connects with the existing validators,
+the existing validators will be fully peered as well.
+
+
+On-Chain Settings
+=================
+
+When starting a fresh network with the Sawtooth Raft consensus engine, the
+required settings below (and the desired optional settings) should be set in the
+genesis block.
+
+
+Required Settings
+-----------------
+
+* ``sawtooth.consensus.algorithm`` - Tells the network which consensus engine to
+  use. Must be set to ``raft``.
+* ``sawtooth.consensus.raft.peers`` - A JSON list of public keys of all
+  validators in the network, formatted as hex strings.
+
+The ``sawtooth.consensus.raft.peers`` setting is extremely important, since the
+Raft engine uses it as its source-of-truth for which nodes to communicate with.
+When a Raft engine starts initially, it checks the setting to determine which
+nodes are in the network. This setting is also used to add or remove nodes from
+the Raft network as covered in the `Changing Network Membership`_ section. As an
+example, the value of ``sawtooth.consensus.raft.peers`` would be formatted like
+this:
+
+.. code-block:: json
+
+  [
+    ""dc26a7099e81bb02869cc8ae57da030fbe4cf276b38ab37d2cc815fec63a14ab"",
+    ""df8e8388ced559bd35c2b05199ca9f8fbebb420979715003355dcb7363016c1d""
+  ]
+
+
+Optional Settings
+-----------------
+
+* ``sawtooth.consensus.raft.heartbeat_tick`` - Determines the interval at which
+  the leader sends heartbeat messages to all other nodes. Default is ``2``.
+* ``sawtooth.consensus.raft.election_tick`` - Determines the timeout after which
+  nodes can start new elections if no messages have been received from the
+  leader. Default is ``20``.
+* ``sawtooth.consensus.raft.period`` - Determines the length of time (in
+  milliseconds) that the consensus engine will wait between initializing and
+  finalizing a block. Default is ``3000``.
+
+These optional settings should only be set `before` any Raft engines have
+started up; if they are changed on a running network and a new node is started,
+these values will be different on the new engine than the rest of the network,
+which could result in unpredictable behavior.
+
+
+Starting a Raft Engine
+======================
+
+
+Configuring the State Storage Directory
+---------------------------------------
+
+The Raft engine stores its state on the file system; by default, it uses the
+``/var/lib/sawtooth-raft`` directory, but this can be changed by setting the
+``SAWTOOTH_RAFT_HOME`` environment variable to the desired path.
+
+
+Logging Configuration
+---------------------
+
+Sawtooth Raft logs to the console by default, but supports
+configurable logging through the `log4rs`_ and `log4rs-syslog`_ libraries. The
+`sawtooth-raft repository`_ provides an example logging configuration file that
+demonstrates how to configure Raft to use syslog (``logging/syslog.yaml``). For
+more examples of logging configuration files, please see the
+`log4rs documentation`_.
+
+.. _log4rs: https://github.com/sfackler/log4rs
+.. _log4rs-syslog: https://github.com/im-0/log4rs-syslog
+.. _sawtooth-raft repository: https://github.com/hyperledger/sawtooth-raft
+.. _log4rs documentation: https://docs.rs/log4rs/0.8.0/log4rs/
+
+The Raft engine provides the ``-L`` option for specifying a logging
+configuration YAML file. For example, to start Raft with the provided syslog
+configuration, you would provide the option ``-L logging/syslog.yaml``.
+
+Sawtooth Raft also supports configurable logging verbosity at run-time. By
+default, it logs with the ``WARN`` logging level (or the logging level specified
+in the configuration file), but this can be changed by providing one or more
+verbosity flags on startup:
+
+- ``-v`` - ``INFO`` logging level
+- ``-vv`` - ``DEBUG`` logging level
+- ``-vvv`` - ``TRACE`` logging level
+
+
+Connecting to the Validator
+---------------------------
+
+When a Sawtooth Raft engine is started, it must be connected to the validator,
+which can be done using the ``--connect`` command line option. For example, if
+the validator is running on host ``203.0.113.0`` and is using the default
+consensus port ``5050``, then the Raft engine should be started with ``--connect
+tcp://127.0.0.1:5050``. If this option is not specified, Sawtooth Raft will
+attempt to connect with the default validator address: ``tcp://localhost:5050``.
+
+Once the validator and the Raft engine have been started, you can check that the
+engine has connected to the validator and registered itself by looking in the
+validator logs for the message ``Consensus engine registered: sawtooth-raft
+X.Y.Z``.
+
+
+Starting a Multi-Node Raft Network
+==================================
+
+The `sawtooth-raft repository`_ provides a set of Docker Compose files in the
+``adhoc`` directory that allow one to quickly and easily setup a Raft network
+using Docker. The compose files in this directory are designed to make manual,
+ad-hoc deployments and testing of Sawtooth Raft networks simpler.
+
+
+Starting the Network
+--------------------
+
+Make sure you have all the Docker images you need:
+
+- sawtooth-validator (>= v1.1)
+- sawtooth-rest-api
+- sawtooth-intkey-tp-python
+- sawtooth-intkey-workload
+- sawtooth-settings-tp
+
+To build these from `sawtooth-core`_, run the following:
+
+.. _sawtooth-core: https://github.com/hyperledger/sawtooth-core
+.. code-block:: console
+
+  $ docker-compose -f docker-compose-installed.yaml build \
+  validator \
+  rest-api \
+  intkey-tp-python \
+  intkey-workload \
+  settings-tp
+
+
+Starting the Admin Service
+~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+This compose file creates the shared network and volume required for the
+validator network to communicate.
+
+.. code-block:: console
+
+  $ docker-compose -f admin.yaml up -d
+
+
+Starting the Nodes
+~~~~~~~~~~~~~~~~~~
+
+If N is the number of nodes you want to create, startup N-1 nodes with the
+``node.yaml`` compose file. For each node, you will need to select a unique name
+and provide this with the ``-p`` option. Example:
+
+.. code-block:: console
+
+  $ docker-compose -p alpha -f node.yaml up
+
+Note that you can include the ``-d`` flag to create all nodes from a single
+terminal.
+
+For the last node, do the same as above, but also set the ``GENESIS`` environment
+variable. Example:
+
+.. code-block:: console
+
+  $ GENESIS=1 docker-compose -p genesis -f node.yaml up
+
+Note that each time a node is started, it adds itself to the list of nodes that
+all new nodes will connect to. This means that if you mess something up starting
+a node, you may need to start over. To do this, use ``docker-compose down`` for
+each node you started, passing the appropriate ``-p`` value; then do
+``docker-compose -f admin.yaml down``.
+
+
+Stopping and Restarting Nodes On a Network
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+To stop a node on a network, you need to stop the containers for that node
+**without removing them**. If you remove the containers, then that node is gone
+for good. To avoid for this, do **NOT** use ``docker-compose down``.
+
+If you are attached to the containers, you can press CTRL+C to stop the node's
+containers.
+
+If you are not attached to the containers, use the command ``docker-compose
+stop`` with the appropriate ``-p`` flag.
+
+After you have stopped a node, you can use ``docker-compose start`` with the
+appropriate ``-p`` flag to restart the stopped node.
+
+
+Applying Workload On a Network
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+A workload generator can be started against the network using the
+``workload.yaml`` compose file. To change the rate from the default, set the
+``RATE`` environment variable prior to running the compose command.
+
+For example, to start a workload of 2 TPS against the network, do:
+
+.. code-block:: console
+
+  $ RATE=2 docker-compose -f workload.yaml up
+
+To stop the workload, use ``docker-compose stop`` or ``docker-compose down``
+with ``workload.yaml``.",,2018-09-21 17:07:22,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219312686,https://github.com/hyperledger/sawtooth-raft/pull/31#discussion_r219312686,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/31,https://github.com/hyperledger/sawtooth-raft/pull/31,"Currently, we don't support changing the heartbeat tick, election tick, or period on a running network. This would require monitoring these on-chain settings and applying the changes to the Raft nodes similarly to what we do with `sawtooth.consensus.raft.peers`.",e2d04656e384bdff1dc9bb55101cd7bb6e68d081,2018-09-20 21:01:11,219316384,"@@ -0,0 +1,298 @@
+***************************************
+Configuring and Deploying Sawtooth Raft
+***************************************
+
+This guide assumes previous experience with creating and deploying Sawtooth
+networks; if you are unfamiliar with Sawtooth, please see the `Application
+Developer's Guide`_ and `System Administrator's Guide`_ in the Sawtooth Core
+documentation.
+
+.. _Application Developer's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/app_developers_guide.html
+.. _System Administrator's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/sysadmin_guide.html
+
+This guide also requires a basic understanding of the Raft consensus algorithm;
+if you are not familiar with Raft, please see the `Raft`_ webpage.
+
+.. _Raft: https://raft.github.io/
+
+
+Validator Peering Requirements
+==============================
+
+Sawtooth Raft requires a fully-peered network where all nodes are able to
+communicate with all other nodes. This is necessary to establish a leader
+through the election process, as well as to maintain leadership through regular
+heartbeat messages. If a Raft network is not fully-peered, leadership election
+may fail due to some nodes being unable to communicate with one another.
+
+In order to achieve a fully-peered network, the list of peers that comprise the
+network will need to be known and maintained at all times. This means that Raft
+networks do not support open membership; an administrator must explicitly add or
+remove nodes to change membership (see `Changing Network Membership`_ for more
+details).
+
+To setup a fully-peered network, all validators must be started with the
+following two options:
+
+* ``--peering static`` - Informs the validator to connect with all of the
+  specified peers.
+* ``--peers {peers_list}`` - Provides the list of peers for the validator to
+  connect to, where `{peers_list}` is the list of public endpoints for all other
+  previously started validators.
+
+For example, if there are two validators already running with public endpoints
+``203.0.113.1:8800`` and ``203.0.113.2:8800``, a new validator would be started
+with the options ``--peering static --peers
+tcp://203.0.113.1:8800,tcp://203.0.113.2:8800``. Since peering is
+bi-directional, when the new validator connects with the existing validators,
+the existing validators will be fully peered as well.
+
+
+On-Chain Settings
+=================
+
+When starting a fresh network with the Sawtooth Raft consensus engine, the
+required settings below (and the desired optional settings) should be set in the
+genesis block.
+
+
+Required Settings
+-----------------
+
+* ``sawtooth.consensus.algorithm`` - Tells the network which consensus engine to
+  use. Must be set to ``raft``.
+* ``sawtooth.consensus.raft.peers`` - A JSON list of public keys of all
+  validators in the network, formatted as hex strings.
+
+The ``sawtooth.consensus.raft.peers`` setting is extremely important, since the
+Raft engine uses it as its source-of-truth for which nodes to communicate with.
+When a Raft engine starts initially, it checks the setting to determine which
+nodes are in the network. This setting is also used to add or remove nodes from
+the Raft network as covered in the `Changing Network Membership`_ section. As an
+example, the value of ``sawtooth.consensus.raft.peers`` would be formatted like
+this:
+
+.. code-block:: json
+
+  [
+    ""dc26a7099e81bb02869cc8ae57da030fbe4cf276b38ab37d2cc815fec63a14ab"",
+    ""df8e8388ced559bd35c2b05199ca9f8fbebb420979715003355dcb7363016c1d""
+  ]
+
+
+Optional Settings
+-----------------
+
+* ``sawtooth.consensus.raft.heartbeat_tick`` - Determines the interval at which
+  the leader sends heartbeat messages to all other nodes. Default is ``2``.
+* ``sawtooth.consensus.raft.election_tick`` - Determines the timeout after which
+  nodes can start new elections if no messages have been received from the
+  leader. Default is ``20``.
+* ``sawtooth.consensus.raft.period`` - Determines the length of time (in
+  milliseconds) that the consensus engine will wait between initializing and
+  finalizing a block. Default is ``3000``.
+
+These optional settings should only be set `before` any Raft engines have
+started up; if they are changed on a running network and a new node is started,
+these values will be different on the new engine than the rest of the network,
+which could result in unpredictable behavior.",106,2018-09-21 17:07:22,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219316384,https://github.com/hyperledger/sawtooth-raft/pull/31#discussion_r219316384,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/31,https://github.com/hyperledger/sawtooth-raft/pull/31,"Need to add this to the landing page: https://build.sawtooth.me/job/Sawtooth-Hyperledger/job/sawtooth-raft/job/PR-31/1/artifact/docs/build/html/index.html

This file is generated from docs/source/_templates/indexcontent.html",e2d04656e384bdff1dc9bb55101cd7bb6e68d081,2018-09-20 21:13:56,219319901,"@@ -0,0 +1,298 @@
+***************************************",1,2018-09-21 17:07:22,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219319901,https://github.com/hyperledger/sawtooth-raft/pull/31#discussion_r219319901,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/31,https://github.com/hyperledger/sawtooth-raft/pull/31,"Suggest also including an example like the following:

For example, to startup a 3 node network where the nodes have endpoints alpha, beta, and gamma, you would do the following:
1. Startup the alpha validator with no peers specified
2. Startup the beta validator with `--peers tcp://alpha:8800`
3. Startup the gamma validator with `--peers tcp://alpha:8800,tcp://beta:8800`",e2d04656e384bdff1dc9bb55101cd7bb6e68d081,2018-09-20 21:21:56,219321854,"@@ -0,0 +1,301 @@
+***************************************
+Configuring and Deploying Sawtooth Raft
+***************************************
+
+This guide assumes previous experience with creating and deploying Sawtooth
+networks; if you are unfamiliar with Sawtooth, please see the `Application
+Developer's Guide`_ and `System Administrator's Guide`_ in the Sawtooth Core
+documentation.
+
+.. _Application Developer's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/app_developers_guide.html
+.. _System Administrator's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/sysadmin_guide.html
+
+This guide also requires a basic understanding of the Raft consensus algorithm;
+if you are not familiar with Raft, please see the `Raft`_ webpage.
+
+.. _Raft: https://raft.github.io/
+
+
+Validator Peering Requirements
+==============================
+
+Sawtooth Raft requires a fully-peered network where all nodes are able to
+communicate with all other nodes. This is necessary to establish a leader
+through the election process, as well as to maintain leadership through regular
+heartbeat messages. If a Raft network is not fully-peered, leadership election
+may fail due to some nodes being unable to communicate with one another.
+
+In order to achieve a fully-peered network, the list of peers that comprise the
+network will need to be known and maintained at all times. This means that Raft
+networks do not support open membership; an administrator must explicitly add or
+remove nodes to change membership (see `Changing Network Membership`_ for more
+details).
+
+To setup a fully-peered network, all validators must be started with the
+following two options:
+
+* ``--peering static`` - Informs the validator to connect with all of the
+  specified peers.
+* ``--peers {peers_list}`` - Provides the list of peers for the validator to
+  connect to, where `{peers_list}` is the list of public endpoints for all other
+  previously started validators.
+
+For example, if there are two validators already running with public endpoints
+``203.0.113.1:8800`` and ``203.0.113.2:8800``, a new validator would be started
+with the options ``--peering static --peers
+tcp://203.0.113.1:8800,tcp://203.0.113.2:8800``. Since peering is
+bi-directional, when the new validator connects with the existing validators,
+the existing validators will be fully peered as well.",,2018-09-21 17:07:22,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219321854,https://github.com/hyperledger/sawtooth-raft/pull/31#discussion_r219321854,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/31,https://github.com/hyperledger/sawtooth-raft/pull/31,The lines after `$ docker-compose` should be indented further (4 spaces should be good),e2d04656e384bdff1dc9bb55101cd7bb6e68d081,2018-09-20 21:23:09,219322154,"@@ -0,0 +1,301 @@
+***************************************
+Configuring and Deploying Sawtooth Raft
+***************************************
+
+This guide assumes previous experience with creating and deploying Sawtooth
+networks; if you are unfamiliar with Sawtooth, please see the `Application
+Developer's Guide`_ and `System Administrator's Guide`_ in the Sawtooth Core
+documentation.
+
+.. _Application Developer's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/app_developers_guide.html
+.. _System Administrator's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/sysadmin_guide.html
+
+This guide also requires a basic understanding of the Raft consensus algorithm;
+if you are not familiar with Raft, please see the `Raft`_ webpage.
+
+.. _Raft: https://raft.github.io/
+
+
+Validator Peering Requirements
+==============================
+
+Sawtooth Raft requires a fully-peered network where all nodes are able to
+communicate with all other nodes. This is necessary to establish a leader
+through the election process, as well as to maintain leadership through regular
+heartbeat messages. If a Raft network is not fully-peered, leadership election
+may fail due to some nodes being unable to communicate with one another.
+
+In order to achieve a fully-peered network, the list of peers that comprise the
+network will need to be known and maintained at all times. This means that Raft
+networks do not support open membership; an administrator must explicitly add or
+remove nodes to change membership (see `Changing Network Membership`_ for more
+details).
+
+To setup a fully-peered network, all validators must be started with the
+following two options:
+
+* ``--peering static`` - Informs the validator to connect with all of the
+  specified peers.
+* ``--peers {peers_list}`` - Provides the list of peers for the validator to
+  connect to, where `{peers_list}` is the list of public endpoints for all other
+  previously started validators.
+
+For example, if there are two validators already running with public endpoints
+``203.0.113.1:8800`` and ``203.0.113.2:8800``, a new validator would be started
+with the options ``--peering static --peers
+tcp://203.0.113.1:8800,tcp://203.0.113.2:8800``. Since peering is
+bi-directional, when the new validator connects with the existing validators,
+the existing validators will be fully peered as well.
+
+
+On-Chain Settings
+=================
+
+When starting a fresh network with the Sawtooth Raft consensus engine, the
+required settings below (and the desired optional settings) should be set in the
+genesis block.
+
+
+Required Settings
+-----------------
+
+* ``sawtooth.consensus.algorithm`` - Tells the network which consensus engine to
+  use. Must be set to ``raft``.
+* ``sawtooth.consensus.raft.peers`` - A JSON list of public keys of all
+  validators in the network, formatted as hex strings.
+
+The ``sawtooth.consensus.raft.peers`` setting is extremely important, since the
+Raft engine uses it as its source-of-truth for which nodes to communicate with.
+When a Raft engine starts initially, it checks the setting to determine which
+nodes are in the network. This setting is also used to add or remove nodes from
+the Raft network as covered in the `Changing Network Membership`_ section. As an
+example, the value of ``sawtooth.consensus.raft.peers`` would be formatted like
+this:
+
+.. code-block:: json
+
+  [
+    ""dc26a7099e81bb02869cc8ae57da030fbe4cf276b38ab37d2cc815fec63a14ab"",
+    ""df8e8388ced559bd35c2b05199ca9f8fbebb420979715003355dcb7363016c1d""
+  ]
+
+
+Optional Settings
+-----------------
+
+* ``sawtooth.consensus.raft.heartbeat_tick`` - Determines the interval at which
+  the leader sends heartbeat messages to all other nodes. Default is ``2``.
+* ``sawtooth.consensus.raft.election_tick`` - Determines the timeout after which
+  nodes can start new elections if no messages have been received from the
+  leader. Default is ``20``.
+* ``sawtooth.consensus.raft.period`` - Determines the length of time (in
+  milliseconds) that the consensus engine will wait between initializing and
+  finalizing a block. Default is ``3000``.
+
+These optional settings should only be set `before` any Raft engines have
+started up; if they are changed on a running network and a new node is started,
+these values will be different on the new engine than the rest of the network,
+which could result in unpredictable behavior.
+
+
+Starting a Raft Engine
+======================
+
+
+Configuring the State Storage Directory
+---------------------------------------
+
+The Raft engine stores its state on the file system; by default, it uses the
+``/var/lib/sawtooth-raft`` directory, but this can be changed by setting the
+``SAWTOOTH_RAFT_HOME`` environment variable to the desired path.
+
+
+Logging Configuration
+---------------------
+
+Sawtooth Raft logs to the console by default, but supports
+configurable logging through the `log4rs`_ and `log4rs-syslog`_ libraries. The
+`sawtooth-raft repository`_ provides an example logging configuration file that
+demonstrates how to configure Raft to use syslog (``logging/syslog.yaml``). For
+more examples of logging configuration files, please see the
+`log4rs documentation`_.
+
+.. _log4rs: https://github.com/sfackler/log4rs
+.. _log4rs-syslog: https://github.com/im-0/log4rs-syslog
+.. _sawtooth-raft repository: https://github.com/hyperledger/sawtooth-raft
+.. _log4rs documentation: https://docs.rs/log4rs/0.8.0/log4rs/
+
+The Raft engine provides the ``-L`` option for specifying a logging
+configuration YAML file. For example, to start Raft with the provided syslog
+configuration, you would provide the option ``-L logging/syslog.yaml``.
+
+Sawtooth Raft also supports configurable logging verbosity at run-time. By
+default, it logs with the ``WARN`` logging level (or the logging level specified
+in the configuration file), but this can be changed by providing one or more
+verbosity flags on startup:
+
+- ``-v`` - ``INFO`` logging level
+- ``-vv`` - ``DEBUG`` logging level
+- ``-vvv`` - ``TRACE`` logging level
+
+
+Connecting to the Validator
+---------------------------
+
+When a Sawtooth Raft engine is started, it must be connected to the validator,
+which can be done using the ``--connect`` command line option. For example, if
+the validator is running on host ``203.0.113.0`` and is using the default
+consensus port ``5050``, then the Raft engine should be started with ``--connect
+tcp://127.0.0.1:5050``. If this option is not specified, Sawtooth Raft will
+attempt to connect with the default validator address: ``tcp://localhost:5050``.
+
+Once the validator and the Raft engine have been started, you can check that the
+engine has connected to the validator and registered itself by looking in the
+validator logs for the message ``Consensus engine registered: sawtooth-raft
+X.Y.Z``.
+
+
+Starting a Multi-Node Raft Network
+==================================
+
+The `sawtooth-raft repository`_ provides a set of Docker Compose files in the
+``adhoc`` directory that allow one to quickly and easily setup a Raft network
+using Docker. The compose files in this directory are designed to make manual,
+ad-hoc deployments and testing of Sawtooth Raft networks simpler.
+
+
+Starting the Network
+--------------------
+
+Make sure you have all the Docker images you need:
+
+- sawtooth-validator (>= v1.1)
+- sawtooth-rest-api
+- sawtooth-intkey-tp-python
+- sawtooth-intkey-workload
+- sawtooth-settings-tp
+
+To build these from `sawtooth-core`_, run the following:
+
+.. _sawtooth-core: https://github.com/hyperledger/sawtooth-core
+.. code-block:: console
+
+  $ docker-compose -f docker-compose-installed.yaml build \
+  validator \
+  rest-api \
+  intkey-tp-python \
+  intkey-workload \
+  settings-tp",,2018-09-21 17:07:22,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219322154,https://github.com/hyperledger/sawtooth-raft/pull/31#discussion_r219322154,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/31,https://github.com/hyperledger/sawtooth-raft/pull/31,Added improvement to JIRA for supporting on-the-fly configuration changes: https://jira.hyperledger.org/browse/STL-1457,e2d04656e384bdff1dc9bb55101cd7bb6e68d081,2018-09-21 16:38:29,219557925,"@@ -0,0 +1,298 @@
+***************************************
+Configuring and Deploying Sawtooth Raft
+***************************************
+
+This guide assumes previous experience with creating and deploying Sawtooth
+networks; if you are unfamiliar with Sawtooth, please see the `Application
+Developer's Guide`_ and `System Administrator's Guide`_ in the Sawtooth Core
+documentation.
+
+.. _Application Developer's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/app_developers_guide.html
+.. _System Administrator's Guide: https://sawtooth.hyperledger.org/docs/core/nightly/master/sysadmin_guide.html
+
+This guide also requires a basic understanding of the Raft consensus algorithm;
+if you are not familiar with Raft, please see the `Raft`_ webpage.
+
+.. _Raft: https://raft.github.io/
+
+
+Validator Peering Requirements
+==============================
+
+Sawtooth Raft requires a fully-peered network where all nodes are able to
+communicate with all other nodes. This is necessary to establish a leader
+through the election process, as well as to maintain leadership through regular
+heartbeat messages. If a Raft network is not fully-peered, leadership election
+may fail due to some nodes being unable to communicate with one another.
+
+In order to achieve a fully-peered network, the list of peers that comprise the
+network will need to be known and maintained at all times. This means that Raft
+networks do not support open membership; an administrator must explicitly add or
+remove nodes to change membership (see `Changing Network Membership`_ for more
+details).
+
+To setup a fully-peered network, all validators must be started with the
+following two options:
+
+* ``--peering static`` - Informs the validator to connect with all of the
+  specified peers.
+* ``--peers {peers_list}`` - Provides the list of peers for the validator to
+  connect to, where `{peers_list}` is the list of public endpoints for all other
+  previously started validators.
+
+For example, if there are two validators already running with public endpoints
+``203.0.113.1:8800`` and ``203.0.113.2:8800``, a new validator would be started
+with the options ``--peering static --peers
+tcp://203.0.113.1:8800,tcp://203.0.113.2:8800``. Since peering is
+bi-directional, when the new validator connects with the existing validators,
+the existing validators will be fully peered as well.
+
+
+On-Chain Settings
+=================
+
+When starting a fresh network with the Sawtooth Raft consensus engine, the
+required settings below (and the desired optional settings) should be set in the
+genesis block.
+
+
+Required Settings
+-----------------
+
+* ``sawtooth.consensus.algorithm`` - Tells the network which consensus engine to
+  use. Must be set to ``raft``.
+* ``sawtooth.consensus.raft.peers`` - A JSON list of public keys of all
+  validators in the network, formatted as hex strings.
+
+The ``sawtooth.consensus.raft.peers`` setting is extremely important, since the
+Raft engine uses it as its source-of-truth for which nodes to communicate with.
+When a Raft engine starts initially, it checks the setting to determine which
+nodes are in the network. This setting is also used to add or remove nodes from
+the Raft network as covered in the `Changing Network Membership`_ section. As an
+example, the value of ``sawtooth.consensus.raft.peers`` would be formatted like
+this:
+
+.. code-block:: json
+
+  [
+    ""dc26a7099e81bb02869cc8ae57da030fbe4cf276b38ab37d2cc815fec63a14ab"",
+    ""df8e8388ced559bd35c2b05199ca9f8fbebb420979715003355dcb7363016c1d""
+  ]
+
+
+Optional Settings
+-----------------
+
+* ``sawtooth.consensus.raft.heartbeat_tick`` - Determines the interval at which
+  the leader sends heartbeat messages to all other nodes. Default is ``2``.
+* ``sawtooth.consensus.raft.election_tick`` - Determines the timeout after which
+  nodes can start new elections if no messages have been received from the
+  leader. Default is ``20``.
+* ``sawtooth.consensus.raft.period`` - Determines the length of time (in
+  milliseconds) that the consensus engine will wait between initializing and
+  finalizing a block. Default is ``3000``.
+
+These optional settings should only be set `before` any Raft engines have
+started up; if they are changed on a running network and a new node is started,
+these values will be different on the new engine than the rest of the network,
+which could result in unpredictable behavior.",106,2018-09-21 17:07:22,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219557925,https://github.com/hyperledger/sawtooth-raft/pull/31#discussion_r219557925,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/31,https://github.com/hyperledger/sawtooth-raft/pull/31,"Change ""Configuring and Deploying Sawtooth Raft"" to ""Configuration and Deployment""",e2d04656e384bdff1dc9bb55101cd7bb6e68d081,2018-09-21 17:01:14,219564321,"@@ -10,7 +10,10 @@
   <h1>Hyperledger Sawtooth Raft Documentation</h1>
 
   <p class=""biglink""><a class=""biglink"" href=""{{ pathto(""introduction"") }}"">{% trans %}Introduction{% endtrans %}</a><br/>
-    <span class=""linkdescr"">{% trans %}learn about Hyperledger Sawtooth{% endtrans %}</span></p>
+    <span class=""linkdescr"">{% trans %}learn about Hyperledger Sawtooth Raft{% endtrans %}</span></p>
+
+  <p class=""biglink""><a class=""biglink"" href=""{{ pathto(""configuring_deploying"") }}"">{% trans %}Configuring and Deploying Sawtooth Raft{% endtrans %}</a><br/>",,2018-09-21 17:07:22,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219564321,https://github.com/hyperledger/sawtooth-raft/pull/31#discussion_r219564321,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/30,https://github.com/hyperledger/sawtooth-raft/pull/30,"copy-pasta: `create_temp_storage(""test_storage_ext_compact"")` should be `create_temp_storage(""test_applied"")`",1087707cc8a33699c58681d4065d4fa1ad868d5b,2018-09-20 18:06:42,219263960,"@@ -478,6 +496,12 @@ mod tests {
         tests::test_storage_ext_compact(storage);
     }
 
+    #[test]
+    fn test_applied() {
+        let (_tmp, storage) = create_temp_storage(""test_storage_ext_compact"");",,2018-09-20 18:41:58,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219263960,https://github.com/hyperledger/sawtooth-raft/pull/30#discussion_r219263960,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/30,https://github.com/hyperledger/sawtooth-raft/pull/30,"No reason to mention blocks here, since the StorageExt trait isn't operating on them and it leaks how we're using it.",1087707cc8a33699c58681d4065d4fa1ad868d5b,2018-09-20 18:07:50,219264327,"@@ -42,6 +42,12 @@ pub trait StorageExt: Storage {
     /// Append the new entries to storage
     fn append(&self, ents: &[Entry]) -> Result<(), Error>;
 
+    /// Get the index of the raft entry that corresponds to the last block that was committed",,2018-09-20 18:41:58,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219264327,https://github.com/hyperledger/sawtooth-raft/pull/30#discussion_r219264327,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/30,https://github.com/hyperledger/sawtooth-raft/pull/30,"copy-pasta: create_temp_storage(""test_storage_ext_compact"") should be create_temp_storage(""test_applied"")",1087707cc8a33699c58681d4065d4fa1ad868d5b,2018-09-20 18:08:42,219264589,"@@ -305,6 +315,12 @@ mod tests {
         tests::test_storage_ext_compact(storage);
     }
 
+    #[test]
+    fn test_applied() {
+        let (_tmp, storage) = create_temp_storage(""test_storage_ext_compact"");",,2018-09-20 18:41:58,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219264589,https://github.com/hyperledger/sawtooth-raft/pull/30#discussion_r219264589,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/30,https://github.com/hyperledger/sawtooth-raft/pull/30,"I am fine with omitting this from the cache, but my reasoning is that you only read this once on startup. I'm not sure the reasoning in the comment makes sense.",1087707cc8a33699c58681d4065d4fa1ad868d5b,2018-09-20 18:10:08,219265021,"@@ -251,6 +251,16 @@ impl<S: StorageExt> StorageExt for CachedStorage<S> {
         self.storage.append(entries)
     }
 
+    // The cache resides in memory and is not persistent, so we only care about setting/getting the
+    // last applied entry in the underlying storage (which may be persistent)
+    fn applied(&self) -> Result<u64, raft::Error> {",,2018-09-20 18:41:58,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219265021,https://github.com/hyperledger/sawtooth-raft/pull/30#discussion_r219265021,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/30,https://github.com/hyperledger/sawtooth-raft/pull/30,"I think this is unrelated to the rest of the commit. If so, it should be in a separate commit.",1087707cc8a33699c58681d4065d4fa1ad868d5b,2018-09-20 18:12:10,219265703,"@@ -21,6 +21,7 @@ use std::collections::{HashMap, VecDeque};
      engine::{Block, BlockId},
  };
 
+#[derive(Debug)]",,2018-09-20 18:41:58,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/219265703,https://github.com/hyperledger/sawtooth-raft/pull/30#discussion_r219265703,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/28,https://github.com/hyperledger/sawtooth-raft/pull/28,The git commit message associated with this change could be improved. The summary should state how the problem is being fixed and the message should include both the problem and how it was fixed.,a0e1ec3151e6da7ff257576199d08782359be9a6,2018-09-19 13:27:07,218802073,"@@ -34,8 +34,7 @@ INIT_APIS=($(docker exec $ADMIN bash -c 'cd /shared_data/rest_apis && ls -d *'))
 echo ""Initial APIs:"" ${INIT_APIS[*]}
 
 echo ""Waiting until network has started""
-docker exec $ADMIN bash -c 'while true; do \
-  API=$(ls /shared_data/rest_apis | head -n 1); \
+docker exec -e API=${INIT_APIS[0]} $ADMIN bash -c 'while true; do \",6,2018-09-19 15:07:56,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/218802073,https://github.com/hyperledger/sawtooth-raft/pull/28#discussion_r218802073,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/27,https://github.com/hyperledger/sawtooth-raft/pull/27,Do you want this println rather than a log statement?,2df160f40e22b70fb75ecf12a3c3ddf1d504cdfc,2018-09-17 16:39:12,218141831,"@@ -52,18 +53,32 @@ impl Storage for FsStorage {
     }
 
     fn entries(&self, low: u64, high: u64, _max_size: u64) -> Result<Vec<Entry>, raft::Error> {
-        let mut entries: Vec<Entry> = read_entries_sorted_by_index(&self.entries_dir)?;
+        if low > high {
+            return err_compacted();
+        }
+
+        let first_entry_index = read_first_index(&self.data_dir)?;
+        let last_entry_index = read_last_index(&self.data_dir)?;
+
+        println!(""low={}, high={}, first_entry_index={}, last_entry_index={}"", low, high, first_entry_index, last_entry_index);",,2018-09-17 18:05:21,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/218141831,https://github.com/hyperledger/sawtooth-raft/pull/27#discussion_r218141831,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/27,https://github.com/hyperledger/sawtooth-raft/pull/27,Is there a reason this `println` is here?,2df160f40e22b70fb75ecf12a3c3ddf1d504cdfc,2018-09-17 16:42:46,218143084,"@@ -52,18 +53,32 @@ impl Storage for FsStorage {
     }
 
     fn entries(&self, low: u64, high: u64, _max_size: u64) -> Result<Vec<Entry>, raft::Error> {
-        let mut entries: Vec<Entry> = read_entries_sorted_by_index(&self.entries_dir)?;
+        if low > high {
+            return err_compacted();
+        }
+
+        let first_entry_index = read_first_index(&self.data_dir)?;
+        let last_entry_index = read_last_index(&self.data_dir)?;
+
+        println!(""low={}, high={}, first_entry_index={}, last_entry_index={}"", low, high, first_entry_index, last_entry_index);",,2018-09-17 18:05:21,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/218143084,https://github.com/hyperledger/sawtooth-raft/pull/27#discussion_r218143084,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/27,https://github.com/hyperledger/sawtooth-raft/pull/27,Accidentally left that in from debugging,2df160f40e22b70fb75ecf12a3c3ddf1d504cdfc,2018-09-17 18:05:44,218170225,"@@ -52,18 +53,32 @@ impl Storage for FsStorage {
     }
 
     fn entries(&self, low: u64, high: u64, _max_size: u64) -> Result<Vec<Entry>, raft::Error> {
-        let mut entries: Vec<Entry> = read_entries_sorted_by_index(&self.entries_dir)?;
+        if low > high {
+            return err_compacted();
+        }
+
+        let first_entry_index = read_first_index(&self.data_dir)?;
+        let last_entry_index = read_last_index(&self.data_dir)?;
+
+        println!(""low={}, high={}, first_entry_index={}, last_entry_index={}"", low, high, first_entry_index, last_entry_index);",,2018-09-17 18:05:44,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/218170225,https://github.com/hyperledger/sawtooth-raft/pull/27#discussion_r218170225,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/25,https://github.com/hyperledger/sawtooth-raft/pull/25,I think we should follow the convention used in core and just call this `sawtooth-raft-engine`. You may need to update the other compose file to use an image name of `sawtooth-raft-engine-local` and remove the $INSTALL_TYPE env var.,684e4e1f3620ea79760b705487df85c1c83f21ac,2018-09-14 15:55:21,217760673,"@@ -0,0 +1,14 @@
+version: '3.6'
+
+volumes:
+  cargo-registry:
+
+services:
+  raft-engine:
+    image: sawtooth-raft-engine-installed:$ISOLATION_ID",,2018-09-14 19:06:54,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217760673,https://github.com/hyperledger/sawtooth-raft/pull/25#discussion_r217760673,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/25,https://github.com/hyperledger/sawtooth-raft/pull/25,You shouldn't need any volumes for building in installed mode.,684e4e1f3620ea79760b705487df85c1c83f21ac,2018-09-14 15:56:28,217761078,"@@ -0,0 +1,14 @@
+version: '3.6'
+
+volumes:
+  cargo-registry:
+
+services:
+  raft-engine:
+    image: sawtooth-raft-engine-installed:$ISOLATION_ID
+    build:
+      context: .
+      dockerfile: Dockerfile-installed
+    volumes:
+      - ./:/project/sawtooth-raft
+      - cargo-registry:/root/.cargo/registry",,2018-09-14 19:06:54,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217761078,https://github.com/hyperledger/sawtooth-raft/pull/25#discussion_r217761078,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/25,https://github.com/hyperledger/sawtooth-raft/pull/25,"We should use the installed image to run tests, so we know we are releasing working artifacts (meaning you should delete the old `docker-compose up --build`.",684e4e1f3620ea79760b705487df85c1c83f21ac,2018-09-14 16:13:29,217765903,"@@ -66,6 +66,7 @@ node ('master') {
             // Build Raft
             stage(""Build Raft"") {
               sh ""docker-compose up --build --abort-on-container-exit --force-recreate --renew-anon-volumes --exit-code-from raft-engine""
+              sh ""docker-compose -f docker-compose-installed.yaml build""",4,2018-09-14 19:06:54,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217765903,https://github.com/hyperledger/sawtooth-raft/pull/25#discussion_r217765903,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/25,https://github.com/hyperledger/sawtooth-raft/pull/25,It seems that we have to run them in the first container as that's the only one that has cargo installed.,684e4e1f3620ea79760b705487df85c1c83f21ac,2018-09-14 18:09:50,217797968,"@@ -66,6 +66,7 @@ node ('master') {
             // Build Raft
             stage(""Build Raft"") {
               sh ""docker-compose up --build --abort-on-container-exit --force-recreate --renew-anon-volumes --exit-code-from raft-engine""
+              sh ""docker-compose -f docker-compose-installed.yaml build""",4,2018-09-14 19:06:54,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217797968,https://github.com/hyperledger/sawtooth-raft/pull/25#discussion_r217797968,rberg2
https://github.com/hyperledger/sawtooth-raft/pull/25,https://github.com/hyperledger/sawtooth-raft/pull/25,"You are right, you need to run the unit tests in the local image because you need `cargo`. You should be able to run the integration tests from the installed images though.",684e4e1f3620ea79760b705487df85c1c83f21ac,2018-09-14 19:20:49,217817312,"@@ -66,6 +66,7 @@ node ('master') {
             // Build Raft
             stage(""Build Raft"") {
               sh ""docker-compose up --build --abort-on-container-exit --force-recreate --renew-anon-volumes --exit-code-from raft-engine""
+              sh ""docker-compose -f docker-compose-installed.yaml build""",4,2018-09-14 19:20:49,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217817312,https://github.com/hyperledger/sawtooth-raft/pull/25#discussion_r217817312,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,This refactor should be a separate commit.,060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-13 20:39:35,217526517,"@@ -142,3 +132,17 @@ pub fn peer_id_to_raft_id(peer_id: &PeerId) -> u64 {
     }
     u
 }
+
+/// Get the peers as a Vec<PeerId> from settings
+pub fn get_peers_from_settings(settings: &HashMap<String, String>) -> Vec<PeerId> {
+    let peers_setting_value = settings
+        .get(""sawtooth.consensus.raft.peers"")
+        .expect(""'sawtooth.consensus.raft.peers' must be set to use Raft"");
+
+    let peers: Vec<String> = serde_json::from_str(peers_setting_value)
+        .expect(""Invalid value at 'sawtooth.consensus.raft.peers'"");
+
+    peers.into_iter()
+        .map(|s| PeerId::from(hex::decode(s).expect(""Peer id not valid hex"")))
+        .collect()
+}",36,2018-09-14 18:49:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217526517,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217526517,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,This change should be refactored behind a private method. Something like `check_for_conf_change(&self) -> Option<ConfChange>` would probably be clearer and a good level of abstraction.,060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-13 20:45:50,217528352,"@@ -142,9 +146,48 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             },
             _ => false,
         } {
-            debug!(""Leader({:?}) transition to Building block {:?}"", self.peer_id, block_id);
-            self.leader_state = Some(LeaderState::Building(Instant::now()));
-            self.service.initialize_block(None).expect(""Failed to initialize block"");
+            // Get list of peers from settings
+            let settings = self.service
+                .get_settings(block_id.clone(), vec![String::from(""sawtooth.consensus.raft.peers"")])
+                .expect(""Failed to get settings"");
+            let peers = get_peers_from_settings(&settings);
+            let peers: HashSet<PeerId> = HashSet::from_iter(peers);
+
+            // Check if membership has changed
+            let old_peers: HashSet<PeerId> = HashSet::from_iter(self.raft_id_to_peer_id.values().cloned());
+            let difference: HashSet<PeerId> = peers.symmetric_difference(&old_peers).cloned().collect();
+
+            if !difference.is_empty() {
+                if difference.len() > 1 {
+                    panic!(""More than one node's membership has changed; only one change can be processed at a time."");
+                }
+
+                // The raft-rs library can only add or delete one node at a time, so there should
+                // only be one item in this iterator
+                difference.iter().for_each(|peer_id| {
+                    // Initialize change
+                    let mut change = ConfChange::new();
+                    change.set_node_id(peer_id_to_raft_id(&peer_id));
+
+                    // Check if adding or removing Node
+                    if peers.len() > old_peers.len() {
+                        change.set_change_type(ConfChangeType::AddNode);
+                        // Include peer ID in context so node can be added to raft_id_to_peer_id map later
+                        change.set_context(Vec::from(peer_id.clone()));
+                    } else if peers.len() < old_peers.len() {
+                        change.set_change_type(ConfChangeType::RemoveNode);
+                    }
+
+                    info!(""Leader({:?}) detected configuration change {:?}"", self.peer_id, change);
+                    debug!(""Leader({:?}) transition to ChangingConfig"", self.peer_id);
+                    self.leader_state = Some(LeaderState::ChangingConfig);
+                    self.raw_node.propose_conf_change(vec![], change).unwrap();
+                });
+            } else {
+                debug!(""Leader({:?}) transition to Building block {:?}"", self.peer_id, block_id);
+                self.leader_state = Some(LeaderState::Building(Instant::now()));
+                self.service.initialize_block(None).expect(""Failed to initialize block"");
+            }",50,2018-09-14 18:49:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217528352,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217528352,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,"I would suggest moving L338 to L355 behind a private method, something like `apply_conf_change(change: &ConfChange)` is probably good.",060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-13 20:48:54,217529228,"@@ -289,6 +332,33 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
                 if entry.get_entry_type() == EntryType::EntryNormal {
                     let block_id: BlockId = BlockId::from(Vec::from(entry.get_data()));
                     self.block_queue.add_block_commit(block_id);
+                } else if entry.get_entry_type() == EntryType::EntryConfChange && entry.get_term() != 1 {
+                    let change: ConfChange = protobuf::parse_from_bytes(entry.get_data())
+                        .expect(""Failed to parse ConfChange"");
+                    let raft_id = change.get_node_id();
+                    info!(""Configuration change received: {:?}"", change);
+
+                    // Update raft_id_to_peer_id according to change
+                    match change.get_change_type() {
+                        ConfChangeType::RemoveNode => {
+                            self.raft_id_to_peer_id.remove(&raft_id).unwrap();
+                        },
+                        ConfChangeType::AddNode => {
+                            self.raft_id_to_peer_id.insert(
+                                raft_id,
+                                PeerId::from(Vec::from(change.get_context()))
+                            );
+                        },
+                        _ => {}
+                    }
+
+                    self.raw_node.apply_conf_change(&change);",,2018-09-14 18:49:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217529228,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217529228,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,Needs copyright header,060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-13 20:50:58,217529853,"@@ -0,0 +1,54 @@
+#!/bin/bash",1,2018-09-14 18:49:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217529853,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217529853,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,"You can assign `$(docker ps | grep admin | awk '{print $1;}')` to a variable so you don't need to rerun the command constantly, as the output shouldn't change.",060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-13 20:52:50,217530424,"@@ -0,0 +1,54 @@
+#!/bin/bash
+
+### This script tests dynamic membership by starting a Raft network with 3 nodes, adding a 4th node, applying a workload, and checking that all 4 nodes reach block 5
+
+echo ""Starting initial network""
+docker-compose -f ../adhoc/admin.yaml up -d
+docker-compose -p alpha -f ../adhoc/node.yaml up -d
+docker-compose -p beta -f ../adhoc/node.yaml up -d
+GENESIS=1 docker-compose -p gamma -f ../adhoc/node.yaml up -d
+
+echo ""Gathering list of initial keys and REST APIs""
+INIT_KEYS=($(docker exec $(docker ps | grep admin | awk '{print $1;}') bash -c 'cd /shared_data/validators && paste $(ls -1) -d , | sed s/,/\ /g'))",,2018-09-14 18:49:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217530424,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217530424,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,Wrap long lines at 80 characters,060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-13 20:53:16,217530564,"@@ -0,0 +1,54 @@
+#!/bin/bash
+
+### This script tests dynamic membership by starting a Raft network with 3 nodes, adding a 4th node, applying a workload, and checking that all 4 nodes reach block 5
+
+echo ""Starting initial network""
+docker-compose -f ../adhoc/admin.yaml up -d
+docker-compose -p alpha -f ../adhoc/node.yaml up -d
+docker-compose -p beta -f ../adhoc/node.yaml up -d
+GENESIS=1 docker-compose -p gamma -f ../adhoc/node.yaml up -d
+
+echo ""Gathering list of initial keys and REST APIs""
+INIT_KEYS=($(docker exec $(docker ps | grep admin | awk '{print $1;}') bash -c 'cd /shared_data/validators && paste $(ls -1) -d , | sed s/,/\ /g'))
+echo ""Initial keys:"" ${INIT_KEYS[*]}
+INIT_APIS=($(docker exec $(docker ps | grep admin | awk '{print $1;}') bash -c 'cd /shared_data/rest_apis && ls -d *'))
+echo ""Initial APIs:"" ${INIT_APIS[*]}
+
+echo ""Waiting until network has started""
+docker exec $(docker ps | grep admin | awk '{print $1;}') bash -c 'while true; do if [[ $(sawtooth block list --url ""http://$(ls /shared_data/rest_apis | head -n 1):8008"" 2>&1) == *""BLOCK_ID""* ]]; then echo ""Network ready"" && break; else echo ""Still waiting..."" && sleep 0.5; fi; done;'",,2018-09-14 18:49:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217530564,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217530564,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,"Should we crash here? Even though Raft is not byzantine, this could be an interesting attack vector.  Perhaps the change should just be ignored if it can't be parsed, since presumably the change couldn't be parsed by anyone else in the network, either. ",060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-14 19:49:32,217824010,"@@ -289,6 +299,17 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
                 if entry.get_entry_type() == EntryType::EntryNormal {
                     let block_id: BlockId = BlockId::from(Vec::from(entry.get_data()));
                     self.block_queue.add_block_commit(block_id);
+                } else if entry.get_entry_type() == EntryType::EntryConfChange && entry.get_term() != 1 {
+                    let change: ConfChange = protobuf::parse_from_bytes(entry.get_data())
+                        .expect(""Failed to parse ConfChange"");",60,2018-09-14 19:50:09,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217824010,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217824010,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,"The error message that was deleted `""'sawtooth.consensus.raft.peers' must be set to use Raft""` seemed more informative.",060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-14 19:49:48,217824074,"@@ -333,6 +354,67 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             }
         }
     }
+
+    fn check_for_conf_change(&mut self, block_id: BlockId) -> Option<ConfChange> {
+        // Get list of peers from settings
+        let settings = self.service
+            .get_settings(block_id, vec![String::from(""sawtooth.consensus.raft.peers"")])
+            .expect(""Failed to get settings"");",81,2018-09-14 19:50:09,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217824074,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217824074,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,"That error message will be displayed if the peers setting isn't found (in the call to `get_peers_from_settings`). This is a different error where it can't even get the settings; if this fails, it's due to an actual error reported by the service.",060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-14 20:02:31,217827302,"@@ -333,6 +354,67 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             }
         }
     }
+
+    fn check_for_conf_change(&mut self, block_id: BlockId) -> Option<ConfChange> {
+        // Get list of peers from settings
+        let settings = self.service
+            .get_settings(block_id, vec![String::from(""sawtooth.consensus.raft.peers"")])
+            .expect(""Failed to get settings"");",81,2018-09-14 20:02:31,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217827302,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217827302,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,I suppose that makes sense to me. @aludvik what are your thoughts on this?,060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-14 20:06:19,217828188,"@@ -289,6 +299,17 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
                 if entry.get_entry_type() == EntryType::EntryNormal {
                     let block_id: BlockId = BlockId::from(Vec::from(entry.get_data()));
                     self.block_queue.add_block_commit(block_id);
+                } else if entry.get_entry_type() == EntryType::EntryConfChange && entry.get_term() != 1 {
+                    let change: ConfChange = protobuf::parse_from_bytes(entry.get_data())
+                        .expect(""Failed to parse ConfChange"");",60,2018-09-14 20:06:19,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217828188,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217828188,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,What happens when the validator goes down?  Does Raft go down too?,060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-14 20:35:37,217835188,"@@ -333,6 +354,67 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             }
         }
     }
+
+    fn check_for_conf_change(&mut self, block_id: BlockId) -> Option<ConfChange> {
+        // Get list of peers from settings
+        let settings = self.service
+            .get_settings(block_id, vec![String::from(""sawtooth.consensus.raft.peers"")])
+            .expect(""Failed to get settings"");",81,2018-09-14 20:35:37,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217835188,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217835188,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,"Yes, Raft goes down as well.",060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-14 21:18:26,217845127,"@@ -333,6 +354,67 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             }
         }
     }
+
+    fn check_for_conf_change(&mut self, block_id: BlockId) -> Option<ConfChange> {
+        // Get list of peers from settings
+        let settings = self.service
+            .get_settings(block_id, vec![String::from(""sawtooth.consensus.raft.peers"")])
+            .expect(""Failed to get settings"");",81,2018-09-14 21:18:26,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217845127,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217845127,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,"It sounds like this is currently a common pattern in sawtooth-raft, when dealing with network communication with the validator.  We should create a story to clean this up and handle any places where an error could occur from the validator gracefully.",060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-14 22:05:09,217853730,"@@ -333,6 +354,67 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             }
         }
     }
+
+    fn check_for_conf_change(&mut self, block_id: BlockId) -> Option<ConfChange> {
+        // Get list of peers from settings
+        let settings = self.service
+            .get_settings(block_id, vec![String::from(""sawtooth.consensus.raft.peers"")])
+            .expect(""Failed to get settings"");",81,2018-09-14 22:05:09,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217853730,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217853730,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,"I think it is better to crash than to carry on in an invalid state. If a setting change occurs, then you won't be able to restart nodes anyways so you are going to eventually end up crashed anyways (they wouldn't be able to determine what world view the rest of the network has). 

On-chain settings are already permissioned so we don't have to worry about a bad actor changing the setting maliciously, just admins making mistakes. I think we can implement mulit-node configuration changes later on as a new feature by extending the behavior of the library at the application level through multiple rounds of configuration changes.",060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-14 22:12:59,217854860,"@@ -289,6 +299,17 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
                 if entry.get_entry_type() == EntryType::EntryNormal {
                     let block_id: BlockId = BlockId::from(Vec::from(entry.get_data()));
                     self.block_queue.add_block_commit(block_id);
+                } else if entry.get_entry_type() == EntryType::EntryConfChange && entry.get_term() != 1 {
+                    let change: ConfChange = protobuf::parse_from_bytes(entry.get_data())
+                        .expect(""Failed to parse ConfChange"");",60,2018-09-14 22:12:59,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217854860,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217854860,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/24,https://github.com/hyperledger/sawtooth-raft/pull/24,"But that means a unparsable configuration setting (due to a typo) brings down the whole network.  Yes, on chain settings are permissioned. but that doesn't mean a typo couldn't get through the voting process. Plus, every node will receive the same bad setting, so they all should ignore the change.

That's not programmer error, that's user error.  `expect` should be reserved for programmer error, and other truly fatal conditions.

I think this actually applies more to the `get_peers_from_settings` function than this particular line. ",060655db165ae3cf896bcd31a17787a6116dfe5f,2018-09-14 22:40:33,217858637,"@@ -289,6 +299,17 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
                 if entry.get_entry_type() == EntryType::EntryNormal {
                     let block_id: BlockId = BlockId::from(Vec::from(entry.get_data()));
                     self.block_queue.add_block_commit(block_id);
+                } else if entry.get_entry_type() == EntryType::EntryConfChange && entry.get_term() != 1 {
+                    let change: ConfChange = protobuf::parse_from_bytes(entry.get_data())
+                        .expect(""Failed to parse ConfChange"");",60,2018-09-14 22:40:33,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/217858637,https://github.com/hyperledger/sawtooth-raft/pull/24#discussion_r217858637,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/19,https://github.com/hyperledger/sawtooth-raft/pull/19,This cache doesn't seem to consume very much memory; I'd like some feedback on whether a max size should need to be enforced.,f8498c3cfd55254f3b7c33692ade1581bae6edd5,2018-08-30 16:41:11,214101084,"@@ -0,0 +1,402 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::VecDeque;
+use std::io;
+use std::path::PathBuf;
+use std::sync::{Arc, RwLock, RwLockReadGuard, RwLockWriteGuard};
+
+use raft::{
+    self, eraftpb::{ConfState, Entry, HardState, Snapshot}, RaftState, Storage,
+};
+
+use fs_storage::FsStorage;
+use storage::StorageExt;
+
+pub const CACHE_SIZE: u64 = 10000;
+
+struct CacheStorage {
+    entries: VecDeque<Entry>,
+    // TODO: implement cache size limitation",,2018-09-04 19:17:02,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214101084,https://github.com/hyperledger/sawtooth-raft/pull/19#discussion_r214101084,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/19,https://github.com/hyperledger/sawtooth-raft/pull/19,Remove this TODO,f8498c3cfd55254f3b7c33692ade1581bae6edd5,2018-08-30 19:37:50,214155810,"@@ -0,0 +1,402 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::VecDeque;
+use std::io;
+use std::path::PathBuf;
+use std::sync::{Arc, RwLock, RwLockReadGuard, RwLockWriteGuard};
+
+use raft::{
+    self, eraftpb::{ConfState, Entry, HardState, Snapshot}, RaftState, Storage,
+};
+
+use fs_storage::FsStorage;
+use storage::StorageExt;
+
+pub const CACHE_SIZE: u64 = 10000;
+
+struct CacheStorage {
+    entries: VecDeque<Entry>,
+    // TODO: implement cache size limitation",,2018-09-04 19:17:02,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214155810,https://github.com/hyperledger/sawtooth-raft/pull/19#discussion_r214155810,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/19,https://github.com/hyperledger/sawtooth-raft/pull/19,"What are the items stored in this cache?  Blocks? Peers?  One may need enforcement, the other may not.",f8498c3cfd55254f3b7c33692ade1581bae6edd5,2018-08-30 19:38:39,214156030,"@@ -0,0 +1,402 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::VecDeque;
+use std::io;
+use std::path::PathBuf;
+use std::sync::{Arc, RwLock, RwLockReadGuard, RwLockWriteGuard};
+
+use raft::{
+    self, eraftpb::{ConfState, Entry, HardState, Snapshot}, RaftState, Storage,
+};
+
+use fs_storage::FsStorage;
+use storage::StorageExt;
+
+pub const CACHE_SIZE: u64 = 10000;
+
+struct CacheStorage {
+    entries: VecDeque<Entry>,
+    // TODO: implement cache size limitation",,2018-09-04 19:17:02,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214156030,https://github.com/hyperledger/sawtooth-raft/pull/19#discussion_r214156030,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/19,https://github.com/hyperledger/sawtooth-raft/pull/19,"This is essentially just storing block numbers. It has very low overhead. On a run with 50k+ blocks, the raft process as a whole only consumed about 35MB of memory with this cache. So unless anyone objects, I think a cache limit would be unnecessary, especially since a compaction mechanism already exists as part of Raft.",f8498c3cfd55254f3b7c33692ade1581bae6edd5,2018-08-30 20:20:36,214167593,"@@ -0,0 +1,402 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::VecDeque;
+use std::io;
+use std::path::PathBuf;
+use std::sync::{Arc, RwLock, RwLockReadGuard, RwLockWriteGuard};
+
+use raft::{
+    self, eraftpb::{ConfState, Entry, HardState, Snapshot}, RaftState, Storage,
+};
+
+use fs_storage::FsStorage;
+use storage::StorageExt;
+
+pub const CACHE_SIZE: u64 = 10000;
+
+struct CacheStorage {
+    entries: VecDeque<Entry>,
+    // TODO: implement cache size limitation",,2018-09-04 19:17:02,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214167593,https://github.com/hyperledger/sawtooth-raft/pull/19#discussion_r214167593,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/19,https://github.com/hyperledger/sawtooth-raft/pull/19,"Ok.  Just remove the TODO, then.",f8498c3cfd55254f3b7c33692ade1581bae6edd5,2018-08-30 21:27:37,214186318,"@@ -0,0 +1,402 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::VecDeque;
+use std::io;
+use std::path::PathBuf;
+use std::sync::{Arc, RwLock, RwLockReadGuard, RwLockWriteGuard};
+
+use raft::{
+    self, eraftpb::{ConfState, Entry, HardState, Snapshot}, RaftState, Storage,
+};
+
+use fs_storage::FsStorage;
+use storage::StorageExt;
+
+pub const CACHE_SIZE: u64 = 10000;
+
+struct CacheStorage {
+    entries: VecDeque<Entry>,
+    // TODO: implement cache size limitation",,2018-09-04 19:17:02,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214186318,https://github.com/hyperledger/sawtooth-raft/pull/19#discussion_r214186318,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/19,https://github.com/hyperledger/sawtooth-raft/pull/19,"Is it possible to make this generic over the type of storage like so:
```
pub struct CachedStorage<S: StorageExt> {
  storage: S,
...
```",f8498c3cfd55254f3b7c33692ade1581bae6edd5,2018-09-04 16:02:45,214974134,"@@ -0,0 +1,408 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::VecDeque;
+use std::io;
+use std::path::PathBuf;
+use std::sync::{Arc, RwLock, RwLockReadGuard, RwLockWriteGuard};
+
+use raft::{
+    self, eraftpb::{ConfState, Entry, HardState, Snapshot}, RaftState, Storage,
+};
+
+use fs_storage::FsStorage;
+use storage::StorageExt;
+
+pub const CACHE_SIZE: u64 = 10000;
+
+struct CacheStorage {
+    entries: VecDeque<Entry>,
+    _cache_size: u64,
+}
+
+impl CacheStorage {
+    fn with_cache_size(cache_size: u64) -> CacheStorage {
+        CacheStorage {
+            entries: VecDeque::new(),
+            _cache_size: cache_size,
+        }
+    }
+
+    fn first_index(&self) -> u64 {
+        match self.entries.front() {
+            Some(entry) => entry.index,
+            None => 1,
+        }
+    }
+
+    fn last_index(&self) -> u64 {
+        match self.entries.back() {
+            Some(entry) => entry.index,
+            None => 0,
+        }
+    }
+
+    fn entries(&self, low: u64, high: u64, _max_size: u64) -> Result<Vec<Entry>, raft::Error> {
+        if self.entries.is_empty() || low < self.first_index() {
+            return Err(raft::Error::Store(raft::StorageError::Compacted));
+        }
+
+        if high > self.last_index() + 1 {
+            return Err(raft::Error::Store(raft::StorageError::Unavailable));
+        }
+
+        Ok(self.entries
+            .iter()
+            .cloned()
+            .filter(|entry| entry.index >= low && entry.index < high)
+            .collect())
+    }
+
+    fn term(&self, idx: u64) -> Option<u64> {
+        self.entries
+            .iter()
+            .find(|ref entry| entry.index == idx)
+            .map(|entry| entry.term)
+    }
+
+    fn compact(&mut self, compact_index: u64) {
+        self.entries.retain(|entry| entry.index >= compact_index);
+    }
+
+    fn append(&mut self, entries: &[Entry]) {
+        entries
+            .into_iter()
+            .for_each(|entry| self.entries.push_back(entry.clone()));
+    }
+}
+
+pub struct CachedFsStorage {
+    fs_storage: FsStorage,",,2018-09-04 19:17:02,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214974134,https://github.com/hyperledger/sawtooth-raft/pull/19#discussion_r214974134,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/19,https://github.com/hyperledger/sawtooth-raft/pull/19,"Simple match statements like this should use the Result combinators like `map()`, `map_err()`, and `and_then()`. For example, the above could be rewritten as:
```
        self.fs_storage.apply_snapshot(snapshot)
              .map(|_| {
                  let compact_index = snapshot.get_metadata().get_index();
                  self.cache_write().compact(compact_index);
            })
```
See: https://doc.rust-lang.org/std/result/enum.Result.html#method.map",f8498c3cfd55254f3b7c33692ade1581bae6edd5,2018-09-04 16:21:24,214980303,"@@ -0,0 +1,408 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::VecDeque;
+use std::io;
+use std::path::PathBuf;
+use std::sync::{Arc, RwLock, RwLockReadGuard, RwLockWriteGuard};
+
+use raft::{
+    self, eraftpb::{ConfState, Entry, HardState, Snapshot}, RaftState, Storage,
+};
+
+use fs_storage::FsStorage;
+use storage::StorageExt;
+
+pub const CACHE_SIZE: u64 = 10000;
+
+struct CacheStorage {
+    entries: VecDeque<Entry>,
+    _cache_size: u64,
+}
+
+impl CacheStorage {
+    fn with_cache_size(cache_size: u64) -> CacheStorage {
+        CacheStorage {
+            entries: VecDeque::new(),
+            _cache_size: cache_size,
+        }
+    }
+
+    fn first_index(&self) -> u64 {
+        match self.entries.front() {
+            Some(entry) => entry.index,
+            None => 1,
+        }
+    }
+
+    fn last_index(&self) -> u64 {
+        match self.entries.back() {
+            Some(entry) => entry.index,
+            None => 0,
+        }
+    }
+
+    fn entries(&self, low: u64, high: u64, _max_size: u64) -> Result<Vec<Entry>, raft::Error> {
+        if self.entries.is_empty() || low < self.first_index() {
+            return Err(raft::Error::Store(raft::StorageError::Compacted));
+        }
+
+        if high > self.last_index() + 1 {
+            return Err(raft::Error::Store(raft::StorageError::Unavailable));
+        }
+
+        Ok(self.entries
+            .iter()
+            .cloned()
+            .filter(|entry| entry.index >= low && entry.index < high)
+            .collect())
+    }
+
+    fn term(&self, idx: u64) -> Option<u64> {
+        self.entries
+            .iter()
+            .find(|ref entry| entry.index == idx)
+            .map(|entry| entry.term)
+    }
+
+    fn compact(&mut self, compact_index: u64) {
+        self.entries.retain(|entry| entry.index >= compact_index);
+    }
+
+    fn append(&mut self, entries: &[Entry]) {
+        entries
+            .into_iter()
+            .for_each(|entry| self.entries.push_back(entry.clone()));
+    }
+}
+
+pub struct CachedFsStorage {
+    fs_storage: FsStorage,
+    cache: Arc<RwLock<CacheStorage>>,
+}
+
+impl CachedFsStorage {
+    pub fn with_data_dir(data_dir: PathBuf) -> io::Result<Self> {
+        let fs_storage = FsStorage::with_data_dir(data_dir).expect(""Failed to create FsStorage"");
+
+        Ok(CachedFsStorage {
+            fs_storage,
+            cache: Arc::new(RwLock::new(CacheStorage::with_cache_size(CACHE_SIZE))),
+        })
+    }
+
+    fn cache_read(&self) -> RwLockReadGuard<CacheStorage> {
+        self.cache.read().unwrap()
+    }
+
+    fn cache_write(&self) -> RwLockWriteGuard<CacheStorage> {
+        self.cache.write().unwrap()
+    }
+}
+
+impl Storage for CachedFsStorage {
+    fn initial_state(&self) -> Result<RaftState, raft::Error> {
+        self.fs_storage.initial_state()
+    }
+
+    fn entries(&self, low: u64, high: u64, _max_size: u64) -> Result<Vec<Entry>, raft::Error> {
+        self.cache_read().entries(low, high, _max_size)
+    }
+
+    fn term(&self, idx: u64) -> Result<u64, raft::Error> {
+        match self.cache_read().term(idx) {
+            Some(term) => Ok(term),
+            None => self.fs_storage.term(idx),
+        }
+    }
+
+    fn first_index(&self) -> Result<u64, raft::Error> {
+        Ok(self.cache_read().first_index())
+    }
+
+    fn last_index(&self) -> Result<u64, raft::Error> {
+        Ok(self.cache_read().last_index())
+    }
+
+    fn snapshot(&self) -> Result<Snapshot, raft::Error> {
+        self.fs_storage.snapshot()
+    }
+}
+
+impl StorageExt for CachedFsStorage {
+    fn set_hardstate(&self, hard_state: &HardState) {
+        self.fs_storage.set_hardstate(hard_state);
+    }
+
+    fn create_snapshot(
+        &self,
+        index: u64,
+        conf_state: Option<&ConfState>,
+        data: Vec<u8>,
+    ) -> Result<Snapshot, raft::Error> {
+        self.fs_storage.create_snapshot(index, conf_state, data)
+    }
+
+    fn apply_snapshot(&self, snapshot: &Snapshot) -> Result<(), raft::Error> {
+        match self.fs_storage.apply_snapshot(snapshot) {
+            Ok(_) => {
+                let compact_index = snapshot.get_metadata().get_index();
+                self.cache_write().compact(compact_index);
+                Ok(())
+            }
+            Err(e) => Err(e),
+        }",,2018-09-04 19:17:02,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214980303,https://github.com/hyperledger/sawtooth-raft/pull/19#discussion_r214980303,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/19,https://github.com/hyperledger/sawtooth-raft/pull/19,"Instead of providing a constructor for a specific type of storage, the constructor should take an argument of a type that implements StorageExt. So you would have:
```
impl CachedStorage<S: StorageExt> {
  pub fn new(storage: S) -> Self {
        Ok(CachedStorage {
            storage,
            cache: Arc::new(RwLock::new(Cache::with_cache_size(CACHE_SIZE))),
        })
  }
}
```
and then later when you construct this you would have:
```
    CachedStorage::new(
        FsStorage::with_data_dir(
            get_path_config().data_dir).expect(""Failed to create FsStorage""))
```",f8498c3cfd55254f3b7c33692ade1581bae6edd5,2018-09-04 17:11:48,214996000,"@@ -0,0 +1,398 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::VecDeque;
+use std::io;
+use std::path::PathBuf;
+use std::sync::{Arc, RwLock, RwLockReadGuard, RwLockWriteGuard};
+
+use raft::{
+    self, eraftpb::{ConfState, Entry, HardState, Snapshot}, RaftState, Storage,
+};
+
+use fs_storage::FsStorage;
+use storage::StorageExt;
+
+pub const CACHE_SIZE: u64 = 10000;
+
+struct Cache {
+    entries: VecDeque<Entry>,
+    _cache_size: u64,
+}
+
+impl Cache {
+    fn with_cache_size(cache_size: u64) -> Cache {
+        Cache {
+            entries: VecDeque::new(),
+            _cache_size: cache_size,
+        }
+    }
+
+    fn first_index(&self) -> u64 {
+        match self.entries.front() {
+            Some(entry) => entry.index,
+            None => 1,
+        }
+    }
+
+    fn last_index(&self) -> u64 {
+        match self.entries.back() {
+            Some(entry) => entry.index,
+            None => 0,
+        }
+    }
+
+    fn entries(&self, low: u64, high: u64, _max_size: u64) -> Result<Vec<Entry>, raft::Error> {
+        if self.entries.is_empty() || low < self.first_index() {
+            return Err(raft::Error::Store(raft::StorageError::Compacted));
+        }
+
+        if high > self.last_index() + 1 {
+            return Err(raft::Error::Store(raft::StorageError::Unavailable));
+        }
+
+        Ok(self.entries
+            .iter()
+            .cloned()
+            .filter(|entry| entry.index >= low && entry.index < high)
+            .collect())
+    }
+
+    fn term(&self, idx: u64) -> Option<u64> {
+        self.entries
+            .iter()
+            .find(|ref entry| entry.index == idx)
+            .map(|entry| entry.term)
+    }
+
+    fn compact(&mut self, compact_index: u64) {
+        self.entries.retain(|entry| entry.index >= compact_index);
+    }
+
+    fn append(&mut self, entries: &[Entry]) {
+        entries
+            .into_iter()
+            .for_each(|entry| self.entries.push_back(entry.clone()));
+    }
+}
+
+pub struct CachedStorage<S: StorageExt> {
+    storage: S,
+    cache: Arc<RwLock<Cache>>,
+}
+
+impl CachedStorage<FsStorage> {
+    pub fn with_data_dir(data_dir: PathBuf) -> io::Result<Self> {
+        let storage = FsStorage::with_data_dir(data_dir).expect(""Failed to create FsStorage"");
+
+        Ok(CachedStorage {
+            storage,
+            cache: Arc::new(RwLock::new(Cache::with_cache_size(CACHE_SIZE))),
+        })
+    }
+}",,2018-09-04 19:17:02,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214996000,https://github.com/hyperledger/sawtooth-raft/pull/19#discussion_r214996000,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/18,https://github.com/hyperledger/sawtooth-raft/pull/18,What is the consequence of failure here? Will the event be regenerated later?,96693fe33446688e8602ca1294a2d61d7c6fed03,2018-08-30 21:29:16,214186736,"@@ -101,13 +103,21 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
         }
 
+        debug!(""Block has been received: {:?}"", &block);
+        self.new_block_backlog.push_back(block.clone());
+
         self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
     }
 
     pub fn on_block_valid(&mut self, block_id: BlockId) {
         // Handle out of order new/valid updates
         debug!(""Block has been validated: {:?}"", &block_id);
-        self.valid_block_backlog.push_back(block_id.clone());
+        let block = self.new_block_backlog
+            .iter()
+            .cloned()
+            .find(|block| block.block_id == block_id)
+            .expect(""BlockNew not received before BlockValid"");
+        self.valid_block_backlog.push_back(block);",,2018-09-07 21:11:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214186736,https://github.com/hyperledger/sawtooth-raft/pull/18#discussion_r214186736,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/18,https://github.com/hyperledger/sawtooth-raft/pull/18,what's the difference between the new_block_backlog and the commit_block_backlog?,96693fe33446688e8602ca1294a2d61d7c6fed03,2018-08-30 21:32:47,214187684,"@@ -63,7 +63,8 @@ pub struct SawtoothRaftNode<S: StorageExt> {
     service: Box<Service>,
     leader_state: Option<LeaderState>,
     follower_state: Option<FollowerState>,
-    valid_block_backlog: VecDeque<BlockId>,
+    new_block_backlog: VecDeque<Block>,",,2018-09-07 21:11:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214187684,https://github.com/hyperledger/sawtooth-raft/pull/18#discussion_r214187684,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/18,https://github.com/hyperledger/sawtooth-raft/pull/18,"Originally I just used `valid_block_backlog` to hold blocks that have been validated; however, `on_block_valid` only takes in the block id, not the block itself. In order to check that the previous block has been committed (i.e. is the chain head), we need a copy of the block from the NewBlock message. When we get the ValidBlock message, we move the block to the other queue for comparison when we want to commit a block.",96693fe33446688e8602ca1294a2d61d7c6fed03,2018-08-30 22:27:54,214199956,"@@ -63,7 +63,8 @@ pub struct SawtoothRaftNode<S: StorageExt> {
     service: Box<Service>,
     leader_state: Option<LeaderState>,
     follower_state: Option<FollowerState>,
-    valid_block_backlog: VecDeque<BlockId>,
+    new_block_backlog: VecDeque<Block>,",,2018-09-07 21:11:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214199956,https://github.com/hyperledger/sawtooth-raft/pull/18#discussion_r214199956,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/18,https://github.com/hyperledger/sawtooth-raft/pull/18,"I don't believe it will. I have never seen a BlockValid message come before a BlockNew message, though, hence the `expect`. But I could make this more robust to guard against this scenario if necessary.",96693fe33446688e8602ca1294a2d61d7c6fed03,2018-08-30 22:31:26,214200619,"@@ -101,13 +103,21 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
         }
 
+        debug!(""Block has been received: {:?}"", &block);
+        self.new_block_backlog.push_back(block.clone());
+
         self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
     }
 
     pub fn on_block_valid(&mut self, block_id: BlockId) {
         // Handle out of order new/valid updates
         debug!(""Block has been validated: {:?}"", &block_id);
-        self.valid_block_backlog.push_back(block_id.clone());
+        let block = self.new_block_backlog
+            .iter()
+            .cloned()
+            .find(|block| block.block_id == block_id)
+            .expect(""BlockNew not received before BlockValid"");
+        self.valid_block_backlog.push_back(block);",,2018-09-07 21:11:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214200619,https://github.com/hyperledger/sawtooth-raft/pull/18#discussion_r214200619,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/18,https://github.com/hyperledger/sawtooth-raft/pull/18,"It could be a protocol error. I would suggest logging as error and returning. Otherwise, the whole consensus engine halts",96693fe33446688e8602ca1294a2d61d7c6fed03,2018-08-31 13:45:53,214358064,"@@ -101,13 +103,21 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
         }
 
+        debug!(""Block has been received: {:?}"", &block);
+        self.new_block_backlog.push_back(block.clone());
+
         self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
     }
 
     pub fn on_block_valid(&mut self, block_id: BlockId) {
         // Handle out of order new/valid updates
         debug!(""Block has been validated: {:?}"", &block_id);
-        self.valid_block_backlog.push_back(block_id.clone());
+        let block = self.new_block_backlog
+            .iter()
+            .cloned()
+            .find(|block| block.block_id == block_id)
+            .expect(""BlockNew not received before BlockValid"");
+        self.valid_block_backlog.push_back(block);",,2018-09-07 21:11:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214358064,https://github.com/hyperledger/sawtooth-raft/pull/18#discussion_r214358064,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/18,https://github.com/hyperledger/sawtooth-raft/pull/18,"We can fix this in a subsequent PR, though.",96693fe33446688e8602ca1294a2d61d7c6fed03,2018-08-31 18:18:07,214436995,"@@ -101,13 +103,21 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
         }
 
+        debug!(""Block has been received: {:?}"", &block);
+        self.new_block_backlog.push_back(block.clone());
+
         self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
     }
 
     pub fn on_block_valid(&mut self, block_id: BlockId) {
         // Handle out of order new/valid updates
         debug!(""Block has been validated: {:?}"", &block_id);
-        self.valid_block_backlog.push_back(block_id.clone());
+        let block = self.new_block_backlog
+            .iter()
+            .cloned()
+            .find(|block| block.block_id == block_id)
+            .expect(""BlockNew not received before BlockValid"");
+        self.valid_block_backlog.push_back(block);",,2018-09-07 21:11:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/214436995,https://github.com/hyperledger/sawtooth-raft/pull/18#discussion_r214436995,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/18,https://github.com/hyperledger/sawtooth-raft/pull/18,If it's brief would prefer we just fix this PR.,96693fe33446688e8602ca1294a2d61d7c6fed03,2018-09-05 13:15:26,215263589,"@@ -101,13 +103,21 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
             self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
         }
 
+        debug!(""Block has been received: {:?}"", &block);
+        self.new_block_backlog.push_back(block.clone());
+
         self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
     }
 
     pub fn on_block_valid(&mut self, block_id: BlockId) {
         // Handle out of order new/valid updates
         debug!(""Block has been validated: {:?}"", &block_id);
-        self.valid_block_backlog.push_back(block_id.clone());
+        let block = self.new_block_backlog
+            .iter()
+            .cloned()
+            .find(|block| block.block_id == block_id)
+            .expect(""BlockNew not received before BlockValid"");
+        self.valid_block_backlog.push_back(block);",,2018-09-07 21:11:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/215263589,https://github.com/hyperledger/sawtooth-raft/pull/18#discussion_r215263589,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/18,https://github.com/hyperledger/sawtooth-raft/pull/18,Can you please clarify how these queues or the general approach relates to the raft library's order enforcement mechanisms e.g. entry index?,96693fe33446688e8602ca1294a2d61d7c6fed03,2018-09-05 13:17:48,215264419,"@@ -63,7 +63,8 @@ pub struct SawtoothRaftNode<S: StorageExt> {
     service: Box<Service>,
     leader_state: Option<LeaderState>,
     follower_state: Option<FollowerState>,
-    valid_block_backlog: VecDeque<BlockId>,
+    new_block_backlog: VecDeque<Block>,",,2018-09-07 21:11:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/215264419,https://github.com/hyperledger/sawtooth-raft/pull/18#discussion_r215264419,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/18,https://github.com/hyperledger/sawtooth-raft/pull/18,"Raft's order enforcement does not guarantee anything about the application itself (i.e. Sawtooth). From the library's perspective, it accepts a state transition (new entry) and saves it to stable storage; it then tells the application to submit that entry. However, the application may not be ready to make that transition--in this case it may not be ready to commit the block because the validator is still in the process of validating said block. So the library makes no guarantees about the application, except that it will only tell the application to commit the entries sequentially. We can rely on the library to send commits in order, but we cannot rely on library to know when the validator is ready to commit blocks.",96693fe33446688e8602ca1294a2d61d7c6fed03,2018-09-05 14:52:54,215303720,"@@ -63,7 +63,8 @@ pub struct SawtoothRaftNode<S: StorageExt> {
     service: Box<Service>,
     leader_state: Option<LeaderState>,
     follower_state: Option<FollowerState>,
-    valid_block_backlog: VecDeque<BlockId>,
+    new_block_backlog: VecDeque<Block>,",,2018-09-07 21:11:16,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/215303720,https://github.com/hyperledger/sawtooth-raft/pull/18#discussion_r215303720,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/13,https://github.com/hyperledger/sawtooth-raft/pull/13,Suggest renaming to `commit_block_backlog`,8a07848695ed0d695fcc16cca3679ed7317d217f,2018-08-17 15:20:51,210944498,"@@ -63,6 +63,8 @@ pub struct SawtoothRaftNode<S: StorageExt> {
     service: Box<Service>,
     leader_state: Option<LeaderState>,
     follower_state: Option<FollowerState>,
+    valid_block_backlog: VecDeque<BlockId>,
+    backlog: VecDeque<BlockId>,",,2018-08-24 16:30:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/210944498,https://github.com/hyperledger/sawtooth-raft/pull/13#discussion_r210944498,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/13,https://github.com/hyperledger/sawtooth-raft/pull/13,Should this just check the back of the deque or otherwise check some ordering to satisfy the comment above about oldest first?,8a07848695ed0d695fcc16cca3679ed7317d217f,2018-08-20 02:21:17,211128135,"@@ -279,39 +294,59 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
                 if entry.get_entry_type() == EntryType::EntryNormal {
                     let block_id: BlockId = BlockId::from(Vec::from(entry.get_data()));
-                    debug!(""Peer({:?}) committing block {:?}"", self.peer_id, block_id);
-                    if match self.leader_state {
-                        Some(LeaderState::Proposing(ref proposed)) => {
-                            &block_id == proposed
-                        },
-                        _ => false,
-                    } {
-                        debug!(""Leader({:?}) transitioning to Committing block {:?}"", self.peer_id, block_id);
-                        self.leader_state = Some(LeaderState::Committing(block_id.clone()));
-                        self.service.commit_block(block_id.clone()).expect(""Failed to commit block"");
-                    }
-
-                    if self.follower_state.is_some() {
-                        match self.service.commit_block(block_id.clone()) {
-                            Err(Error::UnknownBlock(_)) => {
-                                debug!(
-                                    ""Follower({:?}) tried to commit block before available: {:?}"",
-                                    self.peer_id,
-                                    block_id
-                                );
-                                self.follower_state = Some(FollowerState::Committing(block_id));
-                            }
-                            Err(err) => panic!(""Failed to commit block {:?}"", err),
-                            _ => (),
-                        }
-                    }
+                    self.commit_block(block_id).unwrap_or_else(|block_id| {
+                        // Block can't be committed yet, add to backlog
+                        self.commit_block_backlog.push_back(block_id)
+                    });
                 }
             }
         }
 
         // Advance the Raft
         self.raw_node.advance(ready);
     }
+
+    fn commit_block(&mut self, block_id: BlockId) -> Result<(), BlockId> {
+        // Ensure block is committable (oldest validated block)
+        debug!(""VERIFYING - block_id: {:?} in valid blocks: {:?} "", &block_id, self.valid_block_backlog);
+        if !self.valid_block_backlog.contains(&block_id) {",,2018-08-24 16:30:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/211128135,https://github.com/hyperledger/sawtooth-raft/pull/13#discussion_r211128135,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/13,https://github.com/hyperledger/sawtooth-raft/pull/13,"Ah yes, I will fix that.",8a07848695ed0d695fcc16cca3679ed7317d217f,2018-08-20 14:19:54,211279128,"@@ -279,39 +294,59 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
                 if entry.get_entry_type() == EntryType::EntryNormal {
                     let block_id: BlockId = BlockId::from(Vec::from(entry.get_data()));
-                    debug!(""Peer({:?}) committing block {:?}"", self.peer_id, block_id);
-                    if match self.leader_state {
-                        Some(LeaderState::Proposing(ref proposed)) => {
-                            &block_id == proposed
-                        },
-                        _ => false,
-                    } {
-                        debug!(""Leader({:?}) transitioning to Committing block {:?}"", self.peer_id, block_id);
-                        self.leader_state = Some(LeaderState::Committing(block_id.clone()));
-                        self.service.commit_block(block_id.clone()).expect(""Failed to commit block"");
-                    }
-
-                    if self.follower_state.is_some() {
-                        match self.service.commit_block(block_id.clone()) {
-                            Err(Error::UnknownBlock(_)) => {
-                                debug!(
-                                    ""Follower({:?}) tried to commit block before available: {:?}"",
-                                    self.peer_id,
-                                    block_id
-                                );
-                                self.follower_state = Some(FollowerState::Committing(block_id));
-                            }
-                            Err(err) => panic!(""Failed to commit block {:?}"", err),
-                            _ => (),
-                        }
-                    }
+                    self.commit_block(block_id).unwrap_or_else(|block_id| {
+                        // Block can't be committed yet, add to backlog
+                        self.commit_block_backlog.push_back(block_id)
+                    });
                 }
             }
         }
 
         // Advance the Raft
         self.raw_node.advance(ready);
     }
+
+    fn commit_block(&mut self, block_id: BlockId) -> Result<(), BlockId> {
+        // Ensure block is committable (oldest validated block)
+        debug!(""VERIFYING - block_id: {:?} in valid blocks: {:?} "", &block_id, self.valid_block_backlog);
+        if !self.valid_block_backlog.contains(&block_id) {",,2018-08-24 16:30:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/211279128,https://github.com/hyperledger/sawtooth-raft/pull/13#discussion_r211279128,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/13,https://github.com/hyperledger/sawtooth-raft/pull/13,"Updating the comment to reflect the code; block new/valid messages may be received out-of-order, so you cannot rely on the ordering of the `valid_block_backlog`.",8a07848695ed0d695fcc16cca3679ed7317d217f,2018-08-20 14:28:24,211282390,"@@ -279,39 +294,59 @@ impl<S: StorageExt> SawtoothRaftNode<S> {
 
                 if entry.get_entry_type() == EntryType::EntryNormal {
                     let block_id: BlockId = BlockId::from(Vec::from(entry.get_data()));
-                    debug!(""Peer({:?}) committing block {:?}"", self.peer_id, block_id);
-                    if match self.leader_state {
-                        Some(LeaderState::Proposing(ref proposed)) => {
-                            &block_id == proposed
-                        },
-                        _ => false,
-                    } {
-                        debug!(""Leader({:?}) transitioning to Committing block {:?}"", self.peer_id, block_id);
-                        self.leader_state = Some(LeaderState::Committing(block_id.clone()));
-                        self.service.commit_block(block_id.clone()).expect(""Failed to commit block"");
-                    }
-
-                    if self.follower_state.is_some() {
-                        match self.service.commit_block(block_id.clone()) {
-                            Err(Error::UnknownBlock(_)) => {
-                                debug!(
-                                    ""Follower({:?}) tried to commit block before available: {:?}"",
-                                    self.peer_id,
-                                    block_id
-                                );
-                                self.follower_state = Some(FollowerState::Committing(block_id));
-                            }
-                            Err(err) => panic!(""Failed to commit block {:?}"", err),
-                            _ => (),
-                        }
-                    }
+                    self.commit_block(block_id).unwrap_or_else(|block_id| {
+                        // Block can't be committed yet, add to backlog
+                        self.commit_block_backlog.push_back(block_id)
+                    });
                 }
             }
         }
 
         // Advance the Raft
         self.raw_node.advance(ready);
     }
+
+    fn commit_block(&mut self, block_id: BlockId) -> Result<(), BlockId> {
+        // Ensure block is committable (oldest validated block)
+        debug!(""VERIFYING - block_id: {:?} in valid blocks: {:?} "", &block_id, self.valid_block_backlog);
+        if !self.valid_block_backlog.contains(&block_id) {",,2018-08-24 16:30:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/211282390,https://github.com/hyperledger/sawtooth-raft/pull/13#discussion_r211282390,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/7,https://github.com/hyperledger/sawtooth-raft/pull/7,This seems unnecessary.,dc6fbc4e39d6114e8dd7eee987c3418024f72116,2018-07-25 20:22:23,205249563,"@@ -38,9 +42,46 @@ mod ticker;
 fn main() {
     let args = parse_args();
 
-    simple_logger::init_with_level(args.log_level).unwrap();
+    let config = match args.log_config {
+        Some(path) => {
+            // Register deserializer for syslog so we can load syslog appender(s)
+            let mut deserializers = log4rs::file::Deserializers::new();
+            log4rs_syslog::register(&mut deserializers);
+
+            let mut config = match log4rs::load_config_file(path, deserializers) {
+                Ok(x) => x,
+                Err(_) => process::exit(1),
+            };
+
+            config.set_level(args.log_level);
+
+            config
+        },
+        None => {
+            let stdout = ConsoleAppender::builder()
+                .encoder(Box::new(PatternEncoder::new(
+                    ""{h({l:5.5})} | {({M}:{L}):20.20} | {m}{n}"",
+                )))
+                .build();
+
+            match Config::builder()
+                .appender(Appender::builder().build(""stdout"", Box::new(stdout)))
+                .build(Root::builder().appender(""stdout"").build(args.log_level))
+            {
+                Ok(x) => x,
+                Err(_) => process::exit(1),
+            }
+        }
+    };
+
+    match log4rs::init_config(config) {
+        Ok(_) => (),
+        Err(_) => process::exit(1),
+    }
 
-    info!(""Sawtooth Raft Engine ({})"", env!(""CARGO_PKG_VERSION""));
+    info!(""Console logging level: {}"", args.log_level);",,2018-07-25 21:23:15,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/205249563,https://github.com/hyperledger/sawtooth-raft/pull/7#discussion_r205249563,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/7,https://github.com/hyperledger/sawtooth-raft/pull/7,Probably should print an error message.  Same for the additional exits added later.,dc6fbc4e39d6114e8dd7eee987c3418024f72116,2018-07-25 20:25:43,205250583,"@@ -38,9 +42,46 @@ mod ticker;
 fn main() {
     let args = parse_args();
 
-    simple_logger::init_with_level(args.log_level).unwrap();
+    let config = match args.log_config {
+        Some(path) => {
+            // Register deserializer for syslog so we can load syslog appender(s)
+            let mut deserializers = log4rs::file::Deserializers::new();
+            log4rs_syslog::register(&mut deserializers);
+
+            let mut config = match log4rs::load_config_file(path, deserializers) {
+                Ok(x) => x,
+                Err(_) => process::exit(1),",,2018-07-25 21:23:15,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/205250583,https://github.com/hyperledger/sawtooth-raft/pull/7#discussion_r205250583,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/7,https://github.com/hyperledger/sawtooth-raft/pull/7,"Would `?` be sufficient, or are we going to consider these non-fatal errors? Or are you saying just print an error before exiting?",dc6fbc4e39d6114e8dd7eee987c3418024f72116,2018-07-25 20:44:45,205256164,"@@ -38,9 +42,46 @@ mod ticker;
 fn main() {
     let args = parse_args();
 
-    simple_logger::init_with_level(args.log_level).unwrap();
+    let config = match args.log_config {
+        Some(path) => {
+            // Register deserializer for syslog so we can load syslog appender(s)
+            let mut deserializers = log4rs::file::Deserializers::new();
+            log4rs_syslog::register(&mut deserializers);
+
+            let mut config = match log4rs::load_config_file(path, deserializers) {
+                Ok(x) => x,
+                Err(_) => process::exit(1),",,2018-07-25 21:23:15,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/205256164,https://github.com/hyperledger/sawtooth-raft/pull/7#discussion_r205256164,ltseeley
https://github.com/hyperledger/sawtooth-raft/pull/7,https://github.com/hyperledger/sawtooth-raft/pull/7,"main doesn't return a result, so question mark seems out.

In the first case, it would seem like the file provided is either missing or inaccurate, in which case, you should default to console logging and log the error.  In the second case, it would look like the console logger is badly configured (programmer error?), so probably also safe to do an `eprintln!` and exit.",dc6fbc4e39d6114e8dd7eee987c3418024f72116,2018-07-25 20:49:17,205257591,"@@ -38,9 +42,46 @@ mod ticker;
 fn main() {
     let args = parse_args();
 
-    simple_logger::init_with_level(args.log_level).unwrap();
+    let config = match args.log_config {
+        Some(path) => {
+            // Register deserializer for syslog so we can load syslog appender(s)
+            let mut deserializers = log4rs::file::Deserializers::new();
+            log4rs_syslog::register(&mut deserializers);
+
+            let mut config = match log4rs::load_config_file(path, deserializers) {
+                Ok(x) => x,
+                Err(_) => process::exit(1),",,2018-07-25 21:23:15,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/205257591,https://github.com/hyperledger/sawtooth-raft/pull/7#discussion_r205257591,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/4,https://github.com/hyperledger/sawtooth-raft/pull/4,Can these have build sections? I wasn't able to build this test just with docker-compose.,a0659d8b08626b2cc20d90aa1de79462eebdc268,2018-07-11 21:59:05,201853183,"@@ -0,0 +1,215 @@
+# Copyright 2018 Intel Corporation
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ------------------------------------------------------------------------------
+
+version: ""2.1""
+
+volumes:
+  keys:
+
+services:
+
+  test-raft-engine:
+    image: sawtooth-raft-test:$ISOLATION_ID
+    build:
+      context: .
+      dockerfile: sawtooth-raft-test.dockerfile
+    volumes:
+      - ..:/project/sawtooth-raft
+    command: nose2-3
+        -vv
+        -s /project/sawtooth-raft/tests
+        test_liveness
+
+  smallbank-workload:
+    image: sawtooth-raft-test:$ISOLATION_ID
+    build:
+      context: .
+      dockerfile: sawtooth-raft-test.dockerfile
+    expose:
+      - 8008
+    command: ""bash -c \""\
+      sawtooth keygen smallbank-key; \
+      while true; do curl -s http://rest-api-1:8008/state | grep -q head; if [ $$? -eq 0 ]; then break; fi; sleep 0.5; done; \
+      /sawtooth-core/perf/smallbank_workload/target/debug/smallbank-workload load --key /root/.sawtooth/keys/smallbank-key.priv --rate 1 --target http://rest-api-1:8008,http://rest-api-2:8008,http://rest-api-3:8008 \
+      \""""
+
+  validator-1:
+    image: hyperledger/sawtooth-validator:latest
+    volumes:
+      - keys:/shared_keys
+    expose:
+      - 4004
+      - 8800
+      - 5005
+    working_dir: /root
+    command: ""bash -c \""\
+        sawadm keygen validator-2 && \
+        sawadm keygen validator-3 && \
+        sawadm keygen && \
+        sawset genesis \
+          -k /etc/sawtooth/keys/validator.priv \
+          -o config-genesis.batch && \
+        sawset proposal create \
+          -k /etc/sawtooth/keys/validator.priv \
+          sawtooth.consensus.algorithm=raft \
+          sawtooth.consensus.raft.peers='{\\\""'$$(cat /etc/sawtooth/keys/validator.pub)'\\\""':1,'\\\""'$$(cat /etc/sawtooth/keys/validator-2.pub)'\\\""':2,'\\\""'$$(cat /etc/sawtooth/keys/validator-3.pub)'\\\"":3}'
+          sawtooth.consensus.raft.period=1 \
+          -o config.batch && \
+        sawadm genesis \
+          config-genesis.batch config.batch && \
+        mv /etc/sawtooth/keys/validator-* /shared_keys && \
+        echo $$(cat /etc/sawtooth/keys/validator.pub); \
+        sawtooth-validator \
+            --endpoint tcp://validator-1:8800 \
+            --bind component:tcp://eth0:4004 \
+            --bind network:tcp://eth0:8800 \
+            --bind consensus:tcp://eth0:5050 \
+            --peering static \
+            --peers tcp://validator-2:8800,tcp://validator-3:8800
+            --scheduler parallel \
+    \""""
+    stop_signal: SIGKILL
+
+  validator-2:
+    image: hyperledger/sawtooth-validator:latest
+    volumes:
+      - keys:/shared_keys
+    expose:
+      - 4004
+      - 8800
+    command: ""bash -c \""\
+        while true; do if [ -e /shared_keys/validator-2.pub ]; then mv /shared_keys/validator-2.priv /etc/sawtooth/keys/validator.priv && mv /shared_keys/validator-2.pub /etc/sawtooth/keys/validator.pub; break; fi; sleep 0.5; done; \
+        echo $$(cat /etc/sawtooth/keys/validator.pub); \
+        sawtooth-validator \
+            --endpoint tcp://validator-2:8800 \
+            --bind component:tcp://eth0:4004 \
+            --bind network:tcp://eth0:8800 \
+            --bind consensus:tcp://eth0:5050 \
+            --peering static \
+            --peers tcp://validator-1:8800,tcp://validator-3:8800
+            --scheduler parallel \
+    \""""
+    stop_signal: SIGKILL
+
+  validator-3:
+    image: hyperledger/sawtooth-validator:latest
+    volumes:
+      - keys:/shared_keys
+    expose:
+      - 4004
+      - 8800
+    command: ""bash -c \""\
+        while true; do if [ -e /shared_keys/validator-3.pub ]; then mv /shared_keys/validator-3.priv /etc/sawtooth/keys/validator.priv && mv /shared_keys/validator-3.pub /etc/sawtooth/keys/validator.pub; break; fi; sleep 0.5; done; \
+        echo $$(cat /etc/sawtooth/keys/validator.pub); \
+        sawtooth-validator \
+            --endpoint tcp://validator-3:8800 \
+            --bind component:tcp://eth0:4004 \
+            --bind network:tcp://eth0:8800 \
+            --bind consensus:tcp://eth0:5050 \
+            --peering static \
+            --peers tcp://validator-1:8800,tcp://validator-2:8800
+            --scheduler parallel \
+    \""""
+    stop_signal: SIGKILL
+
+  raft-1:
+    image: sawtooth-raft-engine-local:$ISOLATION_ID",128,2018-07-11 23:31:18,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/201853183,https://github.com/hyperledger/sawtooth-raft/pull/4#discussion_r201853183,boydjohnson
https://github.com/hyperledger/sawtooth-raft/pull/3,https://github.com/hyperledger/sawtooth-raft/pull/3,Unfinished comment.,bceb438dbdded39734551bf568928003bebcadf8,2018-07-24 17:31:18,204844751,"@@ -0,0 +1,54 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use raft::{Error, eraftpb::{Entry, HardState, Snapshot}, storage::{MemStorage, Storage}};
+
+/// Extends the storage trait to include methods used by",,2018-07-26 15:15:48,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/204844751,https://github.com/hyperledger/sawtooth-raft/pull/3#discussion_r204844751,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/2,https://github.com/hyperledger/sawtooth-raft/pull/2,Empty heading now that these lines are removed,0fcfe3f7111d66315c623220a49f3ed84b27de5d,2018-07-05 22:42:41,200509076,"@@ -22,15 +22,8 @@ should use a small number of nodes with a relatively fixed membership. (Adding
 and removing nodes is not currently supported, although we intend to add this
 feature in the future).
 
-Each node must have a unique, non-zero integer for an identifier. Currently,
-this must be specified manually on the command line and in the on-chain setting
-below.
-
 ### Configure On-Chain Sawtooth Raft Settings
 
-Assign each validator that will be on the network a unique integer. This will",,2018-07-30 14:30:25,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/200509076,https://github.com/hyperledger/sawtooth-raft/pull/2#discussion_r200509076,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/2,https://github.com/hyperledger/sawtooth-raft/pull/2,PoET comment,0fcfe3f7111d66315c623220a49f3ed84b27de5d,2018-07-05 23:27:54,200515458,"@@ -0,0 +1,162 @@
+# Copyright 2017 Intel Corporation
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ------------------------------------------------------------------------------
+
+# pylint: disable=bare-except
+
+import time
+import unittest
+import logging
+
+import requests
+
+
+LOGGER = logging.getLogger(__name__)
+
+URL = 'http://rest-api-%d:8008'
+
+# The number of nodes in the test (this needs to match the test's compose file)
+NODES = (1, 2, 3)
+
+# Blocks must have between this many batches
+BATCHES_PER_BLOCK_RANGE = (1, 100)
+
+# At the end of the test, this many batches must be in the chain
+MIN_TOTAL_BATCHES = 50
+
+# All nodes must reach this block for the test to pass.
+BLOCK_TO_REACH = 55
+
+# Once all nodes reach the BLOCK_TO_REACH, the test will check for consensus at
+# this block. These are different because PoET occassionally forks.",,2018-07-30 14:30:25,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/200515458,https://github.com/hyperledger/sawtooth-raft/pull/2#discussion_r200515458,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/2,https://github.com/hyperledger/sawtooth-raft/pull/2,Maybe should check at BLOCK_TO_CHECK_CONSENSUS = BLOCK_TO_REACH - SYNC_TOLERANCE,0fcfe3f7111d66315c623220a49f3ed84b27de5d,2018-07-05 23:30:35,200515826,"@@ -0,0 +1,162 @@
+# Copyright 2017 Intel Corporation
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ------------------------------------------------------------------------------
+
+# pylint: disable=bare-except
+
+import time
+import unittest
+import logging
+
+import requests
+
+
+LOGGER = logging.getLogger(__name__)
+
+URL = 'http://rest-api-%d:8008'
+
+# The number of nodes in the test (this needs to match the test's compose file)
+NODES = (1, 2, 3)
+
+# Blocks must have between this many batches
+BATCHES_PER_BLOCK_RANGE = (1, 100)
+
+# At the end of the test, this many batches must be in the chain
+MIN_TOTAL_BATCHES = 50
+
+# All nodes must reach this block for the test to pass.
+BLOCK_TO_REACH = 55
+
+# Once all nodes reach the BLOCK_TO_REACH, the test will check for consensus at
+# this block. These are different because PoET occassionally forks.
+BLOCK_TO_CHECK_CONSENSUS = 10",,2018-07-30 14:30:25,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/200515826,https://github.com/hyperledger/sawtooth-raft/pull/2#discussion_r200515826,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/2,https://github.com/hyperledger/sawtooth-raft/pull/2,Or maybe even just BLOCK_TO_CHECK_CONSENSUS = BLOCK_TO_REACH since all chains are required to have that block and raft should not create any forks.,0fcfe3f7111d66315c623220a49f3ed84b27de5d,2018-07-05 23:35:22,200516441,"@@ -0,0 +1,162 @@
+# Copyright 2017 Intel Corporation
+#
+# Licensed under the Apache License, Version 2.0 (the ""License"");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ------------------------------------------------------------------------------
+
+# pylint: disable=bare-except
+
+import time
+import unittest
+import logging
+
+import requests
+
+
+LOGGER = logging.getLogger(__name__)
+
+URL = 'http://rest-api-%d:8008'
+
+# The number of nodes in the test (this needs to match the test's compose file)
+NODES = (1, 2, 3)
+
+# Blocks must have between this many batches
+BATCHES_PER_BLOCK_RANGE = (1, 100)
+
+# At the end of the test, this many batches must be in the chain
+MIN_TOTAL_BATCHES = 50
+
+# All nodes must reach this block for the test to pass.
+BLOCK_TO_REACH = 55
+
+# Once all nodes reach the BLOCK_TO_REACH, the test will check for consensus at
+# this block. These are different because PoET occassionally forks.
+BLOCK_TO_CHECK_CONSENSUS = 10",,2018-07-30 14:30:25,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/200516441,https://github.com/hyperledger/sawtooth-raft/pull/2#discussion_r200516441,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/1,https://github.com/hyperledger/sawtooth-raft/pull/1,Remove this: TODO,cdaa0ae9e50f221371411d2c1385f581d7c45519,2018-06-19 18:43:25,196537074,"@@ -0,0 +1,122 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::time::Duration;
+use std::sync::mpsc::{Receiver, RecvTimeoutError};
+
+use raft::{
+    raw_node::RawNode,
+    Peer as RaftPeer,
+};
+
+use sawtooth_sdk::consensus::{
+    engine::{Block, PeerInfo, Engine, Update},
+    service::Service,
+};
+
+use config::{self, RaftEngineConfig};
+use ticker;
+use node::SawtoothRaftNode;
+
+
+pub struct RaftEngine {
+    id: u64,
+}
+
+impl RaftEngine {
+    pub fn new(id: u64) -> Self {
+        RaftEngine { id }
+    }
+}
+
+pub const RAFT_TIMEOUT: Duration = Duration::from_millis(100);
+
+impl Engine for RaftEngine {
+    fn start(
+        &mut self,
+        updates: Receiver<Update>,
+        mut service: Box<Service>,
+        chain_head: Block,
+        _peers: Vec<PeerInfo>,
+    ) {
+
+        // Create the configuration for the Raft node.
+        let cfg = config::load_raft_config(self.id, chain_head.block_id, &mut service);
+        info!(""Raft Engine Config Loaded: {:?}"", cfg);
+        let RaftEngineConfig {
+            peers,
+            period,
+            raft: raft_config,
+            storage: raft_storage
+        } = cfg;
+
+        // Create the Raft node.
+        let raft_peers: Vec<RaftPeer> = peers
+            .values()
+            .map(|id| RaftPeer { id: *id, context: None })
+            .collect();
+        let raw_node = RawNode::new(&raft_config, raft_storage, raft_peers).unwrap();
+
+        let mut node = SawtoothRaftNode::new(self.id, raw_node, service, peers, period);
+
+        let mut raft_ticker = ticker::Ticker::new(RAFT_TIMEOUT);
+        let mut timeout = RAFT_TIMEOUT;
+
+        // Loop forever to drive the Raft.
+        loop {
+            match updates.recv_timeout(timeout) {
+                Err(RecvTimeoutError::Timeout) => (),
+                Err(RecvTimeoutError::Disconnected) => break,
+                Ok(update) => {
+                    debug!(""Update: {:?}"", update);
+                    if !handle_update(&mut node, update) {
+                        break;
+                    }
+                }
+            }
+
+            timeout = raft_ticker.tick(|| {
+                node.tick();
+            });
+
+            node.process_ready();
+        }
+    }
+
+    fn version(&self) -> String {
+        env!(""CARGO_PKG_VERSION"").into()
+    }
+
+    fn name(&self) -> String {
+        env!(""CARGO_PKG_NAME"").into()
+    }
+}
+
+// Returns whether the engine should continue
+fn handle_update(node: &mut SawtoothRaftNode, update: Update) -> bool {
+    match update {
+        Update::BlockNew(block) => node.on_block_new(block),
+        Update::BlockValid(block_id) => node.on_block_valid(block_id),
+        Update::BlockCommit(block_id) => node.on_block_commit(block_id),
+        Update::PeerMessage(message, _id) => node.on_peer_message(message),
+        Update::Shutdown => return false,
+
+        // TODO: Handle invalid, peer update",,2018-06-22 13:59:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/196537074,https://github.com/hyperledger/sawtooth-raft/pull/1#discussion_r196537074,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/1,https://github.com/hyperledger/sawtooth-raft/pull/1,s/Emtpy/Empty,cdaa0ae9e50f221371411d2c1385f581d7c45519,2018-06-19 18:46:18,196537999,"@@ -0,0 +1,293 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::HashMap;
+use std::time::{Duration, Instant};
+
+use protobuf::{self, Message as ProtobufMessage, ProtobufError};
+use raft::{
+    self,
+    eraftpb::{
+        EntryType,
+        Message as RaftMessage,
+    },
+    raw_node::RawNode,
+    storage::MemStorage,
+};
+
+use sawtooth_sdk::consensus::{
+    engine::{Block, BlockId, PeerId, PeerMessage, Error},
+    service::Service,
+};
+
+/// Possible states a leader node can be in
+///
+/// The leader transitions between the following states in order:
+///   Building - The leader is building a new block
+///   Publishing - The leader has built a new block and it is being published
+///   Validating - The leader is validating the block it published
+///   Proposing - The leader is proposing the valid block to its peers
+///   Committing - The leader is committing the block that has been accepted by its peers
+enum LeaderState {
+    Building(Instant), // Instant is when the block started being built
+    Publishing(BlockId),
+    Validating(BlockId),
+    Proposing(BlockId),
+    Committing(BlockId),
+}
+
+pub struct SawtoothRaftNode {
+    id: u64,
+    raw_node: RawNode<MemStorage>,
+    service: Box<Service>,
+    leader_state: Option<LeaderState>,
+    raft_id_to_peer_id: HashMap<u64, PeerId>,
+    period: Duration,
+}
+
+impl SawtoothRaftNode {
+    pub fn new(
+        id: u64,
+        raw_node: RawNode<MemStorage>,
+        service: Box<Service>,
+        peers: HashMap<PeerId, u64>,
+        period: Duration
+    ) -> Self {
+        SawtoothRaftNode {
+            id,
+            raw_node,
+            service,
+            leader_state: None,
+            raft_id_to_peer_id: peers.into_iter().map(|(peer_id, raft_id)| (raft_id, peer_id)).collect(),
+            period,
+        }
+    }
+
+    pub fn on_block_new(&mut self, block: Block) {
+        if match self.leader_state {
+            Some(LeaderState::Publishing(ref block_id)) => {
+                block_id == &block.block_id
+            },
+            _ => false,
+        } {
+            debug!(""Leader({}) transition to Validating block {:?}"", self.id, block.block_id);
+            self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
+        }
+
+        // TODO: Only check blocks that we expect to get
+        self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
+    }
+
+    pub fn on_block_valid(&mut self, block_id: BlockId) {
+        // Handle out of order new/valid updates
+        if match self.leader_state {
+            Some(LeaderState::Publishing(ref expected)) => {
+                expected == &block_id
+            },
+            Some(LeaderState::Validating(ref expected)) => {
+                expected == &block_id
+            },
+            _ => false,
+        } {
+            debug!(""Leader({}) transition to Proposing block {:?}"", self.id, block_id);
+            info!(""Leader({}) proposed block {:?}"", self.id, block_id);
+            self.raw_node.propose(vec![], block_id.clone().into()).expect(""Failed to propose block to Raft"");
+            self.leader_state = Some(LeaderState::Proposing(block_id));
+        }
+    }
+
+    pub fn on_block_commit(&mut self, block_id: BlockId) {
+        if match self.leader_state {
+            Some(LeaderState::Committing(ref committing)) => {
+                committing == &block_id
+            },
+            _ => false,
+        } {
+            debug!(""Leader({}) transition to Building block {:?}"", self.id, block_id);
+            self.leader_state = Some(LeaderState::Building(Instant::now()));
+            self.service.initialize_block(None).expect(""Failed to initialize block"");
+        }
+        info!(""Peer({}) committed block {:?}"", self.id, block_id);
+    }
+
+    pub fn on_peer_message(&mut self, message: PeerMessage) {
+        let raft_message = try_into_raft_message(&message)
+            .expect(""Failed to interpret bytes as Raft message"");
+        self.raw_node.step(raft_message)
+            .expect(""Failed to handle Raft message"");
+    }
+
+    pub fn tick(&mut self) {
+        self.raw_node.tick();
+        self.check_publish();
+    }
+
+    fn check_publish(&mut self) {
+        // We want to publish a block if:
+        // 1. We are the leader
+        // 2. We are building a block
+        // 3. The block has been building long enough
+        if match self.leader_state {
+            Some(LeaderState::Building(instant)) => {
+                instant.elapsed() >= self.period
+            }
+            _ => false,
+        } {
+            match self.service.finalize_block(vec![]) {
+                Ok(block_id) => {
+                    debug!(""Leader({}) transition to Publishing block {:?}"", self.id, block_id);
+                    self.leader_state = Some(LeaderState::Publishing(block_id));
+                },
+                Err(Error::BlockNotReady) => {
+                     // Try again later
+                    debug!(""Leader({}) tried to finalize block but block not read"", self.id);
+                },
+                Err(err) => panic!(""Failed to finalize block: {:?}"", err),
+            };
+        }
+    }
+
+    fn send_msg(&mut self, raft_msg: &RaftMessage) {
+        let peer_msg = try_into_peer_message(raft_msg)
+            .expect(""Failed to convert into peer message"");
+        if let Some(peer_id) = self.raft_id_to_peer_id.get(&raft_msg.to) {
+            match self.service.send_to(
+                peer_id,
+                """",
+                peer_msg.content,
+            ) {
+                Ok(_) => (),
+                Err(Error::UnknownPeer(s)) => warn!(""Tried to send to disconnected peer: {}"", s),
+                Err(err) => panic!(""Failed to send to peer: {:?}"", err),
+            }
+        } else {
+            warn!(""Tried to send to unknown peer: {}"", raft_msg.to);
+        }
+    }
+
+    pub fn process_ready(&mut self) {
+        if !self.raw_node.has_ready() {
+            return
+        }
+
+        // The Raft is ready, we can do something now.
+        let mut ready = self.raw_node.ready();
+
+        let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
+        if is_leader {
+            // We just became the leader, so we need to start building a block
+            if self.leader_state.is_none() {
+                debug!(""Leader({}) became leader, intializing block"", self.id);
+                self.leader_state = Some(LeaderState::Building(Instant::now()));
+                self.service.initialize_block(None).expect(""Failed to initialize block"");
+            }
+            // If the peer is leader, the leader can send messages to other followers ASAP.
+            for msg in ready.messages.drain(..) {
+                debug!(""Leader({}) wants to send message to {}"", self.id, msg.to);
+                self.send_msg(&msg);
+            }
+        }
+
+        if !raft::is_empty_snap(&ready.snapshot) {
+            // This is a snapshot, we need to apply the snapshot at first.
+            self.raw_node.mut_store()
+                .wl()
+                .apply_snapshot(ready.snapshot.clone())
+                .unwrap();
+        }
+
+        if !ready.entries.is_empty() {
+            // Append entries to the Raft log
+            self.raw_node.mut_store().wl().append(&ready.entries).unwrap();
+        }
+
+        if let Some(ref hs) = ready.hs {
+            // Raft HardState changed, and we need to persist it.
+            self.raw_node.mut_store().wl().set_hardstate(hs.clone());
+        }
+
+        if !is_leader {
+            // We just stepped down as leader
+            if self.leader_state.is_some() {
+                // If we were building a block, cancel it
+                match self.leader_state {
+                    Some(LeaderState::Building(_)) => {
+                        debug!(""Leader({}) stepped down, cancelling block"", self.id);
+                        self.service.cancel_block().expect(""Failed to cancel block"");
+                    }
+                    _ => (),
+                }
+                self.leader_state = None;
+            }
+            // If not leader, the follower needs to reply the messages to
+            // the leader after appending Raft entries.
+            let msgs = ready.messages.drain(..);
+            for msg in msgs {
+                debug!(""Peer({}) wants to send message to {}"", self.id, msg.to);
+                self.send_msg(&msg);
+            }
+        }
+
+        if let Some(committed_entries) = ready.committed_entries.take() {
+            let mut _last_apply_index = 0;
+            for entry in committed_entries {
+                // Mostly, you need to save the last apply index to resume applying
+                // after restart. Here we just ignore this because we use a Memory storage.
+                _last_apply_index = entry.get_index();
+
+                if entry.get_data().is_empty() {
+                    // Emtpy entry, when the peer becomes Leader it will send an empty entry.",,2018-06-22 13:59:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/196537999,https://github.com/hyperledger/sawtooth-raft/pull/1#discussion_r196537999,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/1,https://github.com/hyperledger/sawtooth-raft/pull/1,Remove TODO,cdaa0ae9e50f221371411d2c1385f581d7c45519,2018-06-19 18:46:30,196538056,"@@ -0,0 +1,293 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::HashMap;
+use std::time::{Duration, Instant};
+
+use protobuf::{self, Message as ProtobufMessage, ProtobufError};
+use raft::{
+    self,
+    eraftpb::{
+        EntryType,
+        Message as RaftMessage,
+    },
+    raw_node::RawNode,
+    storage::MemStorage,
+};
+
+use sawtooth_sdk::consensus::{
+    engine::{Block, BlockId, PeerId, PeerMessage, Error},
+    service::Service,
+};
+
+/// Possible states a leader node can be in
+///
+/// The leader transitions between the following states in order:
+///   Building - The leader is building a new block
+///   Publishing - The leader has built a new block and it is being published
+///   Validating - The leader is validating the block it published
+///   Proposing - The leader is proposing the valid block to its peers
+///   Committing - The leader is committing the block that has been accepted by its peers
+enum LeaderState {
+    Building(Instant), // Instant is when the block started being built
+    Publishing(BlockId),
+    Validating(BlockId),
+    Proposing(BlockId),
+    Committing(BlockId),
+}
+
+pub struct SawtoothRaftNode {
+    id: u64,
+    raw_node: RawNode<MemStorage>,
+    service: Box<Service>,
+    leader_state: Option<LeaderState>,
+    raft_id_to_peer_id: HashMap<u64, PeerId>,
+    period: Duration,
+}
+
+impl SawtoothRaftNode {
+    pub fn new(
+        id: u64,
+        raw_node: RawNode<MemStorage>,
+        service: Box<Service>,
+        peers: HashMap<PeerId, u64>,
+        period: Duration
+    ) -> Self {
+        SawtoothRaftNode {
+            id,
+            raw_node,
+            service,
+            leader_state: None,
+            raft_id_to_peer_id: peers.into_iter().map(|(peer_id, raft_id)| (raft_id, peer_id)).collect(),
+            period,
+        }
+    }
+
+    pub fn on_block_new(&mut self, block: Block) {
+        if match self.leader_state {
+            Some(LeaderState::Publishing(ref block_id)) => {
+                block_id == &block.block_id
+            },
+            _ => false,
+        } {
+            debug!(""Leader({}) transition to Validating block {:?}"", self.id, block.block_id);
+            self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
+        }
+
+        // TODO: Only check blocks that we expect to get
+        self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
+    }
+
+    pub fn on_block_valid(&mut self, block_id: BlockId) {
+        // Handle out of order new/valid updates
+        if match self.leader_state {
+            Some(LeaderState::Publishing(ref expected)) => {
+                expected == &block_id
+            },
+            Some(LeaderState::Validating(ref expected)) => {
+                expected == &block_id
+            },
+            _ => false,
+        } {
+            debug!(""Leader({}) transition to Proposing block {:?}"", self.id, block_id);
+            info!(""Leader({}) proposed block {:?}"", self.id, block_id);
+            self.raw_node.propose(vec![], block_id.clone().into()).expect(""Failed to propose block to Raft"");
+            self.leader_state = Some(LeaderState::Proposing(block_id));
+        }
+    }
+
+    pub fn on_block_commit(&mut self, block_id: BlockId) {
+        if match self.leader_state {
+            Some(LeaderState::Committing(ref committing)) => {
+                committing == &block_id
+            },
+            _ => false,
+        } {
+            debug!(""Leader({}) transition to Building block {:?}"", self.id, block_id);
+            self.leader_state = Some(LeaderState::Building(Instant::now()));
+            self.service.initialize_block(None).expect(""Failed to initialize block"");
+        }
+        info!(""Peer({}) committed block {:?}"", self.id, block_id);
+    }
+
+    pub fn on_peer_message(&mut self, message: PeerMessage) {
+        let raft_message = try_into_raft_message(&message)
+            .expect(""Failed to interpret bytes as Raft message"");
+        self.raw_node.step(raft_message)
+            .expect(""Failed to handle Raft message"");
+    }
+
+    pub fn tick(&mut self) {
+        self.raw_node.tick();
+        self.check_publish();
+    }
+
+    fn check_publish(&mut self) {
+        // We want to publish a block if:
+        // 1. We are the leader
+        // 2. We are building a block
+        // 3. The block has been building long enough
+        if match self.leader_state {
+            Some(LeaderState::Building(instant)) => {
+                instant.elapsed() >= self.period
+            }
+            _ => false,
+        } {
+            match self.service.finalize_block(vec![]) {
+                Ok(block_id) => {
+                    debug!(""Leader({}) transition to Publishing block {:?}"", self.id, block_id);
+                    self.leader_state = Some(LeaderState::Publishing(block_id));
+                },
+                Err(Error::BlockNotReady) => {
+                     // Try again later
+                    debug!(""Leader({}) tried to finalize block but block not read"", self.id);
+                },
+                Err(err) => panic!(""Failed to finalize block: {:?}"", err),
+            };
+        }
+    }
+
+    fn send_msg(&mut self, raft_msg: &RaftMessage) {
+        let peer_msg = try_into_peer_message(raft_msg)
+            .expect(""Failed to convert into peer message"");
+        if let Some(peer_id) = self.raft_id_to_peer_id.get(&raft_msg.to) {
+            match self.service.send_to(
+                peer_id,
+                """",
+                peer_msg.content,
+            ) {
+                Ok(_) => (),
+                Err(Error::UnknownPeer(s)) => warn!(""Tried to send to disconnected peer: {}"", s),
+                Err(err) => panic!(""Failed to send to peer: {:?}"", err),
+            }
+        } else {
+            warn!(""Tried to send to unknown peer: {}"", raft_msg.to);
+        }
+    }
+
+    pub fn process_ready(&mut self) {
+        if !self.raw_node.has_ready() {
+            return
+        }
+
+        // The Raft is ready, we can do something now.
+        let mut ready = self.raw_node.ready();
+
+        let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
+        if is_leader {
+            // We just became the leader, so we need to start building a block
+            if self.leader_state.is_none() {
+                debug!(""Leader({}) became leader, intializing block"", self.id);
+                self.leader_state = Some(LeaderState::Building(Instant::now()));
+                self.service.initialize_block(None).expect(""Failed to initialize block"");
+            }
+            // If the peer is leader, the leader can send messages to other followers ASAP.
+            for msg in ready.messages.drain(..) {
+                debug!(""Leader({}) wants to send message to {}"", self.id, msg.to);
+                self.send_msg(&msg);
+            }
+        }
+
+        if !raft::is_empty_snap(&ready.snapshot) {
+            // This is a snapshot, we need to apply the snapshot at first.
+            self.raw_node.mut_store()
+                .wl()
+                .apply_snapshot(ready.snapshot.clone())
+                .unwrap();
+        }
+
+        if !ready.entries.is_empty() {
+            // Append entries to the Raft log
+            self.raw_node.mut_store().wl().append(&ready.entries).unwrap();
+        }
+
+        if let Some(ref hs) = ready.hs {
+            // Raft HardState changed, and we need to persist it.
+            self.raw_node.mut_store().wl().set_hardstate(hs.clone());
+        }
+
+        if !is_leader {
+            // We just stepped down as leader
+            if self.leader_state.is_some() {
+                // If we were building a block, cancel it
+                match self.leader_state {
+                    Some(LeaderState::Building(_)) => {
+                        debug!(""Leader({}) stepped down, cancelling block"", self.id);
+                        self.service.cancel_block().expect(""Failed to cancel block"");
+                    }
+                    _ => (),
+                }
+                self.leader_state = None;
+            }
+            // If not leader, the follower needs to reply the messages to
+            // the leader after appending Raft entries.
+            let msgs = ready.messages.drain(..);
+            for msg in msgs {
+                debug!(""Peer({}) wants to send message to {}"", self.id, msg.to);
+                self.send_msg(&msg);
+            }
+        }
+
+        if let Some(committed_entries) = ready.committed_entries.take() {
+            let mut _last_apply_index = 0;
+            for entry in committed_entries {
+                // Mostly, you need to save the last apply index to resume applying
+                // after restart. Here we just ignore this because we use a Memory storage.
+                _last_apply_index = entry.get_index();
+
+                if entry.get_data().is_empty() {
+                    // Emtpy entry, when the peer becomes Leader it will send an empty entry.
+                    continue;
+                }
+
+                if entry.get_entry_type() == EntryType::EntryNormal {
+                    // TODO: This usage of Raft only proposes one block at a time. Performance",,2018-06-22 13:59:10,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/196538056,https://github.com/hyperledger/sawtooth-raft/pull/1#discussion_r196538056,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/1,https://github.com/hyperledger/sawtooth-raft/pull/1,"Remove TODO.  If this is a remaining, unhandled case, a comment describing the case may be helpful ",cdaa0ae9e50f221371411d2c1385f581d7c45519,2018-06-19 18:47:27,196538327,"@@ -0,0 +1,293 @@
+/*
+ * Copyright 2018 Intel Corporation
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ * ------------------------------------------------------------------------------
+ */
+
+use std::collections::HashMap;
+use std::time::{Duration, Instant};
+
+use protobuf::{self, Message as ProtobufMessage, ProtobufError};
+use raft::{
+    self,
+    eraftpb::{
+        EntryType,
+        Message as RaftMessage,
+    },
+    raw_node::RawNode,
+    storage::MemStorage,
+};
+
+use sawtooth_sdk::consensus::{
+    engine::{Block, BlockId, PeerId, PeerMessage, Error},
+    service::Service,
+};
+
+/// Possible states a leader node can be in
+///
+/// The leader transitions between the following states in order:
+///   Building - The leader is building a new block
+///   Publishing - The leader has built a new block and it is being published
+///   Validating - The leader is validating the block it published
+///   Proposing - The leader is proposing the valid block to its peers
+///   Committing - The leader is committing the block that has been accepted by its peers
+enum LeaderState {
+    Building(Instant), // Instant is when the block started being built
+    Publishing(BlockId),
+    Validating(BlockId),
+    Proposing(BlockId),
+    Committing(BlockId),
+}
+
+pub struct SawtoothRaftNode {
+    id: u64,
+    raw_node: RawNode<MemStorage>,
+    service: Box<Service>,
+    leader_state: Option<LeaderState>,
+    raft_id_to_peer_id: HashMap<u64, PeerId>,
+    period: Duration,
+}
+
+impl SawtoothRaftNode {
+    pub fn new(
+        id: u64,
+        raw_node: RawNode<MemStorage>,
+        service: Box<Service>,
+        peers: HashMap<PeerId, u64>,
+        period: Duration
+    ) -> Self {
+        SawtoothRaftNode {
+            id,
+            raw_node,
+            service,
+            leader_state: None,
+            raft_id_to_peer_id: peers.into_iter().map(|(peer_id, raft_id)| (raft_id, peer_id)).collect(),
+            period,
+        }
+    }
+
+    pub fn on_block_new(&mut self, block: Block) {
+        if match self.leader_state {
+            Some(LeaderState::Publishing(ref block_id)) => {
+                block_id == &block.block_id
+            },
+            _ => false,
+        } {
+            debug!(""Leader({}) transition to Validating block {:?}"", self.id, block.block_id);
+            self.leader_state = Some(LeaderState::Validating(block.block_id.clone()));
+        }
+
+        // TODO: Only check blocks that we expect to get
+        self.service.check_blocks(vec![block.block_id]).expect(""Failed to send check blocks"");
+    }
+
+    pub fn on_block_valid(&mut self, block_id: BlockId) {
+        // Handle out of order new/valid updates
+        if match self.leader_state {
+            Some(LeaderState::Publishing(ref expected)) => {
+                expected == &block_id
+            },
+            Some(LeaderState::Validating(ref expected)) => {
+                expected == &block_id
+            },
+            _ => false,
+        } {
+            debug!(""Leader({}) transition to Proposing block {:?}"", self.id, block_id);
+            info!(""Leader({}) proposed block {:?}"", self.id, block_id);
+            self.raw_node.propose(vec![], block_id.clone().into()).expect(""Failed to propose block to Raft"");
+            self.leader_state = Some(LeaderState::Proposing(block_id));
+        }
+    }
+
+    pub fn on_block_commit(&mut self, block_id: BlockId) {
+        if match self.leader_state {
+            Some(LeaderState::Committing(ref committing)) => {
+                committing == &block_id
+            },
+            _ => false,
+        } {
+            debug!(""Leader({}) transition to Building block {:?}"", self.id, block_id);
+            self.leader_state = Some(LeaderState::Building(Instant::now()));
+            self.service.initialize_block(None).expect(""Failed to initialize block"");
+        }
+        info!(""Peer({}) committed block {:?}"", self.id, block_id);
+    }
+
+    pub fn on_peer_message(&mut self, message: PeerMessage) {
+        let raft_message = try_into_raft_message(&message)
+            .expect(""Failed to interpret bytes as Raft message"");
+        self.raw_node.step(raft_message)
+            .expect(""Failed to handle Raft message"");
+    }
+
+    pub fn tick(&mut self) {
+        self.raw_node.tick();
+        self.check_publish();
+    }
+
+    fn check_publish(&mut self) {
+        // We want to publish a block if:
+        // 1. We are the leader
+        // 2. We are building a block
+        // 3. The block has been building long enough
+        if match self.leader_state {
+            Some(LeaderState::Building(instant)) => {
+                instant.elapsed() >= self.period
+            }
+            _ => false,
+        } {
+            match self.service.finalize_block(vec![]) {
+                Ok(block_id) => {
+                    debug!(""Leader({}) transition to Publishing block {:?}"", self.id, block_id);
+                    self.leader_state = Some(LeaderState::Publishing(block_id));
+                },
+                Err(Error::BlockNotReady) => {
+                     // Try again later
+                    debug!(""Leader({}) tried to finalize block but block not read"", self.id);
+                },
+                Err(err) => panic!(""Failed to finalize block: {:?}"", err),
+            };
+        }
+    }
+
+    fn send_msg(&mut self, raft_msg: &RaftMessage) {
+        let peer_msg = try_into_peer_message(raft_msg)
+            .expect(""Failed to convert into peer message"");
+        if let Some(peer_id) = self.raft_id_to_peer_id.get(&raft_msg.to) {
+            match self.service.send_to(
+                peer_id,
+                """",
+                peer_msg.content,
+            ) {
+                Ok(_) => (),
+                Err(Error::UnknownPeer(s)) => warn!(""Tried to send to disconnected peer: {}"", s),
+                Err(err) => panic!(""Failed to send to peer: {:?}"", err),
+            }
+        } else {
+            warn!(""Tried to send to unknown peer: {}"", raft_msg.to);
+        }
+    }
+
+    pub fn process_ready(&mut self) {
+        if !self.raw_node.has_ready() {
+            return
+        }
+
+        // The Raft is ready, we can do something now.
+        let mut ready = self.raw_node.ready();
+
+        let is_leader = self.raw_node.raft.state == raft::StateRole::Leader;
+        if is_leader {
+            // We just became the leader, so we need to start building a block
+            if self.leader_state.is_none() {
+                debug!(""Leader({}) became leader, intializing block"", self.id);
+                self.leader_state = Some(LeaderState::Building(Instant::now()));
+                self.service.initialize_block(None).expect(""Failed to initialize block"");
+            }
+            // If the peer is leader, the leader can send messages to other followers ASAP.
+            for msg in ready.messages.drain(..) {
+                debug!(""Leader({}) wants to send message to {}"", self.id, msg.to);
+                self.send_msg(&msg);
+            }
+        }
+
+        if !raft::is_empty_snap(&ready.snapshot) {
+            // This is a snapshot, we need to apply the snapshot at first.
+            self.raw_node.mut_store()
+                .wl()
+                .apply_snapshot(ready.snapshot.clone())
+                .unwrap();
+        }
+
+        if !ready.entries.is_empty() {
+            // Append entries to the Raft log
+            self.raw_node.mut_store().wl().append(&ready.entries).unwrap();
+        }
+
+        if let Some(ref hs) = ready.hs {
+            // Raft HardState changed, and we need to persist it.
+            self.raw_node.mut_store().wl().set_hardstate(hs.clone());
+        }
+
+        if !is_leader {
+            // We just stepped down as leader
+            if self.leader_state.is_some() {
+                // If we were building a block, cancel it
+                match self.leader_state {
+                    Some(LeaderState::Building(_)) => {
+                        debug!(""Leader({}) stepped down, cancelling block"", self.id);
+                        self.service.cancel_block().expect(""Failed to cancel block"");
+                    }
+                    _ => (),
+                }
+                self.leader_state = None;
+            }
+            // If not leader, the follower needs to reply the messages to
+            // the leader after appending Raft entries.
+            let msgs = ready.messages.drain(..);
+            for msg in msgs {
+                debug!(""Peer({}) wants to send message to {}"", self.id, msg.to);
+                self.send_msg(&msg);
+            }
+        }
+
+        if let Some(committed_entries) = ready.committed_entries.take() {
+            let mut _last_apply_index = 0;
+            for entry in committed_entries {
+                // Mostly, you need to save the last apply index to resume applying
+                // after restart. Here we just ignore this because we use a Memory storage.
+                _last_apply_index = entry.get_index();
+
+                if entry.get_data().is_empty() {
+                    // Emtpy entry, when the peer becomes Leader it will send an empty entry.
+                    continue;
+                }
+
+                if entry.get_entry_type() == EntryType::EntryNormal {
+                    // TODO: This usage of Raft only proposes one block at a time. Performance
+                    // could be improved by optimistically proposing blocks before parents are
+                    // committed.
+                    let block_id: BlockId = BlockId::from(Vec::from(entry.get_data()));
+                    debug!(""Peer({}) committing block {:?}"", self.id, block_id);
+                    if match self.leader_state {
+                        Some(LeaderState::Proposing(ref proposed)) => {
+                            &block_id == proposed
+                        },
+                        _ => false,
+                    } {
+                        debug!(""Leader({}) transitioning to Committing block {:?}"", self.id, block_id);
+                        self.leader_state = Some(LeaderState::Committing(block_id.clone()));
+                    }
+                    self.service.commit_block(block_id.clone()).expect(""Failed to commit block"");
+                }
+
+                // TODO: handle EntryConfChange",,2018-06-22 13:59:11,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/196538327,https://github.com/hyperledger/sawtooth-raft/pull/1#discussion_r196538327,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/1,https://github.com/hyperledger/sawtooth-raft/pull/1,It strikes me we've run into determinism problems with JSON.,cdaa0ae9e50f221371411d2c1385f581d7c45519,2018-06-19 20:54:55,196575150,"@@ -0,0 +1,99 @@
+# Sawtooth Raft
+
+Sawtooth Raft is a consensus engine for Hyperledger Sawtooth based on the crash
+fault tolerant consensus algorithm [Raft](http://raft.github.io/).
+Specifically, it is built on top of the Rust implementation of Raft used by
+TiKV, [raft-rs](https://github.com/pingcap/raft-rs).
+
+Currently, Sawtooth Raft is in the prototype phase of development and there is
+additional work to be done in order to make it production worthy.
+
+## Deploying a Sawtooth Network with Raft
+
+Using the Sawtooth Raft engine with Sawtooth requires the following:
+
+1. Configure Sawtooth Raft by specifying the required on-chain settings
+2. Configure the Sawtooth network so that all validators can communicate
+3. Start a Raft engine for every validator and connect it to the validator
+
+Sawtooth deployments using the Sawtooth Raft consensus engine require nodes to
+be fully-connected in order to function correctly. As a result, deployments
+should use a small number of nodes with a relatively fixed membership. (Adding
+and removing nodes is not currently supported, although we intend to add this
+feature in the future).
+
+Each node must have a unique, non-zero integer for an identifier. Currently,
+this must be specified manually on the command line and in the on-chain setting
+below.
+
+### Configure On-Chain Sawtooth Raft Settings
+
+Assign each validator that will be on the network a unique integer. This will
+be its ""raft id"". No id may be 0.
+
+### Configure the Sawtooth Network
+
+When starting validators, they should be configured to use static peering using
+the `--peering static` flag and each node should specify all other nodes as
+their peers using the `--peers` flag.
+
+## On-Chain Settings
+
+The following on-chain settings configure Sawtooth Raft. The required settings
+must be specified in state prior to using Raft consensus. When starting a new
+network, they should be set in the genesis block. All settings are prefixed
+with `sawtooth.consensus.raft`.
+
+The only required setting is `sawtooth.consensus.raft.peers`. It must contain
+a mapping of each node's public key to each node's raft id.
+
+### Required Settings
+
+| key | value |
+| --- | --- |
+| peers | JSON - Map<PeerId, u64> |",54,2018-06-22 13:59:11,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/196575150,https://github.com/hyperledger/sawtooth-raft/pull/1#discussion_r196575150,dcmiddle
https://github.com/hyperledger/sawtooth-raft/pull/1,https://github.com/hyperledger/sawtooth-raft/pull/1,"The json is submitted in the settings transaction, not computed by a transaction processor.  It is deterministic in this case in the same way that a timestamp submitted in a transaction body is deterministic (with respect to validation).",cdaa0ae9e50f221371411d2c1385f581d7c45519,2018-06-19 21:31:14,196585428,"@@ -0,0 +1,99 @@
+# Sawtooth Raft
+
+Sawtooth Raft is a consensus engine for Hyperledger Sawtooth based on the crash
+fault tolerant consensus algorithm [Raft](http://raft.github.io/).
+Specifically, it is built on top of the Rust implementation of Raft used by
+TiKV, [raft-rs](https://github.com/pingcap/raft-rs).
+
+Currently, Sawtooth Raft is in the prototype phase of development and there is
+additional work to be done in order to make it production worthy.
+
+## Deploying a Sawtooth Network with Raft
+
+Using the Sawtooth Raft engine with Sawtooth requires the following:
+
+1. Configure Sawtooth Raft by specifying the required on-chain settings
+2. Configure the Sawtooth network so that all validators can communicate
+3. Start a Raft engine for every validator and connect it to the validator
+
+Sawtooth deployments using the Sawtooth Raft consensus engine require nodes to
+be fully-connected in order to function correctly. As a result, deployments
+should use a small number of nodes with a relatively fixed membership. (Adding
+and removing nodes is not currently supported, although we intend to add this
+feature in the future).
+
+Each node must have a unique, non-zero integer for an identifier. Currently,
+this must be specified manually on the command line and in the on-chain setting
+below.
+
+### Configure On-Chain Sawtooth Raft Settings
+
+Assign each validator that will be on the network a unique integer. This will
+be its ""raft id"". No id may be 0.
+
+### Configure the Sawtooth Network
+
+When starting validators, they should be configured to use static peering using
+the `--peering static` flag and each node should specify all other nodes as
+their peers using the `--peers` flag.
+
+## On-Chain Settings
+
+The following on-chain settings configure Sawtooth Raft. The required settings
+must be specified in state prior to using Raft consensus. When starting a new
+network, they should be set in the genesis block. All settings are prefixed
+with `sawtooth.consensus.raft`.
+
+The only required setting is `sawtooth.consensus.raft.peers`. It must contain
+a mapping of each node's public key to each node's raft id.
+
+### Required Settings
+
+| key | value |
+| --- | --- |
+| peers | JSON - Map<PeerId, u64> |",54,2018-06-22 13:59:11,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/196585428,https://github.com/hyperledger/sawtooth-raft/pull/1#discussion_r196585428,peterschwarz
https://github.com/hyperledger/sawtooth-raft/pull/1,https://github.com/hyperledger/sawtooth-raft/pull/1,"@peterschwarz is right that once this payload is constructed, it isn't going to change. We could run into a problem if we try to iterate over the map produced and expect that iteration to be non-deterministic.

@dcmiddle do you have any thoughts on taking the last 64 bits of the peer id (which is the validator's public key) and casting that to a u64 to use as the Raft Id. This map was the simplest thing to do to get the prototype working, but if I am able to derive a unique u64 from each validator's public key, then this just needs to be a list of PeerIds (validator public keys) and the need to work with Raft Ids directly goes away.",cdaa0ae9e50f221371411d2c1385f581d7c45519,2018-06-20 13:59:41,196790018,"@@ -0,0 +1,99 @@
+# Sawtooth Raft
+
+Sawtooth Raft is a consensus engine for Hyperledger Sawtooth based on the crash
+fault tolerant consensus algorithm [Raft](http://raft.github.io/).
+Specifically, it is built on top of the Rust implementation of Raft used by
+TiKV, [raft-rs](https://github.com/pingcap/raft-rs).
+
+Currently, Sawtooth Raft is in the prototype phase of development and there is
+additional work to be done in order to make it production worthy.
+
+## Deploying a Sawtooth Network with Raft
+
+Using the Sawtooth Raft engine with Sawtooth requires the following:
+
+1. Configure Sawtooth Raft by specifying the required on-chain settings
+2. Configure the Sawtooth network so that all validators can communicate
+3. Start a Raft engine for every validator and connect it to the validator
+
+Sawtooth deployments using the Sawtooth Raft consensus engine require nodes to
+be fully-connected in order to function correctly. As a result, deployments
+should use a small number of nodes with a relatively fixed membership. (Adding
+and removing nodes is not currently supported, although we intend to add this
+feature in the future).
+
+Each node must have a unique, non-zero integer for an identifier. Currently,
+this must be specified manually on the command line and in the on-chain setting
+below.
+
+### Configure On-Chain Sawtooth Raft Settings
+
+Assign each validator that will be on the network a unique integer. This will
+be its ""raft id"". No id may be 0.
+
+### Configure the Sawtooth Network
+
+When starting validators, they should be configured to use static peering using
+the `--peering static` flag and each node should specify all other nodes as
+their peers using the `--peers` flag.
+
+## On-Chain Settings
+
+The following on-chain settings configure Sawtooth Raft. The required settings
+must be specified in state prior to using Raft consensus. When starting a new
+network, they should be set in the genesis block. All settings are prefixed
+with `sawtooth.consensus.raft`.
+
+The only required setting is `sawtooth.consensus.raft.peers`. It must contain
+a mapping of each node's public key to each node's raft id.
+
+### Required Settings
+
+| key | value |
+| --- | --- |
+| peers | JSON - Map<PeerId, u64> |",54,2018-06-22 13:59:11,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/196790018,https://github.com/hyperledger/sawtooth-raft/pull/1#discussion_r196790018,aludvik
https://github.com/hyperledger/sawtooth-raft/pull/1,https://github.com/hyperledger/sawtooth-raft/pull/1,@aludvik Yes that's a good idea. The lower 64 bytes of a serialized secp256k1 public key (uncompressed) will do what you want. The top byte is just a bitcoin key format flag. If we were to switch curves to something else we could always hash into a 64 byte field without any real concern of collisions. An Edwards pubkey for example would only be 32 bytes so we could either pad out 0's on the rest of the bytes or hash it into 64 bytes.,cdaa0ae9e50f221371411d2c1385f581d7c45519,2018-06-20 22:22:05,196960790,"@@ -0,0 +1,99 @@
+# Sawtooth Raft
+
+Sawtooth Raft is a consensus engine for Hyperledger Sawtooth based on the crash
+fault tolerant consensus algorithm [Raft](http://raft.github.io/).
+Specifically, it is built on top of the Rust implementation of Raft used by
+TiKV, [raft-rs](https://github.com/pingcap/raft-rs).
+
+Currently, Sawtooth Raft is in the prototype phase of development and there is
+additional work to be done in order to make it production worthy.
+
+## Deploying a Sawtooth Network with Raft
+
+Using the Sawtooth Raft engine with Sawtooth requires the following:
+
+1. Configure Sawtooth Raft by specifying the required on-chain settings
+2. Configure the Sawtooth network so that all validators can communicate
+3. Start a Raft engine for every validator and connect it to the validator
+
+Sawtooth deployments using the Sawtooth Raft consensus engine require nodes to
+be fully-connected in order to function correctly. As a result, deployments
+should use a small number of nodes with a relatively fixed membership. (Adding
+and removing nodes is not currently supported, although we intend to add this
+feature in the future).
+
+Each node must have a unique, non-zero integer for an identifier. Currently,
+this must be specified manually on the command line and in the on-chain setting
+below.
+
+### Configure On-Chain Sawtooth Raft Settings
+
+Assign each validator that will be on the network a unique integer. This will
+be its ""raft id"". No id may be 0.
+
+### Configure the Sawtooth Network
+
+When starting validators, they should be configured to use static peering using
+the `--peering static` flag and each node should specify all other nodes as
+their peers using the `--peers` flag.
+
+## On-Chain Settings
+
+The following on-chain settings configure Sawtooth Raft. The required settings
+must be specified in state prior to using Raft consensus. When starting a new
+network, they should be set in the genesis block. All settings are prefixed
+with `sawtooth.consensus.raft`.
+
+The only required setting is `sawtooth.consensus.raft.peers`. It must contain
+a mapping of each node's public key to each node's raft id.
+
+### Required Settings
+
+| key | value |
+| --- | --- |
+| peers | JSON - Map<PeerId, u64> |",54,2018-06-22 13:59:11,https://api.github.com/repos/hyperledger/sawtooth-raft/pulls/comments/196960790,https://github.com/hyperledger/sawtooth-raft/pull/1#discussion_r196960790,dcmiddle
