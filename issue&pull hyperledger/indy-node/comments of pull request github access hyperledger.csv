pull request url html,pull request url,body,commit_id,create at,id,diff_hunk,position,update at,url,html url,user
https://github.com/hyperledger/indy-node/pull/1223,https://github.com/hyperledger/indy-node/pull/1223,Is it still a valid comment?,d90a2b3da6a77017f7d6c3b1aee94989b21f4da8,2019-03-28 08:44:59,269901368,"@@ -1,8 +1,10 @@
 #!groovy
 
-@Library('SovrinHelpers@v1.2.1') _
+// TODO doesn't exist yet",4,2019-03-28 09:02:33,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/269901368,https://github.com/hyperledger/indy-node/pull/1223#discussion_r269901368,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1223,https://github.com/hyperledger/indy-node/pull/1223,This needs to be fixed in future PRs,d90a2b3da6a77017f7d6c3b1aee94989b21f4da8,2019-03-28 08:45:32,269901541,"@@ -295,10 +305,38 @@ def systemTests = { component, releaseVersion ->
     }
 }
 
-options = new TestAndPublishOptions()
+def options = new TestAndPublishOptions()
+options.setPkgName(pkgName)
+options.setApprovers(['QA'])
+options.setNotifEmails([
+    QA: [
+        to: ""${env.INDY_NODE_QA_RECIPIENTS ?: ''}"",
+        cc: ""${env.INDY_NODE_RECIPIENTS ?: ''}""
+    ],
+    success: [
+        to: ""${env.INDY_NODE_RECIPIENTS ?: ''}""
+    ],
+    fail: [
+        to: ""${env.INDY_NODE_RECIPIENTS ?: ''}""
+    ]
+])
+
+// TODO duplicates list from build scripts",63,2019-03-28 09:02:33,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/269901541,https://github.com/hyperledger/indy-node/pull/1223#discussion_r269901541,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1223,https://github.com/hyperledger/indy-node/pull/1223,Please put deprecated label here,d90a2b3da6a77017f7d6c3b1aee94989b21f4da8,2019-03-28 08:51:21,269903308,"@@ -87,6 +99,20 @@ Each `build-scripts` folder includes `Readme.md`. Please check them for more det
 
 #### Versioning
 
+- Please note, that we are using versioning that satisfies [PEP 440](https://www.python.org/dev/peps/pep-0440) with release segment as `MAJOR.MINOR.PATCH` that satisfies [SemVer](https://semver.org/) as well.
+- Version is set in the code (see [\_\_version\_\_.json](https://github.com/hyperledger/indy-node/blob/master/indy_node/__version__.json)).
+- Version is bumped for new releases / hotfixes either manually or using [bump_version.sh](https://github.com/hyperledger/indy-node/blob/master/indy_node/bump_version.sh) script. The latter is preferred.
+- During development phase version includes developmental segment `devN`, where `N` is set for CD pipeline artifacts as incremented build number of build server jobs. In the source code it is just equal to `0` always.
+- During release preparation phase (release / hotfix workflows) version includes pre-release segment `rcN`, where `N>=1` and set in the source code by developers.
+- Each dependency (including indy-plenum) has a strict version (see [setup.py](https://github.com/hyperledger/indy-node/blob/master/setup.py))
+- If you install indy-node (either from pypi, or from deb package), the specified in setup.py version of indy-plenum is installed.
+- Master and Stable share the same versioning scheme.
+- Differences in master and stable code:
+    - `setup.py`: different versions of indy-plenum dependency
+    - different versions in migrations scripts
+
+
+##### For releases `< 1.7.0`",97,2019-03-28 09:02:33,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/269903308,https://github.com/hyperledger/indy-node/pull/1223#discussion_r269903308,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1223,https://github.com/hyperledger/indy-node/pull/1223,Please mention that QA may run additional tests against the RC before approving,d90a2b3da6a77017f7d6c3b1aee94989b21f4da8,2019-03-28 08:59:06,269905982,"@@ -99,17 +125,33 @@ Each `build-scripts` folder includes `Readme.md`. Please check them for more det
         - different versions of indy-plenum dependency
     - different versions in migrations scripts
 
-## How to Create a Stable Release
-
-- Create a new branch based on `stable` in indy-plenum
-- Merge `master` branch into this new branch
-- Make sure that proper versions and names are used (without dev suffixes)
-- Raise a PR to indy-plenum's stable, and wait until code is reviewed and merged. So, a new release candidate of plenum is created.
-- Create a new branch based on `stable` in indy-node
-- Merge `master` branch into this new branch
-- Change indy-plenum's dependency version to the new one in indy-node's [setup.py](https://github.com/hyperledger/indy-node/blob/stable/setup.py).
-- Make sure that proper versions and names are used (without dev suffixes)
-- Raise a PR to indy-node's stable, and wait until code is reviewed and merged. So, a new release candidate of indy-node is created.
-- QA needs to test this release candidate from [https://repo.sovrin.org/deb xenial rc](https://repo.sovrin.org/lib/apt/xenial/rc/)
-- QA approves the release candidate of indy-plenum.
-- QA approves the release candidate of indy-node. So, a new stable release is created.
+## Release workflow
+
+1.  [Maintainer] Creates a new release branch `release-X.Y.0` based on `stable`
+2.  [Contributor]
+  - creates a new release candidate branch (e.g. `rc-X.Y.0.rc1`) based on that release branch
+  - merges `master` branch
+  - sets stable version of `indy-plenum` in `setup.py` (for `indy-node` only)
+  - sets new version `X.Y.0.rc1` (`./bump_version.sh X.Y.0.rc1`)
+  - commits and pushes changes
+  - creates a release candidate PR to `release-X.Y.0`
+3. [Maintainer] Waits for CI, reviews the PR and either merges the PR or asks for changes.
+4. [build server] Once the PR is merged CD pipeline is triggered for branch `release-X.Y.0` and it does the following:
+  - creates and pushes release commit to `release-X.Y.0`
+  - publish release candidates packages
+  - performs system testing (`indy-node` only)
+  - creates PR to merge `release-X.Y.0` to `stable`
+  - waits for approval to proceed
+5. [Maintainer/QA] Waits for CI, reviews the PR and either approves or rejects:",136,2019-03-28 09:02:33,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/269905982,https://github.com/hyperledger/indy-node/pull/1223#discussion_r269905982,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1219,https://github.com/hyperledger/indy-node/pull/1219,Why do we have `indy-node-dev` here again?,11ed346e310b2c9e0d1f5724e702cce4e39993f5,2019-03-27 08:15:55,269444490,"@@ -30,7 +30,8 @@
 tests_require = ['pytest==3.3.1', 'pytest-xdist==1.22.1', 'python3-indy==1.6.8', 'pytest-asyncio==0.8.0']
 
 setup(
-    name=metadata['__title__'],
+    # TODO use __title__ from metadata instead
+    name='indy-node-dev',",6,2019-03-27 09:43:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/269444490,https://github.com/hyperledger/indy-node/pull/1219#discussion_r269444490,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1219,https://github.com/hyperledger/indy-node/pull/1219,Just a temporary fix. Will be improved in next coming PR.,11ed346e310b2c9e0d1f5724e702cce4e39993f5,2019-03-27 09:03:28,269460074,"@@ -30,7 +30,8 @@
 tests_require = ['pytest==3.3.1', 'pytest-xdist==1.22.1', 'python3-indy==1.6.8', 'pytest-asyncio==0.8.0']
 
 setup(
-    name=metadata['__title__'],
+    # TODO use __title__ from metadata instead
+    name='indy-node-dev',",6,2019-03-27 09:43:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/269460074,https://github.com/hyperledger/indy-node/pull/1219#discussion_r269460074,andkononykhin
https://github.com/hyperledger/indy-node/pull/1213,https://github.com/hyperledger/indy-node/pull/1213,Should we check it when we edit NODE txn (changing TARGET_NYM)?,db05fd196e4745c65ba8cbc3da791e03e1048ed3,2019-03-20 14:59:26,267384323,"@@ -34,6 +38,13 @@ def authErrorWhileAddingNode(self, request):
         if error:
             return error
 
+        dest = operation.get(TARGET_NYM)",29,2019-03-21 11:27:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/267384323,https://github.com/hyperledger/indy-node/pull/1213#discussion_r267384323,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1213,https://github.com/hyperledger/indy-node/pull/1213,Can we use some helper method from (like `ed25519PkToCurve25519`) for this?,db05fd196e4745c65ba8cbc3da791e03e1048ed3,2019-03-20 14:59:51,267384558,"@@ -34,6 +38,13 @@ def authErrorWhileAddingNode(self, request):
         if error:
             return error
 
+        dest = operation.get(TARGET_NYM)
+        did = base58.b58decode(dest)",,2019-03-21 11:27:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/267384558,https://github.com/hyperledger/indy-node/pull/1213#discussion_r267384558,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1213,https://github.com/hyperledger/indy-node/pull/1213,"yes, will be fixed.",db05fd196e4745c65ba8cbc3da791e03e1048ed3,2019-03-21 08:09:50,267651665,"@@ -34,6 +38,13 @@ def authErrorWhileAddingNode(self, request):
         if error:
             return error
 
+        dest = operation.get(TARGET_NYM)
+        did = base58.b58decode(dest)",,2019-03-21 11:27:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/267651665,https://github.com/hyperledger/indy-node/pull/1213#discussion_r267651665,ArtObr
https://github.com/hyperledger/indy-node/pull/1213,https://github.com/hyperledger/indy-node/pull/1213,Will be extended for verkey changing,db05fd196e4745c65ba8cbc3da791e03e1048ed3,2019-03-21 08:10:10,267651811,"@@ -34,6 +38,13 @@ def authErrorWhileAddingNode(self, request):
         if error:
             return error
 
+        dest = operation.get(TARGET_NYM)",29,2019-03-21 11:27:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/267651811,https://github.com/hyperledger/indy-node/pull/1213#discussion_r267651811,ArtObr
https://github.com/hyperledger/indy-node/pull/1213,https://github.com/hyperledger/indy-node/pull/1213,"Actually it can be done as part of static validation, not dynamic one. See `doStaticValidation`.",db05fd196e4745c65ba8cbc3da791e03e1048ed3,2019-03-21 14:41:43,267789904,"@@ -34,6 +39,15 @@ def authErrorWhileAddingNode(self, request):
         if error:
             return error
 
+        dest = operation.get(TARGET_NYM)",29,2019-03-21 14:41:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/267789904,https://github.com/hyperledger/indy-node/pull/1213#discussion_r267789904,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1213,https://github.com/hyperledger/indy-node/pull/1213,"It the new logic is part of static validation, then it will throw NACK instead of Reject",db05fd196e4745c65ba8cbc3da791e03e1048ed3,2019-03-21 14:42:34,267790424,"@@ -0,0 +1,74 @@
+import json
+
+import base58
+import pytest
+
+from plenum.common.constants import STEWARD_STRING, VALIDATOR, VERKEY
+from plenum.common.exceptions import RequestRejectedException
+from plenum.common.util import randomString
+from plenum.test.helper import sdk_get_and_check_replies, sdk_get_bad_response
+from plenum.test.pool_transactions.helper import sdk_add_new_nym, prepare_new_node_data, prepare_node_request, \
+    sdk_sign_and_send_prepared_request, sdk_change_node_keys
+
+invalid_dest = 'a' * 43
+
+
+def test_send_node_with_invalid_dest_verkey(looper, txnPoolNodeSet, sdk_pool_handle,
+                                            sdk_wallet_trustee, tdir, tconf, allPluginsPath):
+    node_name = ""Psi""
+    new_steward_name = ""testClientSteward"" + randomString(3)
+    new_steward_wallet_handle = sdk_add_new_nym(looper,
+                                                sdk_pool_handle,
+                                                sdk_wallet_trustee,
+                                                alias=new_steward_name,
+                                                role=STEWARD_STRING)
+    sigseed, verkey, bls_key, nodeIp, nodePort, clientIp, clientPort, key_proof = \
+        prepare_new_node_data(tconf, tdir, node_name)
+
+    # Invalid dest passes static validation
+    assert len(base58.b58decode(invalid_dest)) == 32
+
+    _, steward_did = new_steward_wallet_handle
+    node_request = looper.loop.run_until_complete(
+        prepare_node_request(steward_did,
+                             new_node_name=node_name,
+                             clientIp=clientIp,
+                             clientPort=clientPort,
+                             nodeIp=nodeIp,
+                             nodePort=nodePort,
+                             bls_key=bls_key,
+                             destination=invalid_dest,
+                             services=[VALIDATOR],
+                             key_proof=key_proof))
+
+    request_couple = sdk_sign_and_send_prepared_request(looper, new_steward_wallet_handle,
+                                                        sdk_pool_handle, node_request)
+    sdk_get_bad_response(looper, [request_couple], RequestRejectedException,
+                         'Node\'s dest is not correct Ed25519 key.')
+
+    node_request = looper.loop.run_until_complete(
+        prepare_node_request(steward_did,
+                             new_node_name=node_name,
+                             clientIp=clientIp,
+                             clientPort=clientPort,
+                             nodeIp=nodeIp,
+                             nodePort=nodePort,
+                             bls_key=bls_key,
+                             sigseed=sigseed,
+                             services=[VALIDATOR],
+                             key_proof=key_proof))
+
+    node_request = json.loads(node_request)
+    node_request['operation'][VERKEY] = invalid_dest
+    node_request = json.dumps(node_request)
+
+    request_couple = sdk_sign_and_send_prepared_request(looper, new_steward_wallet_handle,
+                                                        sdk_pool_handle, node_request)
+    sdk_get_bad_response(looper, [request_couple], RequestRejectedException,",67,2019-03-21 14:42:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/267790424,https://github.com/hyperledger/indy-node/pull/1213#discussion_r267790424,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1213,https://github.com/hyperledger/indy-node/pull/1213,ok,db05fd196e4745c65ba8cbc3da791e03e1048ed3,2019-03-22 06:35:11,268049775,"@@ -34,6 +39,15 @@ def authErrorWhileAddingNode(self, request):
         if error:
             return error
 
+        dest = operation.get(TARGET_NYM)",29,2019-03-22 06:35:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/268049775,https://github.com/hyperledger/indy-node/pull/1213#discussion_r268049775,ArtObr
https://github.com/hyperledger/indy-node/pull/1213,https://github.com/hyperledger/indy-node/pull/1213,ok,db05fd196e4745c65ba8cbc3da791e03e1048ed3,2019-03-22 06:35:20,268049794,"@@ -0,0 +1,74 @@
+import json
+
+import base58
+import pytest
+
+from plenum.common.constants import STEWARD_STRING, VALIDATOR, VERKEY
+from plenum.common.exceptions import RequestRejectedException
+from plenum.common.util import randomString
+from plenum.test.helper import sdk_get_and_check_replies, sdk_get_bad_response
+from plenum.test.pool_transactions.helper import sdk_add_new_nym, prepare_new_node_data, prepare_node_request, \
+    sdk_sign_and_send_prepared_request, sdk_change_node_keys
+
+invalid_dest = 'a' * 43
+
+
+def test_send_node_with_invalid_dest_verkey(looper, txnPoolNodeSet, sdk_pool_handle,
+                                            sdk_wallet_trustee, tdir, tconf, allPluginsPath):
+    node_name = ""Psi""
+    new_steward_name = ""testClientSteward"" + randomString(3)
+    new_steward_wallet_handle = sdk_add_new_nym(looper,
+                                                sdk_pool_handle,
+                                                sdk_wallet_trustee,
+                                                alias=new_steward_name,
+                                                role=STEWARD_STRING)
+    sigseed, verkey, bls_key, nodeIp, nodePort, clientIp, clientPort, key_proof = \
+        prepare_new_node_data(tconf, tdir, node_name)
+
+    # Invalid dest passes static validation
+    assert len(base58.b58decode(invalid_dest)) == 32
+
+    _, steward_did = new_steward_wallet_handle
+    node_request = looper.loop.run_until_complete(
+        prepare_node_request(steward_did,
+                             new_node_name=node_name,
+                             clientIp=clientIp,
+                             clientPort=clientPort,
+                             nodeIp=nodeIp,
+                             nodePort=nodePort,
+                             bls_key=bls_key,
+                             destination=invalid_dest,
+                             services=[VALIDATOR],
+                             key_proof=key_proof))
+
+    request_couple = sdk_sign_and_send_prepared_request(looper, new_steward_wallet_handle,
+                                                        sdk_pool_handle, node_request)
+    sdk_get_bad_response(looper, [request_couple], RequestRejectedException,
+                         'Node\'s dest is not correct Ed25519 key.')
+
+    node_request = looper.loop.run_until_complete(
+        prepare_node_request(steward_did,
+                             new_node_name=node_name,
+                             clientIp=clientIp,
+                             clientPort=clientPort,
+                             nodeIp=nodeIp,
+                             nodePort=nodePort,
+                             bls_key=bls_key,
+                             sigseed=sigseed,
+                             services=[VALIDATOR],
+                             key_proof=key_proof))
+
+    node_request = json.loads(node_request)
+    node_request['operation'][VERKEY] = invalid_dest
+    node_request = json.dumps(node_request)
+
+    request_couple = sdk_sign_and_send_prepared_request(looper, new_steward_wallet_handle,
+                                                        sdk_pool_handle, node_request)
+    sdk_get_bad_response(looper, [request_couple], RequestRejectedException,",67,2019-03-22 06:35:21,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/268049794,https://github.com/hyperledger/indy-node/pull/1213#discussion_r268049794,ArtObr
https://github.com/hyperledger/indy-node/pull/1208,https://github.com/hyperledger/indy-node/pull/1208,I guess `root` user will lead to root:root ownership for `/etc/indy/indy_config.py`. I think it makes sense to use `root` only for `apt` and `pip` related installations below.,9a617ba5efe260643100e99f8d56c311aec6d8ce,2019-03-15 14:48:13,266012995,"@@ -5,14 +5,20 @@ ARG nodecnt
 ARG clicnt=10
 
 EXPOSE 5000-9799
-USER indy
+USER root",,2019-03-19 09:10:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266012995,https://github.com/hyperledger/indy-node/pull/1208#discussion_r266012995,andkononykhin
https://github.com/hyperledger/indy-node/pull/1208,https://github.com/hyperledger/indy-node/pull/1208,"@ozheregelya or @andkononykhin  or @VladimirWork, will you be able to process this findings so that we can merge the PR? ",9a617ba5efe260643100e99f8d56c311aec6d8ce,2019-03-18 08:50:41,266339797,"@@ -5,14 +5,20 @@ ARG nodecnt
 ARG clicnt=10
 
 EXPOSE 5000-9799
-USER indy
+USER root",,2019-03-19 09:10:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266339797,https://github.com/hyperledger/indy-node/pull/1208#discussion_r266339797,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1208,https://github.com/hyperledger/indy-node/pull/1208,@ashcherbakov I will,9a617ba5efe260643100e99f8d56c311aec6d8ce,2019-03-19 08:32:12,266774590,"@@ -5,14 +5,20 @@ ARG nodecnt
 ARG clicnt=10
 
 EXPOSE 5000-9799
-USER indy
+USER root",,2019-03-19 09:10:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266774590,https://github.com/hyperledger/indy-node/pull/1208#discussion_r266774590,andkononykhin
https://github.com/hyperledger/indy-node/pull/1207,https://github.com/hyperledger/indy-node/pull/1207,"Yes,  you are right. abbreviated verkeys are currently not supported. Can you please also fix the documentation for NODE request in `requests.md`?",3ebb38d9d451a651c4fe2a8a4c763f92981f06db,2019-03-18 08:47:13,266338812,"@@ -458,16 +458,10 @@ Adds a new node to the pool or updates an existing node in the pool
 
 - `dest` (base58-encoded string):
 
-    Target Node's DID as base58-encoded string for 16 or 32 byte DID value.
+    Target Node's verkey as base58-encoded string for 16 or 32 byte DID value.",5,2019-03-18 19:39:30,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266338812,https://github.com/hyperledger/indy-node/pull/1207#discussion_r266338812,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1207,https://github.com/hyperledger/indy-node/pull/1207,Hey! Just updated the same info in both `requests.md` and `requests-new.md`.,3ebb38d9d451a651c4fe2a8a4c763f92981f06db,2019-03-18 19:45:22,266611511,"@@ -458,16 +458,10 @@ Adds a new node to the pool or updates an existing node in the pool
 
 - `dest` (base58-encoded string):
 
-    Target Node's DID as base58-encoded string for 16 or 32 byte DID value.
+    Target Node's verkey as base58-encoded string for 16 or 32 byte DID value.",5,2019-03-18 19:45:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266611511,https://github.com/hyperledger/indy-node/pull/1207#discussion_r266611511,Diiaablo95
https://github.com/hyperledger/indy-node/pull/1207,https://github.com/hyperledger/indy-node/pull/1207,Thank you very much!,3ebb38d9d451a651c4fe2a8a4c763f92981f06db,2019-03-19 06:27:15,266745387,"@@ -458,16 +458,10 @@ Adds a new node to the pool or updates an existing node in the pool
 
 - `dest` (base58-encoded string):
 
-    Target Node's DID as base58-encoded string for 16 or 32 byte DID value.
+    Target Node's verkey as base58-encoded string for 16 or 32 byte DID value.",5,2019-03-19 06:27:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266745387,https://github.com/hyperledger/indy-node/pull/1207#discussion_r266745387,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1200,https://github.com/hyperledger/indy-node/pull/1200,OLD_VALUE can be empty now (see https://github.com/hyperledger/indy-node/pull/1202),dba01302e1cd846425f9ada3504aa87bd9482063,2019-03-12 18:31:29,264825416,"@@ -368,6 +368,19 @@ class ClientAuthRuleOperation(MessageValidator):
     )
 
 
+class ClientGetAuthRuleOperation(MessageValidator):
+    schema = (
+        (TXN_TYPE, ConstantField(GET_AUTH_RULE)),
+        (AUTH_ACTION, ChooseField(values=(ADD_PREFIX, EDIT_PREFIX), optional=True)),
+        (AUTH_TYPE, LimitedLengthStringField(max_length=NAME_FIELD_LIMIT, optional=True)),
+        (FIELD, LimitedLengthStringField(max_length=NAME_FIELD_LIMIT, optional=True)),
+        (OLD_VALUE, LimitedLengthStringField(max_length=NAME_FIELD_LIMIT,",19,2019-03-15 07:33:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/264825416,https://github.com/hyperledger/indy-node/pull/1200#discussion_r264825416,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1200,https://github.com/hyperledger/indy-node/pull/1200,Should we do similar checks as in `_doStaticValidationAuthRule` related to `OLD_VALUE `?,dba01302e1cd846425f9ada3504aa87bd9482063,2019-03-12 18:46:01,264831400,"@@ -60,14 +65,16 @@ def _doStaticValidationAuthRule(self, identifier, reqId, operation):
                                        ""Transaction for change authentication ""
                                        ""rule for {}={} must not contain field {}"".
                                        format(AUTH_ACTION, ADD_PREFIX, OLD_VALUE))
+        self._check_auth_key(operation, identifier, reqId)
 
-        auth_key = self.get_auth_key(operation)
-
-        if auth_key not in self.write_req_validator.auth_map and \
-                auth_key not in self.write_req_validator.anyone_can_write_map:
-            raise InvalidClientRequest(identifier, reqId,
-                                       ""Unknown authorization rule: key '{}' is not ""
-                                       ""found in authorization map"".format(auth_key))
+    def _doStaticValidationGetAuthRule(self, identifier, req_id, operation):
+        required_fields = list(dict(ClientGetAuthRuleOperation.schema).keys())
+        required_fields.remove(OLD_VALUE)
+        if len(operation) > 1:
+            if not set(required_fields).issubset(set(operation.keys())):",69,2019-03-15 07:33:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/264831400,https://github.com/hyperledger/indy-node/pull/1200#discussion_r264831400,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1200,https://github.com/hyperledger/indy-node/pull/1200,Is it WIP?,dba01302e1cd846425f9ada3504aa87bd9482063,2019-03-12 18:49:14,264832810,"@@ -0,0 +1,35 @@
+from plenum.server.request_handlers.handler_interfaces.read_request_handler import ReadRequestHandler
+
+from indy_common.authorize.auth_constraints import ConstraintCreator
+from indy_node.server.pool_config import PoolConfig
+
+from indy_common.authorize.auth_actions import AuthActionEdit, EDIT_PREFIX, AuthActionAdd
+from indy_common.authorize.auth_request_validator import WriteRequestValidator
+from indy_common.constants import POOL_CONFIG, CONFIG_LEDGER_ID, ACTION, AUTH_RULE, CONSTRAINT, AUTH_ACTION, OLD_VALUE, \
+    NEW_VALUE, AUTH_TYPE, FIELD
+from indy_node.server.request_handlers.config_req_handlers.config_write_request_handler import ConfigWriteRequestHandler
+from plenum.common.exceptions import InvalidClientRequest
+from plenum.common.request import Request
+from plenum.server.database_manager import DatabaseManager
+
+
+class GetAuthRuleHandler(ReadRequestHandler):
+
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager, AUTH_RULE, CONFIG_LEDGER_ID)
+
+    def get_result(self, request: Request):
+        self._validate_request_type(request)
+        data, seq_no, update_time, proof = self._get_auth_map()
+        result = self.make_result(request=request,
+                                  data=data,
+                                  last_seq_no=seq_no,
+                                  update_time=update_time,
+                                  proof=proof)
+
+        result.update(request.operation)
+        return result
+
+    def _get_auth_map(self):
+        data, seq_no, update_time, proof = None, None, None, None",,2019-03-15 07:33:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/264832810,https://github.com/hyperledger/indy-node/pull/1200#discussion_r264832810,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1200,https://github.com/hyperledger/indy-node/pull/1200,does not contain,dba01302e1cd846425f9ada3504aa87bd9482063,2019-03-12 18:52:03,264834038,"@@ -1541,6 +1542,159 @@ A generic request to get a transaction from Ledger by its sequence number.
 }
 ```
 
+### GET_AUTH_RULE
+
+A request to get a constraint for an authentication rule or a full list of rules from Ledger by the auth key parameters.
+Two options are possible in a request build:
+- If the request has a full list of parameters (or without `old_value`), then the reply will contain one constraint for this key.
+- If the request are not contain fields other than txn_type, the response will contain a full list of authentication rules.",,2019-03-15 07:33:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/264834038,https://github.com/hyperledger/indy-node/pull/1200#discussion_r264834038,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1200,https://github.com/hyperledger/indy-node/pull/1200,"I think, no. It's not a command which change something. If a request contains excess fields, but we can found a key maybe will be better to do it.",dba01302e1cd846425f9ada3504aa87bd9482063,2019-03-13 07:21:25,264998777,"@@ -60,14 +65,16 @@ def _doStaticValidationAuthRule(self, identifier, reqId, operation):
                                        ""Transaction for change authentication ""
                                        ""rule for {}={} must not contain field {}"".
                                        format(AUTH_ACTION, ADD_PREFIX, OLD_VALUE))
+        self._check_auth_key(operation, identifier, reqId)
 
-        auth_key = self.get_auth_key(operation)
-
-        if auth_key not in self.write_req_validator.auth_map and \
-                auth_key not in self.write_req_validator.anyone_can_write_map:
-            raise InvalidClientRequest(identifier, reqId,
-                                       ""Unknown authorization rule: key '{}' is not ""
-                                       ""found in authorization map"".format(auth_key))
+    def _doStaticValidationGetAuthRule(self, identifier, req_id, operation):
+        required_fields = list(dict(ClientGetAuthRuleOperation.schema).keys())
+        required_fields.remove(OLD_VALUE)
+        if len(operation) > 1:
+            if not set(required_fields).issubset(set(operation.keys())):",69,2019-03-15 07:33:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/264998777,https://github.com/hyperledger/indy-node/pull/1200#discussion_r264998777,Toktar
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Where is it used? Do we really need this field?,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 11:51:13,265089649,"@@ -149,6 +149,24 @@
                                            old_value='*',
                                            new_value='*')
 
+trusted_roles = '[\'TRUSTEE\', \'TRUST_ANCHOR\', \'STEWARD\']'",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265089649,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265089649,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"There is no ROLE field in REVOC_REG_DEF. Please use `*` instead, since we don't have different auth constraints for adding of a new RevocRegDef depending on the field (like in NYM).",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 11:52:14,265089925,"@@ -149,6 +149,24 @@
                                            old_value='*',
                                            new_value='*')
 
+trusted_roles = '[\'TRUSTEE\', \'TRUST_ANCHOR\', \'STEWARD\']'
+
+create_revoc_reg_def = AuthActionAdd(txn_type=REVOC_REG_DEF,
+                                     field=ROLE,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265089925,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265089925,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Please use `*` instead of ROLE,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 11:54:05,265090493,"@@ -149,6 +149,24 @@
                                            old_value='*',
                                            new_value='*')
 
+trusted_roles = '[\'TRUSTEE\', \'TRUST_ANCHOR\', \'STEWARD\']'
+
+create_revoc_reg_def = AuthActionAdd(txn_type=REVOC_REG_DEF,
+                                     field=ROLE,
+                                     value='*')
+
+create_revoc_reg_entry = AuthActionAdd(txn_type=REVOC_REG_ENTRY,
+                                       field='*',
+                                       value='*')
+
+anyone_can_create_revoc_reg_def = AuthActionAdd(txn_type=REVOC_REG_DEF,
+                                                field=ROLE,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265090493,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265090493,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,There is no ROLE field in RevocRegDef operation. ,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 11:56:55,265091326,"@@ -269,6 +270,12 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
         tags = cred_def_id.split("":"")
+
+        role = operation.get(ROLE)",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265091326,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265091326,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,You can use `*` instead of both `ROLE` and `value`,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 11:57:17,265091451,"@@ -269,6 +270,12 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
         tags = cred_def_id.split("":"")
+
+        role = operation.get(ROLE)
+        self.write_req_validator.validate(req,
+                                          [AuthActionAdd(txn_type=REVOC_REG_DEF,
+                                                         field=ROLE,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265091451,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265091451,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,authorized should be True only if `is_owner` is True.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 11:59:14,265092082,"@@ -0,0 +1,20 @@
+from indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit
+from indy_common.constants import REVOC_REG_DEF
+
+
+def test_rev_reg_def_adding(write_request_validation, req, is_owner):
+    authorized = req.identifier in (""trustee_identifier"", ""steward_identifier"", ""trust_anchor_identifier"")",6,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265092082,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265092082,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,why do you need it?,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 12:00:01,265092309,"@@ -149,6 +149,24 @@
                                            old_value='*',
                                            new_value='*')
 
+trusted_roles = '[\'TRUSTEE\', \'TRUST_ANCHOR\', \'STEWARD\']'",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265092309,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265092309,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"Please rather check in what cases it's true (the same condition as in previous test, that is either Trustee, Steward or TrustAnchor AND isOwner?)",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 12:00:16,265092389,"@@ -0,0 +1,20 @@
+from indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit
+from indy_common.constants import REVOC_REG_DEF
+
+
+def test_rev_reg_def_adding(write_request_validation, req, is_owner):
+    authorized = req.identifier in (""trustee_identifier"", ""steward_identifier"", ""trust_anchor_identifier"")
+    assert authorized == write_request_validation(req,
+                                                  [AuthActionAdd(txn_type=REVOC_REG_DEF,
+                                                                 field='some_field',
+                                                                 value='some_value',
+                                                                 is_owner=is_owner)])
+
+
+def test_rev_reg_def_editing(write_request_validation, req, is_owner):
+    assert not write_request_validation(req,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265092389,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265092389,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"Also please add auth checks for RevocRegDefEntry. Make sure that only the owner of RevocRegDef can edit RevocRegEntry.
I think that you can use isOwner flag for this. Create `is_owner` flag which is True if the author of RevocRegEntry is the author of the corresponding RevocRegDef. Pass `is_owner` flag to `AuthActionAdd` for `REVOC_REG_ENTRY`.
",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 12:49:01,265109158,"@@ -269,6 +270,12 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
         tags = cred_def_id.split("":"")
+",20,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265109158,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265109158,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"`ANYONE_CAN_WRITE` will be removed soon, which means that here we can assume that ANYONE_CAN_WRITE  is always False.
So, I believe the `tconf` below is not needed at all.",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 12:52:23,265110410,"@@ -5,11 +5,21 @@
     CLAIM_DEF_SIGNATURE_TYPE, CLAIM_DEF_TAG
 from indy_common.state.domain import make_state_path_for_claim_def
 from indy_node.test.anon_creds.conftest import claim_def, build_revoc_reg_entry_for_given_revoc_reg_def, \
-    build_revoc_def_by_default
+    build_revoc_def_by_default, build_revoc_def_by_client, build_revoc_def_by_trust_anchor
 from indy_node.test.schema.test_send_get_schema import send_schema_seq_no
+from plenum.common.exceptions import RequestNackedException, RequestRejectedException
 from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check
 
 
+@pytest.fixture(scope='module')
+def tconf_false(tconf):",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265110410,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265110410,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"It looks like here we check that a common client can not send RevocRegDef, but we do not check that Trustee, Steward or TrustAnchor can.
I think this test can be parametrized to send RevocRegDef for every role expecting that only sending by Trustee, Steward or TrustAnchor will succeed.",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 12:54:57,265111366,"@@ -58,4 +93,30 @@ def test_client_can_send_revoc_reg_entry(looper,
     rev_reg_entry[VALUE][REVOKED] = [1, 2, 3, 4, 5]
     del rev_reg_entry[VALUE][PREV_ACCUM]
     rev_entry_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, rev_reg_entry)
-    sdk_send_and_check([json.dumps(rev_entry_req)], looper, txnPoolNodeSet, sdk_pool_handle)
\ No newline at end of file
+    sdk_send_and_check([json.dumps(rev_entry_req)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+
+def test_rev_reg_def_only_trustee_steward_trust_anchor_can_create(looper,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265111366,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265111366,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"What does `owner` mean for RevocRegDef entry? Currently we don't require that the author of RevocRegDef is the author of corresponding CredDef (unlike the case of ReovRegEntry where we must require that the author of RevocRegEntry is also the author of the corresponding RevocRegDef).
So, maybe we should use just `trust_anchor_or_steward_or_trustee_constraint` for `create_revoc_reg_def`?",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-13 12:59:19,265113056,"@@ -202,7 +224,9 @@
     pool_config.get_action_id(): one_trustee_constraint,
     validator_info.get_action_id(): AuthConstraintOr([AuthConstraint(TRUSTEE, 1),
                                                       AuthConstraint(STEWARD, 1),
-                                                      AuthConstraint(NETWORK_MONITOR, 1)])
+                                                      AuthConstraint(NETWORK_MONITOR, 1)]),
+    create_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_owners_constraint,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265113056,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265113056,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"If we allow editing of RevocRegDef, then it needs to be allowed by the owner only. 
BTW it looks like this rule is never used.",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 06:55:27,265438638,"@@ -225,8 +238,9 @@
     validator_info.get_action_id(): AuthConstraintOr([AuthConstraint(TRUSTEE, 1),
                                                       AuthConstraint(STEWARD, 1),
                                                       AuthConstraint(NETWORK_MONITOR, 1)]),
-    create_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_owners_constraint,
-    create_revoc_reg_entry.get_action_id(): trust_anchor_or_steward_or_trustee_owners_constraint
+    add_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_constraint,
+    add_revoc_reg_entry.get_action_id(): trust_anchor_or_steward_or_trustee_constraint,
+    edit_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_constraint",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265438638,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265438638,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Adding a RevocRegEntry needs to be allowed by the owner only (owner here means that the one who adds a new RevocRegEntry must be the author of the corresponding RevocRegDef).,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 06:56:40,265438889,"@@ -225,8 +238,9 @@
     validator_info.get_action_id(): AuthConstraintOr([AuthConstraint(TRUSTEE, 1),
                                                       AuthConstraint(STEWARD, 1),
                                                       AuthConstraint(NETWORK_MONITOR, 1)]),
-    create_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_owners_constraint,
-    create_revoc_reg_entry.get_action_id(): trust_anchor_or_steward_or_trustee_owners_constraint
+    add_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_constraint,
+    add_revoc_reg_entry.get_action_id(): trust_anchor_or_steward_or_trustee_constraint,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265438889,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265438889,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Why don't we just write `is_owner = <... condition>` without initial set to False.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 06:59:34,265439475,"@@ -305,6 +304,18 @@ def _validate_revoc_reg_entry(self, req: Request):
             revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
             req_id=req.reqId
         )
+
+        is_owner = False
+
+        if get_req_id(req) == req.operation[REVOC_REG_DEF_ID]:
+            is_owner = True",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265439475,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265439475,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"Here we always consider it as an ADD action, but it may be EDIT or ADD depending on if `current_entry is None`",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 07:03:04,265440100,"@@ -305,6 +304,18 @@ def _validate_revoc_reg_entry(self, req: Request):
             revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
             req_id=req.reqId
         )
+
+        is_owner = False
+
+        if get_req_id(req) == req.operation[REVOC_REG_DEF_ID]:
+            is_owner = True
+
+        self.write_req_validator.validate(req,
+                                          [AuthActionAdd(txn_type=REVOC_REG_ENTRY,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265440100,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265440100,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"This comparison is incorrect. Here Request ID is compared to REVOC_REG_DEF_ID which is RevocReg's key in State Trie.
But we need to compare sender's DID (`req.identifier`) with `revoc_def `'s DID (either get it from `revoc_def` or from `revoc_reg_def_id`, as this DID is part of `revoc_reg_def_id`, see `prepare_revoc_def_for_state` method).


",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 07:12:48,265441952,"@@ -305,6 +304,18 @@ def _validate_revoc_reg_entry(self, req: Request):
             revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
             req_id=req.reqId
         )
+
+        is_owner = False
+
+        if get_req_id(req) == req.operation[REVOC_REG_DEF_ID]:",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265441952,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265441952,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"According to what the method does, it needs to be called trust_anchor_sends_revoc_reg_def`",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 07:14:44,265442320,"@@ -33,57 +24,55 @@ def tconf(tconf):
 def client_send_revoc_reg_def(looper,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265442320,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265442320,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,We need to expect `RequestRejectedException` here.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 07:16:34,265442659,"@@ -96,27 +85,5 @@ def test_client_can_send_revoc_reg_entry(looper,
     sdk_send_and_check([json.dumps(rev_entry_req)], looper, txnPoolNodeSet, sdk_pool_handle)",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265442659,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265442659,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Also we need tests to check that only the one who created a RevocRegDef can create or edit corresponding RevocRegEntry.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 07:17:47,265442891,"@@ -33,57 +24,55 @@ def tconf(tconf):
 def client_send_revoc_reg_def(looper,
                               txnPoolNodeSet,
                               sdk_wallet_client,
+                              sdk_wallet_trust_anchor,
                               sdk_pool_handle,
                               build_revoc_def_by_default,
                               claim_def, tconf):
     # We need to have claim_def to send revocation txns
+    # must be signed by trust anchor since ANYONE_CAN_WRITE is false
 
-    claim_def_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, claim_def)
+    claim_def_req = sdk_sign_request_from_dict(looper, sdk_wallet_trust_anchor, claim_def)
     sdk_send_and_check([json.dumps(claim_def_req)], looper, txnPoolNodeSet, sdk_pool_handle)
 
-    _, author_did = sdk_wallet_client
+    _, author_did = sdk_wallet_trust_anchor
     revoc_reg = build_revoc_def_by_default
     revoc_reg['operation'][CRED_DEF_ID] = \
         make_state_path_for_claim_def(author_did,
                                       str(claim_def_req['operation'][CLAIM_DEF_SCHEMA_REF]),
                                       claim_def_req['operation'][CLAIM_DEF_SIGNATURE_TYPE],
                                       claim_def_req['operation'][CLAIM_DEF_TAG]
                                       ).decode()
-    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, revoc_reg['operation'])
+    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_trust_anchor, revoc_reg['operation'])
     _, revoc_reply = sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0]
     return revoc_req
 
 
-@pytest.fixture(scope=""module"")
-def trust_anchor_send_revoc_reg_def(looper,
-                                    txnPoolNodeSet,
-                                    sdk_wallet_trust_anchor,
-                                    sdk_pool_handle,
-                                    build_revoc_def_by_trust_anchor,
-                                    claim_def, tconf_false):
-    # We need to have claim_def to send revocation txns
+def test_client_cant_send_revoc_reg_def(looper,
+                                        txnPoolNodeSet,
+                                        sdk_wallet_client,
+                                        sdk_wallet_trust_anchor,
+                                        sdk_pool_handle,
+                                        build_revoc_def_by_client,
+                                        claim_def, tconf):
+    # when ANYONE_CAN_WRITE is false only trustee, steward, and trust_anchor can write
 
     claim_def_req = sdk_sign_request_from_dict(looper, sdk_wallet_trust_anchor, claim_def)
     sdk_send_and_check([json.dumps(claim_def_req)], looper, txnPoolNodeSet, sdk_pool_handle)
 
-    _, author_did = sdk_wallet_trust_anchor
-    revoc_reg = build_revoc_def_by_trust_anchor
+    _, author_did = sdk_wallet_client
+    revoc_reg = build_revoc_def_by_client
     revoc_reg['operation'][CRED_DEF_ID] = \
         make_state_path_for_claim_def(author_did,
                                       str(claim_def_req['operation'][CLAIM_DEF_SCHEMA_REF]),
                                       claim_def_req['operation'][CLAIM_DEF_SIGNATURE_TYPE],
                                       claim_def_req['operation'][CLAIM_DEF_TAG]
                                       ).decode()
-    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_trust_anchor, revoc_reg['operation'])
-    _, revoc_reply = sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0]
-    return revoc_req
-
-
-def test_client_can_send_revoc_reg_def(client_send_revoc_reg_def):
-    pass
+    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, revoc_reg['operation'])
+    with pytest.raises(RequestRejectedException):
+        _, revoc_reply = sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0]
 ",92,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265442891,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265442891,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Should `owner_only` be the only restriction for edit `revoc_reg_def`?,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 13:18:01,265562638,"@@ -225,8 +238,9 @@
     validator_info.get_action_id(): AuthConstraintOr([AuthConstraint(TRUSTEE, 1),
                                                       AuthConstraint(STEWARD, 1),
                                                       AuthConstraint(NETWORK_MONITOR, 1)]),
-    create_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_owners_constraint,
-    create_revoc_reg_entry.get_action_id(): trust_anchor_or_steward_or_trustee_owners_constraint
+    add_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_constraint,
+    add_revoc_reg_entry.get_action_id(): trust_anchor_or_steward_or_trustee_constraint,
+    edit_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_constraint",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265562638,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265562638,cam-parra
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"Yes, I think so. It's almost always true that only the owner can edit his own data.",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 13:32:27,265568933,"@@ -225,8 +238,9 @@
     validator_info.get_action_id(): AuthConstraintOr([AuthConstraint(TRUSTEE, 1),
                                                       AuthConstraint(STEWARD, 1),
                                                       AuthConstraint(NETWORK_MONITOR, 1)]),
-    create_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_owners_constraint,
-    create_revoc_reg_entry.get_action_id(): trust_anchor_or_steward_or_trustee_owners_constraint
+    add_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_constraint,
+    add_revoc_reg_entry.get_action_id(): trust_anchor_or_steward_or_trustee_constraint,
+    edit_revoc_reg_def.get_action_id(): trust_anchor_or_steward_or_trustee_constraint",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265568933,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265568933,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"RevocRegEntry isn't needed here (moreover, it's most probably doesn't exist yet).
It's sufficient to get ReovcDef only (maybe create a new method for this).",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 16:38:03,265660888,"@@ -271,10 +271,20 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_type
         tags = cred_def_id.split("":"")
 
-        self.write_req_validator.validate(req,
-                                          [AuthActionAdd(txn_type=REVOC_REG_DEF,
-                                                         field='*',
-                                                         value='*')])
+        rev_entry, _ = self._get_current_revoc_entry_and_revoc_def(req.identifier, revoc_def_type, req.reqId)",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265660888,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265660888,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"First note, it's better to write
` is_owner = txn_data.get(CRED_DEF_ID) == author_did`

Second note, a check for `txn_data.get(CRED_DEF_ID)` is incorrect here.
What you should do instead:
- get RevocDef'S ID (stet key) as `req.operation[REVOC_REG_DEF_ID]` 
- get RevocDef's author DID from RevocDef'S ID  (have a look at `make_state_path_for_revoc_def`, you need DID part from there). I'm not sure if we have a method to get this value from ID. You may consider creating one.
- compare the DID received ion the previous step to `author_did `",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 16:51:37,265667093,"@@ -299,16 +309,14 @@ def _get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, r
         return current_entry, revoc_def
 
     def _validate_revoc_reg_entry(self, req: Request):
+        author_did = req.identifier
         current_entry, revoc_def = self._get_current_revoc_entry_and_revoc_def(
-            author_did=req.identifier,
+            author_did=author_did,
             revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
             req_id=req.reqId
         )
-
-        is_owner = False
-
-        if get_req_id(req) == req.operation[REVOC_REG_DEF_ID]:
-            is_owner = True
+        txn_data = get_payload_data(revoc_def)
+        is_owner = True if txn_data.get(CRED_DEF_ID) == author_did else False",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265667093,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265667093,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Please use ADD or EDIT actions depending on if `current_entry` is present.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 16:52:33,265667530,"@@ -299,16 +309,14 @@ def _get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, r
         return current_entry, revoc_def
 
     def _validate_revoc_reg_entry(self, req: Request):
+        author_did = req.identifier
         current_entry, revoc_def = self._get_current_revoc_entry_and_revoc_def(
-            author_did=req.identifier,
+            author_did=author_did,
             revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
             req_id=req.reqId
         )
-
-        is_owner = False
-
-        if get_req_id(req) == req.operation[REVOC_REG_DEF_ID]:
-            is_owner = True
+        txn_data = get_payload_data(revoc_def)
+        is_owner = True if txn_data.get(CRED_DEF_ID) == author_did else False
 
         self.write_req_validator.validate(req,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265667530,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265667530,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,This test doen't look correct. Please see my comments in Slack.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 16:53:43,265668010,"@@ -72,18 +71,18 @@ def test_client_cant_send_revoc_reg_def(looper,
         _, revoc_reply = sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0]
 
 
-def test_client_cant_send_revoc_reg_entry(looper,
-                                          trust_anchor_sends_revoc_reg_def,
-                                          sdk_wallet_client,
-                                          txnPoolNodeSet,
-                                          sdk_pool_handle):
+def test_trust_anchor_cant_send_revoc_reg_entry(looper,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265668010,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265668010,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Please fix this finding.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-14 16:54:24,265668312,"@@ -0,0 +1,20 @@
+from indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit
+from indy_common.constants import REVOC_REG_DEF
+
+
+def test_rev_reg_def_adding(write_request_validation, req, is_owner):
+    authorized = req.identifier in (""trustee_identifier"", ""steward_identifier"", ""trust_anchor_identifier"")",6,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265668312,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265668312,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"Whether this is an EDIT or ADD action for RevocRegDef is defined by a presence of REVOC_DEF, not CRED_DEF",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-15 13:03:32,265970948,"@@ -269,13 +270,27 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
         tags = cred_def_id.split("":"")
+
+        cred_def, _, _, _ = self.lookup(cred_def_id, isCommitted=False, with_proof=False)",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265970948,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265970948,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Thank you. I did not see that I will update ,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-15 13:25:51,265978476,"@@ -269,13 +270,27 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
         tags = cred_def_id.split("":"")
+
+        cred_def, _, _, _ = self.lookup(cred_def_id, isCommitted=False, with_proof=False)",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265978476,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265978476,cam-parra
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"@ashcherbakov When I do this `
        revoc_def, _, _, _ = self.lookup(req.operation[REVOC_REG_DEF_ID], isCommitted=False, with_proof=False)` I get a PoolLedgerTimeout
",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-15 13:36:35,265982703,"@@ -269,13 +270,27 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
         tags = cred_def_id.split("":"")
+
+        cred_def, _, _, _ = self.lookup(cred_def_id, isCommitted=False, with_proof=False)",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265982703,https://github.com/hyperledger/indy-node/pull/1192#discussion_r265982703,cam-parra
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,I think this is because there is no `REVOC_REG_DEF_ID` in `req.operation`? I think you need to create `REVOC_REG_DEF_ID` from req data. Have a look at `make_state_path_for_revoc_def`.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-15 14:55:43,266016505,"@@ -269,13 +270,27 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
         tags = cred_def_id.split("":"")
+
+        cred_def, _, _, _ = self.lookup(cred_def_id, isCommitted=False, with_proof=False)",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266016505,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266016505,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"The author DID here is not the author of the corresponding CRED_DEF, but the author of this RevocDef. So, `req.identifier` needs to be passed as the first argument.",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-18 08:18:17,266330060,"@@ -269,13 +271,30 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
         tags = cred_def_id.split("":"")
+
+        revoc_def = make_state_path_for_revoc_def(tags[0], cred_def_id, revoc_def_type, revoc_def_tag)",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266330060,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266330060,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,The `txn_type` here must be `REVOC_REG_ENTRY`.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-18 08:21:08,266330905,"@@ -293,11 +312,31 @@ def _get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, r
         return current_entry, revoc_def
 
     def _validate_revoc_reg_entry(self, req: Request):
+        author_did = req.identifier
+        rev_reg_tags = req.operation[REVOC_REG_DEF_ID]
         current_entry, revoc_def = self._get_current_revoc_entry_and_revoc_def(
-            author_did=req.identifier,
+            author_did=author_did,
             revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
             req_id=req.reqId
         )
+
+        cred_did = rev_reg_tags.split("":"", 1)[0]
+        is_owner = cred_did == author_did
+
+        if current_entry:
+            self.write_req_validator.validate(req,",65,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266330905,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266330905,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,A better name for this variable is `revoc_ref_def_author_did`,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-18 08:22:22,266331347,"@@ -293,11 +312,31 @@ def _get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, r
         return current_entry, revoc_def
 
     def _validate_revoc_reg_entry(self, req: Request):
+        author_did = req.identifier
+        rev_reg_tags = req.operation[REVOC_REG_DEF_ID]
         current_entry, revoc_def = self._get_current_revoc_entry_and_revoc_def(
-            author_did=req.identifier,
+            author_did=author_did,
             revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
             req_id=req.reqId
         )
+
+        cred_did = rev_reg_tags.split("":"", 1)[0]",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266331347,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266331347,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,It's better to call this test `test_allowed_roles_can_create_revoc_reg_def`,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-18 08:30:29,266333699,"@@ -5,57 +5,105 @@
     CLAIM_DEF_SIGNATURE_TYPE, CLAIM_DEF_TAG
 from indy_common.state.domain import make_state_path_for_claim_def
 from indy_node.test.anon_creds.conftest import claim_def, build_revoc_reg_entry_for_given_revoc_reg_def, \
-    build_revoc_def_by_default
+    build_revoc_def_by_default, build_revoc_def_by_trust_anchor
 from indy_node.test.schema.test_send_get_schema import send_schema_seq_no
+from plenum.common.exceptions import RequestNackedException, RequestRejectedException
 from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check
 
 
 @pytest.fixture(scope='module')
 def tconf(tconf):
     OLD_ANYONE_CAN_WRITE = tconf.ANYONE_CAN_WRITE
-    tconf.ANYONE_CAN_WRITE = True
+    tconf.ANYONE_CAN_WRITE = False
 
     yield tconf
     tconf.ANYONE_CAN_WRITE = OLD_ANYONE_CAN_WRITE
 
 
-@pytest.fixture(scope=""module"")
-def client_send_revoc_reg_def(looper,
-                              txnPoolNodeSet,
-                              sdk_wallet_client,
-                              sdk_pool_handle,
-                              build_revoc_def_by_default,
-                              claim_def, tconf):
+def send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc,
+                       claim_def, wallet):
     # We need to have claim_def to send revocation txns
+    # must be signed by trust anchor since ANYONE_CAN_WRITE is false
 
-    claim_def_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, claim_def)
+    claim_def_req = sdk_sign_request_from_dict(looper, wallet, claim_def)
     sdk_send_and_check([json.dumps(claim_def_req)], looper, txnPoolNodeSet, sdk_pool_handle)
 
-    _, author_did = sdk_wallet_client
-    revoc_reg = build_revoc_def_by_default
+    _, author_did = wallet
+    revoc_reg = build_revoc
     revoc_reg['operation'][CRED_DEF_ID] = \
         make_state_path_for_claim_def(author_did,
                                       str(claim_def_req['operation'][CLAIM_DEF_SCHEMA_REF]),
                                       claim_def_req['operation'][CLAIM_DEF_SIGNATURE_TYPE],
                                       claim_def_req['operation'][CLAIM_DEF_TAG]
                                       ).decode()
-    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, revoc_reg['operation'])
+    revoc_req = sdk_sign_request_from_dict(looper, wallet, revoc_reg['operation'])
     _, revoc_reply = sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0]
     return revoc_req
 
 
-def test_client_can_send_revoc_reg_def(client_send_revoc_reg_def):
-    pass
+def test_client_cant_send_revoc_reg_def(looper,
+                                        txnPoolNodeSet,
+                                        sdk_wallet_client,
+                                        sdk_pool_handle,
+                                        build_revoc_def_by_default,
+                                        claim_def, tconf):
+    with pytest.raises(RequestRejectedException):
+        send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                           claim_def, sdk_wallet_client)
 
 
-def test_client_can_send_revoc_reg_entry(looper,
-                                         client_send_revoc_reg_def,
-                                         sdk_wallet_client,
-                                         txnPoolNodeSet,
-                                         sdk_pool_handle):
-    revoc_def_req = client_send_revoc_reg_def
-    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req)
-    rev_reg_entry[VALUE][REVOKED] = [1, 2, 3, 4, 5]
-    del rev_reg_entry[VALUE][PREV_ACCUM]
-    rev_entry_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, rev_reg_entry)
-    sdk_send_and_check([json.dumps(rev_entry_req)], looper, txnPoolNodeSet, sdk_pool_handle)
\ No newline at end of file
+def test_allowed_roles_can_send_revoc_reg_def(looper,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266333699,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266333699,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,It's better to call this test `test_client_cant_create_revoc_reg_def`,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-18 08:30:39,266333737,"@@ -5,57 +5,105 @@
     CLAIM_DEF_SIGNATURE_TYPE, CLAIM_DEF_TAG
 from indy_common.state.domain import make_state_path_for_claim_def
 from indy_node.test.anon_creds.conftest import claim_def, build_revoc_reg_entry_for_given_revoc_reg_def, \
-    build_revoc_def_by_default
+    build_revoc_def_by_default, build_revoc_def_by_trust_anchor
 from indy_node.test.schema.test_send_get_schema import send_schema_seq_no
+from plenum.common.exceptions import RequestNackedException, RequestRejectedException
 from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check
 
 
 @pytest.fixture(scope='module')
 def tconf(tconf):
     OLD_ANYONE_CAN_WRITE = tconf.ANYONE_CAN_WRITE
-    tconf.ANYONE_CAN_WRITE = True
+    tconf.ANYONE_CAN_WRITE = False
 
     yield tconf
     tconf.ANYONE_CAN_WRITE = OLD_ANYONE_CAN_WRITE
 
 
-@pytest.fixture(scope=""module"")
-def client_send_revoc_reg_def(looper,
-                              txnPoolNodeSet,
-                              sdk_wallet_client,
-                              sdk_pool_handle,
-                              build_revoc_def_by_default,
-                              claim_def, tconf):
+def send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc,
+                       claim_def, wallet):
     # We need to have claim_def to send revocation txns
+    # must be signed by trust anchor since ANYONE_CAN_WRITE is false
 
-    claim_def_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, claim_def)
+    claim_def_req = sdk_sign_request_from_dict(looper, wallet, claim_def)
     sdk_send_and_check([json.dumps(claim_def_req)], looper, txnPoolNodeSet, sdk_pool_handle)
 
-    _, author_did = sdk_wallet_client
-    revoc_reg = build_revoc_def_by_default
+    _, author_did = wallet
+    revoc_reg = build_revoc
     revoc_reg['operation'][CRED_DEF_ID] = \
         make_state_path_for_claim_def(author_did,
                                       str(claim_def_req['operation'][CLAIM_DEF_SCHEMA_REF]),
                                       claim_def_req['operation'][CLAIM_DEF_SIGNATURE_TYPE],
                                       claim_def_req['operation'][CLAIM_DEF_TAG]
                                       ).decode()
-    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, revoc_reg['operation'])
+    revoc_req = sdk_sign_request_from_dict(looper, wallet, revoc_reg['operation'])
     _, revoc_reply = sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0]
     return revoc_req
 
 
-def test_client_can_send_revoc_reg_def(client_send_revoc_reg_def):
-    pass
+def test_client_cant_send_revoc_reg_def(looper,",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266333737,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266333737,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,It's better to call this test `test_allowed_roles_can_create_revoc_reg_entry`,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-18 08:30:58,266333852,"@@ -5,57 +5,105 @@
     CLAIM_DEF_SIGNATURE_TYPE, CLAIM_DEF_TAG
 from indy_common.state.domain import make_state_path_for_claim_def
 from indy_node.test.anon_creds.conftest import claim_def, build_revoc_reg_entry_for_given_revoc_reg_def, \
-    build_revoc_def_by_default
+    build_revoc_def_by_default, build_revoc_def_by_trust_anchor
 from indy_node.test.schema.test_send_get_schema import send_schema_seq_no
+from plenum.common.exceptions import RequestNackedException, RequestRejectedException
 from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check
 
 
 @pytest.fixture(scope='module')
 def tconf(tconf):
     OLD_ANYONE_CAN_WRITE = tconf.ANYONE_CAN_WRITE
-    tconf.ANYONE_CAN_WRITE = True
+    tconf.ANYONE_CAN_WRITE = False
 
     yield tconf
     tconf.ANYONE_CAN_WRITE = OLD_ANYONE_CAN_WRITE
 
 
-@pytest.fixture(scope=""module"")
-def client_send_revoc_reg_def(looper,
-                              txnPoolNodeSet,
-                              sdk_wallet_client,
-                              sdk_pool_handle,
-                              build_revoc_def_by_default,
-                              claim_def, tconf):
+def send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc,
+                       claim_def, wallet):
     # We need to have claim_def to send revocation txns
+    # must be signed by trust anchor since ANYONE_CAN_WRITE is false
 
-    claim_def_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, claim_def)
+    claim_def_req = sdk_sign_request_from_dict(looper, wallet, claim_def)
     sdk_send_and_check([json.dumps(claim_def_req)], looper, txnPoolNodeSet, sdk_pool_handle)
 
-    _, author_did = sdk_wallet_client
-    revoc_reg = build_revoc_def_by_default
+    _, author_did = wallet
+    revoc_reg = build_revoc
     revoc_reg['operation'][CRED_DEF_ID] = \
         make_state_path_for_claim_def(author_did,
                                       str(claim_def_req['operation'][CLAIM_DEF_SCHEMA_REF]),
                                       claim_def_req['operation'][CLAIM_DEF_SIGNATURE_TYPE],
                                       claim_def_req['operation'][CLAIM_DEF_TAG]
                                       ).decode()
-    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, revoc_reg['operation'])
+    revoc_req = sdk_sign_request_from_dict(looper, wallet, revoc_reg['operation'])
     _, revoc_reply = sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0]
     return revoc_req
 
 
-def test_client_can_send_revoc_reg_def(client_send_revoc_reg_def):
-    pass
+def test_client_cant_send_revoc_reg_def(looper,
+                                        txnPoolNodeSet,
+                                        sdk_wallet_client,
+                                        sdk_pool_handle,
+                                        build_revoc_def_by_default,
+                                        claim_def, tconf):
+    with pytest.raises(RequestRejectedException):
+        send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                           claim_def, sdk_wallet_client)
 
 
-def test_client_can_send_revoc_reg_entry(looper,
-                                         client_send_revoc_reg_def,
-                                         sdk_wallet_client,
-                                         txnPoolNodeSet,
-                                         sdk_pool_handle):
-    revoc_def_req = client_send_revoc_reg_def
-    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req)
-    rev_reg_entry[VALUE][REVOKED] = [1, 2, 3, 4, 5]
-    del rev_reg_entry[VALUE][PREV_ACCUM]
-    rev_entry_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, rev_reg_entry)
-    sdk_send_and_check([json.dumps(rev_entry_req)], looper, txnPoolNodeSet, sdk_pool_handle)
\ No newline at end of file
+def test_allowed_roles_can_send_revoc_reg_def(looper,
+                                              txnPoolNodeSet,
+                                              sdk_wallet_trustee,
+                                              sdk_wallet_trust_anchor,
+                                              sdk_wallet_steward,
+                                              sdk_pool_handle,
+                                              build_revoc_def_by_default,
+                                              claim_def, tconf):
+    # trust anchor
+    send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                       claim_def, sdk_wallet_trust_anchor)
+    # steward
+    send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                       claim_def, sdk_wallet_steward)
+    # trustee
+    send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                       claim_def, sdk_wallet_trustee)
+
+
+def test_allowed_roles_can_send_revoc_reg_entry(looper,",113,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266333852,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266333852,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,"Please also add the following tests:
1) `test_not_owner_cant_create_revoc_reg_entry`. In this test try to create RevocRegEntry by 
- a client 
- a trust anchor who is not the author of the corresponding RevocRegDef
- a steward who is not the author of the corresponding RevocRegDef
- a trustee who is not the author of the corresponding RevocRegDef

2) `test_owner_can_edit_revoc_reg_entry`
In this test create a RevocRegEntry, and edit it by the same author.

3) `test_not_owner_cant_edit_revoc_reg_entry`
In this test create a RevocRegEntry by a Trust Anchor
Try to edit it by 
- a client 
- another trust anchor who is not the author of this RevocRegEntry
- a steward who is not the author of this RevocRegEntry
- a trustee who is not the author of this RevocRegEntry",c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-18 08:33:04,266334597,"@@ -5,57 +5,105 @@
     CLAIM_DEF_SIGNATURE_TYPE, CLAIM_DEF_TAG
 from indy_common.state.domain import make_state_path_for_claim_def
 from indy_node.test.anon_creds.conftest import claim_def, build_revoc_reg_entry_for_given_revoc_reg_def, \
-    build_revoc_def_by_default
+    build_revoc_def_by_default, build_revoc_def_by_trust_anchor
 from indy_node.test.schema.test_send_get_schema import send_schema_seq_no
+from plenum.common.exceptions import RequestNackedException, RequestRejectedException
 from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check
 
 
 @pytest.fixture(scope='module')
 def tconf(tconf):
     OLD_ANYONE_CAN_WRITE = tconf.ANYONE_CAN_WRITE
-    tconf.ANYONE_CAN_WRITE = True
+    tconf.ANYONE_CAN_WRITE = False
 
     yield tconf
     tconf.ANYONE_CAN_WRITE = OLD_ANYONE_CAN_WRITE
 
 
-@pytest.fixture(scope=""module"")
-def client_send_revoc_reg_def(looper,
-                              txnPoolNodeSet,
-                              sdk_wallet_client,
-                              sdk_pool_handle,
-                              build_revoc_def_by_default,
-                              claim_def, tconf):
+def send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc,
+                       claim_def, wallet):
     # We need to have claim_def to send revocation txns
+    # must be signed by trust anchor since ANYONE_CAN_WRITE is false
 
-    claim_def_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, claim_def)
+    claim_def_req = sdk_sign_request_from_dict(looper, wallet, claim_def)
     sdk_send_and_check([json.dumps(claim_def_req)], looper, txnPoolNodeSet, sdk_pool_handle)
 
-    _, author_did = sdk_wallet_client
-    revoc_reg = build_revoc_def_by_default
+    _, author_did = wallet
+    revoc_reg = build_revoc
     revoc_reg['operation'][CRED_DEF_ID] = \
         make_state_path_for_claim_def(author_did,
                                       str(claim_def_req['operation'][CLAIM_DEF_SCHEMA_REF]),
                                       claim_def_req['operation'][CLAIM_DEF_SIGNATURE_TYPE],
                                       claim_def_req['operation'][CLAIM_DEF_TAG]
                                       ).decode()
-    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, revoc_reg['operation'])
+    revoc_req = sdk_sign_request_from_dict(looper, wallet, revoc_reg['operation'])
     _, revoc_reply = sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0]
     return revoc_req
 
 
-def test_client_can_send_revoc_reg_def(client_send_revoc_reg_def):
-    pass
+def test_client_cant_send_revoc_reg_def(looper,
+                                        txnPoolNodeSet,
+                                        sdk_wallet_client,
+                                        sdk_pool_handle,
+                                        build_revoc_def_by_default,
+                                        claim_def, tconf):
+    with pytest.raises(RequestRejectedException):
+        send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                           claim_def, sdk_wallet_client)
 
 
-def test_client_can_send_revoc_reg_entry(looper,
-                                         client_send_revoc_reg_def,
-                                         sdk_wallet_client,
-                                         txnPoolNodeSet,
-                                         sdk_pool_handle):
-    revoc_def_req = client_send_revoc_reg_def
-    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req)
-    rev_reg_entry[VALUE][REVOKED] = [1, 2, 3, 4, 5]
-    del rev_reg_entry[VALUE][PREV_ACCUM]
-    rev_entry_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, rev_reg_entry)
-    sdk_send_and_check([json.dumps(rev_entry_req)], looper, txnPoolNodeSet, sdk_pool_handle)
\ No newline at end of file
+def test_allowed_roles_can_send_revoc_reg_def(looper,
+                                              txnPoolNodeSet,
+                                              sdk_wallet_trustee,
+                                              sdk_wallet_trust_anchor,
+                                              sdk_wallet_steward,
+                                              sdk_pool_handle,
+                                              build_revoc_def_by_default,
+                                              claim_def, tconf):
+    # trust anchor
+    send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                       claim_def, sdk_wallet_trust_anchor)
+    # steward
+    send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                       claim_def, sdk_wallet_steward)
+    # trustee
+    send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                       claim_def, sdk_wallet_trustee)
+
+",112,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266334597,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266334597,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Please do not remove `AUTH_RULE` from import. ,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-18 08:37:30,266335995,"@@ -3,7 +3,7 @@
 from indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit
 from indy_common.authorize.auth_constraints import AuthConstraint, AuthConstraintOr, accepted_roles, IDENTITY_OWNER
 from indy_common.constants import TRUST_ANCHOR, POOL_CONFIG, VALIDATOR_INFO, POOL_UPGRADE, POOL_RESTART, NODE, \
-    CLAIM_DEF, SCHEMA, NYM, ROLE, NETWORK_MONITOR, AUTH_RULE
+    CLAIM_DEF, SCHEMA, NYM, ROLE, NETWORK_MONITOR, REVOC_REG_ENTRY, REVOC_REG_DEF",,2019-03-18 23:17:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266335995,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266335995,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,This needs to be `create_revoc_reg_entry`,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-19 07:07:23,266752903,"@@ -80,33 +94,17 @@ def test_allowed_roles_can_send_revoc_reg_entry(looper,
                                                 build_revoc_def_by_default,
                                                 claim_def, tconf):
     # trust anchor
-    revoc_def_req_trust_anchor = send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
-                                                    claim_def, sdk_wallet_trust_anchor)
-
-    rev_reg_entry_trust_anchor = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req_trust_anchor)
-    rev_reg_entry_trust_anchor[VALUE][REVOKED] = [1, 2, 3, 4, 5]
-    del rev_reg_entry_trust_anchor[VALUE][PREV_ACCUM]
-    rev_entry_req_trust_anchor = sdk_sign_request_from_dict(looper, sdk_wallet_trust_anchor, rev_reg_entry_trust_anchor)
-    sdk_send_and_check([json.dumps(rev_entry_req_trust_anchor)], looper, txnPoolNodeSet, sdk_pool_handle)
+    create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                           build_revoc_def_by_default, claim_def, sdk_wallet_trust_anchor)
 
     # steward
-    revoc_def_req_steward = send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle,
-                                               build_revoc_def_by_default, claim_def, sdk_wallet_steward)
-    rev_reg_entry_steward = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req_steward)
-    rev_reg_entry_steward[VALUE][REVOKED] = [1, 2, 3, 4, 5]
-    del rev_reg_entry_steward[VALUE][PREV_ACCUM]
-    rev_entry_req_steward = sdk_sign_request_from_dict(looper, sdk_wallet_steward, rev_reg_entry_steward)
-    sdk_send_and_check([json.dumps(rev_entry_req_steward)], looper, txnPoolNodeSet, sdk_pool_handle)
 
-    # trustee
-    revoc_def_req_trustee = send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle,
-                                               build_revoc_def_by_default, claim_def, sdk_wallet_trustee)
+    create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                           build_revoc_def_by_default, claim_def, sdk_wallet_steward)
 
-    rev_reg_entry_trustee = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req_trustee)
-    rev_reg_entry_trustee[VALUE][REVOKED] = [1, 2, 3, 4, 5]
-    del rev_reg_entry_trustee[VALUE][PREV_ACCUM]
-    rev_entry_req_trustee = sdk_sign_request_from_dict(looper, sdk_wallet_trustee, rev_reg_entry_trustee)
-    sdk_send_and_check([json.dumps(rev_entry_req_trustee)], looper, txnPoolNodeSet, sdk_pool_handle)
+    # trustee
+    create_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle,",131,2019-03-19 07:20:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266752903,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266752903,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Please process this comment to have consistent test names.,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-19 07:07:42,266752963,"@@ -5,57 +5,105 @@
     CLAIM_DEF_SIGNATURE_TYPE, CLAIM_DEF_TAG
 from indy_common.state.domain import make_state_path_for_claim_def
 from indy_node.test.anon_creds.conftest import claim_def, build_revoc_reg_entry_for_given_revoc_reg_def, \
-    build_revoc_def_by_default
+    build_revoc_def_by_default, build_revoc_def_by_trust_anchor
 from indy_node.test.schema.test_send_get_schema import send_schema_seq_no
+from plenum.common.exceptions import RequestNackedException, RequestRejectedException
 from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check
 
 
 @pytest.fixture(scope='module')
 def tconf(tconf):
     OLD_ANYONE_CAN_WRITE = tconf.ANYONE_CAN_WRITE
-    tconf.ANYONE_CAN_WRITE = True
+    tconf.ANYONE_CAN_WRITE = False
 
     yield tconf
     tconf.ANYONE_CAN_WRITE = OLD_ANYONE_CAN_WRITE
 
 
-@pytest.fixture(scope=""module"")
-def client_send_revoc_reg_def(looper,
-                              txnPoolNodeSet,
-                              sdk_wallet_client,
-                              sdk_pool_handle,
-                              build_revoc_def_by_default,
-                              claim_def, tconf):
+def send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc,
+                       claim_def, wallet):
     # We need to have claim_def to send revocation txns
+    # must be signed by trust anchor since ANYONE_CAN_WRITE is false
 
-    claim_def_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, claim_def)
+    claim_def_req = sdk_sign_request_from_dict(looper, wallet, claim_def)
     sdk_send_and_check([json.dumps(claim_def_req)], looper, txnPoolNodeSet, sdk_pool_handle)
 
-    _, author_did = sdk_wallet_client
-    revoc_reg = build_revoc_def_by_default
+    _, author_did = wallet
+    revoc_reg = build_revoc
     revoc_reg['operation'][CRED_DEF_ID] = \
         make_state_path_for_claim_def(author_did,
                                       str(claim_def_req['operation'][CLAIM_DEF_SCHEMA_REF]),
                                       claim_def_req['operation'][CLAIM_DEF_SIGNATURE_TYPE],
                                       claim_def_req['operation'][CLAIM_DEF_TAG]
                                       ).decode()
-    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, revoc_reg['operation'])
+    revoc_req = sdk_sign_request_from_dict(looper, wallet, revoc_reg['operation'])
     _, revoc_reply = sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0]
     return revoc_req
 
 
-def test_client_can_send_revoc_reg_def(client_send_revoc_reg_def):
-    pass
+def test_client_cant_send_revoc_reg_def(looper,
+                                        txnPoolNodeSet,
+                                        sdk_wallet_client,
+                                        sdk_pool_handle,
+                                        build_revoc_def_by_default,
+                                        claim_def, tconf):
+    with pytest.raises(RequestRejectedException):
+        send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                           claim_def, sdk_wallet_client)
 
 
-def test_client_can_send_revoc_reg_entry(looper,
-                                         client_send_revoc_reg_def,
-                                         sdk_wallet_client,
-                                         txnPoolNodeSet,
-                                         sdk_pool_handle):
-    revoc_def_req = client_send_revoc_reg_def
-    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req)
-    rev_reg_entry[VALUE][REVOKED] = [1, 2, 3, 4, 5]
-    del rev_reg_entry[VALUE][PREV_ACCUM]
-    rev_entry_req = sdk_sign_request_from_dict(looper, sdk_wallet_client, rev_reg_entry)
-    sdk_send_and_check([json.dumps(rev_entry_req)], looper, txnPoolNodeSet, sdk_pool_handle)
\ No newline at end of file
+def test_allowed_roles_can_send_revoc_reg_def(looper,
+                                              txnPoolNodeSet,
+                                              sdk_wallet_trustee,
+                                              sdk_wallet_trust_anchor,
+                                              sdk_wallet_steward,
+                                              sdk_pool_handle,
+                                              build_revoc_def_by_default,
+                                              claim_def, tconf):
+    # trust anchor
+    send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                       claim_def, sdk_wallet_trust_anchor)
+    # steward
+    send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                       claim_def, sdk_wallet_steward)
+    # trustee
+    send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle, build_revoc_def_by_default,
+                       claim_def, sdk_wallet_trustee)
+
+
+def test_allowed_roles_can_send_revoc_reg_entry(looper,",113,2019-03-19 07:20:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266752963,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266752963,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,This needs to # trustee,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-19 07:09:30,266753307,"@@ -148,17 +146,134 @@ def test_trust_anchor_not_owner_cant_create_revoc_reg_entry(looper,
 def test_trustee_not_owner_cant_create_revoc_reg_entry(looper,
                                                        txnPoolNodeSet,
                                                        sdk_wallet_trustee,
-                                                       sdk_wallet_trust_anchor,
+                                                       sdk_wallet_steward,
                                                        sdk_pool_handle,
-                                                       build_revoc_def_by_trust_anchor,
+                                                       build_revoc_def_by_default,
                                                        claim_def, tconf):
-    revoc_def_req_trust_achor = send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle,
-                                                   build_revoc_def_by_trust_anchor,
-                                                   claim_def, sdk_wallet_trust_anchor)
+    revoc_def_req_steward = create_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                 build_revoc_def_by_default,
+                                                 claim_def, sdk_wallet_steward)
 
-    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req_trust_achor)
+    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req_steward)
     rev_reg_entry[VALUE][REVOKED] = [1, 2, 3, 4, 5]
     del rev_reg_entry[VALUE][PREV_ACCUM]
     rev_entry_req_trustee = sdk_sign_request_from_dict(looper, sdk_wallet_trustee, rev_reg_entry)
     with pytest.raises(RequestRejectedException):
         sdk_send_and_check([json.dumps(rev_entry_req_trustee)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+
+def test_allowed_roles_can_edit_revoc_reg_entry(looper,
+                                                txnPoolNodeSet,
+                                                sdk_wallet_trust_anchor,
+                                                sdk_wallet_steward,
+                                                sdk_wallet_trustee,
+                                                sdk_pool_handle,
+                                                build_revoc_def_by_default,
+                                                build_revoc_def_by_trust_anchor,
+                                                build_revoc_def_by_steward,
+                                                claim_def, tconf):
+    # trust anchor
+    revoc_entry_req_trust_anchor = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                          build_revoc_def_by_trust_anchor,
+                                                          claim_def, sdk_wallet_trust_anchor)
+
+    revoc_entry_req_trust_anchor['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_trust_anchor['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_trust_anchor['operation'][VALUE][
+        ACCUM]
+    revoc_entry_req_trust_anchor['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_trust_anchor = sdk_sign_request_from_dict(looper, sdk_wallet_trust_anchor,
+                                                              revoc_entry_req_trust_anchor['operation'])
+
+    sdk_send_and_check([json.dumps(revoc_entry_req_trust_anchor)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+    # steward
+    revoc_entry_req_trustee = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                     build_revoc_def_by_steward,
+                                                     claim_def, sdk_wallet_steward)
+
+    revoc_entry_req_trustee['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_trustee['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_trustee['operation'][VALUE][ACCUM]
+    revoc_entry_req_trustee['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_trustee = sdk_sign_request_from_dict(looper, sdk_wallet_steward,
+                                                         revoc_entry_req_trustee['operation'])
+
+    sdk_send_and_check([json.dumps(revoc_entry_req_trustee)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+    # steward",227,2019-03-19 07:20:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266753307,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266753307,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,The correct variable name is `revoc_entry_req_trustee`,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-19 07:20:15,266755480,"@@ -148,17 +146,134 @@ def test_trust_anchor_not_owner_cant_create_revoc_reg_entry(looper,
 def test_trustee_not_owner_cant_create_revoc_reg_entry(looper,
                                                        txnPoolNodeSet,
                                                        sdk_wallet_trustee,
-                                                       sdk_wallet_trust_anchor,
+                                                       sdk_wallet_steward,
                                                        sdk_pool_handle,
-                                                       build_revoc_def_by_trust_anchor,
+                                                       build_revoc_def_by_default,
                                                        claim_def, tconf):
-    revoc_def_req_trust_achor = send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle,
-                                                   build_revoc_def_by_trust_anchor,
-                                                   claim_def, sdk_wallet_trust_anchor)
+    revoc_def_req_steward = create_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                 build_revoc_def_by_default,
+                                                 claim_def, sdk_wallet_steward)
 
-    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req_trust_achor)
+    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req_steward)
     rev_reg_entry[VALUE][REVOKED] = [1, 2, 3, 4, 5]
     del rev_reg_entry[VALUE][PREV_ACCUM]
     rev_entry_req_trustee = sdk_sign_request_from_dict(looper, sdk_wallet_trustee, rev_reg_entry)
     with pytest.raises(RequestRejectedException):
         sdk_send_and_check([json.dumps(rev_entry_req_trustee)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+
+def test_allowed_roles_can_edit_revoc_reg_entry(looper,
+                                                txnPoolNodeSet,
+                                                sdk_wallet_trust_anchor,
+                                                sdk_wallet_steward,
+                                                sdk_wallet_trustee,
+                                                sdk_pool_handle,
+                                                build_revoc_def_by_default,
+                                                build_revoc_def_by_trust_anchor,
+                                                build_revoc_def_by_steward,
+                                                claim_def, tconf):
+    # trust anchor
+    revoc_entry_req_trust_anchor = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                          build_revoc_def_by_trust_anchor,
+                                                          claim_def, sdk_wallet_trust_anchor)
+
+    revoc_entry_req_trust_anchor['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_trust_anchor['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_trust_anchor['operation'][VALUE][
+        ACCUM]
+    revoc_entry_req_trust_anchor['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_trust_anchor = sdk_sign_request_from_dict(looper, sdk_wallet_trust_anchor,
+                                                              revoc_entry_req_trust_anchor['operation'])
+
+    sdk_send_and_check([json.dumps(revoc_entry_req_trust_anchor)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+    # steward
+    revoc_entry_req_trustee = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                     build_revoc_def_by_steward,
+                                                     claim_def, sdk_wallet_steward)
+
+    revoc_entry_req_trustee['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_trustee['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_trustee['operation'][VALUE][ACCUM]
+    revoc_entry_req_trustee['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_trustee = sdk_sign_request_from_dict(looper, sdk_wallet_steward,
+                                                         revoc_entry_req_trustee['operation'])
+
+    sdk_send_and_check([json.dumps(revoc_entry_req_trustee)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+    # steward
+    revoc_entry_req_steward = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                     build_revoc_def_by_default,
+                                                     claim_def, sdk_wallet_trustee)
+
+    revoc_entry_req_steward['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_steward['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_steward['operation'][VALUE][ACCUM]
+
+    revoc_entry_req_steward['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_steward = sdk_sign_request_from_dict(looper, sdk_wallet_trustee,
+                                                         revoc_entry_req_steward['operation'])
+
+    sdk_send_and_check([json.dumps(revoc_entry_req_steward)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+
+def test_not_owner_trustee_cant_edit_revoc_reg_entry(looper,
+                                                     txnPoolNodeSet,
+                                                     sdk_wallet_trustee,
+                                                     sdk_wallet_trust_anchor,
+                                                     sdk_pool_handle,
+                                                     build_revoc_def_by_demand,
+                                                     claim_def, tconf):
+
+    revoc_entry_req_steward = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,",250,2019-03-19 07:20:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266755480,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266755480,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,The correct variable name is `revoc_entry_req_trust_anchor`,c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-19 07:20:48,266755633,"@@ -148,17 +146,134 @@ def test_trust_anchor_not_owner_cant_create_revoc_reg_entry(looper,
 def test_trustee_not_owner_cant_create_revoc_reg_entry(looper,
                                                        txnPoolNodeSet,
                                                        sdk_wallet_trustee,
-                                                       sdk_wallet_trust_anchor,
+                                                       sdk_wallet_steward,
                                                        sdk_pool_handle,
-                                                       build_revoc_def_by_trust_anchor,
+                                                       build_revoc_def_by_default,
                                                        claim_def, tconf):
-    revoc_def_req_trust_achor = send_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle,
-                                                   build_revoc_def_by_trust_anchor,
-                                                   claim_def, sdk_wallet_trust_anchor)
+    revoc_def_req_steward = create_revoc_reg_def(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                 build_revoc_def_by_default,
+                                                 claim_def, sdk_wallet_steward)
 
-    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req_trust_achor)
+    rev_reg_entry = build_revoc_reg_entry_for_given_revoc_reg_def(revoc_def_req_steward)
     rev_reg_entry[VALUE][REVOKED] = [1, 2, 3, 4, 5]
     del rev_reg_entry[VALUE][PREV_ACCUM]
     rev_entry_req_trustee = sdk_sign_request_from_dict(looper, sdk_wallet_trustee, rev_reg_entry)
     with pytest.raises(RequestRejectedException):
         sdk_send_and_check([json.dumps(rev_entry_req_trustee)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+
+def test_allowed_roles_can_edit_revoc_reg_entry(looper,
+                                                txnPoolNodeSet,
+                                                sdk_wallet_trust_anchor,
+                                                sdk_wallet_steward,
+                                                sdk_wallet_trustee,
+                                                sdk_pool_handle,
+                                                build_revoc_def_by_default,
+                                                build_revoc_def_by_trust_anchor,
+                                                build_revoc_def_by_steward,
+                                                claim_def, tconf):
+    # trust anchor
+    revoc_entry_req_trust_anchor = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                          build_revoc_def_by_trust_anchor,
+                                                          claim_def, sdk_wallet_trust_anchor)
+
+    revoc_entry_req_trust_anchor['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_trust_anchor['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_trust_anchor['operation'][VALUE][
+        ACCUM]
+    revoc_entry_req_trust_anchor['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_trust_anchor = sdk_sign_request_from_dict(looper, sdk_wallet_trust_anchor,
+                                                              revoc_entry_req_trust_anchor['operation'])
+
+    sdk_send_and_check([json.dumps(revoc_entry_req_trust_anchor)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+    # steward
+    revoc_entry_req_trustee = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                     build_revoc_def_by_steward,
+                                                     claim_def, sdk_wallet_steward)
+
+    revoc_entry_req_trustee['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_trustee['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_trustee['operation'][VALUE][ACCUM]
+    revoc_entry_req_trustee['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_trustee = sdk_sign_request_from_dict(looper, sdk_wallet_steward,
+                                                         revoc_entry_req_trustee['operation'])
+
+    sdk_send_and_check([json.dumps(revoc_entry_req_trustee)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+    # steward
+    revoc_entry_req_steward = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                     build_revoc_def_by_default,
+                                                     claim_def, sdk_wallet_trustee)
+
+    revoc_entry_req_steward['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_steward['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_steward['operation'][VALUE][ACCUM]
+
+    revoc_entry_req_steward['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_steward = sdk_sign_request_from_dict(looper, sdk_wallet_trustee,
+                                                         revoc_entry_req_steward['operation'])
+
+    sdk_send_and_check([json.dumps(revoc_entry_req_steward)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+
+def test_not_owner_trustee_cant_edit_revoc_reg_entry(looper,
+                                                     txnPoolNodeSet,
+                                                     sdk_wallet_trustee,
+                                                     sdk_wallet_trust_anchor,
+                                                     sdk_pool_handle,
+                                                     build_revoc_def_by_demand,
+                                                     claim_def, tconf):
+
+    revoc_entry_req_steward = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                     build_revoc_def_by_demand,
+                                                     claim_def, sdk_wallet_trust_anchor)
+
+    revoc_entry_req_steward['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_steward['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_steward['operation'][VALUE][ACCUM]
+
+    revoc_entry_req_steward['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_steward = sdk_sign_request_from_dict(looper, sdk_wallet_trustee,
+                                                         revoc_entry_req_steward['operation'])
+    with pytest.raises(RequestRejectedException):
+        sdk_send_and_check([json.dumps(revoc_entry_req_steward)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+
+def test_not_owner_steward_cant_edit_revoc_reg_entry(looper,
+                                                     txnPoolNodeSet,
+                                                     sdk_wallet_steward,
+                                                     sdk_wallet_trust_anchor,
+                                                     sdk_pool_handle,
+                                                     build_revoc_def_by_steward,
+                                                     claim_def, tconf):
+    revoc_entry_req_steward = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,
+                                                     build_revoc_def_by_steward,
+                                                     claim_def, sdk_wallet_trust_anchor)
+
+    revoc_entry_req_steward['operation'][VALUE][REVOKED] = [6, 7, 8]
+    revoc_entry_req_steward['operation'][VALUE][PREV_ACCUM] = revoc_entry_req_steward['operation'][VALUE][ACCUM]
+
+    revoc_entry_req_steward['operation'][VALUE][ACCUM] = randomString(10)
+    revoc_entry_req_steward = sdk_sign_request_from_dict(looper, sdk_wallet_steward,
+                                                         revoc_entry_req_steward['operation'])
+    with pytest.raises(RequestRejectedException):
+        sdk_send_and_check([json.dumps(revoc_entry_req_steward)], looper, txnPoolNodeSet, sdk_pool_handle)
+
+
+def test_not_owner_trust_anchor_cant_edit_revoc_reg_entry(looper,
+                                                          txnPoolNodeSet,
+                                                          sdk_wallet_steward,
+                                                          sdk_wallet_trust_anchor,
+                                                          sdk_pool_handle,
+                                                          build_revoc_def_by_default,
+                                                          claim_def, tconf):
+
+    revoc_build = build_revoc_def_random(looper, sdk_wallet_steward)
+    revoc_entry_req_steward = create_revoc_reg_entry(looper, txnPoolNodeSet, sdk_pool_handle,",294,2019-03-19 07:20:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266755633,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266755633,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1192,https://github.com/hyperledger/indy-node/pull/1192,Please add tests for `REVOC_REG_ENTRY` (add and edit operations),c7bcee44f21d0cc0445cdb079b557053bad5f90d,2019-03-19 07:26:04,266756885,"@@ -0,0 +1,21 @@
+from indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit
+from indy_common.constants import REVOC_REG_DEF
+
+",4,2019-03-19 07:26:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/266756885,https://github.com/hyperledger/indy-node/pull/1192#discussion_r266756885,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1191,https://github.com/hyperledger/indy-node/pull/1191,`ssh` should be added to replacement part of sed expression instead of the regex pattern,af64349b05ca88b3c6f7ef55eb2a3c6d0591b442,2019-03-05 16:05:07,262563713,"@@ -179,7 +179,7 @@ def systemTests = { component, releaseVersion ->
                     sh """"""
                         sed -i 's/repo.sovrin.org\\/deb xenial .*\\+""/repo.sovrin.org\\/deb xenial $component""/g' core.ubuntu.dockerfile
                         sed -i 's/sdk\\/deb xenial .\\+""/sdk\\/deb xenial stable""/g' core.ubuntu.dockerfile
-                        sed -i 's/\\(apt-get install -y indy-node\\) libindy/\\1=$releaseVersion libindy=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile
+                        sed -i 's/\\(apt-get install -y indy-node\\) ssh libindy/\\1=$releaseVersion libindy=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile",,2019-03-12 14:02:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262563713,https://github.com/hyperledger/indy-node/pull/1191#discussion_r262563713,andkononykhin
https://github.com/hyperledger/indy-node/pull/1191,https://github.com/hyperledger/indy-node/pull/1191,i think it will be enough and cheaper to do chown only for particular dirs in /home/indy (`system` and `.ssh`),af64349b05ca88b3c6f7ef55eb2a3c6d0591b442,2019-03-05 16:06:49,262564486,"@@ -202,7 +202,13 @@ def systemTests = { component, releaseVersion ->
                             docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
                             docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
                             docker cp ./pool_transactions_genesis indyclient:/home/indy/docker_genesis
-                            docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
+                            docker exec -t -u 0 indyclient mkdir -p /home/indy/.ssh/
+                            docker cp ./system_tests/system/config indyclient:/home/indy/.ssh/config
+                            docker cp ./system_tests/system/test_key.pub indyclient:/home/indy/.ssh/test_key.pub
+                            docker cp ./system_tests/system/test_key indyclient:/home/indy/.ssh/test_key
+                            docker exec -t -u 0 indyclient chown -R indy:indy /home/indy",,2019-03-12 14:02:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262564486,https://github.com/hyperledger/indy-node/pull/1191#discussion_r262564486,andkononykhin
https://github.com/hyperledger/indy-node/pull/1191,https://github.com/hyperledger/indy-node/pull/1191,please use `nodesNum` instead of the hard-coded number,af64349b05ca88b3c6f7ef55eb2a3c6d0591b442,2019-03-05 16:08:08,262565034,"@@ -202,7 +202,13 @@ def systemTests = { component, releaseVersion ->
                             docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
                             docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
                             docker cp ./pool_transactions_genesis indyclient:/home/indy/docker_genesis
-                            docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
+                            docker exec -t -u 0 indyclient mkdir -p /home/indy/.ssh/
+                            docker cp ./system_tests/system/config indyclient:/home/indy/.ssh/config
+                            docker cp ./system_tests/system/test_key.pub indyclient:/home/indy/.ssh/test_key.pub
+                            docker cp ./system_tests/system/test_key indyclient:/home/indy/.ssh/test_key
+                            docker exec -t -u 0 indyclient chown -R indy:indy /home/indy
+                            for x in `seq 1 7`; do docker cp ./system_tests/system/test_key.pub node$x:/root/.ssh/authorized_keys; done",,2019-03-12 14:02:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262565034,https://github.com/hyperledger/indy-node/pull/1191#discussion_r262565034,andkononykhin
https://github.com/hyperledger/indy-node/pull/1191,https://github.com/hyperledger/indy-node/pull/1191,the same here,af64349b05ca88b3c6f7ef55eb2a3c6d0591b442,2019-03-05 16:08:30,262565212,"@@ -202,7 +202,13 @@ def systemTests = { component, releaseVersion ->
                             docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
                             docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
                             docker cp ./pool_transactions_genesis indyclient:/home/indy/docker_genesis
-                            docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
+                            docker exec -t -u 0 indyclient mkdir -p /home/indy/.ssh/
+                            docker cp ./system_tests/system/config indyclient:/home/indy/.ssh/config
+                            docker cp ./system_tests/system/test_key.pub indyclient:/home/indy/.ssh/test_key.pub
+                            docker cp ./system_tests/system/test_key indyclient:/home/indy/.ssh/test_key
+                            docker exec -t -u 0 indyclient chown -R indy:indy /home/indy
+                            for x in `seq 1 7`; do docker cp ./system_tests/system/test_key.pub node$x:/root/.ssh/authorized_keys; done
+                            for x in `seq 1 7`; do docker exec -t -u 0 node$x sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config; done",,2019-03-12 14:02:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262565212,https://github.com/hyperledger/indy-node/pull/1191#discussion_r262565212,andkononykhin
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,A command,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:41:33,262808391,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. ",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262808391,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262808391,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,as a key-value dictionary,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:41:59,262808474,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262808474,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262808474,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,A key is an authenticated action,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:42:54,262808649,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262808649,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262808649,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,Dot at the end.,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:43:03,262808675,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262808675,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262808675,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,A value,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:43:40,262808781,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262808781,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262808781,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,"Please add the following before `There are two types....`:
`The actions (keys) are static and can be found in [auth_rules.md](auth_rules.md). So, it's not possible to register new actions by this command. But it's possible to override authentication constraints (values) for a a given action.
`",12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:45:50,262809193,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262809193,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262809193,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,Please add this into the table of content,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:46:31,262809298,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE",12,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262809298,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262809298,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,Dot at the end.,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:47:16,262809426,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262809426,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262809426,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,"It's better to say
```
means that changing a value of a NODE transaction's `service` field from `[VALIDATOR]` to `[]` (demotion of a node) can only be done by one TRUSTEE or one STEWARD, and this Trustee or Steward needs to be the owner (the original creator) of this transaction.
```",12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:52:41,262810464,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262810464,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262810464,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,Please add a title **Action Format**,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:53:53,262810679,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):",39,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262810679,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262810679,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,Please replace to `Action type: add a new entity or edit an existing one.`,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:54:53,262810864,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262810864,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262810864,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,change rights for,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:55:47,262811039,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262811039,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262811039,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,"Do we really use string representation of transactions, or enum numbers as strings (like ""0"", ""1"", ...)?",12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:57:07,262811308,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262811308,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262811308,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,Change the rights for editing (adding) a value of the given transaction field. `*` can be used as `any field`.,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:58:42,262811616,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262811616,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262811616,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,"Old value of a field, which can be changed to a new_value. Makes sense for EDIT actions only.
",12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 06:59:04,262811693,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262811693,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262811693,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,It's needed to determine a type ...,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 07:02:48,262812534,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. Needed for determine the type of constraint for correct deserialization.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262812534,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262812534,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,"Type of a constraint. As of not only `ROLE` is supported, but plugins can register new ones.",12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 07:09:29,262814036,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. Needed for determine the type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of constraint, which for ConstraintEntity is always of type ""ROLE"". Needed for determine the type of constraint for correct deserialization.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262814036,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262814036,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,It's needed to determine a type ...,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 07:09:41,262814079,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. Needed for determine the type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of constraint, which for ConstraintEntity is always of type ""ROLE"". Needed for determine the type of constraint for correct deserialization.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262814079,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262814079,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,... to do the action ...,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 07:10:36,262814261,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. Needed for determine the type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of constraint, which for ConstraintEntity is always of type ""ROLE"". Needed for determine the type of constraint for correct deserialization.
+        
+- `role` (enum number as string; optional):
+
+    Role of a user that the NYM record is being created for. One of the following values
+
+    - None (common USER)
+    - 0 (TRUSTEE)
+    - 2 (STEWARD)
+    - 101 (TRUST_ANCHOR)
+    
+- `sig_count` (int):
+
+    The number of signatures that is needed to do some action described in the transaction fields.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262814261,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262814261,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,".. if the user....
",12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 07:11:18,262814406,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. Needed for determine the type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of constraint, which for ConstraintEntity is always of type ""ROLE"". Needed for determine the type of constraint for correct deserialization.
+        
+- `role` (enum number as string; optional):
+
+    Role of a user that the NYM record is being created for. One of the following values
+
+    - None (common USER)
+    - 0 (TRUSTEE)
+    - 2 (STEWARD)
+    - 101 (TRUST_ANCHOR)
+    
+- `sig_count` (int):
+
+    The number of signatures that is needed to do some action described in the transaction fields.
+    
+- `need_to_be_owner` (boolean):
+
+    Flag to check is user must be owner of some transaction (Example: A steward must be the owner of the node to make changes to it).",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262814406,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262814406,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,for additional parameters of the constraint. Can be used by plugins to add additional restrictions.,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 07:12:50,262814815,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. Needed for determine the type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of constraint, which for ConstraintEntity is always of type ""ROLE"". Needed for determine the type of constraint for correct deserialization.
+        
+- `role` (enum number as string; optional):
+
+    Role of a user that the NYM record is being created for. One of the following values
+
+    - None (common USER)
+    - 0 (TRUSTEE)
+    - 2 (STEWARD)
+    - 101 (TRUST_ANCHOR)
+    
+- `sig_count` (int):
+
+    The number of signatures that is needed to do some action described in the transaction fields.
+    
+- `need_to_be_owner` (boolean):
+
+    Flag to check is user must be owner of some transaction (Example: A steward must be the owner of the node to make changes to it).
+    
+- `metadata` (dict; optional):
+
+    Dictionary to additional parameters of constraint.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262814815,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262814815,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,of a transaction,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 07:13:33,262815037,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. Needed for determine the type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of constraint, which for ConstraintEntity is always of type ""ROLE"". Needed for determine the type of constraint for correct deserialization.
+        
+- `role` (enum number as string; optional):
+
+    Role of a user that the NYM record is being created for. One of the following values
+
+    - None (common USER)
+    - 0 (TRUSTEE)
+    - 2 (STEWARD)
+    - 101 (TRUST_ANCHOR)
+    
+- `sig_count` (int):
+
+    The number of signatures that is needed to do some action described in the transaction fields.
+    
+- `need_to_be_owner` (boolean):
+
+    Flag to check is user must be owner of some transaction (Example: A steward must be the owner of the node to make changes to it).
+    
+- `metadata` (dict; optional):
+
+    Dictionary to additional parameters of constraint.
+
+```
+{
+    'sig_count': 1, 
+    'need_to_be_owner': False, 
+    'constraint_id': 'ROLE', 
+    'metadata': {}, 
+    'role': '0'
+}
+```
+
+*Request Example*:
+```
+{
+    'operation': {
+           'type':'120',
+           'constraint':{  
+                      'constraint_id': 'OR'
+                      'auth_constraints': [{'constraint_id': 'ROLE', 
+                                            'role': '0',
+                                            'sig_count': 1, 
+                                            'need_to_be_owner': False, 
+                                            'metadata': {}}, 
+                                           
+                                           {'constraint_id': 'ROLE', 
+                                            'role': '2',
+                                            'sig_count': 1, 
+                                            'need_to_be_owner': True, 
+                                            'metadata': {}}
+                                           ], 
+           }, 
+           'field' :'services',
+           'auth_type': '0', 
+           'auth_action': 'EDIT'
+           'old_value': [VALIDATOR],
+           'new_value': [],
+    },
+    
+    'identifier': '21BPzYYrFzbuECcBV3M1FH',
+    'reqId': 1514304094738044,
+    'protocolVersion': 1,
+    'signature': '3YVzDtSxxnowVwAXZmxCG2fz1A38j1qLrwKmGEG653GZw7KJRBX57Stc1oxQZqqu9mCqFLa7aBzt4MKXk4MeunVj',
+}
+```
+
+*Reply Example*:
+```
+{     'op':'REPLY',
+      'result':{  
+         'txnMetadata':{  
+            'seqNo':1,
+            'txnTime':1551776783
+         },
+         'reqSignature':{  
+            'values':[  
+               {  
+                  'value':'4j99V2BNRX1dn2QhnR8L9C3W9XQt1W3ScD1pyYaqD1NUnDVhbFGS3cw8dHRe5uVk8W7DoFtHb81ekMs9t9e76Fg',
+                  'from':'M9BJDuS24bqbJNvBRsoGg3'
+               }
+            ],
+            'type':'ED25519'
+         },
+         'txn':{  
+            'data':{  
+               'constraint':{  
+                          'constraint_id': 'OR'
+                          'auth_constraints': [{'constraint_id': 'ROLE', 
+                                                'role': '0',
+                                                'sig_count': 1, 
+                                                'need_to_be_owner': False, 
+                                                'metadata': {}}, 
+                                               
+                                               {'constraint_id': 'ROLE', 
+                                                'role': '2',
+                                                'sig_count': 1, 
+                                                'need_to_be_owner': True, 
+                                                'metadata': {}}
+                                               ], 
+               }, 
+               'field' :'services',
+               'auth_type': '0', 
+               'auth_action': 'EDIT'
+               'old_value': [VALIDATOR],
+               'new_value': [],
+               }
+            },
+            'protocolVersion':2,
+            'metadata':{  
+               'from':'M9BJDuS24bqbJNvBRsoGg3',
+               'digest':'ea13f0a310c7f4494d2828bccbc8ff0bd8b77d0c0bfb1ed9a84104bf55ad0436',
+               'reqId':711182024
+            },
+            'type':'120'
+         },
+         'ver':'1',
+         'rootHash':'GJNfknLWDAb8R93cgAX3Bw6CYDo23HBhiwZnzb4fHtyi',
+         'auditPath':[  
+
+         ]
+      }
+   }
+```
+
+If format of transaction is incorrect, the client will received NACK message for request. ",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262815037,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262815037,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,the client will receive .... for the request.,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 07:13:51,262815125,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. Needed for determine the type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of constraint, which for ConstraintEntity is always of type ""ROLE"". Needed for determine the type of constraint for correct deserialization.
+        
+- `role` (enum number as string; optional):
+
+    Role of a user that the NYM record is being created for. One of the following values
+
+    - None (common USER)
+    - 0 (TRUSTEE)
+    - 2 (STEWARD)
+    - 101 (TRUST_ANCHOR)
+    
+- `sig_count` (int):
+
+    The number of signatures that is needed to do some action described in the transaction fields.
+    
+- `need_to_be_owner` (boolean):
+
+    Flag to check is user must be owner of some transaction (Example: A steward must be the owner of the node to make changes to it).
+    
+- `metadata` (dict; optional):
+
+    Dictionary to additional parameters of constraint.
+
+```
+{
+    'sig_count': 1, 
+    'need_to_be_owner': False, 
+    'constraint_id': 'ROLE', 
+    'metadata': {}, 
+    'role': '0'
+}
+```
+
+*Request Example*:
+```
+{
+    'operation': {
+           'type':'120',
+           'constraint':{  
+                      'constraint_id': 'OR'
+                      'auth_constraints': [{'constraint_id': 'ROLE', 
+                                            'role': '0',
+                                            'sig_count': 1, 
+                                            'need_to_be_owner': False, 
+                                            'metadata': {}}, 
+                                           
+                                           {'constraint_id': 'ROLE', 
+                                            'role': '2',
+                                            'sig_count': 1, 
+                                            'need_to_be_owner': True, 
+                                            'metadata': {}}
+                                           ], 
+           }, 
+           'field' :'services',
+           'auth_type': '0', 
+           'auth_action': 'EDIT'
+           'old_value': [VALIDATOR],
+           'new_value': [],
+    },
+    
+    'identifier': '21BPzYYrFzbuECcBV3M1FH',
+    'reqId': 1514304094738044,
+    'protocolVersion': 1,
+    'signature': '3YVzDtSxxnowVwAXZmxCG2fz1A38j1qLrwKmGEG653GZw7KJRBX57Stc1oxQZqqu9mCqFLa7aBzt4MKXk4MeunVj',
+}
+```
+
+*Reply Example*:
+```
+{     'op':'REPLY',
+      'result':{  
+         'txnMetadata':{  
+            'seqNo':1,
+            'txnTime':1551776783
+         },
+         'reqSignature':{  
+            'values':[  
+               {  
+                  'value':'4j99V2BNRX1dn2QhnR8L9C3W9XQt1W3ScD1pyYaqD1NUnDVhbFGS3cw8dHRe5uVk8W7DoFtHb81ekMs9t9e76Fg',
+                  'from':'M9BJDuS24bqbJNvBRsoGg3'
+               }
+            ],
+            'type':'ED25519'
+         },
+         'txn':{  
+            'data':{  
+               'constraint':{  
+                          'constraint_id': 'OR'
+                          'auth_constraints': [{'constraint_id': 'ROLE', 
+                                                'role': '0',
+                                                'sig_count': 1, 
+                                                'need_to_be_owner': False, 
+                                                'metadata': {}}, 
+                                               
+                                               {'constraint_id': 'ROLE', 
+                                                'role': '2',
+                                                'sig_count': 1, 
+                                                'need_to_be_owner': True, 
+                                                'metadata': {}}
+                                               ], 
+               }, 
+               'field' :'services',
+               'auth_type': '0', 
+               'auth_action': 'EDIT'
+               'old_value': [VALIDATOR],
+               'new_value': [],
+               }
+            },
+            'protocolVersion':2,
+            'metadata':{  
+               'from':'M9BJDuS24bqbJNvBRsoGg3',
+               'digest':'ea13f0a310c7f4494d2828bccbc8ff0bd8b77d0c0bfb1ed9a84104bf55ad0436',
+               'reqId':711182024
+            },
+            'type':'120'
+         },
+         'ver':'1',
+         'rootHash':'GJNfknLWDAb8R93cgAX3Bw6CYDo23HBhiwZnzb4fHtyi',
+         'auditPath':[  
+
+         ]
+      }
+   }
+```
+
+If format of transaction is incorrect, the client will received NACK message for request. ",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262815125,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262815125,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,A client will receive NACK for,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 07:14:24,262815280,"@@ -985,6 +985,209 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+Command to change authentication rules. 
+Authentication rules are stored as key - value dictionary.
+Key - some action in the format `action--txn_type--field--old_value--new_value`
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Change the rights to an action.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights to. (Example: NYM, NODE, POOL_RESTART...)
+
+- `field` (string):
+
+    Change the rights to edit(add) some values from field.
+
+- `old_value` (string; optional):
+
+    Old value of field, which can be changed to a new_value.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. Needed for determine the type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of constraint, which for ConstraintEntity is always of type ""ROLE"". Needed for determine the type of constraint for correct deserialization.
+        
+- `role` (enum number as string; optional):
+
+    Role of a user that the NYM record is being created for. One of the following values
+
+    - None (common USER)
+    - 0 (TRUSTEE)
+    - 2 (STEWARD)
+    - 101 (TRUST_ANCHOR)
+    
+- `sig_count` (int):
+
+    The number of signatures that is needed to do some action described in the transaction fields.
+    
+- `need_to_be_owner` (boolean):
+
+    Flag to check is user must be owner of some transaction (Example: A steward must be the owner of the node to make changes to it).
+    
+- `metadata` (dict; optional):
+
+    Dictionary to additional parameters of constraint.
+
+```
+{
+    'sig_count': 1, 
+    'need_to_be_owner': False, 
+    'constraint_id': 'ROLE', 
+    'metadata': {}, 
+    'role': '0'
+}
+```
+
+*Request Example*:
+```
+{
+    'operation': {
+           'type':'120',
+           'constraint':{  
+                      'constraint_id': 'OR'
+                      'auth_constraints': [{'constraint_id': 'ROLE', 
+                                            'role': '0',
+                                            'sig_count': 1, 
+                                            'need_to_be_owner': False, 
+                                            'metadata': {}}, 
+                                           
+                                           {'constraint_id': 'ROLE', 
+                                            'role': '2',
+                                            'sig_count': 1, 
+                                            'need_to_be_owner': True, 
+                                            'metadata': {}}
+                                           ], 
+           }, 
+           'field' :'services',
+           'auth_type': '0', 
+           'auth_action': 'EDIT'
+           'old_value': [VALIDATOR],
+           'new_value': [],
+    },
+    
+    'identifier': '21BPzYYrFzbuECcBV3M1FH',
+    'reqId': 1514304094738044,
+    'protocolVersion': 1,
+    'signature': '3YVzDtSxxnowVwAXZmxCG2fz1A38j1qLrwKmGEG653GZw7KJRBX57Stc1oxQZqqu9mCqFLa7aBzt4MKXk4MeunVj',
+}
+```
+
+*Reply Example*:
+```
+{     'op':'REPLY',
+      'result':{  
+         'txnMetadata':{  
+            'seqNo':1,
+            'txnTime':1551776783
+         },
+         'reqSignature':{  
+            'values':[  
+               {  
+                  'value':'4j99V2BNRX1dn2QhnR8L9C3W9XQt1W3ScD1pyYaqD1NUnDVhbFGS3cw8dHRe5uVk8W7DoFtHb81ekMs9t9e76Fg',
+                  'from':'M9BJDuS24bqbJNvBRsoGg3'
+               }
+            ],
+            'type':'ED25519'
+         },
+         'txn':{  
+            'data':{  
+               'constraint':{  
+                          'constraint_id': 'OR'
+                          'auth_constraints': [{'constraint_id': 'ROLE', 
+                                                'role': '0',
+                                                'sig_count': 1, 
+                                                'need_to_be_owner': False, 
+                                                'metadata': {}}, 
+                                               
+                                               {'constraint_id': 'ROLE', 
+                                                'role': '2',
+                                                'sig_count': 1, 
+                                                'need_to_be_owner': True, 
+                                                'metadata': {}}
+                                               ], 
+               }, 
+               'field' :'services',
+               'auth_type': '0', 
+               'auth_action': 'EDIT'
+               'old_value': [VALIDATOR],
+               'new_value': [],
+               }
+            },
+            'protocolVersion':2,
+            'metadata':{  
+               'from':'M9BJDuS24bqbJNvBRsoGg3',
+               'digest':'ea13f0a310c7f4494d2828bccbc8ff0bd8b77d0c0bfb1ed9a84104bf55ad0436',
+               'reqId':711182024
+            },
+            'type':'120'
+         },
+         'ver':'1',
+         'rootHash':'GJNfknLWDAb8R93cgAX3Bw6CYDo23HBhiwZnzb4fHtyi',
+         'auditPath':[  
+
+         ]
+      }
+   }
+```
+
+If format of transaction is incorrect, the client will received NACK message for request. 
+A client will receive NACK to ",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262815280,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262815280,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,typo: `a a given`,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 09:42:07,262861516,"@@ -987,12 +988,12 @@ Command to change Pool's configuration
 
 ### AUTH_RULE
 
-Command to change authentication rules. 
-Authentication rules are stored as key - value dictionary.
-Key - some action in the format `action--txn_type--field--old_value--new_value`
-Value is a set of constraints on the execution of this action. There are two types of constraints:
+A command to change authentication rules. 
+Authentication rules are stored as a key-value dictionary.
+A key is an authenticated action in the format `action--txn_type--field--old_value--new_value`.
+A value is a set of constraints on the execution of this action. The actions (keys) are static and can be found in [auth_rules.md](auth_rules.md). So, it's not possible to register new actions by this command. But it's possible to override authentication constraints (values) for a a given action. There are two types of constraints:",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262861516,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262861516,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,typo: `As of now`,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 09:45:16,262862872,"@@ -985,6 +986,211 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+A command to change authentication rules. 
+Authentication rules are stored as a key-value dictionary.
+A key is an authenticated action in the format `action--txn_type--field--old_value--new_value`.
+A value is a set of constraints on the execution of this action. The actions (keys) are static and can be found in [auth_rules.md](auth_rules.md). So, it's not possible to register new actions by this command. But it's possible to override authentication constraints (values) for a a given action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints.
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that changing a value of a NODE transaction's `service` field from `[VALIDATOR]` to `[]` (demotion of a node) can only be done by one TRUSTEE or one STEWARD, and this Trustee or Steward needs to be the owner (the original creator) of this transaction.
+
+**Action Format:**
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Action type: add a new entity or edit an existing one.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights for. (Example: ""0"", ""1"", ...)
+
+- `field` (string):
+
+    Change the rights for editing (adding) a value of the given transaction field. `*` can be used as `any field`.
+
+- `old_value` (string; optional):
+
+   Old value of a field, which can be changed to a new_value. Makes sense for EDIT actions only.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. It's needed to determine a type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of a constraint. As of not only ROLE is supported, but plugins can register new ones. It's needed to determine a type of constraint for correct deserialization.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262862872,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262862872,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,typo: `As of now`,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 09:45:24,262862912,"@@ -709,6 +710,140 @@ Command to change Pool's configuration
 }
 ```
 
+#### AUTH_RULE
+
+Transaction to change authentication rules. 
+Authentication rules are stored in the State as key - value dictionary. This coincides with the storage structure in (auth_map)[auth_rule.md]. 
+If config ledger does not have transaction for key, the State use value from auth_map.
+Key - some action in the format `prefix--txn_type--field--old_value--new_value`
+- `prefix` (enum: `ADD` or `EDIT`)
+- `txn_type` (string) - The type of transaction to change rights to. (Example: ""0"", ""1"", ...)
+- `field` (string) Change the rights to edit(add) some values from field.
+- `old_value` (string; optional) Old value of field, which can be changed to a new_value.
+- `new_value` (string) New value that can be used to fill the field.
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- AuthConstraint with `constraint_id = ROLE_CONSTRAINT_ID` and format `{constraint_id, role, sig_count, need_to_be_owner, metadata}`;
+- AuthConstraintOr with `constraint_id = OR_CONSTRAINT_ID` and `auth_constraints` - list of constraints;
+- AuthConstraintAnd with `constraint_id = AND_CONSTRAINT_ID` and `auth_constraints` - list of constraints;
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+**AbstractAuthConstraint:**
+
+AuthConstraintAnd, AuthConstraintOr
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. It's needed to determine a type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints` - AuthConstraintAnd
+    - `OR` logical disjunction for all constraints from `auth_constraints` - AuthConstraintOr
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+AuthConstraint
+
+- `constraint_id` (enum: `ROLE`):
+
+      Type of a constraint. As of not only ROLE is supported, but plugins can register new ones. It's needed to determine a type of constraint for correct deserialization.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262862912,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262862912,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,"Better to say:
`If config ledger does not have a transaction for a given key, then a default rule defined in code is used.`",12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 09:51:24,262865424,"@@ -709,6 +710,140 @@ Command to change Pool's configuration
 }
 ```
 
+#### AUTH_RULE
+
+Transaction to change authentication rules. 
+Authentication rules are stored in the State as key - value dictionary. This coincides with the storage structure in (auth_map)[auth_rule.md]. 
+If config ledger does not have transaction for key, the State use value from auth_map.",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262865424,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262865424,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,if the user must be owner of a transaction,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 09:52:31,262865880,"@@ -985,6 +986,211 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+A command to change authentication rules. 
+Authentication rules are stored as a key-value dictionary.
+A key is an authenticated action in the format `action--txn_type--field--old_value--new_value`.
+A value is a set of constraints on the execution of this action. The actions (keys) are static and can be found in [auth_rules.md](auth_rules.md). So, it's not possible to register new actions by this command. But it's possible to override authentication constraints (values) for a given action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints.
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that changing a value of a NODE transaction's `service` field from `[VALIDATOR]` to `[]` (demotion of a node) can only be done by one TRUSTEE or one STEWARD, and this Trustee or Steward needs to be the owner (the original creator) of this transaction.
+
+**Action Format:**
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Action type: add a new entity or edit an existing one.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights for. (Example: ""0"", ""1"", ...)
+
+- `field` (string):
+
+    Change the rights for editing (adding) a value of the given transaction field. `*` can be used as `any field`.
+
+- `old_value` (string; optional):
+
+   Old value of a field, which can be changed to a new_value. Makes sense for EDIT actions only.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. It's needed to determine a type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of a constraint. As of not only ROLE is supported, but plugins can register new ones. It's needed to determine a type of constraint for correct deserialization.
+        
+- `role` (enum number as string; optional):
+
+    Role of a user that the NYM record is being created for. One of the following values
+
+    - None (common USER)
+    - 0 (TRUSTEE)
+    - 2 (STEWARD)
+    - 101 (TRUST_ANCHOR)
+    
+- `sig_count` (int):
+
+    The number of signatures that is needed to do the action described in the transaction fields.
+    
+- `need_to_be_owner` (boolean):
+
+    Flag to check is the user must be owner of some transaction (Example: A steward must be the owner of the node to make changes to it).",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262865880,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262865880,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,if the user must be owner of a transaction,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 09:52:41,262865966,"@@ -709,6 +710,140 @@ Command to change Pool's configuration
 }
 ```
 
+#### AUTH_RULE
+
+Transaction to change authentication rules. 
+Authentication rules are stored in the State as key - value dictionary. This coincides with the storage structure in (auth_map)[auth_rule.md]. 
+If config ledger does not have transaction for key, the State use value from auth_map.
+Key - some action in the format `prefix--txn_type--field--old_value--new_value`
+- `prefix` (enum: `ADD` or `EDIT`)
+- `txn_type` (string) - The type of transaction to change rights to. (Example: ""0"", ""1"", ...)
+- `field` (string) Change the rights to edit(add) some values from field.
+- `old_value` (string; optional) Old value of field, which can be changed to a new_value.
+- `new_value` (string) New value that can be used to fill the field.
+Value is a set of constraints on the execution of this action. There are two types of constraints:
+- AuthConstraint with `constraint_id = ROLE_CONSTRAINT_ID` and format `{constraint_id, role, sig_count, need_to_be_owner, metadata}`;
+- AuthConstraintOr with `constraint_id = OR_CONSTRAINT_ID` and `auth_constraints` - list of constraints;
+- AuthConstraintAnd with `constraint_id = AND_CONSTRAINT_ID` and `auth_constraints` - list of constraints;
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that change the value of node services from [VALIDATOR] to [] (demotion of node) can only TRUSTEE or STEWARD if it is owner of this transaction.
+
+**AbstractAuthConstraint:**
+
+AuthConstraintAnd, AuthConstraintOr
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. It's needed to determine a type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints` - AuthConstraintAnd
+    - `OR` logical disjunction for all constraints from `auth_constraints` - AuthConstraintOr
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+AuthConstraint
+
+- `constraint_id` (enum: `ROLE`):
+
+      Type of a constraint. As of not only ROLE is supported, but plugins can register new ones. It's needed to determine a type of constraint for correct deserialization.
+        
+- `role` (enum number as string; optional):
+
+    Role of a user that the NYM record is being created for. One of the following values
+
+    - None (common USER)
+    - 0 (TRUSTEE)
+    - 2 (STEWARD)
+    - 101 (TRUST_ANCHOR)
+   
+- `sig_count` (int):
+
+    The number of signatures that is needed to do the action described in the transaction fields.
+    
+- `need_to_be_owner` (boolean):
+
+    Flag to check is the user must be owner of some transaction (Example: A steward must be the owner of the node to make changes to it).",,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262865966,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262865966,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1189,https://github.com/hyperledger/indy-node/pull/1189,Fix incorrect json,12b1947b2cf37b069a38039b3b79328d4ccecf5e,2019-03-06 11:58:15,262910165,"@@ -985,6 +986,211 @@ Command to change Pool's configuration
 }
 ```
 
+### AUTH_RULE
+
+A command to change authentication rules. 
+Authentication rules are stored as a key-value dictionary.
+A key is an authenticated action in the format `action--txn_type--field--old_value--new_value`.
+A value is a set of constraints on the execution of this action. The actions (keys) are static and can be found in [auth_rules.md](auth_rules.md). So, it's not possible to register new actions by this command. But it's possible to override authentication constraints (values) for a given action. There are two types of constraints:
+- ConstraintEntity contains `{constraint_id, role, sig_count, need_to_be_owner, metadata}`
+- ConstraintList with format `{constraint_id, auth_constraints}` contains list of constraints.
+That is, the entry 
+```
+""EDIT--NODE--services--[VALIDATOR]--[]"" -> {constraint_id: OR,
+                                            auth_constraints: [{constraint_id: ROLE,
+                                                                role: STEWARD, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: True},
+                                                               {constraint_id: ROLE,
+                                                                role: TRUSTEE, 
+                                                                sig_count: 1, 
+                                                                need_to_be_owner: False}
+                                                               ]
+                                           }
+                                                                 
+```
+means that changing a value of a NODE transaction's `service` field from `[VALIDATOR]` to `[]` (demotion of a node) can only be done by one TRUSTEE or one STEWARD, and this Trustee or Steward needs to be the owner (the original creator) of this transaction.
+
+**Action Format:**
+
+- `auth_action` (enum: `ADD` or `EDIT`):
+
+    Action type: add a new entity or edit an existing one.
+    
+- `auth_type` (string):
+
+    The type of transaction to change rights for. (Example: ""0"", ""1"", ...)
+
+- `field` (string):
+
+    Change the rights for editing (adding) a value of the given transaction field. `*` can be used as `any field`.
+
+- `old_value` (string; optional):
+
+   Old value of a field, which can be changed to a new_value. Makes sense for EDIT actions only.
+
+- `new_value` (string):
+   
+   New value that can be used to fill the field.
+
+**ConstraintType:**
+
+ConstraintList
+
+- `constraint_id` (enum: `AND` or `OR`):
+
+    Type of a constraint class. It's needed to determine a type of constraint for correct deserialization.
+    - `AND` logical conjunction for all constraints from `auth_constraints`
+    - `OR` logical disjunction for all constraints from `auth_constraints`
+    
+- `auth_constraints` (list of ConstraintType):
+
+    List of ConstraintType (ConstraintList or ConstraintEntity) objects
+    
+ ```
+{ 'constraint_id': 'AND',
+  'auth_constraints': [<ConstraintEntity>,
+                      <ConstraintEntity>]
+}
+```
+    
+ConstraintEntity
+
+- `constraint_id` (enum: `ROLE`):
+
+   Type of a constraint. As of not only ROLE is supported, but plugins can register new ones. It's needed to determine a type of constraint for correct deserialization.
+        
+- `role` (enum number as string; optional):
+
+    Role of a user that the NYM record is being created for. One of the following values
+
+    - None (common USER)
+    - 0 (TRUSTEE)
+    - 2 (STEWARD)
+    - 101 (TRUST_ANCHOR)
+    
+- `sig_count` (int):
+
+    The number of signatures that is needed to do the action described in the transaction fields.
+    
+- `need_to_be_owner` (boolean):
+
+    Flag to check is the user must be owner of some transaction (Example: A steward must be the owner of the node to make changes to it).
+    
+- `metadata` (dict; optional):
+
+    Dictionary for additional parameters of the constraint. Can be used by plugins to add additional restrictions.
+
+```
+{
+    'sig_count': 1, 
+    'need_to_be_owner': False, 
+    'constraint_id': 'ROLE', 
+    'metadata': {}, 
+    'role': '0'
+}
+```
+
+*Request Example*:",117,2019-03-06 14:27:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/262910165,https://github.com/hyperledger/indy-node/pull/1189#discussion_r262910165,Toktar
https://github.com/hyperledger/indy-node/pull/1187,https://github.com/hyperledger/indy-node/pull/1187,"I think it makes sense to check here that the new NYM was added on all nodes including `delayed_node`, that is call `ensure_all_nodes_have_same_data`",c133a462e3e8f70080b23e12097326b5fc7b703e,2019-03-01 07:05:30,261497455,"@@ -0,0 +1,45 @@
+from indy_common.authorize.auth_actions import ADD_PREFIX, AuthActionAdd
+from indy_common.authorize.auth_constraints import AuthConstraint
+from indy_common.constants import NYM, CONFIG_LEDGER_ID
+from indy_node.test.auth_rule_change.helper import create_verkey_did, sdk_send_and_check_auth_rule_request
+from plenum.common.constants import STEWARD, ROLE, STEWARD_STRING
+from plenum.common.startable import Mode
+from plenum.test.delayers import cDelay, ppDelay, pDelay
+from plenum.test.helper import assertExp
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.test.stasher import delay_rules_without_processing
+from stp_core.loop.eventually import eventually
+
+
+def test_catching_up_auth_rule_txn(looper,
+                                   txnPoolNodeSet,
+                                   sdk_wallet_trustee,
+                                   sdk_wallet_steward,
+                                   sdk_pool_handle):
+    delayed_node = txnPoolNodeSet[-1]
+    wh, _ = sdk_wallet_trustee
+    new_steward_did, new_steward_verkey = create_verkey_did(looper, wh)
+    changed_constraint = AuthConstraint(role=STEWARD,
+                                        sig_count=1)
+    action = AuthActionAdd(txn_type=NYM,
+                           field=ROLE,
+                           value=STEWARD)
+    with delay_rules_without_processing(delayed_node.nodeIbStasher, cDelay(), pDelay(), ppDelay()):
+        sdk_send_and_check_auth_rule_request(looper, sdk_wallet_trustee,
+                                             sdk_pool_handle, auth_action=ADD_PREFIX,
+                                             auth_type=action.txn_type, field=action.field,
+                                             new_value=action.value, old_value=None,
+                                             constraint=changed_constraint.as_dict)
+        delayed_node.start_catchup()
+        looper.run(eventually(lambda: assertExp(delayed_node.mode == Mode.participating)))
+    sdk_add_new_nym(looper,
+                    sdk_pool_handle,
+                    sdk_wallet_steward,
+                    'newSteward2',
+                    STEWARD_STRING,
+                    dest=new_steward_did, verkey=new_steward_verkey)
+",41,2019-03-01 07:32:18,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/261497455,https://github.com/hyperledger/indy-node/pull/1187#discussion_r261497455,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1187,https://github.com/hyperledger/indy-node/pull/1187,Does it make sense to check that 1 steward can not add another Steward before this is changed? Otherwise the test may give false positive results in future if we change this default rule.,c133a462e3e8f70080b23e12097326b5fc7b703e,2019-03-01 07:08:52,261498111,"@@ -0,0 +1,45 @@
+from indy_common.authorize.auth_actions import ADD_PREFIX, AuthActionAdd
+from indy_common.authorize.auth_constraints import AuthConstraint
+from indy_common.constants import NYM, CONFIG_LEDGER_ID
+from indy_node.test.auth_rule_change.helper import create_verkey_did, sdk_send_and_check_auth_rule_request
+from plenum.common.constants import STEWARD, ROLE, STEWARD_STRING
+from plenum.common.startable import Mode
+from plenum.test.delayers import cDelay, ppDelay, pDelay
+from plenum.test.helper import assertExp
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.test.stasher import delay_rules_without_processing
+from stp_core.loop.eventually import eventually
+
+
+def test_catching_up_auth_rule_txn(looper,
+                                   txnPoolNodeSet,
+                                   sdk_wallet_trustee,
+                                   sdk_wallet_steward,
+                                   sdk_pool_handle):
+    delayed_node = txnPoolNodeSet[-1]
+    wh, _ = sdk_wallet_trustee
+    new_steward_did, new_steward_verkey = create_verkey_did(looper, wh)
+    changed_constraint = AuthConstraint(role=STEWARD,
+                                        sig_count=1)
+    action = AuthActionAdd(txn_type=NYM,
+                           field=ROLE,
+                           value=STEWARD)
+    with delay_rules_without_processing(delayed_node.nodeIbStasher, cDelay(), pDelay(), ppDelay()):
+        sdk_send_and_check_auth_rule_request(looper, sdk_wallet_trustee,",28,2019-03-01 07:32:18,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/261498111,https://github.com/hyperledger/indy-node/pull/1187#discussion_r261498111,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1187,https://github.com/hyperledger/indy-node/pull/1187,I think we need to integrate it for the new Pluggable Request Handler for AUTH_RULE txn.,c133a462e3e8f70080b23e12097326b5fc7b703e,2019-03-01 07:32:11,261502289,"@@ -202,3 +206,20 @@ def get_auth_key(operation):
             AuthActionAdd(txn_type=auth_type,
                           field=field,
                           value=new_value).get_action_id()
+
+    @staticmethod
+    def get_auth_constraint(operation):
+        return ConstraintCreator.create_constraint(operation.get(CONSTRAINT))
+
+    def update_auth_constraint(self, auth_key, constraint):
+        self.state.set(auth_key.encode(),
+                       self.constraint_serializer.serialize(constraint))
+
+    def updateState(self, txns, isCommitted=False):",50,2019-03-01 07:32:18,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/261502289,https://github.com/hyperledger/indy-node/pull/1187#discussion_r261502289,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,Make deepcopy() here or before sending ```input_dict``` in ```create_constraint```?,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-26 10:38:31,260223763,"@@ -145,7 +153,8 @@ def from_dict(as_dict):
 
 class ConstraintCreator:
     @staticmethod
-    def create_constraint(as_dict):
+    def create_constraint(input_dict):
+        as_dict = dict(input_dict)",39,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260223763,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260223763,Toktar
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,"i think, that dict() calling is enough. It's like a copy() call",40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-26 11:30:13,260243429,"@@ -145,7 +153,8 @@ def from_dict(as_dict):
 
 class ConstraintCreator:
     @staticmethod
-    def create_constraint(as_dict):
+    def create_constraint(input_dict):
+        as_dict = dict(input_dict)",39,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260243429,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260243429,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,But there are 3 places where we need to do dict(). We can change it to one deepcopy().,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-26 11:32:24,260244181,"@@ -145,7 +153,8 @@ def from_dict(as_dict):
 
 class ConstraintCreator:
     @staticmethod
-    def create_constraint(as_dict):
+    def create_constraint(input_dict):
+        as_dict = dict(input_dict)",39,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260244181,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260244181,Toktar
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,"As of now, we support 2 various types for auth_map. If ANYONE_CAN_WRITE is set to True, then we find rule in anyone_can_write map firstly and then if not found in auth_map. In the future, we will plan to exlude this option, but for now we should take into account anyone_can_write_map too (it's a {} by default)",40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-26 11:47:59,260249193,"@@ -39,10 +35,39 @@ def doStaticValidation(self, request: Request):
             self._doStaticValidationPoolUpgrade(identifier, req_id, operation)
         elif operation[TXN_TYPE] == POOL_CONFIG:
             self._doStaticValidationPoolConfig(identifier, req_id, operation)
+        elif operation[TXN_TYPE] == AUTH_RULE:
+            self._doStaticValidationAuthRule(identifier, req_id, operation)
 
     def _doStaticValidationPoolConfig(self, identifier, reqId, operation):
         pass
 
+    def _doStaticValidationAuthRule(self, identifier, reqId, operation):
+        constraint = operation.get(CONSTRAINT)
+        ConstraintCreator.create_constraint(constraint)
+
+        action = operation.get(AUTH_ACTION, None)
+        old_value = operation.get(OLD_VALUE, None)
+        new_value = operation.get(NEW_VALUE, None)
+        auth_type = operation.get(AUTH_TYPE, None)
+        field = operation.get(FIELD, None)
+        if old_value is None and action == EDIT_PREFIX:
+            raise InvalidClientRequest(identifier, reqId,
+                                       ""Transaction for change authentication ""
+                                       ""rules for {}={} must contain field {}"".
+                                       format(AUTH_ACTION, EDIT_PREFIX, OLD_VALUE))
+        auth_key = AuthActionEdit(txn_type=auth_type,
+                                  field=field,
+                                  old_value=old_value,
+                                  new_value=new_value).get_action_id() \
+            if action == EDIT_PREFIX else \
+            AuthActionAdd(txn_type=auth_type,
+                          field=field,
+                          value=new_value).get_action_id()
+        if auth_key not in self.write_req_validator.auth_map:",,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260249193,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260249193,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,Why this is not a static field as in other validators?,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 06:57:54,260614029,"@@ -303,6 +307,58 @@ class ClientPoolConfigOperation(MessageValidator):
     )
 
 
+class ConstraintField(MessageValidator):
+    _base_types = None
+
+    def __init__(self, constraint_entity_cls, constraint_list_cls, **kwargs):
+        super().__init__(**kwargs)
+        self._constraint_entity = constraint_entity_cls
+        self._constraint_list = constraint_list_cls
+
+    def _specific_validation(self, val):
+        if val is None:
+            return ""Field {} is required"".format(CONSTRAINT)
+        return self._constraint_entity.validate(val) \
+            if val[CONSTRAINT_ID] == ConstraintsEnum.ROLE_CONSTRAINT_ID \
+            else self._constraint_list.validate(val)
+
+
+class ConstraintEntityField(MessageValidator):
+    schema = (
+        (CONSTRAINT_ID, ChooseField(values=ConstraintsEnum.values())),
+        (ROLE, RoleField()),
+        (SIG_COUNT, NonNegativeNumberField()),
+        (NEED_TO_BE_OWNER, BooleanField(optional=True)),
+        (METADATA, AnyMapField(optional=True))
+    )
+
+
+class ConstraintListField(MessageValidator):
+    schema = None
+
+    def __init__(self, schema_is_strict=SCHEMA_IS_STRICT):
+        self.schema = (",,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260614029,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260614029,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,Should the arguments be swapped here?,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 06:59:24,260614320,"@@ -303,6 +307,58 @@ class ClientPoolConfigOperation(MessageValidator):
     )
 
 
+class ConstraintField(MessageValidator):
+    _base_types = None
+
+    def __init__(self, constraint_entity_cls, constraint_list_cls, **kwargs):
+        super().__init__(**kwargs)
+        self._constraint_entity = constraint_entity_cls
+        self._constraint_list = constraint_list_cls
+
+    def _specific_validation(self, val):
+        if val is None:
+            return ""Field {} is required"".format(CONSTRAINT)
+        return self._constraint_entity.validate(val) \
+            if val[CONSTRAINT_ID] == ConstraintsEnum.ROLE_CONSTRAINT_ID \
+            else self._constraint_list.validate(val)
+
+
+class ConstraintEntityField(MessageValidator):
+    schema = (
+        (CONSTRAINT_ID, ChooseField(values=ConstraintsEnum.values())),
+        (ROLE, RoleField()),
+        (SIG_COUNT, NonNegativeNumberField()),
+        (NEED_TO_BE_OWNER, BooleanField(optional=True)),
+        (METADATA, AnyMapField(optional=True))
+    )
+
+
+class ConstraintListField(MessageValidator):
+    schema = None
+
+    def __init__(self, schema_is_strict=SCHEMA_IS_STRICT):
+        self.schema = (
+            (CONSTRAINT_ID, ChooseField(values=ConstraintsEnum.values())),
+            (AUTH_CONSTRAINTS, IterableField(ConstraintField(self,",,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260614320,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260614320,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,Why do we need to explicitly pass classes here if we have just 1 variant for each argument: `ConstraintEntityField` and `ConstraintListField`?,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 07:00:42,260614546,"@@ -303,6 +307,58 @@ class ClientPoolConfigOperation(MessageValidator):
     )
 
 
+class ConstraintField(MessageValidator):
+    _base_types = None
+
+    def __init__(self, constraint_entity_cls, constraint_list_cls, **kwargs):",,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260614546,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260614546,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,Can it throw an exception here?,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 07:03:46,260615079,"@@ -39,10 +35,37 @@ def doStaticValidation(self, request: Request):
             self._doStaticValidationPoolUpgrade(identifier, req_id, operation)
         elif operation[TXN_TYPE] == POOL_CONFIG:
             self._doStaticValidationPoolConfig(identifier, req_id, operation)
+        elif operation[TXN_TYPE] == AUTH_RULE:
+            self._doStaticValidationAuthRule(identifier, req_id, operation)
 
     def _doStaticValidationPoolConfig(self, identifier, reqId, operation):
         pass
 
+    def _doStaticValidationAuthRule(self, identifier, reqId, operation):
+        constraint = operation.get(CONSTRAINT)
+        ConstraintCreator.create_constraint(constraint)",46,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260615079,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260615079,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,I would make it more clear: `Unknown authorization rule: key '' is not found in authorization map`,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 07:12:44,260617048,"@@ -39,10 +35,37 @@ def doStaticValidation(self, request: Request):
             self._doStaticValidationPoolUpgrade(identifier, req_id, operation)
         elif operation[TXN_TYPE] == POOL_CONFIG:
             self._doStaticValidationPoolConfig(identifier, req_id, operation)
+        elif operation[TXN_TYPE] == AUTH_RULE:
+            self._doStaticValidationAuthRule(identifier, req_id, operation)
 
     def _doStaticValidationPoolConfig(self, identifier, reqId, operation):
         pass
 
+    def _doStaticValidationAuthRule(self, identifier, reqId, operation):
+        constraint = operation.get(CONSTRAINT)
+        ConstraintCreator.create_constraint(constraint)
+        action = operation.get(AUTH_ACTION, None)
+
+        if OLD_VALUE not in operation and action == EDIT_PREFIX:
+            raise InvalidClientRequest(identifier, reqId,
+                                       ""Transaction for change authentication ""
+                                       ""rule for {}={} must contain field {}"".
+                                       format(AUTH_ACTION, EDIT_PREFIX, OLD_VALUE))
+
+        if OLD_VALUE in operation and action == ADD_PREFIX:
+            raise InvalidClientRequest(identifier, reqId,
+                                       ""Transaction for change authentication ""
+                                       ""rule for {}={} must not contain field {}"".
+                                       format(AUTH_ACTION, ADD_PREFIX, OLD_VALUE))
+
+        auth_key = self.get_auth_key(operation)
+
+        if auth_key not in self.write_req_validator.auth_map and \
+                auth_key not in self.write_req_validator.anyone_can_write_map:
+            raise InvalidClientRequest(identifier, reqId,
+                                       ""Key '{}' is not contained in the """,,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260617048,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260617048,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,The same test name as above,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 07:14:56,260617530,"@@ -0,0 +1,141 @@
+import pytest
+
+from indy_common.authorize.auth_actions import ADD_PREFIX, EDIT_PREFIX
+from indy_common.authorize.auth_constraints import CONSTRAINT_ID, SIG_COUNT, NEED_TO_BE_OWNER, METADATA, \
+    ConstraintsEnum, ROLE, AUTH_CONSTRAINTS
+from indy_common.constants import AUTH_RULE, NYM, TRUST_ANCHOR, CONSTRAINT, AUTH_ACTION, AUTH_TYPE, FIELD, NEW_VALUE, \
+    OLD_VALUE
+from indy_common.types import ConstraintEntityField
+from plenum.common.constants import TXN_TYPE, TRUSTEE, STEWARD
+from plenum.common.exceptions import RequestRejectedException, \
+    RequestNackedException
+from plenum.test.helper import sdk_gen_request, sdk_sign_and_submit_req_obj, sdk_get_and_check_replies
+
+
+def sdk_send_and_check_auth_rule_request(looper, sdk_wallet_trustee, sdk_pool_handle,
+                                         auth_action=ADD_PREFIX, auth_type=NYM,
+                                         field=ROLE, new_value=TRUST_ANCHOR,
+                                         old_value=None, constraint=None):
+    constraint = _generate_constraint_entity() \
+        if constraint is None \
+        else constraint
+    op = {TXN_TYPE: AUTH_RULE,
+          CONSTRAINT: constraint,
+          AUTH_ACTION: auth_action,
+          AUTH_TYPE: auth_type,
+          FIELD: field,
+          NEW_VALUE: new_value
+          }
+    if old_value:
+        op[OLD_VALUE] = old_value
+    req_obj = sdk_gen_request(op, identifier=sdk_wallet_trustee[1])
+    req = sdk_sign_and_submit_req_obj(looper,
+                                      sdk_pool_handle,
+                                      sdk_wallet_trustee,
+                                      req_obj)
+    resp = sdk_get_and_check_replies(looper, [req])
+    return resp
+
+
+def test_auth_rule_transaction(looper,
+                               sdk_wallet_trustee,
+                               sdk_pool_handle):
+    sdk_send_and_check_auth_rule_request(looper,
+                                         sdk_wallet_trustee,
+                                         sdk_pool_handle)
+
+
+def test_auth_rule_transaction(looper,",,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260617530,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260617530,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,The same test name as above,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 07:17:48,260618154,"@@ -0,0 +1,141 @@
+import pytest
+
+from indy_common.authorize.auth_actions import ADD_PREFIX, EDIT_PREFIX
+from indy_common.authorize.auth_constraints import CONSTRAINT_ID, SIG_COUNT, NEED_TO_BE_OWNER, METADATA, \
+    ConstraintsEnum, ROLE, AUTH_CONSTRAINTS
+from indy_common.constants import AUTH_RULE, NYM, TRUST_ANCHOR, CONSTRAINT, AUTH_ACTION, AUTH_TYPE, FIELD, NEW_VALUE, \
+    OLD_VALUE
+from indy_common.types import ConstraintEntityField
+from plenum.common.constants import TXN_TYPE, TRUSTEE, STEWARD
+from plenum.common.exceptions import RequestRejectedException, \
+    RequestNackedException
+from plenum.test.helper import sdk_gen_request, sdk_sign_and_submit_req_obj, sdk_get_and_check_replies
+
+
+def sdk_send_and_check_auth_rule_request(looper, sdk_wallet_trustee, sdk_pool_handle,
+                                         auth_action=ADD_PREFIX, auth_type=NYM,
+                                         field=ROLE, new_value=TRUST_ANCHOR,
+                                         old_value=None, constraint=None):
+    constraint = _generate_constraint_entity() \
+        if constraint is None \
+        else constraint
+    op = {TXN_TYPE: AUTH_RULE,
+          CONSTRAINT: constraint,
+          AUTH_ACTION: auth_action,
+          AUTH_TYPE: auth_type,
+          FIELD: field,
+          NEW_VALUE: new_value
+          }
+    if old_value:
+        op[OLD_VALUE] = old_value
+    req_obj = sdk_gen_request(op, identifier=sdk_wallet_trustee[1])
+    req = sdk_sign_and_submit_req_obj(looper,
+                                      sdk_pool_handle,
+                                      sdk_wallet_trustee,
+                                      req_obj)
+    resp = sdk_get_and_check_replies(looper, [req])
+    return resp
+
+
+def test_auth_rule_transaction(looper,
+                               sdk_wallet_trustee,
+                               sdk_pool_handle):
+    sdk_send_and_check_auth_rule_request(looper,
+                                         sdk_wallet_trustee,
+                                         sdk_pool_handle)
+
+
+def test_auth_rule_transaction(looper,
+                               sdk_wallet_trustee,
+                               sdk_pool_handle):
+    sdk_send_and_check_auth_rule_request(looper,
+                                         sdk_wallet_trustee,
+                                         sdk_pool_handle,
+                                         auth_action=ADD_PREFIX,
+                                         auth_type=NYM,
+                                         field=ROLE,
+                                         new_value='*'
+                                         )
+
+
+def test_auth_rule_transaction_with_large_constraint(looper,
+                                                     sdk_wallet_trustee,
+                                                     sdk_pool_handle):
+    constraint = _generate_constraint_list(auth_constraints=[_generate_constraint_entity(role=TRUSTEE),
+                                                             _generate_constraint_entity(role=STEWARD)])
+    sdk_send_and_check_auth_rule_request(looper,
+                                         sdk_wallet_trustee,
+                                         sdk_pool_handle,
+                                         constraint=constraint)
+
+
+def test_reject_auth_rule_transaction(looper,
+                                      sdk_wallet_trust_anchor,
+                                      sdk_pool_handle):
+    with pytest.raises(RequestRejectedException) as e:
+        sdk_send_and_check_auth_rule_request(looper,
+                                             sdk_wallet_trust_anchor,
+                                             sdk_pool_handle)
+    e.match('UnauthorizedClientRequest')
+    e.match('can not do this action')
+
+
+def test_reqnack_auth_rule_transaction_with_wrong_key(looper,
+                                                      sdk_wallet_trustee,
+                                                      sdk_pool_handle):
+    with pytest.raises(RequestNackedException) as e:
+        sdk_send_and_check_auth_rule_request(looper,
+                                             sdk_wallet_trustee,
+                                             sdk_pool_handle,
+                                             auth_type=""*"")
+    e.match(""InvalidClientRequest"")
+    e.match(""is not contained in the authorization map"")
+
+
+def test_reqnack_auth_rule_edit_transaction_with_wrong_format(looper,
+                                                              sdk_wallet_trustee,
+                                                              sdk_pool_handle):
+    with pytest.raises(RequestNackedException) as e:
+        sdk_send_and_check_auth_rule_request(looper,
+                                             sdk_wallet_trustee,
+                                             sdk_pool_handle,
+                                             auth_action=EDIT_PREFIX)
+    e.match(""InvalidClientRequest"")
+    e.match(""Transaction for change authentication ""
+            ""rule for {}={} must contain field {}"".
+            format(AUTH_ACTION, EDIT_PREFIX, OLD_VALUE))
+
+
+def test_reqnack_auth_rule_add_transaction_with_wrong_format(looper,",87,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260618154,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260618154,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,Can we add test with even more complex constraint?,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 07:24:34,260619600,"@@ -0,0 +1,141 @@
+import pytest
+
+from indy_common.authorize.auth_actions import ADD_PREFIX, EDIT_PREFIX
+from indy_common.authorize.auth_constraints import CONSTRAINT_ID, SIG_COUNT, NEED_TO_BE_OWNER, METADATA, \
+    ConstraintsEnum, ROLE, AUTH_CONSTRAINTS
+from indy_common.constants import AUTH_RULE, NYM, TRUST_ANCHOR, CONSTRAINT, AUTH_ACTION, AUTH_TYPE, FIELD, NEW_VALUE, \
+    OLD_VALUE
+from indy_common.types import ConstraintEntityField
+from plenum.common.constants import TXN_TYPE, TRUSTEE, STEWARD
+from plenum.common.exceptions import RequestRejectedException, \
+    RequestNackedException
+from plenum.test.helper import sdk_gen_request, sdk_sign_and_submit_req_obj, sdk_get_and_check_replies
+
+
+def sdk_send_and_check_auth_rule_request(looper, sdk_wallet_trustee, sdk_pool_handle,
+                                         auth_action=ADD_PREFIX, auth_type=NYM,
+                                         field=ROLE, new_value=TRUST_ANCHOR,
+                                         old_value=None, constraint=None):
+    constraint = _generate_constraint_entity() \
+        if constraint is None \
+        else constraint
+    op = {TXN_TYPE: AUTH_RULE,
+          CONSTRAINT: constraint,
+          AUTH_ACTION: auth_action,
+          AUTH_TYPE: auth_type,
+          FIELD: field,
+          NEW_VALUE: new_value
+          }
+    if old_value:
+        op[OLD_VALUE] = old_value
+    req_obj = sdk_gen_request(op, identifier=sdk_wallet_trustee[1])
+    req = sdk_sign_and_submit_req_obj(looper,
+                                      sdk_pool_handle,
+                                      sdk_wallet_trustee,
+                                      req_obj)
+    resp = sdk_get_and_check_replies(looper, [req])
+    return resp
+
+
+def test_auth_rule_transaction(looper,
+                               sdk_wallet_trustee,
+                               sdk_pool_handle):
+    sdk_send_and_check_auth_rule_request(looper,
+                                         sdk_wallet_trustee,
+                                         sdk_pool_handle)
+
+
+def test_auth_rule_transaction(looper,
+                               sdk_wallet_trustee,
+                               sdk_pool_handle):
+    sdk_send_and_check_auth_rule_request(looper,
+                                         sdk_wallet_trustee,
+                                         sdk_pool_handle,
+                                         auth_action=ADD_PREFIX,
+                                         auth_type=NYM,
+                                         field=ROLE,
+                                         new_value='*'
+                                         )
+
+
+def test_auth_rule_transaction_with_large_constraint(looper,
+                                                     sdk_wallet_trustee,
+                                                     sdk_pool_handle):
+    constraint = _generate_constraint_list(auth_constraints=[_generate_constraint_entity(role=TRUSTEE),",,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260619600,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260619600,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,As I understand it's only one way to use a self class name in a schema.,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 07:26:36,260620063,"@@ -303,6 +307,58 @@ class ClientPoolConfigOperation(MessageValidator):
     )
 
 
+class ConstraintField(MessageValidator):
+    _base_types = None
+
+    def __init__(self, constraint_entity_cls, constraint_list_cls, **kwargs):
+        super().__init__(**kwargs)
+        self._constraint_entity = constraint_entity_cls
+        self._constraint_list = constraint_list_cls
+
+    def _specific_validation(self, val):
+        if val is None:
+            return ""Field {} is required"".format(CONSTRAINT)
+        return self._constraint_entity.validate(val) \
+            if val[CONSTRAINT_ID] == ConstraintsEnum.ROLE_CONSTRAINT_ID \
+            else self._constraint_list.validate(val)
+
+
+class ConstraintEntityField(MessageValidator):
+    schema = (
+        (CONSTRAINT_ID, ChooseField(values=ConstraintsEnum.values())),
+        (ROLE, RoleField()),
+        (SIG_COUNT, NonNegativeNumberField()),
+        (NEED_TO_BE_OWNER, BooleanField(optional=True)),
+        (METADATA, AnyMapField(optional=True))
+    )
+
+
+class ConstraintListField(MessageValidator):
+    schema = None
+
+    def __init__(self, schema_is_strict=SCHEMA_IS_STRICT):
+        self.schema = (",,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260620063,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260620063,Toktar
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,"Please add tests for `ConstraintField`, `ConstraintEntityField` and `ConstraintListField`",40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-27 07:32:32,260621557,"@@ -303,6 +307,58 @@ class ClientPoolConfigOperation(MessageValidator):
     )
 
 
+class ConstraintField(MessageValidator):",,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/260621557,https://github.com/hyperledger/indy-node/pull/1184#discussion_r260621557,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,"It looks like we don't do any specific validation for `AUTH_CONSTRAINTS`, so it means that list may contain any values and validation will pass?",40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-28 07:20:21,261070353,"@@ -334,22 +336,20 @@ class ConstraintEntityField(MessageValidator):
 
 
 class ConstraintListField(MessageValidator):
-    schema = None
+    _base_types = (dict, )
+    schema = ((CONSTRAINT_ID, ChooseField(values=ConstraintsEnum.values())),
+              (AUTH_CONSTRAINTS, IterableField(AnyField())))
 
-    def __init__(self, schema_is_strict=SCHEMA_IS_STRICT):
-        self.schema = (
-            (CONSTRAINT_ID, ChooseField(values=ConstraintsEnum.values())),
-            (AUTH_CONSTRAINTS, IterableField(ConstraintField(self,
-                                                             ConstraintEntityField())))
-        )
-        super().__init__(schema_is_strict)
+    def _validate_message(self, val):",68,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/261070353,https://github.com/hyperledger/indy-node/pull/1184#discussion_r261070353,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,Please add a test for presence of `CONSTRAINT_ID ` field,40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-28 07:26:28,261071799,"@@ -0,0 +1,67 @@
+import pytest
+
+from indy_common.constants import CONSTRAINT, AUTH_ACTION
+from indy_common.types import ClientAuthRuleOperation
+from indy_node.test.auth_rule_change.helper import generate_constraint_entity, generate_constraint_list, \
+    generate_auth_rule_operation
+from indy_common.authorize.auth_constraints import ROLE, AUTH_CONSTRAINTS, CONSTRAINT_ID
+
+validator = ClientAuthRuleOperation()
+
+valid_auth_rule_operation_small = generate_auth_rule_operation()
+valid_auth_rule_operation_large = generate_auth_rule_operation(constraint=generate_constraint_list(
+    auth_constraints=[generate_constraint_entity(),
+                      generate_constraint_entity()]))
+valid_auth_rule_operation_extra_large = generate_auth_rule_operation(constraint=generate_constraint_list(
+    auth_constraints=[generate_constraint_entity(),
+                      generate_constraint_list(
+                          auth_constraints=[generate_constraint_entity(),
+                                            generate_constraint_entity()])]))
+
+
+def test_valid():
+    validator.validate(valid_auth_rule_operation_small)
+    validator.validate(valid_auth_rule_operation_large)
+    validator.validate(valid_auth_rule_operation_extra_large)
+
+
+def test_invalid_operation_action():
+    # must be ADD_PREFIX or EDIT_PREFIX
+    invalid_auth_rule_operation = generate_auth_rule_operation(auth_action=""auth_action"")
+    with pytest.raises(TypeError) as e:
+        validator.validate(invalid_auth_rule_operation)
+    e.match(AUTH_ACTION)
+
+
+def test_invalid_entity_role():
+    # ConstraintEntityField without required field 'role'
+    invalid_auth_rule_operation = generate_auth_rule_operation()
+    del invalid_auth_rule_operation[CONSTRAINT][ROLE]
+    with pytest.raises(TypeError) as e:
+        validator.validate(invalid_auth_rule_operation)
+    e.match(ROLE)
+
+
+def test_invalid_operation_auth_constraints():
+    # ConstraintListField without required field 'auth_constraints'
+    invalid_auth_rule_operation = generate_auth_rule_operation(constraint=generate_constraint_list(
+        auth_constraints=[generate_constraint_entity(),
+                          generate_constraint_entity()]))
+    del invalid_auth_rule_operation[CONSTRAINT][AUTH_CONSTRAINTS]
+    with pytest.raises(TypeError) as e:
+        validator.validate(invalid_auth_rule_operation)
+    e.match(AUTH_CONSTRAINTS)
+
+
+def test_invalid_operation_auth_constraints_with_large_constraint():
+    # ConstraintListField without required field 'auth_constraints' on the 2nd level
+    invalid_auth_rule_operation = generate_auth_rule_operation(constraint=generate_constraint_list(
+        auth_constraints=[generate_constraint_entity(),
+                          generate_constraint_list(
+                              auth_constraints=[generate_constraint_entity(),
+                                                generate_constraint_entity()])]))
+    del invalid_auth_rule_operation[CONSTRAINT][AUTH_CONSTRAINTS][1][AUTH_CONSTRAINTS]
+    with pytest.raises(TypeError) as e:
+        validator.validate(invalid_auth_rule_operation)
+    e.match(AUTH_CONSTRAINTS)
+",75,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/261071799,https://github.com/hyperledger/indy-node/pull/1184#discussion_r261071799,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1184,https://github.com/hyperledger/indy-node/pull/1184,Please add a test for validation of constraint in extra_large case (remove role from a second-level consraint),40e275c0aa8f3faa64728c3c0ded290dcaa29653,2019-02-28 07:27:57,261072174,"@@ -0,0 +1,67 @@
+import pytest
+
+from indy_common.constants import CONSTRAINT, AUTH_ACTION
+from indy_common.types import ClientAuthRuleOperation
+from indy_node.test.auth_rule_change.helper import generate_constraint_entity, generate_constraint_list, \
+    generate_auth_rule_operation
+from indy_common.authorize.auth_constraints import ROLE, AUTH_CONSTRAINTS, CONSTRAINT_ID
+
+validator = ClientAuthRuleOperation()
+
+valid_auth_rule_operation_small = generate_auth_rule_operation()
+valid_auth_rule_operation_large = generate_auth_rule_operation(constraint=generate_constraint_list(
+    auth_constraints=[generate_constraint_entity(),
+                      generate_constraint_entity()]))
+valid_auth_rule_operation_extra_large = generate_auth_rule_operation(constraint=generate_constraint_list(
+    auth_constraints=[generate_constraint_entity(),
+                      generate_constraint_list(
+                          auth_constraints=[generate_constraint_entity(),
+                                            generate_constraint_entity()])]))
+
+
+def test_valid():
+    validator.validate(valid_auth_rule_operation_small)
+    validator.validate(valid_auth_rule_operation_large)
+    validator.validate(valid_auth_rule_operation_extra_large)
+
+
+def test_invalid_operation_action():
+    # must be ADD_PREFIX or EDIT_PREFIX
+    invalid_auth_rule_operation = generate_auth_rule_operation(auth_action=""auth_action"")
+    with pytest.raises(TypeError) as e:
+        validator.validate(invalid_auth_rule_operation)
+    e.match(AUTH_ACTION)
+
+
+def test_invalid_entity_role():
+    # ConstraintEntityField without required field 'role'
+    invalid_auth_rule_operation = generate_auth_rule_operation()
+    del invalid_auth_rule_operation[CONSTRAINT][ROLE]",38,2019-02-28 09:56:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/261072174,https://github.com/hyperledger/indy-node/pull/1184#discussion_r261072174,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1179,https://github.com/hyperledger/indy-node/pull/1179,"We are going to remove `anyone_can_write_map` at all, so maybe it doesn't make sense to take care of it for now.",beadca5e21b62765d30667275890d9fd18e334ec,2019-02-22 07:22:56,259234635,"@@ -55,9 +57,41 @@ def _find_auth_constraint_key(self, action_id, auth_map):
 
 class ConfigLedgerAuthStrategy(AbstractAuthStrategy):
 
-    def get_auth_constraint(self, action_id) -> AbstractAuthConstraint:
-        """"""Get constraints from config ledger""""""
-        pass
+    def __init__(self,
+                 auth_map,
+                 state: PruningState,
+                 serializer: AbstractConstraintSerializer,
+                 anyone_can_write_map={}):",22,2019-02-22 11:59:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/259234635,https://github.com/hyperledger/indy-node/pull/1179#discussion_r259234635,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1179,https://github.com/hyperledger/indy-node/pull/1179,"I would add static `from_dict` method to every AuthConstraint class, so that `ConstraintCreator` can be simplifed and do not access `AUTH_CONSTRAINTS` (which is actually internals).",beadca5e21b62765d30667275890d9fd18e334ec,2019-02-22 07:34:54,259236957,"@@ -46,23 +80,75 @@ def __str__(self):
 
 
 class AuthConstraintAnd(AbstractAuthConstraint):
-    def __init__(self, auth_constraints):
+    def __init__(self, auth_constraints: List[AbstractAuthConstraint]):
         self.auth_constraints = auth_constraints
-        self.constraint_id = AND_CONSTRAINT_ID
+        self.constraint_id = ConstraintsEnum.AND_CONSTRAINT_ID
+
+    @property
+    def as_dict(self):
+        return {
+            CONSTRAINT_ID: self.constraint_id,
+            AUTH_CONSTRAINTS: [c.as_dict for c in self.auth_constraints]
+        }
 
     def __str__(self):
         return "" AND "".join([str(ac) for ac in self.auth_constraints])
 
 
 class AuthConstraintOr(AbstractAuthConstraint):
-    def __init__(self, auth_constraints):
+    def __init__(self, auth_constraints: List[AbstractAuthConstraint]):
         self.auth_constraints = auth_constraints
-        self.constraint_id = OR_CONSTRAINT_ID
+        self.constraint_id = ConstraintsEnum.OR_CONSTRAINT_ID
+
+    @property
+    def as_dict(self):
+        return {
+            CONSTRAINT_ID: self.constraint_id,
+            AUTH_CONSTRAINTS: [c.as_dict for c in self.auth_constraints]
+        }
 
     def __str__(self):
         return "" OR "".join([str(ac) for ac in self.auth_constraints])
 
 
+class ConstraintCreator:
+    @staticmethod
+    def create_constraint(as_dict):
+        constraint_id = as_dict.pop(CONSTRAINT_ID)
+        if constraint_id is None:
+            raise KeyError('There is no ""constraint_id"" field in deserialised dict: {}'.format(as_dict))
+
+        constraint_cls = constraint_to_class_map.get(constraint_id)
+        if AUTH_CONSTRAINTS in as_dict:",,2019-02-22 11:59:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/259236957,https://github.com/hyperledger/indy-node/pull/1179#discussion_r259236957,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1179,https://github.com/hyperledger/indy-node/pull/1179,"If there is no auth constraint defined in the config state, then we should get it from the local auth map.",beadca5e21b62765d30667275890d9fd18e334ec,2019-02-22 07:59:01,259242212,"@@ -55,9 +57,41 @@ def _find_auth_constraint_key(self, action_id, auth_map):
 
 class ConfigLedgerAuthStrategy(AbstractAuthStrategy):
 
-    def get_auth_constraint(self, action_id) -> AbstractAuthConstraint:
-        """"""Get constraints from config ledger""""""
-        pass
+    def __init__(self,
+                 auth_map,
+                 state: PruningState,
+                 serializer: AbstractConstraintSerializer,
+                 anyone_can_write_map={}):
+        super().__init__(auth_map=auth_map,
+                         anyone_can_write_map=anyone_can_write_map)
+        self.state = state
+        self.serializer = serializer
+
+    def get_auth_constraint(self, action_id: str) -> AbstractAuthConstraint:
+        """"""
+        Find rule_id for incoming action_id
+        """"""
+        if self.anyone_can_write_map:
+            am_id = self._find_auth_constraint_key(action_id, self.anyone_can_write_map)
+            if am_id:
+                return self.anyone_can_write_map.get(am_id)
+        am_id = self._find_auth_constraint_key(action_id, self.auth_map)
+        if not am_id:
+            return None
+        """"""
+        Get auth constraint from state
+        """"""
+        from_state = self.state.get(key=am_id.encode(),
+                                    isCommitted=False)
+        if not from_state:
+            raise LogicError(""There is no any auth constraints for given rule_id: {}"".format(am_id))",,2019-02-22 11:59:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/259242212,https://github.com/hyperledger/indy-node/pull/1179#discussion_r259242212,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1179,https://github.com/hyperledger/indy-node/pull/1179,We should not modify state without consensus. If a rule is not present in the config state - use local auth map instead.,beadca5e21b62765d30667275890d9fd18e334ec,2019-02-22 08:03:01,259243157,"@@ -361,3 +370,29 @@ def is_request_need_quorum(self, msg_dict: dict):
         is_force = OPERATION in msg_dict and msg_dict.get(OPERATION).get(FORCE, False)
         is_force_upgrade = str(is_force) == 'True' and txn_type == POOL_UPGRADE
         return txn_type and not is_force_upgrade and super().is_request_need_quorum(msg_dict)
+
+    @staticmethod
+    def add_auth_rules_to_config_state(state: PruningState,
+                                       auth_map: dict,
+                                       serializer: AbstractConstraintSerializer):
+        for rule_id, auth_constraint in auth_map.items():
+            serialized_key = rule_id.encode()
+            serialized_value = serializer.serialize(auth_constraint)
+            if not state.get(serialized_key, isCommitted=False):
+                state.set(serialized_key, serialized_value)
+
+    def _init_write_request_validator(self):
+        constraint_serializer = ConstraintsSerializer(domain_state_serializer)
+        config_state = self.states[CONFIG_LEDGER_ID]
+        self.add_auth_rules_to_config_state(state=config_state,",,2019-02-22 11:59:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/259243157,https://github.com/hyperledger/indy-node/pull/1179#discussion_r259243157,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1179,https://github.com/hyperledger/indy-node/pull/1179,Please move config stategy tests into a separate file,beadca5e21b62765d30667275890d9fd18e334ec,2019-02-22 08:13:18,259245542,"@@ -88,3 +110,48 @@ def test_is_accepted_for_all_new_value(is_accepted):
 def test_is_accepted_for_all(is_accepted):
     assert is_accepted(""PREFIX--TYPE--*--*--*"",
                        ""PREFIX--TYPE--FIELD--OLD_VALUE--NEW_VALUE"")
+
+
+def test_config_strategy_get_constraint_from_state(state,",,2019-02-22 11:59:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/259245542,https://github.com/hyperledger/indy-node/pull/1179#discussion_r259245542,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1172,https://github.com/hyperledger/indy-node/pull/1172,Could you please surround test file name with parentheses or make the sentence more grammatically accurate? Please make the change for all similar cases (for `stage`).,a361c4503175dd0e17c738fc10a7258911affd0a,2019-02-19 13:36:30,258040003,"@@ -94,6 +94,44 @@ def systemTests = { component ->
         sh ""docker network prune -f""
     }
 
+	def dockerSetup = { testFileName ->
+		dir(""environment/docker/pool"") {
+            stage(""Run pool ${testFileName}"") {
+                 echo ""$prefix: Running nodes...""
+                sh ""./pool_start.sh $nodesNum""
+                pool_nodes = sh(script: 'docker ps', returnStdout: true)
+                echo ""$prefix: $pool_nodes""
+            }
+
+            stage(""Ensure node services started ${testFileName}"") {",,2019-02-28 18:25:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/258040003,https://github.com/hyperledger/indy-node/pull/1172#discussion_r258040003,andkononykhin
https://github.com/hyperledger/indy-node/pull/1172,https://github.com/hyperledger/indy-node/pull/1172,Could you please surround test file name with parentheses or make the sentence more grammatically accurate? Please make the change for all similar cases (for `stage`).,a361c4503175dd0e17c738fc10a7258911affd0a,2019-02-19 13:36:50,258040120,"@@ -94,6 +94,44 @@ def systemTests = { component ->
         sh ""docker network prune -f""
     }
 
+	def dockerSetup = { testFileName ->
+		dir(""environment/docker/pool"") {
+            stage(""Run pool ${testFileName}"") {
+                 echo ""$prefix: Running nodes...""
+                sh ""./pool_start.sh $nodesNum""
+                pool_nodes = sh(script: 'docker ps', returnStdout: true)
+                echo ""$prefix: $pool_nodes""
+            }
+
+            stage(""Ensure node services started ${testFileName}"") {",,2019-02-28 18:25:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/258040120,https://github.com/hyperledger/indy-node/pull/1172#discussion_r258040120,andkononykhin
https://github.com/hyperledger/indy-node/pull/1172,https://github.com/hyperledger/indy-node/pull/1172,"Please, fix the indentation here",a361c4503175dd0e17c738fc10a7258911affd0a,2019-02-19 13:37:38,258040446,"@@ -94,6 +94,44 @@ def systemTests = { component ->
         sh ""docker network prune -f""
     }
 
+	def dockerSetup = { testFileName ->
+		dir(""environment/docker/pool"") {",,2019-02-28 18:25:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/258040446,https://github.com/hyperledger/indy-node/pull/1172#discussion_r258040446,andkononykhin
https://github.com/hyperledger/indy-node/pull/1172,https://github.com/hyperledger/indy-node/pull/1172,"please, fix the indentation here",a361c4503175dd0e17c738fc10a7258911affd0a,2019-02-19 13:38:25,258040727,"@@ -123,105 +161,76 @@ def systemTests = { component ->
             }
         }
 
-        try {
-            dir(""environment/docker/pool""){
-                stage(""Patch core dockerfile"") {
-                    // TODO update dockerfile instead of patching
-                    sh """"""
-                        sed -i 's/repo.sovrin.org\\/deb xenial .*\\+""/repo.sovrin.org\\/deb xenial $component""/g' core.ubuntu.dockerfile
-                        sed -i 's/sdk\\/deb xenial .\\+""/sdk\\/deb xenial stable""/g' core.ubuntu.dockerfile
-                        sed -i 's/\\(apt-get install -y indy-node libindy\\)/&=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile
-                        sed -i 's/\\(RUN pip3 install python3-indy\\)/&==$indySDKVersion pytest/g' core.ubuntu.dockerfile
-                    """"""
-                }
-
-                stage(""Run pool"") {
-                    echo ""$prefix: Running nodes...""
-                    sh ""./pool_start.sh $nodesNum""
-                    pool_nodes = sh(script: 'docker ps', returnStdout: true)
-                    echo ""$prefix: $pool_nodes""
-                }
-
-                stage(""Ensure node services started"") {
-                    // TODO explore and fix the reason why they (mostly Node1) not always active
-                    for (nodeNum = 1; nodeNum <= nodesNum; nodeNum++) {
-                        for (service in ['indy-node', 'indy-node-control']) {
-                            sh """"""
-                                for i in 1 2 3; do
-                                    echo ""Ensure $service on node${nodeNum} is started (try #\$i)""
-                                    docker exec -t -u 0 node${nodeNum} systemctl start $service
-                                    if [ ""\$(docker exec -u 0 node${nodeNum} systemctl is-active $service)"" = ""active"" ]; then
-                                        exit 0
-                                    fi
-                                done
-
-                                echo 'Failed to start $service on node${nodeNum}'
-                                exit 1
-                            """"""
-                        }
-                    }
-                }
-
-
-                stage(""Prepare and run client"") {
-                    sh '''
-                        sed -i 's/\\(docker exec -it\\)/#&/g' client_start.sh
-                        ./client_for_pool_start.sh
-                    '''
-                }
-            }
-
-            stage(""Prepare tests"") {
-                // https://github.com/moby/moby/issues/34096
-                // https://github.com/moby/moby/issues/34096
-                // inconsistent docker behaviour, depends on version
-                // thus, ensure ownership for copied files
-                testHelpers.getSystemTests(targetDir: './system_tests')
-                sh '''
-                    docker cp ./system_tests/system indyclient:/home/indy
-                    docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
-                    docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
-                    docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
-                '''
-            }
-
-            String testReportFileNameXml = ""system_tests_report.${component}.xml""
-            String testReportFileNamePlain = ""system_tests_report.${component}.txt""
-            try {
-                stage(""Run tests"") {
-                    sh """"""
-                        docker exec -t --user indy indyclient bash -c ""\
-                            set -o pipefail; \
-                            cd /home/indy/system && mkdir reports && \
-                            pytest -v --junit-xml=./reports/$testReportFileNameXml test_ledger.py 2>&1 | \
-                            tee ./reports/$testReportFileNamePlain""
-                    """"""
-                }
-            } finally {
-                stage(""Upload test teports"") {
-                    sh ""docker cp indyclient:/home/indy/system/reports/ ./system_tests""
-
-                    dir(""system_tests/reports""){
-                        archiveArtifacts artifacts: testReportFileNamePlain, allowEmptyArchive: true
-                        junit testResults: testReportFileNameXml, allowEmptyResults: true
-                    }
-                }
-            }
-
-        } catch (Exception exc) {
-            echo ""$prefix: fail: $exc""
-            throw exc
-        } finally {
-            stage('Cleanup') {
-                try {
-                    dockerClean()
-                } catch(Exception exc) {
-                    // pass
-                }
-
-                cleanWs()
+        stage(""Patch core dockerfile"") {
+             dir(""environment/docker/pool"") {
+                // TODO update dockerfile instead of patching
+                sh """"""
+                    sed -i 's/repo.sovrin.org\\/deb xenial .*\\+""/repo.sovrin.org\\/deb xenial $component""/g' core.ubuntu.dockerfile
+                    sed -i 's/sdk\\/deb xenial .\\+""/sdk\\/deb xenial stable""/g' core.ubuntu.dockerfile
+                    sed -i 's/\\(apt-get install -y indy-node libindy\\)/&=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile
+                    sed -i 's/\\(RUN pip3 install python3-indy\\)/&==$indySDKVersion pytest/g' core.ubuntu.dockerfile
+                """"""
             }
         }
+
+		for (testFileName in ['test_ledger.py', 'test_consensus.py', 'test_vc.py']) {
+			try {
+				stage(""Setup docker"") {
+					dockerSetup()",,2019-02-28 18:25:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/258040727,https://github.com/hyperledger/indy-node/pull/1172#discussion_r258040727,andkononykhin
https://github.com/hyperledger/indy-node/pull/1172,https://github.com/hyperledger/indy-node/pull/1172,"please, create `finally` block for outer `try` and move `cleanWs()` there",a361c4503175dd0e17c738fc10a7258911affd0a,2019-02-19 13:46:13,258043823,"@@ -123,105 +161,76 @@ def systemTests = { component ->
             }
         }
 
-        try {
-            dir(""environment/docker/pool""){
-                stage(""Patch core dockerfile"") {
-                    // TODO update dockerfile instead of patching
-                    sh """"""
-                        sed -i 's/repo.sovrin.org\\/deb xenial .*\\+""/repo.sovrin.org\\/deb xenial $component""/g' core.ubuntu.dockerfile
-                        sed -i 's/sdk\\/deb xenial .\\+""/sdk\\/deb xenial stable""/g' core.ubuntu.dockerfile
-                        sed -i 's/\\(apt-get install -y indy-node libindy\\)/&=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile
-                        sed -i 's/\\(RUN pip3 install python3-indy\\)/&==$indySDKVersion pytest/g' core.ubuntu.dockerfile
-                    """"""
-                }
-
-                stage(""Run pool"") {
-                    echo ""$prefix: Running nodes...""
-                    sh ""./pool_start.sh $nodesNum""
-                    pool_nodes = sh(script: 'docker ps', returnStdout: true)
-                    echo ""$prefix: $pool_nodes""
-                }
-
-                stage(""Ensure node services started"") {
-                    // TODO explore and fix the reason why they (mostly Node1) not always active
-                    for (nodeNum = 1; nodeNum <= nodesNum; nodeNum++) {
-                        for (service in ['indy-node', 'indy-node-control']) {
-                            sh """"""
-                                for i in 1 2 3; do
-                                    echo ""Ensure $service on node${nodeNum} is started (try #\$i)""
-                                    docker exec -t -u 0 node${nodeNum} systemctl start $service
-                                    if [ ""\$(docker exec -u 0 node${nodeNum} systemctl is-active $service)"" = ""active"" ]; then
-                                        exit 0
-                                    fi
-                                done
-
-                                echo 'Failed to start $service on node${nodeNum}'
-                                exit 1
-                            """"""
-                        }
-                    }
-                }
-
-
-                stage(""Prepare and run client"") {
-                    sh '''
-                        sed -i 's/\\(docker exec -it\\)/#&/g' client_start.sh
-                        ./client_for_pool_start.sh
-                    '''
-                }
-            }
-
-            stage(""Prepare tests"") {
-                // https://github.com/moby/moby/issues/34096
-                // https://github.com/moby/moby/issues/34096
-                // inconsistent docker behaviour, depends on version
-                // thus, ensure ownership for copied files
-                testHelpers.getSystemTests(targetDir: './system_tests')
-                sh '''
-                    docker cp ./system_tests/system indyclient:/home/indy
-                    docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
-                    docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
-                    docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
-                '''
-            }
-
-            String testReportFileNameXml = ""system_tests_report.${component}.xml""
-            String testReportFileNamePlain = ""system_tests_report.${component}.txt""
-            try {
-                stage(""Run tests"") {
-                    sh """"""
-                        docker exec -t --user indy indyclient bash -c ""\
-                            set -o pipefail; \
-                            cd /home/indy/system && mkdir reports && \
-                            pytest -v --junit-xml=./reports/$testReportFileNameXml test_ledger.py 2>&1 | \
-                            tee ./reports/$testReportFileNamePlain""
-                    """"""
-                }
-            } finally {
-                stage(""Upload test teports"") {
-                    sh ""docker cp indyclient:/home/indy/system/reports/ ./system_tests""
-
-                    dir(""system_tests/reports""){
-                        archiveArtifacts artifacts: testReportFileNamePlain, allowEmptyArchive: true
-                        junit testResults: testReportFileNameXml, allowEmptyResults: true
-                    }
-                }
-            }
-
-        } catch (Exception exc) {
-            echo ""$prefix: fail: $exc""
-            throw exc
-        } finally {
-            stage('Cleanup') {
-                try {
-                    dockerClean()
-                } catch(Exception exc) {
-                    // pass
-                }
-
-                cleanWs()
+        stage(""Patch core dockerfile"") {
+             dir(""environment/docker/pool"") {
+                // TODO update dockerfile instead of patching
+                sh """"""
+                    sed -i 's/repo.sovrin.org\\/deb xenial .*\\+""/repo.sovrin.org\\/deb xenial $component""/g' core.ubuntu.dockerfile
+                    sed -i 's/sdk\\/deb xenial .\\+""/sdk\\/deb xenial stable""/g' core.ubuntu.dockerfile
+                    sed -i 's/\\(apt-get install -y indy-node libindy\\)/&=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile
+                    sed -i 's/\\(RUN pip3 install python3-indy\\)/&==$indySDKVersion pytest/g' core.ubuntu.dockerfile
+                """"""
             }
         }
+
+		for (testFileName in ['test_ledger.py', 'test_consensus.py', 'test_vc.py']) {
+			try {
+				stage(""Setup docker"") {
+					dockerSetup()
+				}
+
+				stage(""Prepare ${testFileName}"") {
+					// https://github.com/moby/moby/issues/34096
+					// https://github.com/moby/moby/issues/34096
+					// inconsistent docker behaviour, depends on version
+					// thus, ensure ownership for copied files
+					testHelpers.getSystemTests(targetDir: './system_tests')
+					sh '''
+						docker cp ./system_tests/system/indy-node-tests indyclient:/home/indy
+						docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
+						docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
+						docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
+					'''
+				}
+
+				String testReportFileNameXml = ""system_tests_${testFileName}_report.${component}.xml""
+				String testReportFileNamePlain = ""system_tests_${testFileName}_report.${component}.txt""
+				try {
+					stage(""Run ${testFileName}"") {
+						sh """"""
+							docker exec -t --user indy indyclient bash -c ""\
+								set -o pipefail; \
+								cd /home/indy/system && mkdir reports && \
+								pytest -v --junit-xml=./reports/$testReportFileNameXml ${testFileName} 2>&1 | \
+								tee ./reports/$testReportFileNamePlain""
+						""""""
+					}
+				} finally {
+					stage(""Upload test report for ${testFileName}"") {
+						sh ""docker cp indyclient:/home/indy/system/reports/ ./system_tests""
+
+						dir(""system_tests/reports""){
+							archiveArtifacts artifacts: testReportFileNamePlain, allowEmptyArchive: true
+							junit testResults: testReportFileNameXml, allowEmptyResults: true
+						}
+					}
+				}
+
+			} catch (Exception exc) {
+				echo ""$prefix: fail: $exc""
+				throw exc
+			} finally {
+				stage('Cleanup') {
+					try {
+						dockerClean()
+					} catch(Exception exc) {
+						// pass
+					}
+
+					cleanWs()",,2019-02-28 18:25:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/258043823,https://github.com/hyperledger/indy-node/pull/1172#discussion_r258043823,andkononykhin
https://github.com/hyperledger/indy-node/pull/1172,https://github.com/hyperledger/indy-node/pull/1172,"please, remove `try-catch` (but keep `dockerClean()`) block here since we shouldn't suppress errors here anymore",a361c4503175dd0e17c738fc10a7258911affd0a,2019-02-19 13:47:19,258044379,"@@ -123,105 +161,76 @@ def systemTests = { component ->
             }
         }
 
-        try {
-            dir(""environment/docker/pool""){
-                stage(""Patch core dockerfile"") {
-                    // TODO update dockerfile instead of patching
-                    sh """"""
-                        sed -i 's/repo.sovrin.org\\/deb xenial .*\\+""/repo.sovrin.org\\/deb xenial $component""/g' core.ubuntu.dockerfile
-                        sed -i 's/sdk\\/deb xenial .\\+""/sdk\\/deb xenial stable""/g' core.ubuntu.dockerfile
-                        sed -i 's/\\(apt-get install -y indy-node libindy\\)/&=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile
-                        sed -i 's/\\(RUN pip3 install python3-indy\\)/&==$indySDKVersion pytest/g' core.ubuntu.dockerfile
-                    """"""
-                }
-
-                stage(""Run pool"") {
-                    echo ""$prefix: Running nodes...""
-                    sh ""./pool_start.sh $nodesNum""
-                    pool_nodes = sh(script: 'docker ps', returnStdout: true)
-                    echo ""$prefix: $pool_nodes""
-                }
-
-                stage(""Ensure node services started"") {
-                    // TODO explore and fix the reason why they (mostly Node1) not always active
-                    for (nodeNum = 1; nodeNum <= nodesNum; nodeNum++) {
-                        for (service in ['indy-node', 'indy-node-control']) {
-                            sh """"""
-                                for i in 1 2 3; do
-                                    echo ""Ensure $service on node${nodeNum} is started (try #\$i)""
-                                    docker exec -t -u 0 node${nodeNum} systemctl start $service
-                                    if [ ""\$(docker exec -u 0 node${nodeNum} systemctl is-active $service)"" = ""active"" ]; then
-                                        exit 0
-                                    fi
-                                done
-
-                                echo 'Failed to start $service on node${nodeNum}'
-                                exit 1
-                            """"""
-                        }
-                    }
-                }
-
-
-                stage(""Prepare and run client"") {
-                    sh '''
-                        sed -i 's/\\(docker exec -it\\)/#&/g' client_start.sh
-                        ./client_for_pool_start.sh
-                    '''
-                }
-            }
-
-            stage(""Prepare tests"") {
-                // https://github.com/moby/moby/issues/34096
-                // https://github.com/moby/moby/issues/34096
-                // inconsistent docker behaviour, depends on version
-                // thus, ensure ownership for copied files
-                testHelpers.getSystemTests(targetDir: './system_tests')
-                sh '''
-                    docker cp ./system_tests/system indyclient:/home/indy
-                    docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
-                    docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
-                    docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
-                '''
-            }
-
-            String testReportFileNameXml = ""system_tests_report.${component}.xml""
-            String testReportFileNamePlain = ""system_tests_report.${component}.txt""
-            try {
-                stage(""Run tests"") {
-                    sh """"""
-                        docker exec -t --user indy indyclient bash -c ""\
-                            set -o pipefail; \
-                            cd /home/indy/system && mkdir reports && \
-                            pytest -v --junit-xml=./reports/$testReportFileNameXml test_ledger.py 2>&1 | \
-                            tee ./reports/$testReportFileNamePlain""
-                    """"""
-                }
-            } finally {
-                stage(""Upload test teports"") {
-                    sh ""docker cp indyclient:/home/indy/system/reports/ ./system_tests""
-
-                    dir(""system_tests/reports""){
-                        archiveArtifacts artifacts: testReportFileNamePlain, allowEmptyArchive: true
-                        junit testResults: testReportFileNameXml, allowEmptyResults: true
-                    }
-                }
-            }
-
-        } catch (Exception exc) {
-            echo ""$prefix: fail: $exc""
-            throw exc
-        } finally {
-            stage('Cleanup') {
-                try {
-                    dockerClean()
-                } catch(Exception exc) {
-                    // pass
-                }
-
-                cleanWs()
+        stage(""Patch core dockerfile"") {
+             dir(""environment/docker/pool"") {
+                // TODO update dockerfile instead of patching
+                sh """"""
+                    sed -i 's/repo.sovrin.org\\/deb xenial .*\\+""/repo.sovrin.org\\/deb xenial $component""/g' core.ubuntu.dockerfile
+                    sed -i 's/sdk\\/deb xenial .\\+""/sdk\\/deb xenial stable""/g' core.ubuntu.dockerfile
+                    sed -i 's/\\(apt-get install -y indy-node libindy\\)/&=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile
+                    sed -i 's/\\(RUN pip3 install python3-indy\\)/&==$indySDKVersion pytest/g' core.ubuntu.dockerfile
+                """"""
             }
         }
+
+		for (testFileName in ['test_ledger.py', 'test_consensus.py', 'test_vc.py']) {
+			try {
+				stage(""Setup docker"") {
+					dockerSetup()
+				}
+
+				stage(""Prepare ${testFileName}"") {
+					// https://github.com/moby/moby/issues/34096
+					// https://github.com/moby/moby/issues/34096
+					// inconsistent docker behaviour, depends on version
+					// thus, ensure ownership for copied files
+					testHelpers.getSystemTests(targetDir: './system_tests')
+					sh '''
+						docker cp ./system_tests/system/indy-node-tests indyclient:/home/indy
+						docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
+						docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
+						docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
+					'''
+				}
+
+				String testReportFileNameXml = ""system_tests_${testFileName}_report.${component}.xml""
+				String testReportFileNamePlain = ""system_tests_${testFileName}_report.${component}.txt""
+				try {
+					stage(""Run ${testFileName}"") {
+						sh """"""
+							docker exec -t --user indy indyclient bash -c ""\
+								set -o pipefail; \
+								cd /home/indy/system && mkdir reports && \
+								pytest -v --junit-xml=./reports/$testReportFileNameXml ${testFileName} 2>&1 | \
+								tee ./reports/$testReportFileNamePlain""
+						""""""
+					}
+				} finally {
+					stage(""Upload test report for ${testFileName}"") {
+						sh ""docker cp indyclient:/home/indy/system/reports/ ./system_tests""
+
+						dir(""system_tests/reports""){
+							archiveArtifacts artifacts: testReportFileNamePlain, allowEmptyArchive: true
+							junit testResults: testReportFileNameXml, allowEmptyResults: true
+						}
+					}
+				}
+
+			} catch (Exception exc) {
+				echo ""$prefix: fail: $exc""
+				throw exc
+			} finally {
+				stage('Cleanup') {
+					try {
+						dockerClean()
+					} catch(Exception exc) {",,2019-02-28 18:25:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/258044379,https://github.com/hyperledger/indy-node/pull/1172#discussion_r258044379,andkononykhin
https://github.com/hyperledger/indy-node/pull/1172,https://github.com/hyperledger/indy-node/pull/1172,Are we going to keep all tests in that (`system`) directory?,a361c4503175dd0e17c738fc10a7258911affd0a,2019-02-19 13:51:14,258045961,"@@ -123,105 +161,76 @@ def systemTests = { component ->
             }
         }
 
-        try {
-            dir(""environment/docker/pool""){
-                stage(""Patch core dockerfile"") {
-                    // TODO update dockerfile instead of patching
-                    sh """"""
-                        sed -i 's/repo.sovrin.org\\/deb xenial .*\\+""/repo.sovrin.org\\/deb xenial $component""/g' core.ubuntu.dockerfile
-                        sed -i 's/sdk\\/deb xenial .\\+""/sdk\\/deb xenial stable""/g' core.ubuntu.dockerfile
-                        sed -i 's/\\(apt-get install -y indy-node libindy\\)/&=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile
-                        sed -i 's/\\(RUN pip3 install python3-indy\\)/&==$indySDKVersion pytest/g' core.ubuntu.dockerfile
-                    """"""
-                }
-
-                stage(""Run pool"") {
-                    echo ""$prefix: Running nodes...""
-                    sh ""./pool_start.sh $nodesNum""
-                    pool_nodes = sh(script: 'docker ps', returnStdout: true)
-                    echo ""$prefix: $pool_nodes""
-                }
-
-                stage(""Ensure node services started"") {
-                    // TODO explore and fix the reason why they (mostly Node1) not always active
-                    for (nodeNum = 1; nodeNum <= nodesNum; nodeNum++) {
-                        for (service in ['indy-node', 'indy-node-control']) {
-                            sh """"""
-                                for i in 1 2 3; do
-                                    echo ""Ensure $service on node${nodeNum} is started (try #\$i)""
-                                    docker exec -t -u 0 node${nodeNum} systemctl start $service
-                                    if [ ""\$(docker exec -u 0 node${nodeNum} systemctl is-active $service)"" = ""active"" ]; then
-                                        exit 0
-                                    fi
-                                done
-
-                                echo 'Failed to start $service on node${nodeNum}'
-                                exit 1
-                            """"""
-                        }
-                    }
-                }
-
-
-                stage(""Prepare and run client"") {
-                    sh '''
-                        sed -i 's/\\(docker exec -it\\)/#&/g' client_start.sh
-                        ./client_for_pool_start.sh
-                    '''
-                }
-            }
-
-            stage(""Prepare tests"") {
-                // https://github.com/moby/moby/issues/34096
-                // https://github.com/moby/moby/issues/34096
-                // inconsistent docker behaviour, depends on version
-                // thus, ensure ownership for copied files
-                testHelpers.getSystemTests(targetDir: './system_tests')
-                sh '''
-                    docker cp ./system_tests/system indyclient:/home/indy
-                    docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
-                    docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
-                    docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
-                '''
-            }
-
-            String testReportFileNameXml = ""system_tests_report.${component}.xml""
-            String testReportFileNamePlain = ""system_tests_report.${component}.txt""
-            try {
-                stage(""Run tests"") {
-                    sh """"""
-                        docker exec -t --user indy indyclient bash -c ""\
-                            set -o pipefail; \
-                            cd /home/indy/system && mkdir reports && \
-                            pytest -v --junit-xml=./reports/$testReportFileNameXml test_ledger.py 2>&1 | \
-                            tee ./reports/$testReportFileNamePlain""
-                    """"""
-                }
-            } finally {
-                stage(""Upload test teports"") {
-                    sh ""docker cp indyclient:/home/indy/system/reports/ ./system_tests""
-
-                    dir(""system_tests/reports""){
-                        archiveArtifacts artifacts: testReportFileNamePlain, allowEmptyArchive: true
-                        junit testResults: testReportFileNameXml, allowEmptyResults: true
-                    }
-                }
-            }
-
-        } catch (Exception exc) {
-            echo ""$prefix: fail: $exc""
-            throw exc
-        } finally {
-            stage('Cleanup') {
-                try {
-                    dockerClean()
-                } catch(Exception exc) {
-                    // pass
-                }
-
-                cleanWs()
+        stage(""Patch core dockerfile"") {
+             dir(""environment/docker/pool"") {
+                // TODO update dockerfile instead of patching
+                sh """"""
+                    sed -i 's/repo.sovrin.org\\/deb xenial .*\\+""/repo.sovrin.org\\/deb xenial $component""/g' core.ubuntu.dockerfile
+                    sed -i 's/sdk\\/deb xenial .\\+""/sdk\\/deb xenial stable""/g' core.ubuntu.dockerfile
+                    sed -i 's/\\(apt-get install -y indy-node libindy\\)/&=$indySDKVersion python3-indy-crypto=$indyCryptoVersion libindy-crypto=$indyCryptoVersion/g' core.ubuntu.dockerfile
+                    sed -i 's/\\(RUN pip3 install python3-indy\\)/&==$indySDKVersion pytest/g' core.ubuntu.dockerfile
+                """"""
             }
         }
+
+		for (testFileName in ['test_ledger.py', 'test_consensus.py', 'test_vc.py']) {
+			try {
+				stage(""Setup docker"") {
+					dockerSetup()
+				}
+
+				stage(""Prepare ${testFileName}"") {
+					// https://github.com/moby/moby/issues/34096
+					// https://github.com/moby/moby/issues/34096
+					// inconsistent docker behaviour, depends on version
+					// thus, ensure ownership for copied files
+					testHelpers.getSystemTests(targetDir: './system_tests')
+					sh '''
+						docker cp ./system_tests/system/indy-node-tests indyclient:/home/indy
+						docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis ./
+						docker cp ./pool_transactions_genesis indyclient:/home/indy/system/docker_genesis
+						docker exec -t -u 0 indyclient chown -R indy:indy /home/indy/system
+					'''
+				}
+
+				String testReportFileNameXml = ""system_tests_${testFileName}_report.${component}.xml""
+				String testReportFileNamePlain = ""system_tests_${testFileName}_report.${component}.txt""
+				try {
+					stage(""Run ${testFileName}"") {
+						sh """"""
+							docker exec -t --user indy indyclient bash -c ""\
+								set -o pipefail; \
+								cd /home/indy/system && mkdir reports && \",,2019-02-28 18:25:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/258045961,https://github.com/hyperledger/indy-node/pull/1172#discussion_r258045961,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,What is the case when we fallback to this?,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-13 06:55:59,264993722,"@@ -0,0 +1,54 @@
+from typing import Iterable
+
+try:
+    from common.version import (
+        InvalidVersionError, PEP440BasedVersion, SemVerBase,
+        DigitDotVersion, SourceVersion, PackageVersion
+    )
+except ImportError:
+    from indy_common.version_fallback import (",,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/264993722,https://github.com/hyperledger/indy-node/pull/1171#discussion_r264993722,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,What is the case when we use it in a raw env?,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-13 07:23:43,264999301,"@@ -0,0 +1,282 @@
+# TODO it's a copy-paste of common.version:
+# remove once plenum is merged to node
+# !!! do not try to import from plenum since that code might be
+# called (imported) in raw env from metadata routine where",,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/264999301,https://github.com/hyperledger/indy-node/pull/1171#discussion_r264999301,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,"Is it fully compatible with the current action_log?
What is the main reason for re-factoring of this class?",9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-13 07:50:43,265005578,"@@ -1,62 +1,196 @@
 import csv
-from abc import ABCMeta
-from datetime import datetime
-from os import path
+import io
+import os
+import datetime
+import functools
+from typing import Type, Union, Tuple
+from enum import Enum, unique
+from dateutil.parser import parse as parse_dt
 
-from dateutil.parser import parse as parse_date
+# TODO
+#  - move csv serializer to separate module
 
 ",17,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265005578,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265005578,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,"This may be a matter of taste, but I would prefer explicit methods. If methods number and logic depends on parameter (event type). then maybe it's sufficient just to have `append(event_type, ...)` method.
BTW are dynamically created methods shown and checked in IDE as suggestions?",9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-13 09:36:09,265040158,"@@ -1,62 +1,196 @@
 import csv
-from abc import ABCMeta
-from datetime import datetime
-from os import path
+import io
+import os
+import datetime
+import functools
+from typing import Type, Union, Tuple
+from enum import Enum, unique
+from dateutil.parser import parse as parse_dt
 
-from dateutil.parser import parse as parse_date
+# TODO
+#  - move csv serializer to separate module
 
 
-class ActionLog(metaclass=ABCMeta):
+class CsvSerializer:
+    _items = []
+
+    def __iter__(self):
+        for item in self._items:
+            yield getattr(self, item)
+
+    def pack(self, delimiter: str = '\t'):
+        with io.StringIO() as fs:
+            csv.writer(fs, delimiter=delimiter).writerow(self)
+            return fs.getvalue()
+
+    @classmethod
+    def unpack(cls, row: str, *args, delimiter: str = '\t', **kwargs):
+        reader = csv.reader([row], delimiter=delimiter)
+        return cls(*next(reader), *args, **kwargs)
+
+    def __eq__(self, other):
+        return self.__dict__ == other.__dict__
+
+    def __ne__(self, other):
+        return not self == other
+
+    def __repr__(self):
+        return str(self.__dict__)
+
+
+class ActionLogData(CsvSerializer):
+    _items = ['when']
+
+    def __init__(self, when: Union[datetime.datetime, str]):
+        if isinstance(when, str):
+            when = parse_dt(when)
+        if not isinstance(when, datetime.datetime):
+            raise TypeError(
+                ""'when' should be 'datetime' or 'str', got: {}""
+                .format(type(when))
+            )
+        self.when = when
+
+
+@unique
+class ActionLogEvents(Enum):
+    scheduled = 1
+    started = 2
+    succeeded = 3
+    failed = 4
+    cancelled = 5
+
+    def __str__(self):
+        return self.name
+
+
+# Note. datetime class is referred not directly (through datetime module)
+# since it makes possible to mock it in tests using subclasses
+class ActionLogEvent(CsvSerializer):
+    def __init__(
+            self,
+            ts: Union[datetime.datetime, str],
+            ev_type: Enum,
+            data: Type[Union[CsvSerializer, str]],
+            *args: Tuple[str],
+            data_class: Type[Union[CsvSerializer, None]] = None,
+            types: Type[Enum] = ActionLogEvents
+    ):
+        if ts:
+            if isinstance(ts, str):
+                ts = parse_dt(ts)
+            if not isinstance(ts, datetime.datetime):
+                raise TypeError(
+                    ""'ts' should be 'datetime' or None, got: {}""
+                    .format(type(ts))
+                )
+
+        if isinstance(ev_type, str):
+            try:
+                ev_type = types[ev_type]
+            except KeyError:
+                raise ValueError(""Unknown event {}""
+                                 .format(ev_type))
+
+        if not isinstance(ev_type, Enum):
+            raise TypeError(
+                ""'ev_type' should be 'Enum', got: {}""
+                .format(type(ts))
+            )
+
+        if ev_type not in types:
+            raise ValueError(""Unknown event {}"".format(ev_type))
+
+        data = data_class(data, *args) if data_class else data
+        if not isinstance(data, CsvSerializer):
+            raise TypeError(
+                ""'data' should be 'CsvSerializer', got: {}""
+                .format(type(data))
+            )
+
+        self.ts = ts if ts else datetime.datetime.utcnow()
+        self.ev_type = ev_type
+        self.data = data
+
+        self._data_items_prefix = '_data_'
+        self._items = (
+            ['ts', 'ev_type'] +
+            [(self._data_items_prefix + i) for i in self.data._items]
+        )
+        pass
+
+    def __getattr__(self, name):
+        try:
+            _name = name.split(self._data_items_prefix)[1]
+        except IndexError:
+            raise AttributeError
+        else:
+            return getattr(self.data, _name)
+
+
+class ActionLog:
     """"""
     Append-only event log of action event
     """"""
 
-    SCHEDULED = ""scheduled""
-    STARTED = ""started""
-    SUCCEEDED = ""succeeded""
-    FAILED = ""failed""
-    CANCELLED = ""cancelled""
-
-    def __init__(self, filePath, delimiter=""\t""):
-        self.__delimiter = delimiter
-        self.__filePath = filePath
-        self.__items = []
+    def __init__(
+            self,
+            file_path: str,
+            data_class: Type[CsvSerializer] = ActionLogData,
+            event_types: Type[Enum] = ActionLogEvents,
+            delimiter: str ='\t'
+    ):
+        self._delimiter = delimiter
+        self._file_path = file_path
+        self._items = []
+        self._data_class = data_class
+        self._event_types = event_types
         self._load()
 
+        for ev_type in self._event_types:",165,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265040158,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265040158,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,"Is it used in migration scripts, or in migration tool?",9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-13 09:38:55,265041361,"@@ -51,67 +59,51 @@ def get_action_id(txn):
             seq_no = ''
         return '{}{}'.format(get_req_id(txn), seq_no)
 
+    # implements legacy logic used only by migration logic,
+    # please use Version classes in code instead
+    # TODO refactor migration logic to get rid of that API usage",54,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265041361,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265041361,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,Why do we need this?,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-13 11:36:10,265084899,"@@ -26,6 +34,131 @@ def decode_err_handler(error):
 MAX_DEPS_DEPTH = 6
 
 
+class ShellError(subprocess.CalledProcessError):
+    def __init__(self, *args, exc: subprocess.CalledProcessError = None, **kwargs):
+        if exc:
+            super().__init__(exc.returncode, exc.cmd, output=exc.output, stderr=exc.stderr)
+        else:
+            super().__init__(*args, **kwargs)
+
+    @property
+    def stdout_decoded(self):
+        return (self.stdout.decode(locale.getpreferredencoding(), 'decode_errors')
+                if self.stdout else """")
+
+    @property
+    def stderr_decoded(self):
+        return (self.stdout.decode(locale.getpreferredencoding(), 'decode_errors')
+                if self.stderr else """")
+
+
+# TODO use some library instead of dpkg fpr version routine
+class DebianVersion(PackageVersion):
+    cache = {}  # seems not actually necessary
+    # https://www.debian.org/doc/debian-policy/ch-controlfields.html#version
+    re_version = re.compile(r'(?:([0-9]):)?([0-9][a-zA-Z0-9.+\-~]*)')
+
+    @classmethod
+    def _cmp(cls, v1, v2):
+        if v1 == v2:
+            return 0
+        else:
+            cmd = compose_cmd(['dpkg', '--compare-versions', v1, 'gt', v2])
+            try:
+                NodeControlUtil.run_shell_script(cmd)
+            except ShellError as exc:
+                if exc.stderr:
+                    raise
+                else:
+                    return -1
+            else:
+                return 1
+
+    @classmethod
+    def cmp(cls, v1, v2):
+        key = (v1.full, v2.full)
+        if key not in cls.cache:
+            cls.cache[key] = cls._cmp(*key)
+            cls.cache[key[::-1]] = cls.cache[key] * (-1)",66,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265084899,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265084899,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,Do we have tests where upstream is specified?,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-13 11:45:26,265087740,"@@ -82,22 +226,93 @@ def _pkts_dedup(cls, deps):
         return ret
 
     @classmethod
-    def _parse_version_deps_from_pkt_mgr_output(cls, output):
+    def _parse_version_deps_from_pkg_mgr_output(
+            cls,
+            output: str,
+            upstream_cls: Type[Union[SourceVersion, None]] = None
+    ):
         out_lines = output.split(""\n"")
         ver = None
         ext_deps = []
+        num_pkgs = 0
         for ln in out_lines:
             act_line = ln.strip("" \n"")
             if act_line.startswith(""Version:""):
-                ver = ver or act_line.split("":"", maxsplit=1)[1].strip("" \n"")
+                # this method might be used for the dependnecy tree resolving
+                # when 'output' includes data for multiple packages,
+                # version info here doesn't make any sense in such a case
+                num_pkgs += 1
+                ver = (None if num_pkgs > 1 else
+                       act_line.split("":"", maxsplit=1)[1].strip("" \n""))
             if act_line.startswith(""Depends:""):
                 ext_deps += cls._parse_deps(act_line.split("":"", maxsplit=1)[1].strip("" \n""))
-        return ver, cls._pkts_dedup(ext_deps)
+
+        if ver and upstream_cls:
+            try:
+                ver = DebianVersion(ver, upstream_cls=upstream_cls)
+            except InvalidVersionError as exc:
+                logger.warning(
+                    ""Failed to parse debian version {}: {}""
+                    .format(ver, exc)
+                )
+                ver = None
+                ext_deps = []
+        else:
+            ver = None
+
+        return ver, cls._pkgs_dedup(ext_deps)
 
     @classmethod
-    def curr_pkt_info(cls, pkg_name):
+    def curr_pkg_info(cls, pkg_name: str) -> Tuple[PackageVersion, List]:
         package_info = cls._get_curr_info(pkg_name)
-        return cls._parse_version_deps_from_pkt_mgr_output(package_info)
+        return cls._parse_version_deps_from_pkg_mgr_output(
+            package_info, upstream_cls=src_version_cls(pkg_name))
+
+    @classmethod
+    def get_latest_pkg_version(
+            cls,
+            pkg_name: str,
+            upstream: SourceVersion = None,",242,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265087740,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265087740,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,"Why did we change it? I think we have `run_shell_command`, and, `run_shell_script` should be used when when we are not interested in the output (see comments above)",9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-13 11:48:38,265088794,"@@ -45,8 +178,17 @@ def run_shell_command(cls, command, timeout=TIMEOUT):
     # Method is used in case we are NOT interested in command output
     # everything: command, errors, output etc are logged to journalctl
     @classmethod
-    def run_shell_script(cls, command, timeout=TIMEOUT):
-        subprocess.run(command, shell=True, timeout=timeout, check=True)
+    def run_shell_script(cls, command, stdout=False, stderr=False,",,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265088794,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265088794,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,e.g. `pip install .`,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 10:22:42,265501701,"@@ -0,0 +1,54 @@
+from typing import Iterable
+
+try:
+    from common.version import (
+        InvalidVersionError, PEP440BasedVersion, SemVerBase,
+        DigitDotVersion, SourceVersion, PackageVersion
+    )
+except ImportError:
+    from indy_common.version_fallback import (",,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265501701,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265501701,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,"yes:

- ` indy_node/test/upgrade/test_upgrade_log.py::test_upgrade_log_loads_legacy_data`
- `indy_node/test/upgrade/test_restart_log.py::test_restart_log_loads_legacy_data`

reason: to operate with objects instead of raw strings after initial parsing (data from extrenal sources, e.g. io)",9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 10:26:41,265503255,"@@ -1,62 +1,196 @@
 import csv
-from abc import ABCMeta
-from datetime import datetime
-from os import path
+import io
+import os
+import datetime
+import functools
+from typing import Type, Union, Tuple
+from enum import Enum, unique
+from dateutil.parser import parse as parse_dt
 
-from dateutil.parser import parse as parse_date
+# TODO
+#  - move csv serializer to separate module
 
 ",17,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265503255,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265503255,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,"explicit methods here can't satisfy the constructor API since it accepts any Enum, as a trade-off I can add explicit ones in child classes where enum for types becomes defined",9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 10:29:23,265504328,"@@ -1,62 +1,196 @@
 import csv
-from abc import ABCMeta
-from datetime import datetime
-from os import path
+import io
+import os
+import datetime
+import functools
+from typing import Type, Union, Tuple
+from enum import Enum, unique
+from dateutil.parser import parse as parse_dt
 
-from dateutil.parser import parse as parse_date
+# TODO
+#  - move csv serializer to separate module
 
 
-class ActionLog(metaclass=ABCMeta):
+class CsvSerializer:
+    _items = []
+
+    def __iter__(self):
+        for item in self._items:
+            yield getattr(self, item)
+
+    def pack(self, delimiter: str = '\t'):
+        with io.StringIO() as fs:
+            csv.writer(fs, delimiter=delimiter).writerow(self)
+            return fs.getvalue()
+
+    @classmethod
+    def unpack(cls, row: str, *args, delimiter: str = '\t', **kwargs):
+        reader = csv.reader([row], delimiter=delimiter)
+        return cls(*next(reader), *args, **kwargs)
+
+    def __eq__(self, other):
+        return self.__dict__ == other.__dict__
+
+    def __ne__(self, other):
+        return not self == other
+
+    def __repr__(self):
+        return str(self.__dict__)
+
+
+class ActionLogData(CsvSerializer):
+    _items = ['when']
+
+    def __init__(self, when: Union[datetime.datetime, str]):
+        if isinstance(when, str):
+            when = parse_dt(when)
+        if not isinstance(when, datetime.datetime):
+            raise TypeError(
+                ""'when' should be 'datetime' or 'str', got: {}""
+                .format(type(when))
+            )
+        self.when = when
+
+
+@unique
+class ActionLogEvents(Enum):
+    scheduled = 1
+    started = 2
+    succeeded = 3
+    failed = 4
+    cancelled = 5
+
+    def __str__(self):
+        return self.name
+
+
+# Note. datetime class is referred not directly (through datetime module)
+# since it makes possible to mock it in tests using subclasses
+class ActionLogEvent(CsvSerializer):
+    def __init__(
+            self,
+            ts: Union[datetime.datetime, str],
+            ev_type: Enum,
+            data: Type[Union[CsvSerializer, str]],
+            *args: Tuple[str],
+            data_class: Type[Union[CsvSerializer, None]] = None,
+            types: Type[Enum] = ActionLogEvents
+    ):
+        if ts:
+            if isinstance(ts, str):
+                ts = parse_dt(ts)
+            if not isinstance(ts, datetime.datetime):
+                raise TypeError(
+                    ""'ts' should be 'datetime' or None, got: {}""
+                    .format(type(ts))
+                )
+
+        if isinstance(ev_type, str):
+            try:
+                ev_type = types[ev_type]
+            except KeyError:
+                raise ValueError(""Unknown event {}""
+                                 .format(ev_type))
+
+        if not isinstance(ev_type, Enum):
+            raise TypeError(
+                ""'ev_type' should be 'Enum', got: {}""
+                .format(type(ts))
+            )
+
+        if ev_type not in types:
+            raise ValueError(""Unknown event {}"".format(ev_type))
+
+        data = data_class(data, *args) if data_class else data
+        if not isinstance(data, CsvSerializer):
+            raise TypeError(
+                ""'data' should be 'CsvSerializer', got: {}""
+                .format(type(data))
+            )
+
+        self.ts = ts if ts else datetime.datetime.utcnow()
+        self.ev_type = ev_type
+        self.data = data
+
+        self._data_items_prefix = '_data_'
+        self._items = (
+            ['ts', 'ev_type'] +
+            [(self._data_items_prefix + i) for i in self.data._items]
+        )
+        pass
+
+    def __getattr__(self, name):
+        try:
+            _name = name.split(self._data_items_prefix)[1]
+        except IndexError:
+            raise AttributeError
+        else:
+            return getattr(self.data, _name)
+
+
+class ActionLog:
     """"""
     Append-only event log of action event
     """"""
 
-    SCHEDULED = ""scheduled""
-    STARTED = ""started""
-    SUCCEEDED = ""succeeded""
-    FAILED = ""failed""
-    CANCELLED = ""cancelled""
-
-    def __init__(self, filePath, delimiter=""\t""):
-        self.__delimiter = delimiter
-        self.__filePath = filePath
-        self.__items = []
+    def __init__(
+            self,
+            file_path: str,
+            data_class: Type[CsvSerializer] = ActionLogData,
+            event_types: Type[Enum] = ActionLogEvents,
+            delimiter: str ='\t'
+    ):
+        self._delimiter = delimiter
+        self._file_path = file_path
+        self._items = []
+        self._data_class = data_class
+        self._event_types = event_types
         self._load()
 
+        for ev_type in self._event_types:",165,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265504328,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265504328,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,to reduce number of shell calls since for now we don't have python library API (and don't implement our custom logic) to perform such comparison gently,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 10:31:50,265505286,"@@ -26,6 +34,131 @@ def decode_err_handler(error):
 MAX_DEPS_DEPTH = 6
 
 
+class ShellError(subprocess.CalledProcessError):
+    def __init__(self, *args, exc: subprocess.CalledProcessError = None, **kwargs):
+        if exc:
+            super().__init__(exc.returncode, exc.cmd, output=exc.output, stderr=exc.stderr)
+        else:
+            super().__init__(*args, **kwargs)
+
+    @property
+    def stdout_decoded(self):
+        return (self.stdout.decode(locale.getpreferredencoding(), 'decode_errors')
+                if self.stdout else """")
+
+    @property
+    def stderr_decoded(self):
+        return (self.stdout.decode(locale.getpreferredencoding(), 'decode_errors')
+                if self.stderr else """")
+
+
+# TODO use some library instead of dpkg fpr version routine
+class DebianVersion(PackageVersion):
+    cache = {}  # seems not actually necessary
+    # https://www.debian.org/doc/debian-policy/ch-controlfields.html#version
+    re_version = re.compile(r'(?:([0-9]):)?([0-9][a-zA-Z0-9.+\-~]*)')
+
+    @classmethod
+    def _cmp(cls, v1, v2):
+        if v1 == v2:
+            return 0
+        else:
+            cmd = compose_cmd(['dpkg', '--compare-versions', v1, 'gt', v2])
+            try:
+                NodeControlUtil.run_shell_script(cmd)
+            except ShellError as exc:
+                if exc.stderr:
+                    raise
+                else:
+                    return -1
+            else:
+                return 1
+
+    @classmethod
+    def cmp(cls, v1, v2):
+        key = (v1.full, v2.full)
+        if key not in cls.cache:
+            cls.cache[key] = cls._cmp(*key)
+            cls.cache[key[::-1]] = cls.cache[key] * (-1)",66,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265505286,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265505286,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,"sometimes we expect both stdout/stderr and shell errors exceptions, neither `run_shell_command` nor `run_shell_script` provided such functionality. I will move new logic to separate API to keep these well tested ones.",9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 10:34:05,265506171,"@@ -45,8 +178,17 @@ def run_shell_command(cls, command, timeout=TIMEOUT):
     # Method is used in case we are NOT interested in command output
     # everything: command, errors, output etc are logged to journalctl
     @classmethod
-    def run_shell_script(cls, command, timeout=TIMEOUT):
-        subprocess.run(command, shell=True, timeout=timeout, check=True)
+    def run_shell_script(cls, command, stdout=False, stderr=False,",,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265506171,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265506171,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,"`indy_node/test/node_control_utils/test_node_control_util.py::test_generated_cmd_get_latest_pkg_version` it checks generated shell command when `upstream` is specified, further logic doesn't depend on `upstream`",9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 10:54:42,265513857,"@@ -82,22 +226,93 @@ def _pkts_dedup(cls, deps):
         return ret
 
     @classmethod
-    def _parse_version_deps_from_pkt_mgr_output(cls, output):
+    def _parse_version_deps_from_pkg_mgr_output(
+            cls,
+            output: str,
+            upstream_cls: Type[Union[SourceVersion, None]] = None
+    ):
         out_lines = output.split(""\n"")
         ver = None
         ext_deps = []
+        num_pkgs = 0
         for ln in out_lines:
             act_line = ln.strip("" \n"")
             if act_line.startswith(""Version:""):
-                ver = ver or act_line.split("":"", maxsplit=1)[1].strip("" \n"")
+                # this method might be used for the dependnecy tree resolving
+                # when 'output' includes data for multiple packages,
+                # version info here doesn't make any sense in such a case
+                num_pkgs += 1
+                ver = (None if num_pkgs > 1 else
+                       act_line.split("":"", maxsplit=1)[1].strip("" \n""))
             if act_line.startswith(""Depends:""):
                 ext_deps += cls._parse_deps(act_line.split("":"", maxsplit=1)[1].strip("" \n""))
-        return ver, cls._pkts_dedup(ext_deps)
+
+        if ver and upstream_cls:
+            try:
+                ver = DebianVersion(ver, upstream_cls=upstream_cls)
+            except InvalidVersionError as exc:
+                logger.warning(
+                    ""Failed to parse debian version {}: {}""
+                    .format(ver, exc)
+                )
+                ver = None
+                ext_deps = []
+        else:
+            ver = None
+
+        return ver, cls._pkgs_dedup(ext_deps)
 
     @classmethod
-    def curr_pkt_info(cls, pkg_name):
+    def curr_pkg_info(cls, pkg_name: str) -> Tuple[PackageVersion, List]:
         package_info = cls._get_curr_info(pkg_name)
-        return cls._parse_version_deps_from_pkt_mgr_output(package_info)
+        return cls._parse_version_deps_from_pkg_mgr_output(
+            package_info, upstream_cls=src_version_cls(pkg_name))
+
+    @classmethod
+    def get_latest_pkg_version(
+            cls,
+            pkg_name: str,
+            upstream: SourceVersion = None,",242,2019-03-14 11:17:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265513857,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265513857,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,e.g. `pip install .` or run `bump_version.sh`,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 11:18:15,265521670,"@@ -0,0 +1,282 @@
+# TODO it's a copy-paste of common.version:
+# remove once plenum is merged to node
+# !!! do not try to import from plenum since that code might be
+# called (imported) in raw env from metadata routine where",,2019-03-14 11:18:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265521670,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265521670,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,done,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 11:18:28,265521732,"@@ -1,62 +1,196 @@
 import csv
-from abc import ABCMeta
-from datetime import datetime
-from os import path
+import io
+import os
+import datetime
+import functools
+from typing import Type, Union, Tuple
+from enum import Enum, unique
+from dateutil.parser import parse as parse_dt
 
-from dateutil.parser import parse as parse_date
+# TODO
+#  - move csv serializer to separate module
 
 
-class ActionLog(metaclass=ABCMeta):
+class CsvSerializer:
+    _items = []
+
+    def __iter__(self):
+        for item in self._items:
+            yield getattr(self, item)
+
+    def pack(self, delimiter: str = '\t'):
+        with io.StringIO() as fs:
+            csv.writer(fs, delimiter=delimiter).writerow(self)
+            return fs.getvalue()
+
+    @classmethod
+    def unpack(cls, row: str, *args, delimiter: str = '\t', **kwargs):
+        reader = csv.reader([row], delimiter=delimiter)
+        return cls(*next(reader), *args, **kwargs)
+
+    def __eq__(self, other):
+        return self.__dict__ == other.__dict__
+
+    def __ne__(self, other):
+        return not self == other
+
+    def __repr__(self):
+        return str(self.__dict__)
+
+
+class ActionLogData(CsvSerializer):
+    _items = ['when']
+
+    def __init__(self, when: Union[datetime.datetime, str]):
+        if isinstance(when, str):
+            when = parse_dt(when)
+        if not isinstance(when, datetime.datetime):
+            raise TypeError(
+                ""'when' should be 'datetime' or 'str', got: {}""
+                .format(type(when))
+            )
+        self.when = when
+
+
+@unique
+class ActionLogEvents(Enum):
+    scheduled = 1
+    started = 2
+    succeeded = 3
+    failed = 4
+    cancelled = 5
+
+    def __str__(self):
+        return self.name
+
+
+# Note. datetime class is referred not directly (through datetime module)
+# since it makes possible to mock it in tests using subclasses
+class ActionLogEvent(CsvSerializer):
+    def __init__(
+            self,
+            ts: Union[datetime.datetime, str],
+            ev_type: Enum,
+            data: Type[Union[CsvSerializer, str]],
+            *args: Tuple[str],
+            data_class: Type[Union[CsvSerializer, None]] = None,
+            types: Type[Enum] = ActionLogEvents
+    ):
+        if ts:
+            if isinstance(ts, str):
+                ts = parse_dt(ts)
+            if not isinstance(ts, datetime.datetime):
+                raise TypeError(
+                    ""'ts' should be 'datetime' or None, got: {}""
+                    .format(type(ts))
+                )
+
+        if isinstance(ev_type, str):
+            try:
+                ev_type = types[ev_type]
+            except KeyError:
+                raise ValueError(""Unknown event {}""
+                                 .format(ev_type))
+
+        if not isinstance(ev_type, Enum):
+            raise TypeError(
+                ""'ev_type' should be 'Enum', got: {}""
+                .format(type(ts))
+            )
+
+        if ev_type not in types:
+            raise ValueError(""Unknown event {}"".format(ev_type))
+
+        data = data_class(data, *args) if data_class else data
+        if not isinstance(data, CsvSerializer):
+            raise TypeError(
+                ""'data' should be 'CsvSerializer', got: {}""
+                .format(type(data))
+            )
+
+        self.ts = ts if ts else datetime.datetime.utcnow()
+        self.ev_type = ev_type
+        self.data = data
+
+        self._data_items_prefix = '_data_'
+        self._items = (
+            ['ts', 'ev_type'] +
+            [(self._data_items_prefix + i) for i in self.data._items]
+        )
+        pass
+
+    def __getattr__(self, name):
+        try:
+            _name = name.split(self._data_items_prefix)[1]
+        except IndexError:
+            raise AttributeError
+        else:
+            return getattr(self.data, _name)
+
+
+class ActionLog:
     """"""
     Append-only event log of action event
     """"""
 
-    SCHEDULED = ""scheduled""
-    STARTED = ""started""
-    SUCCEEDED = ""succeeded""
-    FAILED = ""failed""
-    CANCELLED = ""cancelled""
-
-    def __init__(self, filePath, delimiter=""\t""):
-        self.__delimiter = delimiter
-        self.__filePath = filePath
-        self.__items = []
+    def __init__(
+            self,
+            file_path: str,
+            data_class: Type[CsvSerializer] = ActionLogData,
+            event_types: Type[Enum] = ActionLogEvents,
+            delimiter: str ='\t'
+    ):
+        self._delimiter = delimiter
+        self._file_path = file_path
+        self._items = []
+        self._data_class = data_class
+        self._event_types = event_types
         self._load()
 
+        for ev_type in self._event_types:",165,2019-03-14 11:18:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265521732,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265521732,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,`indy_node/utils/migration_tool.py`,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 11:19:20,265522001,"@@ -51,67 +59,51 @@ def get_action_id(txn):
             seq_no = ''
         return '{}{}'.format(get_req_id(txn), seq_no)
 
+    # implements legacy logic used only by migration logic,
+    # please use Version classes in code instead
+    # TODO refactor migration logic to get rid of that API usage",54,2019-03-14 11:19:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265522001,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265522001,andkononykhin
https://github.com/hyperledger/indy-node/pull/1171,https://github.com/hyperledger/indy-node/pull/1171,done,9c45205fe534eedc885d773dc9ac496f5cf673f3,2019-03-14 11:19:38,265522091,"@@ -45,8 +178,17 @@ def run_shell_command(cls, command, timeout=TIMEOUT):
     # Method is used in case we are NOT interested in command output
     # everything: command, errors, output etc are logged to journalctl
     @classmethod
-    def run_shell_script(cls, command, timeout=TIMEOUT):
-        subprocess.run(command, shell=True, timeout=timeout, check=True)
+    def run_shell_script(cls, command, stdout=False, stderr=False,",,2019-03-14 11:19:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/265522091,https://github.com/hyperledger/indy-node/pull/1171#discussion_r265522091,andkononykhin
https://github.com/hyperledger/indy-node/pull/1159,https://github.com/hyperledger/indy-node/pull/1159,Looks like duplicate check,0666d03b21da6387a484c9ca9b79c04d4a9f2d89,2019-02-06 10:52:53,254221723,"@@ -1,314 +1,337 @@
-import sys
 import pytest
+import json
 
 from enum import Enum, unique
 
 from indy.did import create_and_store_my_did
 
-from plenum.common.constants import TRUSTEE, STEWARD, NYM
-from plenum.common.exceptions import RequestRejectedException
-from plenum.test.helper import sdk_sign_and_submit_op, sdk_get_and_check_replies
-from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.common.constants import (
+    TRUSTEE, STEWARD, NYM, TXN_TYPE, TARGET_NYM, VERKEY, ROLE,
+    CURRENT_PROTOCOL_VERSION)
+from plenum.common.exceptions import UnauthorizedClientRequest
+from plenum.common.signer_did import DidSigner
+from plenum.common.member.member import Member
+from plenum.test.helper import sdk_gen_request, sdk_sign_request_objects
 
+from indy_common.types import Request
 from indy_common.roles import Roles
-from indy_node.test.helper import createHalfKeyIdentifierAndAbbrevVerkey
 
+from indy_node.test.helper import createUuidIdentifierAndFullVerkey
 
 #   TODO
 #   - more specific string patterns for auth exc check
-#   - mixed cases: both verkey and role are presented in NYM txn
-#     ??? possibly not necessary for now since role and verkey related constrains
-#     are composed like logical AND validation fails if any of them fails
 #   - ANYONE_CAN_WRITE=True case
 
 
-# FIXTURES
+class DID(object):
+    def __init__(self, did=None, role=Roles.IDENTITY_OWNER, verkey=None, creator=None, wallet_handle=None):
+        self.did = did
+        self.role = role
+        self.verkey = verkey
+        self.creator = creator
+        self.wallet_handle = wallet_handle
 
-class EnumBase(Enum):
-    def __str__(self):
-        return self.name
+    @property
+    def wallet_did(self):
+        return (self.wallet_handle, self.did)
 
 
 @unique
-class ActionIds(EnumBase):
-    add = 0
-    demote = 1
-    rotate = 2
+class EnumBase(Enum):
+    def __str__(self):
+        return self.name
 
 
-@unique
-class Demotions(EnumBase):
-    # other DID-without-verkey created by the demoter
-    self_created_no_verkey = 1
-    # other DID-with-verkey created by the demoter
-    self_created_verkey = 2
-    # other DID-without-verkey created by other
-    other_created_no_verkey = 3
-    # other DID-with-verkey created by other
-    other_created_verkey = 4
+ActionIds = Enum('ActionIds', 'add edit', type=EnumBase)
 
+# params for addition:
+# - signer:
+#   - role: Roles
+# - dest:
+#   - verkey in NYM: omitted, None, val
+#   - role: Roles, omitted
+NYMAddDestRoles = Enum(
+    'NYMAddDestRoles',
+    [(r.name, r.value) for r in Roles] + [('omitted', 'omitted')],
+    type=EnumBase)
 
-@unique
-class Rotations(EnumBase):
-    none_val = 1
-    val_val = 2
-    val_none = 3
-    none_none = 4
+NYMAddDestVerkeys = Enum('NYMAddDestVerkeys', 'none val omitted', type=EnumBase)
 
+# params for edition:
+# - signer:
+#   - [self, creator] + [other], where other = any of Roles
+# - dest:
+#   - role in ledger: Roles
+#   - verkey in ledger: None, val
+#   - role: Roles, omitted
+#   - verkey in NYM: same, new (not None), demote(None), omitted
+LedgerDIDVerkeys = Enum('LedgerDIDVerkeys', 'none val', type=EnumBase)
+LedgerDIDRoles = Roles
 
-@unique
-class Rotator(EnumBase):
-    self = 1
-    creator = 2
-    other = 3
+NYMEditSignerTypes = Enum(
+    'NYMEditSignerTypes',
+    [(r.name, r.value) for r in Roles] + [('self', 'self'), ('creator', 'creator')],
+    type=EnumBase
+)
 
+NYMEditDestRoles = NYMAddDestRoles
+NYMEditDestVerkeys = Enum('NYMEditDestVerkeys', 'same new demote omitted', type=EnumBase)
 
-# FIXME class name
-class DIDWallet(object):
-    def __init__(self, did=None, role=Roles.IDENTITY_OWNER, verkey=None, creator=None, wallet_handle=None):
-        self.did = did
-        self.role = role
-        self.verkey = verkey
-        self.creator = creator
-        self.wallet_handle = wallet_handle
 
-    @property
-    def wallet_did(self):
-        return (self.wallet_handle, self.did)
+dids = {}
+did_editor_others = {}
+did_provisioners = did_editor_others
 
+# FIXTURES
 
-def auth_check(action_id, signer, dest):
 
-    # is_self = signer.did == dest.did
-    is_owner = signer == (dest if dest.verkey is not None else dest.creator)
+@pytest.fixture(scope=""module"")
+def trustee(sdk_wallet_trustee):
+    return DID(did=sdk_wallet_trustee[1], role=Roles.TRUSTEE, wallet_handle=sdk_wallet_trustee[0])
 
-    if action_id == ActionIds.add:
-        if dest.role in (Roles.TRUSTEE, Roles.STEWARD):
-            return signer.role == Roles.TRUSTEE
-        elif dest.role in (Roles.TRUST_ANCHOR, Roles.NETWORK_MONITOR):
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
-        elif dest.role == Roles.IDENTITY_OWNER:
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD, Roles.TRUST_ANCHOR)
 
-    elif action_id == ActionIds.demote:
-        if dest.role in (Roles.TRUSTEE, Roles.STEWARD):
-            return signer.role == Roles.TRUSTEE
-        elif dest.role == Roles.TRUST_ANCHOR:
-            return (signer.role == Roles.TRUSTEE)
-            # FIXME INDY-1968: uncomment when the task is addressed
-            # return ((signer.role == Roles.TRUSTEE) or
-            #        (signer.role == Roles.TRUST_ANCHOR and
-            #            is_self and is_owner))
-        elif dest.role == Roles.NETWORK_MONITOR:
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
-        # FIXME INDY-1969: remove when the task is addressed
-        elif dest.role == Roles.IDENTITY_OWNER:
-            return is_owner
+@pytest.fixture(scope=""module"")
+def poolTxnData(looper, poolTxnData, trustee):
+    global dids
+    global did_editor_others
+
+    # TODO non-Trustee creators
+
+    data = poolTxnData
+
+    def _add_did(role, did_name, with_verkey=True):
+        nonlocal data
+
+        data['seeds'][did_name] = did_name + '0' * (32 - len(did_name))
+        t_sgnr = DidSigner(seed=data['seeds'][did_name].encode())
+        verkey = t_sgnr.full_verkey if with_verkey else None
+        data['txns'].append(
+            Member.nym_txn(nym=t_sgnr.identifier,
+                           verkey=verkey,
+                           role=role.value,
+                           name=did_name,
+                           creator=trustee.did)
+        )
+
+        if verkey:
+            (sdk_did, sdk_verkey) = looper.loop.run_until_complete(
+                create_and_store_my_did(
+                    trustee.wallet_handle,
+                    json.dumps({'seed': data['seeds'][did_name]}))
+            )
+
+        return DID(
+            did=t_sgnr.identifier, role=role, verkey=verkey,
+            creator=trustee, wallet_handle=trustee.wallet_handle
+        )
+
+    params = [(dr, dv) for dr in LedgerDIDRoles for dv in LedgerDIDVerkeys]
+    for (dr, dv) in params:
+        dids[(dr, dv)] = _add_did(
+            dr, ""{}-{}"".format(dr.name, dv.name),
+            with_verkey=(dv == LedgerDIDVerkeys.val)
+        )
+
+    for dr in Roles:
+        did_editor_others[dr] = _add_did(dr, ""{}-other"".format(dr.name))
+
+    return data
+
+
+@pytest.fixture(scope=""module"", params=list(Roles))
+def provisioner_role(request):
+    return request.param
 
-    elif action_id == ActionIds.rotate:
-        return is_owner
 
-    return False
+@pytest.fixture(scope=""module"")
+def provisioner(poolTxnData, provisioner_role):
+    return did_provisioners[provisioner_role]
 
 
-def create_new_did(looper, sdk_pool_handle, creator, role, skipverkey=False):
+@pytest.fixture(scope=""module"", params=list(NYMAddDestRoles))
+def nym_add_dest_role(request):
+    return request.param
 
-    op = {
-        'type': NYM,
-        'role': role.value
-    }
 
-    new_did_verkey = None
+@pytest.fixture(scope=""module"", params=list(NYMAddDestVerkeys))
+def nym_add_dest_verkey(request):
+    return request.param
 
-    if skipverkey:
-        new_did, _ = createHalfKeyIdentifierAndAbbrevVerkey()
-        op.update({'dest': new_did})
-    else:
-        new_did, new_did_verkey = looper.loop.run_until_complete(
-            create_and_store_my_did(creator.wallet_handle, ""{}""))
 
-    op.update({'dest': new_did, 'verkey': new_did_verkey})
+@pytest.fixture(scope=""function"")
+def add_op(nym_add_dest_role, nym_add_dest_verkey):
+    did, verkey = createUuidIdentifierAndFullVerkey()
 
-    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, creator.wallet_did, op)
-    sdk_get_and_check_replies(looper, [req])
+    op = {
+        TXN_TYPE: NYM,
+        TARGET_NYM: did,
+        ROLE: nym_add_dest_role.value,
+        VERKEY: verkey
+    }
 
-    return DIDWallet(did=new_did, role=role, verkey=new_did_verkey,
-                     creator=creator, wallet_handle=creator.wallet_handle)
+    if nym_add_dest_role == NYMAddDestRoles.omitted:
+        del op[ROLE]
 
+    if nym_add_dest_verkey == NYMAddDestVerkeys.omitted:
+        del op[VERKEY]
 
-@pytest.fixture(scope=""module"")
-def trustee(sdk_wallet_trustee):
-    return DIDWallet(did=sdk_wallet_trustee[1], role=Roles.TRUSTEE, wallet_handle=sdk_wallet_trustee[0])
+    return op
 
 
-def did_fixture_wrapper():
-    def _fixture(looper, sdk_pool_handle, txnPoolNodeSet, trustee, request):
-        marker = request.node.get_marker('skip_did_verkey')
-        return create_new_did(looper, sdk_pool_handle, trustee, request.param,
-                              skipverkey=(marker is not None))
-    return _fixture
+@pytest.fixture(scope=""module"", params=list(LedgerDIDRoles))
+def edited_ledger_role(request):
+    return request.param
 
 
-# adds did_per_module and did_per_function fixtures
-for scope in ('module', 'function'):
-    setattr(
-        sys.modules[__name__],
-        ""did_per_{}"".format(scope),
-        pytest.fixture(scope=scope, params=list(Roles))(did_fixture_wrapper()))
+@pytest.fixture(scope=""module"", params=list(LedgerDIDVerkeys))
+def edited_ledger_verkey(request):
+    return request.param
 
 
-@pytest.fixture(scope=""module"")
-def provisioner(did_per_module):
-    return did_per_module
+@pytest.fixture(scope=""function"")
+def edited(edited_ledger_role, edited_ledger_verkey):
+    return dids[(edited_ledger_role, edited_ledger_verkey)]
 
 
-@pytest.fixture(scope=""module"", params=list(Roles) + [None],
-                ids=lambda r: str(r) if r else 'omitted_role')
-def provisioned_role(request):
+@pytest.fixture(scope=""module"", params=list(NYMEditDestRoles))
+def edited_nym_role(request):
     return request.param
 
 
-@pytest.fixture(scope=""function"")
-def provisioned(provisioned_role):
-    did, verkey = createHalfKeyIdentifierAndAbbrevVerkey()
-    return (
-        DIDWallet(
-            did=did,
-            role=provisioned_role if provisioned_role else Roles.IDENTITY_OWNER,
-            verkey=verkey),
-        provisioned_role is None)
-
-
-# scope is 'function' since demoter demotes
-# themselves at the end of the each demotion test
-@pytest.fixture(scope=""function"")
-def demoter(did_per_function):
-    return did_per_function
+@pytest.fixture(scope=""module"", params=list(NYMEditDestVerkeys))
+def edited_nym_verkey(request):
+    return request.param
 
 
-@pytest.fixture(scope=""function"",
-                params=[(x, y) for x in Demotions for y in Roles] + [None],
-                ids=lambda p: ""{}-{}"".format(p[0], p[1]) if p else 'self')
-def demotion(request):
+@pytest.fixture(scope=""module"", params=list(NYMEditSignerTypes))
+def editor_type(request):
     return request.param
 
 
 @pytest.fixture(scope=""function"")
-def demoted(looper, sdk_pool_handle, txnPoolNodeSet, trustee, demoter, demotion):
-    if demotion is None:  # self demotion
-        return demoter
+def editor(editor_type, edited):
+    if editor_type == NYMEditSignerTypes.self:
+        return edited
+    elif editor_type == NYMEditSignerTypes.creator:
+        return edited
     else:
-        demotion_type, role = demotion
-        if demotion_type == Demotions.self_created_no_verkey:
-            if auth_check(ActionIds.add, demoter, DIDWallet(role=role)):
-                return create_new_did(looper, sdk_pool_handle, demoter, role, skipverkey=True)
-        elif demotion_type == Demotions.self_created_verkey:
-            if auth_check(ActionIds.add, demoter, DIDWallet(role=role)):
-                return create_new_did(looper, sdk_pool_handle, demoter, role)
-        elif demotion_type == Demotions.other_created_no_verkey:
-            return create_new_did(looper, sdk_pool_handle, trustee, role, skipverkey=True)
-        elif demotion_type == Demotions.other_created_verkey:
-            return create_new_did(looper, sdk_pool_handle, trustee, role)
-
-
-# Note. dedicated trustee is used to test rotations by other
-# (not creator and not self). Other other-rotators (e.g. TRUST_ANCHOR)
-# are ignored as less powerful.
-@pytest.fixture(scope=""module"")
-def trustee_not_creator(looper, sdk_pool_handle, txnPoolNodeSet, trustee):
-    return create_new_did(looper, sdk_pool_handle, trustee, Roles.TRUSTEE)
+        return did_editor_others[Roles(editor_type.value)]
 
 
-@pytest.fixture(scope=""function"", params=list(Rotations))
-def rotation_verkey(request):
-    if request.param in (Rotations.none_none, Rotations.none_val):
-        request.node.add_marker('skip_did_verkey')
+@pytest.fixture(scope=""function"")
+def edit_op(edited, edited_nym_role, edited_nym_verkey):
+    op = {
+        TXN_TYPE: NYM,
+        TARGET_NYM: edited.did,
+    }
 
-    verkey = None
-    if request.param in (Rotations.val_val, Rotations.none_val):
-        _, verkey_ = createHalfKeyIdentifierAndAbbrevVerkey()
+    if edited_nym_role != NYMEditDestRoles.omitted:
+        op[ROLE] = edited_nym_role.value
 
-    return verkey
+    if edited_nym_verkey == NYMEditDestVerkeys.same:
+        op[VERKEY] = edited.verkey
+    elif edited_nym_verkey == NYMEditDestVerkeys.new:
+        _, op[VERKEY] = createUuidIdentifierAndFullVerkey()
+    elif edited_nym_verkey == NYMEditDestVerkeys.demote:
+        if edited.verkey is None:
+            return None  # pass that case since it is covered by `same` case as well
+        else:
+            op[VERKEY] = None
 
+    return op
 
-@pytest.fixture(scope=""function"", params=list(Rotator))
-def rotator(did_per_function, trustee_not_creator, request):
-    if request.param == Rotator.self:
-        return did_per_function
-    elif request.param == Rotator.creator:
-        return did_per_function.creator
-    elif request.param == Rotator.other:
-        return trustee_not_creator
 
+# TEST HELPERS
 
-@pytest.fixture(scope=""function"")
-def rotated(did_per_function):
-    return did_per_function
+def auth_check(action_id, signer, op, did_ledger=None):
+    op_role = Roles(op[ROLE]) if ROLE in op else None
 
+    def check_promotion():
+        # omitted role means IDENTITY_OWNER
+        if op_role in (None, Roles.IDENTITY_OWNER):
+            return signer.role in (Roles.TRUSTEE, Roles.STEWARD, Roles.TRUST_ANCHOR)
+        elif op_role in (Roles.TRUSTEE, Roles.STEWARD):
+            return signer.role == Roles.TRUSTEE
+        elif op_role in (Roles.TRUST_ANCHOR, Roles.NETWORK_MONITOR):
+            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
 
-# TEST HELPERS
+    def check_demotion():
+        if did_ledger.role in (Roles.TRUSTEE, Roles.STEWARD):
+            return signer.role == Roles.TRUSTEE
+        elif did_ledger.role == Roles.TRUST_ANCHOR:
+            return (signer.role == Roles.TRUSTEE)
+            # FIXME INDY-1968: uncomment when the task is addressed
+            # return ((signer.role == Roles.TRUSTEE) or
+            #        (signer.role == Roles.TRUST_ANCHOR and
+            #            is_self and is_owner))
+        elif did_ledger.role == Roles.NETWORK_MONITOR:
+            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
 
-def sign_submit_check(looper, sdk_pool_handle, signer, dest, action_id, op):
-    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, signer.wallet_did, op)
+    if action_id == ActionIds.add:
+        return check_promotion()
 
-    if auth_check(action_id, signer, dest):
-        sdk_get_and_check_replies(looper, [req])
-    else:
-        with pytest.raises(RequestRejectedException) as excinfo:
-            sdk_get_and_check_replies(looper, [req])
-        excinfo.match('UnauthorizedClientRequest')
+    elif action_id == ActionIds.edit:
+        # is_self = signer.did == did_ledger.did
+        is_owner = signer == (did_ledger if did_ledger.verkey is not None else
+                              did_ledger.creator)
 
+        if (VERKEY in op) and (not is_owner):
+            return False
 
-def add(looper, sdk_pool_handle, provisioner, provisioned, omit_role=False):
-    op = {
-        'type': NYM,
-        'dest': provisioned.did,
-        'verkey': provisioned.verkey,
-    }
+        if ROLE in op:
+            if op_role == did_ledger.role:
+                # FIXME INDY-1969: related to the task
+                return is_owner  # TODO what is a case here, is it correctly designed
 
-    if not omit_role:
-        op['role'] = provisioned.role.value
+            elif op_role == Roles.IDENTITY_OWNER:  # demotion of existent DID
+                return check_demotion()
 
-    sign_submit_check(looper, sdk_pool_handle, provisioner, provisioned, ActionIds.add, op)
+            elif did_ledger.role == Roles.IDENTITY_OWNER:  # promotion of existent DID
+                return check_promotion()
 
+            else:  # role updating: demotion + promotion
+                return (check_demotion() and check_promotion())
+        else:
+            return True
 
-def demote(looper, sdk_pool_handle, demoter, demoted):
-    op = {
-        'type': NYM,
-        'dest': demoted.did,
-        'role': None
-    }
+    return False
 
-    sign_submit_check(looper, sdk_pool_handle, demoter,
-                      demoted, ActionIds.demote, op)
 
+def sign_and_validate(looper, node, action_id, signer, op, did_ledger=None):
+    req_obj = sdk_gen_request(op, protocol_version=CURRENT_PROTOCOL_VERSION,
+                              identifier=signer.did)
+    s_req = sdk_sign_request_objects(looper, signer.wallet_did, [req_obj])[0]
 
-def rotate(looper, sdk_pool_handle, rotator, rotated, new_verkey):
-    op = {
-        'type': NYM,
-        'dest': rotated.did,
-        'verkey': new_verkey
-    }
+    request = Request(**json.loads(s_req))
 
-    sign_submit_check(looper, sdk_pool_handle, rotator,
-                      rotated, ActionIds.rotate, op)
+    if auth_check(action_id, signer, op, did_ledger):
+        node.get_req_handler(txn_type=NYM).validate(request)
+    else:
+        with pytest.raises(UnauthorizedClientRequest):
+            node.get_req_handler(txn_type=NYM).validate(request)
 
 
 # TESTS
+# Note. some fixtures are referred explicitly just to make test nodeid names predictable
+
+def test_nym_add(
+        provisioner_role, nym_add_dest_role, nym_add_dest_verkey,
+        looper, txnPoolNodeSet,
+        provisioner, add_op):
+    sign_and_validate(looper, txnPoolNodeSet[0], ActionIds.add, provisioner, add_op)
 
-def test_nym_add(looper, sdk_pool_handle, txnPoolNodeSet, provisioner, provisioned):
-    provisioned, omit_role = provisioned
-    add(looper, sdk_pool_handle, provisioner, provisioned, omit_role=omit_role)
 
+def test_nym_edit(
+        edited_ledger_role, edited_ledger_verkey, editor_type,
+        edited_nym_role, edited_nym_verkey,
+        looper, txnPoolNodeSet,
+        editor, edited, edit_op):
 
-# Demotion is considered as NYM with only 'role' field specified and it's None.
-# If NYM includes 'verkey' field as well it mixes role demotion/promotion and
-# verkey rotation and should be checked separately.
-def test_nym_demote(looper, sdk_pool_handle, txnPoolNodeSet, demoter, demoted):
-    # might be None for cases 'self_created_no_verkey' and 'self_created_verkey' or self demotion
-    if demoted:
-        demote(looper, sdk_pool_handle, demoter, demoted)
+    if edit_op is None:  # might be None, means a duplicate test case
+        return
 
+    if editor.verkey is None:  # skip that as well since it doesn't make sense
+        return
 
-def test_nym_rotate(looper, sdk_pool_handle, txnPoolNodeSet, rotator, rotated, rotation_verkey):
-    rotate(looper, sdk_pool_handle, rotator, rotated, rotation_verkey)
+    if edit_op is not None:  # might be None, means a duplicate test case",,2019-02-06 11:51:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/254221723,https://github.com/hyperledger/indy-node/pull/1159#discussion_r254221723,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1159,https://github.com/hyperledger/indy-node/pull/1159,Is it really edited here as well?,0666d03b21da6387a484c9ca9b79c04d4a9f2d89,2019-02-06 11:12:07,254228132,"@@ -1,314 +1,337 @@
-import sys
 import pytest
+import json
 
 from enum import Enum, unique
 
 from indy.did import create_and_store_my_did
 
-from plenum.common.constants import TRUSTEE, STEWARD, NYM
-from plenum.common.exceptions import RequestRejectedException
-from plenum.test.helper import sdk_sign_and_submit_op, sdk_get_and_check_replies
-from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.common.constants import (
+    TRUSTEE, STEWARD, NYM, TXN_TYPE, TARGET_NYM, VERKEY, ROLE,
+    CURRENT_PROTOCOL_VERSION)
+from plenum.common.exceptions import UnauthorizedClientRequest
+from plenum.common.signer_did import DidSigner
+from plenum.common.member.member import Member
+from plenum.test.helper import sdk_gen_request, sdk_sign_request_objects
 
+from indy_common.types import Request
 from indy_common.roles import Roles
-from indy_node.test.helper import createHalfKeyIdentifierAndAbbrevVerkey
 
+from indy_node.test.helper import createUuidIdentifierAndFullVerkey
 
 #   TODO
 #   - more specific string patterns for auth exc check
-#   - mixed cases: both verkey and role are presented in NYM txn
-#     ??? possibly not necessary for now since role and verkey related constrains
-#     are composed like logical AND validation fails if any of them fails
 #   - ANYONE_CAN_WRITE=True case
 
 
-# FIXTURES
+class DID(object):
+    def __init__(self, did=None, role=Roles.IDENTITY_OWNER, verkey=None, creator=None, wallet_handle=None):
+        self.did = did
+        self.role = role
+        self.verkey = verkey
+        self.creator = creator
+        self.wallet_handle = wallet_handle
 
-class EnumBase(Enum):
-    def __str__(self):
-        return self.name
+    @property
+    def wallet_did(self):
+        return (self.wallet_handle, self.did)
 
 
 @unique
-class ActionIds(EnumBase):
-    add = 0
-    demote = 1
-    rotate = 2
+class EnumBase(Enum):
+    def __str__(self):
+        return self.name
 
 
-@unique
-class Demotions(EnumBase):
-    # other DID-without-verkey created by the demoter
-    self_created_no_verkey = 1
-    # other DID-with-verkey created by the demoter
-    self_created_verkey = 2
-    # other DID-without-verkey created by other
-    other_created_no_verkey = 3
-    # other DID-with-verkey created by other
-    other_created_verkey = 4
+ActionIds = Enum('ActionIds', 'add edit', type=EnumBase)
 
+# params for addition:
+# - signer:
+#   - role: Roles
+# - dest:
+#   - verkey in NYM: omitted, None, val
+#   - role: Roles, omitted
+NYMAddDestRoles = Enum(
+    'NYMAddDestRoles',
+    [(r.name, r.value) for r in Roles] + [('omitted', 'omitted')],
+    type=EnumBase)
 
-@unique
-class Rotations(EnumBase):
-    none_val = 1
-    val_val = 2
-    val_none = 3
-    none_none = 4
+NYMAddDestVerkeys = Enum('NYMAddDestVerkeys', 'none val omitted', type=EnumBase)
 
+# params for edition:
+# - signer:
+#   - [self, creator] + [other], where other = any of Roles
+# - dest:
+#   - role in ledger: Roles
+#   - verkey in ledger: None, val
+#   - role: Roles, omitted
+#   - verkey in NYM: same, new (not None), demote(None), omitted
+LedgerDIDVerkeys = Enum('LedgerDIDVerkeys', 'none val', type=EnumBase)
+LedgerDIDRoles = Roles
 
-@unique
-class Rotator(EnumBase):
-    self = 1
-    creator = 2
-    other = 3
+NYMEditSignerTypes = Enum(
+    'NYMEditSignerTypes',
+    [(r.name, r.value) for r in Roles] + [('self', 'self'), ('creator', 'creator')],
+    type=EnumBase
+)
 
+NYMEditDestRoles = NYMAddDestRoles
+NYMEditDestVerkeys = Enum('NYMEditDestVerkeys', 'same new demote omitted', type=EnumBase)
 
-# FIXME class name
-class DIDWallet(object):
-    def __init__(self, did=None, role=Roles.IDENTITY_OWNER, verkey=None, creator=None, wallet_handle=None):
-        self.did = did
-        self.role = role
-        self.verkey = verkey
-        self.creator = creator
-        self.wallet_handle = wallet_handle
 
-    @property
-    def wallet_did(self):
-        return (self.wallet_handle, self.did)
+dids = {}
+did_editor_others = {}
+did_provisioners = did_editor_others
 
+# FIXTURES
 
-def auth_check(action_id, signer, dest):
 
-    # is_self = signer.did == dest.did
-    is_owner = signer == (dest if dest.verkey is not None else dest.creator)
+@pytest.fixture(scope=""module"")
+def trustee(sdk_wallet_trustee):
+    return DID(did=sdk_wallet_trustee[1], role=Roles.TRUSTEE, wallet_handle=sdk_wallet_trustee[0])
 
-    if action_id == ActionIds.add:
-        if dest.role in (Roles.TRUSTEE, Roles.STEWARD):
-            return signer.role == Roles.TRUSTEE
-        elif dest.role in (Roles.TRUST_ANCHOR, Roles.NETWORK_MONITOR):
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
-        elif dest.role == Roles.IDENTITY_OWNER:
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD, Roles.TRUST_ANCHOR)
 
-    elif action_id == ActionIds.demote:
-        if dest.role in (Roles.TRUSTEE, Roles.STEWARD):
-            return signer.role == Roles.TRUSTEE
-        elif dest.role == Roles.TRUST_ANCHOR:
-            return (signer.role == Roles.TRUSTEE)
-            # FIXME INDY-1968: uncomment when the task is addressed
-            # return ((signer.role == Roles.TRUSTEE) or
-            #        (signer.role == Roles.TRUST_ANCHOR and
-            #            is_self and is_owner))
-        elif dest.role == Roles.NETWORK_MONITOR:
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
-        # FIXME INDY-1969: remove when the task is addressed
-        elif dest.role == Roles.IDENTITY_OWNER:
-            return is_owner
+@pytest.fixture(scope=""module"")
+def poolTxnData(looper, poolTxnData, trustee):
+    global dids
+    global did_editor_others
+
+    # TODO non-Trustee creators
+
+    data = poolTxnData
+
+    def _add_did(role, did_name, with_verkey=True):
+        nonlocal data
+
+        data['seeds'][did_name] = did_name + '0' * (32 - len(did_name))
+        t_sgnr = DidSigner(seed=data['seeds'][did_name].encode())
+        verkey = t_sgnr.full_verkey if with_verkey else None
+        data['txns'].append(
+            Member.nym_txn(nym=t_sgnr.identifier,
+                           verkey=verkey,
+                           role=role.value,
+                           name=did_name,
+                           creator=trustee.did)
+        )
+
+        if verkey:
+            (sdk_did, sdk_verkey) = looper.loop.run_until_complete(
+                create_and_store_my_did(
+                    trustee.wallet_handle,
+                    json.dumps({'seed': data['seeds'][did_name]}))
+            )
+
+        return DID(
+            did=t_sgnr.identifier, role=role, verkey=verkey,
+            creator=trustee, wallet_handle=trustee.wallet_handle
+        )
+
+    params = [(dr, dv) for dr in LedgerDIDRoles for dv in LedgerDIDVerkeys]
+    for (dr, dv) in params:
+        dids[(dr, dv)] = _add_did(
+            dr, ""{}-{}"".format(dr.name, dv.name),
+            with_verkey=(dv == LedgerDIDVerkeys.val)
+        )
+
+    for dr in Roles:
+        did_editor_others[dr] = _add_did(dr, ""{}-other"".format(dr.name))
+
+    return data
+
+
+@pytest.fixture(scope=""module"", params=list(Roles))
+def provisioner_role(request):
+    return request.param
 
-    elif action_id == ActionIds.rotate:
-        return is_owner
 
-    return False
+@pytest.fixture(scope=""module"")
+def provisioner(poolTxnData, provisioner_role):
+    return did_provisioners[provisioner_role]
 
 
-def create_new_did(looper, sdk_pool_handle, creator, role, skipverkey=False):
+@pytest.fixture(scope=""module"", params=list(NYMAddDestRoles))
+def nym_add_dest_role(request):
+    return request.param
 
-    op = {
-        'type': NYM,
-        'role': role.value
-    }
 
-    new_did_verkey = None
+@pytest.fixture(scope=""module"", params=list(NYMAddDestVerkeys))
+def nym_add_dest_verkey(request):
+    return request.param
 
-    if skipverkey:
-        new_did, _ = createHalfKeyIdentifierAndAbbrevVerkey()
-        op.update({'dest': new_did})
-    else:
-        new_did, new_did_verkey = looper.loop.run_until_complete(
-            create_and_store_my_did(creator.wallet_handle, ""{}""))
 
-    op.update({'dest': new_did, 'verkey': new_did_verkey})
+@pytest.fixture(scope=""function"")
+def add_op(nym_add_dest_role, nym_add_dest_verkey):
+    did, verkey = createUuidIdentifierAndFullVerkey()
 
-    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, creator.wallet_did, op)
-    sdk_get_and_check_replies(looper, [req])
+    op = {
+        TXN_TYPE: NYM,
+        TARGET_NYM: did,
+        ROLE: nym_add_dest_role.value,
+        VERKEY: verkey
+    }
 
-    return DIDWallet(did=new_did, role=role, verkey=new_did_verkey,
-                     creator=creator, wallet_handle=creator.wallet_handle)
+    if nym_add_dest_role == NYMAddDestRoles.omitted:
+        del op[ROLE]
 
+    if nym_add_dest_verkey == NYMAddDestVerkeys.omitted:
+        del op[VERKEY]
 
-@pytest.fixture(scope=""module"")
-def trustee(sdk_wallet_trustee):
-    return DIDWallet(did=sdk_wallet_trustee[1], role=Roles.TRUSTEE, wallet_handle=sdk_wallet_trustee[0])
+    return op
 
 
-def did_fixture_wrapper():
-    def _fixture(looper, sdk_pool_handle, txnPoolNodeSet, trustee, request):
-        marker = request.node.get_marker('skip_did_verkey')
-        return create_new_did(looper, sdk_pool_handle, trustee, request.param,
-                              skipverkey=(marker is not None))
-    return _fixture
+@pytest.fixture(scope=""module"", params=list(LedgerDIDRoles))
+def edited_ledger_role(request):
+    return request.param
 
 
-# adds did_per_module and did_per_function fixtures
-for scope in ('module', 'function'):
-    setattr(
-        sys.modules[__name__],
-        ""did_per_{}"".format(scope),
-        pytest.fixture(scope=scope, params=list(Roles))(did_fixture_wrapper()))
+@pytest.fixture(scope=""module"", params=list(LedgerDIDVerkeys))
+def edited_ledger_verkey(request):
+    return request.param
 
 
-@pytest.fixture(scope=""module"")
-def provisioner(did_per_module):
-    return did_per_module
+@pytest.fixture(scope=""function"")
+def edited(edited_ledger_role, edited_ledger_verkey):
+    return dids[(edited_ledger_role, edited_ledger_verkey)]
 
 
-@pytest.fixture(scope=""module"", params=list(Roles) + [None],
-                ids=lambda r: str(r) if r else 'omitted_role')
-def provisioned_role(request):
+@pytest.fixture(scope=""module"", params=list(NYMEditDestRoles))
+def edited_nym_role(request):
     return request.param
 
 
-@pytest.fixture(scope=""function"")
-def provisioned(provisioned_role):
-    did, verkey = createHalfKeyIdentifierAndAbbrevVerkey()
-    return (
-        DIDWallet(
-            did=did,
-            role=provisioned_role if provisioned_role else Roles.IDENTITY_OWNER,
-            verkey=verkey),
-        provisioned_role is None)
-
-
-# scope is 'function' since demoter demotes
-# themselves at the end of the each demotion test
-@pytest.fixture(scope=""function"")
-def demoter(did_per_function):
-    return did_per_function
+@pytest.fixture(scope=""module"", params=list(NYMEditDestVerkeys))
+def edited_nym_verkey(request):
+    return request.param
 
 
-@pytest.fixture(scope=""function"",
-                params=[(x, y) for x in Demotions for y in Roles] + [None],
-                ids=lambda p: ""{}-{}"".format(p[0], p[1]) if p else 'self')
-def demotion(request):
+@pytest.fixture(scope=""module"", params=list(NYMEditSignerTypes))
+def editor_type(request):
     return request.param
 
 
 @pytest.fixture(scope=""function"")
-def demoted(looper, sdk_pool_handle, txnPoolNodeSet, trustee, demoter, demotion):
-    if demotion is None:  # self demotion
-        return demoter
+def editor(editor_type, edited):
+    if editor_type == NYMEditSignerTypes.self:
+        return edited
+    elif editor_type == NYMEditSignerTypes.creator:
+        return edited",,2019-02-06 11:51:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/254228132,https://github.com/hyperledger/indy-node/pull/1159#discussion_r254228132,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1159,https://github.com/hyperledger/indy-node/pull/1159,"It's an error code, fixed. Thanks",0666d03b21da6387a484c9ca9b79c04d4a9f2d89,2019-02-06 11:40:50,254236851,"@@ -1,314 +1,337 @@
-import sys
 import pytest
+import json
 
 from enum import Enum, unique
 
 from indy.did import create_and_store_my_did
 
-from plenum.common.constants import TRUSTEE, STEWARD, NYM
-from plenum.common.exceptions import RequestRejectedException
-from plenum.test.helper import sdk_sign_and_submit_op, sdk_get_and_check_replies
-from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.common.constants import (
+    TRUSTEE, STEWARD, NYM, TXN_TYPE, TARGET_NYM, VERKEY, ROLE,
+    CURRENT_PROTOCOL_VERSION)
+from plenum.common.exceptions import UnauthorizedClientRequest
+from plenum.common.signer_did import DidSigner
+from plenum.common.member.member import Member
+from plenum.test.helper import sdk_gen_request, sdk_sign_request_objects
 
+from indy_common.types import Request
 from indy_common.roles import Roles
-from indy_node.test.helper import createHalfKeyIdentifierAndAbbrevVerkey
 
+from indy_node.test.helper import createUuidIdentifierAndFullVerkey
 
 #   TODO
 #   - more specific string patterns for auth exc check
-#   - mixed cases: both verkey and role are presented in NYM txn
-#     ??? possibly not necessary for now since role and verkey related constrains
-#     are composed like logical AND validation fails if any of them fails
 #   - ANYONE_CAN_WRITE=True case
 
 
-# FIXTURES
+class DID(object):
+    def __init__(self, did=None, role=Roles.IDENTITY_OWNER, verkey=None, creator=None, wallet_handle=None):
+        self.did = did
+        self.role = role
+        self.verkey = verkey
+        self.creator = creator
+        self.wallet_handle = wallet_handle
 
-class EnumBase(Enum):
-    def __str__(self):
-        return self.name
+    @property
+    def wallet_did(self):
+        return (self.wallet_handle, self.did)
 
 
 @unique
-class ActionIds(EnumBase):
-    add = 0
-    demote = 1
-    rotate = 2
+class EnumBase(Enum):
+    def __str__(self):
+        return self.name
 
 
-@unique
-class Demotions(EnumBase):
-    # other DID-without-verkey created by the demoter
-    self_created_no_verkey = 1
-    # other DID-with-verkey created by the demoter
-    self_created_verkey = 2
-    # other DID-without-verkey created by other
-    other_created_no_verkey = 3
-    # other DID-with-verkey created by other
-    other_created_verkey = 4
+ActionIds = Enum('ActionIds', 'add edit', type=EnumBase)
 
+# params for addition:
+# - signer:
+#   - role: Roles
+# - dest:
+#   - verkey in NYM: omitted, None, val
+#   - role: Roles, omitted
+NYMAddDestRoles = Enum(
+    'NYMAddDestRoles',
+    [(r.name, r.value) for r in Roles] + [('omitted', 'omitted')],
+    type=EnumBase)
 
-@unique
-class Rotations(EnumBase):
-    none_val = 1
-    val_val = 2
-    val_none = 3
-    none_none = 4
+NYMAddDestVerkeys = Enum('NYMAddDestVerkeys', 'none val omitted', type=EnumBase)
 
+# params for edition:
+# - signer:
+#   - [self, creator] + [other], where other = any of Roles
+# - dest:
+#   - role in ledger: Roles
+#   - verkey in ledger: None, val
+#   - role: Roles, omitted
+#   - verkey in NYM: same, new (not None), demote(None), omitted
+LedgerDIDVerkeys = Enum('LedgerDIDVerkeys', 'none val', type=EnumBase)
+LedgerDIDRoles = Roles
 
-@unique
-class Rotator(EnumBase):
-    self = 1
-    creator = 2
-    other = 3
+NYMEditSignerTypes = Enum(
+    'NYMEditSignerTypes',
+    [(r.name, r.value) for r in Roles] + [('self', 'self'), ('creator', 'creator')],
+    type=EnumBase
+)
 
+NYMEditDestRoles = NYMAddDestRoles
+NYMEditDestVerkeys = Enum('NYMEditDestVerkeys', 'same new demote omitted', type=EnumBase)
 
-# FIXME class name
-class DIDWallet(object):
-    def __init__(self, did=None, role=Roles.IDENTITY_OWNER, verkey=None, creator=None, wallet_handle=None):
-        self.did = did
-        self.role = role
-        self.verkey = verkey
-        self.creator = creator
-        self.wallet_handle = wallet_handle
 
-    @property
-    def wallet_did(self):
-        return (self.wallet_handle, self.did)
+dids = {}
+did_editor_others = {}
+did_provisioners = did_editor_others
 
+# FIXTURES
 
-def auth_check(action_id, signer, dest):
 
-    # is_self = signer.did == dest.did
-    is_owner = signer == (dest if dest.verkey is not None else dest.creator)
+@pytest.fixture(scope=""module"")
+def trustee(sdk_wallet_trustee):
+    return DID(did=sdk_wallet_trustee[1], role=Roles.TRUSTEE, wallet_handle=sdk_wallet_trustee[0])
 
-    if action_id == ActionIds.add:
-        if dest.role in (Roles.TRUSTEE, Roles.STEWARD):
-            return signer.role == Roles.TRUSTEE
-        elif dest.role in (Roles.TRUST_ANCHOR, Roles.NETWORK_MONITOR):
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
-        elif dest.role == Roles.IDENTITY_OWNER:
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD, Roles.TRUST_ANCHOR)
 
-    elif action_id == ActionIds.demote:
-        if dest.role in (Roles.TRUSTEE, Roles.STEWARD):
-            return signer.role == Roles.TRUSTEE
-        elif dest.role == Roles.TRUST_ANCHOR:
-            return (signer.role == Roles.TRUSTEE)
-            # FIXME INDY-1968: uncomment when the task is addressed
-            # return ((signer.role == Roles.TRUSTEE) or
-            #        (signer.role == Roles.TRUST_ANCHOR and
-            #            is_self and is_owner))
-        elif dest.role == Roles.NETWORK_MONITOR:
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
-        # FIXME INDY-1969: remove when the task is addressed
-        elif dest.role == Roles.IDENTITY_OWNER:
-            return is_owner
+@pytest.fixture(scope=""module"")
+def poolTxnData(looper, poolTxnData, trustee):
+    global dids
+    global did_editor_others
+
+    # TODO non-Trustee creators
+
+    data = poolTxnData
+
+    def _add_did(role, did_name, with_verkey=True):
+        nonlocal data
+
+        data['seeds'][did_name] = did_name + '0' * (32 - len(did_name))
+        t_sgnr = DidSigner(seed=data['seeds'][did_name].encode())
+        verkey = t_sgnr.full_verkey if with_verkey else None
+        data['txns'].append(
+            Member.nym_txn(nym=t_sgnr.identifier,
+                           verkey=verkey,
+                           role=role.value,
+                           name=did_name,
+                           creator=trustee.did)
+        )
+
+        if verkey:
+            (sdk_did, sdk_verkey) = looper.loop.run_until_complete(
+                create_and_store_my_did(
+                    trustee.wallet_handle,
+                    json.dumps({'seed': data['seeds'][did_name]}))
+            )
+
+        return DID(
+            did=t_sgnr.identifier, role=role, verkey=verkey,
+            creator=trustee, wallet_handle=trustee.wallet_handle
+        )
+
+    params = [(dr, dv) for dr in LedgerDIDRoles for dv in LedgerDIDVerkeys]
+    for (dr, dv) in params:
+        dids[(dr, dv)] = _add_did(
+            dr, ""{}-{}"".format(dr.name, dv.name),
+            with_verkey=(dv == LedgerDIDVerkeys.val)
+        )
+
+    for dr in Roles:
+        did_editor_others[dr] = _add_did(dr, ""{}-other"".format(dr.name))
+
+    return data
+
+
+@pytest.fixture(scope=""module"", params=list(Roles))
+def provisioner_role(request):
+    return request.param
 
-    elif action_id == ActionIds.rotate:
-        return is_owner
 
-    return False
+@pytest.fixture(scope=""module"")
+def provisioner(poolTxnData, provisioner_role):
+    return did_provisioners[provisioner_role]
 
 
-def create_new_did(looper, sdk_pool_handle, creator, role, skipverkey=False):
+@pytest.fixture(scope=""module"", params=list(NYMAddDestRoles))
+def nym_add_dest_role(request):
+    return request.param
 
-    op = {
-        'type': NYM,
-        'role': role.value
-    }
 
-    new_did_verkey = None
+@pytest.fixture(scope=""module"", params=list(NYMAddDestVerkeys))
+def nym_add_dest_verkey(request):
+    return request.param
 
-    if skipverkey:
-        new_did, _ = createHalfKeyIdentifierAndAbbrevVerkey()
-        op.update({'dest': new_did})
-    else:
-        new_did, new_did_verkey = looper.loop.run_until_complete(
-            create_and_store_my_did(creator.wallet_handle, ""{}""))
 
-    op.update({'dest': new_did, 'verkey': new_did_verkey})
+@pytest.fixture(scope=""function"")
+def add_op(nym_add_dest_role, nym_add_dest_verkey):
+    did, verkey = createUuidIdentifierAndFullVerkey()
 
-    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, creator.wallet_did, op)
-    sdk_get_and_check_replies(looper, [req])
+    op = {
+        TXN_TYPE: NYM,
+        TARGET_NYM: did,
+        ROLE: nym_add_dest_role.value,
+        VERKEY: verkey
+    }
 
-    return DIDWallet(did=new_did, role=role, verkey=new_did_verkey,
-                     creator=creator, wallet_handle=creator.wallet_handle)
+    if nym_add_dest_role == NYMAddDestRoles.omitted:
+        del op[ROLE]
 
+    if nym_add_dest_verkey == NYMAddDestVerkeys.omitted:
+        del op[VERKEY]
 
-@pytest.fixture(scope=""module"")
-def trustee(sdk_wallet_trustee):
-    return DIDWallet(did=sdk_wallet_trustee[1], role=Roles.TRUSTEE, wallet_handle=sdk_wallet_trustee[0])
+    return op
 
 
-def did_fixture_wrapper():
-    def _fixture(looper, sdk_pool_handle, txnPoolNodeSet, trustee, request):
-        marker = request.node.get_marker('skip_did_verkey')
-        return create_new_did(looper, sdk_pool_handle, trustee, request.param,
-                              skipverkey=(marker is not None))
-    return _fixture
+@pytest.fixture(scope=""module"", params=list(LedgerDIDRoles))
+def edited_ledger_role(request):
+    return request.param
 
 
-# adds did_per_module and did_per_function fixtures
-for scope in ('module', 'function'):
-    setattr(
-        sys.modules[__name__],
-        ""did_per_{}"".format(scope),
-        pytest.fixture(scope=scope, params=list(Roles))(did_fixture_wrapper()))
+@pytest.fixture(scope=""module"", params=list(LedgerDIDVerkeys))
+def edited_ledger_verkey(request):
+    return request.param
 
 
-@pytest.fixture(scope=""module"")
-def provisioner(did_per_module):
-    return did_per_module
+@pytest.fixture(scope=""function"")
+def edited(edited_ledger_role, edited_ledger_verkey):
+    return dids[(edited_ledger_role, edited_ledger_verkey)]
 
 
-@pytest.fixture(scope=""module"", params=list(Roles) + [None],
-                ids=lambda r: str(r) if r else 'omitted_role')
-def provisioned_role(request):
+@pytest.fixture(scope=""module"", params=list(NYMEditDestRoles))
+def edited_nym_role(request):
     return request.param
 
 
-@pytest.fixture(scope=""function"")
-def provisioned(provisioned_role):
-    did, verkey = createHalfKeyIdentifierAndAbbrevVerkey()
-    return (
-        DIDWallet(
-            did=did,
-            role=provisioned_role if provisioned_role else Roles.IDENTITY_OWNER,
-            verkey=verkey),
-        provisioned_role is None)
-
-
-# scope is 'function' since demoter demotes
-# themselves at the end of the each demotion test
-@pytest.fixture(scope=""function"")
-def demoter(did_per_function):
-    return did_per_function
+@pytest.fixture(scope=""module"", params=list(NYMEditDestVerkeys))
+def edited_nym_verkey(request):
+    return request.param
 
 
-@pytest.fixture(scope=""function"",
-                params=[(x, y) for x in Demotions for y in Roles] + [None],
-                ids=lambda p: ""{}-{}"".format(p[0], p[1]) if p else 'self')
-def demotion(request):
+@pytest.fixture(scope=""module"", params=list(NYMEditSignerTypes))
+def editor_type(request):
     return request.param
 
 
 @pytest.fixture(scope=""function"")
-def demoted(looper, sdk_pool_handle, txnPoolNodeSet, trustee, demoter, demotion):
-    if demotion is None:  # self demotion
-        return demoter
+def editor(editor_type, edited):
+    if editor_type == NYMEditSignerTypes.self:
+        return edited
+    elif editor_type == NYMEditSignerTypes.creator:
+        return edited",,2019-02-06 11:51:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/254236851,https://github.com/hyperledger/indy-node/pull/1159#discussion_r254236851,andkononykhin
https://github.com/hyperledger/indy-node/pull/1159,https://github.com/hyperledger/indy-node/pull/1159,"fixed, thanks",0666d03b21da6387a484c9ca9b79c04d4a9f2d89,2019-02-06 11:42:53,254237486,"@@ -1,314 +1,337 @@
-import sys
 import pytest
+import json
 
 from enum import Enum, unique
 
 from indy.did import create_and_store_my_did
 
-from plenum.common.constants import TRUSTEE, STEWARD, NYM
-from plenum.common.exceptions import RequestRejectedException
-from plenum.test.helper import sdk_sign_and_submit_op, sdk_get_and_check_replies
-from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.common.constants import (
+    TRUSTEE, STEWARD, NYM, TXN_TYPE, TARGET_NYM, VERKEY, ROLE,
+    CURRENT_PROTOCOL_VERSION)
+from plenum.common.exceptions import UnauthorizedClientRequest
+from plenum.common.signer_did import DidSigner
+from plenum.common.member.member import Member
+from plenum.test.helper import sdk_gen_request, sdk_sign_request_objects
 
+from indy_common.types import Request
 from indy_common.roles import Roles
-from indy_node.test.helper import createHalfKeyIdentifierAndAbbrevVerkey
 
+from indy_node.test.helper import createUuidIdentifierAndFullVerkey
 
 #   TODO
 #   - more specific string patterns for auth exc check
-#   - mixed cases: both verkey and role are presented in NYM txn
-#     ??? possibly not necessary for now since role and verkey related constrains
-#     are composed like logical AND validation fails if any of them fails
 #   - ANYONE_CAN_WRITE=True case
 
 
-# FIXTURES
+class DID(object):
+    def __init__(self, did=None, role=Roles.IDENTITY_OWNER, verkey=None, creator=None, wallet_handle=None):
+        self.did = did
+        self.role = role
+        self.verkey = verkey
+        self.creator = creator
+        self.wallet_handle = wallet_handle
 
-class EnumBase(Enum):
-    def __str__(self):
-        return self.name
+    @property
+    def wallet_did(self):
+        return (self.wallet_handle, self.did)
 
 
 @unique
-class ActionIds(EnumBase):
-    add = 0
-    demote = 1
-    rotate = 2
+class EnumBase(Enum):
+    def __str__(self):
+        return self.name
 
 
-@unique
-class Demotions(EnumBase):
-    # other DID-without-verkey created by the demoter
-    self_created_no_verkey = 1
-    # other DID-with-verkey created by the demoter
-    self_created_verkey = 2
-    # other DID-without-verkey created by other
-    other_created_no_verkey = 3
-    # other DID-with-verkey created by other
-    other_created_verkey = 4
+ActionIds = Enum('ActionIds', 'add edit', type=EnumBase)
 
+# params for addition:
+# - signer:
+#   - role: Roles
+# - dest:
+#   - verkey in NYM: omitted, None, val
+#   - role: Roles, omitted
+NYMAddDestRoles = Enum(
+    'NYMAddDestRoles',
+    [(r.name, r.value) for r in Roles] + [('omitted', 'omitted')],
+    type=EnumBase)
 
-@unique
-class Rotations(EnumBase):
-    none_val = 1
-    val_val = 2
-    val_none = 3
-    none_none = 4
+NYMAddDestVerkeys = Enum('NYMAddDestVerkeys', 'none val omitted', type=EnumBase)
 
+# params for edition:
+# - signer:
+#   - [self, creator] + [other], where other = any of Roles
+# - dest:
+#   - role in ledger: Roles
+#   - verkey in ledger: None, val
+#   - role: Roles, omitted
+#   - verkey in NYM: same, new (not None), demote(None), omitted
+LedgerDIDVerkeys = Enum('LedgerDIDVerkeys', 'none val', type=EnumBase)
+LedgerDIDRoles = Roles
 
-@unique
-class Rotator(EnumBase):
-    self = 1
-    creator = 2
-    other = 3
+NYMEditSignerTypes = Enum(
+    'NYMEditSignerTypes',
+    [(r.name, r.value) for r in Roles] + [('self', 'self'), ('creator', 'creator')],
+    type=EnumBase
+)
 
+NYMEditDestRoles = NYMAddDestRoles
+NYMEditDestVerkeys = Enum('NYMEditDestVerkeys', 'same new demote omitted', type=EnumBase)
 
-# FIXME class name
-class DIDWallet(object):
-    def __init__(self, did=None, role=Roles.IDENTITY_OWNER, verkey=None, creator=None, wallet_handle=None):
-        self.did = did
-        self.role = role
-        self.verkey = verkey
-        self.creator = creator
-        self.wallet_handle = wallet_handle
 
-    @property
-    def wallet_did(self):
-        return (self.wallet_handle, self.did)
+dids = {}
+did_editor_others = {}
+did_provisioners = did_editor_others
 
+# FIXTURES
 
-def auth_check(action_id, signer, dest):
 
-    # is_self = signer.did == dest.did
-    is_owner = signer == (dest if dest.verkey is not None else dest.creator)
+@pytest.fixture(scope=""module"")
+def trustee(sdk_wallet_trustee):
+    return DID(did=sdk_wallet_trustee[1], role=Roles.TRUSTEE, wallet_handle=sdk_wallet_trustee[0])
 
-    if action_id == ActionIds.add:
-        if dest.role in (Roles.TRUSTEE, Roles.STEWARD):
-            return signer.role == Roles.TRUSTEE
-        elif dest.role in (Roles.TRUST_ANCHOR, Roles.NETWORK_MONITOR):
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
-        elif dest.role == Roles.IDENTITY_OWNER:
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD, Roles.TRUST_ANCHOR)
 
-    elif action_id == ActionIds.demote:
-        if dest.role in (Roles.TRUSTEE, Roles.STEWARD):
-            return signer.role == Roles.TRUSTEE
-        elif dest.role == Roles.TRUST_ANCHOR:
-            return (signer.role == Roles.TRUSTEE)
-            # FIXME INDY-1968: uncomment when the task is addressed
-            # return ((signer.role == Roles.TRUSTEE) or
-            #        (signer.role == Roles.TRUST_ANCHOR and
-            #            is_self and is_owner))
-        elif dest.role == Roles.NETWORK_MONITOR:
-            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
-        # FIXME INDY-1969: remove when the task is addressed
-        elif dest.role == Roles.IDENTITY_OWNER:
-            return is_owner
+@pytest.fixture(scope=""module"")
+def poolTxnData(looper, poolTxnData, trustee):
+    global dids
+    global did_editor_others
+
+    # TODO non-Trustee creators
+
+    data = poolTxnData
+
+    def _add_did(role, did_name, with_verkey=True):
+        nonlocal data
+
+        data['seeds'][did_name] = did_name + '0' * (32 - len(did_name))
+        t_sgnr = DidSigner(seed=data['seeds'][did_name].encode())
+        verkey = t_sgnr.full_verkey if with_verkey else None
+        data['txns'].append(
+            Member.nym_txn(nym=t_sgnr.identifier,
+                           verkey=verkey,
+                           role=role.value,
+                           name=did_name,
+                           creator=trustee.did)
+        )
+
+        if verkey:
+            (sdk_did, sdk_verkey) = looper.loop.run_until_complete(
+                create_and_store_my_did(
+                    trustee.wallet_handle,
+                    json.dumps({'seed': data['seeds'][did_name]}))
+            )
+
+        return DID(
+            did=t_sgnr.identifier, role=role, verkey=verkey,
+            creator=trustee, wallet_handle=trustee.wallet_handle
+        )
+
+    params = [(dr, dv) for dr in LedgerDIDRoles for dv in LedgerDIDVerkeys]
+    for (dr, dv) in params:
+        dids[(dr, dv)] = _add_did(
+            dr, ""{}-{}"".format(dr.name, dv.name),
+            with_verkey=(dv == LedgerDIDVerkeys.val)
+        )
+
+    for dr in Roles:
+        did_editor_others[dr] = _add_did(dr, ""{}-other"".format(dr.name))
+
+    return data
+
+
+@pytest.fixture(scope=""module"", params=list(Roles))
+def provisioner_role(request):
+    return request.param
 
-    elif action_id == ActionIds.rotate:
-        return is_owner
 
-    return False
+@pytest.fixture(scope=""module"")
+def provisioner(poolTxnData, provisioner_role):
+    return did_provisioners[provisioner_role]
 
 
-def create_new_did(looper, sdk_pool_handle, creator, role, skipverkey=False):
+@pytest.fixture(scope=""module"", params=list(NYMAddDestRoles))
+def nym_add_dest_role(request):
+    return request.param
 
-    op = {
-        'type': NYM,
-        'role': role.value
-    }
 
-    new_did_verkey = None
+@pytest.fixture(scope=""module"", params=list(NYMAddDestVerkeys))
+def nym_add_dest_verkey(request):
+    return request.param
 
-    if skipverkey:
-        new_did, _ = createHalfKeyIdentifierAndAbbrevVerkey()
-        op.update({'dest': new_did})
-    else:
-        new_did, new_did_verkey = looper.loop.run_until_complete(
-            create_and_store_my_did(creator.wallet_handle, ""{}""))
 
-    op.update({'dest': new_did, 'verkey': new_did_verkey})
+@pytest.fixture(scope=""function"")
+def add_op(nym_add_dest_role, nym_add_dest_verkey):
+    did, verkey = createUuidIdentifierAndFullVerkey()
 
-    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, creator.wallet_did, op)
-    sdk_get_and_check_replies(looper, [req])
+    op = {
+        TXN_TYPE: NYM,
+        TARGET_NYM: did,
+        ROLE: nym_add_dest_role.value,
+        VERKEY: verkey
+    }
 
-    return DIDWallet(did=new_did, role=role, verkey=new_did_verkey,
-                     creator=creator, wallet_handle=creator.wallet_handle)
+    if nym_add_dest_role == NYMAddDestRoles.omitted:
+        del op[ROLE]
 
+    if nym_add_dest_verkey == NYMAddDestVerkeys.omitted:
+        del op[VERKEY]
 
-@pytest.fixture(scope=""module"")
-def trustee(sdk_wallet_trustee):
-    return DIDWallet(did=sdk_wallet_trustee[1], role=Roles.TRUSTEE, wallet_handle=sdk_wallet_trustee[0])
+    return op
 
 
-def did_fixture_wrapper():
-    def _fixture(looper, sdk_pool_handle, txnPoolNodeSet, trustee, request):
-        marker = request.node.get_marker('skip_did_verkey')
-        return create_new_did(looper, sdk_pool_handle, trustee, request.param,
-                              skipverkey=(marker is not None))
-    return _fixture
+@pytest.fixture(scope=""module"", params=list(LedgerDIDRoles))
+def edited_ledger_role(request):
+    return request.param
 
 
-# adds did_per_module and did_per_function fixtures
-for scope in ('module', 'function'):
-    setattr(
-        sys.modules[__name__],
-        ""did_per_{}"".format(scope),
-        pytest.fixture(scope=scope, params=list(Roles))(did_fixture_wrapper()))
+@pytest.fixture(scope=""module"", params=list(LedgerDIDVerkeys))
+def edited_ledger_verkey(request):
+    return request.param
 
 
-@pytest.fixture(scope=""module"")
-def provisioner(did_per_module):
-    return did_per_module
+@pytest.fixture(scope=""function"")
+def edited(edited_ledger_role, edited_ledger_verkey):
+    return dids[(edited_ledger_role, edited_ledger_verkey)]
 
 
-@pytest.fixture(scope=""module"", params=list(Roles) + [None],
-                ids=lambda r: str(r) if r else 'omitted_role')
-def provisioned_role(request):
+@pytest.fixture(scope=""module"", params=list(NYMEditDestRoles))
+def edited_nym_role(request):
     return request.param
 
 
-@pytest.fixture(scope=""function"")
-def provisioned(provisioned_role):
-    did, verkey = createHalfKeyIdentifierAndAbbrevVerkey()
-    return (
-        DIDWallet(
-            did=did,
-            role=provisioned_role if provisioned_role else Roles.IDENTITY_OWNER,
-            verkey=verkey),
-        provisioned_role is None)
-
-
-# scope is 'function' since demoter demotes
-# themselves at the end of the each demotion test
-@pytest.fixture(scope=""function"")
-def demoter(did_per_function):
-    return did_per_function
+@pytest.fixture(scope=""module"", params=list(NYMEditDestVerkeys))
+def edited_nym_verkey(request):
+    return request.param
 
 
-@pytest.fixture(scope=""function"",
-                params=[(x, y) for x in Demotions for y in Roles] + [None],
-                ids=lambda p: ""{}-{}"".format(p[0], p[1]) if p else 'self')
-def demotion(request):
+@pytest.fixture(scope=""module"", params=list(NYMEditSignerTypes))
+def editor_type(request):
     return request.param
 
 
 @pytest.fixture(scope=""function"")
-def demoted(looper, sdk_pool_handle, txnPoolNodeSet, trustee, demoter, demotion):
-    if demotion is None:  # self demotion
-        return demoter
+def editor(editor_type, edited):
+    if editor_type == NYMEditSignerTypes.self:
+        return edited
+    elif editor_type == NYMEditSignerTypes.creator:
+        return edited
     else:
-        demotion_type, role = demotion
-        if demotion_type == Demotions.self_created_no_verkey:
-            if auth_check(ActionIds.add, demoter, DIDWallet(role=role)):
-                return create_new_did(looper, sdk_pool_handle, demoter, role, skipverkey=True)
-        elif demotion_type == Demotions.self_created_verkey:
-            if auth_check(ActionIds.add, demoter, DIDWallet(role=role)):
-                return create_new_did(looper, sdk_pool_handle, demoter, role)
-        elif demotion_type == Demotions.other_created_no_verkey:
-            return create_new_did(looper, sdk_pool_handle, trustee, role, skipverkey=True)
-        elif demotion_type == Demotions.other_created_verkey:
-            return create_new_did(looper, sdk_pool_handle, trustee, role)
-
-
-# Note. dedicated trustee is used to test rotations by other
-# (not creator and not self). Other other-rotators (e.g. TRUST_ANCHOR)
-# are ignored as less powerful.
-@pytest.fixture(scope=""module"")
-def trustee_not_creator(looper, sdk_pool_handle, txnPoolNodeSet, trustee):
-    return create_new_did(looper, sdk_pool_handle, trustee, Roles.TRUSTEE)
+        return did_editor_others[Roles(editor_type.value)]
 
 
-@pytest.fixture(scope=""function"", params=list(Rotations))
-def rotation_verkey(request):
-    if request.param in (Rotations.none_none, Rotations.none_val):
-        request.node.add_marker('skip_did_verkey')
+@pytest.fixture(scope=""function"")
+def edit_op(edited, edited_nym_role, edited_nym_verkey):
+    op = {
+        TXN_TYPE: NYM,
+        TARGET_NYM: edited.did,
+    }
 
-    verkey = None
-    if request.param in (Rotations.val_val, Rotations.none_val):
-        _, verkey_ = createHalfKeyIdentifierAndAbbrevVerkey()
+    if edited_nym_role != NYMEditDestRoles.omitted:
+        op[ROLE] = edited_nym_role.value
 
-    return verkey
+    if edited_nym_verkey == NYMEditDestVerkeys.same:
+        op[VERKEY] = edited.verkey
+    elif edited_nym_verkey == NYMEditDestVerkeys.new:
+        _, op[VERKEY] = createUuidIdentifierAndFullVerkey()
+    elif edited_nym_verkey == NYMEditDestVerkeys.demote:
+        if edited.verkey is None:
+            return None  # pass that case since it is covered by `same` case as well
+        else:
+            op[VERKEY] = None
 
+    return op
 
-@pytest.fixture(scope=""function"", params=list(Rotator))
-def rotator(did_per_function, trustee_not_creator, request):
-    if request.param == Rotator.self:
-        return did_per_function
-    elif request.param == Rotator.creator:
-        return did_per_function.creator
-    elif request.param == Rotator.other:
-        return trustee_not_creator
 
+# TEST HELPERS
 
-@pytest.fixture(scope=""function"")
-def rotated(did_per_function):
-    return did_per_function
+def auth_check(action_id, signer, op, did_ledger=None):
+    op_role = Roles(op[ROLE]) if ROLE in op else None
 
+    def check_promotion():
+        # omitted role means IDENTITY_OWNER
+        if op_role in (None, Roles.IDENTITY_OWNER):
+            return signer.role in (Roles.TRUSTEE, Roles.STEWARD, Roles.TRUST_ANCHOR)
+        elif op_role in (Roles.TRUSTEE, Roles.STEWARD):
+            return signer.role == Roles.TRUSTEE
+        elif op_role in (Roles.TRUST_ANCHOR, Roles.NETWORK_MONITOR):
+            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
 
-# TEST HELPERS
+    def check_demotion():
+        if did_ledger.role in (Roles.TRUSTEE, Roles.STEWARD):
+            return signer.role == Roles.TRUSTEE
+        elif did_ledger.role == Roles.TRUST_ANCHOR:
+            return (signer.role == Roles.TRUSTEE)
+            # FIXME INDY-1968: uncomment when the task is addressed
+            # return ((signer.role == Roles.TRUSTEE) or
+            #        (signer.role == Roles.TRUST_ANCHOR and
+            #            is_self and is_owner))
+        elif did_ledger.role == Roles.NETWORK_MONITOR:
+            return signer.role in (Roles.TRUSTEE, Roles.STEWARD)
 
-def sign_submit_check(looper, sdk_pool_handle, signer, dest, action_id, op):
-    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, signer.wallet_did, op)
+    if action_id == ActionIds.add:
+        return check_promotion()
 
-    if auth_check(action_id, signer, dest):
-        sdk_get_and_check_replies(looper, [req])
-    else:
-        with pytest.raises(RequestRejectedException) as excinfo:
-            sdk_get_and_check_replies(looper, [req])
-        excinfo.match('UnauthorizedClientRequest')
+    elif action_id == ActionIds.edit:
+        # is_self = signer.did == did_ledger.did
+        is_owner = signer == (did_ledger if did_ledger.verkey is not None else
+                              did_ledger.creator)
 
+        if (VERKEY in op) and (not is_owner):
+            return False
 
-def add(looper, sdk_pool_handle, provisioner, provisioned, omit_role=False):
-    op = {
-        'type': NYM,
-        'dest': provisioned.did,
-        'verkey': provisioned.verkey,
-    }
+        if ROLE in op:
+            if op_role == did_ledger.role:
+                # FIXME INDY-1969: related to the task
+                return is_owner  # TODO what is a case here, is it correctly designed
 
-    if not omit_role:
-        op['role'] = provisioned.role.value
+            elif op_role == Roles.IDENTITY_OWNER:  # demotion of existent DID
+                return check_demotion()
 
-    sign_submit_check(looper, sdk_pool_handle, provisioner, provisioned, ActionIds.add, op)
+            elif did_ledger.role == Roles.IDENTITY_OWNER:  # promotion of existent DID
+                return check_promotion()
 
+            else:  # role updating: demotion + promotion
+                return (check_demotion() and check_promotion())
+        else:
+            return True
 
-def demote(looper, sdk_pool_handle, demoter, demoted):
-    op = {
-        'type': NYM,
-        'dest': demoted.did,
-        'role': None
-    }
+    return False
 
-    sign_submit_check(looper, sdk_pool_handle, demoter,
-                      demoted, ActionIds.demote, op)
 
+def sign_and_validate(looper, node, action_id, signer, op, did_ledger=None):
+    req_obj = sdk_gen_request(op, protocol_version=CURRENT_PROTOCOL_VERSION,
+                              identifier=signer.did)
+    s_req = sdk_sign_request_objects(looper, signer.wallet_did, [req_obj])[0]
 
-def rotate(looper, sdk_pool_handle, rotator, rotated, new_verkey):
-    op = {
-        'type': NYM,
-        'dest': rotated.did,
-        'verkey': new_verkey
-    }
+    request = Request(**json.loads(s_req))
 
-    sign_submit_check(looper, sdk_pool_handle, rotator,
-                      rotated, ActionIds.rotate, op)
+    if auth_check(action_id, signer, op, did_ledger):
+        node.get_req_handler(txn_type=NYM).validate(request)
+    else:
+        with pytest.raises(UnauthorizedClientRequest):
+            node.get_req_handler(txn_type=NYM).validate(request)
 
 
 # TESTS
+# Note. some fixtures are referred explicitly just to make test nodeid names predictable
+
+def test_nym_add(
+        provisioner_role, nym_add_dest_role, nym_add_dest_verkey,
+        looper, txnPoolNodeSet,
+        provisioner, add_op):
+    sign_and_validate(looper, txnPoolNodeSet[0], ActionIds.add, provisioner, add_op)
 
-def test_nym_add(looper, sdk_pool_handle, txnPoolNodeSet, provisioner, provisioned):
-    provisioned, omit_role = provisioned
-    add(looper, sdk_pool_handle, provisioner, provisioned, omit_role=omit_role)
 
+def test_nym_edit(
+        edited_ledger_role, edited_ledger_verkey, editor_type,
+        edited_nym_role, edited_nym_verkey,
+        looper, txnPoolNodeSet,
+        editor, edited, edit_op):
 
-# Demotion is considered as NYM with only 'role' field specified and it's None.
-# If NYM includes 'verkey' field as well it mixes role demotion/promotion and
-# verkey rotation and should be checked separately.
-def test_nym_demote(looper, sdk_pool_handle, txnPoolNodeSet, demoter, demoted):
-    # might be None for cases 'self_created_no_verkey' and 'self_created_verkey' or self demotion
-    if demoted:
-        demote(looper, sdk_pool_handle, demoter, demoted)
+    if edit_op is None:  # might be None, means a duplicate test case
+        return
 
+    if editor.verkey is None:  # skip that as well since it doesn't make sense
+        return
 
-def test_nym_rotate(looper, sdk_pool_handle, txnPoolNodeSet, rotator, rotated, rotation_verkey):
-    rotate(looper, sdk_pool_handle, rotator, rotated, rotation_verkey)
+    if edit_op is not None:  # might be None, means a duplicate test case",,2019-02-06 11:51:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/254237486,https://github.com/hyperledger/indy-node/pull/1159#discussion_r254237486,andkononykhin
https://github.com/hyperledger/indy-node/pull/1145,https://github.com/hyperledger/indy-node/pull/1145,I think it's better to say `number of signatures`,2d030fdb2fc2c31eb563fbb43117e0518f1e4eb4,2019-01-30 06:19:23,252128745,"@@ -20,18 +24,30 @@ def __init__(self, role, sig_count, need_to_be_owner=False, metadata={}):
         self.metadata = metadata
         self.constraint_id = ROLE_CONSTRAINT_ID
 
+    def __str__(self):
+        role = get_named_role(self.role) if self.role != '*' else 'ALL'
+        return ""Required role: {}, Count of signatures: {}, Need to be owner: {}"".format(role,",,2019-02-01 12:51:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/252128745,https://github.com/hyperledger/indy-node/pull/1145#discussion_r252128745,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1145,https://github.com/hyperledger/indy-node/pull/1145,"Maybe we should have shorter description.
Cases:
- owner is None and role != *:
    `X <role> signatures are required `
- owner is None and role == *:
    `X signatures of any role are required`
- owner is not None and number  of sigs = 1:
    `<role> needs to be owner`
- owner is not None, number of sigs = 1, and role == *
    `needs to be owner`
- owner is not None and number  of sigs = 1 and role != *
    `X <role> signatures are required and needs to be owner`
- owner is not None and number  of sigs = 1 and role == *
    `X signatures of any role are required and needs to be owner`
- else (fallback):
    as in the PR",2d030fdb2fc2c31eb563fbb43117e0518f1e4eb4,2019-01-30 06:31:39,252130739,"@@ -20,18 +24,30 @@ def __init__(self, role, sig_count, need_to_be_owner=False, metadata={}):
         self.metadata = metadata
         self.constraint_id = ROLE_CONSTRAINT_ID
 
+    def __str__(self):
+        role = get_named_role(self.role) if self.role != '*' else 'ALL'
+        return ""Required role: {}, Count of signatures: {}, Need to be owner: {}"".format(role,",,2019-02-01 12:51:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/252130739,https://github.com/hyperledger/indy-node/pull/1145#discussion_r252130739,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1145,https://github.com/hyperledger/indy-node/pull/1145,Maybe better to say `Not enough signatures`?,2d030fdb2fc2c31eb563fbb43117e0518f1e4eb4,2019-01-30 06:32:44,252130899,"@@ -73,11 +77,12 @@ def authorize(self,
         if is_role_accepted is None:
             return False, ""sender's DID {} is not found in the Ledger"".format(request.identifier)
         if not is_role_accepted:
-            return False, ""role is not accepted""
+            return False, ""{} can not do this action"".format(self.get_named_role_from_req(request))
         if not self.is_sig_count_accepted(request, auth_constraint):
-            return False, ""count of signatures is not accepted""
+            return False, ""Count of signatures is not accepted""",,2019-02-01 12:51:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/252130899,https://github.com/hyperledger/indy-node/pull/1145#discussion_r252130899,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1145,https://github.com/hyperledger/indy-node/pull/1145,"Why are we talking about verkey field? This is a generic exception, isn't it?",2d030fdb2fc2c31eb563fbb43117e0518f1e4eb4,2019-01-30 06:33:25,252131024,"@@ -73,11 +77,12 @@ def authorize(self,
         if is_role_accepted is None:
             return False, ""sender's DID {} is not found in the Ledger"".format(request.identifier)
         if not is_role_accepted:
-            return False, ""role is not accepted""
+            return False, ""{} can not do this action"".format(self.get_named_role_from_req(request))
         if not self.is_sig_count_accepted(request, auth_constraint):
-            return False, ""count of signatures is not accepted""
+            return False, ""Count of signatures is not accepted""
         if not self.is_owner_accepted(auth_constraint, auth_action):
-            return False, ""actor must be owner""
+            return False, ""{} can not touch verkey field since only the owner can modify it"".\",,2019-02-01 12:51:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/252131024,https://github.com/hyperledger/indy-node/pull/1145#discussion_r252131024,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1145,https://github.com/hyperledger/indy-node/pull/1145,Maybe we should rather check if this is `AuthActionEdit` action and get the field from there (action.field) instead of having hard-coded `NYM` and `verkey`?,2d030fdb2fc2c31eb563fbb43117e0518f1e4eb4,2019-02-01 12:42:13,253036660,"@@ -73,11 +79,17 @@ def authorize(self,
         if is_role_accepted is None:
             return False, ""sender's DID {} is not found in the Ledger"".format(request.identifier)
         if not is_role_accepted:
-            return False, ""role is not accepted""
+            return False, ""{} can not do this action"".format(self.get_named_role_from_req(request))
         if not self.is_sig_count_accepted(request, auth_constraint):
-            return False, ""count of signatures is not accepted""
+            return False, ""Not enough signatures""
         if not self.is_owner_accepted(auth_constraint, auth_action):
-            return False, ""actor must be owner""
+            if auth_action.txn_type == NYM:",,2019-02-01 12:51:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/253036660,https://github.com/hyperledger/indy-node/pull/1145#discussion_r253036660,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1132,https://github.com/hyperledger/indy-node/pull/1132,Why this is done in dynamic validation and not in processing?,69ad21454ea71641bdffc0940a1c54603e5b75c7,2019-01-22 08:04:29,249672711,"@@ -1,5 +1,38 @@
+from indy_node.server.request_handlers.action_req_handlers.utils import generate_action_result
+from indy_node.server.restarter import Restarter
+
+from indy_common.constants import POOL_RESTART
+
+from plenum.common.request import Request
+from plenum.common.txn_util import get_request_data
+from plenum.server.database_manager import DatabaseManager
 from plenum.server.request_handlers.handler_interfaces.action_request_handler import ActionRequestHandler
+from stp_core.common.log import getlogger
+
+logger = getlogger()
 
 
 class PoolRestartHandler(ActionRequestHandler):
-    pass
+
+    def __init__(self, database_manager: DatabaseManager,
+                 restarter: Restarter):
+        super().__init__(database_manager, POOL_RESTART, None)
+        self.restarter = restarter
+
+    def static_validation(self, request: Request):
+        pass
+
+    def dynamic_validation(self, request: Request):
+        self._validate_request_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        logger.debug(""Transaction {} with type {} started""
+                     .format(req_id, request.txn_type))
+        self.restarter.handleRestartRequest(request)",43,2019-01-22 09:10:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/249672711,https://github.com/hyperledger/indy-node/pull/1132#discussion_r249672711,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1132,https://github.com/hyperledger/indy-node/pull/1132,fixed,69ad21454ea71641bdffc0940a1c54603e5b75c7,2019-01-22 09:13:17,249693656,"@@ -1,5 +1,38 @@
+from indy_node.server.request_handlers.action_req_handlers.utils import generate_action_result
+from indy_node.server.restarter import Restarter
+
+from indy_common.constants import POOL_RESTART
+
+from plenum.common.request import Request
+from plenum.common.txn_util import get_request_data
+from plenum.server.database_manager import DatabaseManager
 from plenum.server.request_handlers.handler_interfaces.action_request_handler import ActionRequestHandler
+from stp_core.common.log import getlogger
+
+logger = getlogger()
 
 
 class PoolRestartHandler(ActionRequestHandler):
-    pass
+
+    def __init__(self, database_manager: DatabaseManager,
+                 restarter: Restarter):
+        super().__init__(database_manager, POOL_RESTART, None)
+        self.restarter = restarter
+
+    def static_validation(self, request: Request):
+        pass
+
+    def dynamic_validation(self, request: Request):
+        self._validate_request_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        logger.debug(""Transaction {} with type {} started""
+                     .format(req_id, request.txn_type))
+        self.restarter.handleRestartRequest(request)",43,2019-01-22 09:13:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/249693656,https://github.com/hyperledger/indy-node/pull/1132#discussion_r249693656,ArtObr
https://github.com/hyperledger/indy-node/pull/1130,https://github.com/hyperledger/indy-node/pull/1130,"I might be wrong, but it seems like this comment belongs before `op` assignment, not after",0e7fa926b026f891a034536f976b40d3cb75bd35,2019-01-16 11:13:45,248241559,"@@ -0,0 +1,72 @@
+import pytest
+from indy import did
+
+from indy_common.constants import NETWORK_MONITOR
+from indy_node.test.validator_info.helper import sdk_get_validator_info
+from plenum.common.constants import STEWARD_STRING
+from plenum.common.exceptions import RequestRejectedException
+from plenum.test.helper import sdk_sign_and_submit_op, sdk_get_and_check_replies
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+
+
+def test_network_monitor_suspension_by_another_steward(looper,
+                                                       sdk_pool_handle,
+                                                       sdk_wallet_steward,
+                                                       sdk_wallet_trustee,
+                                                       sdk_wallet_handle,
+                                                       with_verkey):
+    new_steward_did, new_steward_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    new_network_monitor_did, new_network_monitor_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_steward[0], ""{}""))
+    """"""Adding new steward""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    sdk_wallet_trustee, 'newSteward', STEWARD_STRING, verkey=new_steward_verkey, dest=new_steward_did)
+    """"""Adding NETWORK_MONITOR role by first steward""""""
+    op = {'type': '1',
+          'dest': new_network_monitor_did,
+          'role': NETWORK_MONITOR,
+          'verkey': new_network_monitor_verkey}
+    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, (sdk_wallet_handle, new_steward_did), op)
+    sdk_get_and_check_replies(looper, [req])
+    """"""Check that get_validator_info command works for NETWORK_MONITOR role""""""
+    sdk_get_validator_info(looper, (sdk_wallet_handle, new_network_monitor_did), sdk_pool_handle)
+    op = {'type': '1',
+          'dest': new_network_monitor_did,
+          'role': None}
+    if with_verkey:
+        op['verkey'] = new_network_monitor_verkey
+    """"""Blacklisting network_monitor by new steward""""""",,2019-01-16 12:46:34,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/248241559,https://github.com/hyperledger/indy-node/pull/1130#discussion_r248241559,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1130,https://github.com/hyperledger/indy-node/pull/1130,"I might be wrong, but it seems like this comment belongs before op assignment, not after",0e7fa926b026f891a034536f976b40d3cb75bd35,2019-01-16 11:16:21,248242345,"@@ -0,0 +1,72 @@
+import pytest
+from indy import did
+
+from indy_common.constants import NETWORK_MONITOR
+from indy_node.test.validator_info.helper import sdk_get_validator_info
+from plenum.common.constants import STEWARD_STRING
+from plenum.common.exceptions import RequestRejectedException
+from plenum.test.helper import sdk_sign_and_submit_op, sdk_get_and_check_replies
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+
+
+def test_network_monitor_suspension_by_another_steward(looper,
+                                                       sdk_pool_handle,
+                                                       sdk_wallet_steward,
+                                                       sdk_wallet_trustee,
+                                                       sdk_wallet_handle,
+                                                       with_verkey):
+    new_steward_did, new_steward_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    new_network_monitor_did, new_network_monitor_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_steward[0], ""{}""))
+    """"""Adding new steward""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    sdk_wallet_trustee, 'newSteward', STEWARD_STRING, verkey=new_steward_verkey, dest=new_steward_did)
+    """"""Adding NETWORK_MONITOR role by first steward""""""
+    op = {'type': '1',
+          'dest': new_network_monitor_did,
+          'role': NETWORK_MONITOR,
+          'verkey': new_network_monitor_verkey}
+    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, (sdk_wallet_handle, new_steward_did), op)
+    sdk_get_and_check_replies(looper, [req])
+    """"""Check that get_validator_info command works for NETWORK_MONITOR role""""""
+    sdk_get_validator_info(looper, (sdk_wallet_handle, new_network_monitor_did), sdk_pool_handle)
+    op = {'type': '1',
+          'dest': new_network_monitor_did,
+          'role': None}
+    if with_verkey:
+        op['verkey'] = new_network_monitor_verkey
+    """"""Blacklisting network_monitor by new steward""""""
+    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, (sdk_wallet_handle, new_steward_did), op)
+    if with_verkey:
+        with pytest.raises(RequestRejectedException):
+            sdk_get_and_check_replies(looper, [req])
+    else:
+        sdk_get_and_check_replies(looper, [req])
+        with pytest.raises(RequestRejectedException):
+            sdk_get_validator_info(looper, (sdk_wallet_handle, new_network_monitor_did), sdk_pool_handle)
+
+
+def test_network_monitor_suspension_by_itself(looper,
+                                              sdk_pool_handle,
+                                              sdk_wallet_steward,
+                                              sdk_wallet_handle,
+                                              with_verkey):
+    new_network_monitor_did, new_network_monitor_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_steward[0], ""{}""))
+    """"""Adding NETWORK_MONITOR role by steward""""""
+    op = {'type': '1',
+          'dest': new_network_monitor_did,
+          'role': NETWORK_MONITOR,
+          'verkey': new_network_monitor_verkey}
+    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, (sdk_wallet_handle, sdk_wallet_steward[1]), op)
+    sdk_get_and_check_replies(looper, [req])
+    op = {'type': '1',
+          'dest': new_network_monitor_did,
+          'role': None}
+    if with_verkey:
+        op['verkey'] = new_network_monitor_verkey
+    """"""Blacklisting network_monitor by itself""""""",,2019-01-16 12:46:34,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/248242345,https://github.com/hyperledger/indy-node/pull/1130#discussion_r248242345,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1130,https://github.com/hyperledger/indy-node/pull/1130,"I might be wrong, but it seems like this comment belongs before op assignment, not after",0e7fa926b026f891a034536f976b40d3cb75bd35,2019-01-16 11:16:28,248242386,"@@ -0,0 +1,77 @@
+import pytest
+from indy import did
+
+from indy_common.constants import TRUST_ANCHOR_STRING
+from plenum.common.constants import TRUSTEE_STRING, STEWARD_STRING
+from plenum.common.exceptions import RequestRejectedException
+from plenum.test.helper import sdk_get_and_check_replies, sdk_sign_and_submit_op
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+
+
+def test_steward_suspension_by_another_trustee(looper,
+                                               sdk_pool_handle,
+                                               sdk_wallet_trustee,
+                                               sdk_wallet_handle,
+                                               with_verkey):
+    new_trustee_did, new_trustee_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    new_steward_did, new_steward_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    """"""Adding new steward""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    sdk_wallet_trustee, 'newSteward', STEWARD_STRING, verkey=new_steward_verkey, dest=new_steward_did)
+    """"""Adding new trustee""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    sdk_wallet_trustee, 'newTrustee', TRUSTEE_STRING, verkey=new_trustee_verkey, dest=new_trustee_did)
+    op = {'type': '1',
+          'dest': new_steward_did,
+          'role': None}
+    if with_verkey:
+        op['verkey'] = new_steward_verkey
+    """"""Blacklisting new steward by new trustee""""""",,2019-01-16 12:46:34,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/248242386,https://github.com/hyperledger/indy-node/pull/1130#discussion_r248242386,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1130,https://github.com/hyperledger/indy-node/pull/1130,Either this or previous comment `Demote new steward' seem redundant,0e7fa926b026f891a034536f976b40d3cb75bd35,2019-01-16 11:18:17,248242884,"@@ -0,0 +1,77 @@
+import pytest
+from indy import did
+
+from indy_common.constants import TRUST_ANCHOR_STRING
+from plenum.common.constants import TRUSTEE_STRING, STEWARD_STRING
+from plenum.common.exceptions import RequestRejectedException
+from plenum.test.helper import sdk_get_and_check_replies, sdk_sign_and_submit_op
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+
+
+def test_steward_suspension_by_another_trustee(looper,
+                                               sdk_pool_handle,
+                                               sdk_wallet_trustee,
+                                               sdk_wallet_handle,
+                                               with_verkey):
+    new_trustee_did, new_trustee_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    new_steward_did, new_steward_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    """"""Adding new steward""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    sdk_wallet_trustee, 'newSteward', STEWARD_STRING, verkey=new_steward_verkey, dest=new_steward_did)
+    """"""Adding new trustee""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    sdk_wallet_trustee, 'newTrustee', TRUSTEE_STRING, verkey=new_trustee_verkey, dest=new_trustee_did)
+    op = {'type': '1',
+          'dest': new_steward_did,
+          'role': None}
+    if with_verkey:
+        op['verkey'] = new_steward_verkey
+    """"""Blacklisting new steward by new trustee""""""
+    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, (sdk_wallet_handle, new_trustee_did), op)
+    if with_verkey:
+        with pytest.raises(RequestRejectedException):
+            sdk_get_and_check_replies(looper, [req])
+    else:
+        sdk_get_and_check_replies(looper, [req])
+
+
+def test_steward_cannot_work_after_demote(looper,
+                                          sdk_pool_handle,
+                                          sdk_wallet_trustee,
+                                          sdk_wallet_handle):
+    new_steward_did, new_steward_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    new_ta_did, new_ta_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    new_ta_2_did, new_ta_2_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    """"""Adding new steward""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    sdk_wallet_trustee,
+                    'newSteward',
+                    STEWARD_STRING,
+                    verkey=new_steward_verkey, dest=new_steward_did)
+    """"""Adding new TA""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    (sdk_wallet_handle, new_steward_did),
+                    'newSteward',
+                    TRUST_ANCHOR_STRING,
+                    verkey=new_ta_verkey, dest=new_ta_did)
+    """"""Demote new steward""""""
+    op = {'type': '1',
+          'dest': new_steward_did,
+          'role': None}
+    """"""Blacklisting new steward by trustee""""""",,2019-01-16 12:46:34,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/248242884,https://github.com/hyperledger/indy-node/pull/1130#discussion_r248242884,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1130,https://github.com/hyperledger/indy-node/pull/1130,Probably `test_steward_cannot_create_trust_anchors_after_demote` would be a better name?,0e7fa926b026f891a034536f976b40d3cb75bd35,2019-01-16 11:19:26,248243212,"@@ -0,0 +1,77 @@
+import pytest
+from indy import did
+
+from indy_common.constants import TRUST_ANCHOR_STRING
+from plenum.common.constants import TRUSTEE_STRING, STEWARD_STRING
+from plenum.common.exceptions import RequestRejectedException
+from plenum.test.helper import sdk_get_and_check_replies, sdk_sign_and_submit_op
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+
+
+def test_steward_suspension_by_another_trustee(looper,
+                                               sdk_pool_handle,
+                                               sdk_wallet_trustee,
+                                               sdk_wallet_handle,
+                                               with_verkey):
+    new_trustee_did, new_trustee_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    new_steward_did, new_steward_verkey = looper.loop.run_until_complete(
+        did.create_and_store_my_did(sdk_wallet_trustee[0], ""{}""))
+    """"""Adding new steward""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    sdk_wallet_trustee, 'newSteward', STEWARD_STRING, verkey=new_steward_verkey, dest=new_steward_did)
+    """"""Adding new trustee""""""
+    sdk_add_new_nym(looper, sdk_pool_handle,
+                    sdk_wallet_trustee, 'newTrustee', TRUSTEE_STRING, verkey=new_trustee_verkey, dest=new_trustee_did)
+    op = {'type': '1',
+          'dest': new_steward_did,
+          'role': None}
+    if with_verkey:
+        op['verkey'] = new_steward_verkey
+    """"""Blacklisting new steward by new trustee""""""
+    req = sdk_sign_and_submit_op(looper, sdk_pool_handle, (sdk_wallet_handle, new_trustee_did), op)
+    if with_verkey:
+        with pytest.raises(RequestRejectedException):
+            sdk_get_and_check_replies(looper, [req])
+    else:
+        sdk_get_and_check_replies(looper, [req])
+
+
+def test_steward_cannot_work_after_demote(looper,",,2019-01-16 12:46:34,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/248243212,https://github.com/hyperledger/indy-node/pull/1130#discussion_r248243212,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1121,https://github.com/hyperledger/indy-node/pull/1121,"Since `python-distro` doesn't present in Ubuntu 16.04 canonical repo, we need to build it manually in `build-3rd-parties.sh` (`build_from_pypi distro 1.3.0`)",421fb2efe7f880f4cd089e1c33489f1915c822ab,2019-01-14 06:33:52,247392558,"@@ -58,7 +58,8 @@
     )],
     install_requires=['indy-plenum-dev==1.6.646',
                       'python-dateutil',
-                      'timeout-decorator==0.4.0'],
+                      'timeout-decorator==0.4.0',
+                      'distro==1.3.0'],",6,2019-01-14 09:16:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/247392558,https://github.com/hyperledger/indy-node/pull/1121#discussion_r247392558,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1121,https://github.com/hyperledger/indy-node/pull/1121,ok,421fb2efe7f880f4cd089e1c33489f1915c822ab,2019-01-14 06:54:22,247394843,"@@ -58,7 +58,8 @@
     )],
     install_requires=['indy-plenum-dev==1.6.646',
                       'python-dateutil',
-                      'timeout-decorator==0.4.0'],
+                      'timeout-decorator==0.4.0',
+                      'distro==1.3.0'],",6,2019-01-14 09:16:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/247394843,https://github.com/hyperledger/indy-node/pull/1121#discussion_r247394843,ArtObr
https://github.com/hyperledger/indy-node/pull/1119,https://github.com/hyperledger/indy-node/pull/1119,It would be better to have all attributes maximum length,1aea33e82c619622dd702f3923a53e3ae09f10fa,2019-01-10 08:28:35,246669037,"@@ -48,3 +51,39 @@ def test_can_not_send_same_schema(looper, sdk_pool_handle,
     ex_info.match(
         ""can have one and only one SCHEMA with name business and version 1.8""
     )
+
+
+def test_schema_maximum_attrib(looper, sdk_pool_handle,
+                               sdk_wallet_trust_anchor):
+    attribs = []
+    string = randomString(NAME_FIELD_LIMIT)
+    for i in range(SCHEMA_ATTRIBUTES_LIMIT):
+        i = str(i)
+        attribs.append(string[:-len(i)] + i)",,2019-01-10 09:04:01,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/246669037,https://github.com/hyperledger/indy-node/pull/1119#discussion_r246669037,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1119,https://github.com/hyperledger/indy-node/pull/1119,I think we are already making maximum length here,1aea33e82c619622dd702f3923a53e3ae09f10fa,2019-01-10 08:53:52,246676309,"@@ -48,3 +51,39 @@ def test_can_not_send_same_schema(looper, sdk_pool_handle,
     ex_info.match(
         ""can have one and only one SCHEMA with name business and version 1.8""
     )
+
+
+def test_schema_maximum_attrib(looper, sdk_pool_handle,
+                               sdk_wallet_trust_anchor):
+    attribs = []
+    string = randomString(NAME_FIELD_LIMIT)
+    for i in range(SCHEMA_ATTRIBUTES_LIMIT):
+        i = str(i)
+        attribs.append(string[:-len(i)] + i)",,2019-01-10 09:04:01,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/246676309,https://github.com/hyperledger/indy-node/pull/1119#discussion_r246676309,ArtObr
https://github.com/hyperledger/indy-node/pull/1119,https://github.com/hyperledger/indy-node/pull/1119,simplified,1aea33e82c619622dd702f3923a53e3ae09f10fa,2019-01-10 09:00:01,246678149,"@@ -48,3 +51,39 @@ def test_can_not_send_same_schema(looper, sdk_pool_handle,
     ex_info.match(
         ""can have one and only one SCHEMA with name business and version 1.8""
     )
+
+
+def test_schema_maximum_attrib(looper, sdk_pool_handle,
+                               sdk_wallet_trust_anchor):
+    attribs = []
+    string = randomString(NAME_FIELD_LIMIT)
+    for i in range(SCHEMA_ATTRIBUTES_LIMIT):
+        i = str(i)
+        attribs.append(string[:-len(i)] + i)",,2019-01-10 09:04:01,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/246678149,https://github.com/hyperledger/indy-node/pull/1119#discussion_r246678149,ArtObr
https://github.com/hyperledger/indy-node/pull/1117,https://github.com/hyperledger/indy-node/pull/1117,Not allowing trustees to create network monitors (while allowing stewards) seems weird,38dec0544a68bd2128f290082d7bb8e4a40a7acd,2019-01-09 11:19:03,246345695,"@@ -175,13 +184,14 @@
            addNewSteward.get_action_id(): AuthConstraint(TRUSTEE, 1),
            addNewTrustAnchor.get_action_id(): AuthConstraintOr([AuthConstraint(TRUSTEE, 1),
                                                                 AuthConstraint(STEWARD, 1)]),
+           addNewNetworkMonitor.get_action_id(): AuthConstraint(STEWARD, 1),",,2019-01-09 15:29:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/246345695,https://github.com/hyperledger/indy-node/pull/1117#discussion_r246345695,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1117,https://github.com/hyperledger/indy-node/pull/1117,Incorrect test name,38dec0544a68bd2128f290082d7bb8e4a40a7acd,2019-01-10 08:30:27,246669516,"@@ -3,7 +3,7 @@
 
 
 def test_pool_restart_add_action(write_request_validation, is_owner, req):",3,2019-01-10 08:30:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/246669516,https://github.com/hyperledger/indy-node/pull/1117#discussion_r246669516,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1116,https://github.com/hyperledger/indy-node/pull/1116,"Why do we need so many overrides and patches? Can't we just have a more simple test similar to other tests in `upgrade` folder? For example, `test_upgrade_does_not_get_into_loop`?",4e36b5e1e4a4fb91d3f2223bbc77aa6fe2fb5dfe,2019-01-11 09:01:22,247042040,"@@ -0,0 +1,159 @@
+import asyncio
+from functools import partial
+
+import dateutil
+import dateutil.tz
+import pytest
+
+from datetime import datetime, timedelta
+
+from copy import deepcopy
+
+from indy_common.constants import START
+
+from indy_node.test.upgrade.conftest import patch_packet_mgr_output, EXT_PKT_NAME, EXT_PKT_VERSION
+
+from indy_common.config_helper import NodeConfigHelper
+
+from indy_node.server.upgrader import Upgrader, UpgradeMessage
+from indy_node.test.helper import TEST_INITIAL_NODE_VERSION
+from indy_node.test.upgrade.helper import sdk_ensure_upgrade_sent, bumpedVersion
+from plenum.test.helper import randomText
+
+from plenum.test.test_node import ensureElectionsDone, checkNodesConnected
+from stp_core.common.log import getlogger
+
+delta = 2
+logger = getlogger()
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    old_delta = tconf.MinSepBetweenNodeUpgrades
+    tconf.MinSepBetweenNodeUpgrades = delta
+    yield tconf
+    tconf.MinSepBetweenNodeUpgrades = old_delta
+
+
+@pytest.fixture(scope='function')
+def validUpgrade(nodeIds, tconf, monkeypatch):
+    schedule = {}
+    unow = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
+    startAt = unow + timedelta(seconds=100)
+    acceptableDiff = tconf.MinSepBetweenNodeUpgrades + 1
+    for i in nodeIds:
+        schedule[i] = datetime.isoformat(startAt)
+        startAt = startAt + timedelta(seconds=acceptableDiff + 3)
+
+    patch_packet_mgr_output(monkeypatch, EXT_PKT_NAME, EXT_PKT_VERSION)
+
+    return dict(name='upgrade-{}'.format(randomText(3)), version=bumpedVersion(EXT_PKT_VERSION),
+                action=START, schedule=schedule, timeout=1, package=EXT_PKT_NAME,
+                sha256='db34a72a90d026dae49c3b3f0436c8d3963476c77468ad955845a1ccf7b03f55')
+
+
+@pytest.fixture(scope='function')
+def skip_functions():
+    # Do this to prevent exceptions because of node_control_tool absence
+    old_get_version = deepcopy(Upgrader.getVersion)
+    old_update = deepcopy(Upgrader._update_action_log_for_started_action)
+    Upgrader.getVersion = lambda self, pkg: '1.6.0'
+    Upgrader._update_action_log_for_started_action = lambda self: 1
+    yield
+    Upgrader.getVersion = staticmethod(old_get_version)
+    Upgrader._update_action_log_for_started_action = old_update
+
+
+async def _sendUpgradeRequest(self, when, version, upgrade_id, failTimeout, pkg_name):",,2019-01-11 15:49:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/247042040,https://github.com/hyperledger/indy-node/pull/1116#discussion_r247042040,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1116,https://github.com/hyperledger/indy-node/pull/1116,fixed,4e36b5e1e4a4fb91d3f2223bbc77aa6fe2fb5dfe,2019-01-11 12:54:54,247106208,"@@ -0,0 +1,159 @@
+import asyncio
+from functools import partial
+
+import dateutil
+import dateutil.tz
+import pytest
+
+from datetime import datetime, timedelta
+
+from copy import deepcopy
+
+from indy_common.constants import START
+
+from indy_node.test.upgrade.conftest import patch_packet_mgr_output, EXT_PKT_NAME, EXT_PKT_VERSION
+
+from indy_common.config_helper import NodeConfigHelper
+
+from indy_node.server.upgrader import Upgrader, UpgradeMessage
+from indy_node.test.helper import TEST_INITIAL_NODE_VERSION
+from indy_node.test.upgrade.helper import sdk_ensure_upgrade_sent, bumpedVersion
+from plenum.test.helper import randomText
+
+from plenum.test.test_node import ensureElectionsDone, checkNodesConnected
+from stp_core.common.log import getlogger
+
+delta = 2
+logger = getlogger()
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    old_delta = tconf.MinSepBetweenNodeUpgrades
+    tconf.MinSepBetweenNodeUpgrades = delta
+    yield tconf
+    tconf.MinSepBetweenNodeUpgrades = old_delta
+
+
+@pytest.fixture(scope='function')
+def validUpgrade(nodeIds, tconf, monkeypatch):
+    schedule = {}
+    unow = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
+    startAt = unow + timedelta(seconds=100)
+    acceptableDiff = tconf.MinSepBetweenNodeUpgrades + 1
+    for i in nodeIds:
+        schedule[i] = datetime.isoformat(startAt)
+        startAt = startAt + timedelta(seconds=acceptableDiff + 3)
+
+    patch_packet_mgr_output(monkeypatch, EXT_PKT_NAME, EXT_PKT_VERSION)
+
+    return dict(name='upgrade-{}'.format(randomText(3)), version=bumpedVersion(EXT_PKT_VERSION),
+                action=START, schedule=schedule, timeout=1, package=EXT_PKT_NAME,
+                sha256='db34a72a90d026dae49c3b3f0436c8d3963476c77468ad955845a1ccf7b03f55')
+
+
+@pytest.fixture(scope='function')
+def skip_functions():
+    # Do this to prevent exceptions because of node_control_tool absence
+    old_get_version = deepcopy(Upgrader.getVersion)
+    old_update = deepcopy(Upgrader._update_action_log_for_started_action)
+    Upgrader.getVersion = lambda self, pkg: '1.6.0'
+    Upgrader._update_action_log_for_started_action = lambda self: 1
+    yield
+    Upgrader.getVersion = staticmethod(old_get_version)
+    Upgrader._update_action_log_for_started_action = old_update
+
+
+async def _sendUpgradeRequest(self, when, version, upgrade_id, failTimeout, pkg_name):",,2019-01-11 15:49:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/247106208,https://github.com/hyperledger/indy-node/pull/1116#discussion_r247106208,ArtObr
https://github.com/hyperledger/indy-node/pull/1116,https://github.com/hyperledger/indy-node/pull/1116,Why can't we use existing `validUpgrade` fixture and update its output if needed?,4e36b5e1e4a4fb91d3f2223bbc77aa6fe2fb5dfe,2019-01-11 12:59:10,247107256,"@@ -0,0 +1,69 @@
+import dateutil
+import dateutil.tz
+import pytest
+
+from datetime import datetime, timedelta
+from copy import deepcopy
+from indy_common.constants import START
+from indy_node.test.upgrade.conftest import patch_packet_mgr_output, EXT_PKT_NAME, EXT_PKT_VERSION
+
+from indy_node.server.upgrader import Upgrader
+from indy_node.test.upgrade.helper import sdk_ensure_upgrade_sent, bumpedVersion
+from plenum.test.helper import randomText
+
+from stp_core.common.log import getlogger
+
+delta = 2
+logger = getlogger()
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    old_delta = tconf.MinSepBetweenNodeUpgrades
+    tconf.MinSepBetweenNodeUpgrades = delta
+    yield tconf
+    tconf.MinSepBetweenNodeUpgrades = old_delta
+
+
+@pytest.fixture(scope='function')
+def validUpgrade(nodeIds, tconf, monkeypatch):",,2019-01-11 15:49:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/247107256,https://github.com/hyperledger/indy-node/pull/1116#discussion_r247107256,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1116,https://github.com/hyperledger/indy-node/pull/1116,"Can we check that Upgrade actually didn't happen in this case, that is we are still on the same version?",4e36b5e1e4a4fb91d3f2223bbc77aa6fe2fb5dfe,2019-01-11 12:59:46,247107391,"@@ -0,0 +1,69 @@
+import dateutil
+import dateutil.tz
+import pytest
+
+from datetime import datetime, timedelta
+from copy import deepcopy
+from indy_common.constants import START
+from indy_node.test.upgrade.conftest import patch_packet_mgr_output, EXT_PKT_NAME, EXT_PKT_VERSION
+
+from indy_node.server.upgrader import Upgrader
+from indy_node.test.upgrade.helper import sdk_ensure_upgrade_sent, bumpedVersion
+from plenum.test.helper import randomText
+
+from stp_core.common.log import getlogger
+
+delta = 2
+logger = getlogger()
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    old_delta = tconf.MinSepBetweenNodeUpgrades
+    tconf.MinSepBetweenNodeUpgrades = delta
+    yield tconf
+    tconf.MinSepBetweenNodeUpgrades = old_delta
+
+
+@pytest.fixture(scope='function')
+def validUpgrade(nodeIds, tconf, monkeypatch):
+    schedule = {}
+    unow = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
+    startAt = unow + timedelta(seconds=delta)
+    for i in nodeIds:
+        schedule[i] = datetime.isoformat(startAt)
+        startAt = startAt + timedelta(seconds=delta)
+
+    patch_packet_mgr_output(monkeypatch, EXT_PKT_NAME, EXT_PKT_VERSION)
+
+    return dict(name='upgrade-{}'.format(randomText(3)), version=bumpedVersion(EXT_PKT_VERSION),
+                action=START, schedule=schedule, timeout=1, package=EXT_PKT_NAME,
+                sha256='db34a72a90d026dae49c3b3f0436c8d3963476c77468ad955845a1ccf7b03f55')
+
+
+@pytest.fixture(scope='function')
+def skip_functions():
+    # Do this to prevent exceptions because of node_control_tool absence
+    old_action_failed = deepcopy(Upgrader._action_failed)
+
+    Upgrader._action_failed = \
+        lambda self, version, scheduled_on, upgrade_id, external_reason: 1
+    yield
+    Upgrader._action_failed = old_action_failed
+
+
+def test_node_doesnt_retry_upgrade(looper, nodeSet, validUpgrade, nodeIds,
+                                   sdk_pool_handle, sdk_wallet_trustee, tconf,
+                                   skip_functions):
+    # Emulating connection problems
+    for node in nodeSet:
+        node.upgrader.retry_limit = 0
+
+    # Send upgrade
+    sdk_ensure_upgrade_sent(looper, sdk_pool_handle,
+                            sdk_wallet_trustee, validUpgrade)
+    looper.runFor(len(nodeIds) * delta)
+",63,2019-01-11 15:49:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/247107391,https://github.com/hyperledger/indy-node/pull/1116#discussion_r247107391,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1116,https://github.com/hyperledger/indy-node/pull/1116,existing validUpgrade parametrized with different kind of versions. But probably that doesn't matter. Will change it,4e36b5e1e4a4fb91d3f2223bbc77aa6fe2fb5dfe,2019-01-11 13:08:45,247109596,"@@ -0,0 +1,69 @@
+import dateutil
+import dateutil.tz
+import pytest
+
+from datetime import datetime, timedelta
+from copy import deepcopy
+from indy_common.constants import START
+from indy_node.test.upgrade.conftest import patch_packet_mgr_output, EXT_PKT_NAME, EXT_PKT_VERSION
+
+from indy_node.server.upgrader import Upgrader
+from indy_node.test.upgrade.helper import sdk_ensure_upgrade_sent, bumpedVersion
+from plenum.test.helper import randomText
+
+from stp_core.common.log import getlogger
+
+delta = 2
+logger = getlogger()
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    old_delta = tconf.MinSepBetweenNodeUpgrades
+    tconf.MinSepBetweenNodeUpgrades = delta
+    yield tconf
+    tconf.MinSepBetweenNodeUpgrades = old_delta
+
+
+@pytest.fixture(scope='function')
+def validUpgrade(nodeIds, tconf, monkeypatch):",,2019-01-11 15:49:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/247109596,https://github.com/hyperledger/indy-node/pull/1116#discussion_r247109596,ArtObr
https://github.com/hyperledger/indy-node/pull/1112,https://github.com/hyperledger/indy-node/pull/1112,"The method can return None if the role is None. But this can be a valid role, if auth constraint has `*` as a role.
So, `is_role_accepted` can return two possible errors:
- did doesn't exist on the ledger (if there is a KeyError in `get_role`)
- role X can not do the operation (if role doesn't match the auth constraint, regardless of whether the role is None or not)",e7aef6d8020a6d66b613ee21f651c4d769ab7d74,2018-12-25 06:33:58,243880027,"@@ -66,7 +66,10 @@ def authorize(self,
                   request: Request,
                   auth_constraint: AuthConstraint,
                   auth_action: AbstractAuthAction=None):
-        if not self.is_role_accepted(request, auth_constraint):
+        is_role_accepted = self.is_role_accepted(request, auth_constraint)
+        if is_role_accepted is None:
+            return False, ""role is not found""",,2018-12-25 15:26:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243880027,https://github.com/hyperledger/indy-node/pull/1112#discussion_r243880027,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1112,https://github.com/hyperledger/indy-node/pull/1112,"'None' roles are stored as empty strings, so the role returned as None means that sender's DID is not found in a ledger. Left a comment regarding this.",e7aef6d8020a6d66b613ee21f651c4d769ab7d74,2018-12-25 10:35:44,243899228,"@@ -66,7 +66,10 @@ def authorize(self,
                   request: Request,
                   auth_constraint: AuthConstraint,
                   auth_action: AbstractAuthAction=None):
-        if not self.is_role_accepted(request, auth_constraint):
+        is_role_accepted = self.is_role_accepted(request, auth_constraint)
+        if is_role_accepted is None:
+            return False, ""role is not found""",,2018-12-25 15:26:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243899228,https://github.com/hyperledger/indy-node/pull/1112#discussion_r243899228,sergey-shilov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,Please add a png version of the diagram as well,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 06:46:28,243880833,"@@ -0,0 +1,92 @@
+@startuml",1,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243880833,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243880833,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,ok,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 07:34:30,243884211,"@@ -0,0 +1,92 @@
+@startuml",1,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243884211,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243884211,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"I think we should avoid registering `post_xxx_handlers` here. The idea is to instantiate and new `BatchHandler` if we want a handler, and register it in `WriteRequestManager`, not in `DomainBatchHandler`.
",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 08:05:05,243886733,"@@ -0,0 +1,69 @@
+from collections import Callable
+
+import base58
+
+from plenum.server.batch_handlers.domain_batch_handler import DomainBatchHandler as PDomainBatchHandler
+from plenum.server.database_manager import DatabaseManager
+
+
+class DomainBatchHandler(PDomainBatchHandler):
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager)
+        self.post_batch_creation_handlers = []",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243886733,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243886733,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,This needs to be a separate class `IdrCacheBatchHandler` that extends `BatchHandler`.,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 08:05:55,243886781,"@@ -0,0 +1,69 @@
+from collections import Callable
+
+import base58
+
+from plenum.server.batch_handlers.domain_batch_handler import DomainBatchHandler as PDomainBatchHandler
+from plenum.server.database_manager import DatabaseManager
+
+
+class DomainBatchHandler(PDomainBatchHandler):
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager)
+        self.post_batch_creation_handlers = []
+        self.post_batch_commit_handlers = []
+        self.post_batch_rejection_handlers = []
+
+        self._add_default_handlers()
+
+    def commit_batch(self, txn_count, state_root, txn_root, pp_time):
+        result = super().commit_batch(txn_count, state_root, txn_root, pp_time)
+        self.post_batch_commited(state_root)
+        return result
+
+    def post_batch_applied(self, state_root):
+        for handler in self.post_batch_creation_handlers:
+            handler(state_root)
+
+    def post_batch_rejected(self):
+        for handler in self.post_batch_rejection_handlers:
+            handler()
+
+    def post_batch_commited(self, state_root):
+        for handler in self.post_batch_commit_handlers:
+            handler(state_root)
+
+    def _add_default_handlers(self):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243886781,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243886781,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,This needs to be private,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 08:13:52,243887393,"@@ -0,0 +1,72 @@
+from indy_common.state import domain
+
+from indy_common.constants import ATTRIB
+from plenum.common.constants import DOMAIN_LEDGER_ID, RAW, ENC, HASH, TARGET_NYM
+from plenum.common.exceptions import InvalidClientRequest, UnauthorizedClientRequest
+
+from plenum.common.request import Request
+from plenum.common.txn_util import get_type, get_request_data
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler
+
+
+class AttributeHandler(WriteRequestHandler):
+
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager, ATTRIB, DOMAIN_LEDGER_ID)
+
+    def static_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        if not self._validate_attrib_keys(operation):
+            raise InvalidClientRequest(identifier, req_id,
+                                       '{} should have one and only one of '
+                                       '{}, {}, {}'
+                                       .format(ATTRIB, RAW, ENC, HASH))
+
+    def dynamic_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        if not (not operation.get(TARGET_NYM) or
+                self.has_nym(operation[TARGET_NYM], isCommitted=False)):
+            raise InvalidClientRequest(identifier, req_id,
+                                       '{} should be added before adding '
+                                       'attribute for it'.
+                                       format(TARGET_NYM))
+
+        if operation.get(TARGET_NYM) and operation[TARGET_NYM] != identifier and \
+                not self.database_manager.idr_cache.getOwnerFor(operation[TARGET_NYM],
+                                                                isCommitted=False) == identifier:
+            raise UnauthorizedClientRequest(
+                identifier,
+                req_id,
+                ""Only identity owner/guardian can add attribute ""
+                ""for that identity"")
+
+    def gen_txn_path(self, txn):
+        path = domain.prepare_attr_for_state(txn, path_only=True)
+        return path.decode()
+
+    def _update_state_with_single_txn(self, txn, isCommitted=False) -> None:
+        """"""
+        The state trie stores the hash of the whole attribute data at:
+            the did+attribute name if the data is plaintext (RAW)
+            the did+hash(attribute) if the data is encrypted (ENC)
+        If the attribute is HASH, then nothing is stored in attribute store,
+        the trie stores a blank value for the key did+hash
+        """"""
+        assert get_type(txn) == ATTRIB
+        attr_type, path, value, hashed_value, value_bytes = domain.prepare_attr_for_state(txn)
+        self.state.set(path, value_bytes)
+        if attr_type != HASH:
+            self.database_manager.attribute_store.set(hashed_value, value)
+
+    def has_nym(self, nym, isCommitted: bool = True):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243887393,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243887393,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"This needs to be `update_state`, or make a common `update_state` in `WriteReqHandler` that iterates through each txn and calls `_update_state_with_single_txn`.",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 08:15:01,243887477,"@@ -0,0 +1,72 @@
+from indy_common.state import domain
+
+from indy_common.constants import ATTRIB
+from plenum.common.constants import DOMAIN_LEDGER_ID, RAW, ENC, HASH, TARGET_NYM
+from plenum.common.exceptions import InvalidClientRequest, UnauthorizedClientRequest
+
+from plenum.common.request import Request
+from plenum.common.txn_util import get_type, get_request_data
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler
+
+
+class AttributeHandler(WriteRequestHandler):
+
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager, ATTRIB, DOMAIN_LEDGER_ID)
+
+    def static_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        if not self._validate_attrib_keys(operation):
+            raise InvalidClientRequest(identifier, req_id,
+                                       '{} should have one and only one of '
+                                       '{}, {}, {}'
+                                       .format(ATTRIB, RAW, ENC, HASH))
+
+    def dynamic_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        if not (not operation.get(TARGET_NYM) or
+                self.has_nym(operation[TARGET_NYM], isCommitted=False)):
+            raise InvalidClientRequest(identifier, req_id,
+                                       '{} should be added before adding '
+                                       'attribute for it'.
+                                       format(TARGET_NYM))
+
+        if operation.get(TARGET_NYM) and operation[TARGET_NYM] != identifier and \
+                not self.database_manager.idr_cache.getOwnerFor(operation[TARGET_NYM],
+                                                                isCommitted=False) == identifier:
+            raise UnauthorizedClientRequest(
+                identifier,
+                req_id,
+                ""Only identity owner/guardian can add attribute ""
+                ""for that identity"")
+
+    def gen_txn_path(self, txn):
+        path = domain.prepare_attr_for_state(txn, path_only=True)
+        return path.decode()
+
+    def _update_state_with_single_txn(self, txn, isCommitted=False) -> None:",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243887477,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243887477,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,Please use the latest code from master with the latest Validator approach for every txn type,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 08:16:21,243887576,"@@ -0,0 +1,68 @@
+from indy_common.auth import Authoriser
+
+from indy_common.state import domain
+
+from indy_common.constants import CLAIM_DEF, REF, SCHEMA
+
+from plenum.common.constants import DOMAIN_LEDGER_ID
+from plenum.common.exceptions import UnauthorizedClientRequest, UnknownIdentifier, InvalidClientRequest
+from plenum.common.request import Request
+from plenum.common.roles import Roles
+from plenum.common.txn_util import get_type
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler
+
+
+class ClaimDefHandler(WriteRequestHandler):
+
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager, CLAIM_DEF, DOMAIN_LEDGER_ID)
+
+    def static_validation(self, request: Request):
+        pass
+
+    def dynamic_validation(self, request: Request):",26,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243887576,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243887576,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"Please make it private, or better combine with `_update_state_with_single_txn`",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 08:19:21,243887808,"@@ -0,0 +1,133 @@
+from binascii import hexlify
+
+from indy_common.state import domain
+
+from indy_common.roles import Roles
+
+from indy_common.constants import NYM
+
+from indy_common.auth import Authoriser
+from plenum.common.constants import ROLE, TARGET_NYM, TRUSTEE, VERKEY, TXN_TIME
+
+from plenum.common.exceptions import InvalidClientRequest, UnknownIdentifier, UnauthorizedClientRequest
+from plenum.common.request import Request
+from plenum.common.txn_util import get_payload_data, get_from, get_seq_no, get_txn_time, get_request_data
+from plenum.common.types import f
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.nym_handler import NymHandler as PNymHandler
+
+
+class NymHandler(PNymHandler):
+
+    def __init__(self, config, database_manager: DatabaseManager):
+        super().__init__(config, database_manager)
+
+    def static_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+        role = operation.get(ROLE)
+        nym = operation.get(TARGET_NYM)
+        if isinstance(nym, str):
+            nym = nym.strip()
+        if not nym:
+            raise InvalidClientRequest(identifier, req_id,
+                                       ""{} needs to be present"".
+                                       format(TARGET_NYM))
+        if not Authoriser.isValidRole(role):
+            raise InvalidClientRequest(identifier, req_id,
+                                       ""{} not a valid role"".
+                                       format(role))
+
+    def dynamic_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+        try:
+            origin_role = self.database_manager.idr_cache.getRole(
+                identifier, isCommitted=False) or None
+        except BaseException:
+            raise UnknownIdentifier(
+                identifier,
+                req_id)
+
+        nym_data = self.database_manager.idr_cache.getNym(operation[TARGET_NYM], isCommitted=False)
+        if not nym_data:
+            # If nym does not exist
+            self._validate_new_nym(identifier, req_id, operation, origin_role)
+        else:
+            self._validate_existing_nym(identifier, req_id, operation, origin_role, nym_data)
+
+    def gen_txn_path(self, txn):
+        nym = get_payload_data(txn).get(TARGET_NYM)
+        binary_digest = domain.make_state_path_for_nym(nym)
+        return hexlify(binary_digest).decode()
+
+    def _update_state_with_single_txn(self, txn, isCommitted=False):
+        txn_data = get_payload_data(txn)
+        nym = txn_data.get(TARGET_NYM)
+        data = {
+            f.IDENTIFIER.nm: get_from(txn),
+            f.SEQ_NO.nm: get_seq_no(txn),
+            TXN_TIME: get_txn_time(txn)
+        }
+        if ROLE in txn_data:
+            data[ROLE] = txn_data.get(ROLE)
+        if VERKEY in txn_data:
+            data[VERKEY] = txn_data.get(VERKEY)
+        self.update_nym(nym, txn, isCommitted=isCommitted)
+
+    def update_nym(self, nym, txn, isCommitted=True):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243887808,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243887808,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,Do we really want to extend Plenum's Nym Handler here?,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 08:19:51,243887859,"@@ -0,0 +1,133 @@
+from binascii import hexlify
+
+from indy_common.state import domain
+
+from indy_common.roles import Roles
+
+from indy_common.constants import NYM
+
+from indy_common.auth import Authoriser
+from plenum.common.constants import ROLE, TARGET_NYM, TRUSTEE, VERKEY, TXN_TIME
+
+from plenum.common.exceptions import InvalidClientRequest, UnknownIdentifier, UnauthorizedClientRequest
+from plenum.common.request import Request
+from plenum.common.txn_util import get_payload_data, get_from, get_seq_no, get_txn_time, get_request_data
+from plenum.common.types import f
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.nym_handler import NymHandler as PNymHandler
+
+
+class NymHandler(PNymHandler):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243887859,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243887859,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,I think we need to implement all Domain ReadRequestHandlers in the scope of INDY-1857,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 08:25:21,243888355,"@@ -0,0 +1,5 @@
+from indy_node.server.request_handlers.read_request_handler import ReadRequestHandler
+
+
+class GetNymHandler(ReadRequestHandler):",13,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243888355,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243888355,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,fixed,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 14:52:48,243913677,"@@ -0,0 +1,69 @@
+from collections import Callable
+
+import base58
+
+from plenum.server.batch_handlers.domain_batch_handler import DomainBatchHandler as PDomainBatchHandler
+from plenum.server.database_manager import DatabaseManager
+
+
+class DomainBatchHandler(PDomainBatchHandler):
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager)
+        self.post_batch_creation_handlers = []",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243913677,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243913677,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,fixed,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-25 14:53:00,243913686,"@@ -0,0 +1,69 @@
+from collections import Callable
+
+import base58
+
+from plenum.server.batch_handlers.domain_batch_handler import DomainBatchHandler as PDomainBatchHandler
+from plenum.server.database_manager import DatabaseManager
+
+
+class DomainBatchHandler(PDomainBatchHandler):
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager)
+        self.post_batch_creation_handlers = []
+        self.post_batch_commit_handlers = []
+        self.post_batch_rejection_handlers = []
+
+        self._add_default_handlers()
+
+    def commit_batch(self, txn_count, state_root, txn_root, pp_time):
+        result = super().commit_batch(txn_count, state_root, txn_root, pp_time)
+        self.post_batch_commited(state_root)
+        return result
+
+    def post_batch_applied(self, state_root):
+        for handler in self.post_batch_creation_handlers:
+            handler(state_root)
+
+    def post_batch_rejected(self):
+        for handler in self.post_batch_rejection_handlers:
+            handler()
+
+    def post_batch_commited(self, state_root):
+        for handler in self.post_batch_commit_handlers:
+            handler(state_root)
+
+    def _add_default_handlers(self):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243913686,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243913686,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"Agreed, i will make it protected",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-26 07:19:22,243953155,"@@ -0,0 +1,133 @@
+from binascii import hexlify
+
+from indy_common.state import domain
+
+from indy_common.roles import Roles
+
+from indy_common.constants import NYM
+
+from indy_common.auth import Authoriser
+from plenum.common.constants import ROLE, TARGET_NYM, TRUSTEE, VERKEY, TXN_TIME
+
+from plenum.common.exceptions import InvalidClientRequest, UnknownIdentifier, UnauthorizedClientRequest
+from plenum.common.request import Request
+from plenum.common.txn_util import get_payload_data, get_from, get_seq_no, get_txn_time, get_request_data
+from plenum.common.types import f
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.nym_handler import NymHandler as PNymHandler
+
+
+class NymHandler(PNymHandler):
+
+    def __init__(self, config, database_manager: DatabaseManager):
+        super().__init__(config, database_manager)
+
+    def static_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+        role = operation.get(ROLE)
+        nym = operation.get(TARGET_NYM)
+        if isinstance(nym, str):
+            nym = nym.strip()
+        if not nym:
+            raise InvalidClientRequest(identifier, req_id,
+                                       ""{} needs to be present"".
+                                       format(TARGET_NYM))
+        if not Authoriser.isValidRole(role):
+            raise InvalidClientRequest(identifier, req_id,
+                                       ""{} not a valid role"".
+                                       format(role))
+
+    def dynamic_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+        try:
+            origin_role = self.database_manager.idr_cache.getRole(
+                identifier, isCommitted=False) or None
+        except BaseException:
+            raise UnknownIdentifier(
+                identifier,
+                req_id)
+
+        nym_data = self.database_manager.idr_cache.getNym(operation[TARGET_NYM], isCommitted=False)
+        if not nym_data:
+            # If nym does not exist
+            self._validate_new_nym(identifier, req_id, operation, origin_role)
+        else:
+            self._validate_existing_nym(identifier, req_id, operation, origin_role, nym_data)
+
+    def gen_txn_path(self, txn):
+        nym = get_payload_data(txn).get(TARGET_NYM)
+        binary_digest = domain.make_state_path_for_nym(nym)
+        return hexlify(binary_digest).decode()
+
+    def _update_state_with_single_txn(self, txn, isCommitted=False):
+        txn_data = get_payload_data(txn)
+        nym = txn_data.get(TARGET_NYM)
+        data = {
+            f.IDENTIFIER.nm: get_from(txn),
+            f.SEQ_NO.nm: get_seq_no(txn),
+            TXN_TIME: get_txn_time(txn)
+        }
+        if ROLE in txn_data:
+            data[ROLE] = txn_data.get(ROLE)
+        if VERKEY in txn_data:
+            data[VERKEY] = txn_data.get(VERKEY)
+        self.update_nym(nym, txn, isCommitted=isCommitted)
+
+    def update_nym(self, nym, txn, isCommitted=True):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243953155,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243953155,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"I think, we can aviod this",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-26 08:25:24,243960781,"@@ -0,0 +1,133 @@
+from binascii import hexlify
+
+from indy_common.state import domain
+
+from indy_common.roles import Roles
+
+from indy_common.constants import NYM
+
+from indy_common.auth import Authoriser
+from plenum.common.constants import ROLE, TARGET_NYM, TRUSTEE, VERKEY, TXN_TIME
+
+from plenum.common.exceptions import InvalidClientRequest, UnknownIdentifier, UnauthorizedClientRequest
+from plenum.common.request import Request
+from plenum.common.txn_util import get_payload_data, get_from, get_seq_no, get_txn_time, get_request_data
+from plenum.common.types import f
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.nym_handler import NymHandler as PNymHandler
+
+
+class NymHandler(PNymHandler):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243960781,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243960781,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,fixed,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-26 09:00:36,243964948,"@@ -0,0 +1,72 @@
+from indy_common.state import domain
+
+from indy_common.constants import ATTRIB
+from plenum.common.constants import DOMAIN_LEDGER_ID, RAW, ENC, HASH, TARGET_NYM
+from plenum.common.exceptions import InvalidClientRequest, UnauthorizedClientRequest
+
+from plenum.common.request import Request
+from plenum.common.txn_util import get_type, get_request_data
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler
+
+
+class AttributeHandler(WriteRequestHandler):
+
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager, ATTRIB, DOMAIN_LEDGER_ID)
+
+    def static_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        if not self._validate_attrib_keys(operation):
+            raise InvalidClientRequest(identifier, req_id,
+                                       '{} should have one and only one of '
+                                       '{}, {}, {}'
+                                       .format(ATTRIB, RAW, ENC, HASH))
+
+    def dynamic_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        if not (not operation.get(TARGET_NYM) or
+                self.has_nym(operation[TARGET_NYM], isCommitted=False)):
+            raise InvalidClientRequest(identifier, req_id,
+                                       '{} should be added before adding '
+                                       'attribute for it'.
+                                       format(TARGET_NYM))
+
+        if operation.get(TARGET_NYM) and operation[TARGET_NYM] != identifier and \
+                not self.database_manager.idr_cache.getOwnerFor(operation[TARGET_NYM],
+                                                                isCommitted=False) == identifier:
+            raise UnauthorizedClientRequest(
+                identifier,
+                req_id,
+                ""Only identity owner/guardian can add attribute ""
+                ""for that identity"")
+
+    def gen_txn_path(self, txn):
+        path = domain.prepare_attr_for_state(txn, path_only=True)
+        return path.decode()
+
+    def _update_state_with_single_txn(self, txn, isCommitted=False) -> None:
+        """"""
+        The state trie stores the hash of the whole attribute data at:
+            the did+attribute name if the data is plaintext (RAW)
+            the did+hash(attribute) if the data is encrypted (ENC)
+        If the attribute is HASH, then nothing is stored in attribute store,
+        the trie stores a blank value for the key did+hash
+        """"""
+        assert get_type(txn) == ATTRIB
+        attr_type, path, value, hashed_value, value_bytes = domain.prepare_attr_for_state(txn)
+        self.state.set(path, value_bytes)
+        if attr_type != HASH:
+            self.database_manager.attribute_store.set(hashed_value, value)
+
+    def has_nym(self, nym, isCommitted: bool = True):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243964948,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243964948,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,fixed,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-26 09:24:20,243968072,"@@ -0,0 +1,72 @@
+from indy_common.state import domain
+
+from indy_common.constants import ATTRIB
+from plenum.common.constants import DOMAIN_LEDGER_ID, RAW, ENC, HASH, TARGET_NYM
+from plenum.common.exceptions import InvalidClientRequest, UnauthorizedClientRequest
+
+from plenum.common.request import Request
+from plenum.common.txn_util import get_type, get_request_data
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler
+
+
+class AttributeHandler(WriteRequestHandler):
+
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager, ATTRIB, DOMAIN_LEDGER_ID)
+
+    def static_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        if not self._validate_attrib_keys(operation):
+            raise InvalidClientRequest(identifier, req_id,
+                                       '{} should have one and only one of '
+                                       '{}, {}, {}'
+                                       .format(ATTRIB, RAW, ENC, HASH))
+
+    def dynamic_validation(self, request: Request):
+        self._validate_type(request)
+        identifier, req_id, operation = get_request_data(request)
+
+        if not (not operation.get(TARGET_NYM) or
+                self.has_nym(operation[TARGET_NYM], isCommitted=False)):
+            raise InvalidClientRequest(identifier, req_id,
+                                       '{} should be added before adding '
+                                       'attribute for it'.
+                                       format(TARGET_NYM))
+
+        if operation.get(TARGET_NYM) and operation[TARGET_NYM] != identifier and \
+                not self.database_manager.idr_cache.getOwnerFor(operation[TARGET_NYM],
+                                                                isCommitted=False) == identifier:
+            raise UnauthorizedClientRequest(
+                identifier,
+                req_id,
+                ""Only identity owner/guardian can add attribute ""
+                ""for that identity"")
+
+    def gen_txn_path(self, txn):
+        path = domain.prepare_attr_for_state(txn, path_only=True)
+        return path.decode()
+
+    def _update_state_with_single_txn(self, txn, isCommitted=False) -> None:",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243968072,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243968072,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,done,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-26 10:56:38,243980333,"@@ -0,0 +1,68 @@
+from indy_common.auth import Authoriser
+
+from indy_common.state import domain
+
+from indy_common.constants import CLAIM_DEF, REF, SCHEMA
+
+from plenum.common.constants import DOMAIN_LEDGER_ID
+from plenum.common.exceptions import UnauthorizedClientRequest, UnknownIdentifier, InvalidClientRequest
+from plenum.common.request import Request
+from plenum.common.roles import Roles
+from plenum.common.txn_util import get_type
+from plenum.server.database_manager import DatabaseManager
+from plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler
+
+
+class ClaimDefHandler(WriteRequestHandler):
+
+    def __init__(self, database_manager: DatabaseManager):
+        super().__init__(database_manager, CLAIM_DEF, DOMAIN_LEDGER_ID)
+
+    def static_validation(self, request: Request):
+        pass
+
+    def dynamic_validation(self, request: Request):",26,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243980333,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243980333,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,ok,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-26 11:07:22,243981566,"@@ -0,0 +1,5 @@
+from indy_node.server.request_handlers.read_request_handler import ReadRequestHandler
+
+
+class GetNymHandler(ReadRequestHandler):",13,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243981566,https://github.com/hyperledger/indy-node/pull/1111#discussion_r243981566,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,is_committed needs to be False by default,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-27 06:39:10,244091225,"@@ -46,24 +46,25 @@ def dynamic_validation(self, request: Request):
                 ""for that identity"")
 
     def gen_txn_path(self, txn):
+        self._validate_txn_type(txn)
         path = domain.prepare_attr_for_state(txn, path_only=True)
         return path.decode()
 
-    def _update_state_with_single_txn(self, txn, isCommitted=False) -> None:
+    def _update_state_with_single_txn(self, txn, is_committed=True) -> None:",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244091225,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244091225,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"It would be great to have everything related to IdrCache in one place. What about creating `IdrCacheHandler` which implements both Batch and Write RequestHandlers, and move the logic from IdrCacheBatchHandler as well as `idr_cache.set` there?",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-27 06:52:04,244092668,"@@ -57,39 +59,47 @@ def dynamic_validation(self, request: Request):
             self._validate_existing_nym(identifier, req_id, operation, origin_role, nym_data)
 
     def gen_txn_path(self, txn):
+        self._validate_txn_type(txn)
         nym = get_payload_data(txn).get(TARGET_NYM)
         binary_digest = domain.make_state_path_for_nym(nym)
         return hexlify(binary_digest).decode()
 
-    def _update_state_with_single_txn(self, txn, isCommitted=False):
+    def _update_state_with_single_txn(self, txn, is_committed=True):
+        self._validate_txn_type(txn)
+        nym = get_payload_data(txn).get(TARGET_NYM)
+        existing_data = get_nym_details(self.state, nym,
+                                        is_committed=is_committed)
         txn_data = get_payload_data(txn)
-        nym = txn_data.get(TARGET_NYM)
-        data = {
-            f.IDENTIFIER.nm: get_from(txn),
-            f.SEQ_NO.nm: get_seq_no(txn),
-            TXN_TIME: get_txn_time(txn)
-        }
+        new_data = {}
+        if not existing_data:
+            new_data[f.IDENTIFIER.nm] = get_from(txn)
+            new_data[ROLE] = None
+            new_data[VERKEY] = None
+
         if ROLE in txn_data:
-            data[ROLE] = txn_data.get(ROLE)
+            new_data[ROLE] = txn_data[ROLE]
         if VERKEY in txn_data:
-            data[VERKEY] = txn_data.get(VERKEY)
-        self.update_nym(nym, txn, isCommitted=isCommitted)
-
-    def update_nym(self, nym, txn, isCommitted=True):
-        updatedData = super().update_nym(nym, txn, isCommitted=isCommitted)
+            new_data[VERKEY] = txn_data[VERKEY]
+        new_data[F.seqNo.name] = get_seq_no(txn)
+        new_data[TXN_TIME] = get_txn_time(txn)
+        existing_data.update(new_data)
+        val = self.state_serializer.serialize(existing_data)
+        key = nym_to_state_key(nym)
+        self.state.set(key, val)
         txn_time = get_txn_time(txn)
         self.database_manager.idr_cache.set(nym,",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244092668,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244092668,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"What about moving `lookup` and `make_result` to Plenum?
As I can see the only thing is that Plenum doesn't have `decode_state_value`. Maybe we can move it to Plenum as well?",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-27 07:08:34,244094404,"@@ -1,24 +1,43 @@
 from indy_common.state import domain
+from plenum.common.constants import DATA, TXN_TIME, STATE_PROOF
+from plenum.common.plenum_protocol_version import PlenumProtocolVersion
+from plenum.common.types import f
 
 from plenum.server.request_handlers.handler_interfaces.read_request_handler import \
     ReadRequestHandler as PReadRequestHandler
 
 
 class ReadRequestHandler(PReadRequestHandler):
 
-    def lookup(self, path, isCommitted=True, with_proof=False) -> (str, int):
+    def lookup(self, path, is_committed=True, with_proof=False) -> (str, int):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244094404,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244094404,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,fixed,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-27 10:04:13,244121562,"@@ -46,24 +46,25 @@ def dynamic_validation(self, request: Request):
                 ""for that identity"")
 
     def gen_txn_path(self, txn):
+        self._validate_txn_type(txn)
         path = domain.prepare_attr_for_state(txn, path_only=True)
         return path.decode()
 
-    def _update_state_with_single_txn(self, txn, isCommitted=False) -> None:
+    def _update_state_with_single_txn(self, txn, is_committed=True) -> None:",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244121562,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244121562,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,done,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-27 10:10:07,244122580,"@@ -1,24 +1,43 @@
 from indy_common.state import domain
+from plenum.common.constants import DATA, TXN_TIME, STATE_PROOF
+from plenum.common.plenum_protocol_version import PlenumProtocolVersion
+from plenum.common.types import f
 
 from plenum.server.request_handlers.handler_interfaces.read_request_handler import \
     ReadRequestHandler as PReadRequestHandler
 
 
 class ReadRequestHandler(PReadRequestHandler):
 
-    def lookup(self, path, isCommitted=True, with_proof=False) -> (str, int):
+    def lookup(self, path, is_committed=True, with_proof=False) -> (str, int):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244122580,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244122580,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,done,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 06:37:50,244270502,"@@ -57,39 +59,47 @@ def dynamic_validation(self, request: Request):
             self._validate_existing_nym(identifier, req_id, operation, origin_role, nym_data)
 
     def gen_txn_path(self, txn):
+        self._validate_txn_type(txn)
         nym = get_payload_data(txn).get(TARGET_NYM)
         binary_digest = domain.make_state_path_for_nym(nym)
         return hexlify(binary_digest).decode()
 
-    def _update_state_with_single_txn(self, txn, isCommitted=False):
+    def _update_state_with_single_txn(self, txn, is_committed=True):
+        self._validate_txn_type(txn)
+        nym = get_payload_data(txn).get(TARGET_NYM)
+        existing_data = get_nym_details(self.state, nym,
+                                        is_committed=is_committed)
         txn_data = get_payload_data(txn)
-        nym = txn_data.get(TARGET_NYM)
-        data = {
-            f.IDENTIFIER.nm: get_from(txn),
-            f.SEQ_NO.nm: get_seq_no(txn),
-            TXN_TIME: get_txn_time(txn)
-        }
+        new_data = {}
+        if not existing_data:
+            new_data[f.IDENTIFIER.nm] = get_from(txn)
+            new_data[ROLE] = None
+            new_data[VERKEY] = None
+
         if ROLE in txn_data:
-            data[ROLE] = txn_data.get(ROLE)
+            new_data[ROLE] = txn_data[ROLE]
         if VERKEY in txn_data:
-            data[VERKEY] = txn_data.get(VERKEY)
-        self.update_nym(nym, txn, isCommitted=isCommitted)
-
-    def update_nym(self, nym, txn, isCommitted=True):
-        updatedData = super().update_nym(nym, txn, isCommitted=isCommitted)
+            new_data[VERKEY] = txn_data[VERKEY]
+        new_data[F.seqNo.name] = get_seq_no(txn)
+        new_data[TXN_TIME] = get_txn_time(txn)
+        existing_data.update(new_data)
+        val = self.state_serializer.serialize(existing_data)
+        key = nym_to_state_key(nym)
+        self.state.set(key, val)
         txn_time = get_txn_time(txn)
         self.database_manager.idr_cache.set(nym,",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244270502,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244270502,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"with_proof needs to be True, doesn't it?",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 07:10:30,244273483,"@@ -54,13 +55,13 @@ def get_attr(self,
                  did: str,
                  key: str,
                  attr_type,
-                 is_committed=True) -> (str, int, int, list):
+                 is_committed=False) -> (str, int, int, list):
         assert did is not None
         assert key is not None
         path = domain.make_state_path_for_attr(did, key, attr_type == HASH)
         try:
             hashed_val, last_seq_no, last_update_time, proof = \
-                self.lookup(path, is_committed, with_proof=True)
+                self.lookup(path, is_committed, with_proof=False)",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244273483,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244273483,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,is_committed needs to be True for all `get_result` methods,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 07:12:42,244273687,"@@ -54,13 +55,13 @@ def get_attr(self,
                  did: str,
                  key: str,
                  attr_type,
-                 is_committed=True) -> (str, int, int, list):
+                 is_committed=False) -> (str, int, int, list):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244273687,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244273687,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"yes, fixed",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 07:25:19,244274746,"@@ -54,13 +55,13 @@ def get_attr(self,
                  did: str,
                  key: str,
                  attr_type,
-                 is_committed=True) -> (str, int, int, list):
+                 is_committed=False) -> (str, int, int, list):
         assert did is not None
         assert key is not None
         path = domain.make_state_path_for_attr(did, key, attr_type == HASH)
         try:
             hashed_val, last_seq_no, last_update_time, proof = \
-                self.lookup(path, is_committed, with_proof=True)
+                self.lookup(path, is_committed, with_proof=False)",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244274746,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244274746,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,fixed,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 07:30:44,244275208,"@@ -54,13 +55,13 @@ def get_attr(self,
                  did: str,
                  key: str,
                  attr_type,
-                 is_committed=True) -> (str, int, int, list):
+                 is_committed=False) -> (str, int, int, list):",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244275208,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244275208,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"Here we don't require a proof.
A rule: 
- when we return a result to the user (`get_result` in read request handlers) - we do require a proof 
- when we just get the value for some other purposes (validation, checking for existence, etc,) - we do not require a proof",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 08:14:37,244279775,"@@ -36,7 +36,7 @@ def dynamic_validation(self, request: Request):
                                        ""Format of {} field is not acceptable. ""
                                        ""Expected: 'did:marker:signature_type:schema_ref' or ""
                                        ""'did:marker:signature_type:schema_ref:tag'"".format(CRED_DEF_ID))
-        cred_def, _, _, _ = self.get_revoc_reg_def.lookup(cred_def_id, is_committed=False, with_proof=False)
+        cred_def, _, _, _ = self.get_revoc_reg_def.lookup(cred_def_id, is_committed=False, with_proof=True)",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244279775,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244279775,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"Here is committed needs to False.
A rule:
- when we return a result to the user (get_result in read request handlers) - we do require a committed state
- when we just get the value for some other purposes (validation, checking for existence, etc,) - we require uncommitted state
",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 08:17:29,244280085,"@@ -46,8 +46,8 @@ def get_result(self, request: Request):
     def get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, req_id):
         assert revoc_reg_def_id
         current_entry, _, _, _ = self._get_revoc_def_entry(revoc_reg_def_id=revoc_reg_def_id,",48,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244280085,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244280085,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,Why do we need `get_current_revoc_entry_and_revoc_def` and `_get_revoc_def_entry` here at all?,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 08:19:40,244280322,"@@ -46,8 +46,8 @@ def get_result(self, request: Request):
     def get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, req_id):",46,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244280322,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244280322,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,ok,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 08:23:41,244280727,"@@ -36,7 +36,7 @@ def dynamic_validation(self, request: Request):
                                        ""Format of {} field is not acceptable. ""
                                        ""Expected: 'did:marker:signature_type:schema_ref' or ""
                                        ""'did:marker:signature_type:schema_ref:tag'"".format(CRED_DEF_ID))
-        cred_def, _, _, _ = self.get_revoc_reg_def.lookup(cred_def_id, is_committed=False, with_proof=False)
+        cred_def, _, _, _ = self.get_revoc_reg_def.lookup(cred_def_id, is_committed=False, with_proof=True)",,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244280727,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244280727,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,ok,7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 08:29:35,244281358,"@@ -46,8 +46,8 @@ def get_result(self, request: Request):
     def get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, req_id):
         assert revoc_reg_def_id
         current_entry, _, _, _ = self._get_revoc_def_entry(revoc_reg_def_id=revoc_reg_def_id,",48,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244281358,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244281358,ArtObr
https://github.com/hyperledger/indy-node/pull/1111,https://github.com/hyperledger/indy-node/pull/1111,"They used only in RevocRegEntryHandler, but i think logically they need to be defined in GetRevocRegEntry. (Also because they calling lookup function)",7b4faf19aae648f8f9f910f231804ec1175f909e,2018-12-28 08:52:12,244283959,"@@ -46,8 +46,8 @@ def get_result(self, request: Request):
     def get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, req_id):",46,2018-12-28 10:15:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/244283959,https://github.com/hyperledger/indy-node/pull/1111#discussion_r244283959,ArtObr
https://github.com/hyperledger/indy-node/pull/1101,https://github.com/hyperledger/indy-node/pull/1101,I think it makes sense to put a reference to http://hyperledger-indy.readthedocs.io/projects/plenum here.,b4e09a4845cf995d7e1896c8c4116d97a1379875,2018-12-19 12:13:10,242894098,"@@ -40,7 +40,7 @@ with a different network, using whatever conventions a community chooses.
 Please visit [Technical Overview of Plenum](https://github.com/hyperledger/indy-plenum/blob/master/docs/main.md).
 ",9,2019-02-02 22:22:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/242894098,https://github.com/hyperledger/indy-node/pull/1101#discussion_r242894098,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1101,https://github.com/hyperledger/indy-node/pull/1101,"The new format of requests is not yet implemented.
So, please refer to `requests.md` for now.",b4e09a4845cf995d7e1896c8c4116d97a1379875,2018-12-19 12:14:47,242894479,"@@ -0,0 +1,34 @@
+.. Hyperledger Indy Node documentation master file, created by
+   sphinx-quickstart on Wed Nov  7 15:20:42 2018.
+   You can adapt this file completely to your liking, but it should at least
+   contain the root `toctree` directive.
+
+Welcome to Hyperledger Indy Node's documentation!
+=================================================
+
+
+.. toctree::
+   :maxdepth: 1
+
+   start-nodes.md 
+   add-node.md
+   auth_rules.md
+   ci-cd.md
+   cluster-simulation.md
+   helper-scripts.md
+   indy-file-structure-guideline.md
+   indy-running-locally.md
+   node-monitoring-tools-for-stewards.md
+   node-state-diagnostic-tools.md
+   pool-upgrade.md
+   requests-new.md",,2019-02-02 22:22:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/242894479,https://github.com/hyperledger/indy-node/pull/1101#discussion_r242894479,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1101,https://github.com/hyperledger/indy-node/pull/1101,"Please remove this doc, as this is outdated since we removed client code from Indy Node (this doc needs to deleted from the docs folder as well).",b4e09a4845cf995d7e1896c8c4116d97a1379875,2018-12-19 12:16:57,242894998,"@@ -0,0 +1,34 @@
+.. Hyperledger Indy Node documentation master file, created by
+   sphinx-quickstart on Wed Nov  7 15:20:42 2018.
+   You can adapt this file completely to your liking, but it should at least
+   contain the root `toctree` directive.
+
+Welcome to Hyperledger Indy Node's documentation!
+=================================================
+
+
+.. toctree::
+   :maxdepth: 1
+
+   start-nodes.md 
+   add-node.md
+   auth_rules.md
+   ci-cd.md
+   cluster-simulation.md",,2019-02-02 22:22:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/242894998,https://github.com/hyperledger/indy-node/pull/1101#discussion_r242894998,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1101,https://github.com/hyperledger/indy-node/pull/1101,"Please remove this doc, as this is outdated since we removed client code from Indy Node (this doc needs to deleted from the docs folder as well).",b4e09a4845cf995d7e1896c8c4116d97a1379875,2018-12-19 12:18:37,242895365,"@@ -0,0 +1,34 @@
+.. Hyperledger Indy Node documentation master file, created by
+   sphinx-quickstart on Wed Nov  7 15:20:42 2018.
+   You can adapt this file completely to your liking, but it should at least
+   contain the root `toctree` directive.
+
+Welcome to Hyperledger Indy Node's documentation!
+=================================================
+
+
+.. toctree::
+   :maxdepth: 1
+
+   start-nodes.md 
+   add-node.md
+   auth_rules.md
+   ci-cd.md
+   cluster-simulation.md
+   helper-scripts.md
+   indy-file-structure-guideline.md
+   indy-running-locally.md",,2019-02-02 22:22:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/242895365,https://github.com/hyperledger/indy-node/pull/1101#discussion_r242895365,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1101,https://github.com/hyperledger/indy-node/pull/1101,"I think the following order would be more convenient:
    transactions.md
    requests.md
    auth_rules.md
    pool-upgrade.md
    start-nodes.md 
    add-node.md
    helper-scripts.md
    setup-iptables.md
    node-monitoring-tools-for-stewards.md
    node-state-diagnostic-tools.md
    ci-cd.md
    indy-file-structure-guideline.md
    write-code-guideline.md
    setup-dev.md
    1.3_to_1.4_migration_guide.md",b4e09a4845cf995d7e1896c8c4116d97a1379875,2018-12-19 12:20:29,242895818,"@@ -0,0 +1,34 @@
+.. Hyperledger Indy Node documentation master file, created by
+   sphinx-quickstart on Wed Nov  7 15:20:42 2018.
+   You can adapt this file completely to your liking, but it should at least
+   contain the root `toctree` directive.
+
+Welcome to Hyperledger Indy Node's documentation!
+=================================================
+
+
+.. toctree::
+   :maxdepth: 1
+",12,2019-02-02 22:22:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/242895818,https://github.com/hyperledger/indy-node/pull/1101#discussion_r242895818,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1101,https://github.com/hyperledger/indy-node/pull/1101,"Once we have actually built the readthedocs site, I will include readthedocs links for all of the documentation links that are relevant. For now, I think we can keep it as a github link. ",b4e09a4845cf995d7e1896c8c4116d97a1379875,2019-01-03 15:43:30,245039843,"@@ -40,7 +40,7 @@ with a different network, using whatever conventions a community chooses.
 Please visit [Technical Overview of Plenum](https://github.com/hyperledger/indy-plenum/blob/master/docs/main.md).
 ",9,2019-02-02 22:22:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/245039843,https://github.com/hyperledger/indy-node/pull/1101#discussion_r245039843,michaeldboyd
https://github.com/hyperledger/indy-node/pull/1100,https://github.com/hyperledger/indy-node/pull/1100,Do we still need this try-except? This looks like a generic logic for checking if there is a role. It needs to be part of `write_req_validator.validate`,73dbd69a365b815246d37827873ed4a4519015a7,2018-12-19 10:18:27,242860990,"@@ -30,39 +30,38 @@ def __init__(self, idrCache: IdrCache,
         self.info_tool = info_tool
         self.poolManager = poolManager
         self.poolCfg = poolCfg
+        self.write_req_validator = WriteRequestValidator(config=getConfig(),
+                                                         auth_map=authMap,
+                                                         cache=self.idrCache,
+                                                         anyone_can_write_map=anyoneCanWriteMap)
 
     def doStaticValidation(self, request: Request):
         pass
 
     def validate(self, req: Request):
-        status = None
         operation = req.operation
         typ = operation.get(TXN_TYPE)
         if typ not in self.operation_types:
             return
         origin = req.identifier
         try:",37,2018-12-19 11:24:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/242860990,https://github.com/hyperledger/indy-node/pull/1100#discussion_r242860990,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1100,https://github.com/hyperledger/indy-node/pull/1100,This check needs to be part of common auth map rules and validator,73dbd69a365b815246d37827873ed4a4519015a7,2018-12-19 10:35:58,242866397,"@@ -180,31 +187,22 @@ def _validateNym(self, req: Request):
 
     def _validateNewNym(self, req: Request, op, originRole):
         role = op.get(ROLE)
-        r, msg = Authoriser.authorised(NYM,
-                                       originRole,
-                                       field=ROLE,
-                                       oldVal=None,
-                                       newVal=role)
-        if not r:
-            raise UnauthorizedClientRequest(
-                req.identifier,
-                req.reqId,
-                ""{} cannot add {}"".format(
-                    Roles.nameFromValue(originRole),
-                    Roles.nameFromValue(role))
-            )
+        self.write_req_validator.validate(req,
+                                          [AuthActionAdd(txn_type=NYM,
+                                                         field=ROLE,
+                                                         value=role)])
 
     def _validateExistingNym(self, req: Request, op, originRole, nymData):
         unauthorized = False
-        reason = None
         origin = req.identifier
         owner = self.idrCache.getOwnerFor(op[TARGET_NYM], isCommitted=False)
-        isOwner = origin == owner
+        is_owner = origin == owner
 
-        if not originRole == TRUSTEE and not isOwner:
+        if not originRole == TRUSTEE and not is_owner:",61,2018-12-19 11:24:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/242866397,https://github.com/hyperledger/indy-node/pull/1100#discussion_r242866397,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1100,https://github.com/hyperledger/indy-node/pull/1100,It would be great to have more descriptive exception than `There is no accepted constraint` for this kind of cases.,73dbd69a365b815246d37827873ed4a4519015a7,2018-12-19 10:52:50,242872404,"@@ -11,7 +11,7 @@ def test_non_steward_cannot_create_trust_anchor(
     sdk_wallet_client = sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_steward)
     with pytest.raises(RequestRejectedException) as e:
         sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_client, role=TRUST_ANCHOR_STRING)
-    e.match('None role cannot')
+    e.match('There is no accepted constraint')",5,2018-12-19 11:24:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/242872404,https://github.com/hyperledger/indy-node/pull/1100#discussion_r242872404,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1100,https://github.com/hyperledger/indy-node/pull/1100,"I'm not sure that we need `anyone_can_write_map` anymore with the new approach.
Our new auth constraints assume to have the following format:
`(TRUST_ANCHOR, fees=0 ) OR (ANYONE, fees=10).`
So, by default a txn will succeed only when the first constraint is True.
Plugins can register a validator for fees, so that the can validate that the second condition is true.


",73dbd69a365b815246d37827873ed4a4519015a7,2018-12-19 11:05:13,242876091,"@@ -21,11 +22,13 @@ def validate(self, request, action_list: [AbstractAuthAction]):
 
 
 class WriteRequestValidator(AbstractRequestValidator, CompositeAuthorizer):
-    def __init__(self, config, auth_map, cache):
+    def __init__(self, config, auth_map, cache, anyone_can_write_map=None):",18,2018-12-19 11:24:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/242876091,https://github.com/hyperledger/indy-node/pull/1100#discussion_r242876091,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1100,https://github.com/hyperledger/indy-node/pull/1100,Done.,73dbd69a365b815246d37827873ed4a4519015a7,2018-12-24 15:36:20,243839937,"@@ -180,31 +187,22 @@ def _validateNym(self, req: Request):
 
     def _validateNewNym(self, req: Request, op, originRole):
         role = op.get(ROLE)
-        r, msg = Authoriser.authorised(NYM,
-                                       originRole,
-                                       field=ROLE,
-                                       oldVal=None,
-                                       newVal=role)
-        if not r:
-            raise UnauthorizedClientRequest(
-                req.identifier,
-                req.reqId,
-                ""{} cannot add {}"".format(
-                    Roles.nameFromValue(originRole),
-                    Roles.nameFromValue(role))
-            )
+        self.write_req_validator.validate(req,
+                                          [AuthActionAdd(txn_type=NYM,
+                                                         field=ROLE,
+                                                         value=role)])
 
     def _validateExistingNym(self, req: Request, op, originRole, nymData):
         unauthorized = False
-        reason = None
         origin = req.identifier
         owner = self.idrCache.getOwnerFor(op[TARGET_NYM], isCommitted=False)
-        isOwner = origin == owner
+        is_owner = origin == owner
 
-        if not originRole == TRUSTEE and not isOwner:
+        if not originRole == TRUSTEE and not is_owner:",61,2018-12-24 15:36:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243839937,https://github.com/hyperledger/indy-node/pull/1100#discussion_r243839937,sergey-shilov
https://github.com/hyperledger/indy-node/pull/1100,https://github.com/hyperledger/indy-node/pull/1100,Done.,73dbd69a365b815246d37827873ed4a4519015a7,2018-12-24 15:36:35,243839960,"@@ -30,39 +30,38 @@ def __init__(self, idrCache: IdrCache,
         self.info_tool = info_tool
         self.poolManager = poolManager
         self.poolCfg = poolCfg
+        self.write_req_validator = WriteRequestValidator(config=getConfig(),
+                                                         auth_map=authMap,
+                                                         cache=self.idrCache,
+                                                         anyone_can_write_map=anyoneCanWriteMap)
 
     def doStaticValidation(self, request: Request):
         pass
 
     def validate(self, req: Request):
-        status = None
         operation = req.operation
         typ = operation.get(TXN_TYPE)
         if typ not in self.operation_types:
             return
         origin = req.identifier
         try:",37,2018-12-24 15:36:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/243839960,https://github.com/hyperledger/indy-node/pull/1100#discussion_r243839960,sergey-shilov
https://github.com/hyperledger/indy-node/pull/1090,https://github.com/hyperledger/indy-node/pull/1090,Why do we re-init it here? Should we just get already existent req handler?,2a84ec7ecf15d0ccdea331cde7b2acdd9726a02e,2018-12-13 10:04:27,241338688,"@@ -41,7 +41,7 @@ def test_validation_with_unexpected_accum(
         create_node_and_not_start):
     node = create_node_and_not_start
     req_entry = build_txn_for_revoc_def_entry_by_default
-    req_handler = node.getDomainReqHandler()
+    req_handler = node.init_domain_req_handler()",,2018-12-17 13:13:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241338688,https://github.com/hyperledger/indy-node/pull/1090#discussion_r241338688,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1090,https://github.com/hyperledger/indy-node/pull/1090,fixed,2a84ec7ecf15d0ccdea331cde7b2acdd9726a02e,2018-12-14 08:27:16,241674453,"@@ -41,7 +41,7 @@ def test_validation_with_unexpected_accum(
         create_node_and_not_start):
     node = create_node_and_not_start
     req_entry = build_txn_for_revoc_def_entry_by_default
-    req_handler = node.getDomainReqHandler()
+    req_handler = node.init_domain_req_handler()",,2018-12-17 13:13:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241674453,https://github.com/hyperledger/indy-node/pull/1090#discussion_r241674453,ArtObr
https://github.com/hyperledger/indy-node/pull/1090,https://github.com/hyperledger/indy-node/pull/1090,Why do we need it?,2a84ec7ecf15d0ccdea331cde7b2acdd9726a02e,2018-12-14 13:48:58,241759469,"@@ -0,0 +1,5 @@
+from plenum.server.req_handler import RequestHandler
+
+
+class QueryReqHandler(RequestHandler):",,2018-12-17 13:13:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241759469,https://github.com/hyperledger/indy-node/pull/1090#discussion_r241759469,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1090,https://github.com/hyperledger/indy-node/pull/1090,"It should extend ReadRequestHandler from Plenum, shouldn't it?",2a84ec7ecf15d0ccdea331cde7b2acdd9726a02e,2018-12-14 13:49:49,241759698,"@@ -0,0 +1,5 @@
+from indy_node.server.query_req_handler import QueryReqHandler
+
+
+class GetAttributeHandler(QueryReqHandler):",,2018-12-17 13:13:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241759698,https://github.com/hyperledger/indy-node/pull/1090#discussion_r241759698,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1090,https://github.com/hyperledger/indy-node/pull/1090,removed,2a84ec7ecf15d0ccdea331cde7b2acdd9726a02e,2018-12-14 13:52:54,241760681,"@@ -0,0 +1,5 @@
+from plenum.server.req_handler import RequestHandler
+
+
+class QueryReqHandler(RequestHandler):",,2018-12-17 13:13:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241760681,https://github.com/hyperledger/indy-node/pull/1090#discussion_r241760681,ArtObr
https://github.com/hyperledger/indy-node/pull/1090,https://github.com/hyperledger/indy-node/pull/1090,yes,2a84ec7ecf15d0ccdea331cde7b2acdd9726a02e,2018-12-14 13:53:01,241760712,"@@ -0,0 +1,5 @@
+from indy_node.server.query_req_handler import QueryReqHandler
+
+
+class GetAttributeHandler(QueryReqHandler):",,2018-12-17 13:13:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241760712,https://github.com/hyperledger/indy-node/pull/1090#discussion_r241760712,ArtObr
https://github.com/hyperledger/indy-node/pull/1087,https://github.com/hyperledger/indy-node/pull/1087,I suspect comment belongs to code after loop?,fb8e89e04468bec5bf17cd35be3648a94f78aa77,2018-12-10 16:13:29,240275741,"@@ -20,7 +20,11 @@
       command: ""ssh-keyscan -H {{ item.item }}""
       when: item.rc != 0
       register: host_keys
+      # ssh-keyscan fails silently returning nothing with 0 exit code
       loop: ""{{ known_hosts.results }}""
+      until: host_keys.rc == 0 and (not not host_keys.stdout|trim)",6,2018-12-10 16:14:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240275741,https://github.com/hyperledger/indy-node/pull/1087#discussion_r240275741,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,Why import role in `tasks` instead of adding role dependency in `meta`?,e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 14:31:04,240230993,"@@ -14,27 +14,12 @@
     - indy_cli_pool_genesis_txns_path_local
     - indy_cli_pool_genesis_txns_path_remote
 
-# TODO move the following three tasks (HTTPS, sovrin key and sovrin repos)
-#      into separate role
-- name: Install HTTPS support for apt
-  apt:
-    name:
-      - apt-transport-https
-      - ca-certificates
-    update_cache: true
-  become: true
-
-- name: Add sovrin key
-  apt_key:
-    keyserver: keyserver.ubuntu.com
-    id: 3B75B82CF342D9FB
-  become: true
-
-- name: Add sovrin repositories for indy-sdk
-  apt_repository:
-    repo: ""deb https://repo.sovrin.org/sdk/deb xenial {{ indy_cli_channel }}""
-    state: present
-  become: true
+- name: Install indy sdk repo
+  import_role:
+    name: indy_repo
+  vars:
+    indy_repo_sdk_channels: ""{{ indy_cli_channel }}""
+    indy_repo_sdk: true",,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240230993,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240230993,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,Why import role in `tasks` instead of adding role dependency in `meta`?,e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 14:32:21,240231489,"@@ -16,27 +16,12 @@
     - indy_node_pool_genesis_txns_name
     - indy_node_pool_genesis_txns_path
 
-# TODO move the following three tasks (HTTPS, sovrin key and sovrin repos)
-#      into separate role
-- name: Install HTTPS support for apt
-  apt:
-    name:
-      - apt-transport-https
-      - ca-certificates
-    update_cache: true
-  become: true
-
-- name: Add sovrin key
-  apt_key:
-    keyserver: keyserver.ubuntu.com
-    id: 3B75B82CF342D9FB
-  become: true
-
-- name: Add sovrin repositories
-  apt_repository:
-    repo: ""deb https://repo.sovrin.org/deb xenial {{ indy_node_channel }}""
-    state: present
-  become: true
+- name: Install indy node repo
+  import_role:
+    name: indy_repo
+  vars:
+    indy_repo_node_channels: ""{{ indy_node_channel }}""
+    indy_repo_node: true",,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240231489,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240231489,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,Probably `indy_repo_node_enabled` would be better name. Another (questionable) option is to make this parameter implicit by not adding any repo when `indy_repo_node_channels` list is empty.,e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 14:34:27,240232362,"@@ -0,0 +1,7 @@
+---
+indy_repo_node: false
+indy_repo_node_channels: master",,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240232362,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240232362,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,"Also it might make sense to move HTTPS support and adding keys to some common role, and put remaining `apt_repository` tasks in corresponding roles (indy_node, indy_cli)",e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 16:01:28,240270466,"@@ -0,0 +1,32 @@
+---
+# TODO it might make sense to split the role into indy_node_repo and indy_sdk_repo",2,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240270466,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240270466,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,Why double `not`?,e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 16:09:37,240274021,"@@ -0,0 +1,14 @@
+---
+- name: Execute role {{ plugins_role }}
+  include_role:
+    name: ""{{ plugins_role }}""
+  when: not not plugins_role",,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240274021,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240274021,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,"meta is:
- less explicit
- called before any tasks that is not desired here
",e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 17:08:49,240298922,"@@ -14,27 +14,12 @@
     - indy_cli_pool_genesis_txns_path_local
     - indy_cli_pool_genesis_txns_path_remote
 
-# TODO move the following three tasks (HTTPS, sovrin key and sovrin repos)
-#      into separate role
-- name: Install HTTPS support for apt
-  apt:
-    name:
-      - apt-transport-https
-      - ca-certificates
-    update_cache: true
-  become: true
-
-- name: Add sovrin key
-  apt_key:
-    keyserver: keyserver.ubuntu.com
-    id: 3B75B82CF342D9FB
-  become: true
-
-- name: Add sovrin repositories for indy-sdk
-  apt_repository:
-    repo: ""deb https://repo.sovrin.org/sdk/deb xenial {{ indy_cli_channel }}""
-    state: present
-  become: true
+- name: Install indy sdk repo
+  import_role:
+    name: indy_repo
+  vars:
+    indy_repo_sdk_channels: ""{{ indy_cli_channel }}""
+    indy_repo_sdk: true",,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240298922,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240298922,andkononykhin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,"meta is:
- less explicit
- called before any tasks that is not desired here
",e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 17:08:59,240298988,"@@ -16,27 +16,12 @@
     - indy_node_pool_genesis_txns_name
     - indy_node_pool_genesis_txns_path
 
-# TODO move the following three tasks (HTTPS, sovrin key and sovrin repos)
-#      into separate role
-- name: Install HTTPS support for apt
-  apt:
-    name:
-      - apt-transport-https
-      - ca-certificates
-    update_cache: true
-  become: true
-
-- name: Add sovrin key
-  apt_key:
-    keyserver: keyserver.ubuntu.com
-    id: 3B75B82CF342D9FB
-  become: true
-
-- name: Add sovrin repositories
-  apt_repository:
-    repo: ""deb https://repo.sovrin.org/deb xenial {{ indy_node_channel }}""
-    state: present
-  become: true
+- name: Install indy node repo
+  import_role:
+    name: indy_repo
+  vars:
+    indy_repo_node_channels: ""{{ indy_node_channel }}""
+    indy_repo_node: true",,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240298988,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240298988,andkononykhin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,"yes, splitting the code will definitely lead to such changes",e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 17:10:47,240299660,"@@ -0,0 +1,32 @@
+---
+# TODO it might make sense to split the role into indy_node_repo and indy_sdk_repo",2,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240299660,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240299660,andkononykhin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,for string->boolean coercion. without that you'll get something like `'plugins_role' is undefined`,e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 17:16:37,240301826,"@@ -0,0 +1,14 @@
+---
+- name: Execute role {{ plugins_role }}
+  include_role:
+    name: ""{{ plugins_role }}""
+  when: not not plugins_role",,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240301826,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240301826,andkononykhin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,"yes, makes sense to remove them",e3d8d21fee38edd061f173370b77a36937986047,2018-12-10 17:18:50,240302743,"@@ -0,0 +1,7 @@
+---
+indy_repo_node: false
+indy_repo_node_channels: master",,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240302743,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240302743,andkononykhin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,on the other hand it might not: https and the key are common for both repos only for the current moment but things might change since they are actually separate repos,e3d8d21fee38edd061f173370b77a36937986047,2018-12-11 07:42:21,240499790,"@@ -0,0 +1,32 @@
+---
+# TODO it might make sense to split the role into indy_node_repo and indy_sdk_repo",2,2018-12-11 08:39:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240499790,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240499790,andkononykhin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,updated,e3d8d21fee38edd061f173370b77a36937986047,2018-12-11 08:40:24,240513748,"@@ -0,0 +1,14 @@
+---
+- name: Execute role {{ plugins_role }}
+  include_role:
+    name: ""{{ plugins_role }}""
+  when: not not plugins_role",,2018-12-11 08:40:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240513748,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240513748,andkononykhin
https://github.com/hyperledger/indy-node/pull/1086,https://github.com/hyperledger/indy-node/pull/1086,done,e3d8d21fee38edd061f173370b77a36937986047,2018-12-11 08:40:34,240513793,"@@ -0,0 +1,7 @@
+---
+indy_repo_node: false
+indy_repo_node_channels: master",,2018-12-11 08:40:34,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240513793,https://github.com/hyperledger/indy-node/pull/1086#discussion_r240513793,andkononykhin
https://github.com/hyperledger/indy-node/pull/1085,https://github.com/hyperledger/indy-node/pull/1085,Why we need this conversion?,5b437718d434fd74c6e472db9b87700c695ae615,2018-12-07 14:22:09,239822974,"@@ -150,15 +153,42 @@ def terminate(self, instance, region=None):
 class AwsEC2Launcher(AwsEC2Waiter):
     """""" Helper class to launch EC2 instances. """"""
 
+    _camel_to_snake_re1 = re.compile('(.)([A-Z][a-z]+)')
+    _camel_to_snake_re2 = re.compile('([a-z0-9])([A-Z])')
+
     def __init__(self):
         # TODO consider to use waiter for 'instance_status_ok'
         # if 'instance_running' is not enough in any circumstances
         super(AwsEC2Launcher, self).__init__('instance_running')
 
+    @classmethod
+    def _camel_to_snake(cls, camel_one):",49,2018-12-07 14:26:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/239822974,https://github.com/hyperledger/indy-node/pull/1085#discussion_r239822974,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1085,https://github.com/hyperledger/indy-node/pull/1085,Leaving 8 as default would be nice,5b437718d434fd74c6e472db9b87700c695ae615,2018-12-07 14:26:36,239824407,"@@ -45,6 +45,7 @@ aws_instance_count: 4
 aws_ec2_type: t2.micro
 aws_ec2_market_spot: true
 aws_ec2_spot_max_price: null
+aws_ebs_volume_size: 16",4,2018-12-07 14:26:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/239824407,https://github.com/hyperledger/indy-node/pull/1085#discussion_r239824407,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1081,https://github.com/hyperledger/indy-node/pull/1081,How can view_changer be None here?,991b1f0c8324ee400ee9f628e60b8a7d08b0c970,2018-12-11 07:31:53,240497375,"@@ -92,6 +93,22 @@ def test_pool_restart_now_without_datetime(
                      tdir, tconf, START)
 
 
+def test_pool_restart_in_view_change(sdk_pool_handle, sdk_wallet_trustee, looper,
+                                     tdir, tconf, txnPoolNodeSet):
+
+    for node in txnPoolNodeSet:
+        if node.view_changer is None:",31,2018-12-11 07:31:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240497375,https://github.com/hyperledger/indy-node/pull/1081#discussion_r240497375,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1076,https://github.com/hyperledger/indy-node/pull/1076,What if container is not stopped yet?,b3050f7608720bf99ea33bbf6032e02a13a8eeab,2018-12-06 11:29:41,239418850,"@@ -64,8 +64,124 @@ def buildDebUbuntu = { repoName, releaseVersion, sourcePath ->
     return ""$volumeName""
 }
 
+def systemTests = { component ->
+
+    String prefix = ""System Tests ($component)""
+    String defaultNetwork = 'pool-network'
+
+    def dockerClean = { networkName ->
+        networkName = networkName ?: defaultNetwork
+
+        try {
+            sh ""docker ps -q --filter network=$networkName | xargs -r docker rm -f""",14,2018-12-06 11:30:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/239418850,https://github.com/hyperledger/indy-node/pull/1076#discussion_r239418850,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1076,https://github.com/hyperledger/indy-node/pull/1076,"`rm -f`, we don't care",b3050f7608720bf99ea33bbf6032e02a13a8eeab,2018-12-06 11:31:36,239419396,"@@ -64,8 +64,124 @@ def buildDebUbuntu = { repoName, releaseVersion, sourcePath ->
     return ""$volumeName""
 }
 
+def systemTests = { component ->
+
+    String prefix = ""System Tests ($component)""
+    String defaultNetwork = 'pool-network'
+
+    def dockerClean = { networkName ->
+        networkName = networkName ?: defaultNetwork
+
+        try {
+            sh ""docker ps -q --filter network=$networkName | xargs -r docker rm -f""",14,2018-12-06 11:31:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/239419396,https://github.com/hyperledger/indy-node/pull/1076#discussion_r239419396,andkononykhin
https://github.com/hyperledger/indy-node/pull/1074,https://github.com/hyperledger/indy-node/pull/1074,Do we really need low-level client API here?,e1195ef6e1d80a3fbe077e704731bb56a544e0de,2018-12-06 10:25:53,239399449,"@@ -115,6 +139,12 @@ def __init__(self):
     def terminate(self, instance, region=None):
         instance.terminate()
         self.add_instance(instance, region)
+        # cancel spot request if any
+        if instance.spot_instance_request_id:
+            ec2cl = boto3.client('ec2', region_name=(region if region",117,2018-12-06 10:56:00,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/239399449,https://github.com/hyperledger/indy-node/pull/1074#discussion_r239399449,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1074,https://github.com/hyperledger/indy-node/pull/1074,"Python iterates dictionaries by keys by default anyway, so there is no real need in specifying `keys` except for additional clarity.",e1195ef6e1d80a3fbe077e704731bb56a544e0de,2018-12-06 10:28:42,239400355,"@@ -179,11 +227,12 @@ def _host_info(inst):
 
     valid_region_ids = valid_instances(regions, count)
 
-    for region in AWS_REGIONS:
+    for region in AWS_REGIONS.keys():",189,2018-12-06 10:56:00,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/239400355,https://github.com/hyperledger/indy-node/pull/1074#discussion_r239400355,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1074,https://github.com/hyperledger/indy-node/pull/1074,we don't have any alternative for now (boto3 1.9.60),e1195ef6e1d80a3fbe077e704731bb56a544e0de,2018-12-06 12:22:44,239432882,"@@ -115,6 +139,12 @@ def __init__(self):
     def terminate(self, instance, region=None):
         instance.terminate()
         self.add_instance(instance, region)
+        # cancel spot request if any
+        if instance.spot_instance_request_id:
+            ec2cl = boto3.client('ec2', region_name=(region if region",117,2018-12-06 12:22:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/239432882,https://github.com/hyperledger/indy-node/pull/1074#discussion_r239432882,andkononykhin
https://github.com/hyperledger/indy-node/pull/1074,https://github.com/hyperledger/indy-node/pull/1074,ok,e1195ef6e1d80a3fbe077e704731bb56a544e0de,2018-12-06 12:23:02,239432963,"@@ -179,11 +227,12 @@ def _host_info(inst):
 
     valid_region_ids = valid_instances(regions, count)
 
-    for region in AWS_REGIONS:
+    for region in AWS_REGIONS.keys():",189,2018-12-06 12:23:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/239432963,https://github.com/hyperledger/indy-node/pull/1074#discussion_r239432963,andkononykhin
https://github.com/hyperledger/indy-node/pull/1072,https://github.com/hyperledger/indy-node/pull/1072,This script deals with SDK clients and should not be removed.,878637594c34c739954c12233e63a8daffd86275,2018-12-04 10:59:02,238615292,"@@ -1,38 +0,0 @@
-# Test for checking that all simultaneous clients have a chance to connect to the pool with enabled client stack restart",,2018-12-04 12:37:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238615292,https://github.com/hyperledger/indy-node/pull/1072#discussion_r238615292,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1072,https://github.com/hyperledger/indy-node/pull/1072,This script deals with SDK clients and should not be removed.,878637594c34c739954c12233e63a8daffd86275,2018-12-04 10:59:28,238615433,"@@ -1,121 +0,0 @@
-import argparse",,2018-12-04 12:37:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238615433,https://github.com/hyperledger/indy-node/pull/1072#discussion_r238615433,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1070,https://github.com/hyperledger/indy-node/pull/1070,Better call it `Adding new Identity Owner`,35017052d84ebfdfd52747ac3644c792ae7d2072,2018-12-03 13:02:23,238259210,"@@ -0,0 +1,33 @@
+# Current implemented rules in auth_map
+| Transaction type | Field | Previous value | New value | Who can| Description |
+|------------------|-------|----------------|-----------|--------|-------------|
+| NYM              |`role` |`<empty>`       | TRUSTEE   | TRUSTEE|Adding new TRUSTEE|
+| NYM              |`role` |`<empty>`       | STEWARD   | TRUSTEE|Adding new STEWARD|
+| NYM              |`role` |`<empty>`       | TRUST_ANCHOR| TRUSTEE, STEWARD|Adding new TRUST_ANCHOR|
+| NYM              |`role` |`<empty>`       |`<empty>`  | TRUSTEE, STEWARD, TRUST_ANCHOR| Adding new nym|",,2018-12-03 13:44:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238259210,https://github.com/hyperledger/indy-node/pull/1070#discussion_r238259210,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1070,https://github.com/hyperledger/indy-node/pull/1070,Better call it `Blacklisting Trustee`,35017052d84ebfdfd52747ac3644c792ae7d2072,2018-12-03 13:02:47,238259300,"@@ -0,0 +1,33 @@
+# Current implemented rules in auth_map
+| Transaction type | Field | Previous value | New value | Who can| Description |
+|------------------|-------|----------------|-----------|--------|-------------|
+| NYM              |`role` |`<empty>`       | TRUSTEE   | TRUSTEE|Adding new TRUSTEE|
+| NYM              |`role` |`<empty>`       | STEWARD   | TRUSTEE|Adding new STEWARD|
+| NYM              |`role` |`<empty>`       | TRUST_ANCHOR| TRUSTEE, STEWARD|Adding new TRUST_ANCHOR|
+| NYM              |`role` |`<empty>`       |`<empty>`  | TRUSTEE, STEWARD, TRUST_ANCHOR| Adding new nym|
+| NYM              |`role` | TRUSTEE        |`<empty>`  | TRUSTEE | Change role from TRUSTEE to None|",,2018-12-03 13:44:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238259300,https://github.com/hyperledger/indy-node/pull/1070#discussion_r238259300,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1070,https://github.com/hyperledger/indy-node/pull/1070,Better call it `Blacklisting Steward`,35017052d84ebfdfd52747ac3644c792ae7d2072,2018-12-03 13:02:52,238259333,"@@ -0,0 +1,33 @@
+# Current implemented rules in auth_map
+| Transaction type | Field | Previous value | New value | Who can| Description |
+|------------------|-------|----------------|-----------|--------|-------------|
+| NYM              |`role` |`<empty>`       | TRUSTEE   | TRUSTEE|Adding new TRUSTEE|
+| NYM              |`role` |`<empty>`       | STEWARD   | TRUSTEE|Adding new STEWARD|
+| NYM              |`role` |`<empty>`       | TRUST_ANCHOR| TRUSTEE, STEWARD|Adding new TRUST_ANCHOR|
+| NYM              |`role` |`<empty>`       |`<empty>`  | TRUSTEE, STEWARD, TRUST_ANCHOR| Adding new nym|
+| NYM              |`role` | TRUSTEE        |`<empty>`  | TRUSTEE | Change role from TRUSTEE to None|
+| NYM              |`role` | STEWARD        |`<empty>`  | TRUSTEE | Change role from STEWARD to None|",,2018-12-03 13:44:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238259333,https://github.com/hyperledger/indy-node/pull/1070#discussion_r238259333,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1070,https://github.com/hyperledger/indy-node/pull/1070,Better call it `Blacklisting Trust Anchor`,35017052d84ebfdfd52747ac3644c792ae7d2072,2018-12-03 13:03:02,238259375,"@@ -0,0 +1,33 @@
+# Current implemented rules in auth_map
+| Transaction type | Field | Previous value | New value | Who can| Description |
+|------------------|-------|----------------|-----------|--------|-------------|
+| NYM              |`role` |`<empty>`       | TRUSTEE   | TRUSTEE|Adding new TRUSTEE|
+| NYM              |`role` |`<empty>`       | STEWARD   | TRUSTEE|Adding new STEWARD|
+| NYM              |`role` |`<empty>`       | TRUST_ANCHOR| TRUSTEE, STEWARD|Adding new TRUST_ANCHOR|
+| NYM              |`role` |`<empty>`       |`<empty>`  | TRUSTEE, STEWARD, TRUST_ANCHOR| Adding new nym|
+| NYM              |`role` | TRUSTEE        |`<empty>`  | TRUSTEE | Change role from TRUSTEE to None|
+| NYM              |`role` | STEWARD        |`<empty>`  | TRUSTEE | Change role from STEWARD to None|
+| NYM              |`role` | TRUST_ANCHOR   |`<empty>`  | TRUSTEE | Change role from TRUST_ANCHOR to None|",,2018-12-03 13:44:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238259375,https://github.com/hyperledger/indy-node/pull/1070#discussion_r238259375,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1070,https://github.com/hyperledger/indy-node/pull/1070,Better call it `Key Rotation`,35017052d84ebfdfd52747ac3644c792ae7d2072,2018-12-03 13:03:37,238259539,"@@ -0,0 +1,33 @@
+# Current implemented rules in auth_map
+| Transaction type | Field | Previous value | New value | Who can| Description |
+|------------------|-------|----------------|-----------|--------|-------------|
+| NYM              |`role` |`<empty>`       | TRUSTEE   | TRUSTEE|Adding new TRUSTEE|
+| NYM              |`role` |`<empty>`       | STEWARD   | TRUSTEE|Adding new STEWARD|
+| NYM              |`role` |`<empty>`       | TRUST_ANCHOR| TRUSTEE, STEWARD|Adding new TRUST_ANCHOR|
+| NYM              |`role` |`<empty>`       |`<empty>`  | TRUSTEE, STEWARD, TRUST_ANCHOR| Adding new nym|
+| NYM              |`role` | TRUSTEE        |`<empty>`  | TRUSTEE | Change role from TRUSTEE to None|
+| NYM              |`role` | STEWARD        |`<empty>`  | TRUSTEE | Change role from STEWARD to None|
+| NYM              |`role` | TRUST_ANCHOR   |`<empty>`  | TRUSTEE | Change role from TRUST_ANCHOR to None|
+| NYM              |`verkey`|`*`|`*`| Owner of this nym | Any operations with verkey field|",,2018-12-03 13:44:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238259539,https://github.com/hyperledger/indy-node/pull/1070#discussion_r238259539,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1070,https://github.com/hyperledger/indy-node/pull/1070,"`Adding new Schema`.

Also we need to have a line `Editing a Schema`, where we say that `No one can edit existing Schema`",35017052d84ebfdfd52747ac3644c792ae7d2072,2018-12-03 13:04:39,238259797,"@@ -0,0 +1,33 @@
+# Current implemented rules in auth_map
+| Transaction type | Field | Previous value | New value | Who can| Description |
+|------------------|-------|----------------|-----------|--------|-------------|
+| NYM              |`role` |`<empty>`       | TRUSTEE   | TRUSTEE|Adding new TRUSTEE|
+| NYM              |`role` |`<empty>`       | STEWARD   | TRUSTEE|Adding new STEWARD|
+| NYM              |`role` |`<empty>`       | TRUST_ANCHOR| TRUSTEE, STEWARD|Adding new TRUST_ANCHOR|
+| NYM              |`role` |`<empty>`       |`<empty>`  | TRUSTEE, STEWARD, TRUST_ANCHOR| Adding new nym|
+| NYM              |`role` | TRUSTEE        |`<empty>`  | TRUSTEE | Change role from TRUSTEE to None|
+| NYM              |`role` | STEWARD        |`<empty>`  | TRUSTEE | Change role from STEWARD to None|
+| NYM              |`role` | TRUST_ANCHOR   |`<empty>`  | TRUSTEE | Change role from TRUST_ANCHOR to None|
+| NYM              |`verkey`|`*`|`*`| Owner of this nym | Any operations with verkey field|
+| SCHEMA           |`*`|`*`|`*`| TRUSTEE, STEWARD, TRUST_ANCHOR | Any operations with SCHEMA transactions|",,2018-12-03 13:44:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238259797,https://github.com/hyperledger/indy-node/pull/1070#discussion_r238259797,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1070,https://github.com/hyperledger/indy-node/pull/1070,"Need to split to `Adding new Claim Def` (TRUST_ANCHOR, TRUSTEE and STEWARD only?) and `Editing existing ClaimDef` (Owner only?)",35017052d84ebfdfd52747ac3644c792ae7d2072,2018-12-03 13:07:05,238260584,"@@ -0,0 +1,33 @@
+# Current implemented rules in auth_map
+| Transaction type | Field | Previous value | New value | Who can| Description |
+|------------------|-------|----------------|-----------|--------|-------------|
+| NYM              |`role` |`<empty>`       | TRUSTEE   | TRUSTEE|Adding new TRUSTEE|
+| NYM              |`role` |`<empty>`       | STEWARD   | TRUSTEE|Adding new STEWARD|
+| NYM              |`role` |`<empty>`       | TRUST_ANCHOR| TRUSTEE, STEWARD|Adding new TRUST_ANCHOR|
+| NYM              |`role` |`<empty>`       |`<empty>`  | TRUSTEE, STEWARD, TRUST_ANCHOR| Adding new nym|
+| NYM              |`role` | TRUSTEE        |`<empty>`  | TRUSTEE | Change role from TRUSTEE to None|
+| NYM              |`role` | STEWARD        |`<empty>`  | TRUSTEE | Change role from STEWARD to None|
+| NYM              |`role` | TRUST_ANCHOR   |`<empty>`  | TRUSTEE | Change role from TRUST_ANCHOR to None|
+| NYM              |`verkey`|`*`|`*`| Owner of this nym | Any operations with verkey field|
+| SCHEMA           |`*`|`*`|`*`| TRUSTEE, STEWARD, TRUST_ANCHOR | Any operations with SCHEMA transactions|
+| CLAIM_DEF        |`*`|`*`|`*`| Owner of this claim_def txn| Any operations with CLAIM_DEF transaction|",,2018-12-03 13:44:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238260584,https://github.com/hyperledger/indy-node/pull/1070#discussion_r238260584,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1070,https://github.com/hyperledger/indy-node/pull/1070,What about Revocation transactions?,35017052d84ebfdfd52747ac3644c792ae7d2072,2018-12-03 13:08:02,238260863,"@@ -0,0 +1,33 @@
+# Current implemented rules in auth_map
+| Transaction type | Field | Previous value | New value | Who can| Description |
+|------------------|-------|----------------|-----------|--------|-------------|
+| NYM              |`role` |`<empty>`       | TRUSTEE   | TRUSTEE|Adding new TRUSTEE|
+| NYM              |`role` |`<empty>`       | STEWARD   | TRUSTEE|Adding new STEWARD|
+| NYM              |`role` |`<empty>`       | TRUST_ANCHOR| TRUSTEE, STEWARD|Adding new TRUST_ANCHOR|
+| NYM              |`role` |`<empty>`       |`<empty>`  | TRUSTEE, STEWARD, TRUST_ANCHOR| Adding new nym|
+| NYM              |`role` | TRUSTEE        |`<empty>`  | TRUSTEE | Change role from TRUSTEE to None|
+| NYM              |`role` | STEWARD        |`<empty>`  | TRUSTEE | Change role from STEWARD to None|
+| NYM              |`role` | TRUST_ANCHOR   |`<empty>`  | TRUSTEE | Change role from TRUST_ANCHOR to None|
+| NYM              |`verkey`|`*`|`*`| Owner of this nym | Any operations with verkey field|
+| SCHEMA           |`*`|`*`|`*`| TRUSTEE, STEWARD, TRUST_ANCHOR | Any operations with SCHEMA transactions|
+| CLAIM_DEF        |`*`|`*`|`*`| Owner of this claim_def txn| Any operations with CLAIM_DEF transaction|
+| NODE             |`services`|`<empty>`|`[VALIDATOR]`| STEWARD if it is owner of this transaction| Add new node to pool|
+| NODE             |`services`|`[VALIDATOR]`|`[]`| TRUSTEE, STEWARD if it is owner of this transaction| Demotion of node|
+| NODE             |`services`|`[]`|`[VALIDATOR]`| TRUSTEE, STEWARD if it is owner of this transaction| Promotion of node|
+| NODE             |`node_ip`|`*`|`*`| STEWARD if it is owner of this transaction| Change Node's ip address|
+| NODE             |`node_port`|`*`|`*`| STEWARD if it is owner of this transaction| Change Node's port|
+| NODE             |`client_ip`|`*`|`*`| STEWARD if it is owner of this transaction| Change Client's ip address| 
+| NODE             |`client_port`|`*`|`*`| STEWARD if it is owner of this transaction| Change Client's port|
+| NODE             |`blskey`|`*`|`*`| STEWARD if it is owner of this transaction| Change Node's blskey|
+| POOL_UPGRADE     |`action`|`<empty>`|`start`|TRUSTEE| Start upgrade procedure|
+| POOL_UPGRADE     |`action`|`start`|`cancel`|TRUSTEE| Cancel upgrade procedure|
+| POOL_RESTART     |`action`|`*`|`*`|TRUSTEE| Restart pool command|
+| POOL_CONFIG      |`action`|`*`|`*`|TRUSTEE| Pool config command (like a `read only` option)| 
+| VALIDATOR_INFO   |`*`|`*`|`*`| TRUSTEE, STEWARD| Get validator_info from pool|
+",30,2018-12-03 13:44:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238260863,https://github.com/hyperledger/indy-node/pull/1070#discussion_r238260863,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1066,https://github.com/hyperledger/indy-node/pull/1066,"What is the difference between ""Update Time"" and ""timestamp""?",18b92410c24d9ef0e9d911de3632a0a3a23d6c02,2018-11-30 08:46:21,237782701,"@@ -187,3 +186,12 @@ def test_validator_info_file_metrics_count_all_ledgers_field_valid(node):
     info = node._info_tool.info
     has_cnt = len(info['Node_info']['Metrics']['transaction-count'])
     assert has_cnt == len(new_ids) + 3
+
+
+def test_validator_info_update_date_field_valid(info):
+    assert ""Update time"" in info
+    import time
+    import datetime
+    from_str = time.mktime(datetime.datetime.strptime(info[""Update time""],
+                                                      ""%A, %B %d, %Y %I:%M:%S %p %z"").timetuple())
+    assert int(from_str) == info[""timestamp""]",20,2018-11-30 08:46:22,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237782701,https://github.com/hyperledger/indy-node/pull/1066#discussion_r237782701,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1066,https://github.com/hyperledger/indy-node/pull/1066,Why did we remove this?,18b92410c24d9ef0e9d911de3632a0a3a23d6c02,2018-11-30 08:47:14,237782936,"@@ -11,9 +13,12 @@ class ValidatorNodeInfoTool(PlenumValidatorNodeInfoTool):
     @property
     def info(self):
         info = super().info
+        ts_str = ""{}"".format(time.strftime(
+            ""%A, %B %{0}d, %Y %{0}I:%M:%S %p %z"".format('#' if os.name == 'nt' else '-'),
+            time.localtime(info[""timestamp""])))
+        info.update({""Update time"": ts_str})
         if 'Node_info' in info:
             if 'Metrics' in info['Node_info']:
-                info['Node_info']['Metrics']['transaction-count'].update(config=self.__config_ledger_size)",17,2018-11-30 08:47:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237782936,https://github.com/hyperledger/indy-node/pull/1066#discussion_r237782936,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1066,https://github.com/hyperledger/indy-node/pull/1066,"timestamp is an int value
Update Time is human readable string with tz offset",18b92410c24d9ef0e9d911de3632a0a3a23d6c02,2018-11-30 09:02:55,237787032,"@@ -187,3 +186,12 @@ def test_validator_info_file_metrics_count_all_ledgers_field_valid(node):
     info = node._info_tool.info
     has_cnt = len(info['Node_info']['Metrics']['transaction-count'])
     assert has_cnt == len(new_ids) + 3
+
+
+def test_validator_info_update_date_field_valid(info):
+    assert ""Update time"" in info
+    import time
+    import datetime
+    from_str = time.mktime(datetime.datetime.strptime(info[""Update time""],
+                                                      ""%A, %B %d, %Y %I:%M:%S %p %z"").timetuple())
+    assert int(from_str) == info[""timestamp""]",20,2018-11-30 09:02:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237787032,https://github.com/hyperledger/indy-node/pull/1066#discussion_r237787032,dsurnin
https://github.com/hyperledger/indy-node/pull/1066,https://github.com/hyperledger/indy-node/pull/1066,it was moved to plenum ,18b92410c24d9ef0e9d911de3632a0a3a23d6c02,2018-11-30 09:03:05,237787067,"@@ -11,9 +13,12 @@ class ValidatorNodeInfoTool(PlenumValidatorNodeInfoTool):
     @property
     def info(self):
         info = super().info
+        ts_str = ""{}"".format(time.strftime(
+            ""%A, %B %{0}d, %Y %{0}I:%M:%S %p %z"".format('#' if os.name == 'nt' else '-'),
+            time.localtime(info[""timestamp""])))
+        info.update({""Update time"": ts_str})
         if 'Node_info' in info:
             if 'Metrics' in info['Node_info']:
-                info['Node_info']['Metrics']['transaction-count'].update(config=self.__config_ledger_size)",17,2018-11-30 09:03:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237787067,https://github.com/hyperledger/indy-node/pull/1066#discussion_r237787067,dsurnin
https://github.com/hyperledger/indy-node/pull/1063,https://github.com/hyperledger/indy-node/pull/1063,I would add additional ledger here (a plugin?) to check that it's also counted,cc49de1542f822c79fee59fb5ad8b12559baf16e,2018-11-29 06:32:49,237366895,"@@ -25,19 +24,25 @@ def test_validator_info_file_metrics_count_ledger_field_valid(info):
     assert info['Node_info']['Metrics']['transaction-count']['config'] == 0
 
 
-@pytest.mark.skip(reason=""info will not be included by default"")
-def test_validator_info_file_software_indy_node_valid(info):
-    assert info['Software']['indy-node'] == node_pgk_version
+def test_validator_info_file_metrics_count_all_ledgers_field_valid(node, info):",13,2018-11-29 06:43:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237366895,https://github.com/hyperledger/indy-node/pull/1063#discussion_r237366895,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1063,https://github.com/hyperledger/indy-node/pull/1063,I think it's better to use JsonSerializer here,cc49de1542f822c79fee59fb5ad8b12559baf16e,2018-11-29 06:39:52,237367981,"@@ -519,7 +527,7 @@ async def handle_client(client_reader, client_writer):
             else:
                 logger.debug(""Received data: {}"".format(data))
                 stats = json.loads(data.decode())
-                print(json.dumps(stats, indent=2, cls=NewEncoder))
+                print(json.dumps(stats, indent=2, cls=NewEncoder, sort_keys=True))",137,2018-11-29 06:43:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237367981,https://github.com/hyperledger/indy-node/pull/1063#discussion_r237367981,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1063,https://github.com/hyperledger/indy-node/pull/1063,Please add a test making sure that the output is sorted,cc49de1542f822c79fee59fb5ad8b12559baf16e,2018-11-29 06:40:42,237368111,"@@ -519,7 +527,7 @@ async def handle_client(client_reader, client_writer):
             else:
                 logger.debug(""Received data: {}"".format(data))
                 stats = json.loads(data.decode())
-                print(json.dumps(stats, indent=2, cls=NewEncoder))
+                print(json.dumps(stats, indent=2, cls=NewEncoder, sort_keys=True))",137,2018-11-29 06:43:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237368111,https://github.com/hyperledger/indy-node/pull/1063#discussion_r237368111,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"Please support `metadata` as a 3d parameter, that can be potentially used by Plugins",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-04 12:41:44,238645229,"@@ -0,0 +1,245 @@
+import re
+from typing import List, NamedTuple
+
+from indy_common.constants import LOCAL_AUTH_POLICY, CONFIG_LEDGER_AUTH_POLICY
+from plenum.common.constants import TRUSTEE, STEWARD
+
+from abc import ABCMeta, abstractmethod
+
+from indy_common.constants import OWNER, POOL_UPGRADE, TRUST_ANCHOR, NYM, \
+    POOL_CONFIG, SCHEMA, CLAIM_DEF, \
+    POOL_RESTART, VALIDATOR_INFO
+
+
+RULE_DELIMETER = ""--""
+
+
+def compile_rule_id(txn_type,
+                    field,
+                    old_value,
+                    new_value) -> str:
+    return RULE_DELIMETER.join([txn_type,
+                                field,
+                                old_value,
+                                new_value])
+
+
+""""""
+
+Definition for one auth constraint (for example, ('TRUSTEE', 3))
+
+""""""
+
+RoleDef = NamedTuple('Roledef', [('role', str), ('sig_count', int)])",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238645229,https://github.com/hyperledger/indy-node/pull/1060#discussion_r238645229,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"Should we return a description on why validation didn't pass, for example `wrong role: one of XXX expected`, or `requires at least N signatures`.",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-04 12:44:14,238645991,"@@ -0,0 +1,245 @@
+import re
+from typing import List, NamedTuple
+
+from indy_common.constants import LOCAL_AUTH_POLICY, CONFIG_LEDGER_AUTH_POLICY
+from plenum.common.constants import TRUSTEE, STEWARD
+
+from abc import ABCMeta, abstractmethod
+
+from indy_common.constants import OWNER, POOL_UPGRADE, TRUST_ANCHOR, NYM, \
+    POOL_CONFIG, SCHEMA, CLAIM_DEF, \
+    POOL_RESTART, VALIDATOR_INFO
+
+
+RULE_DELIMETER = ""--""
+
+
+def compile_rule_id(txn_type,
+                    field,
+                    old_value,
+                    new_value) -> str:
+    return RULE_DELIMETER.join([txn_type,
+                                field,
+                                old_value,
+                                new_value])
+
+
+""""""
+
+Definition for one auth constraint (for example, ('TRUSTEE', 3))
+
+""""""
+
+RoleDef = NamedTuple('Roledef', [('role', str), ('sig_count', int)])
+
+""""""
+
+Combined auth constraints (for example, [('TRUSTEE', 3), ('STEWARD', 7)])
+
+""""""
+
+
+class AuthConstraint(List[RoleDef]):
+    """"""
+    'AND' strategy implemented. If there is several RoleDefs, then all of this must be presented in incomming constraints
+    """"""
+    def is_accepted(self, other_constraint):",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238645991,https://github.com/hyperledger/indy-node/pull/1060#discussion_r238645991,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"I think we need the following hierarchy for AuthConstracint:
```
class AbstractAuthConstraint:
    def is_accepted(self, value):
       pass

class AuthConstraint:
 def __init__(role, sig_count, metadata):
     ....

  def is_accepted(self, value):
    # check role and sig_count
    # check metadata

  def check_metadata()
     return True


class PluginAuthConstraint(AuthConstraint) #registered by plugins

  def check_metadata()
     .....

class AndAuthConstraint(List[AuthConstraint])
  def is_accepted(self, value):
  # check that all are valid

class OrAuthConstraint(List[AuthConstraint])
  def is_accepted(self, value):
  # check that at least one constraint is valid


```",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-04 12:45:46,238646415,"@@ -0,0 +1,245 @@
+import re
+from typing import List, NamedTuple
+
+from indy_common.constants import LOCAL_AUTH_POLICY, CONFIG_LEDGER_AUTH_POLICY
+from plenum.common.constants import TRUSTEE, STEWARD
+
+from abc import ABCMeta, abstractmethod
+
+from indy_common.constants import OWNER, POOL_UPGRADE, TRUST_ANCHOR, NYM, \
+    POOL_CONFIG, SCHEMA, CLAIM_DEF, \
+    POOL_RESTART, VALIDATOR_INFO
+
+
+RULE_DELIMETER = ""--""
+
+
+def compile_rule_id(txn_type,
+                    field,
+                    old_value,
+                    new_value) -> str:
+    return RULE_DELIMETER.join([txn_type,
+                                field,
+                                old_value,
+                                new_value])
+
+
+""""""
+
+Definition for one auth constraint (for example, ('TRUSTEE', 3))
+
+""""""
+
+RoleDef = NamedTuple('Roledef', [('role', str), ('sig_count', int)])
+
+""""""
+
+Combined auth constraints (for example, [('TRUSTEE', 3), ('STEWARD', 7)])
+
+""""""
+
+
+class AuthConstraint(List[RoleDef]):",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238646415,https://github.com/hyperledger/indy-node/pull/1060#discussion_r238646415,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"I would split the file into `auth_constraints`, `auth_rules`, `auth_policies`, `authorizer`. Please create a special package for this.",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-04 13:16:18,238656925,"@@ -0,0 +1,245 @@
+import re
+from typing import List, NamedTuple
+
+from indy_common.constants import LOCAL_AUTH_POLICY, CONFIG_LEDGER_AUTH_POLICY
+from plenum.common.constants import TRUSTEE, STEWARD
+
+from abc import ABCMeta, abstractmethod
+
+from indy_common.constants import OWNER, POOL_UPGRADE, TRUST_ANCHOR, NYM, \
+    POOL_CONFIG, SCHEMA, CLAIM_DEF, \
+    POOL_RESTART, VALIDATOR_INFO
+
+
+RULE_DELIMETER = ""--""
+
+
+def compile_rule_id(txn_type,
+                    field,
+                    old_value,
+                    new_value) -> str:
+    return RULE_DELIMETER.join([txn_type,
+                                field,
+                                old_value,
+                                new_value])
+
+
+""""""
+
+Definition for one auth constraint (for example, ('TRUSTEE', 3))
+
+""""""
+
+RoleDef = NamedTuple('Roledef', [('role', str), ('sig_count', int)])
+
+""""""
+
+Combined auth constraints (for example, [('TRUSTEE', 3), ('STEWARD', 7)])
+
+""""""
+
+
+class AuthConstraint(List[RoleDef]):
+    """"""
+    'AND' strategy implemented. If there is several RoleDefs, then all of this must be presented in incomming constraints
+    """"""
+    def is_accepted(self, other_constraint):
+        compares = []
+        for r in other_constraint:
+            for s in self:
+                if r.role == s.role and s.sig_count <= r.sig_count:
+                    compares.append(True)
+        return len(self) == len(compares) and all(compares)
+
+
+""""""
+
+Rule's classes
+
+""""""
+
+
+class AbstractRule(metaclass=ABCMeta):
+    def __init__(self,
+                 description: str,
+                 txn_type: str,
+                 default_auth_constraint: AuthConstraint,
+                 rule_id='',
+                 field='*',
+                 old_value='*',
+                 new_value='*'):
+        self.description = description
+        self.txn_type = txn_type
+        self.rule_id = rule_id
+        self.default_auth_constraint = default_auth_constraint
+        self.field = field
+        # self.old_value = '*' if old_value == '*' else re.escape(old_value)
+        # self.new_value = '*' if new_value == '*' else re.escape(new_value)
+        self.old_value = old_value
+        self.new_value = new_value
+        self.allow_field = False
+        self.allow_old_value = False
+        self.allow_new_value = False
+        self.allow_for_all = False
+        self._create_rule_id()
+        self._preprocessing()
+
+    def _create_rule_id(self) -> str:
+        if not self.rule_id:
+            self.rule_id = compile_rule_id(self.txn_type,
+                                           self.field,
+                                           '*' if self.old_value == '*' else re.escape(self.old_value),
+                                           '*' if self.new_value == '*' else re.escape(self.new_value))
+
+    @abstractmethod
+    def _preprocessing(self):
+        raise NotImplementedError()
+
+
+class RuleAdd(AbstractRule):
+    def _preprocessing(self):
+        self.allow_old_value = True
+        if self.field == '*':
+            self.allow_field = True
+        if self.new_value == '*':
+            self.allow_new_value = True
+        if self.default_auth_constraint == []:
+            self.allow_for_all = True
+
+
+class RuleRemove(AbstractRule):
+    def _preprocessing(self):
+        self.allow_old_value = True
+        self.allow_new_value = True
+        if self.field == '*':
+            self.allow_field = True
+        if self.default_auth_constraint == []:
+            self.allow_for_all = True
+
+
+class RuleEdit(AbstractRule):
+    def _preprocessing(self):
+        if self.field == '*':
+            self.allow_field = True
+        if self.old_value == '*':
+            self.allow_old_value = True
+        if self.new_value == '*':
+            self.allow_new_value = True
+        if self.default_auth_constraint == []:
+            self.allow_for_all = True
+
+
+""""""
+
+Policy's clases
+
+""""""
+",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/238656925,https://github.com/hyperledger/indy-node/pull/1060#discussion_r238656925,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,Please use common Camel Case for all actions ,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-11 13:26:12,240608098,"@@ -0,0 +1,231 @@
+from typing import NamedTuple
+
+from indy_common.auth_constraints import AuthConstraint, AuthConstraintOr
+from indy_common.constants import ROLE, NODE
+from plenum.common.constants import TRUSTEE, STEWARD, VERKEY
+
+from abc import ABCMeta, abstractmethod
+
+from indy_common.constants import OWNER, POOL_UPGRADE, TRUST_ANCHOR, NYM, \
+    POOL_CONFIG, SCHEMA, CLAIM_DEF, \
+    POOL_RESTART, VALIDATOR_INFO
+
+
+RULE_DELIMETER = ""--""
+ADD_PREFIX = ""ADD""
+EDIT_PREFIX = ""EDIT""
+
+ActionDef = NamedTuple('ActionDef', [('prefix', str), ('txn_type', str), ('field', str), ('old_value', str), ('new_value', str)])
+
+
+def compile_action_id(txn_type,
+                      field,
+                      old_value,
+                      new_value,
+                      prefix='') -> str:
+    return RULE_DELIMETER.join([prefix,
+                                txn_type,
+                                field,
+                                old_value,
+                                new_value])
+
+
+def split_action_id(action_id) -> ActionDef:
+    return ActionDef(*action_id.split(RULE_DELIMETER))
+
+
+""""""
+
+Action's classes
+
+""""""
+
+
+class AbstractAuthAction(metaclass=ABCMeta):
+    def __init__(self, txn_type):
+        pass
+
+    @abstractmethod
+    def get_action_id(self):
+        raise NotImplementedError()
+
+
+class AuthActionAdd(AbstractAuthAction):
+    def __init__(self, txn_type, field=None, value=None):
+        self.txn_type = txn_type
+        self.field = field
+        self.value = value
+
+    def get_action_id(self):
+        return compile_action_id(txn_type=self.txn_type,
+                                 field=self.field,
+                                 old_value='*',
+                                 new_value=self.value,
+                                 prefix=ADD_PREFIX)
+
+
+class AuthActionEdit(AbstractAuthAction):
+    def __init__(self, txn_type, field=None, old_value=None, new_value=None):
+        self.txn_type = txn_type
+        self.field = field
+        self.old_value = old_value
+        self.new_value = new_value
+
+    def get_action_id(self):
+        return compile_action_id(txn_type=self.txn_type,
+                                 field=self.field,
+                                 old_value=self.old_value,
+                                 new_value=self.new_value,
+                                 prefix=EDIT_PREFIX)
+
+
+addNewTrustee = AuthActionAdd(txn_type=NYM,",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240608098,https://github.com/hyperledger/indy-node/pull/1060#discussion_r240608098,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,Please move concrete actions and auth_map into a separate file,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-11 13:26:30,240608213,"@@ -0,0 +1,231 @@
+from typing import NamedTuple
+
+from indy_common.auth_constraints import AuthConstraint, AuthConstraintOr
+from indy_common.constants import ROLE, NODE
+from plenum.common.constants import TRUSTEE, STEWARD, VERKEY
+
+from abc import ABCMeta, abstractmethod
+
+from indy_common.constants import OWNER, POOL_UPGRADE, TRUST_ANCHOR, NYM, \
+    POOL_CONFIG, SCHEMA, CLAIM_DEF, \
+    POOL_RESTART, VALIDATOR_INFO
+
+
+RULE_DELIMETER = ""--""
+ADD_PREFIX = ""ADD""
+EDIT_PREFIX = ""EDIT""
+
+ActionDef = NamedTuple('ActionDef', [('prefix', str), ('txn_type', str), ('field', str), ('old_value', str), ('new_value', str)])
+
+
+def compile_action_id(txn_type,
+                      field,
+                      old_value,
+                      new_value,
+                      prefix='') -> str:
+    return RULE_DELIMETER.join([prefix,
+                                txn_type,
+                                field,
+                                old_value,
+                                new_value])
+
+
+def split_action_id(action_id) -> ActionDef:
+    return ActionDef(*action_id.split(RULE_DELIMETER))
+
+
+""""""
+
+Action's classes
+
+""""""
+
+
+class AbstractAuthAction(metaclass=ABCMeta):
+    def __init__(self, txn_type):
+        pass
+
+    @abstractmethod
+    def get_action_id(self):
+        raise NotImplementedError()
+
+
+class AuthActionAdd(AbstractAuthAction):
+    def __init__(self, txn_type, field=None, value=None):
+        self.txn_type = txn_type
+        self.field = field
+        self.value = value
+
+    def get_action_id(self):
+        return compile_action_id(txn_type=self.txn_type,
+                                 field=self.field,
+                                 old_value='*',
+                                 new_value=self.value,
+                                 prefix=ADD_PREFIX)
+
+
+class AuthActionEdit(AbstractAuthAction):
+    def __init__(self, txn_type, field=None, old_value=None, new_value=None):
+        self.txn_type = txn_type
+        self.field = field
+        self.old_value = old_value
+        self.new_value = new_value
+
+    def get_action_id(self):
+        return compile_action_id(txn_type=self.txn_type,
+                                 field=self.field,
+                                 old_value=self.old_value,
+                                 new_value=self.new_value,
+                                 prefix=EDIT_PREFIX)
+
+
+addNewTrustee = AuthActionAdd(txn_type=NYM,",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/240608213,https://github.com/hyperledger/indy-node/pull/1060#discussion_r240608213,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"I think `AuthConstraintAnd` and `AuthConstraintOr` need to extend  `AbstractAuthConstraint`, and `AbstractAuthConstraint` should have just one field: `constraint_id `",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 12:55:12,241002417,"@@ -0,0 +1,53 @@
+from abc import ABCMeta, abstractmethod
+from typing import List
+
+
+ROLE_CONSTRAINT_ID = 'ROLE'
+AND_CONSTRAINT_ID = 'AND'
+OR_CONSTRAINT_ID = 'OR'
+
+
+class AbstractAuthConstraint(metaclass=ABCMeta):
+    def __init__(self, role, sig_count, need_to_be_owner=False, metadata={}):
+        self.role = role
+        self.sig_count = sig_count
+        self.need_to_be_owner = need_to_be_owner
+        self.metadata = metadata
+        self.constraint_id = ''
+
+
+class AuthConstraint(AbstractAuthConstraint):
+    def __init__(self, role, sig_count, need_to_be_owner=False, metadata={}):
+        super().__init__(role, sig_count, need_to_be_owner=need_to_be_owner, metadata=metadata)
+        self.constraint_id = ROLE_CONSTRAINT_ID
+
+
+class AuthConstraintAnd:",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241002417,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241002417,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,Should we move all the classes related to authorization into `auth` package?,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 12:56:50,241002888,"@@ -0,0 +1,147 @@
+from abc import ABCMeta
+
+from indy_common.auth_constraints import AuthConstraint, AbstractAuthConstraint, ROLE_CONSTRAINT_ID, AuthConstraintAnd
+from indy_common.auth_actions import AbstractAuthAction
+from indy_common.types import Request
+from indy_node.persistence.idr_cache import IdrCache
+from plenum.common.constants import TXN_TYPE, NYM, TARGET_NYM
+
+",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241002888,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241002888,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,Why do we call `parent` here? Should we just call `super().authorize`? ,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 13:17:27,241009144,"@@ -0,0 +1,147 @@
+from abc import ABCMeta
+
+from indy_common.auth_constraints import AuthConstraint, AbstractAuthConstraint, ROLE_CONSTRAINT_ID, AuthConstraintAnd
+from indy_common.auth_actions import AbstractAuthAction
+from indy_common.types import Request
+from indy_node.persistence.idr_cache import IdrCache
+from plenum.common.constants import TXN_TYPE, NYM, TARGET_NYM
+
+
+class AuthRuleNotFound(Exception):
+    pass
+
+
+class AuthValidationError(Exception):
+    pass
+
+
+class AbstractAuthorizer(metaclass=ABCMeta):
+
+    def __init__(self):
+        self.parent = None
+
+    def authorize(self,
+                  request: Request,
+                  auth_constraint: AbstractAuthConstraint,
+                  auth_action: AbstractAuthAction)-> (bool, str):
+        raise NotImplementedError()
+
+
+class RolesAuthorizer(AbstractAuthorizer):
+    def __init__(self, cache: IdrCache):
+        super().__init__()
+        self.cache = cache
+
+    def get_role(self, request: Request):
+        """"""Also need to check isOwner or not""""""
+        idr = request.identifier
+        try:
+            role = self.cache.getRole(idr, isCommitted=False)
+        except KeyError:
+            role = None
+
+        return role
+
+    def get_sig_count(self, request: Request):
+        pass
+
+    def _get_req_owner_for_nym(self, request: Request):
+        try:
+            owner = self.cache.getOwnerFor(request.identifier, isCommitted=False)
+        except KeyError:
+            """"""Not found in idrCache""""""
+            owner = None
+        return owner
+
+    def _get_txn_owner_for_nym(self, request: Request):
+        try:
+            owner = self.cache.getOwnerFor(request.operation[TARGET_NYM], isCommitted=False)
+        except KeyError:
+            """"""Not found in idrCache""""""
+            owner = None
+        return owner
+
+    def _get_req_owner(self, request: Request):
+        return request.identifier
+
+    def _get_txn_owner(self, request: Request):
+        txn_type = request.operation[TXN_TYPE]
+        if txn_type == NYM:
+            return self._get_txn_owner_for_nym(request)
+        return None
+
+    def is_owner_accepted(self, request: Request, constraint: AuthConstraint):
+        if constraint.need_to_be_owner and \
+                self._get_req_owner(request) != self._get_txn_owner(request):
+            return False
+        return True
+
+    def is_role_accepted(self, request: Request, auth_constraint: AuthConstraint):
+        role = self.get_role(request)
+        if role:
+            return role == auth_constraint.role or auth_constraint.role == '*'
+
+    def is_sig_count_accepted(self, request: Request, auth_constraint: AuthConstraint):
+        sig_count = 1
+        if auth_constraint.sig_count != 1:
+            sig_count = self.get_sig_count(request)
+
+        return sig_count >= auth_constraint.sig_count
+
+    def authorize(self, request: Request, auth_constraint: AuthConstraint, auth_action: AbstractAuthAction=None):
+        if not self.is_role_accepted(request, auth_constraint):
+            return False, ""role is not accepted""
+        if not self.is_sig_count_accepted(request, auth_constraint):
+            return False, ""count of signatures is not accepted""
+        if not self.is_owner_accepted(request, auth_constraint):
+            return False, ""actor must be owner""
+        return True, """"
+
+
+class CompositeAuthorizer(AbstractAuthorizer):
+    def __init__(self):
+        super().__init__()
+        self.authorizers = {}
+
+    def register_authorizer(self, authorizer, auth_constraint_id=ROLE_CONSTRAINT_ID):
+        authorizer.parent = self
+        self.authorizers.setdefault(auth_constraint_id, []).append(authorizer)
+
+    def authorize(self, request: Request, auth_constraint: AuthConstraint, auth_action: AbstractAuthAction):
+        for authorizer in self.authorizers.get(auth_constraint.constraint_id):
+            authorized, reason = authorizer.authorize(request=request,
+                                                      auth_constraint=auth_constraint,
+                                                      auth_action=auth_action)
+            if not authorized:
+                raise AuthValidationError(""Validation error with reason: {}"".format(reason))
+            return True, """"
+
+
+class AndAuthorizer(CompositeAuthorizer):
+
+    def authorize(self, request, auth_constraint: AuthConstraintAnd, auth_action: AbstractAuthAction):
+        for constraint in auth_constraint.auth_constraints:
+            authorized, reason = self.parent.authorize(request=request,",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241009144,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241009144,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,What if auth_constraint is not found? I think it means that this action is not allowed.,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 13:20:20,241010062,"@@ -0,0 +1,48 @@
+from abc import abstractmethod
+from typing import List
+
+from indy_common.auth_cons_strategies import LocalAuthStrategy
+from indy_common.auth_constraints import ROLE_CONSTRAINT_ID, AND_CONSTRAINT_ID, OR_CONSTRAINT_ID
+from indy_common.auth_actions import AbstractAuthAction
+from indy_common.authorizer import AbstractAuthorizer, CompositeAuthorizer, RolesAuthorizer, AndAuthorizer, \
+    OrAuthorizer, AuthValidationError
+from indy_common.types import Request
+
+
+class AbstractRequestValidator(AbstractAuthorizer):
+
+    @abstractmethod
+    def validate(self, request, action_list: [AbstractAuthAction]):
+        raise NotImplementedError()
+
+
+class WriteRequestValidator(AbstractRequestValidator, CompositeAuthorizer):
+    def __init__(self, config, auth_map, cache):
+        CompositeAuthorizer.__init__(self)
+        self.cache = cache
+        self.config = config
+        self.auth_map = auth_map
+        self.auth_cons_strategy = self.create_auth_strategy()
+        self.register_default_authorizers()
+
+    def register_default_authorizers(self):
+        self.register_authorizer(RolesAuthorizer(cache=self.cache), auth_constraint_id=ROLE_CONSTRAINT_ID)
+        self.register_authorizer(AndAuthorizer(), auth_constraint_id=AND_CONSTRAINT_ID)
+        self.register_authorizer(OrAuthorizer(), auth_constraint_id=OR_CONSTRAINT_ID)
+
+    def validate(self, request: Request, action_list: [AbstractAuthAction]):
+        for action in action_list:
+            action_id = action.get_action_id()
+            auth_constraint = self.auth_cons_strategy.get_auth_constraint(action_id)
+            if auth_constraint:",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241010062,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241010062,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"Please add tests for `split_action_id`. 
`split_action_id(compile_action_id(action)) == action??`",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 13:27:26,241012514,"@@ -0,0 +1,17 @@
+from indy_common.auth_actions import compile_action_id, ADD_PREFIX, EDIT_PREFIX
+",2,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241012514,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241012514,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,Please add more tests for `is_accepted_action_id` and `LocalAuthStrategy.get_auth_constraint`,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 13:29:27,241013184,"@@ -0,0 +1,58 @@
+from abc import abstractmethod, ABCMeta
+
+from indy_common.auth_constraints import AbstractAuthConstraint
+from indy_common.auth_actions import split_action_id
+
+
+class AbstractAuthStrategy(metaclass=ABCMeta):
+    def __init__(self, auth_map):
+        self.auth_map = auth_map
+
+    @abstractmethod
+    def get_auth_constraint(self, action_id) -> AbstractAuthConstraint:
+        raise NotImplementedError()
+
+    @abstractmethod
+    def _find_auth_constraint_key(self, action_id):
+        raise NotImplementedError()
+
+    @staticmethod
+    def is_accepted_action_id(from_auth_map, from_req):",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241013184,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241013184,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"Please check that expected constraint is found. Please add more tests (is_accepted_action_id ?) for different cases, especially with *.",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 13:30:06,241013420,"@@ -0,0 +1,32 @@
+import pytest
+
+from indy_common.auth_cons_strategies import LocalAuthStrategy
+from indy_common.auth_constraints import AuthConstraint
+
+
+@pytest.fixture(scope='function')
+def auth_map(action_add, action_edit):
+    """"""
+    action_ids:
+    for add: ""ADD--SomeType--some_field--*--new_value""
+    for edit: ""EDIT--SomeType--some_field--old_value--new_value""
+    """"""
+    return {action_add.get_action_id(): AuthConstraint(role=""Actor"",
+                                                       sig_count=3),
+            action_edit.get_action_id(): AuthConstraint(role=""Actor"",
+                                                        sig_count=2)}
+
+
+@pytest.fixture(scope='function')
+def local_auth_strategy(auth_map):
+    return LocalAuthStrategy(auth_map=auth_map)
+
+
+def test_local_strategy_found_the_same_action_id(local_auth_strategy):
+    assert local_auth_strategy.get_auth_constraint(""ADD--SomeType--some_field--*--new_value"")",26,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241013420,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241013420,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,done,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 14:51:09,241043947,"@@ -0,0 +1,58 @@
+from abc import abstractmethod, ABCMeta
+
+from indy_common.auth_constraints import AbstractAuthConstraint
+from indy_common.auth_actions import split_action_id
+
+
+class AbstractAuthStrategy(metaclass=ABCMeta):
+    def __init__(self, auth_map):
+        self.auth_map = auth_map
+
+    @abstractmethod
+    def get_auth_constraint(self, action_id) -> AbstractAuthConstraint:
+        raise NotImplementedError()
+
+    @abstractmethod
+    def _find_auth_constraint_key(self, action_id):
+        raise NotImplementedError()
+
+    @staticmethod
+    def is_accepted_action_id(from_auth_map, from_req):",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241043947,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241043947,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"done
",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 14:51:27,241044115,"@@ -0,0 +1,32 @@
+import pytest
+
+from indy_common.auth_cons_strategies import LocalAuthStrategy
+from indy_common.auth_constraints import AuthConstraint
+
+
+@pytest.fixture(scope='function')
+def auth_map(action_add, action_edit):
+    """"""
+    action_ids:
+    for add: ""ADD--SomeType--some_field--*--new_value""
+    for edit: ""EDIT--SomeType--some_field--old_value--new_value""
+    """"""
+    return {action_add.get_action_id(): AuthConstraint(role=""Actor"",
+                                                       sig_count=3),
+            action_edit.get_action_id(): AuthConstraint(role=""Actor"",
+                                                        sig_count=2)}
+
+
+@pytest.fixture(scope='function')
+def local_auth_strategy(auth_map):
+    return LocalAuthStrategy(auth_map=auth_map)
+
+
+def test_local_strategy_found_the_same_action_id(local_auth_strategy):
+    assert local_auth_strategy.get_auth_constraint(""ADD--SomeType--some_field--*--new_value"")",26,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241044115,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241044115,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"in case of instantiating from class with Composite as a parent, attribute `authorizers` will be empty and super().authorize will not continue iterating over other authorizers. Therefore, we need to have a reference to object with registered authotizers. Like in Composite pattern",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 14:54:41,241045598,"@@ -0,0 +1,147 @@
+from abc import ABCMeta
+
+from indy_common.auth_constraints import AuthConstraint, AbstractAuthConstraint, ROLE_CONSTRAINT_ID, AuthConstraintAnd
+from indy_common.auth_actions import AbstractAuthAction
+from indy_common.types import Request
+from indy_node.persistence.idr_cache import IdrCache
+from plenum.common.constants import TXN_TYPE, NYM, TARGET_NYM
+
+
+class AuthRuleNotFound(Exception):
+    pass
+
+
+class AuthValidationError(Exception):
+    pass
+
+
+class AbstractAuthorizer(metaclass=ABCMeta):
+
+    def __init__(self):
+        self.parent = None
+
+    def authorize(self,
+                  request: Request,
+                  auth_constraint: AbstractAuthConstraint,
+                  auth_action: AbstractAuthAction)-> (bool, str):
+        raise NotImplementedError()
+
+
+class RolesAuthorizer(AbstractAuthorizer):
+    def __init__(self, cache: IdrCache):
+        super().__init__()
+        self.cache = cache
+
+    def get_role(self, request: Request):
+        """"""Also need to check isOwner or not""""""
+        idr = request.identifier
+        try:
+            role = self.cache.getRole(idr, isCommitted=False)
+        except KeyError:
+            role = None
+
+        return role
+
+    def get_sig_count(self, request: Request):
+        pass
+
+    def _get_req_owner_for_nym(self, request: Request):
+        try:
+            owner = self.cache.getOwnerFor(request.identifier, isCommitted=False)
+        except KeyError:
+            """"""Not found in idrCache""""""
+            owner = None
+        return owner
+
+    def _get_txn_owner_for_nym(self, request: Request):
+        try:
+            owner = self.cache.getOwnerFor(request.operation[TARGET_NYM], isCommitted=False)
+        except KeyError:
+            """"""Not found in idrCache""""""
+            owner = None
+        return owner
+
+    def _get_req_owner(self, request: Request):
+        return request.identifier
+
+    def _get_txn_owner(self, request: Request):
+        txn_type = request.operation[TXN_TYPE]
+        if txn_type == NYM:
+            return self._get_txn_owner_for_nym(request)
+        return None
+
+    def is_owner_accepted(self, request: Request, constraint: AuthConstraint):
+        if constraint.need_to_be_owner and \
+                self._get_req_owner(request) != self._get_txn_owner(request):
+            return False
+        return True
+
+    def is_role_accepted(self, request: Request, auth_constraint: AuthConstraint):
+        role = self.get_role(request)
+        if role:
+            return role == auth_constraint.role or auth_constraint.role == '*'
+
+    def is_sig_count_accepted(self, request: Request, auth_constraint: AuthConstraint):
+        sig_count = 1
+        if auth_constraint.sig_count != 1:
+            sig_count = self.get_sig_count(request)
+
+        return sig_count >= auth_constraint.sig_count
+
+    def authorize(self, request: Request, auth_constraint: AuthConstraint, auth_action: AbstractAuthAction=None):
+        if not self.is_role_accepted(request, auth_constraint):
+            return False, ""role is not accepted""
+        if not self.is_sig_count_accepted(request, auth_constraint):
+            return False, ""count of signatures is not accepted""
+        if not self.is_owner_accepted(request, auth_constraint):
+            return False, ""actor must be owner""
+        return True, """"
+
+
+class CompositeAuthorizer(AbstractAuthorizer):
+    def __init__(self):
+        super().__init__()
+        self.authorizers = {}
+
+    def register_authorizer(self, authorizer, auth_constraint_id=ROLE_CONSTRAINT_ID):
+        authorizer.parent = self
+        self.authorizers.setdefault(auth_constraint_id, []).append(authorizer)
+
+    def authorize(self, request: Request, auth_constraint: AuthConstraint, auth_action: AbstractAuthAction):
+        for authorizer in self.authorizers.get(auth_constraint.constraint_id):
+            authorized, reason = authorizer.authorize(request=request,
+                                                      auth_constraint=auth_constraint,
+                                                      auth_action=auth_action)
+            if not authorized:
+                raise AuthValidationError(""Validation error with reason: {}"".format(reason))
+            return True, """"
+
+
+class AndAuthorizer(CompositeAuthorizer):
+
+    def authorize(self, request, auth_constraint: AuthConstraintAnd, auth_action: AbstractAuthAction):
+        for constraint in auth_constraint.auth_constraints:
+            authorized, reason = self.parent.authorize(request=request,",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241045598,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241045598,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"But this should call Composite's authorize, not the actual parent authorize. If we have And/Or owned/parent by other And/Ors, then it may lead to calling an incorrect parent (And/Or instead of Composte's authorize).",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 14:58:47,241047490,"@@ -0,0 +1,147 @@
+from abc import ABCMeta
+
+from indy_common.auth_constraints import AuthConstraint, AbstractAuthConstraint, ROLE_CONSTRAINT_ID, AuthConstraintAnd
+from indy_common.auth_actions import AbstractAuthAction
+from indy_common.types import Request
+from indy_node.persistence.idr_cache import IdrCache
+from plenum.common.constants import TXN_TYPE, NYM, TARGET_NYM
+
+
+class AuthRuleNotFound(Exception):
+    pass
+
+
+class AuthValidationError(Exception):
+    pass
+
+
+class AbstractAuthorizer(metaclass=ABCMeta):
+
+    def __init__(self):
+        self.parent = None
+
+    def authorize(self,
+                  request: Request,
+                  auth_constraint: AbstractAuthConstraint,
+                  auth_action: AbstractAuthAction)-> (bool, str):
+        raise NotImplementedError()
+
+
+class RolesAuthorizer(AbstractAuthorizer):
+    def __init__(self, cache: IdrCache):
+        super().__init__()
+        self.cache = cache
+
+    def get_role(self, request: Request):
+        """"""Also need to check isOwner or not""""""
+        idr = request.identifier
+        try:
+            role = self.cache.getRole(idr, isCommitted=False)
+        except KeyError:
+            role = None
+
+        return role
+
+    def get_sig_count(self, request: Request):
+        pass
+
+    def _get_req_owner_for_nym(self, request: Request):
+        try:
+            owner = self.cache.getOwnerFor(request.identifier, isCommitted=False)
+        except KeyError:
+            """"""Not found in idrCache""""""
+            owner = None
+        return owner
+
+    def _get_txn_owner_for_nym(self, request: Request):
+        try:
+            owner = self.cache.getOwnerFor(request.operation[TARGET_NYM], isCommitted=False)
+        except KeyError:
+            """"""Not found in idrCache""""""
+            owner = None
+        return owner
+
+    def _get_req_owner(self, request: Request):
+        return request.identifier
+
+    def _get_txn_owner(self, request: Request):
+        txn_type = request.operation[TXN_TYPE]
+        if txn_type == NYM:
+            return self._get_txn_owner_for_nym(request)
+        return None
+
+    def is_owner_accepted(self, request: Request, constraint: AuthConstraint):
+        if constraint.need_to_be_owner and \
+                self._get_req_owner(request) != self._get_txn_owner(request):
+            return False
+        return True
+
+    def is_role_accepted(self, request: Request, auth_constraint: AuthConstraint):
+        role = self.get_role(request)
+        if role:
+            return role == auth_constraint.role or auth_constraint.role == '*'
+
+    def is_sig_count_accepted(self, request: Request, auth_constraint: AuthConstraint):
+        sig_count = 1
+        if auth_constraint.sig_count != 1:
+            sig_count = self.get_sig_count(request)
+
+        return sig_count >= auth_constraint.sig_count
+
+    def authorize(self, request: Request, auth_constraint: AuthConstraint, auth_action: AbstractAuthAction=None):
+        if not self.is_role_accepted(request, auth_constraint):
+            return False, ""role is not accepted""
+        if not self.is_sig_count_accepted(request, auth_constraint):
+            return False, ""count of signatures is not accepted""
+        if not self.is_owner_accepted(request, auth_constraint):
+            return False, ""actor must be owner""
+        return True, """"
+
+
+class CompositeAuthorizer(AbstractAuthorizer):
+    def __init__(self):
+        super().__init__()
+        self.authorizers = {}
+
+    def register_authorizer(self, authorizer, auth_constraint_id=ROLE_CONSTRAINT_ID):
+        authorizer.parent = self
+        self.authorizers.setdefault(auth_constraint_id, []).append(authorizer)
+
+    def authorize(self, request: Request, auth_constraint: AuthConstraint, auth_action: AbstractAuthAction):
+        for authorizer in self.authorizers.get(auth_constraint.constraint_id):
+            authorized, reason = authorizer.authorize(request=request,
+                                                      auth_constraint=auth_constraint,
+                                                      auth_action=auth_action)
+            if not authorized:
+                raise AuthValidationError(""Validation error with reason: {}"".format(reason))
+            return True, """"
+
+
+class AndAuthorizer(CompositeAuthorizer):
+
+    def authorize(self, request, auth_constraint: AuthConstraintAnd, auth_action: AbstractAuthAction):
+        for constraint in auth_constraint.auth_constraints:
+            authorized, reason = self.parent.authorize(request=request,",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241047490,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241047490,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,ok,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 15:04:02,241049677,"@@ -0,0 +1,53 @@
+from abc import ABCMeta, abstractmethod
+from typing import List
+
+
+ROLE_CONSTRAINT_ID = 'ROLE'
+AND_CONSTRAINT_ID = 'AND'
+OR_CONSTRAINT_ID = 'OR'
+
+
+class AbstractAuthConstraint(metaclass=ABCMeta):
+    def __init__(self, role, sig_count, need_to_be_owner=False, metadata={}):
+        self.role = role
+        self.sig_count = sig_count
+        self.need_to_be_owner = need_to_be_owner
+        self.metadata = metadata
+        self.constraint_id = ''
+
+
+class AuthConstraint(AbstractAuthConstraint):
+    def __init__(self, role, sig_count, need_to_be_owner=False, metadata={}):
+        super().__init__(role, sig_count, need_to_be_owner=need_to_be_owner, metadata=metadata)
+        self.constraint_id = ROLE_CONSTRAINT_ID
+
+
+class AuthConstraintAnd:",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241049677,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241049677,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,done,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 15:53:42,241071225,"@@ -0,0 +1,17 @@
+from indy_common.auth_actions import compile_action_id, ADD_PREFIX, EDIT_PREFIX
+",2,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241071225,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241071225,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,done,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-12 15:53:59,241071373,"@@ -0,0 +1,48 @@
+from abc import abstractmethod
+from typing import List
+
+from indy_common.auth_cons_strategies import LocalAuthStrategy
+from indy_common.auth_constraints import ROLE_CONSTRAINT_ID, AND_CONSTRAINT_ID, OR_CONSTRAINT_ID
+from indy_common.auth_actions import AbstractAuthAction
+from indy_common.authorizer import AbstractAuthorizer, CompositeAuthorizer, RolesAuthorizer, AndAuthorizer, \
+    OrAuthorizer, AuthValidationError
+from indy_common.types import Request
+
+
+class AbstractRequestValidator(AbstractAuthorizer):
+
+    @abstractmethod
+    def validate(self, request, action_list: [AbstractAuthAction]):
+        raise NotImplementedError()
+
+
+class WriteRequestValidator(AbstractRequestValidator, CompositeAuthorizer):
+    def __init__(self, config, auth_map, cache):
+        CompositeAuthorizer.__init__(self)
+        self.cache = cache
+        self.config = config
+        self.auth_map = auth_map
+        self.auth_cons_strategy = self.create_auth_strategy()
+        self.register_default_authorizers()
+
+    def register_default_authorizers(self):
+        self.register_authorizer(RolesAuthorizer(cache=self.cache), auth_constraint_id=ROLE_CONSTRAINT_ID)
+        self.register_authorizer(AndAuthorizer(), auth_constraint_id=AND_CONSTRAINT_ID)
+        self.register_authorizer(OrAuthorizer(), auth_constraint_id=OR_CONSTRAINT_ID)
+
+    def validate(self, request: Request, action_list: [AbstractAuthAction]):
+        for action in action_list:
+            action_id = action.get_action_id()
+            auth_constraint = self.auth_cons_strategy.get_auth_constraint(action_id)
+            if auth_constraint:",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241071373,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241071373,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,Do we log / raise validation error?,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-13 06:46:18,241286966,"@@ -30,18 +29,20 @@ def register_default_authorizers(self):
         self.register_authorizer(AndAuthorizer(), auth_constraint_id=AND_CONSTRAINT_ID)
         self.register_authorizer(OrAuthorizer(), auth_constraint_id=OR_CONSTRAINT_ID)
 
-    def validate(self, request: Request, action_list: [AbstractAuthAction]):
+    def validate(self, request: Request, action_list: [AbstractAuthAction], is_owner=False):
         for action in action_list:
             action_id = action.get_action_id()
             auth_constraint = self.auth_cons_strategy.get_auth_constraint(action_id)
             if auth_constraint:
                 try:
                     super().authorize(request=request,
                                       auth_constraint=auth_constraint,
-                                      auth_action=action)
+                                      auth_action=action,
+                                      is_owner=is_owner)
                 except AuthValidationError:",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241286966,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241286966,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,Maybe we should put `is_owner` to EditAction?,ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-13 06:47:04,241287092,"@@ -30,18 +29,20 @@ def register_default_authorizers(self):
         self.register_authorizer(AndAuthorizer(), auth_constraint_id=AND_CONSTRAINT_ID)
         self.register_authorizer(OrAuthorizer(), auth_constraint_id=OR_CONSTRAINT_ID)
 
-    def validate(self, request: Request, action_list: [AbstractAuthAction]):
+    def validate(self, request: Request, action_list: [AbstractAuthAction], is_owner=False):",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241287092,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241287092,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"I think, that it will be usefull for revocation rules, when we need to check, that actor for adding revocation_entry is an owner of revocation definition too.",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-13 09:25:14,241324660,"@@ -30,18 +29,20 @@ def register_default_authorizers(self):
         self.register_authorizer(AndAuthorizer(), auth_constraint_id=AND_CONSTRAINT_ID)
         self.register_authorizer(OrAuthorizer(), auth_constraint_id=OR_CONSTRAINT_ID)
 
-    def validate(self, request: Request, action_list: [AbstractAuthAction]):
+    def validate(self, request: Request, action_list: [AbstractAuthAction], is_owner=False):",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241324660,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241324660,anikitinDSR
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"Ok, then we can add it for all both Add and Edit actions",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-13 09:54:45,241335159,"@@ -30,18 +29,20 @@ def register_default_authorizers(self):
         self.register_authorizer(AndAuthorizer(), auth_constraint_id=AND_CONSTRAINT_ID)
         self.register_authorizer(OrAuthorizer(), auth_constraint_id=OR_CONSTRAINT_ID)
 
-    def validate(self, request: Request, action_list: [AbstractAuthAction]):
+    def validate(self, request: Request, action_list: [AbstractAuthAction], is_owner=False):",,2018-12-13 13:05:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241335159,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241335159,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1060,https://github.com/hyperledger/indy-node/pull/1060,"It's better to say:
`Request can not be authorized as action is not allowed: {}`.format(request)",ac4b989ba50a4e14f3a72a7ea1cfb689756c0177,2018-12-13 13:18:21,241395134,"@@ -33,21 +34,26 @@ def register_default_authorizers(self):
         self.register_authorizer(AndAuthorizer(), auth_constraint_id=AND_CONSTRAINT_ID)
         self.register_authorizer(OrAuthorizer(), auth_constraint_id=OR_CONSTRAINT_ID)
 
-    def validate(self, request: Request, action_list: [AbstractAuthAction], is_owner=False):
+    def validate(self, request: Request, action_list: [AbstractAuthAction]):
         for action in action_list:
             action_id = action.get_action_id()
             auth_constraint = self.auth_cons_strategy.get_auth_constraint(action_id)
             if auth_constraint:
                 try:
                     super().authorize(request=request,
                                       auth_constraint=auth_constraint,
-                                      auth_action=action,
-                                      is_owner=is_owner)
+                                      auth_action=action)
                 except AuthValidationError as exp:
-                    logger.warning(""Request {} cannot be authorized by reason: {}"".format(request, exp))
-                    return False
+                    logger.warning(""Request {} cannot be authorized by reason: {}"".format(request, exp.reason))
+                    raise UnauthorizedClientRequest(request.identifier,
+                                                    request.reqId,
+                                                    exp.reason)
                 return True
-            return False
+            error_msg = ""There is no authorization constraints for request: {}"".format(request)",52,2018-12-13 13:18:21,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/241395134,https://github.com/hyperledger/indy-node/pull/1060#discussion_r241395134,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1059,https://github.com/hyperledger/indy-node/pull/1059,"What about `CLIENT_CONNECTIONS_LIMIT=10000` in `postinst_node`?
",f954c77ad22f90d6f6c33ec48cfe86b78c7799ec,2018-11-28 07:42:52,236968911,"@@ -3,6 +3,11 @@
 In order to prevent the indy-node process from reaching of open file descriptors limit caused by clients connections it is strongly",,2018-11-28 09:47:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/236968911,https://github.com/hyperledger/indy-node/pull/1059#discussion_r236968911,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1059,https://github.com/hyperledger/indy-node/pull/1059,I think a link of this doc and explicit statement about setting firewall rules needs to be part of `README.md` and `start-nodes.md`,f954c77ad22f90d6f6c33ec48cfe86b78c7799ec,2018-11-28 07:44:48,236969358,"@@ -3,6 +3,11 @@
 In order to prevent the indy-node process from reaching of open file descriptors limit caused by clients connections it is strongly
 recommended to add iptables rule that limits the number of simultaneous clients connections for client port.
 ",,2018-11-28 09:47:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/236969358,https://github.com/hyperledger/indy-node/pull/1059#discussion_r236969358,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1059,https://github.com/hyperledger/indy-node/pull/1059,Sure.,f954c77ad22f90d6f6c33ec48cfe86b78c7799ec,2018-11-28 08:55:50,236989091,"@@ -3,6 +3,11 @@
 In order to prevent the indy-node process from reaching of open file descriptors limit caused by clients connections it is strongly",,2018-11-28 09:47:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/236989091,https://github.com/hyperledger/indy-node/pull/1059#discussion_r236989091,sergey-shilov
https://github.com/hyperledger/indy-node/pull/1059,https://github.com/hyperledger/indy-node/pull/1059,Updated _setup-iptables.md_ and _start-nodes.md_.,f954c77ad22f90d6f6c33ec48cfe86b78c7799ec,2018-11-28 09:48:07,237008246,"@@ -3,6 +3,11 @@
 In order to prevent the indy-node process from reaching of open file descriptors limit caused by clients connections it is strongly
 recommended to add iptables rule that limits the number of simultaneous clients connections for client port.
 ",,2018-11-28 09:48:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237008246,https://github.com/hyperledger/indy-node/pull/1059#discussion_r237008246,sergey-shilov
https://github.com/hyperledger/indy-node/pull/1051,https://github.com/hyperledger/indy-node/pull/1051,"Please edit `dev-setup` scripts and how-to doc to get rid of anoncreds and charm-crypto installation.
The following is no longer needed:
```
echo 'Installing Charm Crypto...'
sudo apt-get install -y python3-charm-crypto
echo 'Installed Charm Crypto'
```
",02fa311c8e5626fac2f7c265c14964b3787b5b78,2018-11-23 07:38:29,235860750,"@@ -69,15 +69,10 @@ Indy Node repo consists of the following parts:
       So, if you want to work with Indy Node, you will need to have the Plenum code as well in most of the cases
       and work with two projects at the same time 
       (see [How to Start Working with the Code](#how-to-start-working-with-the-code) below).",3,2018-11-23 08:28:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/235860750,https://github.com/hyperledger/indy-node/pull/1051#discussion_r235860750,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1051,https://github.com/hyperledger/indy-node/pull/1051,Why can't we just remove this class? Where is it used?,02fa311c8e5626fac2f7c265c14964b3787b5b78,2018-11-23 07:51:00,235862359,"@@ -1,33 +1,27 @@
 import datetime",,2018-11-23 08:28:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/235862359,https://github.com/hyperledger/indy-node/pull/1051#discussion_r235862359,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1051,https://github.com/hyperledger/indy-node/pull/1051,Removed,02fa311c8e5626fac2f7c265c14964b3787b5b78,2018-11-23 08:09:52,235865229,"@@ -1,33 +1,27 @@
 import datetime",,2018-11-23 08:28:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/235865229,https://github.com/hyperledger/indy-node/pull/1051#discussion_r235865229,ArtObr
https://github.com/hyperledger/indy-node/pull/1051,https://github.com/hyperledger/indy-node/pull/1051,Fixed,02fa311c8e5626fac2f7c265c14964b3787b5b78,2018-11-23 08:09:56,235865247,"@@ -69,15 +69,10 @@ Indy Node repo consists of the following parts:
       So, if you want to work with Indy Node, you will need to have the Plenum code as well in most of the cases
       and work with two projects at the same time 
       (see [How to Start Working with the Code](#how-to-start-working-with-the-code) below).",3,2018-11-23 08:28:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/235865247,https://github.com/hyperledger/indy-node/pull/1051#discussion_r235865247,ArtObr
https://github.com/hyperledger/indy-node/pull/1045,https://github.com/hyperledger/indy-node/pull/1045,Why do we need whole file commented?,048d3c3e49b14b21d1aab8f781d8c2a066ea8424,2018-11-21 12:23:52,235366117,"@@ -1,112 +1,112 @@
-import pytest
-from indy_client.test.cli.constants import INVALID_SYNTAX, SCHEMA_ADDED
-from indy_client.test.cli.helper import createUuidIdentifier
-from indy_client.test.cli.helper import connect_and_check_output
-from indy_client.client.wallet.wallet import Wallet
-
-
-@pytest.fixture(scope='module')
-def wallet():
-    return Wallet('my wallet')
-
-
-SCHEMA_FOUND = ['Found schema', 'Degree',
-                '1.0', 'attrib1', 'attrib2', 'attrib3']
-SCHEMA_NOT_FOUND = 'Schema not found'
-
-
-@pytest.fixture(scope=""module"")
-def aliceCli(be, do, poolNodesStarted, aliceCLI, wallet):
-    keyseed = 'a' * 32
-
-    be(aliceCLI)
-    addAndActivateCLIWallet(aliceCLI, wallet)
-    connect_and_check_output(do, aliceCLI.txn_dir)
-    do('new key with seed {}'.format(keyseed))
-
-    return aliceCLI
-
-
-def addAndActivateCLIWallet(cli, wallet):
-    cli.wallets[wallet.name] = wallet
-    cli.activeWallet = wallet
-
-
-@pytest.fixture(scope=""module"")
-def send_schema(be, do, poolNodesStarted, trusteeCli):
-
-    be(trusteeCli)
-    do('send SCHEMA name=Degree version=1.0 keys=attrib1,attrib2,attrib3',
-       expect=SCHEMA_ADDED, within=5)
-
-
-def test_send_get_schema_succeeds(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    do('send GET_SCHEMA dest={} name=Degree version=1.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_FOUND, within=5)
-
-
-def test_send_get_schema_as_alice(
-        be, do, poolNodesStarted, trusteeCli, send_schema, aliceCli):
-
-    be(aliceCli)
-    do('send GET_SCHEMA dest={} name=Degree version=1.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_name(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    do('send GET_SCHEMA dest={} name=invalid version=1.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_NOT_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_dest(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    uuid_identifier = createUuidIdentifier()
-    do('send GET_SCHEMA dest={} name=invalid version=1.0'.format(
-        uuid_identifier), expect=SCHEMA_NOT_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_version(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-    do('send GET_SCHEMA dest={} name=Degree version=2.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_NOT_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_version_syntax(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA dest={} name=Degree version=asdf'.format(
-            trusteeCli.activeDID), expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
-
-
-def test_send_get_schema_fails_without_version(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA dest={} name=Degree'.format(trusteeCli.activeDID),
-            expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
-
-
-def test_send_get_schema_fails_without_name(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA dest={} version=1.0'.format(trusteeCli.activeDID),
-            expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
-
-
-def test_send_get_schema_fails_without_dest(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA name=Degree version=1.0',
-            expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
+# import pytest",113,2018-11-21 12:35:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/235366117,https://github.com/hyperledger/indy-node/pull/1045#discussion_r235366117,dsurnin
https://github.com/hyperledger/indy-node/pull/1045,https://github.com/hyperledger/indy-node/pull/1045,"here and later
are there any special conditions we do not use dedicated SDKs build_req* functions?",048d3c3e49b14b21d1aab8f781d8c2a066ea8424,2018-11-21 12:34:41,235368976,"@@ -102,28 +92,15 @@ def test_validator_info_file_get_claim_def(read_txn_and_get_latest_info,
     assert latest_info['Node_info']['Metrics']['average-per-second']['read-transactions'] > 0
 
 
-@pytest.fixture()
-def client_and_wallet(steward, stewardWallet):
-    return steward, stewardWallet
-
-
-def submitRequests(client, wallet, op):
-    req = wallet.signOp(op)
-    # TODO: This looks boilerplate
-    wallet.pendRequest(req)
-    reqs = wallet.preparePending()
-    return client.submitReqs(*reqs)[0]
-
-
-def makeGetNymRequest(client, wallet, nym):
+def makeGetNymRequest(looper, sdk_pool_handle, sdk_wallet, nym):
     op = {
         TARGET_NYM: nym,
         TXN_TYPE: GET_NYM,
     }
-    return submitRequests(client, wallet, op)
+    return sdk_submit_operation_and_get_replies(looper, sdk_pool_handle, sdk_wallet, op)",59,2018-11-21 12:35:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/235368976,https://github.com/hyperledger/indy-node/pull/1045#discussion_r235368976,dsurnin
https://github.com/hyperledger/indy-node/pull/1045,https://github.com/hyperledger/indy-node/pull/1045,This test will be integrated by Cam in separate PR. He is in process now.,048d3c3e49b14b21d1aab8f781d8c2a066ea8424,2018-11-21 13:06:28,235379073,"@@ -1,112 +1,112 @@
-import pytest
-from indy_client.test.cli.constants import INVALID_SYNTAX, SCHEMA_ADDED
-from indy_client.test.cli.helper import createUuidIdentifier
-from indy_client.test.cli.helper import connect_and_check_output
-from indy_client.client.wallet.wallet import Wallet
-
-
-@pytest.fixture(scope='module')
-def wallet():
-    return Wallet('my wallet')
-
-
-SCHEMA_FOUND = ['Found schema', 'Degree',
-                '1.0', 'attrib1', 'attrib2', 'attrib3']
-SCHEMA_NOT_FOUND = 'Schema not found'
-
-
-@pytest.fixture(scope=""module"")
-def aliceCli(be, do, poolNodesStarted, aliceCLI, wallet):
-    keyseed = 'a' * 32
-
-    be(aliceCLI)
-    addAndActivateCLIWallet(aliceCLI, wallet)
-    connect_and_check_output(do, aliceCLI.txn_dir)
-    do('new key with seed {}'.format(keyseed))
-
-    return aliceCLI
-
-
-def addAndActivateCLIWallet(cli, wallet):
-    cli.wallets[wallet.name] = wallet
-    cli.activeWallet = wallet
-
-
-@pytest.fixture(scope=""module"")
-def send_schema(be, do, poolNodesStarted, trusteeCli):
-
-    be(trusteeCli)
-    do('send SCHEMA name=Degree version=1.0 keys=attrib1,attrib2,attrib3',
-       expect=SCHEMA_ADDED, within=5)
-
-
-def test_send_get_schema_succeeds(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    do('send GET_SCHEMA dest={} name=Degree version=1.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_FOUND, within=5)
-
-
-def test_send_get_schema_as_alice(
-        be, do, poolNodesStarted, trusteeCli, send_schema, aliceCli):
-
-    be(aliceCli)
-    do('send GET_SCHEMA dest={} name=Degree version=1.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_name(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    do('send GET_SCHEMA dest={} name=invalid version=1.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_NOT_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_dest(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    uuid_identifier = createUuidIdentifier()
-    do('send GET_SCHEMA dest={} name=invalid version=1.0'.format(
-        uuid_identifier), expect=SCHEMA_NOT_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_version(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-    do('send GET_SCHEMA dest={} name=Degree version=2.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_NOT_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_version_syntax(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA dest={} name=Degree version=asdf'.format(
-            trusteeCli.activeDID), expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
-
-
-def test_send_get_schema_fails_without_version(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA dest={} name=Degree'.format(trusteeCli.activeDID),
-            expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
-
-
-def test_send_get_schema_fails_without_name(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA dest={} version=1.0'.format(trusteeCli.activeDID),
-            expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
-
-
-def test_send_get_schema_fails_without_dest(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA name=Degree version=1.0',
-            expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
+# import pytest",113,2018-11-21 13:07:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/235379073,https://github.com/hyperledger/indy-node/pull/1045#discussion_r235379073,ArtObr
https://github.com/hyperledger/indy-node/pull/1045,https://github.com/hyperledger/indy-node/pull/1045,No,048d3c3e49b14b21d1aab8f781d8c2a066ea8424,2018-11-21 13:11:25,235380536,"@@ -102,28 +92,15 @@ def test_validator_info_file_get_claim_def(read_txn_and_get_latest_info,
     assert latest_info['Node_info']['Metrics']['average-per-second']['read-transactions'] > 0
 
 
-@pytest.fixture()
-def client_and_wallet(steward, stewardWallet):
-    return steward, stewardWallet
-
-
-def submitRequests(client, wallet, op):
-    req = wallet.signOp(op)
-    # TODO: This looks boilerplate
-    wallet.pendRequest(req)
-    reqs = wallet.preparePending()
-    return client.submitReqs(*reqs)[0]
-
-
-def makeGetNymRequest(client, wallet, nym):
+def makeGetNymRequest(looper, sdk_pool_handle, sdk_wallet, nym):
     op = {
         TARGET_NYM: nym,
         TXN_TYPE: GET_NYM,
     }
-    return submitRequests(client, wallet, op)
+    return sdk_submit_operation_and_get_replies(looper, sdk_pool_handle, sdk_wallet, op)",59,2018-11-21 13:11:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/235380536,https://github.com/hyperledger/indy-node/pull/1045#discussion_r235380536,ArtObr
https://github.com/hyperledger/indy-node/pull/1044,https://github.com/hyperledger/indy-node/pull/1044,Please add comments about the difference and usage for `run_shell_command` and `run_shell_script`.,b174d52a7b4cc5f60acd7225f1e626034bcb2642,2018-11-20 12:46:20,234987516,"@@ -30,8 +30,7 @@ class NodeControlUtil:
     @classmethod
     def run_shell_command(cls, command, timeout=TIMEOUT):",8,2018-11-20 12:53:03,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234987516,https://github.com/hyperledger/indy-node/pull/1044#discussion_r234987516,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1044,https://github.com/hyperledger/indy-node/pull/1044,done,b174d52a7b4cc5f60acd7225f1e626034bcb2642,2018-11-20 12:53:12,234989548,"@@ -30,8 +30,7 @@ class NodeControlUtil:
     @classmethod
     def run_shell_command(cls, command, timeout=TIMEOUT):",8,2018-11-20 12:53:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234989548,https://github.com/hyperledger/indy-node/pull/1044#discussion_r234989548,dsurnin
https://github.com/hyperledger/indy-node/pull/1041,https://github.com/hyperledger/indy-node/pull/1041,Do we really need `pool` tag here?,c8ae6f7ac18d2afb971714d8d4a63db218dc8bef,2018-11-28 10:40:20,237028277,"@@ -0,0 +1,16 @@
+---
+- name: Configure pool
+  gather_facts: false
+  hosts: nodes
+  roles:
+    - indy_node
+  tags: [ 'pool', 'nodes' ]",14,2018-11-28 17:59:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237028277,https://github.com/hyperledger/indy-node/pull/1041#discussion_r237028277,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1041,https://github.com/hyperledger/indy-node/pull/1041,I think it would be handy to be able to refer that using `pool` since the playbook actually configures not a set of separate nodes but the pool of them.,c8ae6f7ac18d2afb971714d8d4a63db218dc8bef,2018-11-28 10:52:40,237032424,"@@ -0,0 +1,16 @@
+---
+- name: Configure pool
+  gather_facts: false
+  hosts: nodes
+  roles:
+    - indy_node
+  tags: [ 'pool', 'nodes' ]",14,2018-11-28 17:59:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237032424,https://github.com/hyperledger/indy-node/pull/1041#discussion_r237032424,andkononykhin
https://github.com/hyperledger/indy-node/pull/1041,https://github.com/hyperledger/indy-node/pull/1041,"This is repeated in 3 different playbooks, probably this better be moved to check_inventory.yml",c8ae6f7ac18d2afb971714d8d4a63db218dc8bef,2018-11-29 09:08:56,237401468,"@@ -1,4 +1,11 @@
 ---
+- name: Check inventory directory
+  gather_facts: false
+  hosts: localhost
+  tasks:
+    - include_tasks: tasks/check_inventory.yml
+      when: not (skip_inventory_check|default(false)|bool)",7,2018-11-29 09:10:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/237401468,https://github.com/hyperledger/indy-node/pull/1041#discussion_r237401468,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1040,https://github.com/hyperledger/indy-node/pull/1040,"I think, it would be nice to make a fixture sended_schema (like send_schema in removed tests), instead of writing schema every time",55d6905f1fbdde999e821b3b26fa7606d469fcc8,2018-11-19 15:38:38,234667125,"@@ -1,112 +1,109 @@
+import json
 import pytest
-from indy_client.test.cli.constants import INVALID_SYNTAX, SCHEMA_ADDED
-from indy_client.test.cli.helper import createUuidIdentifier
-from indy_client.test.cli.helper import connect_and_check_output
-from indy_client.client.wallet.wallet import Wallet
 
-
-@pytest.fixture(scope='module')
-def wallet():
-    return Wallet('my wallet')
-
-
-SCHEMA_FOUND = ['Found schema', 'Degree',
-                '1.0', 'attrib1', 'attrib2', 'attrib3']
-SCHEMA_NOT_FOUND = 'Schema not found'
-
-
-@pytest.fixture(scope=""module"")
-def aliceCli(be, do, poolNodesStarted, aliceCLI, wallet):
-    keyseed = 'a' * 32
-
-    be(aliceCLI)
-    addAndActivateCLIWallet(aliceCLI, wallet)
-    connect_and_check_output(do, aliceCLI.txn_dir)
-    do('new key with seed {}'.format(keyseed))
-
-    return aliceCLI
-
-
-def addAndActivateCLIWallet(cli, wallet):
-    cli.wallets[wallet.name] = wallet
-    cli.activeWallet = wallet
-
-
-@pytest.fixture(scope=""module"")
-def send_schema(be, do, poolNodesStarted, trusteeCli):
-
-    be(trusteeCli)
-    do('send SCHEMA name=Degree version=1.0 keys=attrib1,attrib2,attrib3',
-       expect=SCHEMA_ADDED, within=5)
-
-
-def test_send_get_schema_succeeds(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    do('send GET_SCHEMA dest={} name=Degree version=1.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_FOUND, within=5)
-
-
-def test_send_get_schema_as_alice(
-        be, do, poolNodesStarted, trusteeCli, send_schema, aliceCli):
-
-    be(aliceCli)
-    do('send GET_SCHEMA dest={} name=Degree version=1.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_name(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    do('send GET_SCHEMA dest={} name=invalid version=1.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_NOT_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_dest(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    uuid_identifier = createUuidIdentifier()
-    do('send GET_SCHEMA dest={} name=invalid version=1.0'.format(
-        uuid_identifier), expect=SCHEMA_NOT_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_version(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-    do('send GET_SCHEMA dest={} name=Degree version=2.0'.format(
-        trusteeCli.activeDID), expect=SCHEMA_NOT_FOUND, within=5)
-
-
-def test_send_get_schema_fails_with_invalid_version_syntax(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA dest={} name=Degree version=asdf'.format(
-            trusteeCli.activeDID), expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
-
-
-def test_send_get_schema_fails_without_version(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA dest={} name=Degree'.format(trusteeCli.activeDID),
-            expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
-
-
-def test_send_get_schema_fails_without_name(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA dest={} version=1.0'.format(trusteeCli.activeDID),
-            expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
-
-
-def test_send_get_schema_fails_without_dest(
-        be, do, poolNodesStarted, trusteeCli, send_schema):
-
-    with pytest.raises(AssertionError) as excinfo:
-        do('send GET_SCHEMA name=Degree version=1.0',
-            expect=SCHEMA_NOT_FOUND, within=5)
-    assert(INVALID_SYNTAX in str(excinfo.value))
+from indy_node.test.schema.helper import write_schema, prepare_get_schema_and_send
+from indy.ledger import parse_get_schema_response
+
+
+def test_send_get_schema_succeeds(looper, sdk_pool_handle,
+                                  sdk_wallet_trust_anchor):
+    _, issuer_id = sdk_wallet_trust_anchor
+
+    schema_name = ""Faber""
+    schema_version = ""1.8""
+    schema_attr = [""attribute1""]
+
+    write_schema(",126,2018-11-19 15:38:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234667125,https://github.com/hyperledger/indy-node/pull/1040#discussion_r234667125,ArtObr
https://github.com/hyperledger/indy-node/pull/1040,https://github.com/hyperledger/indy-node/pull/1040,We should probably write these methods with same style as in https://github.com/hyperledger/indy-node/pull/1034,55d6905f1fbdde999e821b3b26fa7606d469fcc8,2018-11-19 15:40:36,234667976,"@@ -177,10 +177,42 @@ def validate_claim_def_txn(txn):
 
 # Misc utility
 
-def sdk_write_schema(looper, sdk_pool_handle, sdk_wallet_steward):
+def sdk_write_schema(looper, sdk_pool_handle, sdk_wallet_steward, multi_attribute=[], name="""", version=""""):
     _, identifier = sdk_wallet_steward
-    _, schema_json = looper.loop.run_until_complete(
-        issuer_create_schema(identifier, ""name"", ""1.0"", json.dumps([""first"", ""last""])))
+
+    if multi_attribute:",19,2018-11-19 15:40:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234667976,https://github.com/hyperledger/indy-node/pull/1040#discussion_r234667976,ArtObr
https://github.com/hyperledger/indy-node/pull/1034,https://github.com/hyperledger/indy-node/pull/1034,Please use snake case for method and test names,e28124310d7406e56b1a0f72b66335f429f29317,2018-11-14 08:32:55,233351768,"@@ -1,10 +1,24 @@
+import json
+
+from indy.anoncreds import issuer_create_schema
+from indy.ledger import build_schema_request
 from indy_client.test.cli.constants import SCHEMA_ADDED, SCHEMA_NOT_ADDED_DUPLICATE
+from indy_node.test.api.helper import sdk_write_schema
+from plenum.test.helper import sdk_get_reply, sdk_sign_and_submit_req
 
 
-def test_send_schema_multiple_attribs(be, do, poolNodesStarted, trusteeCli):
-    be(trusteeCli)
-    do('send SCHEMA name=Degree version=1.0 keys=attrib1,attrib2,attrib3',
-       expect=SCHEMA_ADDED, within=5)
+def testSendSchemaMultipleAttribs(looper, sdk_pool_handle, sdk_wallet_trust_anchor):",,2018-11-19 15:47:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233351768,https://github.com/hyperledger/indy-node/pull/1034#discussion_r233351768,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1034,https://github.com/hyperledger/indy-node/pull/1034,Please make sure that there are no indy_client dependencies there,e28124310d7406e56b1a0f72b66335f429f29317,2018-11-14 08:34:18,233352130,"@@ -1,10 +1,24 @@
+import json
+
+from indy.anoncreds import issuer_create_schema
+from indy.ledger import build_schema_request
 from indy_client.test.cli.constants import SCHEMA_ADDED, SCHEMA_NOT_ADDED_DUPLICATE",,2018-11-19 15:47:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233352130,https://github.com/hyperledger/indy-node/pull/1034#discussion_r233352130,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1034,https://github.com/hyperledger/indy-node/pull/1034,Please move the tests into indy_node/test/... folder,e28124310d7406e56b1a0f72b66335f429f29317,2018-11-14 08:34:46,233352271,"@@ -1,10 +1,24 @@
+import json
+
+from indy.anoncreds import issuer_create_schema",,2018-11-19 15:47:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233352271,https://github.com/hyperledger/indy-node/pull/1034#discussion_r233352271,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1034,https://github.com/hyperledger/indy-node/pull/1034,"Each test must end with an assertion, not return.
Ideally, each test should be flat, straightforward, and consist of 3 main parts:
1) Configuration 
2) Execution
3) Assertion",e28124310d7406e56b1a0f72b66335f429f29317,2018-11-14 08:36:13,233352670,"@@ -1,10 +1,24 @@
+import json
+
+from indy.anoncreds import issuer_create_schema
+from indy.ledger import build_schema_request
 from indy_client.test.cli.constants import SCHEMA_ADDED, SCHEMA_NOT_ADDED_DUPLICATE
+from indy_node.test.api.helper import sdk_write_schema
+from plenum.test.helper import sdk_get_reply, sdk_sign_and_submit_req
 
 
-def test_send_schema_multiple_attribs(be, do, poolNodesStarted, trusteeCli):
-    be(trusteeCli)
-    do('send SCHEMA name=Degree version=1.0 keys=attrib1,attrib2,attrib3',
-       expect=SCHEMA_ADDED, within=5)
+def testSendSchemaMultipleAttribs(looper, sdk_pool_handle, sdk_wallet_trust_anchor):
+
+    wallet_handle, identifier = sdk_wallet_trust_anchor
+
+    schema_json, _ = sdk_write_schema(looper, sdk_pool_handle, sdk_wallet_trust_anchor)
+    _, schema_json = looper.loop.run_until_complete(
+        issuer_create_schema(identifier, ""name=Degree"", ""1.0"", json.dumps([""attrib1"",""attrib2"",""attrib3""])))
+
+    request = looper.loop.run_until_complete(build_schema_request(identifier, schema_json))
+
+    return schema_json, \",,2018-11-19 15:47:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233352670,https://github.com/hyperledger/indy-node/pull/1034#discussion_r233352670,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1034,https://github.com/hyperledger/indy-node/pull/1034,Why do we need this else here? I think we should remove it,e28124310d7406e56b1a0f72b66335f429f29317,2018-11-19 13:19:22,234614393,"@@ -184,3 +184,28 @@ def sdk_write_schema(looper, sdk_pool_handle, sdk_wallet_steward):
     request = looper.loop.run_until_complete(build_schema_request(identifier, schema_json))
     return schema_json, \
            sdk_get_reply(looper, sdk_sign_and_submit_req(sdk_pool_handle, sdk_wallet_steward, request))[1]
+
+
+def sdk_write_schema_and_check(looper, sdk_pool_handle, sdk_wallet_steward,
+                               multi_attribute=[], name="""", version=""""):
+    _, identifier = sdk_wallet_steward
+
+    if multi_attribute:
+        _, schema_json = looper.loop.run_until_complete(
+            issuer_create_schema(
+                identifier, name,
+                version, json.dumps(multi_attribute)
+            ))
+    else:",,2018-11-19 15:47:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234614393,https://github.com/hyperledger/indy-node/pull/1034#discussion_r234614393,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1034,https://github.com/hyperledger/indy-node/pull/1034,I would rename the parameter here to just `attributes`,e28124310d7406e56b1a0f72b66335f429f29317,2018-11-19 13:20:23,234614673,"@@ -184,3 +184,28 @@ def sdk_write_schema(looper, sdk_pool_handle, sdk_wallet_steward):
     request = looper.loop.run_until_complete(build_schema_request(identifier, schema_json))
     return schema_json, \
            sdk_get_reply(looper, sdk_sign_and_submit_req(sdk_pool_handle, sdk_wallet_steward, request))[1]
+
+
+def sdk_write_schema_and_check(looper, sdk_pool_handle, sdk_wallet_steward,
+                               multi_attribute=[], name="""", version=""""):",,2018-11-19 15:47:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234614673,https://github.com/hyperledger/indy-node/pull/1034#discussion_r234614673,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1034,https://github.com/hyperledger/indy-node/pull/1034,This is for the functions that relied on this helper before my modifications. ,e28124310d7406e56b1a0f72b66335f429f29317,2018-11-19 13:46:11,234622631,"@@ -184,3 +184,28 @@ def sdk_write_schema(looper, sdk_pool_handle, sdk_wallet_steward):
     request = looper.loop.run_until_complete(build_schema_request(identifier, schema_json))
     return schema_json, \
            sdk_get_reply(looper, sdk_sign_and_submit_req(sdk_pool_handle, sdk_wallet_steward, request))[1]
+
+
+def sdk_write_schema_and_check(looper, sdk_pool_handle, sdk_wallet_steward,
+                               multi_attribute=[], name="""", version=""""):
+    _, identifier = sdk_wallet_steward
+
+    if multi_attribute:
+        _, schema_json = looper.loop.run_until_complete(
+            issuer_create_schema(
+                identifier, name,
+                version, json.dumps(multi_attribute)
+            ))
+    else:",,2018-11-19 15:47:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234622631,https://github.com/hyperledger/indy-node/pull/1034#discussion_r234622631,cam-parra
https://github.com/hyperledger/indy-node/pull/1034,https://github.com/hyperledger/indy-node/pull/1034,"I was incorrect. Yes I believe this if can be removed
",e28124310d7406e56b1a0f72b66335f429f29317,2018-11-19 15:42:27,234668863,"@@ -184,3 +184,28 @@ def sdk_write_schema(looper, sdk_pool_handle, sdk_wallet_steward):
     request = looper.loop.run_until_complete(build_schema_request(identifier, schema_json))
     return schema_json, \
            sdk_get_reply(looper, sdk_sign_and_submit_req(sdk_pool_handle, sdk_wallet_steward, request))[1]
+
+
+def sdk_write_schema_and_check(looper, sdk_pool_handle, sdk_wallet_steward,
+                               multi_attribute=[], name="""", version=""""):
+    _, identifier = sdk_wallet_steward
+
+    if multi_attribute:
+        _, schema_json = looper.loop.run_until_complete(
+            issuer_create_schema(
+                identifier, name,
+                version, json.dumps(multi_attribute)
+            ))
+    else:",,2018-11-19 15:47:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234668863,https://github.com/hyperledger/indy-node/pull/1034#discussion_r234668863,cam-parra
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,Please move the test into indy-node folder,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:20:16,233348227,"@@ -1,35 +1,22 @@
 from plenum.common.util import randomString, hexToFriendly
-from plenum.common.constants import SERVICES, VALIDATOR, TARGET_NYM, DATA
+from plenum.common.constants import SERVICES, TARGET_NYM, DATA
 from plenum.common.txn_util import get_payload_data
 
-from plenum.test.pool_transactions.helper import sdk_add_new_nym, sdk_add_new_node, demote_node
-from indy_client.test.cli.helper import doSendNodeCmd
+from plenum.test.pool_transactions.helper import sdk_add_new_nym, sdk_add_new_node, demote_node, promote_node
 
 
-def testSuspendNode(be, do, trusteeCli, newNodeAdded):
+def testSuspendNode(looper, sdk_pool_handle, sdk_wallet_trustee, newNodeAdded):",12,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233348227,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233348227,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,This tests need to be migrated to SDK and moved to indy-node folder,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:21:47,233348582,"@@ -1,173 +0,0 @@
-import base58
-from plenum.bls.bls_crypto_factory import create_default_bls_crypto_factory
-
-from plenum.common.constants import NODE_IP, CLIENT_IP, CLIENT_PORT, NODE_PORT, \
-    ALIAS, BLS_KEY, BLS_KEY_PROOF
-from plenum.common.keygen_utils import init_bls_keys
-from plenum.common.util import randomString
-from plenum.test.cli.helper import exitFromCli
-from stp_core.network.port_dispenser import genHa
-
-from indy_client.test.cli.helper import doSendNodeCmd
-
-
-def test_add_new_node(newNodeAdded):",14,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233348582,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233348582,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,This tests need to be migrated to SDK and moved to indy-node folder,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:22:10,233348684,"@@ -1,51 +0,0 @@
-import pytest
-from plenum.common.signer_did import DidSigner
-from plenum.common.txn_util import get_payload_data
-from stp_core.crypto.util import randomSeed
-from indy_client.test.cli.helper import addAgent
-from plenum.common.constants import SERVICES, VALIDATOR, TARGET_NYM, DATA
-from indy_client.test.cli.constants import NODE_REQUEST_COMPLETED, NODE_REQUEST_FAILED
-
-
-def ensurePoolIsOperable(be, do, cli):",10,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233348684,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233348684,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,This tests need to be migrated to SDK and moved to indy-node folder,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:23:27,233349085,"@@ -1,137 +0,0 @@
-from copy import copy
-
-import pytest
-
-from indy_node.test import waits
-from stp_core.loop.eventually import eventually
-from plenum.common.constants import VERSION
-from indy_common.constants import ACTION, CANCEL, JUSTIFICATION
-from indy_node.test.upgrade.helper import checkUpgradeScheduled, \
-    checkNoUpgradeScheduled
-from indy_node.test.upgrade.conftest import validUpgrade, validUpgradeExpForceFalse, validUpgradeExpForceTrue
-
-
-def send_upgrade_cmd(do, expect, upgrade_data):",14,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233349085,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233349085,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,This tests need to be migrated to SDK and moved to indy-node folder,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:23:36,233349120,"@@ -1,27 +0,0 @@
-import dateutil
-import pytest
-from datetime import timedelta, datetime
-
-from indy_client.test.cli.test_pool_upgrade import poolUpgradeSubmitted
-from indy_client.test.cli.test_pool_upgrade import poolUpgradeScheduled
-from indy_node.test.upgrade.conftest import validUpgrade as _validUpgrade
-
-
-@pytest.fixture(scope='function')",10,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233349120,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233349120,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,This tests need to be migrated to SDK and moved to indy-node folder,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:23:48,233349171,"@@ -1,44 +0,0 @@
-from copy import deepcopy
-
-from indy_node.test.upgrade.conftest import validUpgrade
-from indy_client.test.cli.constants import INVALID_SYNTAX, ERROR
-from indy_node.test.upgrade.helper import loweredVersion
-from plenum.common.constants import VERSION
-from plenum.common.util import randomString
-from indy_common.constants import JUSTIFICATION, JUSTIFICATION_MAX_SIZE
-
-
-def testPoolUpgradeFailsIfVersionIsLowerThanCurrent(",,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233349171,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233349171,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,This tests need to be migrated to SDK and moved to indy-node folder,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:24:09,233349254,"@@ -1,153 +0,0 @@
-from binascii import hexlify
-
-import pytest
-from plenum.common.util import friendlyToRaw
-
-from indy_client.test.cli.constants import INVALID_SYNTAX
-from indy_client.test.cli.helper import createUuidIdentifier, addNym, \
-    createHalfKeyIdentifierAndAbbrevVerkey, createCryptonym
-from indy_common.roles import Roles
-from indy_node.test.helper import check_str_is_base58_compatible
-
-CURRENT_VERKEY_FOR_NYM = 'Current verkey for NYM {dest} is {verkey}'
-CURRENT_VERKEY_FOR_NYM_WITH_ROLE = 'Current verkey for NYM {dest} is ' \
-                                   '{verkey} with role {role}'
-CURRENT_VERKEY_IS_SAME_AS_IDENTIFIER = \
-    'Current verkey is same as identifier {dest}'
-NYM_NOT_FOUND = 'NYM {dest} not found'
-
-
-def testSendGetNymSucceedsForExistingUuidDest(",,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233349254,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233349254,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,This tests need to be migrated to SDK and moved to indy-node folder,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:24:17,233349292,"@@ -1,609 +0,0 @@
-import pytest
-from plenum.common.signer_did import DidSigner
-
-from stp_core.crypto.util import randomSeed
-
-from plenum.common.constants import NODE_IP, NODE_PORT, CLIENT_IP, CLIENT_PORT, \
-    ALIAS, SERVICES, VALIDATOR
-from plenum.common.signer_simple import SimpleSigner
-from plenum.common.util import cryptonymToHex, randomString
-from indy_client.test.cli.conftest import newStewardCli as getNewStewardCli, \
-    newStewardVals as getNewStewardVals, newNodeVals as getNewNodeVals
-from indy_client.test.cli.constants import NODE_REQUEST_COMPLETED, NODE_REQUEST_FAILED, INVALID_SYNTAX
-from indy_client.test.cli.helper import addAgent
-
-NYM_ADDED = ""Nym {remote} added""
-
-",17,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233349292,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233349292,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,This tests need to be migrated to SDK and moved to indy-node folder,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:24:26,233349339,"@@ -1,541 +0,0 @@
-import pytest
-from libnacl import randombytes
-
-from plenum.common.util import rawToFriendly, friendlyToHexStr, friendlyToHex, \
-    hexToFriendly
-from indy_client.test.cli.constants import ERROR, INVALID_SYNTAX
-from indy_client.test.cli.helper import createUuidIdentifier, \
-    createHalfKeyIdentifierAndAbbrevVerkey, createUuidIdentifierAndFullVerkey, \
-    createCryptonym
-from indy_common.roles import Roles
-
-NYM_ADDED = 'Nym {dest} added'
-
-",14,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233349339,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233349339,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,"I thought to do this in the next PR. And make this PR mainly for deleting. Tell me, if we need to do that in this PR.",8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:49:27,233356520,"@@ -1,35 +1,22 @@
 from plenum.common.util import randomString, hexToFriendly
-from plenum.common.constants import SERVICES, VALIDATOR, TARGET_NYM, DATA
+from plenum.common.constants import SERVICES, TARGET_NYM, DATA
 from plenum.common.txn_util import get_payload_data
 
-from plenum.test.pool_transactions.helper import sdk_add_new_nym, sdk_add_new_node, demote_node
-from indy_client.test.cli.helper import doSendNodeCmd
+from plenum.test.pool_transactions.helper import sdk_add_new_nym, sdk_add_new_node, demote_node, promote_node
 
 
-def testSuspendNode(be, do, trusteeCli, newNodeAdded):
+def testSuspendNode(looper, sdk_pool_handle, sdk_wallet_trustee, newNodeAdded):",12,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233356520,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233356520,ArtObr
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,"We are having pretty same functionality in 
indy-plenum/plenum/test/pool_transactions/test_nodes_data_changed.py
Please, tell me, if we need to integrate this in node",8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:55:22,233358244,"@@ -1,173 +0,0 @@
-import base58
-from plenum.bls.bls_crypto_factory import create_default_bls_crypto_factory
-
-from plenum.common.constants import NODE_IP, CLIENT_IP, CLIENT_PORT, NODE_PORT, \
-    ALIAS, BLS_KEY, BLS_KEY_PROOF
-from plenum.common.keygen_utils import init_bls_keys
-from plenum.common.util import randomString
-from plenum.test.cli.helper import exitFromCli
-from stp_core.network.port_dispenser import genHa
-
-from indy_client.test.cli.helper import doSendNodeCmd
-
-
-def test_add_new_node(newNodeAdded):",14,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233358244,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233358244,ArtObr
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,"I think we have pretty same functionality in 
indy-plenum/plenum/test/pool_transactions/test_suspend_node.py
Please, tell me, if we need to integrate this in node",8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 08:59:02,233359543,"@@ -1,51 +0,0 @@
-import pytest
-from plenum.common.signer_did import DidSigner
-from plenum.common.txn_util import get_payload_data
-from stp_core.crypto.util import randomSeed
-from indy_client.test.cli.helper import addAgent
-from plenum.common.constants import SERVICES, VALIDATOR, TARGET_NYM, DATA
-from indy_client.test.cli.constants import NODE_REQUEST_COMPLETED, NODE_REQUEST_FAILED
-
-
-def ensurePoolIsOperable(be, do, cli):",10,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233359543,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233359543,ArtObr
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,"I think we have every tests case duplicated in
indy-node/indy_node/test/upgrade
Please, tell me, if we need to integrate this in node",8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 09:07:45,233362346,"@@ -1,137 +0,0 @@
-from copy import copy
-
-import pytest
-
-from indy_node.test import waits
-from stp_core.loop.eventually import eventually
-from plenum.common.constants import VERSION
-from indy_common.constants import ACTION, CANCEL, JUSTIFICATION
-from indy_node.test.upgrade.helper import checkUpgradeScheduled, \
-    checkNoUpgradeScheduled
-from indy_node.test.upgrade.conftest import validUpgrade, validUpgradeExpForceFalse, validUpgradeExpForceTrue
-
-
-def send_upgrade_cmd(do, expect, upgrade_data):",14,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233362346,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233362346,ArtObr
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,"I think we have this test case duplicated in
indy-node/indy_node/test/upgrade/test_node_schedules_upgrade_for_proper_datetime.py
Please, tell me, if we need to integrate this in node

",8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 09:08:46,233362636,"@@ -1,27 +0,0 @@
-import dateutil
-import pytest
-from datetime import timedelta, datetime
-
-from indy_client.test.cli.test_pool_upgrade import poolUpgradeSubmitted
-from indy_client.test.cli.test_pool_upgrade import poolUpgradeScheduled
-from indy_node.test.upgrade.conftest import validUpgrade as _validUpgrade
-
-
-@pytest.fixture(scope='function')",10,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233362636,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233362636,ArtObr
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,integrated,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-14 13:07:26,233437815,"@@ -1,541 +0,0 @@
-import pytest
-from libnacl import randombytes
-
-from plenum.common.util import rawToFriendly, friendlyToHexStr, friendlyToHex, \
-    hexToFriendly
-from indy_client.test.cli.constants import ERROR, INVALID_SYNTAX
-from indy_client.test.cli.helper import createUuidIdentifier, \
-    createHalfKeyIdentifierAndAbbrevVerkey, createUuidIdentifierAndFullVerkey, \
-    createCryptonym
-from indy_common.roles import Roles
-
-NYM_ADDED = 'Nym {dest} added'
-
-",14,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233437815,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233437815,ArtObr
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,integrated,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-15 07:14:53,233732189,"@@ -1,609 +0,0 @@
-import pytest
-from plenum.common.signer_did import DidSigner
-
-from stp_core.crypto.util import randomSeed
-
-from plenum.common.constants import NODE_IP, NODE_PORT, CLIENT_IP, CLIENT_PORT, \
-    ALIAS, SERVICES, VALIDATOR
-from plenum.common.signer_simple import SimpleSigner
-from plenum.common.util import cryptonymToHex, randomString
-from indy_client.test.cli.conftest import newStewardCli as getNewStewardCli, \
-    newStewardVals as getNewStewardVals, newNodeVals as getNewNodeVals
-from indy_client.test.cli.constants import NODE_REQUEST_COMPLETED, NODE_REQUEST_FAILED, INVALID_SYNTAX
-from indy_client.test.cli.helper import addAgent
-
-NYM_ADDED = ""Nym {remote} added""
-
-",17,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233732189,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233732189,ArtObr
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,Restored. Will be integrated in future PRs,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-15 09:59:20,233778279,"@@ -1,153 +0,0 @@
-from binascii import hexlify
-
-import pytest
-from plenum.common.util import friendlyToRaw
-
-from indy_client.test.cli.constants import INVALID_SYNTAX
-from indy_client.test.cli.helper import createUuidIdentifier, addNym, \
-    createHalfKeyIdentifierAndAbbrevVerkey, createCryptonym
-from indy_common.roles import Roles
-from indy_node.test.helper import check_str_is_base58_compatible
-
-CURRENT_VERKEY_FOR_NYM = 'Current verkey for NYM {dest} is {verkey}'
-CURRENT_VERKEY_FOR_NYM_WITH_ROLE = 'Current verkey for NYM {dest} is ' \
-                                   '{verkey} with role {role}'
-CURRENT_VERKEY_IS_SAME_AS_IDENTIFIER = \
-    'Current verkey is same as identifier {dest}'
-NYM_NOT_FOUND = 'NYM {dest} not found'
-
-
-def testSendGetNymSucceedsForExistingUuidDest(",,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233778279,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233778279,ArtObr
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,Restored. Will be integrated in future PRs,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-15 10:00:58,233778918,"@@ -1,44 +0,0 @@
-from copy import deepcopy
-
-from indy_node.test.upgrade.conftest import validUpgrade
-from indy_client.test.cli.constants import INVALID_SYNTAX, ERROR
-from indy_node.test.upgrade.helper import loweredVersion
-from plenum.common.constants import VERSION
-from plenum.common.util import randomString
-from indy_common.constants import JUSTIFICATION, JUSTIFICATION_MAX_SIZE
-
-
-def testPoolUpgradeFailsIfVersionIsLowerThanCurrent(",,2018-11-15 10:01:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233778918,https://github.com/hyperledger/indy-node/pull/1033#discussion_r233778918,ArtObr
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,Did we try to unskip all the skipped tests? Maybe some of them are already fixed?,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-19 09:55:55,234554064,"@@ -0,0 +1,578 @@
+import json
+import pytest
+from plenum.common.constants import NODE_IP, NODE_PORT, CLIENT_IP, CLIENT_PORT, ALIAS, VALIDATOR, SERVICES
+
+from plenum.common.util import cryptonymToHex, hexToFriendly
+
+from plenum.common.exceptions import RequestNackedException, RequestRejectedException
+
+from plenum.common.types import OPERATION
+
+from plenum.test.helper import sdk_get_and_check_replies, sdk_get_bad_response
+
+from plenum.test.pool_transactions.helper import sdk_add_new_nym, prepare_node_request, \
+    sdk_sign_and_send_prepared_request
+
+
+@pytest.fixture(scope='function')
+def node_request(looper, sdk_node_theta_added):
+    sdk_steward_wallet, node = sdk_node_theta_added
+    node_dest = hexToFriendly(node.nodestack.verhex)
+    wh, did = sdk_steward_wallet
+    node_request = looper.loop.run_until_complete(
+        prepare_node_request(did, node.name, destination=node_dest,
+                             nodeIp=node.nodestack.ha[0],
+                             nodePort=node.nodestack.ha[1],
+                             clientIp=node.clientstack.ha[0],
+                             clientPort=node.clientstack.ha[1]))
+    return json.loads(node_request)
+
+
+def ensurePoolIsOperable(looper, sdk_pool_handle, sdk_wallet_creator):
+    sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_creator)
+
+
+def testSendNodeFailsIfDestIsShortReadableName(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['dest'] = 'TheNewNode'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'b58 decoded value length 8 should be one of [16, 32]')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfDestIsHexKey(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['dest'] = cryptonymToHex(
+        node_request['operation']['dest']).decode()
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'should not contain the following chars')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+@pytest.mark.skip(reason='SOV-1096')
+def testSendNodeHasInvalidSyntaxIfDestIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['dest'] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_and_check_replies(looper, [request_couple])
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'b58 decoded value length 1 should be one of [16, 32]')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+@pytest.mark.skip(reason='SOV-1096')
+def testSendNodeHasInvalidSyntaxIfDestIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['dest']
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_and_check_replies(looper, [request_couple])
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'b58 decoded value length 1 should be one of [16, 32]')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpContainsLeadingSpace(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = ' 122.62.52.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpContainsTrailingSpace(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = '122.62.52.13 '
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpHasWrongFormat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = '122.62.52'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfSomeNodeIpComponentsAreNegative(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = '122.-1.52.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfSomeNodeIpComponentsAreHigherThanUpperBound(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = '122.62.256.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][NODE_IP]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields - node_ip')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsNegative(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = -1
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'network port out of the range 0-65535')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsHigherThanUpperBound(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = 65536
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'network port out of the range 0-65535')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsFloat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = 5555.5
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortHasWrongFormat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = 'ninety'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types ')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][NODE_PORT]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields - node_port')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpContainsLeadingSpace(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = ' 122.62.52.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpContainsTrailingSpace(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = '122.62.52.13 '
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpHasWrongFormat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = '122.62.52'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfSomeClientIpComponentsAreNegative(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = '122.-1.52.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfSomeClientIpComponentsAreHigherThanUpperBound(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = '122.62.256.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][CLIENT_IP]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields - client_ip')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsNegative(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = -1
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'network port out of the range 0-65535')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsHigherThanUpperBound(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = 65536
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'network port out of the range 0-65535')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsFloat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = 5555.5
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortHasWrongFormat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = 'ninety'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][CLIENT_PORT]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields - client_port')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfAliasIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][ALIAS] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'empty string')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfAliasIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][ALIAS]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields ')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfServicesContainsUnknownValue(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][SERVICES] = [VALIDATOR, 'DECIDER']
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'unknown value')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfServicesIsValidatorValue(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][SERVICES] = VALIDATOR  # just string, not array
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfServicesIsEmptyString(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][SERVICES] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeSuccessIfDataContainsUnknownField(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][SERVICES] = []
+    node_request['operation']['data']['extra'] = 42
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestRejectedException,
+                         'not found in authorized map')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfDataIsEmptyJson(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'] = {}
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields ')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+@pytest.mark.skip(reason='INDY-68')",486,2018-11-19 12:12:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234554064,https://github.com/hyperledger/indy-node/pull/1033#discussion_r234554064,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1033,https://github.com/hyperledger/indy-node/pull/1033,I will try to unskip it in next pr,8fcbf6a2b51f8f64a648e6b14d38651ad8808d58,2018-11-19 12:22:42,234598594,"@@ -0,0 +1,578 @@
+import json
+import pytest
+from plenum.common.constants import NODE_IP, NODE_PORT, CLIENT_IP, CLIENT_PORT, ALIAS, VALIDATOR, SERVICES
+
+from plenum.common.util import cryptonymToHex, hexToFriendly
+
+from plenum.common.exceptions import RequestNackedException, RequestRejectedException
+
+from plenum.common.types import OPERATION
+
+from plenum.test.helper import sdk_get_and_check_replies, sdk_get_bad_response
+
+from plenum.test.pool_transactions.helper import sdk_add_new_nym, prepare_node_request, \
+    sdk_sign_and_send_prepared_request
+
+
+@pytest.fixture(scope='function')
+def node_request(looper, sdk_node_theta_added):
+    sdk_steward_wallet, node = sdk_node_theta_added
+    node_dest = hexToFriendly(node.nodestack.verhex)
+    wh, did = sdk_steward_wallet
+    node_request = looper.loop.run_until_complete(
+        prepare_node_request(did, node.name, destination=node_dest,
+                             nodeIp=node.nodestack.ha[0],
+                             nodePort=node.nodestack.ha[1],
+                             clientIp=node.clientstack.ha[0],
+                             clientPort=node.clientstack.ha[1]))
+    return json.loads(node_request)
+
+
+def ensurePoolIsOperable(looper, sdk_pool_handle, sdk_wallet_creator):
+    sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_creator)
+
+
+def testSendNodeFailsIfDestIsShortReadableName(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['dest'] = 'TheNewNode'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'b58 decoded value length 8 should be one of [16, 32]')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfDestIsHexKey(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['dest'] = cryptonymToHex(
+        node_request['operation']['dest']).decode()
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'should not contain the following chars')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+@pytest.mark.skip(reason='SOV-1096')
+def testSendNodeHasInvalidSyntaxIfDestIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['dest'] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_and_check_replies(looper, [request_couple])
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'b58 decoded value length 1 should be one of [16, 32]')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+@pytest.mark.skip(reason='SOV-1096')
+def testSendNodeHasInvalidSyntaxIfDestIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['dest']
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_and_check_replies(looper, [request_couple])
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'b58 decoded value length 1 should be one of [16, 32]')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpContainsLeadingSpace(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = ' 122.62.52.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpContainsTrailingSpace(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = '122.62.52.13 '
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpHasWrongFormat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = '122.62.52'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfSomeNodeIpComponentsAreNegative(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = '122.-1.52.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfSomeNodeIpComponentsAreHigherThanUpperBound(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = '122.62.256.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_IP] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodeIpIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][NODE_IP]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields - node_ip')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsNegative(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = -1
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'network port out of the range 0-65535')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsHigherThanUpperBound(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = 65536
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'network port out of the range 0-65535')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsFloat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = 5555.5
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortHasWrongFormat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = 'ninety'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][NODE_PORT] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types ')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfNodePortIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][NODE_PORT]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields - node_port')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpContainsLeadingSpace(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = ' 122.62.52.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpContainsTrailingSpace(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = '122.62.52.13 '
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpHasWrongFormat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = '122.62.52'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfSomeClientIpComponentsAreNegative(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = '122.-1.52.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfSomeClientIpComponentsAreHigherThanUpperBound(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = '122.62.256.13'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_IP] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'invalid network ip address')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientIpIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][CLIENT_IP]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields - client_ip')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsNegative(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = -1
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'network port out of the range 0-65535')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsHigherThanUpperBound(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = 65536
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'network port out of the range 0-65535')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsFloat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = 5555.5
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortHasWrongFormat(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = 'ninety'
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][CLIENT_PORT] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfClientPortIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][CLIENT_PORT]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields - client_port')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfAliasIsEmpty(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][ALIAS] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'empty string')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfAliasIsMissed(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    del node_request['operation']['data'][ALIAS]
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields ')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfServicesContainsUnknownValue(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][SERVICES] = [VALIDATOR, 'DECIDER']
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'unknown value')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfServicesIsValidatorValue(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][SERVICES] = VALIDATOR  # just string, not array
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfServicesIsEmptyString(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][SERVICES] = ''
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'expected types')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeSuccessIfDataContainsUnknownField(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'][SERVICES] = []
+    node_request['operation']['data']['extra'] = 42
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestRejectedException,
+                         'not found in authorized map')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+def testSendNodeFailsIfDataIsEmptyJson(
+        looper, sdk_pool_handle, nodeSet, sdk_node_theta_added, node_request):
+    node_request['operation']['data'] = {}
+    steward_wallet, node = sdk_node_theta_added
+    request_couple = sdk_sign_and_send_prepared_request(looper, steward_wallet,
+                                                        sdk_pool_handle,
+                                                        json.dumps(node_request))
+    sdk_get_bad_response(looper, [request_couple], RequestNackedException,
+                         'missed fields ')
+    ensurePoolIsOperable(looper, sdk_pool_handle, steward_wallet)
+
+
+@pytest.mark.skip(reason='INDY-68')",486,2018-11-19 12:22:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/234598594,https://github.com/hyperledger/indy-node/pull/1033#discussion_r234598594,ArtObr
https://github.com/hyperledger/indy-node/pull/1032,https://github.com/hyperledger/indy-node/pull/1032,No code from indy-client can be used anymore,d275696db1f15514011a2d7b3ebb3438a613fe94,2018-11-14 08:15:43,233347012,"@@ -0,0 +1,277 @@
+import json
+from contextlib import contextmanager
+
+import base58
+import libnacl.public
+import pytest
+
+from plenum.common.constants import ENC, TXN_ID, TARGET_NYM, \
+    TXN_TYPE, NONCE, STEWARD_STRING
+from plenum.common.exceptions import RequestRejectedException
+from plenum.common.signer_did import DidSigner
+from plenum.common.util import adict, randomString
+from indy_client.client.wallet.attribute import Attribute, LedgerStore",13,2018-11-14 08:17:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233347012,https://github.com/hyperledger/indy-node/pull/1032#discussion_r233347012,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1032,https://github.com/hyperledger/indy-node/pull/1032,"this is intermediate PR
the other code will be deleted with next PRs",d275696db1f15514011a2d7b3ebb3438a613fe94,2018-11-14 08:20:28,233348282,"@@ -0,0 +1,277 @@
+import json
+from contextlib import contextmanager
+
+import base58
+import libnacl.public
+import pytest
+
+from plenum.common.constants import ENC, TXN_ID, TARGET_NYM, \
+    TXN_TYPE, NONCE, STEWARD_STRING
+from plenum.common.exceptions import RequestRejectedException
+from plenum.common.signer_did import DidSigner
+from plenum.common.util import adict, randomString
+from indy_client.client.wallet.attribute import Attribute, LedgerStore",13,2018-11-14 08:20:29,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233348282,https://github.com/hyperledger/indy-node/pull/1032#discussion_r233348282,dsurnin
https://github.com/hyperledger/indy-node/pull/1032,https://github.com/hyperledger/indy-node/pull/1032,ok,d275696db1f15514011a2d7b3ebb3438a613fe94,2018-11-14 08:31:09,233351268,"@@ -0,0 +1,277 @@
+import json
+from contextlib import contextmanager
+
+import base58
+import libnacl.public
+import pytest
+
+from plenum.common.constants import ENC, TXN_ID, TARGET_NYM, \
+    TXN_TYPE, NONCE, STEWARD_STRING
+from plenum.common.exceptions import RequestRejectedException
+from plenum.common.signer_did import DidSigner
+from plenum.common.util import adict, randomString
+from indy_client.client.wallet.attribute import Attribute, LedgerStore",13,2018-11-14 08:31:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233351268,https://github.com/hyperledger/indy-node/pull/1032#discussion_r233351268,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1029,https://github.com/hyperledger/indy-node/pull/1029,Is `{% raw %}` really needed here?,d7db641b38d131b7d9ba09a1f274e7e7ee671081,2018-11-13 16:22:15,233117188,"@@ -5,6 +5,16 @@
     dest: ""{{ ssh_dir }}/ssh_config""
 
 - name: Create inventory file for AWS hosts
+  vars:
+    ssh_private_key: ""{% raw %}{{ inventory_dir }}{% endraw %}/{{ ssh_dir_name }}/key""
+    known_hosts_file: ""{% raw %}{{ inventory_dir }}{% endraw %}/{{ ssh_dir_name }}/known_hosts""",6,2018-11-13 16:52:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233117188,https://github.com/hyperledger/indy-node/pull/1029#discussion_r233117188,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1029,https://github.com/hyperledger/indy-node/pull/1029,"`known_hosts` ansible module is idempotent, so it's not really needed to scan existing known_hosts to avoid double adding keys. Is it done for performance reasons?",d7db641b38d131b7d9ba09a1f274e7e7ee671081,2018-11-13 16:51:14,233130229,"@@ -0,0 +1,36 @@
+---
+- name: Check in-variables
+  assert:
+    that:
+      - lookup('vars', item, default='')
+    msg: ""{{ lookup('vars', item, default='undefined')|string }}""
+  loop:
+    - known_hosts_file
+    - hosts
+
+- name: Ensure '{{ known_hosts_file }}' exists
+  copy:
+    content: """"
+    dest: ""{{ known_hosts_file }}""
+    force: no
+
+- name: Check existent records in '{{ known_hosts_file }}' file",17,2018-11-13 16:52:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233130229,https://github.com/hyperledger/indy-node/pull/1029#discussion_r233130229,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1029,https://github.com/hyperledger/indy-node/pull/1029,"yes, it is just to not to perform any unnecessary scans if the host in known_hosts already",d7db641b38d131b7d9ba09a1f274e7e7ee671081,2018-11-13 17:07:11,233137375,"@@ -0,0 +1,36 @@
+---
+- name: Check in-variables
+  assert:
+    that:
+      - lookup('vars', item, default='')
+    msg: ""{{ lookup('vars', item, default='undefined')|string }}""
+  loop:
+    - known_hosts_file
+    - hosts
+
+- name: Ensure '{{ known_hosts_file }}' exists
+  copy:
+    content: """"
+    dest: ""{{ known_hosts_file }}""
+    force: no
+
+- name: Check existent records in '{{ known_hosts_file }}' file",17,2018-11-13 17:07:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233137375,https://github.com/hyperledger/indy-node/pull/1029#discussion_r233137375,andkononykhin
https://github.com/hyperledger/indy-node/pull/1029,https://github.com/hyperledger/indy-node/pull/1029,"yes, to keep jinja2 expression after rendering. it's an original behavior, no changes",d7db641b38d131b7d9ba09a1f274e7e7ee671081,2018-11-13 17:11:05,233139040,"@@ -5,6 +5,16 @@
     dest: ""{{ ssh_dir }}/ssh_config""
 
 - name: Create inventory file for AWS hosts
+  vars:
+    ssh_private_key: ""{% raw %}{{ inventory_dir }}{% endraw %}/{{ ssh_dir_name }}/key""
+    known_hosts_file: ""{% raw %}{{ inventory_dir }}{% endraw %}/{{ ssh_dir_name }}/known_hosts""",6,2018-11-13 17:11:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/233139040,https://github.com/hyperledger/indy-node/pull/1029#discussion_r233139040,andkononykhin
https://github.com/hyperledger/indy-node/pull/1028,https://github.com/hyperledger/indy-node/pull/1028,Why two separate names? Feels like it could lead to confusion at some point.,278d454f9f1d0a66e62571a535ac4f3ff77d483f,2018-11-12 15:28:31,232701264,"@@ -1,11 +1,13 @@
 ---
-# AWS primary parameters
-aws_ec2_type: t2.micro
+# General
+aws_project_name: PoolAutomation
+aws_project_name_short: PA",,2018-11-13 15:25:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/232701264,https://github.com/hyperledger/indy-node/pull/1028#discussion_r232701264,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1028,https://github.com/hyperledger/indy-node/pull/1028,Looks like a candidate for extraction to common var,278d454f9f1d0a66e62571a535ac4f3ff77d483f,2018-11-12 15:32:37,232702841,"@@ -23,15 +25,19 @@ aws_regions:
   - us-west-1
   - us-west-2
 
-instance_count: 4
-
-pa_aws_prefix: PA
-
-# Derivative parameters
-group_name: ""{{ aws_tag_role }}s""
+#   EC2 instance type
+aws_ec2_type: t2.micro
 
+#   Resource tags and names
+aws_tag_project: ""{{ aws_project_name }}""
 aws_tag_namespace: ""{{ inventory_dir | default('test', true) | basename }}""
+aws_tag_role: default
+aws_add_tags: {} # additional tags
+aws_keyname: ""{{ [aws_project_name_short, aws_tag_namespace, group_name]|join('-')|lower }}""
+aws_sgroup: ""{{ [aws_project_name_short, aws_tag_namespace, group_name]|join('-')|lower }}""",,2018-11-13 15:25:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/232702841,https://github.com/hyperledger/indy-node/pull/1028#discussion_r232702841,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1028,https://github.com/hyperledger/indy-node/pull/1028,"yes,exactly. Fixed",278d454f9f1d0a66e62571a535ac4f3ff77d483f,2018-11-13 08:52:24,232942966,"@@ -23,15 +25,19 @@ aws_regions:
   - us-west-1
   - us-west-2
 
-instance_count: 4
-
-pa_aws_prefix: PA
-
-# Derivative parameters
-group_name: ""{{ aws_tag_role }}s""
+#   EC2 instance type
+aws_ec2_type: t2.micro
 
+#   Resource tags and names
+aws_tag_project: ""{{ aws_project_name }}""
 aws_tag_namespace: ""{{ inventory_dir | default('test', true) | basename }}""
+aws_tag_role: default
+aws_add_tags: {} # additional tags
+aws_keyname: ""{{ [aws_project_name_short, aws_tag_namespace, group_name]|join('-')|lower }}""
+aws_sgroup: ""{{ [aws_project_name_short, aws_tag_namespace, group_name]|join('-')|lower }}""",,2018-11-13 15:25:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/232942966,https://github.com/hyperledger/indy-node/pull/1028#discussion_r232942966,andkononykhin
https://github.com/hyperledger/indy-node/pull/1028,https://github.com/hyperledger/indy-node/pull/1028,Renamed the latter. We need full name and some short form for prefixes.,278d454f9f1d0a66e62571a535ac4f3ff77d483f,2018-11-13 08:53:23,232943359,"@@ -1,11 +1,13 @@
 ---
-# AWS primary parameters
-aws_ec2_type: t2.micro
+# General
+aws_project_name: PoolAutomation
+aws_project_name_short: PA",,2018-11-13 15:25:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/232943359,https://github.com/hyperledger/indy-node/pull/1028#discussion_r232943359,andkononykhin
https://github.com/hyperledger/indy-node/pull/1023,https://github.com/hyperledger/indy-node/pull/1023,"What if AWS is fast enough so state becomes `starting`? In fact I don't think this assert is even needed - as far as I can see contract of launcher is:
- on `launch` return asked number of instances without any guarantees about their state
- after `wait` it's guaranteed that all instances are in some defined state",784f2f20c5908a2226f89335aeffbf7eff0b3402,2018-11-08 13:09:36,231879746,"@@ -93,21 +103,60 @@ def test_find_ubuntu_image(ec2):
     assert 'UNSUPPORTED' not in image.description
 
 
-def test_create_instances(ec2):
+def test_AwsEC2Launcher(ec2):
+    launcher = AwsEC2Launcher()
     params = PARAMS._replace(role='test_create')
-    instances = create_instances(ec2, params, 2)
+    instances = launcher.launch(params, 2, ec2=ec2)
 
     assert len(instances) == 2
+    assert len(launcher._ids) > 0
+
     for instance in instances:
+        instance.reload()
+        assert instance.state['Name'] == 'pending'",,2018-11-09 10:50:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231879746,https://github.com/hyperledger/indy-node/pull/1023#discussion_r231879746,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1023,https://github.com/hyperledger/indy-node/pull/1023,"Accessing implementation details often leads to fragile tests, is it really worth here?",784f2f20c5908a2226f89335aeffbf7eff0b3402,2018-11-08 13:11:05,231880129,"@@ -93,21 +103,60 @@ def test_find_ubuntu_image(ec2):
     assert 'UNSUPPORTED' not in image.description
 
 
-def test_create_instances(ec2):
+def test_AwsEC2Launcher(ec2):
+    launcher = AwsEC2Launcher()
     params = PARAMS._replace(role='test_create')
-    instances = create_instances(ec2, params, 2)
+    instances = launcher.launch(params, 2, ec2=ec2)
 
     assert len(instances) == 2
+    assert len(launcher._ids) > 0",,2018-11-09 10:50:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231880129,https://github.com/hyperledger/indy-node/pull/1023#discussion_r231880129,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1023,https://github.com/hyperledger/indy-node/pull/1023,"I suspect that we'll need separate instances of launcher per region, so it might be more convenient to pass `ec2` to launcher constructor instead of `launch`",784f2f20c5908a2226f89335aeffbf7eff0b3402,2018-11-08 13:12:47,231880649,"@@ -93,21 +103,60 @@ def test_find_ubuntu_image(ec2):
     assert 'UNSUPPORTED' not in image.description
 
 
-def test_create_instances(ec2):
+def test_AwsEC2Launcher(ec2):
+    launcher = AwsEC2Launcher()
     params = PARAMS._replace(role='test_create')
-    instances = create_instances(ec2, params, 2)
+    instances = launcher.launch(params, 2, ec2=ec2)",54,2018-11-09 10:50:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231880649,https://github.com/hyperledger/indy-node/pull/1023#discussion_r231880649,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1023,https://github.com/hyperledger/indy-node/pull/1023,"We already store instances in launcher, can we call `reload` inside `wait` to make API more convenient?",784f2f20c5908a2226f89335aeffbf7eff0b3402,2018-11-08 13:14:58,231881292,"@@ -93,21 +103,60 @@ def test_find_ubuntu_image(ec2):
     assert 'UNSUPPORTED' not in image.description
 
 
-def test_create_instances(ec2):
+def test_AwsEC2Launcher(ec2):
+    launcher = AwsEC2Launcher()
     params = PARAMS._replace(role='test_create')
-    instances = create_instances(ec2, params, 2)
+    instances = launcher.launch(params, 2, ec2=ec2)
 
     assert len(instances) == 2
+    assert len(launcher._ids) > 0
+
     for instance in instances:
+        instance.reload()
+        assert instance.state['Name'] == 'pending'
+
+    launcher.wait()
+    assert len(launcher._ids) == 0
+
+    for instance in instances:
+        instance.reload()",,2018-11-09 10:50:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231881292,https://github.com/hyperledger/indy-node/pull/1023#discussion_r231881292,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1023,https://github.com/hyperledger/indy-node/pull/1023,Agree. Will add an api.,784f2f20c5908a2226f89335aeffbf7eff0b3402,2018-11-08 14:02:29,231897634,"@@ -93,21 +103,60 @@ def test_find_ubuntu_image(ec2):
     assert 'UNSUPPORTED' not in image.description
 
 
-def test_create_instances(ec2):
+def test_AwsEC2Launcher(ec2):
+    launcher = AwsEC2Launcher()
     params = PARAMS._replace(role='test_create')
-    instances = create_instances(ec2, params, 2)
+    instances = launcher.launch(params, 2, ec2=ec2)
 
     assert len(instances) == 2
+    assert len(launcher._ids) > 0",,2018-11-09 10:50:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231897634,https://github.com/hyperledger/indy-node/pull/1023#discussion_r231897634,andkononykhin
https://github.com/hyperledger/indy-node/pull/1023,https://github.com/hyperledger/indy-node/pull/1023,Why do you think so? It would lead to collection of waiters just to serve instance launching across regions. Waiter class can encapsulate that well itself.,784f2f20c5908a2226f89335aeffbf7eff0b3402,2018-11-08 14:03:56,231898101,"@@ -93,21 +103,60 @@ def test_find_ubuntu_image(ec2):
     assert 'UNSUPPORTED' not in image.description
 
 
-def test_create_instances(ec2):
+def test_AwsEC2Launcher(ec2):
+    launcher = AwsEC2Launcher()
     params = PARAMS._replace(role='test_create')
-    instances = create_instances(ec2, params, 2)
+    instances = launcher.launch(params, 2, ec2=ec2)",54,2018-11-09 10:50:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231898101,https://github.com/hyperledger/indy-node/pull/1023#discussion_r231898101,andkononykhin
https://github.com/hyperledger/indy-node/pull/1023,https://github.com/hyperledger/indy-node/pull/1023,Yes. Not actually necessary. Was a kind of debugging,784f2f20c5908a2226f89335aeffbf7eff0b3402,2018-11-08 14:07:32,231899255,"@@ -93,21 +103,60 @@ def test_find_ubuntu_image(ec2):
     assert 'UNSUPPORTED' not in image.description
 
 
-def test_create_instances(ec2):
+def test_AwsEC2Launcher(ec2):
+    launcher = AwsEC2Launcher()
     params = PARAMS._replace(role='test_create')
-    instances = create_instances(ec2, params, 2)
+    instances = launcher.launch(params, 2, ec2=ec2)
 
     assert len(instances) == 2
+    assert len(launcher._ids) > 0
+
     for instance in instances:
+        instance.reload()
+        assert instance.state['Name'] == 'pending'",,2018-11-09 10:50:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231899255,https://github.com/hyperledger/indy-node/pull/1023#discussion_r231899255,andkononykhin
https://github.com/hyperledger/indy-node/pull/1023,https://github.com/hyperledger/indy-node/pull/1023,"Waiter uses boto3 client api, reload is from resource api. And in any case we shouldn't rely on implementation details: here we should be sure that instance state is synced before any checks. Thus I don't think it's a good idea.  ",784f2f20c5908a2226f89335aeffbf7eff0b3402,2018-11-08 14:36:00,231910795,"@@ -93,21 +103,60 @@ def test_find_ubuntu_image(ec2):
     assert 'UNSUPPORTED' not in image.description
 
 
-def test_create_instances(ec2):
+def test_AwsEC2Launcher(ec2):
+    launcher = AwsEC2Launcher()
     params = PARAMS._replace(role='test_create')
-    instances = create_instances(ec2, params, 2)
+    instances = launcher.launch(params, 2, ec2=ec2)
 
     assert len(instances) == 2
+    assert len(launcher._ids) > 0
+
     for instance in instances:
+        instance.reload()
+        assert instance.state['Name'] == 'pending'
+
+    launcher.wait()
+    assert len(launcher._ids) == 0
+
+    for instance in instances:
+        instance.reload()",,2018-11-09 10:50:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231910795,https://github.com/hyperledger/indy-node/pull/1023#discussion_r231910795,andkononykhin
https://github.com/hyperledger/indy-node/pull/1021,https://github.com/hyperledger/indy-node/pull/1021,Please update the documentation,2eb5525cb096d1b12f4f44c22bcd8b6cc45356c1,2018-11-08 13:28:21,231885579,"@@ -0,0 +1,27 @@
+import random
+from indy import ledger
+
+from perf_load.perf_req_gen import RequestGenerator
+
+
+class RGGetTxn(RequestGenerator):
+    _req_types = [""3""]
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        self._ledger = kwargs.get(""ledger"", ""DOMAIN"")",12,2018-11-08 13:28:22,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231885579,https://github.com/hyperledger/indy-node/pull/1021#discussion_r231885579,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,Looks like this is no longer needed,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-06 15:41:05,231173345,"@@ -1,17 +1,11 @@
 ---
 # AWS primary parameters
-aws_type: t2.micro
-aws_image: ami-027583e616ca104df
+aws_ec2_type: t2.micro
+aws_ami_id: ami-027583e616ca104df",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231173345,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231173345,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,Any reason for names starting with underscores?,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-06 15:43:06,231174209,"@@ -96,15 +98,22 @@ def get_tag(inst, name):
 
 
 HostInfo = namedtuple('HostInfo', 'tag_id public_ip user')
+AWSWaiterInfo = namedtuple('AWSWaiterInfo', 'waiter kwargs')
 
 
 def manage_instances(regions, params, count):
-    valid_region_ids = valid_instances(regions, count)
     hosts = []
+    waiters = []
     changed = False
 
+    valid_region_ids = valid_instances(regions, count)
+
     for region in AWS_REGIONS:
+        _terminated = []
+        _launched = []",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231174209,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231174209,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,"`kwargs` is very generic, do we really need this? Having explicit `instance_ids` would be much more readable",d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-06 15:45:09,231175120,"@@ -96,15 +98,22 @@ def get_tag(inst, name):
 
 
 HostInfo = namedtuple('HostInfo', 'tag_id public_ip user')
+AWSWaiterInfo = namedtuple('AWSWaiterInfo', 'waiter kwargs')",13,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231175120,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231175120,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,"AFAIK this is going to add another tag to EC2 instances, so probably this better be named as `aws_tag_prefix` to be consistent with `aws_tag_namespace` and `aws_tag_role`. Also `prefix` looks very general here, probably something like `owner` or `dept` or `purpose` would be better.",d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-06 16:15:30,231188345,"@@ -30,3 +24,12 @@ aws_regions:
   - us-east-2
   - us-west-1
   - us-west-2
+
+instance_count: 4
+
+pa_aws_prefix: PA",27,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231188345,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231188345,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,"In fact now passing the whole dir as inventory still has quirks because after running `pool_create` keys and ssh_config are also treated as host list, giving lots of warnings.",d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-06 16:23:02,231191570,"@@ -0,0 +1,55 @@
+# Helper scripts for Pool Automation Ansible roles
+
+## Quickstart
+
+- `inventory-init.py`: helps to create inventory directory with group variables
+   that override Ansible Roles' defaults. The inventory directory then might be
+   passed either to [Ansible command line tools][2aceed7f] or
+   [molecule][1d2f4724].
+
+  [2aceed7f]: https://docs.ansible.com/ansible/latest/user_guide/command_line_tools.html ""ansible tools""
+  [1d2f4724]: https://molecule.readthedocs.io/en/latest/index.html ""molecule""
+
+## Scripts
+
+### inventory-init.py
+
+Used to create inventory directory with user specified values for group
+variables to use in Ansible roles.
+
+The tool explores default values for each role it found and provides
+command line API to override them.
+
+The tool creates directory with the structure acceptable for Ansible inventory
+directories as declared in [Working With Inventory](https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#splitting-out-host-and-group-specific-data). Also it adds an inventory file for
+`localhost` to make its specification explicit.
+
+```shell
+inventory-dir/
+└── group_vars
+|   └── all
+|       ├── <role-name1>_config.yml
+|       ...
+└── localhost.yml
+```
+
+So it is possible to place your inventory file(s) here (e.g. `inventory-dir/hosts`)
+and pass either the whole directory or an inventory file to [Ansible command line tools][2aceed7f].",37,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231191570,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231191570,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,"Having single config file per group instead of per role might be more manageable, at least now",d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-06 16:28:02,231193886,"@@ -0,0 +1,184 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+import os
+import sys
+from inspect import getsourcefile
+import json
+import glob
+import argparse
+import yaml
+from collections import OrderedDict
+import logging
+import logging.config
+
+logger = logging.getLogger(__name__)
+
+DEF_LOGGING_FORMAT = (""%(asctime)s - %(name)s - %(levelname)s - ""
+                      ""[%(filename)s:%(lineno)d]: %(message)s"")
+DEF_LOGLEVEL = logging.INFO
+
+
+def _init_roles_defaults():
+    proj_dir = os.getenv('ANSIBLE_PROJECT_DIR')
+    if not proj_dir:
+        script_path = os.path.abspath(getsourcefile(lambda: 0))
+        proj_dir = os.path.abspath(os.path.join(os.path.dirname(script_path), '..'))
+    else:
+        proj_dir = os.path.abspath(proj_dir)
+
+    roles = {os.path.basename(r): {'path': r} for r in glob.iglob(""{}/roles/*"".format(proj_dir))}
+
+    if not roles:
+        logger.error(""No roles are found in {}"".format(proj_dir))
+        raise RuntimeError(""No roles are found in {}"".format(proj_dir))
+
+    for role, params in roles.iteritems():
+        _fpath = ""{}/defaults/main.yml"".format(params['path'])
+        try:
+            with open(_fpath, 'r') as _f:
+                roles[role]['defaults'] = yaml.safe_load(_f)
+        except IOError:
+            logger.debug(""Ignoring absense of the file {}"".format(_fpath))
+
+    return roles
+
+
+def _clear_logging():
+    for handler in logging.root.handlers[:]:
+        handler.flush()
+        logging.root.removeHandler(handler)
+        handler.close()
+
+
+def _set_logging(logconfig_path=None):
+    _clear_logging()
+    if logconfig_path:
+        with open(logconfig_path, ""rb"") as f:
+            logging.config.dictConfig(
+                json.load(f, object_pairs_hook=OrderedDict)
+            )
+    else:
+        logging.basicConfig(level=DEF_LOGLEVEL, format=DEF_LOGGING_FORMAT)
+
+
+def _parse_args(roles):
+    parser = argparse.ArgumentParser(
+        description=""Inventory Init Tool"",
+        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
+
+    parser.add_argument('inventory-dir',
+                        help='path to inventory directory')
+
+    for role, params in roles.iteritems():
+        if 'defaults' not in params:
+            continue
+
+        _group = parser.add_argument_group(
+            ""{} vars"".format(role)
+        )
+        for p, d in params['defaults'].iteritems():
+            _help_kwargs = {'metavar': ""{}"".format(type(d).__name__).upper()}
+            # TODO smarter data types related routine:
+            #   - dict: is it acutal case?
+            #   - be generic: shouldn't have any role's specific things
+            if type(d) is list:
+                _help_kwargs['nargs'] = '+'
+                _help_kwargs['metavar'] = 'ITEM'
+            elif type(d) in (int, float):
+                _help_kwargs['type'] = type(d)
+
+            _group.add_argument(""--{}.{}"".format(role, p), **_help_kwargs)
+
+    parser.add_argument(""--logconfig"", metavar=""PATH"", default=None,
+                        help=(""Path to json-formatted logging configuration""
+                              "" file, if not defined the one the basic""
+                              "" one will be used""))
+
+    parser.add_argument(""--show-defaults"", action=""store_true"",
+                        help=""Show defaults and exit"")
+
+    return vars(parser.parse_args())
+
+
+def _dump_defaults(roles):
+    for role, params in roles.iteritems():
+        if 'defaults' in params:
+            print(role.upper())
+            print(yaml.safe_dump(params['defaults'], default_flow_style=False))
+
+
+def _dump_config(config_path, config_vars, default_vars):
+    """"""Dumps user specified config and commented out defaults""""""
+
+    # TODO consider to use Ansible's 'to_nice_yaml' from
+    # ansible.plugins.filter.core.py BUT it's not a public API
+    with open(config_path, ""w"") as _f:
+        _f.write('---\n')
+        if config_vars:
+            yaml.safe_dump(config_vars, _f, default_flow_style=False)
+        _s = yaml.safe_dump(default_vars, default_flow_style=False)
+        _f.write(''.join([""\n# DEFAULTS\n\n""] + [""#{}"".format(_l) for _l in _s.splitlines(True)]))
+
+
+def _specify_localhost(inventory_dir):
+    localhost_spec = {
+        'all': {
+            'hosts': {
+                'localhost': {
+                    'ansible_connection': 'local',
+                    'ansible_python_interpreter': '{{ ansible_playbook_python }}'
+                }
+            }
+        }
+    }
+
+    with open(os.path.join(inventory_dir, 'localhost.yml'), ""w"") as _f:
+        _f.write('---\n')
+        yaml.safe_dump(localhost_spec, _f, default_flow_style=False)
+
+
+def main():
+
+    _set_logging()
+
+    roles = _init_roles_defaults()
+
+    args = _parse_args(roles)
+
+    # output default api settings
+
+    # config logging
+    if args['logconfig'] is not None:
+        _set_logging(args['logconfig'])
+
+    logger.debug(""Cmd line arguments: {}"".format(args))
+
+    if args[""show_defaults""]:
+        _dump_defaults(roles)
+        exit(0)
+
+    # create inventory dir hierarchy
+    group_vars_dir = ""{}/group_vars/all"".format(args['inventory-dir'])
+    if not os.path.isdir(group_vars_dir):
+        os.makedirs(group_vars_dir)
+
+    # dump configs
+    for role, params in roles.iteritems():
+        if 'defaults' not in params:
+            continue
+
+        # construct user specified config parameters
+        config = {}
+        for _p in params['defaults'].keys():
+            _arg_name = ""{}.{}"".format(role, _p)
+            if args.get(_arg_name):
+                config[_p] = args[_arg_name]
+
+        _dump_config(""{}/{}_config.yml"".format(group_vars_dir, role), config, params['defaults'])",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231193886,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231193886,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,"This can be simplified to
```
  - role: aws_manage
    instance_count: 0
```",d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-06 16:30:21,231194993,"@@ -3,4 +3,6 @@
   gather_facts: false
   hosts: localhost
   roles:
-    - { role: aws_manage, tag_namespace: test, tag_role: node, instance_count: 0 }
+    - role: aws_manage
+      vars:
+        instance_count: 0",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231194993,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231194993,skhoroshavin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,Could you explain why?,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 09:52:35,231440439,"@@ -1,17 +1,11 @@
 ---
 # AWS primary parameters
-aws_type: t2.micro
-aws_image: ami-027583e616ca104df
+aws_ec2_type: t2.micro
+aws_ami_id: ami-027583e616ca104df",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231440439,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231440439,andkononykhin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,just to separate them from function's top level ones,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 09:53:28,231440736,"@@ -96,15 +98,22 @@ def get_tag(inst, name):
 
 
 HostInfo = namedtuple('HostInfo', 'tag_id public_ip user')
+AWSWaiterInfo = namedtuple('AWSWaiterInfo', 'waiter kwargs')
 
 
 def manage_instances(regions, params, count):
-    valid_region_ids = valid_instances(regions, count)
     hosts = []
+    waiters = []
     changed = False
 
+    valid_region_ids = valid_instances(regions, count)
+
     for region in AWS_REGIONS:
+        _terminated = []
+        _launched = []",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231440736,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231440736,andkononykhin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,"I think, yes, we do. [EC2.Waiter wait API](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ec2.html#EC2.Waiter.InstanceTerminated.wait) accepts a set of useful arguments (like Filter) that might be utilized in future",d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 10:01:23,231443250,"@@ -96,15 +98,22 @@ def get_tag(inst, name):
 
 
 HostInfo = namedtuple('HostInfo', 'tag_id public_ip user')
+AWSWaiterInfo = namedtuple('AWSWaiterInfo', 'waiter kwargs')",13,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231443250,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231443250,andkononykhin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,"Yes, it is going but not in that PR and it would be likely something like `Project`. It wouldn't be a tag prefix but rather a separate tag itself. Here it is used only for resources where no tags are created (for now) and it's really just a prefix for names.",d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 10:07:39,231445406,"@@ -30,3 +24,12 @@ aws_regions:
   - us-east-2
   - us-west-1
   - us-west-2
+
+instance_count: 4
+
+pa_aws_prefix: PA",27,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231445406,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231445406,andkononykhin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,Fixed,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 10:08:05,231445535,"@@ -0,0 +1,55 @@
+# Helper scripts for Pool Automation Ansible roles
+
+## Quickstart
+
+- `inventory-init.py`: helps to create inventory directory with group variables
+   that override Ansible Roles' defaults. The inventory directory then might be
+   passed either to [Ansible command line tools][2aceed7f] or
+   [molecule][1d2f4724].
+
+  [2aceed7f]: https://docs.ansible.com/ansible/latest/user_guide/command_line_tools.html ""ansible tools""
+  [1d2f4724]: https://molecule.readthedocs.io/en/latest/index.html ""molecule""
+
+## Scripts
+
+### inventory-init.py
+
+Used to create inventory directory with user specified values for group
+variables to use in Ansible roles.
+
+The tool explores default values for each role it found and provides
+command line API to override them.
+
+The tool creates directory with the structure acceptable for Ansible inventory
+directories as declared in [Working With Inventory](https://docs.ansible.com/ansible/latest/user_guide/intro_inventory.html#splitting-out-host-and-group-specific-data). Also it adds an inventory file for
+`localhost` to make its specification explicit.
+
+```shell
+inventory-dir/
+└── group_vars
+|   └── all
+|       ├── <role-name1>_config.yml
+|       ...
+└── localhost.yml
+```
+
+So it is possible to place your inventory file(s) here (e.g. `inventory-dir/hosts`)
+and pass either the whole directory or an inventory file to [Ansible command line tools][2aceed7f].",37,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231445535,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231445535,andkononykhin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,But it would be less readable since defaults will be accumulated for all roles.,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 10:09:02,231445939,"@@ -0,0 +1,184 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+import os
+import sys
+from inspect import getsourcefile
+import json
+import glob
+import argparse
+import yaml
+from collections import OrderedDict
+import logging
+import logging.config
+
+logger = logging.getLogger(__name__)
+
+DEF_LOGGING_FORMAT = (""%(asctime)s - %(name)s - %(levelname)s - ""
+                      ""[%(filename)s:%(lineno)d]: %(message)s"")
+DEF_LOGLEVEL = logging.INFO
+
+
+def _init_roles_defaults():
+    proj_dir = os.getenv('ANSIBLE_PROJECT_DIR')
+    if not proj_dir:
+        script_path = os.path.abspath(getsourcefile(lambda: 0))
+        proj_dir = os.path.abspath(os.path.join(os.path.dirname(script_path), '..'))
+    else:
+        proj_dir = os.path.abspath(proj_dir)
+
+    roles = {os.path.basename(r): {'path': r} for r in glob.iglob(""{}/roles/*"".format(proj_dir))}
+
+    if not roles:
+        logger.error(""No roles are found in {}"".format(proj_dir))
+        raise RuntimeError(""No roles are found in {}"".format(proj_dir))
+
+    for role, params in roles.iteritems():
+        _fpath = ""{}/defaults/main.yml"".format(params['path'])
+        try:
+            with open(_fpath, 'r') as _f:
+                roles[role]['defaults'] = yaml.safe_load(_f)
+        except IOError:
+            logger.debug(""Ignoring absense of the file {}"".format(_fpath))
+
+    return roles
+
+
+def _clear_logging():
+    for handler in logging.root.handlers[:]:
+        handler.flush()
+        logging.root.removeHandler(handler)
+        handler.close()
+
+
+def _set_logging(logconfig_path=None):
+    _clear_logging()
+    if logconfig_path:
+        with open(logconfig_path, ""rb"") as f:
+            logging.config.dictConfig(
+                json.load(f, object_pairs_hook=OrderedDict)
+            )
+    else:
+        logging.basicConfig(level=DEF_LOGLEVEL, format=DEF_LOGGING_FORMAT)
+
+
+def _parse_args(roles):
+    parser = argparse.ArgumentParser(
+        description=""Inventory Init Tool"",
+        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
+
+    parser.add_argument('inventory-dir',
+                        help='path to inventory directory')
+
+    for role, params in roles.iteritems():
+        if 'defaults' not in params:
+            continue
+
+        _group = parser.add_argument_group(
+            ""{} vars"".format(role)
+        )
+        for p, d in params['defaults'].iteritems():
+            _help_kwargs = {'metavar': ""{}"".format(type(d).__name__).upper()}
+            # TODO smarter data types related routine:
+            #   - dict: is it acutal case?
+            #   - be generic: shouldn't have any role's specific things
+            if type(d) is list:
+                _help_kwargs['nargs'] = '+'
+                _help_kwargs['metavar'] = 'ITEM'
+            elif type(d) in (int, float):
+                _help_kwargs['type'] = type(d)
+
+            _group.add_argument(""--{}.{}"".format(role, p), **_help_kwargs)
+
+    parser.add_argument(""--logconfig"", metavar=""PATH"", default=None,
+                        help=(""Path to json-formatted logging configuration""
+                              "" file, if not defined the one the basic""
+                              "" one will be used""))
+
+    parser.add_argument(""--show-defaults"", action=""store_true"",
+                        help=""Show defaults and exit"")
+
+    return vars(parser.parse_args())
+
+
+def _dump_defaults(roles):
+    for role, params in roles.iteritems():
+        if 'defaults' in params:
+            print(role.upper())
+            print(yaml.safe_dump(params['defaults'], default_flow_style=False))
+
+
+def _dump_config(config_path, config_vars, default_vars):
+    """"""Dumps user specified config and commented out defaults""""""
+
+    # TODO consider to use Ansible's 'to_nice_yaml' from
+    # ansible.plugins.filter.core.py BUT it's not a public API
+    with open(config_path, ""w"") as _f:
+        _f.write('---\n')
+        if config_vars:
+            yaml.safe_dump(config_vars, _f, default_flow_style=False)
+        _s = yaml.safe_dump(default_vars, default_flow_style=False)
+        _f.write(''.join([""\n# DEFAULTS\n\n""] + [""#{}"".format(_l) for _l in _s.splitlines(True)]))
+
+
+def _specify_localhost(inventory_dir):
+    localhost_spec = {
+        'all': {
+            'hosts': {
+                'localhost': {
+                    'ansible_connection': 'local',
+                    'ansible_python_interpreter': '{{ ansible_playbook_python }}'
+                }
+            }
+        }
+    }
+
+    with open(os.path.join(inventory_dir, 'localhost.yml'), ""w"") as _f:
+        _f.write('---\n')
+        yaml.safe_dump(localhost_spec, _f, default_flow_style=False)
+
+
+def main():
+
+    _set_logging()
+
+    roles = _init_roles_defaults()
+
+    args = _parse_args(roles)
+
+    # output default api settings
+
+    # config logging
+    if args['logconfig'] is not None:
+        _set_logging(args['logconfig'])
+
+    logger.debug(""Cmd line arguments: {}"".format(args))
+
+    if args[""show_defaults""]:
+        _dump_defaults(roles)
+        exit(0)
+
+    # create inventory dir hierarchy
+    group_vars_dir = ""{}/group_vars/all"".format(args['inventory-dir'])
+    if not os.path.isdir(group_vars_dir):
+        os.makedirs(group_vars_dir)
+
+    # dump configs
+    for role, params in roles.iteritems():
+        if 'defaults' not in params:
+            continue
+
+        # construct user specified config parameters
+        config = {}
+        for _p in params['defaults'].keys():
+            _arg_name = ""{}.{}"".format(role, _p)
+            if args.get(_arg_name):
+                config[_p] = args[_arg_name]
+
+        _dump_config(""{}/{}_config.yml"".format(group_vars_dir, role), config, params['defaults'])",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231445939,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231445939,andkononykhin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,Thanks. Fixed,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 10:09:12,231446016,"@@ -3,4 +3,6 @@
   gather_facts: false
   hosts: localhost
   roles:
-    - { role: aws_manage, tag_namespace: test, tag_role: node, instance_count: 0 }
+    - role: aws_manage
+      vars:
+        instance_count: 0",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231446016,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231446016,andkononykhin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,Fixed,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 16:18:19,231572562,"@@ -96,15 +98,22 @@ def get_tag(inst, name):
 
 
 HostInfo = namedtuple('HostInfo', 'tag_id public_ip user')
+AWSWaiterInfo = namedtuple('AWSWaiterInfo', 'waiter kwargs')
 
 
 def manage_instances(regions, params, count):
-    valid_region_ids = valid_instances(regions, count)
     hosts = []
+    waiters = []
     changed = False
 
+    valid_region_ids = valid_instances(regions, count)
+
     for region in AWS_REGIONS:
+        _terminated = []
+        _launched = []",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231572562,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231572562,andkononykhin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,Done,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 16:18:35,231572654,"@@ -0,0 +1,184 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+import os
+import sys
+from inspect import getsourcefile
+import json
+import glob
+import argparse
+import yaml
+from collections import OrderedDict
+import logging
+import logging.config
+
+logger = logging.getLogger(__name__)
+
+DEF_LOGGING_FORMAT = (""%(asctime)s - %(name)s - %(levelname)s - ""
+                      ""[%(filename)s:%(lineno)d]: %(message)s"")
+DEF_LOGLEVEL = logging.INFO
+
+
+def _init_roles_defaults():
+    proj_dir = os.getenv('ANSIBLE_PROJECT_DIR')
+    if not proj_dir:
+        script_path = os.path.abspath(getsourcefile(lambda: 0))
+        proj_dir = os.path.abspath(os.path.join(os.path.dirname(script_path), '..'))
+    else:
+        proj_dir = os.path.abspath(proj_dir)
+
+    roles = {os.path.basename(r): {'path': r} for r in glob.iglob(""{}/roles/*"".format(proj_dir))}
+
+    if not roles:
+        logger.error(""No roles are found in {}"".format(proj_dir))
+        raise RuntimeError(""No roles are found in {}"".format(proj_dir))
+
+    for role, params in roles.iteritems():
+        _fpath = ""{}/defaults/main.yml"".format(params['path'])
+        try:
+            with open(_fpath, 'r') as _f:
+                roles[role]['defaults'] = yaml.safe_load(_f)
+        except IOError:
+            logger.debug(""Ignoring absense of the file {}"".format(_fpath))
+
+    return roles
+
+
+def _clear_logging():
+    for handler in logging.root.handlers[:]:
+        handler.flush()
+        logging.root.removeHandler(handler)
+        handler.close()
+
+
+def _set_logging(logconfig_path=None):
+    _clear_logging()
+    if logconfig_path:
+        with open(logconfig_path, ""rb"") as f:
+            logging.config.dictConfig(
+                json.load(f, object_pairs_hook=OrderedDict)
+            )
+    else:
+        logging.basicConfig(level=DEF_LOGLEVEL, format=DEF_LOGGING_FORMAT)
+
+
+def _parse_args(roles):
+    parser = argparse.ArgumentParser(
+        description=""Inventory Init Tool"",
+        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
+
+    parser.add_argument('inventory-dir',
+                        help='path to inventory directory')
+
+    for role, params in roles.iteritems():
+        if 'defaults' not in params:
+            continue
+
+        _group = parser.add_argument_group(
+            ""{} vars"".format(role)
+        )
+        for p, d in params['defaults'].iteritems():
+            _help_kwargs = {'metavar': ""{}"".format(type(d).__name__).upper()}
+            # TODO smarter data types related routine:
+            #   - dict: is it acutal case?
+            #   - be generic: shouldn't have any role's specific things
+            if type(d) is list:
+                _help_kwargs['nargs'] = '+'
+                _help_kwargs['metavar'] = 'ITEM'
+            elif type(d) in (int, float):
+                _help_kwargs['type'] = type(d)
+
+            _group.add_argument(""--{}.{}"".format(role, p), **_help_kwargs)
+
+    parser.add_argument(""--logconfig"", metavar=""PATH"", default=None,
+                        help=(""Path to json-formatted logging configuration""
+                              "" file, if not defined the one the basic""
+                              "" one will be used""))
+
+    parser.add_argument(""--show-defaults"", action=""store_true"",
+                        help=""Show defaults and exit"")
+
+    return vars(parser.parse_args())
+
+
+def _dump_defaults(roles):
+    for role, params in roles.iteritems():
+        if 'defaults' in params:
+            print(role.upper())
+            print(yaml.safe_dump(params['defaults'], default_flow_style=False))
+
+
+def _dump_config(config_path, config_vars, default_vars):
+    """"""Dumps user specified config and commented out defaults""""""
+
+    # TODO consider to use Ansible's 'to_nice_yaml' from
+    # ansible.plugins.filter.core.py BUT it's not a public API
+    with open(config_path, ""w"") as _f:
+        _f.write('---\n')
+        if config_vars:
+            yaml.safe_dump(config_vars, _f, default_flow_style=False)
+        _s = yaml.safe_dump(default_vars, default_flow_style=False)
+        _f.write(''.join([""\n# DEFAULTS\n\n""] + [""#{}"".format(_l) for _l in _s.splitlines(True)]))
+
+
+def _specify_localhost(inventory_dir):
+    localhost_spec = {
+        'all': {
+            'hosts': {
+                'localhost': {
+                    'ansible_connection': 'local',
+                    'ansible_python_interpreter': '{{ ansible_playbook_python }}'
+                }
+            }
+        }
+    }
+
+    with open(os.path.join(inventory_dir, 'localhost.yml'), ""w"") as _f:
+        _f.write('---\n')
+        yaml.safe_dump(localhost_spec, _f, default_flow_style=False)
+
+
+def main():
+
+    _set_logging()
+
+    roles = _init_roles_defaults()
+
+    args = _parse_args(roles)
+
+    # output default api settings
+
+    # config logging
+    if args['logconfig'] is not None:
+        _set_logging(args['logconfig'])
+
+    logger.debug(""Cmd line arguments: {}"".format(args))
+
+    if args[""show_defaults""]:
+        _dump_defaults(roles)
+        exit(0)
+
+    # create inventory dir hierarchy
+    group_vars_dir = ""{}/group_vars/all"".format(args['inventory-dir'])
+    if not os.path.isdir(group_vars_dir):
+        os.makedirs(group_vars_dir)
+
+    # dump configs
+    for role, params in roles.iteritems():
+        if 'defaults' not in params:
+            continue
+
+        # construct user specified config parameters
+        config = {}
+        for _p in params['defaults'].keys():
+            _arg_name = ""{}.{}"".format(role, _p)
+            if args.get(_arg_name):
+                config[_p] = args[_arg_name]
+
+        _dump_config(""{}/{}_config.yml"".format(group_vars_dir, role), config, params['defaults'])",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231572654,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231572654,andkononykhin
https://github.com/hyperledger/indy-node/pull/1007,https://github.com/hyperledger/indy-node/pull/1007,`aws_ami_id` has been removed,d7b6d709c5fef1e452317e2db4a5f3f05f9d4e88,2018-11-07 16:19:12,231572916,"@@ -1,17 +1,11 @@
 ---
 # AWS primary parameters
-aws_type: t2.micro
-aws_image: ami-027583e616ca104df
+aws_ec2_type: t2.micro
+aws_ami_id: ami-027583e616ca104df",,2018-11-08 03:36:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/231572916,https://github.com/hyperledger/indy-node/pull/1007#discussion_r231572916,andkononykhin
https://github.com/hyperledger/indy-node/pull/1005,https://github.com/hyperledger/indy-node/pull/1005,"Name ""config"" is too general. Rename it to something like ""pool_cfg_writes"" and RGConfig rename accordingly.",74cb251a9a315674a4602e17daeaddf0155c53c1,2018-10-31 10:33:06,229639029,"@@ -14,7 +15,7 @@ class ReqTypeParser:
          ""revoc_reg_entry"": RGEntryRevoc, ""get_nym"": RGGetNym, ""get_attrib"": RGGetAttrib, ""get_schema"": RGGetSchema,
          ""get_cred_def"": RGGetDefinition, ""get_revoc_reg_def"": RGGetDefRevoc, ""get_revoc_reg"": RGGetEntryRevoc,
          ""get_revoc_reg_delta"": RGGetRevocRegDelta, ""get_payment_sources"": RGGetPaymentSources, ""payment"": RGPayment,
-         ""verify_payment"": RGVerifyPayment}
+         ""verify_payment"": RGVerifyPayment, ""config"": RGConfig}",13,2018-10-31 10:37:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229639029,https://github.com/hyperledger/indy-node/pull/1005#discussion_r229639029,dsurnin
https://github.com/hyperledger/indy-node/pull/1005,https://github.com/hyperledger/indy-node/pull/1005,"this functions generates random data for the req. For config type it is enough to generate just random int like this
def _rand_data(self):
      return str(random.randint(0, 99999999))",74cb251a9a315674a4602e17daeaddf0155c53c1,2018-10-31 10:36:58,229640261,"@@ -0,0 +1,17 @@
+import libnacl
+from indy import ledger
+
+from perf_load.perf_utils import rawToFriendly
+from perf_load.perf_req_gen import RequestGenerator
+
+
+class RGConfig(RequestGenerator):
+    _req_types = [""111""]
+
+    def _rand_data(self):",11,2018-10-31 10:37:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229640261,https://github.com/hyperledger/indy-node/pull/1005#discussion_r229640261,dsurnin
https://github.com/hyperledger/indy-node/pull/1005,https://github.com/hyperledger/indy-node/pull/1005,Fixed.,74cb251a9a315674a4602e17daeaddf0155c53c1,2018-10-31 14:43:13,229723832,"@@ -14,7 +15,7 @@ class ReqTypeParser:
          ""revoc_reg_entry"": RGEntryRevoc, ""get_nym"": RGGetNym, ""get_attrib"": RGGetAttrib, ""get_schema"": RGGetSchema,
          ""get_cred_def"": RGGetDefinition, ""get_revoc_reg_def"": RGGetDefRevoc, ""get_revoc_reg"": RGGetEntryRevoc,
          ""get_revoc_reg_delta"": RGGetRevocRegDelta, ""get_payment_sources"": RGGetPaymentSources, ""payment"": RGPayment,
-         ""verify_payment"": RGVerifyPayment}
+         ""verify_payment"": RGVerifyPayment, ""config"": RGConfig}",13,2018-10-31 14:43:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229723832,https://github.com/hyperledger/indy-node/pull/1005#discussion_r229723832,NataliaDracheva
https://github.com/hyperledger/indy-node/pull/1005,https://github.com/hyperledger/indy-node/pull/1005,Fixed.,74cb251a9a315674a4602e17daeaddf0155c53c1,2018-10-31 14:43:20,229723885,"@@ -0,0 +1,17 @@
+import libnacl
+from indy import ledger
+
+from perf_load.perf_utils import rawToFriendly
+from perf_load.perf_req_gen import RequestGenerator
+
+
+class RGConfig(RequestGenerator):
+    _req_types = [""111""]
+
+    def _rand_data(self):",11,2018-10-31 14:43:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229723885,https://github.com/hyperledger/indy-node/pull/1005#discussion_r229723885,NataliaDracheva
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,Should we call `strip` here?,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-30 14:39:22,229333912,"@@ -12,8 +25,15 @@
 class NodeControlUtil:
     @classmethod
     def run_shell_command(cls, command, timeout):
-        return subprocess.run(command, shell=True, check=True, universal_newlines=True,
-                              stdout=subprocess.PIPE, timeout=timeout)
+        try:
+            ret = subprocess.run(command, shell=True, check=False, stdout=subprocess.PIPE,
+                                 stderr=subprocess.PIPE, timeout=timeout)
+        except Exception as ex:
+            logger.warning(""command {} failed with {}"".format(command, ex))
+            return """"
+        if ret.stdout:
+            return ret.stdout.decode(locale.getpreferredencoding(), 'decode_errors')",,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229333912,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229333912,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,Please add comments why do we need it,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-30 14:39:57,229334190,"@@ -1,9 +1,22 @@
 import subprocess
 import shutil
+import codecs
+import locale
 
 from stp_core.common.log import getlogger
 from indy_common.util import compose_cmd
 
+
+# copied from validator-info from plenum
+def decode_err_handler(error):",15,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229334190,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229334190,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,Did we remove `universal_newlines` and `check` intentionally? ,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-30 14:45:33,229336716,"@@ -12,8 +25,15 @@
 class NodeControlUtil:
     @classmethod
     def run_shell_command(cls, command, timeout):
-        return subprocess.run(command, shell=True, check=True, universal_newlines=True,",31,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229336716,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229336716,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,Do we have unit tests for this method?,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-30 14:47:47,229337618,"@@ -64,34 +79,26 @@ def curr_pkt_info(cls, pkg_name):
         return cls._parse_version_deps_from_pkt_mgr_output(package_info)
 
     @classmethod
-    def _get_info_from_package_manager(cls, package):
-        cmd = compose_cmd(['apt-cache', 'show', package])
-        try:
-            ret = cls.run_shell_command(cmd, TIMEOUT)
-        except Exception as ex:
-            return """"
-        if ret.returncode != 0:
-            return """"
-        return ret.stdout.strip()
+    def _get_info_from_package_manager(cls, *package):
+        cmd_arg = "" "".join(list(package))
+        cmd = compose_cmd(['apt-cache', 'show', cmd_arg])
+        return cls.run_shell_command(cmd, TIMEOUT)
 
     @classmethod
     def update_package_cache(cls):
         cmd = compose_cmd(['apt', 'update'])
-        ret = cls.run_shell_command(cmd, TIMEOUT)
-        if ret.returncode != 0:
-            raise Exception('cannot update package cache since {} returned {}'.format(cmd, ret.returncode))
-        return ret.stdout.strip()
+        return cls.run_shell_command(cmd, TIMEOUT)
 
     @classmethod
-    def get_deps_tree(cls, package, depth=0):
-        ret = [package]
+    def get_deps_tree(cls, *package, depth=0):",136,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229337618,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229337618,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,Do we have unit tests for this method?,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-30 14:48:39,229338003,"@@ -55,7 +70,7 @@ def _parse_deps(deps: str):
             if act_line.startswith(""Version:""):
                 ver = act_line.split("":"", maxsplit=1)[1].strip("" \n"")
             if act_line.startswith(""Depends:""):
-                ext_deps = _parse_deps(act_line.split("":"", maxsplit=1)[1].strip("" \n""))
+                ext_deps += _parse_deps(act_line.split("":"", maxsplit=1)[1].strip("" \n""))",,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229338003,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229338003,ashcherbakov
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,added,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-31 12:46:27,229677815,"@@ -12,8 +25,15 @@
 class NodeControlUtil:
     @classmethod
     def run_shell_command(cls, command, timeout):
-        return subprocess.run(command, shell=True, check=True, universal_newlines=True,
-                              stdout=subprocess.PIPE, timeout=timeout)
+        try:
+            ret = subprocess.run(command, shell=True, check=False, stdout=subprocess.PIPE,
+                                 stderr=subprocess.PIPE, timeout=timeout)
+        except Exception as ex:
+            logger.warning(""command {} failed with {}"".format(command, ex))
+            return """"
+        if ret.stdout:
+            return ret.stdout.decode(locale.getpreferredencoding(), 'decode_errors')",,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229677815,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229677815,dsurnin
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,added,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-31 12:55:31,229680604,"@@ -1,9 +1,22 @@
 import subprocess
 import shutil
+import codecs
+import locale
 
 from stp_core.common.log import getlogger
 from indy_common.util import compose_cmd
 
+
+# copied from validator-info from plenum
+def decode_err_handler(error):",15,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229680604,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229680604,dsurnin
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,It was made to prevent automatic output stream decoding,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-31 12:58:28,229681504,"@@ -12,8 +25,15 @@
 class NodeControlUtil:
     @classmethod
     def run_shell_command(cls, command, timeout):
-        return subprocess.run(command, shell=True, check=True, universal_newlines=True,",31,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229681504,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229681504,dsurnin
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,yes,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-31 12:59:38,229681934,"@@ -64,34 +79,26 @@ def curr_pkt_info(cls, pkg_name):
         return cls._parse_version_deps_from_pkt_mgr_output(package_info)
 
     @classmethod
-    def _get_info_from_package_manager(cls, package):
-        cmd = compose_cmd(['apt-cache', 'show', package])
-        try:
-            ret = cls.run_shell_command(cmd, TIMEOUT)
-        except Exception as ex:
-            return """"
-        if ret.returncode != 0:
-            return """"
-        return ret.stdout.strip()
+    def _get_info_from_package_manager(cls, *package):
+        cmd_arg = "" "".join(list(package))
+        cmd = compose_cmd(['apt-cache', 'show', cmd_arg])
+        return cls.run_shell_command(cmd, TIMEOUT)
 
     @classmethod
     def update_package_cache(cls):
         cmd = compose_cmd(['apt', 'update'])
-        ret = cls.run_shell_command(cmd, TIMEOUT)
-        if ret.returncode != 0:
-            raise Exception('cannot update package cache since {} returned {}'.format(cmd, ret.returncode))
-        return ret.stdout.strip()
+        return cls.run_shell_command(cmd, TIMEOUT)
 
     @classmethod
-    def get_deps_tree(cls, package, depth=0):
-        ret = [package]
+    def get_deps_tree(cls, *package, depth=0):",136,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229681934,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229681934,dsurnin
https://github.com/hyperledger/indy-node/pull/1004,https://github.com/hyperledger/indy-node/pull/1004,added,1bb9ff8ffb97d572cb45fd08ab4f917e747af436,2018-10-31 13:51:00,229700884,"@@ -55,7 +70,7 @@ def _parse_deps(deps: str):
             if act_line.startswith(""Version:""):
                 ver = act_line.split("":"", maxsplit=1)[1].strip("" \n"")
             if act_line.startswith(""Depends:""):
-                ext_deps = _parse_deps(act_line.split("":"", maxsplit=1)[1].strip("" \n""))
+                ext_deps += _parse_deps(act_line.split("":"", maxsplit=1)[1].strip("" \n""))",,2018-11-04 13:40:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/229700884,https://github.com/hyperledger/indy-node/pull/1004#discussion_r229700884,dsurnin
https://github.com/hyperledger/indy-node/pull/995,https://github.com/hyperledger/indy-node/pull/995,Probably this better be moved to common role,d6931c977869954086e279785cc1b75e9f9e5a80,2018-10-23 18:39:04,227516249,"@@ -1,4 +1,12 @@
 ---
+- name: Install HTTPS support for apt",4,2018-10-29 16:43:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227516249,https://github.com/hyperledger/indy-node/pull/995#discussion_r227516249,skhoroshavin
https://github.com/hyperledger/indy-node/pull/995,https://github.com/hyperledger/indy-node/pull/995,Is custom `network_mode` really needed here?,d6931c977869954086e279785cc1b75e9f9e5a80,2018-10-23 19:21:15,227530523,"@@ -0,0 +1,35 @@
+---
+dependency:
+  name: galaxy
+driver:
+  name: docker
+lint:
+  name: yamllint
+  options:
+    config-file: ../common/yamllint
+platforms:
+  - name: instance
+    image: solita/ubuntu-systemd:latest
+    command: /sbin/init
+    capabilities:
+      - SYS_ADMIN
+    volumes:
+      - /sys/fs/cgroup:/sys/fs/cgroup:ro
+    privileged: true
+    network_mode: ${NETWORK_MODE:-bridge}",,2018-10-29 16:43:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227530523,https://github.com/hyperledger/indy-node/pull/995#discussion_r227530523,skhoroshavin
https://github.com/hyperledger/indy-node/pull/995,https://github.com/hyperledger/indy-node/pull/995,"`privileged` is superset of `SYS_ADMIN` capability so one of them could be dropped. Also it seems like `SYS_ADMIN` is enough, so it's better to drop `privileged`: https://molecule.readthedocs.io/en/latest/examples.html#systemd-container",d6931c977869954086e279785cc1b75e9f9e5a80,2018-10-23 19:32:37,227533861,"@@ -0,0 +1,35 @@
+---
+dependency:
+  name: galaxy
+driver:
+  name: docker
+lint:
+  name: yamllint
+  options:
+    config-file: ../common/yamllint
+platforms:
+  - name: instance
+    image: solita/ubuntu-systemd:latest
+    command: /sbin/init
+    capabilities:
+      - SYS_ADMIN
+    volumes:
+      - /sys/fs/cgroup:/sys/fs/cgroup:ro
+    privileged: true",,2018-10-29 16:43:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227533861,https://github.com/hyperledger/indy-node/pull/995#discussion_r227533861,skhoroshavin
https://github.com/hyperledger/indy-node/pull/995,https://github.com/hyperledger/indy-node/pull/995,Given that vagrant is so much slower than docker and cannot be run inside VMs it think that making docker scenario default would be better,d6931c977869954086e279785cc1b75e9f9e5a80,2018-10-23 19:34:20,227534412,"@@ -0,0 +1,35 @@
+---",,2018-10-29 16:43:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227534412,https://github.com/hyperledger/indy-node/pull/995#discussion_r227534412,skhoroshavin
https://github.com/hyperledger/indy-node/pull/995,https://github.com/hyperledger/indy-node/pull/995,Ok,d6931c977869954086e279785cc1b75e9f9e5a80,2018-10-24 09:27:12,227710139,"@@ -1,4 +1,12 @@
 ---
+- name: Install HTTPS support for apt",4,2018-10-29 16:43:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227710139,https://github.com/hyperledger/indy-node/pull/995#discussion_r227710139,andkononykhin
https://github.com/hyperledger/indy-node/pull/995,https://github.com/hyperledger/indy-node/pull/995,"Yes, necessary in some circumstances (at least in my dev environment). Will think about that more.",d6931c977869954086e279785cc1b75e9f9e5a80,2018-10-24 09:28:36,227710684,"@@ -0,0 +1,35 @@
+---
+dependency:
+  name: galaxy
+driver:
+  name: docker
+lint:
+  name: yamllint
+  options:
+    config-file: ../common/yamllint
+platforms:
+  - name: instance
+    image: solita/ubuntu-systemd:latest
+    command: /sbin/init
+    capabilities:
+      - SYS_ADMIN
+    volumes:
+      - /sys/fs/cgroup:/sys/fs/cgroup:ro
+    privileged: true
+    network_mode: ${NETWORK_MODE:-bridge}",,2018-10-29 16:43:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227710684,https://github.com/hyperledger/indy-node/pull/995#discussion_r227710684,andkononykhin
https://github.com/hyperledger/indy-node/pull/995,https://github.com/hyperledger/indy-node/pull/995,ok,d6931c977869954086e279785cc1b75e9f9e5a80,2018-10-24 09:29:10,227711093,"@@ -0,0 +1,35 @@
+---
+dependency:
+  name: galaxy
+driver:
+  name: docker
+lint:
+  name: yamllint
+  options:
+    config-file: ../common/yamllint
+platforms:
+  - name: instance
+    image: solita/ubuntu-systemd:latest
+    command: /sbin/init
+    capabilities:
+      - SYS_ADMIN
+    volumes:
+      - /sys/fs/cgroup:/sys/fs/cgroup:ro
+    privileged: true",,2018-10-29 16:43:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227711093,https://github.com/hyperledger/indy-node/pull/995#discussion_r227711093,andkononykhin
https://github.com/hyperledger/indy-node/pull/995,https://github.com/hyperledger/indy-node/pull/995,"Yes, makes sense",d6931c977869954086e279785cc1b75e9f9e5a80,2018-10-24 09:29:23,227711242,"@@ -0,0 +1,35 @@
+---",,2018-10-29 16:43:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227711242,https://github.com/hyperledger/indy-node/pull/995#discussion_r227711242,andkononykhin
https://github.com/hyperledger/indy-node/pull/987,https://github.com/hyperledger/indy-node/pull/987,Can we extend the test to depend on python3-indy-crypto which depends on libindy-crypto?,44c86c9fbfa8688d1554091ec98212ff982e2351,2018-10-22 15:20:04,227020898,"@@ -53,8 +55,10 @@ def mock_get_info_from_package_manager(package):
     monkeypatch.setattr(NodeControlUtil, 'update_package_cache', lambda *x: None)
     monkeypatch.setattr(NodeControlUtil, '_get_info_from_package_manager',
                         lambda x: mock_get_info_from_package_manager(x))
+    monkeypatch.setattr(NodeControlUtil, 'get_sys_holds',",44,2018-10-24 08:28:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227020898,https://github.com/hyperledger/indy-node/pull/987#discussion_r227020898,ashcherbakov
https://github.com/hyperledger/indy-node/pull/987,https://github.com/hyperledger/indy-node/pull/987,done,44c86c9fbfa8688d1554091ec98212ff982e2351,2018-10-23 07:00:10,227248604,"@@ -53,8 +55,10 @@ def mock_get_info_from_package_manager(package):
     monkeypatch.setattr(NodeControlUtil, 'update_package_cache', lambda *x: None)
     monkeypatch.setattr(NodeControlUtil, '_get_info_from_package_manager',
                         lambda x: mock_get_info_from_package_manager(x))
+    monkeypatch.setattr(NodeControlUtil, 'get_sys_holds',",44,2018-10-24 08:28:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227248604,https://github.com/hyperledger/indy-node/pull/987#discussion_r227248604,dsurnin
https://github.com/hyperledger/indy-node/pull/987,https://github.com/hyperledger/indy-node/pull/987,How are we going to do hold now (new installations for example)? I believe hold is needed to avoid unintended update of dependencies (this was a feature requested).,44c86c9fbfa8688d1554091ec98212ff982e2351,2018-10-23 13:43:40,227396570,"@@ -82,41 +72,31 @@ def __init__(
         # Listen for incoming connections
         self.server.listen(1)
 
-    def _ext_init(self):
-        NodeControlUtil.update_package_cache()
-        self.ext_ver, ext_deps = self._ext_info()
-        self.deps = ext_deps + self.deps
-        holds = set([self.upgrade_entry] + ext_deps + self.packages_to_hold.strip("" "").split("" ""))
-        self.packages_to_hold = ' '.join(list(holds))
-
-    def _ext_info(self, pkg=None):
-        pkg_name = pkg or self.upgrade_entry
-        return NodeControlUtil.curr_pkt_info(pkg_name)
-
-    def _hold_packages(self):",62,2018-10-24 08:28:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227396570,https://github.com/hyperledger/indy-node/pull/987#discussion_r227396570,ashcherbakov
https://github.com/hyperledger/indy-node/pull/987,https://github.com/hyperledger/indy-node/pull/987,hold logic reverted,44c86c9fbfa8688d1554091ec98212ff982e2351,2018-10-24 09:02:28,227700844,"@@ -82,41 +72,31 @@ def __init__(
         # Listen for incoming connections
         self.server.listen(1)
 
-    def _ext_init(self):
-        NodeControlUtil.update_package_cache()
-        self.ext_ver, ext_deps = self._ext_info()
-        self.deps = ext_deps + self.deps
-        holds = set([self.upgrade_entry] + ext_deps + self.packages_to_hold.strip("" "").split("" ""))
-        self.packages_to_hold = ' '.join(list(holds))
-
-    def _ext_info(self, pkg=None):
-        pkg_name = pkg or self.upgrade_entry
-        return NodeControlUtil.curr_pkt_info(pkg_name)
-
-    def _hold_packages(self):",62,2018-10-24 09:02:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/227700844,https://github.com/hyperledger/indy-node/pull/987#discussion_r227700844,dsurnin
https://github.com/hyperledger/indy-node/pull/984,https://github.com/hyperledger/indy-node/pull/984,It's better to use `with` context manager instead of explicit closing,b2853c75bf943c1c671237709d52c906a82f5043,2018-10-17 13:02:08,225917440,"@@ -0,0 +1,270 @@
+import json
+import logging
+import types
+from collections import OrderedDict
+from typing import Any
+
+import sys
+
+import pytest
+from stp_core.common.log import getlogger
+
+from plenum.common.constants import STEWARD_STRING
+from plenum.common.util import randomString
+from plenum.common.messages.node_messages import Commit
+
+from plenum.server.node import Node
+from plenum.test.pool_transactions.helper import sdk_add_new_nym, prepare_nym_request, \
+    sdk_sign_and_send_prepared_request
+from plenum.test.helper import sdk_json_to_request_object
+from pympler import asizeof
+
+max_depth = 10
+
+
+# Self made memory function. We can use it if we want to explore
+# something specific.
+def get_max(obj, seen=None, now_depth=0, path=str()):
+    if now_depth > max_depth:
+        return {}
+    dictionary = {(path, type(obj)): sys.getsizeof(obj)}
+    path += str(type(obj)) + ' ---> '
+    if seen is None:
+        seen = set()
+    obj_id = id(obj)
+    if obj_id in seen:
+        return {}
+    seen.add(obj_id)
+    if isinstance(obj, dict):
+        vpath = path + 'value ---> '
+        for d in [get_max(v, seen, now_depth + 1, vpath) for v in obj.values()]:
+            updater(dictionary, d)
+        kpath = path + 'key ---> '
+        for d in [get_max(k, seen, now_depth + 1, kpath) for k in obj.keys()]:
+            updater(dictionary, d)
+    elif hasattr(obj, '__dict__'):
+        dpath = path + '__dict__ ---> '
+        d = get_max(obj.__dict__, seen, now_depth + 1, dpath)
+        updater(dictionary, d)
+    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):
+        ipath = path + '__iter__ ---> '
+        for d in [get_max(i, seen, now_depth + 1, ipath) for i in obj]:
+            updater(dictionary, d)
+    return dictionary
+
+
+def updater(store_d, new_d):
+    for k in new_d.keys():
+        if k in store_d:
+            store_d[k] += int(new_d[k])
+        else:
+            store_d[k] = new_d[k]
+
+
+def dont_send_commit(self, msg: Any, *rids, signer=None, message_splitter=None):
+    if isinstance(msg, (Commit)):
+        if rids:
+            rids = [rid for rid in rids if rid not in self.nodestack.getRemote(self.ignore_node_name).uid]
+        else:
+            rids = [self.nodestack.getRemote(name).uid for name
+                    in self.nodestack.remotes.keys() if name not in self.ignore_node_name]
+    self.old_send(msg, *rids, signer=signer, message_splitter=message_splitter)
+
+
+def dont_send_commit_to(nodes, ignore_node_name):
+    for node in nodes:
+        if not hasattr(node, 'ignore_node_name'):
+            node.ignore_node_name = []
+        node.ignore_node_name.append(ignore_node_name)
+        node.old_send = types.MethodType(Node.send, node)
+        node.send = types.MethodType(dont_send_commit, node)
+
+
+def reset_sending(nodes):
+    for node in nodes:
+        node.send = types.MethodType(Node.send, node)
+
+
+def sdk_add_new_nym_without_waiting(looper, sdk_pool_handle, creators_wallet,
+                                    alias=None, role=None, seed=None,
+                                    dest=None, verkey=None, skipverkey=False):
+    seed = seed or randomString(32)
+    alias = alias or randomString(5)
+    wh, _ = creators_wallet
+
+    nym_request, new_did = looper.loop.run_until_complete(
+        prepare_nym_request(creators_wallet, seed,
+                            alias, role, dest, verkey, skipverkey))
+    sdk_sign_and_send_prepared_request(looper, creators_wallet,
+                                       sdk_pool_handle, nym_request)
+
+
+# Pytest logger is heavy, so we exclude it
+@pytest.fixture
+def logger():
+    logger = getlogger()
+    old_value = logger.getEffectiveLevel()
+    logger.root.setLevel(logging.CRITICAL)
+    yield logger
+    logger.root.setLevel(old_value)
+
+
+@pytest.mark.skip('Unskip if you need to debug')
+def test_memory_debugging(looper,
+                          nodeSet,
+                          sdk_wallet_trust_anchor,
+                          sdk_pool_handle,
+                          logger):
+    # Settings
+    requests_count = 500
+    file_name = '.memory_data.txt'
+
+    # Sets for emulating commits problems
+    set1 = list(nodeSet)
+    set1.remove(nodeSet[0])
+    set2 = list(nodeSet)
+    set2.remove(nodeSet[1])
+    set3 = list(nodeSet)
+    set3.remove(nodeSet[2])
+    primary = nodeSet[0]
+
+    memory_dicts = OrderedDict()
+
+    memory_dicts['After starting'] = asizeof.asized(primary, detail=15)
+
+    while primary.master_replica.lastPrePrepareSeqNo < requests_count:
+        sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_trust_anchor)
+
+    memory_dicts['After ordering'] = asizeof.asized(primary, detail=15)
+
+    # Emulate commit sending problems
+    dont_send_commit_to(set1, nodeSet[0].name)
+    dont_send_commit_to(set2, nodeSet[1].name)
+    dont_send_commit_to(set3, nodeSet[2].name)
+
+    # Sending requests until nodes generate `unordered_requests_count` 3pc batches
+    while primary.master_replica.lastPrePrepareSeqNo < requests_count * 2:
+        sdk_add_new_nym_without_waiting(looper, sdk_pool_handle, sdk_wallet_trust_anchor)
+
+    memory_dicts['After {} unordered'.format(requests_count)] = asizeof.asized(primary, detail=15)
+
+    # Remove commit problems
+    reset_sending(set1)
+    reset_sending(set2)
+    reset_sending(set3)
+
+    # primary ask for commits
+    for i in range(primary.master_replica.last_ordered_3pc[1], primary.master_replica.lastPrePrepareSeqNo):
+        primary.replicas._replicas.values()[0]._request_commit((0, i))
+    for i in range(primary.replicas._replicas.values()[1].last_ordered_3pc[1],
+                   primary.replicas._replicas.values()[1].lastPrePrepareSeqNo):
+        primary.replicas._replicas.values()[1]._request_commit((0, i))
+    looper.runFor(5)
+
+    memory_dicts['After {} ordered'.format(requests_count)] = asizeof.asized(primary, detail=15)
+
+    # primary clear queues
+    primary.replicas._replicas.values()[0]._gc(primary.replicas._replicas.values()[0].last_ordered_3pc)
+    primary.replicas._replicas.values()[1]._gc(primary.replicas._replicas.values()[1].last_ordered_3pc)
+
+    memory_dicts['After _gc called'] = asizeof.asized(primary, detail=15)
+
+    # Emulate problems again
+    dont_send_commit_to(set1, nodeSet[0].name)
+    dont_send_commit_to(set2, nodeSet[1].name)
+    dont_send_commit_to(set3, nodeSet[2].name)
+
+    while primary.master_replica.lastPrePrepareSeqNo < requests_count * 3:
+        sdk_add_new_nym_without_waiting(looper, sdk_pool_handle, sdk_wallet_trust_anchor)
+
+    memory_dicts['After {} unordered again'.format(requests_count)] = asizeof.asized(primary, detail=15)
+
+    # Remove commit problems
+    reset_sending(set1)
+    reset_sending(set2)
+    reset_sending(set3)
+
+    for i in range(primary.master_replica.last_ordered_3pc[1], primary.master_replica.lastPrePrepareSeqNo):
+        primary.replicas._replicas.values()[0]._request_commit((0, i))
+    for i in range(primary.replicas._replicas.values()[1].last_ordered_3pc[1],
+                   primary.replicas._replicas.values()[1].lastPrePrepareSeqNo):
+        primary.replicas._replicas.values()[1]._request_commit((0, i))
+    looper.runFor(5)
+
+    memory_dicts['After {} ordered again'.format(requests_count)] = asizeof.asized(primary, detail=15)
+
+    primary.replicas._replicas.values()[0]._gc(primary.replicas._replicas.values()[0].last_ordered_3pc)
+    primary.replicas._replicas.values()[1]._gc(primary.replicas._replicas.values()[1].last_ordered_3pc)
+
+    memory_dicts['After _gc called again'] = asizeof.asized(primary, detail=15)
+
+    file = open(file_name, 'w')",201,2018-10-17 13:04:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/225917440,https://github.com/hyperledger/indy-node/pull/984#discussion_r225917440,ashcherbakov
https://github.com/hyperledger/indy-node/pull/984,https://github.com/hyperledger/indy-node/pull/984,Can we put this into a loop to avoid duplication?,b2853c75bf943c1c671237709d52c906a82f5043,2018-10-17 13:02:41,225917635,"@@ -0,0 +1,270 @@
+import json
+import logging
+import types
+from collections import OrderedDict
+from typing import Any
+
+import sys
+
+import pytest
+from stp_core.common.log import getlogger
+
+from plenum.common.constants import STEWARD_STRING
+from plenum.common.util import randomString
+from plenum.common.messages.node_messages import Commit
+
+from plenum.server.node import Node
+from plenum.test.pool_transactions.helper import sdk_add_new_nym, prepare_nym_request, \
+    sdk_sign_and_send_prepared_request
+from plenum.test.helper import sdk_json_to_request_object
+from pympler import asizeof
+
+max_depth = 10
+
+
+# Self made memory function. We can use it if we want to explore
+# something specific.
+def get_max(obj, seen=None, now_depth=0, path=str()):
+    if now_depth > max_depth:
+        return {}
+    dictionary = {(path, type(obj)): sys.getsizeof(obj)}
+    path += str(type(obj)) + ' ---> '
+    if seen is None:
+        seen = set()
+    obj_id = id(obj)
+    if obj_id in seen:
+        return {}
+    seen.add(obj_id)
+    if isinstance(obj, dict):
+        vpath = path + 'value ---> '
+        for d in [get_max(v, seen, now_depth + 1, vpath) for v in obj.values()]:
+            updater(dictionary, d)
+        kpath = path + 'key ---> '
+        for d in [get_max(k, seen, now_depth + 1, kpath) for k in obj.keys()]:
+            updater(dictionary, d)
+    elif hasattr(obj, '__dict__'):
+        dpath = path + '__dict__ ---> '
+        d = get_max(obj.__dict__, seen, now_depth + 1, dpath)
+        updater(dictionary, d)
+    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):
+        ipath = path + '__iter__ ---> '
+        for d in [get_max(i, seen, now_depth + 1, ipath) for i in obj]:
+            updater(dictionary, d)
+    return dictionary
+
+
+def updater(store_d, new_d):
+    for k in new_d.keys():
+        if k in store_d:
+            store_d[k] += int(new_d[k])
+        else:
+            store_d[k] = new_d[k]
+
+
+def dont_send_commit(self, msg: Any, *rids, signer=None, message_splitter=None):
+    if isinstance(msg, (Commit)):
+        if rids:
+            rids = [rid for rid in rids if rid not in self.nodestack.getRemote(self.ignore_node_name).uid]
+        else:
+            rids = [self.nodestack.getRemote(name).uid for name
+                    in self.nodestack.remotes.keys() if name not in self.ignore_node_name]
+    self.old_send(msg, *rids, signer=signer, message_splitter=message_splitter)
+
+
+def dont_send_commit_to(nodes, ignore_node_name):
+    for node in nodes:
+        if not hasattr(node, 'ignore_node_name'):
+            node.ignore_node_name = []
+        node.ignore_node_name.append(ignore_node_name)
+        node.old_send = types.MethodType(Node.send, node)
+        node.send = types.MethodType(dont_send_commit, node)
+
+
+def reset_sending(nodes):
+    for node in nodes:
+        node.send = types.MethodType(Node.send, node)
+
+
+def sdk_add_new_nym_without_waiting(looper, sdk_pool_handle, creators_wallet,
+                                    alias=None, role=None, seed=None,
+                                    dest=None, verkey=None, skipverkey=False):
+    seed = seed or randomString(32)
+    alias = alias or randomString(5)
+    wh, _ = creators_wallet
+
+    nym_request, new_did = looper.loop.run_until_complete(
+        prepare_nym_request(creators_wallet, seed,
+                            alias, role, dest, verkey, skipverkey))
+    sdk_sign_and_send_prepared_request(looper, creators_wallet,
+                                       sdk_pool_handle, nym_request)
+
+
+# Pytest logger is heavy, so we exclude it
+@pytest.fixture
+def logger():
+    logger = getlogger()
+    old_value = logger.getEffectiveLevel()
+    logger.root.setLevel(logging.CRITICAL)
+    yield logger
+    logger.root.setLevel(old_value)
+
+
+@pytest.mark.skip('Unskip if you need to debug')
+def test_memory_debugging(looper,
+                          nodeSet,
+                          sdk_wallet_trust_anchor,
+                          sdk_pool_handle,
+                          logger):
+    # Settings
+    requests_count = 500
+    file_name = '.memory_data.txt'
+
+    # Sets for emulating commits problems
+    set1 = list(nodeSet)
+    set1.remove(nodeSet[0])
+    set2 = list(nodeSet)
+    set2.remove(nodeSet[1])
+    set3 = list(nodeSet)
+    set3.remove(nodeSet[2])
+    primary = nodeSet[0]
+
+    memory_dicts = OrderedDict()
+
+    memory_dicts['After starting'] = asizeof.asized(primary, detail=15)
+
+    while primary.master_replica.lastPrePrepareSeqNo < requests_count:
+        sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_trust_anchor)
+
+    memory_dicts['After ordering'] = asizeof.asized(primary, detail=15)
+
+    # Emulate commit sending problems
+    dont_send_commit_to(set1, nodeSet[0].name)
+    dont_send_commit_to(set2, nodeSet[1].name)
+    dont_send_commit_to(set3, nodeSet[2].name)
+
+    # Sending requests until nodes generate `unordered_requests_count` 3pc batches
+    while primary.master_replica.lastPrePrepareSeqNo < requests_count * 2:
+        sdk_add_new_nym_without_waiting(looper, sdk_pool_handle, sdk_wallet_trust_anchor)
+
+    memory_dicts['After {} unordered'.format(requests_count)] = asizeof.asized(primary, detail=15)
+
+    # Remove commit problems
+    reset_sending(set1)
+    reset_sending(set2)
+    reset_sending(set3)
+
+    # primary ask for commits
+    for i in range(primary.master_replica.last_ordered_3pc[1], primary.master_replica.lastPrePrepareSeqNo):
+        primary.replicas._replicas.values()[0]._request_commit((0, i))
+    for i in range(primary.replicas._replicas.values()[1].last_ordered_3pc[1],
+                   primary.replicas._replicas.values()[1].lastPrePrepareSeqNo):
+        primary.replicas._replicas.values()[1]._request_commit((0, i))
+    looper.runFor(5)
+
+    memory_dicts['After {} ordered'.format(requests_count)] = asizeof.asized(primary, detail=15)
+
+    # primary clear queues
+    primary.replicas._replicas.values()[0]._gc(primary.replicas._replicas.values()[0].last_ordered_3pc)
+    primary.replicas._replicas.values()[1]._gc(primary.replicas._replicas.values()[1].last_ordered_3pc)
+
+    memory_dicts['After _gc called'] = asizeof.asized(primary, detail=15)
+
+    # Emulate problems again",172,2018-10-17 13:04:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/225917635,https://github.com/hyperledger/indy-node/pull/984#discussion_r225917635,ashcherbakov
https://github.com/hyperledger/indy-node/pull/984,https://github.com/hyperledger/indy-node/pull/984,Can we check that we really have expected number of unordered requests here?,b2853c75bf943c1c671237709d52c906a82f5043,2018-10-17 13:04:08,225918221,"@@ -0,0 +1,270 @@
+import json
+import logging
+import types
+from collections import OrderedDict
+from typing import Any
+
+import sys
+
+import pytest
+from stp_core.common.log import getlogger
+
+from plenum.common.constants import STEWARD_STRING
+from plenum.common.util import randomString
+from plenum.common.messages.node_messages import Commit
+
+from plenum.server.node import Node
+from plenum.test.pool_transactions.helper import sdk_add_new_nym, prepare_nym_request, \
+    sdk_sign_and_send_prepared_request
+from plenum.test.helper import sdk_json_to_request_object
+from pympler import asizeof
+
+max_depth = 10
+
+
+# Self made memory function. We can use it if we want to explore
+# something specific.
+def get_max(obj, seen=None, now_depth=0, path=str()):
+    if now_depth > max_depth:
+        return {}
+    dictionary = {(path, type(obj)): sys.getsizeof(obj)}
+    path += str(type(obj)) + ' ---> '
+    if seen is None:
+        seen = set()
+    obj_id = id(obj)
+    if obj_id in seen:
+        return {}
+    seen.add(obj_id)
+    if isinstance(obj, dict):
+        vpath = path + 'value ---> '
+        for d in [get_max(v, seen, now_depth + 1, vpath) for v in obj.values()]:
+            updater(dictionary, d)
+        kpath = path + 'key ---> '
+        for d in [get_max(k, seen, now_depth + 1, kpath) for k in obj.keys()]:
+            updater(dictionary, d)
+    elif hasattr(obj, '__dict__'):
+        dpath = path + '__dict__ ---> '
+        d = get_max(obj.__dict__, seen, now_depth + 1, dpath)
+        updater(dictionary, d)
+    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):
+        ipath = path + '__iter__ ---> '
+        for d in [get_max(i, seen, now_depth + 1, ipath) for i in obj]:
+            updater(dictionary, d)
+    return dictionary
+
+
+def updater(store_d, new_d):
+    for k in new_d.keys():
+        if k in store_d:
+            store_d[k] += int(new_d[k])
+        else:
+            store_d[k] = new_d[k]
+
+
+def dont_send_commit(self, msg: Any, *rids, signer=None, message_splitter=None):
+    if isinstance(msg, (Commit)):
+        if rids:
+            rids = [rid for rid in rids if rid not in self.nodestack.getRemote(self.ignore_node_name).uid]
+        else:
+            rids = [self.nodestack.getRemote(name).uid for name
+                    in self.nodestack.remotes.keys() if name not in self.ignore_node_name]
+    self.old_send(msg, *rids, signer=signer, message_splitter=message_splitter)
+
+
+def dont_send_commit_to(nodes, ignore_node_name):
+    for node in nodes:
+        if not hasattr(node, 'ignore_node_name'):
+            node.ignore_node_name = []
+        node.ignore_node_name.append(ignore_node_name)
+        node.old_send = types.MethodType(Node.send, node)
+        node.send = types.MethodType(dont_send_commit, node)
+
+
+def reset_sending(nodes):
+    for node in nodes:
+        node.send = types.MethodType(Node.send, node)
+
+
+def sdk_add_new_nym_without_waiting(looper, sdk_pool_handle, creators_wallet,
+                                    alias=None, role=None, seed=None,
+                                    dest=None, verkey=None, skipverkey=False):
+    seed = seed or randomString(32)
+    alias = alias or randomString(5)
+    wh, _ = creators_wallet
+
+    nym_request, new_did = looper.loop.run_until_complete(
+        prepare_nym_request(creators_wallet, seed,
+                            alias, role, dest, verkey, skipverkey))
+    sdk_sign_and_send_prepared_request(looper, creators_wallet,
+                                       sdk_pool_handle, nym_request)
+
+
+# Pytest logger is heavy, so we exclude it
+@pytest.fixture
+def logger():
+    logger = getlogger()
+    old_value = logger.getEffectiveLevel()
+    logger.root.setLevel(logging.CRITICAL)
+    yield logger
+    logger.root.setLevel(old_value)
+
+
+@pytest.mark.skip('Unskip if you need to debug')
+def test_memory_debugging(looper,
+                          nodeSet,
+                          sdk_wallet_trust_anchor,
+                          sdk_pool_handle,
+                          logger):
+    # Settings
+    requests_count = 500
+    file_name = '.memory_data.txt'
+
+    # Sets for emulating commits problems
+    set1 = list(nodeSet)
+    set1.remove(nodeSet[0])
+    set2 = list(nodeSet)
+    set2.remove(nodeSet[1])
+    set3 = list(nodeSet)
+    set3.remove(nodeSet[2])
+    primary = nodeSet[0]
+
+    memory_dicts = OrderedDict()
+
+    memory_dicts['After starting'] = asizeof.asized(primary, detail=15)
+
+    while primary.master_replica.lastPrePrepareSeqNo < requests_count:
+        sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_trust_anchor)
+
+    memory_dicts['After ordering'] = asizeof.asized(primary, detail=15)
+
+    # Emulate commit sending problems
+    dont_send_commit_to(set1, nodeSet[0].name)
+    dont_send_commit_to(set2, nodeSet[1].name)
+    dont_send_commit_to(set3, nodeSet[2].name)
+
+    # Sending requests until nodes generate `unordered_requests_count` 3pc batches
+    while primary.master_replica.lastPrePrepareSeqNo < requests_count * 2:
+        sdk_add_new_nym_without_waiting(looper, sdk_pool_handle, sdk_wallet_trust_anchor)",147,2018-10-17 13:04:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/225918221,https://github.com/hyperledger/indy-node/pull/984#discussion_r225918221,ashcherbakov
https://github.com/hyperledger/indy-node/pull/973,https://github.com/hyperledger/indy-node/pull/973,We should probably support `-` as a possible char in version as well,6de7c3d7a99c78893d237d6f7e8d96337ee662a1,2018-10-11 11:34:40,224413074,"@@ -75,22 +76,25 @@ def update_package_cache(cls):
         return ret.stdout.strip()
 
     @classmethod
-    def get_deps_tree(cls, package, include):
-        package_info = cls._get_info_from_package_manager(package)
-        ret = [package]
-        deps = []
-        deps_deps = []
-        for dep in include:
-            if dep in package_info:
-                match = re.search('.*{} \(= ([0-9]+\.[0-9]+\.[0-9]+)\).*'.format(dep), package_info)
-                if match:
-                    dep_version = match.group(1)
-                    dep_package = '{}={}'.format(dep, dep_version)
-                    deps.append(dep_package)
-                    deps_deps.append(cls.get_deps_tree(dep_package, include))
-        ret.append(deps)
-        ret.append(deps_deps)
-        return ret
+    def get_deps_tree(cls, package, include, depth=0):
+        if depth < MAX_DEPS_DEPTH:
+            package_info = cls._get_info_from_package_manager(package)
+            ret = [package]
+            deps = []
+            deps_deps = []
+            for dep in include:
+                if dep in package_info:
+                    match = re.search('.*{} \(= ([0-9]+\.[0-9]+\.[0-9]+[\.\+\~0-9A-Za-z]*)\).*'.format(dep), package_info)",,2018-10-11 11:41:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/224413074,https://github.com/hyperledger/indy-node/pull/973#discussion_r224413074,ashcherbakov
https://github.com/hyperledger/indy-node/pull/970,https://github.com/hyperledger/indy-node/pull/970,I think it need to install a version of RocksDB Plenum really depends on.,6e349ea9b6e1aed542731968c938804e5135b9c9,2018-10-10 15:51:31,224137384,"@@ -0,0 +1,61 @@
+#!/bin/bash
+
+brew update
+
+echo 'Installing libsodium...'
+brew install https://raw.githubusercontent.com/Homebrew/homebrew-core/65effd2b617bade68a8a2c5b39e1c3089cc0e945/Formula/libsodium.rb   
+echo 'Installed libsodium'
+
+echo 'Installing RocksDB...'",,2018-10-11 09:32:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/224137384,https://github.com/hyperledger/indy-node/pull/970#discussion_r224137384,ashcherbakov
https://github.com/hyperledger/indy-node/pull/970,https://github.com/hyperledger/indy-node/pull/970,I think it needs to install a version of libindy Plenum really depends on.,6e349ea9b6e1aed542731968c938804e5135b9c9,2018-10-10 15:52:03,224137617,"@@ -0,0 +1,61 @@
+#!/bin/bash
+
+brew update
+
+echo 'Installing libsodium...'
+brew install https://raw.githubusercontent.com/Homebrew/homebrew-core/65effd2b617bade68a8a2c5b39e1c3089cc0e945/Formula/libsodium.rb   
+echo 'Installed libsodium'
+
+echo 'Installing RocksDB...'
+brew install rocksdb
+echo 'Installing RocksDB...'
+
+echo 'Installing Charm Crypto...'
+xcode-select --install
+brew install gmp
+brew install pbc
+pushd /tmp
+git clone https://github.com/JHUISI/charm.git
+pushd charm
+./configure.sh --enable-darwin
+make
+make install
+make test
+popd
+rm -rf charm
+popd
+echo 'Installed Charm Crypto'
+
+echo 'Installing libindy...'",38,2018-10-11 09:32:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/224137617,https://github.com/hyperledger/indy-node/pull/970#discussion_r224137617,ashcherbakov
https://github.com/hyperledger/indy-node/pull/970,https://github.com/hyperledger/indy-node/pull/970,I think it needs to install a version of libindy-crypto Plenum really depends on.,6e349ea9b6e1aed542731968c938804e5135b9c9,2018-10-10 15:52:14,224137683,"@@ -0,0 +1,61 @@
+#!/bin/bash
+
+brew update
+
+echo 'Installing libsodium...'
+brew install https://raw.githubusercontent.com/Homebrew/homebrew-core/65effd2b617bade68a8a2c5b39e1c3089cc0e945/Formula/libsodium.rb   
+echo 'Installed libsodium'
+
+echo 'Installing RocksDB...'
+brew install rocksdb
+echo 'Installing RocksDB...'
+
+echo 'Installing Charm Crypto...'
+xcode-select --install
+brew install gmp
+brew install pbc
+pushd /tmp
+git clone https://github.com/JHUISI/charm.git
+pushd charm
+./configure.sh --enable-darwin
+make
+make install
+make test
+popd
+rm -rf charm
+popd
+echo 'Installed Charm Crypto'
+
+echo 'Installing libindy...'
+brew install pkg-config
+brew install automake 
+brew install autoconf
+brew install cmake
+brew install openssl
+brew install zeromq
+brew install zmq
+export PKG_CONFIG_ALLOW_CROSS=1
+export CARGO_INCREMENTAL=1
+export RUST_LOG=indy=trace
+export RUST_TEST_THREADS=1
+export OPENSSL_DIR=$(brew --prefix openssl)
+pushd /tmp
+git clone https://github.com/hyperledger/indy-sdk.git
+pushd indy-sdk/libindy
+cargo build --release
+cp target/release/libindy.dylib /usr/local/lib/
+popd
+rm -rf indy-sdk
+popd
+echo 'Installed libindy'
+
+echo 'Installing libcrypto...'",63,2018-10-11 09:32:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/224137683,https://github.com/hyperledger/indy-node/pull/970#discussion_r224137683,ashcherbakov
https://github.com/hyperledger/indy-node/pull/970,https://github.com/hyperledger/indy-node/pull/970,"In plenum code base the pinned version for the python wrapper seems to be 0.4.3 but the stable version which is available in indy-crypto seems to be only 0.4.2
Is 0.4.2 binary compatible with 0.4.3 wrapper? Can we pin the binary in this script to 0.4.2 of indy-crypto?",6e349ea9b6e1aed542731968c938804e5135b9c9,2018-10-11 08:11:54,224353600,"@@ -0,0 +1,61 @@
+#!/bin/bash
+
+brew update
+
+echo 'Installing libsodium...'
+brew install https://raw.githubusercontent.com/Homebrew/homebrew-core/65effd2b617bade68a8a2c5b39e1c3089cc0e945/Formula/libsodium.rb   
+echo 'Installed libsodium'
+
+echo 'Installing RocksDB...'
+brew install rocksdb
+echo 'Installing RocksDB...'
+
+echo 'Installing Charm Crypto...'
+xcode-select --install
+brew install gmp
+brew install pbc
+pushd /tmp
+git clone https://github.com/JHUISI/charm.git
+pushd charm
+./configure.sh --enable-darwin
+make
+make install
+make test
+popd
+rm -rf charm
+popd
+echo 'Installed Charm Crypto'
+
+echo 'Installing libindy...'
+brew install pkg-config
+brew install automake 
+brew install autoconf
+brew install cmake
+brew install openssl
+brew install zeromq
+brew install zmq
+export PKG_CONFIG_ALLOW_CROSS=1
+export CARGO_INCREMENTAL=1
+export RUST_LOG=indy=trace
+export RUST_TEST_THREADS=1
+export OPENSSL_DIR=$(brew --prefix openssl)
+pushd /tmp
+git clone https://github.com/hyperledger/indy-sdk.git
+pushd indy-sdk/libindy
+cargo build --release
+cp target/release/libindy.dylib /usr/local/lib/
+popd
+rm -rf indy-sdk
+popd
+echo 'Installed libindy'
+
+echo 'Installing libcrypto...'",63,2018-10-11 09:32:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/224353600,https://github.com/hyperledger/indy-node/pull/970#discussion_r224353600,faisal00813
https://github.com/hyperledger/indy-node/pull/970,https://github.com/hyperledger/indy-node/pull/970,"The correct version is 0.4.5 now (it's just fixed for stable, and will be fixed for master soon).
Ideally it would be great to get this version from setup.py file in Plenum.",6e349ea9b6e1aed542731968c938804e5135b9c9,2018-10-11 08:18:20,224355483,"@@ -0,0 +1,61 @@
+#!/bin/bash
+
+brew update
+
+echo 'Installing libsodium...'
+brew install https://raw.githubusercontent.com/Homebrew/homebrew-core/65effd2b617bade68a8a2c5b39e1c3089cc0e945/Formula/libsodium.rb   
+echo 'Installed libsodium'
+
+echo 'Installing RocksDB...'
+brew install rocksdb
+echo 'Installing RocksDB...'
+
+echo 'Installing Charm Crypto...'
+xcode-select --install
+brew install gmp
+brew install pbc
+pushd /tmp
+git clone https://github.com/JHUISI/charm.git
+pushd charm
+./configure.sh --enable-darwin
+make
+make install
+make test
+popd
+rm -rf charm
+popd
+echo 'Installed Charm Crypto'
+
+echo 'Installing libindy...'
+brew install pkg-config
+brew install automake 
+brew install autoconf
+brew install cmake
+brew install openssl
+brew install zeromq
+brew install zmq
+export PKG_CONFIG_ALLOW_CROSS=1
+export CARGO_INCREMENTAL=1
+export RUST_LOG=indy=trace
+export RUST_TEST_THREADS=1
+export OPENSSL_DIR=$(brew --prefix openssl)
+pushd /tmp
+git clone https://github.com/hyperledger/indy-sdk.git
+pushd indy-sdk/libindy
+cargo build --release
+cp target/release/libindy.dylib /usr/local/lib/
+popd
+rm -rf indy-sdk
+popd
+echo 'Installed libindy'
+
+echo 'Installing libcrypto...'",63,2018-10-11 09:32:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/224355483,https://github.com/hyperledger/indy-node/pull/970#discussion_r224355483,ashcherbakov
https://github.com/hyperledger/indy-node/pull/962,https://github.com/hyperledger/indy-node/pull/962,Why?,a1ba627144699217903ec320275ff0d7cc515d52,2018-10-04 12:48:05,222653811,"@@ -223,12 +223,13 @@ def process_storage(storage, args):
     if args.output is not None:
         columns = [Timestamp()]
         for m in MetricsName:
-            columns.append(MetricsValue(m, 'sum'))
-            columns.append(MetricsValue(m, 'count'))
-            columns.append(MetricsValue(m, 'min'))
-            columns.append(MetricsValue(m, 'lo'))
-            columns.append(MetricsValue(m, 'avg'))
-            columns.append(MetricsValue(m, 'hi'))
+            if m < 30000:",10,2018-10-04 12:48:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/222653811,https://github.com/hyperledger/indy-node/pull/962#discussion_r222653811,sergey-shilov
https://github.com/hyperledger/indy-node/pull/962,https://github.com/hyperledger/indy-node/pull/962,"But further it would be nice to have something like _temp_seed = 30000_ and condition _if m < temp_seed:_, but merged due to urgency.",a1ba627144699217903ec320275ff0d7cc515d52,2018-10-04 14:14:00,222685995,"@@ -223,12 +223,13 @@ def process_storage(storage, args):
     if args.output is not None:
         columns = [Timestamp()]
         for m in MetricsName:
-            columns.append(MetricsValue(m, 'sum'))
-            columns.append(MetricsValue(m, 'count'))
-            columns.append(MetricsValue(m, 'min'))
-            columns.append(MetricsValue(m, 'lo'))
-            columns.append(MetricsValue(m, 'avg'))
-            columns.append(MetricsValue(m, 'hi'))
+            if m < 30000:",10,2018-10-04 14:14:00,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/222685995,https://github.com/hyperledger/indy-node/pull/962#discussion_r222685995,sergey-shilov
https://github.com/hyperledger/indy-node/pull/960,https://github.com/hyperledger/indy-node/pull/960,Seems like after test simplification this item is obsolete?,32ba5da6e71637b783db6af31f18ed2ced67b421,2018-10-03 14:30:18,222333654,"@@ -40,6 +42,24 @@ def test_pool_restart(
     _comparison_reply(responses, req_obj)
 
 
+def test_restarter_can_initialize_after_pool_restart(txnPoolNodeSet):
+    '''
+    1. Schedule restart after restart_timeout seconds",,2018-10-04 09:11:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/222333654,https://github.com/hyperledger/indy-node/pull/960#discussion_r222333654,skhoroshavin
https://github.com/hyperledger/indy-node/pull/960,https://github.com/hyperledger/indy-node/pull/960,"Sorry, yes. Fixed it.",32ba5da6e71637b783db6af31f18ed2ced67b421,2018-10-03 14:32:51,222334755,"@@ -40,6 +42,24 @@ def test_pool_restart(
     _comparison_reply(responses, req_obj)
 
 
+def test_restarter_can_initialize_after_pool_restart(txnPoolNodeSet):
+    '''
+    1. Schedule restart after restart_timeout seconds",,2018-10-04 09:11:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/222334755,https://github.com/hyperledger/indy-node/pull/960#discussion_r222334755,Toktar
https://github.com/hyperledger/indy-node/pull/960,https://github.com/hyperledger/indy-node/pull/960,Is this import really needed?,32ba5da6e71637b783db6af31f18ed2ced67b421,2018-10-04 09:04:55,222590523,"@@ -7,13 +7,15 @@
 from indy_node.server.restart_log import RestartLog
 
 from indy_common.constants import POOL_RESTART, ACTION, START, CANCEL
+from indy_node.server.restarter import Restarter
 from indy_node.test.pool_restart.helper import _createServer, _stopServer, sdk_send_restart
 from plenum.common.constants import REPLY, TXN_TYPE
 from plenum.common.types import f
 from plenum.test.helper import sdk_gen_request, sdk_sign_and_submit_req_obj, \
     sdk_get_reply, sdk_get_and_check_replies
 from indy_node.test.upgrade.helper import NodeControlToolExecutor as NCT, \
     nodeControlGeneralMonkeypatching
+from stp_core.loop.eventually import eventually",,2018-10-04 09:11:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/222590523,https://github.com/hyperledger/indy-node/pull/960#discussion_r222590523,sergey-shilov
https://github.com/hyperledger/indy-node/pull/960,https://github.com/hyperledger/indy-node/pull/960,No. Fixed it.,32ba5da6e71637b783db6af31f18ed2ced67b421,2018-10-04 09:12:13,222592825,"@@ -7,13 +7,15 @@
 from indy_node.server.restart_log import RestartLog
 
 from indy_common.constants import POOL_RESTART, ACTION, START, CANCEL
+from indy_node.server.restarter import Restarter
 from indy_node.test.pool_restart.helper import _createServer, _stopServer, sdk_send_restart
 from plenum.common.constants import REPLY, TXN_TYPE
 from plenum.common.types import f
 from plenum.test.helper import sdk_gen_request, sdk_sign_and_submit_req_obj, \
     sdk_get_reply, sdk_get_and_check_replies
 from indy_node.test.upgrade.helper import NodeControlToolExecutor as NCT, \
     nodeControlGeneralMonkeypatching
+from stp_core.loop.eventually import eventually",,2018-10-04 09:12:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/222592825,https://github.com/hyperledger/indy-node/pull/960#discussion_r222592825,Toktar
https://github.com/hyperledger/indy-node/pull/956,https://github.com/hyperledger/indy-node/pull/956,Better add separate if clause with break,f8242c2fb4f6920eb5195c3f901f2d8f9de59345,2018-09-28 08:35:02,221178443,"@@ -210,7 +210,7 @@ def process_storage(storage, args):
 
     print(""Profiling info:"")
     for m in MetricsName:
-        if m < MetricsName.NODE_PROD_TIME and \
+        if m > 30000 or m < MetricsName.NODE_PROD_TIME and \",,2018-09-28 08:39:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/221178443,https://github.com/hyperledger/indy-node/pull/956#discussion_r221178443,skhoroshavin
https://github.com/hyperledger/indy-node/pull/938,https://github.com/hyperledger/indy-node/pull/938,why do you need inc index var?,1ba5fbdd1885f4bfa30166b46e19ce7977f404d8,2018-09-10 12:34:42,216303603,"@@ -0,0 +1,67 @@
+#! /usr/bin/env python3
+
+import matplotlib.pyplot as plt
+import datetime
+import pandas
+import argparse
+
+
+parser = argparse.ArgumentParser()
+parser.add_argument('--file', required=False, default=""./spike_log.csv"",
+                    help=""Input CSV file name with logs"", dest=""log_file"")
+
+
+def get_spike_length(values):
+    first_spike_start = values[0][3]
+    for i in range(1, len(values)):
+        if values[i][3] == first_spike_start:
+            return i
+        i += 1",,2018-09-10 15:02:30,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/216303603,https://github.com/hyperledger/indy-node/pull/938#discussion_r216303603,dsurnin
https://github.com/hyperledger/indy-node/pull/938,https://github.com/hyperledger/indy-node/pull/938,"Removed it from code, thank you.",1ba5fbdd1885f4bfa30166b46e19ce7977f404d8,2018-09-10 12:42:07,216305598,"@@ -0,0 +1,67 @@
+#! /usr/bin/env python3
+
+import matplotlib.pyplot as plt
+import datetime
+import pandas
+import argparse
+
+
+parser = argparse.ArgumentParser()
+parser.add_argument('--file', required=False, default=""./spike_log.csv"",
+                    help=""Input CSV file name with logs"", dest=""log_file"")
+
+
+def get_spike_length(values):
+    first_spike_start = values[0][3]
+    for i in range(1, len(values)):
+        if values[i][3] == first_spike_start:
+            return i
+        i += 1",,2018-09-10 15:02:30,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/216305598,https://github.com/hyperledger/indy-node/pull/938#discussion_r216305598,NataliaDracheva
https://github.com/hyperledger/indy-node/pull/937,https://github.com/hyperledger/indy-node/pull/937,"May be re-factor this to avoid code duplication?

```python
cmd_args = ['/usr/local/bin/read_ledger', '--type', 'pool', '--count']
if (getpass.getuser() != 'indy'):
        cmd_args = ['sudo'] + cmd_args
completed = subprocess.run(cmd_args, check=True, stdout=subprocess.PIPE)
```",f3def66f84c6a3e1093e708d83a8a761cd71372f,2018-09-18 14:30:40,218456913,"@@ -80,34 +89,48 @@ def parseTransactions(ledger):
 
 def getLedger():
     try:
-        completed = subprocess.run(
-        ['sudo', '/usr/local/bin/read_ledger', '--type', 'pool', '--count'],
-        check=True,
-        stdout=subprocess.PIPE,
-        )
+        if (getpass.getuser() == 'indy'):
+            completed = subprocess.run(
+            ['/usr/local/bin/read_ledger', '--type', 'pool', '--count'],
+            check=True,
+            stdout=subprocess.PIPE,
+            )
+        else:
+            completed = subprocess.run(
+            ['sudo', '/usr/local/bin/read_ledger', '--type', 'pool', '--count'],
+            check=True,
+            stdout=subprocess.PIPE,
+            )",,2018-09-24 22:37:18,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/218456913,https://github.com/hyperledger/indy-node/pull/937#discussion_r218456913,sergey-shilov
https://github.com/hyperledger/indy-node/pull/937,https://github.com/hyperledger/indy-node/pull/937,"May be re-factor this to avoid code duplication?

```python
cmd_args = ['/usr/local/bin/read_ledger', '--type', 'pool', '--frm', '1', '--to', completed.stdout]
if (getpass.getuser() != 'indy'):
        cmd_args = ['sudo'] + cmd_args
completed = subprocess.run(cmd_args, check=True, stdout=subprocess.PIPE)
```",f3def66f84c6a3e1093e708d83a8a761cd71372f,2018-09-18 14:32:09,218457478,"@@ -80,34 +89,48 @@ def parseTransactions(ledger):
 
 def getLedger():
     try:
-        completed = subprocess.run(
-        ['sudo', '/usr/local/bin/read_ledger', '--type', 'pool', '--count'],
-        check=True,
-        stdout=subprocess.PIPE,
-        )
+        if (getpass.getuser() == 'indy'):
+            completed = subprocess.run(
+            ['/usr/local/bin/read_ledger', '--type', 'pool', '--count'],
+            check=True,
+            stdout=subprocess.PIPE,
+            )
+        else:
+            completed = subprocess.run(
+            ['sudo', '/usr/local/bin/read_ledger', '--type', 'pool', '--count'],
+            check=True,
+            stdout=subprocess.PIPE,
+            )
     except subprocess.CalledProcessError as err:
-        logger.error('ERROR attempting to run read_ledger --count subprocess: {}'.format(err))
+        log.error('ERROR attempting to run read_ledger --count subprocess: {}'.format(err))
         raise
     transCount = completed.stdout.decode('utf-8').strip()
-    logging.info(""{} entries in ledger."".format(transCount))
+    log.info(""{} entries in ledger."".format(transCount))
     try:
-        completed = subprocess.run(
-        ['sudo', '/usr/local/bin/read_ledger', '--type', 'pool', '--frm', '1', '--to', completed.stdout],
-        check=True,
-        stdout=subprocess.PIPE,
-        )
+        if (getpass.getuser() == 'indy'):
+            completed = subprocess.run(
+            ['/usr/local/bin/read_ledger', '--type', 'pool', '--frm', '1', '--to', completed.stdout],
+            check=True,
+            stdout=subprocess.PIPE,
+            )
+        else:
+            completed = subprocess.run(
+            ['sudo', '/usr/local/bin/read_ledger', '--type', 'pool', '--frm', '1', '--to', completed.stdout],
+            check=True,
+            stdout=subprocess.PIPE,
+            )",,2018-09-24 22:37:18,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/218457478,https://github.com/hyperledger/indy-node/pull/937#discussion_r218457478,sergey-shilov
https://github.com/hyperledger/indy-node/pull/935,https://github.com/hyperledger/indy-node/pull/935,I think it is not need to use path.join here since func arg is the folder from config. just expand user is enough.,daa07b40658094a4919680d6484e7a59fcc23953,2018-09-05 07:07:25,215156502,"@@ -1,79 +1,206 @@
 #! /usr/bin/env python3
 
-""""""This script uses another load script (perf_processes.py) running it with different parameters which are
-provided in config_perf_spike_load.yml file""""""
 
-
-from datetime import timedelta, datetime
 import subprocess
 import yaml
 import time
 import os
+import collections
+import matplotlib.pyplot as plt
+import numpy as np
+import argparse
+
+parser = argparse.ArgumentParser(description='This script uses another load script (perf_processes.py) running it '
+                                             'with different parameters which are provided in '
+                                             'config_perf_spike_load.yml file')
+
+parser.add_argument('-g', '--graph', default=False, type=bool, required=False, dest='graph',
+                    help='Build a graph to check if the configured profile is correct')
+
+args = parser.parse_args()
+
+
+def create_output_directory(folder_path):
+    output_folder = """"
+    for folder in folder_path:
+        output_folder = os.path.join(output_folder, folder)",,2018-09-05 10:09:30,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/215156502,https://github.com/hyperledger/indy-node/pull/935#discussion_r215156502,dsurnin
https://github.com/hyperledger/indy-node/pull/935,https://github.com/hyperledger/indy-node/pull/935,"I would suggest to specify some value here, e.g. ""output"", to send all output from console to file by default ",daa07b40658094a4919680d6484e7a59fcc23953,2018-09-05 07:11:01,215157219,"@@ -1,29 +1,42 @@
 # perf_spike_load.py arguments
-perf_spike:
-    read_mode: permanent #permanent = background reading operation with writing spikes, spike = reading and writing spikes with 0 load in between 
-    spike_time_in_seconds: 180
-    rest_time_in_seconds: 180
-    overall_time_in_seconds: 3600 # 1h = 3600 sec, 24h = 86400
-# perf_processes.py will be called with arguments provided below  during perf_spike_load.py execution. You may move arguments between common and _txns sections:
-# e.g. if you want to define different clients number for reading and writing transactions, just copy ""clients"" to read_ and write_txns sections and provide values. 
-# The script takes the most specific arguments (for transactions rather than common) in case of a duplication.
+profile:
+  spike_time_in_seconds: 60
+  rest_time_in_seconds: 20
+  overall_time_in_seconds: 600 # 1h = 3600 sec, 24h = 86400
+
+# perf_processes.py will be called with arguments provided below  during perf_spike_load.py execution. You may move arguments between common and processes sections:
+# e.g. if you want to define different clients number for reading and writing transactions, just copy ""clients"" to any of processes sections and provide values. 
+# The script takes the most specific arguments (for processes rather than common) in case of a duplication.
 common: 
-    clients: 1
-    seed: 000000000000000000000000Trustee1
-    num: 1
-    refresh: 100
-    buff_req: 100
-    sep: ""|""
-    wallet_key: key
-    mode: t
-    pool_config: """"
-    sync_mode: all
-    out: """"
-    genesis: ~/pool_transactions_genesis
-    directory: . 
-read_txns:
+  clients: 1
+  seed: 000000000000000000000000Trustee1
+  num: 1
+  refresh: 60
+  buff_req: 300
+  sep: ""|""
+  wallet_key: key
+  mode: p
+  pool_config: """"
+  sync_mode: all
+  out: """"",,2018-09-05 10:09:30,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/215157219,https://github.com/hyperledger/indy-node/pull/935#discussion_r215157219,dsurnin
https://github.com/hyperledger/indy-node/pull/929,https://github.com/hyperledger/indy-node/pull/929,Please add the script to setup.py ,29f27a72e3808cc900ff415c825fe5388d784eae,2018-09-04 07:18:59,214808841,"@@ -0,0 +1,770 @@
+#!/usr/bin/env python3",1,2018-09-04 13:35:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/214808841,https://github.com/hyperledger/indy-node/pull/929#discussion_r214808841,ashcherbakov
https://github.com/hyperledger/indy-node/pull/929,https://github.com/hyperledger/indy-node/pull/929,Done,29f27a72e3808cc900ff415c825fe5388d784eae,2018-09-04 08:47:00,214833488,"@@ -0,0 +1,770 @@
+#!/usr/bin/env python3",1,2018-09-04 13:35:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/214833488,https://github.com/hyperledger/indy-node/pull/929#discussion_r214833488,sergey-shilov
https://github.com/hyperledger/indy-node/pull/929,https://github.com/hyperledger/indy-node/pull/929,What if KeyError is raised here? ,29f27a72e3808cc900ff415c825fe5388d784eae,2018-09-04 10:55:44,214871152,"@@ -0,0 +1,796 @@
+#!/usr/bin/env python3
+# -*- coding: utf-8 -*-
+
+import importlib
+import argparse
+import datetime
+import json
+import os
+import sys
+import subprocess
+from collections import OrderedDict
+from glob import glob
+import re
+import pwd
+import pathlib
+
+from indy_common.config_util import getConfig
+from indy_common.config_helper import ConfigHelper
+from storage.kv_store_rocksdb_int_keys import KeyValueStorageRocksdbIntKeys
+from stp_core.common.log import Logger
+from stp_core.common.log import getlogger
+
+config = getConfig()
+
+logger = getlogger()  # to make flake8 happy
+clients = {}   # task -> (reader, writer)
+INDY_USER = ""indy""
+
+
+class BaseUnknown:
+    def __init__(self, val):
+        self._val = val
+
+    def _str(self):
+        return str(self._val)
+
+    def __str__(self):
+        return self._str() if not self.is_unknown() else ""unknown""
+
+    def is_unknown(self):
+        return self._val is None
+
+    @property
+    def val(self):
+        return self._val
+
+    @val.setter
+    def val(self, val):
+        self._val = val
+
+
+class NewEncoder(json.JSONEncoder):
+    def default(self, o):
+        if isinstance(o, BaseUnknown):
+            return o.val
+        elif isinstance(o, ConnectionStatsOut):
+            return o.bindings
+        else:
+            return super().default(o)
+
+
+class FloatUnknown(BaseUnknown):
+    def _str(self):
+        return ""{:.2f}"".format(self.val)
+
+
+class TimestampUnknown(BaseUnknown):
+    def _str(self):
+        return ""{} ({})"".format(
+            datetime.datetime.fromtimestamp(self.val).strftime(
+                ""%A, %B %{0}d, %Y %{0}I:%M:%S %p"".format(
+                    '#' if os.name == 'nt' else '-')),
+            self.val
+        )
+
+
+class UptimeUnknown(BaseUnknown):
+    def _str(self):
+        days, remainder = divmod(self.val, 86400)
+        hours, remainder = divmod(remainder, 3600)
+        minutes, seconds = divmod(remainder, 60)
+        parts = []
+
+        for s, v in zip(['day', 'hour', 'minute', 'second'],
+                        [days, hours, minutes, seconds]):
+            if v or len(parts):
+                parts.append(""{} {}{}"".format(v, s, '' if v == 1 else 's'))
+
+        return "", "".join(parts) if parts else '0 seconds'
+
+
+class StateUnknown(BaseUnknown):
+    def __str__(self):
+        return self.val if not self.is_unknown() else 'in unknown state'
+
+
+class NodesListUnknown(BaseUnknown):
+    def __init__(self, val):
+        super().__init__([] if val is None else val)
+
+    def _str(self):
+        return ""\n"".join(""#  {}"".format(alias) for alias in self.val)
+
+    def __iter__(self):
+        return iter(self.val)
+
+
+class BaseStats(OrderedDict):
+    shema = []
+
+    def __init__(self, stats, verbose=False):
+        if stats is None:
+            logger.debug(
+                ""{} no stats found"".format(type(self).__name__))
+
+        for k, cls in self.shema:
+            val = None if stats is None else stats.get(k)
+            try:
+                if issubclass(cls, BaseStats):
+                    self[k] = cls(val, verbose=verbose)
+                else:
+                    self[k] = cls(val)
+            except Exception as e:
+                logger.warning(
+                    ""{} Failed to parse attribute '{}': {}"".format(
+                        type(self).__name__, k, e))
+                self[k] = None
+
+        self._verbose = verbose
+
+
+class ConnectionStatsOut:
+
+    def __init__(self, bindings, verbose):
+        self.bindings = bindings
+        self._verbose = verbose
+
+    def __str__(self):
+        if not self._verbose:
+            data = [""{}"".format(b['port']) for b in self.bindings]
+        else:
+            data = [
+                ""{}{}"".format(
+                    b['port'],
+                    ""/{} on {}"".format(b['protocol'], b['ip'])
+                ) for b in self.bindings
+            ]
+
+        data = list(set(data))
+
+        return "", "".join(data)
+
+
+class BindingStats(BaseUnknown):
+
+    @staticmethod
+    def explore_bindings(port):
+        ANYADDR_IPV4 = '*'
+
+        def shell_cmd(command):
+            res = None
+            try:
+                ret = subprocess.check_output(
+                    command, stderr=subprocess.STDOUT, shell=True)
+            except subprocess.CalledProcessError as e:
+                logger.warning(
+                    ""Shell command '{}' failed, ""
+                    ""return code {}, stderr: {}"".format(
+                        command, e.returncode, e.stderr)
+                )
+            except Exception as e:
+                logger.warning(
+                    ""Failed to process shell command: '{}', ""
+                    ""unexpected error: {}"".format(command, e)
+                )
+            else:
+                logger.debug(""command '{}': stdout '{}'"".format(command, ret))
+                res = ret.decode().strip()
+
+            return res
+
+        if port is None:
+            return None
+
+        # TODO
+        # 1. need to filter more (e.g. by pid) for such cases as:
+        #   - SO_REUSEPORT or SO_REUSEADDR
+        #   - tcp + udp
+        # 2. procss ipv6 as well
+        #
+        # parse listening ip using 'ss' tool
+        command = ""ss -ln4 | sort -u | grep ':{}\s'"".format(port)
+        ret = shell_cmd(command)
+
+        if ret is None:
+            return None
+
+        ips = []
+        ips_with_netmasks = {}
+        for line in ret.split('\n'):
+            try:
+                parts = re.compile(""\s+"").split(line)
+                # format:
+                # Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port
+                protocol, ip = parts[0], parts[4].split("":"")[0]
+            except Exception as e:
+                logger.warning(
+                    ""Failed to parse protocol, ip from '{}', ""
+                    ""error: {}"".format(line, e)
+                )
+            else:
+                if ip == ANYADDR_IPV4:
+                    # TODO mask here seems not necessary,
+                    # but requested in INDY-715
+                    ip = ""0.0.0.0/0""
+                else:
+                    if ip not in ips_with_netmasks:
+                        # parse mask using 'ip' tool
+                        # TODO more filtering by 'ip' tool itself if possible
+                        command = ""ip a | grep 'inet {}'"".format(ip)
+                        ret = shell_cmd(command)
+
+                        try:
+                            ip_with_netmask = re.match(
+                                ""^inet\s([^\s]+)"", ret).group(1)
+                        except Exception as e:
+                            logger.debug(
+                                ""Failed to parse ip with mask: command {}, ""
+                                ""stdout: {}, error {}"".format(command, ret, e))
+                            ip = ""{}/unknown"".format(ip)
+
+                        ips_with_netmasks[ip] = ip_with_netmask
+
+                    ip = ips_with_netmasks[ip]
+
+                ips.append((protocol, ip))
+
+        return list(set(ips))
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+        # change schema: ignoring any data received except port,
+        # resolve it ourselves (requested in original task INDY-715)
+        # TODO refactor
+
+        bindings = self.explore_bindings(self.val)
+        logger.info(
+            ""Found the following bindings ""
+            ""with port {}: {}"".format(self.val, bindings)
+        )
+        self.val = ConnectionStatsOut([] if bindings is None else [
+            dict(port=self.val, protocol=protocol, ip=ip)
+            for protocol, ip in bindings
+        ], False)
+
+
+class TransactionsStats(BaseStats):
+    shema = [
+        (""config"", BaseUnknown),
+        (""ledger"", BaseUnknown),
+        (""pool"", BaseUnknown)
+    ]
+
+
+class AverageStats(BaseStats):
+    shema = [
+        (""read-transactions"", FloatUnknown),
+        (""write-transactions"", FloatUnknown)
+    ]
+
+
+class MetricsStats(BaseStats):
+    shema = [
+        (""uptime"", UptimeUnknown),
+        (""transaction-count"", TransactionsStats),
+        (""average-per-second"", AverageStats)
+    ]
+
+
+class NodeStats(BaseStats):
+    shema = [
+        (""Name"", BaseUnknown),
+        (""did"", BaseUnknown),
+        (""verkey"", BaseUnknown),
+        (""Node_port"", BindingStats),
+        (""Client_port"", BindingStats),
+        (""Metrics"", MetricsStats)
+    ]
+
+
+class PoolStats(BaseStats):
+    shema = [
+        (""Total_nodes_count"", BaseUnknown),
+        (""Reachable_nodes"", NodesListUnknown),
+        (""Reachable_nodes_count"", BaseUnknown),
+        (""Unreachable_nodes"", NodesListUnknown),
+        (""Unreachable_nodes_count"", BaseUnknown)
+    ]
+
+
+class SoftwareStats(BaseStats):
+    shema = [
+        (""indy-node"", BaseUnknown),
+        (""sovrin"", BaseUnknown)
+    ]
+
+    @staticmethod
+    def pkgVersion(pkgName):
+        try:
+            pkg = importlib.import_module(pkgName)
+        except ImportError as e:
+            logger.warning(""Failed to import {}: {}"".format(pkgName, e))
+        else:
+            try:
+                return pkg.__version__
+            except AttributeError as e:
+                logger.warning(
+                    ""Failed to get version of {}: {}"".format(pkgName, e))
+                return None
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+        pkgMappings = {
+            'indy-node': 'indy_node'
+        }
+
+        for pkgName, obj in self.items():
+            if obj is None or obj.is_unknown():
+                self[pkgName] = BaseUnknown(
+                    self.pkgVersion(pkgMappings.get(pkgName, pkgName)))
+
+
+class ValidatorStats(BaseStats):
+    shema = [
+        (""response-version"", BaseUnknown),
+        (""timestamp"", TimestampUnknown),
+        (""Node_info"", NodeStats),
+        (""state"", StateUnknown),
+        (""enabled"", BaseUnknown),
+        (""Pool_info"", PoolStats),
+        (""software"", SoftwareStats)
+    ]
+
+    @staticmethod
+    def get_process_state():
+        ctl = os.getenv('INDY_CONTROL', 'systemctl')
+        if ctl == ""systemctl"":
+           return ValidatorStats.get_process_state_via_systemctl()
+        elif ctl == ""supervisorctl"":
+           return ValidatorStats.get_process_state_via_supervisorctl()
+        else:
+           return ""Invalid value for INDY_CONTROL environment variable: '%s'"" % ctl
+
+    @staticmethod
+    def get_process_state_via_systemctl():
+        ret = subprocess.check_output(
+            'systemctl is-failed indy-node; exit 0',
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret == 'inactive':
+            return 'stopped'
+        elif ret == 'active':
+            return 'running'
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""is-failed state: {}"".format(ret)
+            )
+            return None
+
+    @staticmethod
+    def get_process_state_via_supervisorctl():
+        ret = subprocess.check_output(
+            ""supervisorctl status indy-node | awk '{print $2}'; exit 0"",
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret == 'STOPPED':
+            return 'stopped'
+        elif ret == 'RUNNING':
+            return 'running'
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""status: {}"".format(ret)
+            )
+            return None
+
+    @staticmethod
+    def get_enabled_state():
+        ctl = os.getenv('INDY_CONTROL', 'systemctl')
+        if ctl == ""systemctl"":
+           return ValidatorStats.get_enabled_state_via_systemctl()
+        elif ctl == ""supervisorctl"":
+           return ValidatorStats.get_enabled_state_via_supervisorctl()
+        else:
+           return ""Invalid value for INDY_CONTROL environment variable: '%s'"" % ctl
+
+    @staticmethod
+    def get_enabled_state_via_systemctl():
+        ret = subprocess.check_output(
+            'systemctl is-enabled indy-node; exit 0',
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret in ('enabled', 'static'):
+            return True
+        elif ret == 'disabled':
+            return False
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""is-enabled state: {}"".format(ret)
+            )
+            return None
+
+    @staticmethod
+    def get_enabled_state_via_supervisorctl():
+        ret = subprocess.check_output(
+            ""supervisorctl status indy-node | awk '{print $2}'; exit 0"",
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret in ('RUNNING', 'BACKOFF', 'STARTING'):
+            return True
+        elif ret == 'STOPPED':
+            return False
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""is-enabled state: {}"".format(ret)
+            )
+            return None
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        # TODO move that to classes too
+
+        if self['state'].is_unknown():
+            self['state'] = StateUnknown(self.get_process_state())
+
+        if self['enabled'].is_unknown():
+            self['enabled'] = BaseUnknown(self.get_enabled_state())
+
+    def __str__(self):
+        # TODO moving parts to other classes seems reasonable but
+        # will drop visibility of output
+        lines = [
+            ""Validator {} is {}"".format(self['Node_info']['Name'], self['state']),
+            ""Current time:     {}"".format(self['timestamp']),
+            ""Validator DID:    {}"".format(self['Node_info']['did']),
+            ""Verification Key: {}"".format(self['Node_info']['verkey']),
+            ""Node Port:        {}"".format(self['Node_info']['Node_port']),
+            ""Client Port:      {}"".format(self['Node_info']['Client_port']),
+            ""Metrics:"",
+            ""  Uptime: {}"".format(self['Node_info']['Metrics']['uptime']),
+            ""#  Total Config Transactions:  {}"".format(
+                self['Node_info']['Metrics']['transaction-count']['config']),
+            ""  Total Ledger Transactions:  {}"".format(
+                self['Node_info']['Metrics']['transaction-count']['ledger']),
+            ""  Total Pool Transactions:    {}"".format(
+                self['Node_info']['Metrics']['transaction-count']['pool']),
+            ""  Read Transactions/Seconds:  {}"".format(
+                self['Node_info']['Metrics']['average-per-second']['read-transactions']),
+            ""  Write Transactions/Seconds: {}"".format(
+                self['Node_info']['Metrics']['average-per-second']['write-transactions']),
+            ""Reachable Hosts:   {}/{}"".format(
+                self['Pool_info']['Reachable_nodes_count'],
+                self['Pool_info']['Total_nodes_count'])
+        ] + [
+            ""#  {}"".format(alias)
+            for alias in self['Pool_info']['Reachable_nodes']
+        ] + [
+            ""Unreachable Hosts: {}/{}"".format(
+                self['Pool_info']['Unreachable_nodes_count'],
+                self['Pool_info']['Total_nodes_count']
+            )
+        ] + [
+            ""#  {}"".format(alias)
+            for alias in self['Pool_info']['Unreachable_nodes']
+        ] + [
+            ""#Software Versions:""
+        ] + [
+            ""#  {}: {}"".format(pkgName, self['software'][pkgName])
+            for pkgName in self['software'].keys()
+        ]
+
+        # skip lines with started with '#' if not verbose
+        # or remove '#' otherwise
+        return (""\n"".join(
+            [l[(1 if l[0] == '#' else 0):]
+                for l in lines if self._verbose or l[0] != '#'])
+        )
+
+
+def get_validator_stats(stats, verbose, _json):
+
+    logger.debug(""Data {}"".format(stats))
+    vstats = ValidatorStats(stats, verbose)
+
+    if _json:
+        return json.dumps(vstats, indent=2, cls=NewEncoder)
+
+    return vstats
+
+
+def format_key(key):
+    return ""{:15}"".format('""{}"": '.format(key))
+
+
+def make_indent(indent):
+    return indent * ""{:5}"".format("""")
+
+
+def format_value(value):
+    return "" {:10}"".format(str(value))
+
+
+def create_print_tree(stats: dict, indent=0, lines=[]):
+    for key, value in stats.items():
+        if isinstance(value, dict):
+            lines.append(make_indent(indent) + format_key(key))
+            create_print_tree(value, indent + 1, lines)
+        elif isinstance(value, list):
+            lines.append(make_indent(indent) + format_key(key))
+            for line in value:
+                lines.append(make_indent(indent + 1) + format_value(line))
+        else:
+            if isinstance(value, dict) and not value or \
+                isinstance(value, list) and not value:
+                value = 'n/a'
+            lines.append(make_indent(indent) + format_key(key) + format_value(value))
+    return lines
+
+
+def set_log_owner(log_path):
+    def set_own():
+        try:
+            os.chown(log_path, indy_uid, indy_gid)
+        except PermissionError as e:
+            print(""Cannot set owner of {} file to indy"".format(log_path))
+            print(""The owner of {} must be {}:{}"".format(log_path, INDY_USER, INDY_USER))
+            sys.exit(1)
+
+    indy_ids = pwd.getpwnam(INDY_USER)
+    indy_uid = indy_ids.pw_uid
+    indy_gid = indy_ids.pw_gid
+    if os.path.exists(log_path):
+        f_stat = os.stat(log_path)
+        if f_stat.st_uid != indy_uid or f_stat.st_gid != indy_gid:
+            set_own()
+    else:
+        pathlib.Path(log_path).touch()
+        set_own()
+
+
+def remove_log_handlers():
+    for hndl in logger.root.handlers:
+        logger.root.removeHandler(hndl)
+
+    for hndl in logger.handlers:
+        logger.removeHandler(hndl)
+
+
+def read_json_data(info_path, num: int = 1, from_start = False, _from: int = None, _to: int = None):
+    assert _from <= _to if _from != None and _to != None else True
+
+    db_path, db_name = os.path.split(info_path)
+    db = KeyValueStorageRocksdbIntKeys(db_path, db_name, read_only=True)
+
+    it = db.iterator()
+
+    if _from != None:
+        it.seek_for_prev(db.to_byte_repr(_from))
+    elif _to != None or from_start:
+        it.seek_to_first()
+    else:
+        it.seek_to_last()
+        it = reversed(it)
+
+    json_data = []
+    cnt = 0
+
+    for ts, data in it:
+        try:
+            obj = json.loads(data.decode())
+        except json.JSONDecodeError:
+            print(""DB '{}' contains invalid records"".format(info_path))
+            return None
+
+        obj['timestamp'] = int(ts)
+
+        if _from != None or _to != None:
+            if _from == None or _from <= obj['timestamp']:
+                if _to == None or obj['timestamp'] <= _to:
+                    json_data.append(obj)
+                else:
+                    break
+        else:
+            if from_start:
+                json_data.append(obj)
+            else:
+                json_data.insert(0, obj)
+
+            if num != -1:
+                cnt += 1
+                if cnt == num:
+                    break
+
+    return json_data
+
+
+def compile_json_ouput(file_paths):
+    output_data = {}
+    for file_path in file_paths:
+        json_data = read_json_data(file_path)
+        if json_data:
+            for json_obj in json_data:
+                output_data.update(json_obj)
+    return output_data
+
+
+def get_info_paths(node_names, basedir):
+    postfix = ""_info_db""
+    info_paths = []
+    _info_paths = glob(os.path.join(basedir, ""*{}"".format(postfix)))
+    if node_names:
+        for info_path in _info_paths:
+            match = False
+            for node_name in node_names:
+                name = os.path.basename(info_path[:-len(postfix)])
+                if node_name.lower() == name:
+                    match = True
+                    break
+            if match:
+                info_paths.append(info_path)
+    else:
+        info_paths = _info_paths
+    return info_paths
+
+
+def parse_args():
+    config_helper = ConfigHelper(config)
+
+    parser = argparse.ArgumentParser(
+        description=(
+            ""Tool to explore and gather historycal statistics about running validator""
+        ),
+        formatter_class=argparse.ArgumentDefaultsHelpFormatter
+    )
+
+    parser.add_argument(
+        ""-n"", ""--num"", metavar=""NUM"", type=int,
+        default=1,
+        help=(""Number of records to print (from the end by default), -1 means all records"")
+    )
+
+    parser.add_argument(
+        ""-s"", ""--from_start"", action=""store_true"",
+        help=(""Count records from the start"")
+    )
+
+    parser.add_argument(
+        ""--names"", metavar=""Node1,Node2"",
+        default=None,
+        help=(""Comma-separated list of nodes to print records for."")
+    )
+
+    parser.add_argument(
+        ""--frm"", metavar=""TIMESTAMP"", type=int,
+        default=None,
+        help=(""Print records from timestamp (ignores -n and -s)"")
+    )
+
+    parser.add_argument(
+        ""--to"", metavar=""TIMESTAMP"", type=int,
+        default=None,
+        help=(""Print records to timestamp (ignores -n and -s)"")
+    )
+
+    output_group = parser.add_argument_group(
+        ""output"", ""specify output formatting""
+    )
+
+    output_group.add_argument(
+        ""--fields"", metavar=""Path.To.Field1,Path.To.Fie.ld2"",
+        default=None,
+        help=(""Comma-separated list of JSON nodes to print (ignores -v and --json, case-sensitive)."")
+    )
+
+    output_group.add_argument(
+        ""--json"", action=""store_true"",
+        help=""Format output as JSON (ignores -v)""
+    )
+
+    output_group.add_argument(
+        ""-v"", ""--verbose"", action=""store_true"",
+        help=""Verbose mode (command line)""
+    )
+
+    db_group = parser.add_argument_group(
+        ""database"", ""settings for exploring validator stats from database""
+    )
+
+    db_group.add_argument(
+        ""-d"", ""--basedir"", metavar=""PATH"",
+        default=config_helper.node_info_dir,
+        help=(""Path to databases base directory"")
+    )
+
+    other_group = parser.add_argument_group(
+        ""other"", ""other settings""
+    )
+
+    other_group.add_argument(
+        ""--log"", metavar=""FILE"",
+        default=os.path.join(
+            config_helper.log_base_dir,
+            os.path.basename(sys.argv[0] + "".log"")
+        ),
+        help=""Path to log file"")
+
+    return parser.parse_args()
+
+
+def check_args(args):
+    if args.num <= 0 and args.num != -1:
+        print(""Number of records to print must be greater than 0 or equal to -1"")
+        return False
+
+    return True
+
+
+def main():
+    global logger
+
+    args = parse_args()
+
+    if not check_args(args):
+        return -1
+
+    remove_log_handlers()
+
+    if args.log:
+        set_log_owner(args.log)
+
+    Logger().enableFileLogging(args.log)
+
+    logger.debug(""Cmd line arguments: {}"".format(args))
+
+    node_names = str(args.names).split("","") if args.names else None
+
+    info_paths = get_info_paths(node_names, args.basedir)
+
+    if len(info_paths) == 0:
+        print(""No storages found"")
+        return -1
+
+    fields_paths = None
+    if args.fields:
+        fields_paths = args.fields.split("","")
+
+    for info_path in info_paths:
+        json_data = read_json_data(info_path, args.num, args.from_start, args.frm, args.to)
+        if json_data:
+            print(""===================================================="")
+            print(json_data[0]['Node_info']['Name'])
+            print(""===================================================="")
+            for json_obj in json_data:
+                if fields_paths:
+                    stats = """"
+                    for fields_path in fields_paths:
+                        path = fields_path.split(""."")
+                        _obj = json_obj
+                        for node in path:
+                            _obj = _obj[node]",,2018-09-04 13:35:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/214871152,https://github.com/hyperledger/indy-node/pull/929#discussion_r214871152,ashcherbakov
https://github.com/hyperledger/indy-node/pull/929,https://github.com/hyperledger/indy-node/pull/929,"I think it's ok, it tells user that input path is incorrect. Also stack trace contains invalid key.",29f27a72e3808cc900ff415c825fe5388d784eae,2018-09-04 11:31:19,214879878,"@@ -0,0 +1,796 @@
+#!/usr/bin/env python3
+# -*- coding: utf-8 -*-
+
+import importlib
+import argparse
+import datetime
+import json
+import os
+import sys
+import subprocess
+from collections import OrderedDict
+from glob import glob
+import re
+import pwd
+import pathlib
+
+from indy_common.config_util import getConfig
+from indy_common.config_helper import ConfigHelper
+from storage.kv_store_rocksdb_int_keys import KeyValueStorageRocksdbIntKeys
+from stp_core.common.log import Logger
+from stp_core.common.log import getlogger
+
+config = getConfig()
+
+logger = getlogger()  # to make flake8 happy
+clients = {}   # task -> (reader, writer)
+INDY_USER = ""indy""
+
+
+class BaseUnknown:
+    def __init__(self, val):
+        self._val = val
+
+    def _str(self):
+        return str(self._val)
+
+    def __str__(self):
+        return self._str() if not self.is_unknown() else ""unknown""
+
+    def is_unknown(self):
+        return self._val is None
+
+    @property
+    def val(self):
+        return self._val
+
+    @val.setter
+    def val(self, val):
+        self._val = val
+
+
+class NewEncoder(json.JSONEncoder):
+    def default(self, o):
+        if isinstance(o, BaseUnknown):
+            return o.val
+        elif isinstance(o, ConnectionStatsOut):
+            return o.bindings
+        else:
+            return super().default(o)
+
+
+class FloatUnknown(BaseUnknown):
+    def _str(self):
+        return ""{:.2f}"".format(self.val)
+
+
+class TimestampUnknown(BaseUnknown):
+    def _str(self):
+        return ""{} ({})"".format(
+            datetime.datetime.fromtimestamp(self.val).strftime(
+                ""%A, %B %{0}d, %Y %{0}I:%M:%S %p"".format(
+                    '#' if os.name == 'nt' else '-')),
+            self.val
+        )
+
+
+class UptimeUnknown(BaseUnknown):
+    def _str(self):
+        days, remainder = divmod(self.val, 86400)
+        hours, remainder = divmod(remainder, 3600)
+        minutes, seconds = divmod(remainder, 60)
+        parts = []
+
+        for s, v in zip(['day', 'hour', 'minute', 'second'],
+                        [days, hours, minutes, seconds]):
+            if v or len(parts):
+                parts.append(""{} {}{}"".format(v, s, '' if v == 1 else 's'))
+
+        return "", "".join(parts) if parts else '0 seconds'
+
+
+class StateUnknown(BaseUnknown):
+    def __str__(self):
+        return self.val if not self.is_unknown() else 'in unknown state'
+
+
+class NodesListUnknown(BaseUnknown):
+    def __init__(self, val):
+        super().__init__([] if val is None else val)
+
+    def _str(self):
+        return ""\n"".join(""#  {}"".format(alias) for alias in self.val)
+
+    def __iter__(self):
+        return iter(self.val)
+
+
+class BaseStats(OrderedDict):
+    shema = []
+
+    def __init__(self, stats, verbose=False):
+        if stats is None:
+            logger.debug(
+                ""{} no stats found"".format(type(self).__name__))
+
+        for k, cls in self.shema:
+            val = None if stats is None else stats.get(k)
+            try:
+                if issubclass(cls, BaseStats):
+                    self[k] = cls(val, verbose=verbose)
+                else:
+                    self[k] = cls(val)
+            except Exception as e:
+                logger.warning(
+                    ""{} Failed to parse attribute '{}': {}"".format(
+                        type(self).__name__, k, e))
+                self[k] = None
+
+        self._verbose = verbose
+
+
+class ConnectionStatsOut:
+
+    def __init__(self, bindings, verbose):
+        self.bindings = bindings
+        self._verbose = verbose
+
+    def __str__(self):
+        if not self._verbose:
+            data = [""{}"".format(b['port']) for b in self.bindings]
+        else:
+            data = [
+                ""{}{}"".format(
+                    b['port'],
+                    ""/{} on {}"".format(b['protocol'], b['ip'])
+                ) for b in self.bindings
+            ]
+
+        data = list(set(data))
+
+        return "", "".join(data)
+
+
+class BindingStats(BaseUnknown):
+
+    @staticmethod
+    def explore_bindings(port):
+        ANYADDR_IPV4 = '*'
+
+        def shell_cmd(command):
+            res = None
+            try:
+                ret = subprocess.check_output(
+                    command, stderr=subprocess.STDOUT, shell=True)
+            except subprocess.CalledProcessError as e:
+                logger.warning(
+                    ""Shell command '{}' failed, ""
+                    ""return code {}, stderr: {}"".format(
+                        command, e.returncode, e.stderr)
+                )
+            except Exception as e:
+                logger.warning(
+                    ""Failed to process shell command: '{}', ""
+                    ""unexpected error: {}"".format(command, e)
+                )
+            else:
+                logger.debug(""command '{}': stdout '{}'"".format(command, ret))
+                res = ret.decode().strip()
+
+            return res
+
+        if port is None:
+            return None
+
+        # TODO
+        # 1. need to filter more (e.g. by pid) for such cases as:
+        #   - SO_REUSEPORT or SO_REUSEADDR
+        #   - tcp + udp
+        # 2. procss ipv6 as well
+        #
+        # parse listening ip using 'ss' tool
+        command = ""ss -ln4 | sort -u | grep ':{}\s'"".format(port)
+        ret = shell_cmd(command)
+
+        if ret is None:
+            return None
+
+        ips = []
+        ips_with_netmasks = {}
+        for line in ret.split('\n'):
+            try:
+                parts = re.compile(""\s+"").split(line)
+                # format:
+                # Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port
+                protocol, ip = parts[0], parts[4].split("":"")[0]
+            except Exception as e:
+                logger.warning(
+                    ""Failed to parse protocol, ip from '{}', ""
+                    ""error: {}"".format(line, e)
+                )
+            else:
+                if ip == ANYADDR_IPV4:
+                    # TODO mask here seems not necessary,
+                    # but requested in INDY-715
+                    ip = ""0.0.0.0/0""
+                else:
+                    if ip not in ips_with_netmasks:
+                        # parse mask using 'ip' tool
+                        # TODO more filtering by 'ip' tool itself if possible
+                        command = ""ip a | grep 'inet {}'"".format(ip)
+                        ret = shell_cmd(command)
+
+                        try:
+                            ip_with_netmask = re.match(
+                                ""^inet\s([^\s]+)"", ret).group(1)
+                        except Exception as e:
+                            logger.debug(
+                                ""Failed to parse ip with mask: command {}, ""
+                                ""stdout: {}, error {}"".format(command, ret, e))
+                            ip = ""{}/unknown"".format(ip)
+
+                        ips_with_netmasks[ip] = ip_with_netmask
+
+                    ip = ips_with_netmasks[ip]
+
+                ips.append((protocol, ip))
+
+        return list(set(ips))
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+        # change schema: ignoring any data received except port,
+        # resolve it ourselves (requested in original task INDY-715)
+        # TODO refactor
+
+        bindings = self.explore_bindings(self.val)
+        logger.info(
+            ""Found the following bindings ""
+            ""with port {}: {}"".format(self.val, bindings)
+        )
+        self.val = ConnectionStatsOut([] if bindings is None else [
+            dict(port=self.val, protocol=protocol, ip=ip)
+            for protocol, ip in bindings
+        ], False)
+
+
+class TransactionsStats(BaseStats):
+    shema = [
+        (""config"", BaseUnknown),
+        (""ledger"", BaseUnknown),
+        (""pool"", BaseUnknown)
+    ]
+
+
+class AverageStats(BaseStats):
+    shema = [
+        (""read-transactions"", FloatUnknown),
+        (""write-transactions"", FloatUnknown)
+    ]
+
+
+class MetricsStats(BaseStats):
+    shema = [
+        (""uptime"", UptimeUnknown),
+        (""transaction-count"", TransactionsStats),
+        (""average-per-second"", AverageStats)
+    ]
+
+
+class NodeStats(BaseStats):
+    shema = [
+        (""Name"", BaseUnknown),
+        (""did"", BaseUnknown),
+        (""verkey"", BaseUnknown),
+        (""Node_port"", BindingStats),
+        (""Client_port"", BindingStats),
+        (""Metrics"", MetricsStats)
+    ]
+
+
+class PoolStats(BaseStats):
+    shema = [
+        (""Total_nodes_count"", BaseUnknown),
+        (""Reachable_nodes"", NodesListUnknown),
+        (""Reachable_nodes_count"", BaseUnknown),
+        (""Unreachable_nodes"", NodesListUnknown),
+        (""Unreachable_nodes_count"", BaseUnknown)
+    ]
+
+
+class SoftwareStats(BaseStats):
+    shema = [
+        (""indy-node"", BaseUnknown),
+        (""sovrin"", BaseUnknown)
+    ]
+
+    @staticmethod
+    def pkgVersion(pkgName):
+        try:
+            pkg = importlib.import_module(pkgName)
+        except ImportError as e:
+            logger.warning(""Failed to import {}: {}"".format(pkgName, e))
+        else:
+            try:
+                return pkg.__version__
+            except AttributeError as e:
+                logger.warning(
+                    ""Failed to get version of {}: {}"".format(pkgName, e))
+                return None
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+        pkgMappings = {
+            'indy-node': 'indy_node'
+        }
+
+        for pkgName, obj in self.items():
+            if obj is None or obj.is_unknown():
+                self[pkgName] = BaseUnknown(
+                    self.pkgVersion(pkgMappings.get(pkgName, pkgName)))
+
+
+class ValidatorStats(BaseStats):
+    shema = [
+        (""response-version"", BaseUnknown),
+        (""timestamp"", TimestampUnknown),
+        (""Node_info"", NodeStats),
+        (""state"", StateUnknown),
+        (""enabled"", BaseUnknown),
+        (""Pool_info"", PoolStats),
+        (""software"", SoftwareStats)
+    ]
+
+    @staticmethod
+    def get_process_state():
+        ctl = os.getenv('INDY_CONTROL', 'systemctl')
+        if ctl == ""systemctl"":
+           return ValidatorStats.get_process_state_via_systemctl()
+        elif ctl == ""supervisorctl"":
+           return ValidatorStats.get_process_state_via_supervisorctl()
+        else:
+           return ""Invalid value for INDY_CONTROL environment variable: '%s'"" % ctl
+
+    @staticmethod
+    def get_process_state_via_systemctl():
+        ret = subprocess.check_output(
+            'systemctl is-failed indy-node; exit 0',
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret == 'inactive':
+            return 'stopped'
+        elif ret == 'active':
+            return 'running'
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""is-failed state: {}"".format(ret)
+            )
+            return None
+
+    @staticmethod
+    def get_process_state_via_supervisorctl():
+        ret = subprocess.check_output(
+            ""supervisorctl status indy-node | awk '{print $2}'; exit 0"",
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret == 'STOPPED':
+            return 'stopped'
+        elif ret == 'RUNNING':
+            return 'running'
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""status: {}"".format(ret)
+            )
+            return None
+
+    @staticmethod
+    def get_enabled_state():
+        ctl = os.getenv('INDY_CONTROL', 'systemctl')
+        if ctl == ""systemctl"":
+           return ValidatorStats.get_enabled_state_via_systemctl()
+        elif ctl == ""supervisorctl"":
+           return ValidatorStats.get_enabled_state_via_supervisorctl()
+        else:
+           return ""Invalid value for INDY_CONTROL environment variable: '%s'"" % ctl
+
+    @staticmethod
+    def get_enabled_state_via_systemctl():
+        ret = subprocess.check_output(
+            'systemctl is-enabled indy-node; exit 0',
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret in ('enabled', 'static'):
+            return True
+        elif ret == 'disabled':
+            return False
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""is-enabled state: {}"".format(ret)
+            )
+            return None
+
+    @staticmethod
+    def get_enabled_state_via_supervisorctl():
+        ret = subprocess.check_output(
+            ""supervisorctl status indy-node | awk '{print $2}'; exit 0"",
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret in ('RUNNING', 'BACKOFF', 'STARTING'):
+            return True
+        elif ret == 'STOPPED':
+            return False
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""is-enabled state: {}"".format(ret)
+            )
+            return None
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        # TODO move that to classes too
+
+        if self['state'].is_unknown():
+            self['state'] = StateUnknown(self.get_process_state())
+
+        if self['enabled'].is_unknown():
+            self['enabled'] = BaseUnknown(self.get_enabled_state())
+
+    def __str__(self):
+        # TODO moving parts to other classes seems reasonable but
+        # will drop visibility of output
+        lines = [
+            ""Validator {} is {}"".format(self['Node_info']['Name'], self['state']),
+            ""Current time:     {}"".format(self['timestamp']),
+            ""Validator DID:    {}"".format(self['Node_info']['did']),
+            ""Verification Key: {}"".format(self['Node_info']['verkey']),
+            ""Node Port:        {}"".format(self['Node_info']['Node_port']),
+            ""Client Port:      {}"".format(self['Node_info']['Client_port']),
+            ""Metrics:"",
+            ""  Uptime: {}"".format(self['Node_info']['Metrics']['uptime']),
+            ""#  Total Config Transactions:  {}"".format(
+                self['Node_info']['Metrics']['transaction-count']['config']),
+            ""  Total Ledger Transactions:  {}"".format(
+                self['Node_info']['Metrics']['transaction-count']['ledger']),
+            ""  Total Pool Transactions:    {}"".format(
+                self['Node_info']['Metrics']['transaction-count']['pool']),
+            ""  Read Transactions/Seconds:  {}"".format(
+                self['Node_info']['Metrics']['average-per-second']['read-transactions']),
+            ""  Write Transactions/Seconds: {}"".format(
+                self['Node_info']['Metrics']['average-per-second']['write-transactions']),
+            ""Reachable Hosts:   {}/{}"".format(
+                self['Pool_info']['Reachable_nodes_count'],
+                self['Pool_info']['Total_nodes_count'])
+        ] + [
+            ""#  {}"".format(alias)
+            for alias in self['Pool_info']['Reachable_nodes']
+        ] + [
+            ""Unreachable Hosts: {}/{}"".format(
+                self['Pool_info']['Unreachable_nodes_count'],
+                self['Pool_info']['Total_nodes_count']
+            )
+        ] + [
+            ""#  {}"".format(alias)
+            for alias in self['Pool_info']['Unreachable_nodes']
+        ] + [
+            ""#Software Versions:""
+        ] + [
+            ""#  {}: {}"".format(pkgName, self['software'][pkgName])
+            for pkgName in self['software'].keys()
+        ]
+
+        # skip lines with started with '#' if not verbose
+        # or remove '#' otherwise
+        return (""\n"".join(
+            [l[(1 if l[0] == '#' else 0):]
+                for l in lines if self._verbose or l[0] != '#'])
+        )
+
+
+def get_validator_stats(stats, verbose, _json):
+
+    logger.debug(""Data {}"".format(stats))
+    vstats = ValidatorStats(stats, verbose)
+
+    if _json:
+        return json.dumps(vstats, indent=2, cls=NewEncoder)
+
+    return vstats
+
+
+def format_key(key):
+    return ""{:15}"".format('""{}"": '.format(key))
+
+
+def make_indent(indent):
+    return indent * ""{:5}"".format("""")
+
+
+def format_value(value):
+    return "" {:10}"".format(str(value))
+
+
+def create_print_tree(stats: dict, indent=0, lines=[]):
+    for key, value in stats.items():
+        if isinstance(value, dict):
+            lines.append(make_indent(indent) + format_key(key))
+            create_print_tree(value, indent + 1, lines)
+        elif isinstance(value, list):
+            lines.append(make_indent(indent) + format_key(key))
+            for line in value:
+                lines.append(make_indent(indent + 1) + format_value(line))
+        else:
+            if isinstance(value, dict) and not value or \
+                isinstance(value, list) and not value:
+                value = 'n/a'
+            lines.append(make_indent(indent) + format_key(key) + format_value(value))
+    return lines
+
+
+def set_log_owner(log_path):
+    def set_own():
+        try:
+            os.chown(log_path, indy_uid, indy_gid)
+        except PermissionError as e:
+            print(""Cannot set owner of {} file to indy"".format(log_path))
+            print(""The owner of {} must be {}:{}"".format(log_path, INDY_USER, INDY_USER))
+            sys.exit(1)
+
+    indy_ids = pwd.getpwnam(INDY_USER)
+    indy_uid = indy_ids.pw_uid
+    indy_gid = indy_ids.pw_gid
+    if os.path.exists(log_path):
+        f_stat = os.stat(log_path)
+        if f_stat.st_uid != indy_uid or f_stat.st_gid != indy_gid:
+            set_own()
+    else:
+        pathlib.Path(log_path).touch()
+        set_own()
+
+
+def remove_log_handlers():
+    for hndl in logger.root.handlers:
+        logger.root.removeHandler(hndl)
+
+    for hndl in logger.handlers:
+        logger.removeHandler(hndl)
+
+
+def read_json_data(info_path, num: int = 1, from_start = False, _from: int = None, _to: int = None):
+    assert _from <= _to if _from != None and _to != None else True
+
+    db_path, db_name = os.path.split(info_path)
+    db = KeyValueStorageRocksdbIntKeys(db_path, db_name, read_only=True)
+
+    it = db.iterator()
+
+    if _from != None:
+        it.seek_for_prev(db.to_byte_repr(_from))
+    elif _to != None or from_start:
+        it.seek_to_first()
+    else:
+        it.seek_to_last()
+        it = reversed(it)
+
+    json_data = []
+    cnt = 0
+
+    for ts, data in it:
+        try:
+            obj = json.loads(data.decode())
+        except json.JSONDecodeError:
+            print(""DB '{}' contains invalid records"".format(info_path))
+            return None
+
+        obj['timestamp'] = int(ts)
+
+        if _from != None or _to != None:
+            if _from == None or _from <= obj['timestamp']:
+                if _to == None or obj['timestamp'] <= _to:
+                    json_data.append(obj)
+                else:
+                    break
+        else:
+            if from_start:
+                json_data.append(obj)
+            else:
+                json_data.insert(0, obj)
+
+            if num != -1:
+                cnt += 1
+                if cnt == num:
+                    break
+
+    return json_data
+
+
+def compile_json_ouput(file_paths):
+    output_data = {}
+    for file_path in file_paths:
+        json_data = read_json_data(file_path)
+        if json_data:
+            for json_obj in json_data:
+                output_data.update(json_obj)
+    return output_data
+
+
+def get_info_paths(node_names, basedir):
+    postfix = ""_info_db""
+    info_paths = []
+    _info_paths = glob(os.path.join(basedir, ""*{}"".format(postfix)))
+    if node_names:
+        for info_path in _info_paths:
+            match = False
+            for node_name in node_names:
+                name = os.path.basename(info_path[:-len(postfix)])
+                if node_name.lower() == name:
+                    match = True
+                    break
+            if match:
+                info_paths.append(info_path)
+    else:
+        info_paths = _info_paths
+    return info_paths
+
+
+def parse_args():
+    config_helper = ConfigHelper(config)
+
+    parser = argparse.ArgumentParser(
+        description=(
+            ""Tool to explore and gather historycal statistics about running validator""
+        ),
+        formatter_class=argparse.ArgumentDefaultsHelpFormatter
+    )
+
+    parser.add_argument(
+        ""-n"", ""--num"", metavar=""NUM"", type=int,
+        default=1,
+        help=(""Number of records to print (from the end by default), -1 means all records"")
+    )
+
+    parser.add_argument(
+        ""-s"", ""--from_start"", action=""store_true"",
+        help=(""Count records from the start"")
+    )
+
+    parser.add_argument(
+        ""--names"", metavar=""Node1,Node2"",
+        default=None,
+        help=(""Comma-separated list of nodes to print records for."")
+    )
+
+    parser.add_argument(
+        ""--frm"", metavar=""TIMESTAMP"", type=int,
+        default=None,
+        help=(""Print records from timestamp (ignores -n and -s)"")
+    )
+
+    parser.add_argument(
+        ""--to"", metavar=""TIMESTAMP"", type=int,
+        default=None,
+        help=(""Print records to timestamp (ignores -n and -s)"")
+    )
+
+    output_group = parser.add_argument_group(
+        ""output"", ""specify output formatting""
+    )
+
+    output_group.add_argument(
+        ""--fields"", metavar=""Path.To.Field1,Path.To.Fie.ld2"",
+        default=None,
+        help=(""Comma-separated list of JSON nodes to print (ignores -v and --json, case-sensitive)."")
+    )
+
+    output_group.add_argument(
+        ""--json"", action=""store_true"",
+        help=""Format output as JSON (ignores -v)""
+    )
+
+    output_group.add_argument(
+        ""-v"", ""--verbose"", action=""store_true"",
+        help=""Verbose mode (command line)""
+    )
+
+    db_group = parser.add_argument_group(
+        ""database"", ""settings for exploring validator stats from database""
+    )
+
+    db_group.add_argument(
+        ""-d"", ""--basedir"", metavar=""PATH"",
+        default=config_helper.node_info_dir,
+        help=(""Path to databases base directory"")
+    )
+
+    other_group = parser.add_argument_group(
+        ""other"", ""other settings""
+    )
+
+    other_group.add_argument(
+        ""--log"", metavar=""FILE"",
+        default=os.path.join(
+            config_helper.log_base_dir,
+            os.path.basename(sys.argv[0] + "".log"")
+        ),
+        help=""Path to log file"")
+
+    return parser.parse_args()
+
+
+def check_args(args):
+    if args.num <= 0 and args.num != -1:
+        print(""Number of records to print must be greater than 0 or equal to -1"")
+        return False
+
+    return True
+
+
+def main():
+    global logger
+
+    args = parse_args()
+
+    if not check_args(args):
+        return -1
+
+    remove_log_handlers()
+
+    if args.log:
+        set_log_owner(args.log)
+
+    Logger().enableFileLogging(args.log)
+
+    logger.debug(""Cmd line arguments: {}"".format(args))
+
+    node_names = str(args.names).split("","") if args.names else None
+
+    info_paths = get_info_paths(node_names, args.basedir)
+
+    if len(info_paths) == 0:
+        print(""No storages found"")
+        return -1
+
+    fields_paths = None
+    if args.fields:
+        fields_paths = args.fields.split("","")
+
+    for info_path in info_paths:
+        json_data = read_json_data(info_path, args.num, args.from_start, args.frm, args.to)
+        if json_data:
+            print(""===================================================="")
+            print(json_data[0]['Node_info']['Name'])
+            print(""===================================================="")
+            for json_obj in json_data:
+                if fields_paths:
+                    stats = """"
+                    for fields_path in fields_paths:
+                        path = fields_path.split(""."")
+                        _obj = json_obj
+                        for node in path:
+                            _obj = _obj[node]",,2018-09-04 13:35:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/214879878,https://github.com/hyperledger/indy-node/pull/929#discussion_r214879878,sergey-shilov
https://github.com/hyperledger/indy-node/pull/929,https://github.com/hyperledger/indy-node/pull/929,"But yes, we can catch it and print the error.",29f27a72e3808cc900ff415c825fe5388d784eae,2018-09-04 11:32:52,214880274,"@@ -0,0 +1,796 @@
+#!/usr/bin/env python3
+# -*- coding: utf-8 -*-
+
+import importlib
+import argparse
+import datetime
+import json
+import os
+import sys
+import subprocess
+from collections import OrderedDict
+from glob import glob
+import re
+import pwd
+import pathlib
+
+from indy_common.config_util import getConfig
+from indy_common.config_helper import ConfigHelper
+from storage.kv_store_rocksdb_int_keys import KeyValueStorageRocksdbIntKeys
+from stp_core.common.log import Logger
+from stp_core.common.log import getlogger
+
+config = getConfig()
+
+logger = getlogger()  # to make flake8 happy
+clients = {}   # task -> (reader, writer)
+INDY_USER = ""indy""
+
+
+class BaseUnknown:
+    def __init__(self, val):
+        self._val = val
+
+    def _str(self):
+        return str(self._val)
+
+    def __str__(self):
+        return self._str() if not self.is_unknown() else ""unknown""
+
+    def is_unknown(self):
+        return self._val is None
+
+    @property
+    def val(self):
+        return self._val
+
+    @val.setter
+    def val(self, val):
+        self._val = val
+
+
+class NewEncoder(json.JSONEncoder):
+    def default(self, o):
+        if isinstance(o, BaseUnknown):
+            return o.val
+        elif isinstance(o, ConnectionStatsOut):
+            return o.bindings
+        else:
+            return super().default(o)
+
+
+class FloatUnknown(BaseUnknown):
+    def _str(self):
+        return ""{:.2f}"".format(self.val)
+
+
+class TimestampUnknown(BaseUnknown):
+    def _str(self):
+        return ""{} ({})"".format(
+            datetime.datetime.fromtimestamp(self.val).strftime(
+                ""%A, %B %{0}d, %Y %{0}I:%M:%S %p"".format(
+                    '#' if os.name == 'nt' else '-')),
+            self.val
+        )
+
+
+class UptimeUnknown(BaseUnknown):
+    def _str(self):
+        days, remainder = divmod(self.val, 86400)
+        hours, remainder = divmod(remainder, 3600)
+        minutes, seconds = divmod(remainder, 60)
+        parts = []
+
+        for s, v in zip(['day', 'hour', 'minute', 'second'],
+                        [days, hours, minutes, seconds]):
+            if v or len(parts):
+                parts.append(""{} {}{}"".format(v, s, '' if v == 1 else 's'))
+
+        return "", "".join(parts) if parts else '0 seconds'
+
+
+class StateUnknown(BaseUnknown):
+    def __str__(self):
+        return self.val if not self.is_unknown() else 'in unknown state'
+
+
+class NodesListUnknown(BaseUnknown):
+    def __init__(self, val):
+        super().__init__([] if val is None else val)
+
+    def _str(self):
+        return ""\n"".join(""#  {}"".format(alias) for alias in self.val)
+
+    def __iter__(self):
+        return iter(self.val)
+
+
+class BaseStats(OrderedDict):
+    shema = []
+
+    def __init__(self, stats, verbose=False):
+        if stats is None:
+            logger.debug(
+                ""{} no stats found"".format(type(self).__name__))
+
+        for k, cls in self.shema:
+            val = None if stats is None else stats.get(k)
+            try:
+                if issubclass(cls, BaseStats):
+                    self[k] = cls(val, verbose=verbose)
+                else:
+                    self[k] = cls(val)
+            except Exception as e:
+                logger.warning(
+                    ""{} Failed to parse attribute '{}': {}"".format(
+                        type(self).__name__, k, e))
+                self[k] = None
+
+        self._verbose = verbose
+
+
+class ConnectionStatsOut:
+
+    def __init__(self, bindings, verbose):
+        self.bindings = bindings
+        self._verbose = verbose
+
+    def __str__(self):
+        if not self._verbose:
+            data = [""{}"".format(b['port']) for b in self.bindings]
+        else:
+            data = [
+                ""{}{}"".format(
+                    b['port'],
+                    ""/{} on {}"".format(b['protocol'], b['ip'])
+                ) for b in self.bindings
+            ]
+
+        data = list(set(data))
+
+        return "", "".join(data)
+
+
+class BindingStats(BaseUnknown):
+
+    @staticmethod
+    def explore_bindings(port):
+        ANYADDR_IPV4 = '*'
+
+        def shell_cmd(command):
+            res = None
+            try:
+                ret = subprocess.check_output(
+                    command, stderr=subprocess.STDOUT, shell=True)
+            except subprocess.CalledProcessError as e:
+                logger.warning(
+                    ""Shell command '{}' failed, ""
+                    ""return code {}, stderr: {}"".format(
+                        command, e.returncode, e.stderr)
+                )
+            except Exception as e:
+                logger.warning(
+                    ""Failed to process shell command: '{}', ""
+                    ""unexpected error: {}"".format(command, e)
+                )
+            else:
+                logger.debug(""command '{}': stdout '{}'"".format(command, ret))
+                res = ret.decode().strip()
+
+            return res
+
+        if port is None:
+            return None
+
+        # TODO
+        # 1. need to filter more (e.g. by pid) for such cases as:
+        #   - SO_REUSEPORT or SO_REUSEADDR
+        #   - tcp + udp
+        # 2. procss ipv6 as well
+        #
+        # parse listening ip using 'ss' tool
+        command = ""ss -ln4 | sort -u | grep ':{}\s'"".format(port)
+        ret = shell_cmd(command)
+
+        if ret is None:
+            return None
+
+        ips = []
+        ips_with_netmasks = {}
+        for line in ret.split('\n'):
+            try:
+                parts = re.compile(""\s+"").split(line)
+                # format:
+                # Netid State Recv-Q Send-Q Local Address:Port Peer Address:Port
+                protocol, ip = parts[0], parts[4].split("":"")[0]
+            except Exception as e:
+                logger.warning(
+                    ""Failed to parse protocol, ip from '{}', ""
+                    ""error: {}"".format(line, e)
+                )
+            else:
+                if ip == ANYADDR_IPV4:
+                    # TODO mask here seems not necessary,
+                    # but requested in INDY-715
+                    ip = ""0.0.0.0/0""
+                else:
+                    if ip not in ips_with_netmasks:
+                        # parse mask using 'ip' tool
+                        # TODO more filtering by 'ip' tool itself if possible
+                        command = ""ip a | grep 'inet {}'"".format(ip)
+                        ret = shell_cmd(command)
+
+                        try:
+                            ip_with_netmask = re.match(
+                                ""^inet\s([^\s]+)"", ret).group(1)
+                        except Exception as e:
+                            logger.debug(
+                                ""Failed to parse ip with mask: command {}, ""
+                                ""stdout: {}, error {}"".format(command, ret, e))
+                            ip = ""{}/unknown"".format(ip)
+
+                        ips_with_netmasks[ip] = ip_with_netmask
+
+                    ip = ips_with_netmasks[ip]
+
+                ips.append((protocol, ip))
+
+        return list(set(ips))
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+        # change schema: ignoring any data received except port,
+        # resolve it ourselves (requested in original task INDY-715)
+        # TODO refactor
+
+        bindings = self.explore_bindings(self.val)
+        logger.info(
+            ""Found the following bindings ""
+            ""with port {}: {}"".format(self.val, bindings)
+        )
+        self.val = ConnectionStatsOut([] if bindings is None else [
+            dict(port=self.val, protocol=protocol, ip=ip)
+            for protocol, ip in bindings
+        ], False)
+
+
+class TransactionsStats(BaseStats):
+    shema = [
+        (""config"", BaseUnknown),
+        (""ledger"", BaseUnknown),
+        (""pool"", BaseUnknown)
+    ]
+
+
+class AverageStats(BaseStats):
+    shema = [
+        (""read-transactions"", FloatUnknown),
+        (""write-transactions"", FloatUnknown)
+    ]
+
+
+class MetricsStats(BaseStats):
+    shema = [
+        (""uptime"", UptimeUnknown),
+        (""transaction-count"", TransactionsStats),
+        (""average-per-second"", AverageStats)
+    ]
+
+
+class NodeStats(BaseStats):
+    shema = [
+        (""Name"", BaseUnknown),
+        (""did"", BaseUnknown),
+        (""verkey"", BaseUnknown),
+        (""Node_port"", BindingStats),
+        (""Client_port"", BindingStats),
+        (""Metrics"", MetricsStats)
+    ]
+
+
+class PoolStats(BaseStats):
+    shema = [
+        (""Total_nodes_count"", BaseUnknown),
+        (""Reachable_nodes"", NodesListUnknown),
+        (""Reachable_nodes_count"", BaseUnknown),
+        (""Unreachable_nodes"", NodesListUnknown),
+        (""Unreachable_nodes_count"", BaseUnknown)
+    ]
+
+
+class SoftwareStats(BaseStats):
+    shema = [
+        (""indy-node"", BaseUnknown),
+        (""sovrin"", BaseUnknown)
+    ]
+
+    @staticmethod
+    def pkgVersion(pkgName):
+        try:
+            pkg = importlib.import_module(pkgName)
+        except ImportError as e:
+            logger.warning(""Failed to import {}: {}"".format(pkgName, e))
+        else:
+            try:
+                return pkg.__version__
+            except AttributeError as e:
+                logger.warning(
+                    ""Failed to get version of {}: {}"".format(pkgName, e))
+                return None
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+        pkgMappings = {
+            'indy-node': 'indy_node'
+        }
+
+        for pkgName, obj in self.items():
+            if obj is None or obj.is_unknown():
+                self[pkgName] = BaseUnknown(
+                    self.pkgVersion(pkgMappings.get(pkgName, pkgName)))
+
+
+class ValidatorStats(BaseStats):
+    shema = [
+        (""response-version"", BaseUnknown),
+        (""timestamp"", TimestampUnknown),
+        (""Node_info"", NodeStats),
+        (""state"", StateUnknown),
+        (""enabled"", BaseUnknown),
+        (""Pool_info"", PoolStats),
+        (""software"", SoftwareStats)
+    ]
+
+    @staticmethod
+    def get_process_state():
+        ctl = os.getenv('INDY_CONTROL', 'systemctl')
+        if ctl == ""systemctl"":
+           return ValidatorStats.get_process_state_via_systemctl()
+        elif ctl == ""supervisorctl"":
+           return ValidatorStats.get_process_state_via_supervisorctl()
+        else:
+           return ""Invalid value for INDY_CONTROL environment variable: '%s'"" % ctl
+
+    @staticmethod
+    def get_process_state_via_systemctl():
+        ret = subprocess.check_output(
+            'systemctl is-failed indy-node; exit 0',
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret == 'inactive':
+            return 'stopped'
+        elif ret == 'active':
+            return 'running'
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""is-failed state: {}"".format(ret)
+            )
+            return None
+
+    @staticmethod
+    def get_process_state_via_supervisorctl():
+        ret = subprocess.check_output(
+            ""supervisorctl status indy-node | awk '{print $2}'; exit 0"",
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret == 'STOPPED':
+            return 'stopped'
+        elif ret == 'RUNNING':
+            return 'running'
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""status: {}"".format(ret)
+            )
+            return None
+
+    @staticmethod
+    def get_enabled_state():
+        ctl = os.getenv('INDY_CONTROL', 'systemctl')
+        if ctl == ""systemctl"":
+           return ValidatorStats.get_enabled_state_via_systemctl()
+        elif ctl == ""supervisorctl"":
+           return ValidatorStats.get_enabled_state_via_supervisorctl()
+        else:
+           return ""Invalid value for INDY_CONTROL environment variable: '%s'"" % ctl
+
+    @staticmethod
+    def get_enabled_state_via_systemctl():
+        ret = subprocess.check_output(
+            'systemctl is-enabled indy-node; exit 0',
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret in ('enabled', 'static'):
+            return True
+        elif ret == 'disabled':
+            return False
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""is-enabled state: {}"".format(ret)
+            )
+            return None
+
+    @staticmethod
+    def get_enabled_state_via_supervisorctl():
+        ret = subprocess.check_output(
+            ""supervisorctl status indy-node | awk '{print $2}'; exit 0"",
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret in ('RUNNING', 'BACKOFF', 'STARTING'):
+            return True
+        elif ret == 'STOPPED':
+            return False
+        else:
+            logger.info(
+                ""Non-expected output for indy-node ""
+                ""is-enabled state: {}"".format(ret)
+            )
+            return None
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        # TODO move that to classes too
+
+        if self['state'].is_unknown():
+            self['state'] = StateUnknown(self.get_process_state())
+
+        if self['enabled'].is_unknown():
+            self['enabled'] = BaseUnknown(self.get_enabled_state())
+
+    def __str__(self):
+        # TODO moving parts to other classes seems reasonable but
+        # will drop visibility of output
+        lines = [
+            ""Validator {} is {}"".format(self['Node_info']['Name'], self['state']),
+            ""Current time:     {}"".format(self['timestamp']),
+            ""Validator DID:    {}"".format(self['Node_info']['did']),
+            ""Verification Key: {}"".format(self['Node_info']['verkey']),
+            ""Node Port:        {}"".format(self['Node_info']['Node_port']),
+            ""Client Port:      {}"".format(self['Node_info']['Client_port']),
+            ""Metrics:"",
+            ""  Uptime: {}"".format(self['Node_info']['Metrics']['uptime']),
+            ""#  Total Config Transactions:  {}"".format(
+                self['Node_info']['Metrics']['transaction-count']['config']),
+            ""  Total Ledger Transactions:  {}"".format(
+                self['Node_info']['Metrics']['transaction-count']['ledger']),
+            ""  Total Pool Transactions:    {}"".format(
+                self['Node_info']['Metrics']['transaction-count']['pool']),
+            ""  Read Transactions/Seconds:  {}"".format(
+                self['Node_info']['Metrics']['average-per-second']['read-transactions']),
+            ""  Write Transactions/Seconds: {}"".format(
+                self['Node_info']['Metrics']['average-per-second']['write-transactions']),
+            ""Reachable Hosts:   {}/{}"".format(
+                self['Pool_info']['Reachable_nodes_count'],
+                self['Pool_info']['Total_nodes_count'])
+        ] + [
+            ""#  {}"".format(alias)
+            for alias in self['Pool_info']['Reachable_nodes']
+        ] + [
+            ""Unreachable Hosts: {}/{}"".format(
+                self['Pool_info']['Unreachable_nodes_count'],
+                self['Pool_info']['Total_nodes_count']
+            )
+        ] + [
+            ""#  {}"".format(alias)
+            for alias in self['Pool_info']['Unreachable_nodes']
+        ] + [
+            ""#Software Versions:""
+        ] + [
+            ""#  {}: {}"".format(pkgName, self['software'][pkgName])
+            for pkgName in self['software'].keys()
+        ]
+
+        # skip lines with started with '#' if not verbose
+        # or remove '#' otherwise
+        return (""\n"".join(
+            [l[(1 if l[0] == '#' else 0):]
+                for l in lines if self._verbose or l[0] != '#'])
+        )
+
+
+def get_validator_stats(stats, verbose, _json):
+
+    logger.debug(""Data {}"".format(stats))
+    vstats = ValidatorStats(stats, verbose)
+
+    if _json:
+        return json.dumps(vstats, indent=2, cls=NewEncoder)
+
+    return vstats
+
+
+def format_key(key):
+    return ""{:15}"".format('""{}"": '.format(key))
+
+
+def make_indent(indent):
+    return indent * ""{:5}"".format("""")
+
+
+def format_value(value):
+    return "" {:10}"".format(str(value))
+
+
+def create_print_tree(stats: dict, indent=0, lines=[]):
+    for key, value in stats.items():
+        if isinstance(value, dict):
+            lines.append(make_indent(indent) + format_key(key))
+            create_print_tree(value, indent + 1, lines)
+        elif isinstance(value, list):
+            lines.append(make_indent(indent) + format_key(key))
+            for line in value:
+                lines.append(make_indent(indent + 1) + format_value(line))
+        else:
+            if isinstance(value, dict) and not value or \
+                isinstance(value, list) and not value:
+                value = 'n/a'
+            lines.append(make_indent(indent) + format_key(key) + format_value(value))
+    return lines
+
+
+def set_log_owner(log_path):
+    def set_own():
+        try:
+            os.chown(log_path, indy_uid, indy_gid)
+        except PermissionError as e:
+            print(""Cannot set owner of {} file to indy"".format(log_path))
+            print(""The owner of {} must be {}:{}"".format(log_path, INDY_USER, INDY_USER))
+            sys.exit(1)
+
+    indy_ids = pwd.getpwnam(INDY_USER)
+    indy_uid = indy_ids.pw_uid
+    indy_gid = indy_ids.pw_gid
+    if os.path.exists(log_path):
+        f_stat = os.stat(log_path)
+        if f_stat.st_uid != indy_uid or f_stat.st_gid != indy_gid:
+            set_own()
+    else:
+        pathlib.Path(log_path).touch()
+        set_own()
+
+
+def remove_log_handlers():
+    for hndl in logger.root.handlers:
+        logger.root.removeHandler(hndl)
+
+    for hndl in logger.handlers:
+        logger.removeHandler(hndl)
+
+
+def read_json_data(info_path, num: int = 1, from_start = False, _from: int = None, _to: int = None):
+    assert _from <= _to if _from != None and _to != None else True
+
+    db_path, db_name = os.path.split(info_path)
+    db = KeyValueStorageRocksdbIntKeys(db_path, db_name, read_only=True)
+
+    it = db.iterator()
+
+    if _from != None:
+        it.seek_for_prev(db.to_byte_repr(_from))
+    elif _to != None or from_start:
+        it.seek_to_first()
+    else:
+        it.seek_to_last()
+        it = reversed(it)
+
+    json_data = []
+    cnt = 0
+
+    for ts, data in it:
+        try:
+            obj = json.loads(data.decode())
+        except json.JSONDecodeError:
+            print(""DB '{}' contains invalid records"".format(info_path))
+            return None
+
+        obj['timestamp'] = int(ts)
+
+        if _from != None or _to != None:
+            if _from == None or _from <= obj['timestamp']:
+                if _to == None or obj['timestamp'] <= _to:
+                    json_data.append(obj)
+                else:
+                    break
+        else:
+            if from_start:
+                json_data.append(obj)
+            else:
+                json_data.insert(0, obj)
+
+            if num != -1:
+                cnt += 1
+                if cnt == num:
+                    break
+
+    return json_data
+
+
+def compile_json_ouput(file_paths):
+    output_data = {}
+    for file_path in file_paths:
+        json_data = read_json_data(file_path)
+        if json_data:
+            for json_obj in json_data:
+                output_data.update(json_obj)
+    return output_data
+
+
+def get_info_paths(node_names, basedir):
+    postfix = ""_info_db""
+    info_paths = []
+    _info_paths = glob(os.path.join(basedir, ""*{}"".format(postfix)))
+    if node_names:
+        for info_path in _info_paths:
+            match = False
+            for node_name in node_names:
+                name = os.path.basename(info_path[:-len(postfix)])
+                if node_name.lower() == name:
+                    match = True
+                    break
+            if match:
+                info_paths.append(info_path)
+    else:
+        info_paths = _info_paths
+    return info_paths
+
+
+def parse_args():
+    config_helper = ConfigHelper(config)
+
+    parser = argparse.ArgumentParser(
+        description=(
+            ""Tool to explore and gather historycal statistics about running validator""
+        ),
+        formatter_class=argparse.ArgumentDefaultsHelpFormatter
+    )
+
+    parser.add_argument(
+        ""-n"", ""--num"", metavar=""NUM"", type=int,
+        default=1,
+        help=(""Number of records to print (from the end by default), -1 means all records"")
+    )
+
+    parser.add_argument(
+        ""-s"", ""--from_start"", action=""store_true"",
+        help=(""Count records from the start"")
+    )
+
+    parser.add_argument(
+        ""--names"", metavar=""Node1,Node2"",
+        default=None,
+        help=(""Comma-separated list of nodes to print records for."")
+    )
+
+    parser.add_argument(
+        ""--frm"", metavar=""TIMESTAMP"", type=int,
+        default=None,
+        help=(""Print records from timestamp (ignores -n and -s)"")
+    )
+
+    parser.add_argument(
+        ""--to"", metavar=""TIMESTAMP"", type=int,
+        default=None,
+        help=(""Print records to timestamp (ignores -n and -s)"")
+    )
+
+    output_group = parser.add_argument_group(
+        ""output"", ""specify output formatting""
+    )
+
+    output_group.add_argument(
+        ""--fields"", metavar=""Path.To.Field1,Path.To.Fie.ld2"",
+        default=None,
+        help=(""Comma-separated list of JSON nodes to print (ignores -v and --json, case-sensitive)."")
+    )
+
+    output_group.add_argument(
+        ""--json"", action=""store_true"",
+        help=""Format output as JSON (ignores -v)""
+    )
+
+    output_group.add_argument(
+        ""-v"", ""--verbose"", action=""store_true"",
+        help=""Verbose mode (command line)""
+    )
+
+    db_group = parser.add_argument_group(
+        ""database"", ""settings for exploring validator stats from database""
+    )
+
+    db_group.add_argument(
+        ""-d"", ""--basedir"", metavar=""PATH"",
+        default=config_helper.node_info_dir,
+        help=(""Path to databases base directory"")
+    )
+
+    other_group = parser.add_argument_group(
+        ""other"", ""other settings""
+    )
+
+    other_group.add_argument(
+        ""--log"", metavar=""FILE"",
+        default=os.path.join(
+            config_helper.log_base_dir,
+            os.path.basename(sys.argv[0] + "".log"")
+        ),
+        help=""Path to log file"")
+
+    return parser.parse_args()
+
+
+def check_args(args):
+    if args.num <= 0 and args.num != -1:
+        print(""Number of records to print must be greater than 0 or equal to -1"")
+        return False
+
+    return True
+
+
+def main():
+    global logger
+
+    args = parse_args()
+
+    if not check_args(args):
+        return -1
+
+    remove_log_handlers()
+
+    if args.log:
+        set_log_owner(args.log)
+
+    Logger().enableFileLogging(args.log)
+
+    logger.debug(""Cmd line arguments: {}"".format(args))
+
+    node_names = str(args.names).split("","") if args.names else None
+
+    info_paths = get_info_paths(node_names, args.basedir)
+
+    if len(info_paths) == 0:
+        print(""No storages found"")
+        return -1
+
+    fields_paths = None
+    if args.fields:
+        fields_paths = args.fields.split("","")
+
+    for info_path in info_paths:
+        json_data = read_json_data(info_path, args.num, args.from_start, args.frm, args.to)
+        if json_data:
+            print(""===================================================="")
+            print(json_data[0]['Node_info']['Name'])
+            print(""===================================================="")
+            for json_obj in json_data:
+                if fields_paths:
+                    stats = """"
+                    for fields_path in fields_paths:
+                        path = fields_path.split(""."")
+                        _obj = json_obj
+                        for node in path:
+                            _obj = _obj[node]",,2018-09-04 13:35:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/214880274,https://github.com/hyperledger/indy-node/pull/929#discussion_r214880274,sergey-shilov
https://github.com/hyperledger/indy-node/pull/919,https://github.com/hyperledger/indy-node/pull/919,It would be great to have FEEs amount for each txn configurable,b20bc9c9e2eb4785660fd8142af7e609b1ef7081,2018-08-30 10:48:56,213985239,"@@ -976,6 +982,107 @@ def _gen_req_data(self):
         return req
 
 
+class RGFeesNym(RGBasePayment):
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        self._sources_amounts = {}
+        self._last_used = None
+
+    async def __retrieve_minted_sources(self):
+        for payment_address in self._payment_addresses:
+            self._sources_amounts[payment_address] = []
+            self._sources_amounts[payment_address].extend(await self._get_payment_sources(payment_address))
+
+    async def on_pool_create(self, pool_handle, wallet_handle, submitter_did, *args, **kwargs):
+        await super().on_pool_create(pool_handle, wallet_handle, submitter_did, *args, **kwargs)
+        await self.__retrieve_minted_sources()
+
+        fees_req = await payment.build_set_txn_fees_req(wallet_handle, submitter_did, self._payment_method,",74,2018-08-30 10:57:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/213985239,https://github.com/hyperledger/indy-node/pull/919#discussion_r213985239,ashcherbakov
https://github.com/hyperledger/indy-node/pull/919,https://github.com/hyperledger/indy-node/pull/919,Please extend docs with new info,b20bc9c9e2eb4785660fd8142af7e609b1ef7081,2018-08-30 10:57:49,213987485,"@@ -976,6 +982,107 @@ def _gen_req_data(self):
         return req
 
 
+class RGFeesNym(RGBasePayment):
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        self._sources_amounts = {}
+        self._last_used = None
+
+    async def __retrieve_minted_sources(self):
+        for payment_address in self._payment_addresses:
+            self._sources_amounts[payment_address] = []
+            self._sources_amounts[payment_address].extend(await self._get_payment_sources(payment_address))
+
+    async def on_pool_create(self, pool_handle, wallet_handle, submitter_did, *args, **kwargs):
+        await super().on_pool_create(pool_handle, wallet_handle, submitter_did, *args, **kwargs)
+        await self.__retrieve_minted_sources()
+
+        fees_req = await payment.build_set_txn_fees_req(wallet_handle, submitter_did, self._payment_method,
+                                                        json.dumps({""1"": 1}))
+        for trustee_did in [self._submitter_did, *self._additional_trustees_dids]:
+            fees_req = await ledger.multi_sign_request(self._wallet_handle, trustee_did, fees_req)
+
+        resp = await ledger.submit_request(self._pool_handle, fees_req)
+        ensure_is_reply(resp)
+
+    def _rand_data(self):
+        raw = libnacl.randombytes(16)
+        req_did = self.rawToFriendly(raw)
+        return req_did
+
+    def _from_file_str_data(self, file_str):
+        raise NotImplementedError(""ne _from_file_str_data"")
+
+    async def _gen_req(self, submit_did, req_data):
+        req = await ledger.build_nym_request(submit_did, req_data, None, None, None)
+
+        for ap in self._sources_amounts:
+            if self._sources_amounts[ap]:
+                (source, amount) = self._sources_amounts[ap].pop()
+                address = ap
+                inputs = [source]
+                outputs = [{""recipient"": address, ""amount"": amount - 1}]
+                req_fees = await payment.add_request_fees(self._wallet_handle, submit_did, req,
+                                                          json.dumps(inputs),
+                                                          json.dumps(outputs), None)
+                return req_fees[0]
+        raise NoReqDataAvailableException()
+
+    async def on_request_replied(self, req_data, req, resp_or_exp):
+        if isinstance(resp_or_exp, Exception):
+            return
+
+        resp = resp_or_exp
+
+        try:
+            resp_obj = json.loads(resp)
+
+            if ""op"" not in resp_obj:
+                raise Exception(""Response does not contain op field."")
+
+            if resp_obj[""op""] == ""REQNACK"" or resp_obj[""op""] == ""REJECT"":
+                return
+                # self._sources_amounts.append((source, amount))
+            elif resp_obj[""op""] == ""REPLY"":
+                receipt_infos_json = await payment.parse_response_with_fees(self._payment_method, resp)
+                receipt_infos = json.loads(receipt_infos_json)
+                receipt_info = receipt_infos[0]
+                self._sources_amounts[receipt_info[""recipient""]].append((receipt_info[""receipt""], receipt_info[""amount""]))
+
+        except Exception as e:
+            print(""Error on payment txn postprocessing: {}"".format(e))
+
+
+class RGFeesSchema(RGFeesNym):",130,2018-08-30 10:57:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/213987485,https://github.com/hyperledger/indy-node/pull/919#discussion_r213987485,ashcherbakov
https://github.com/hyperledger/indy-node/pull/911,https://github.com/hyperledger/indy-node/pull/911,Please add the script to `setup.py` so that it's installed with the build,ceb3eb7a3a0077261eceb478bdd2bab94bc378e6,2018-08-22 06:35:55,211842219,"@@ -0,0 +1,64 @@
+#! /usr/bin/env python3
+import argparse",,2018-08-22 11:32:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211842219,https://github.com/hyperledger/indy-node/pull/911#discussion_r211842219,ashcherbakov
https://github.com/hyperledger/indy-node/pull/911,https://github.com/hyperledger/indy-node/pull/911,Is it in base58 so that it can be copy-pasted to the NODE txn?,ceb3eb7a3a0077261eceb478bdd2bab94bc378e6,2018-08-22 06:37:04,211842400,"@@ -0,0 +1,64 @@
+#! /usr/bin/env python3
+import argparse
+import os
+
+from crypto.bls.bls_key_manager import LoadBLSKeyError
+from crypto.bls.indy_crypto.bls_crypto_indy_crypto import \
+    BlsCryptoSignerIndyCrypto
+from indy_common.config_helper import NodeConfigHelper
+from plenum.bls.bls_key_manager_file import BlsKeyManagerFile
+from indy_common.config_util import getConfig
+
+config = getConfig()
+config.enableStdOutLogging = False
+ENV_FILE_PATH = ""/etc/indy/indy.env""
+
+
+def load_keys() -> (str, str):
+    node_name = get_node_name()
+    if node_name is None:
+        raise LoadBLSKeyError(""Please use parameter --name for setting node name."")
+
+    node_config_helper = NodeConfigHelper(node_name, getConfig())
+    keys_dir = os.path.expanduser(node_config_helper.keys_dir)
+    if not os.path.exists(keys_dir):
+        raise LoadBLSKeyError(""Keys are not exist. Please generate BLS keys."")
+
+    dir = os.path.join(keys_dir, node_name)
+    sk, pk = BlsKeyManagerFile(dir).load_keys()
+    return sk, pk
+
+
+def get_node_name():
+    node_name = parse_args()
+    node_name_key = 'NODE_NAME'
+
+    if os.path.exists(ENV_FILE_PATH):
+        with open(ENV_FILE_PATH, ""r"") as fenv:
+            for line in fenv.readlines():
+                if line.find(node_name_key) != -1:
+                    node_name = line.split('=')[1].strip()
+                    break
+    return node_name
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(
+        description=""Generate BLS keys proof of possession."")
+
+    parser.add_argument('--name', required=False, help='node name')
+    args = parser.parse_args()
+    return args.name
+
+
+if __name__ == ""__main__"":
+    pk = sk = None
+    try:
+        sk, pk = load_keys()
+    except LoadBLSKeyError as e:
+        print(e.args[0])
+
+    if None not in [pk, sk]:
+        print(""The Public BLS Key is"", pk)
+        key_proof = BlsCryptoSignerIndyCrypto.generate_key_proof(sk, pk)",,2018-08-22 11:32:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211842400,https://github.com/hyperledger/indy-node/pull/911#discussion_r211842400,ashcherbakov
https://github.com/hyperledger/indy-node/pull/911,https://github.com/hyperledger/indy-node/pull/911,Is it in base58 so that it can be copy-pasted to the NODE txn?,ceb3eb7a3a0077261eceb478bdd2bab94bc378e6,2018-08-22 06:37:28,211842480,"@@ -0,0 +1,64 @@
+#! /usr/bin/env python3
+import argparse
+import os
+
+from crypto.bls.bls_key_manager import LoadBLSKeyError
+from crypto.bls.indy_crypto.bls_crypto_indy_crypto import \
+    BlsCryptoSignerIndyCrypto
+from indy_common.config_helper import NodeConfigHelper
+from plenum.bls.bls_key_manager_file import BlsKeyManagerFile
+from indy_common.config_util import getConfig
+
+config = getConfig()
+config.enableStdOutLogging = False
+ENV_FILE_PATH = ""/etc/indy/indy.env""
+
+
+def load_keys() -> (str, str):
+    node_name = get_node_name()
+    if node_name is None:
+        raise LoadBLSKeyError(""Please use parameter --name for setting node name."")
+
+    node_config_helper = NodeConfigHelper(node_name, getConfig())
+    keys_dir = os.path.expanduser(node_config_helper.keys_dir)
+    if not os.path.exists(keys_dir):
+        raise LoadBLSKeyError(""Keys are not exist. Please generate BLS keys."")
+
+    dir = os.path.join(keys_dir, node_name)
+    sk, pk = BlsKeyManagerFile(dir).load_keys()
+    return sk, pk
+
+
+def get_node_name():
+    node_name = parse_args()
+    node_name_key = 'NODE_NAME'
+
+    if os.path.exists(ENV_FILE_PATH):
+        with open(ENV_FILE_PATH, ""r"") as fenv:
+            for line in fenv.readlines():
+                if line.find(node_name_key) != -1:
+                    node_name = line.split('=')[1].strip()
+                    break
+    return node_name
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(
+        description=""Generate BLS keys proof of possession."")
+
+    parser.add_argument('--name', required=False, help='node name')
+    args = parser.parse_args()
+    return args.name
+
+
+if __name__ == ""__main__"":
+    pk = sk = None
+    try:
+        sk, pk = load_keys()
+    except LoadBLSKeyError as e:
+        print(e.args[0])
+
+    if None not in [pk, sk]:
+        print(""The Public BLS Key is"", pk)",,2018-08-22 11:32:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211842480,https://github.com/hyperledger/indy-node/pull/911#discussion_r211842480,ashcherbakov
https://github.com/hyperledger/indy-node/pull/911,https://github.com/hyperledger/indy-node/pull/911,`Generating proof of possession for the Node's BLS key`,ceb3eb7a3a0077261eceb478bdd2bab94bc378e6,2018-08-22 06:54:45,211845800,"@@ -0,0 +1,64 @@
+#! /usr/bin/env python3
+import argparse
+import os
+
+from crypto.bls.bls_key_manager import LoadBLSKeyError
+from crypto.bls.indy_crypto.bls_crypto_indy_crypto import \
+    BlsCryptoSignerIndyCrypto
+from indy_common.config_helper import NodeConfigHelper
+from plenum.bls.bls_key_manager_file import BlsKeyManagerFile
+from indy_common.config_util import getConfig
+
+config = getConfig()
+config.enableStdOutLogging = False
+ENV_FILE_PATH = ""/etc/indy/indy.env""
+
+
+def load_keys() -> (str, str):
+    node_name = get_node_name()
+    if node_name is None:
+        raise LoadBLSKeyError(""Please use parameter --name for setting node name."")
+
+    node_config_helper = NodeConfigHelper(node_name, getConfig())
+    keys_dir = os.path.expanduser(node_config_helper.keys_dir)
+    if not os.path.exists(keys_dir):
+        raise LoadBLSKeyError(""Keys are not exist. Please generate BLS keys."")
+
+    dir = os.path.join(keys_dir, node_name)
+    sk, pk = BlsKeyManagerFile(dir).load_keys()
+    return sk, pk
+
+
+def get_node_name():
+    node_name = parse_args()
+    node_name_key = 'NODE_NAME'
+
+    if os.path.exists(ENV_FILE_PATH):
+        with open(ENV_FILE_PATH, ""r"") as fenv:
+            for line in fenv.readlines():
+                if line.find(node_name_key) != -1:
+                    node_name = line.split('=')[1].strip()
+                    break
+    return node_name
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(
+        description=""Generate BLS keys proof of possession."")",,2018-08-22 11:32:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211845800,https://github.com/hyperledger/indy-node/pull/911#discussion_r211845800,ashcherbakov
https://github.com/hyperledger/indy-node/pull/911,https://github.com/hyperledger/indy-node/pull/911,"After generating generate_key_proof() uses bls_to_str() which decode BLS entity as base58
```
def generate_key_proof(sk: str, pk: str):
        sk_bls = IndyCryptoBlsUtils.bls_from_str(sk, SignKey)
        pk_bls = IndyCryptoBlsUtils.bls_from_str(pk, VerKey)
        key_proof = ProofOfPossession.new(ver_key=pk_bls, sign_key=sk_bls)
        key_proof_str = IndyCryptoBlsUtils.bls_to_str(key_proof)
        return key_proof_str
```",ceb3eb7a3a0077261eceb478bdd2bab94bc378e6,2018-08-22 07:31:27,211853695,"@@ -0,0 +1,64 @@
+#! /usr/bin/env python3
+import argparse
+import os
+
+from crypto.bls.bls_key_manager import LoadBLSKeyError
+from crypto.bls.indy_crypto.bls_crypto_indy_crypto import \
+    BlsCryptoSignerIndyCrypto
+from indy_common.config_helper import NodeConfigHelper
+from plenum.bls.bls_key_manager_file import BlsKeyManagerFile
+from indy_common.config_util import getConfig
+
+config = getConfig()
+config.enableStdOutLogging = False
+ENV_FILE_PATH = ""/etc/indy/indy.env""
+
+
+def load_keys() -> (str, str):
+    node_name = get_node_name()
+    if node_name is None:
+        raise LoadBLSKeyError(""Please use parameter --name for setting node name."")
+
+    node_config_helper = NodeConfigHelper(node_name, getConfig())
+    keys_dir = os.path.expanduser(node_config_helper.keys_dir)
+    if not os.path.exists(keys_dir):
+        raise LoadBLSKeyError(""Keys are not exist. Please generate BLS keys."")
+
+    dir = os.path.join(keys_dir, node_name)
+    sk, pk = BlsKeyManagerFile(dir).load_keys()
+    return sk, pk
+
+
+def get_node_name():
+    node_name = parse_args()
+    node_name_key = 'NODE_NAME'
+
+    if os.path.exists(ENV_FILE_PATH):
+        with open(ENV_FILE_PATH, ""r"") as fenv:
+            for line in fenv.readlines():
+                if line.find(node_name_key) != -1:
+                    node_name = line.split('=')[1].strip()
+                    break
+    return node_name
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(
+        description=""Generate BLS keys proof of possession."")
+
+    parser.add_argument('--name', required=False, help='node name')
+    args = parser.parse_args()
+    return args.name
+
+
+if __name__ == ""__main__"":
+    pk = sk = None
+    try:
+        sk, pk = load_keys()
+    except LoadBLSKeyError as e:
+        print(e.args[0])
+
+    if None not in [pk, sk]:
+        print(""The Public BLS Key is"", pk)
+        key_proof = BlsCryptoSignerIndyCrypto.generate_key_proof(sk, pk)",,2018-08-22 11:32:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211853695,https://github.com/hyperledger/indy-node/pull/911#discussion_r211853695,Toktar
https://github.com/hyperledger/indy-node/pull/911,https://github.com/hyperledger/indy-node/pull/911,For reading bls keys from files we use method [__load_from_file()](https://github.com/hyperledger/indy-plenum/blob/5fda787d2b6da17ca4b90ea00ccc280c5e1aee2e/plenum/bls/bls_key_manager_file.py#L47-L51) which decode key after reading.,ceb3eb7a3a0077261eceb478bdd2bab94bc378e6,2018-08-22 07:38:20,211855435,"@@ -0,0 +1,64 @@
+#! /usr/bin/env python3
+import argparse
+import os
+
+from crypto.bls.bls_key_manager import LoadBLSKeyError
+from crypto.bls.indy_crypto.bls_crypto_indy_crypto import \
+    BlsCryptoSignerIndyCrypto
+from indy_common.config_helper import NodeConfigHelper
+from plenum.bls.bls_key_manager_file import BlsKeyManagerFile
+from indy_common.config_util import getConfig
+
+config = getConfig()
+config.enableStdOutLogging = False
+ENV_FILE_PATH = ""/etc/indy/indy.env""
+
+
+def load_keys() -> (str, str):
+    node_name = get_node_name()
+    if node_name is None:
+        raise LoadBLSKeyError(""Please use parameter --name for setting node name."")
+
+    node_config_helper = NodeConfigHelper(node_name, getConfig())
+    keys_dir = os.path.expanduser(node_config_helper.keys_dir)
+    if not os.path.exists(keys_dir):
+        raise LoadBLSKeyError(""Keys are not exist. Please generate BLS keys."")
+
+    dir = os.path.join(keys_dir, node_name)
+    sk, pk = BlsKeyManagerFile(dir).load_keys()
+    return sk, pk
+
+
+def get_node_name():
+    node_name = parse_args()
+    node_name_key = 'NODE_NAME'
+
+    if os.path.exists(ENV_FILE_PATH):
+        with open(ENV_FILE_PATH, ""r"") as fenv:
+            for line in fenv.readlines():
+                if line.find(node_name_key) != -1:
+                    node_name = line.split('=')[1].strip()
+                    break
+    return node_name
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(
+        description=""Generate BLS keys proof of possession."")
+
+    parser.add_argument('--name', required=False, help='node name')
+    args = parser.parse_args()
+    return args.name
+
+
+if __name__ == ""__main__"":
+    pk = sk = None
+    try:
+        sk, pk = load_keys()
+    except LoadBLSKeyError as e:
+        print(e.args[0])
+
+    if None not in [pk, sk]:
+        print(""The Public BLS Key is"", pk)",,2018-08-22 11:32:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211855435,https://github.com/hyperledger/indy-node/pull/911#discussion_r211855435,Toktar
https://github.com/hyperledger/indy-node/pull/911,https://github.com/hyperledger/indy-node/pull/911,Done,ceb3eb7a3a0077261eceb478bdd2bab94bc378e6,2018-08-22 07:42:43,211856530,"@@ -0,0 +1,64 @@
+#! /usr/bin/env python3
+import argparse",,2018-08-22 11:32:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211856530,https://github.com/hyperledger/indy-node/pull/911#discussion_r211856530,Toktar
https://github.com/hyperledger/indy-node/pull/911,https://github.com/hyperledger/indy-node/pull/911,Done,ceb3eb7a3a0077261eceb478bdd2bab94bc378e6,2018-08-22 07:42:54,211856565,"@@ -0,0 +1,64 @@
+#! /usr/bin/env python3
+import argparse
+import os
+
+from crypto.bls.bls_key_manager import LoadBLSKeyError
+from crypto.bls.indy_crypto.bls_crypto_indy_crypto import \
+    BlsCryptoSignerIndyCrypto
+from indy_common.config_helper import NodeConfigHelper
+from plenum.bls.bls_key_manager_file import BlsKeyManagerFile
+from indy_common.config_util import getConfig
+
+config = getConfig()
+config.enableStdOutLogging = False
+ENV_FILE_PATH = ""/etc/indy/indy.env""
+
+
+def load_keys() -> (str, str):
+    node_name = get_node_name()
+    if node_name is None:
+        raise LoadBLSKeyError(""Please use parameter --name for setting node name."")
+
+    node_config_helper = NodeConfigHelper(node_name, getConfig())
+    keys_dir = os.path.expanduser(node_config_helper.keys_dir)
+    if not os.path.exists(keys_dir):
+        raise LoadBLSKeyError(""Keys are not exist. Please generate BLS keys."")
+
+    dir = os.path.join(keys_dir, node_name)
+    sk, pk = BlsKeyManagerFile(dir).load_keys()
+    return sk, pk
+
+
+def get_node_name():
+    node_name = parse_args()
+    node_name_key = 'NODE_NAME'
+
+    if os.path.exists(ENV_FILE_PATH):
+        with open(ENV_FILE_PATH, ""r"") as fenv:
+            for line in fenv.readlines():
+                if line.find(node_name_key) != -1:
+                    node_name = line.split('=')[1].strip()
+                    break
+    return node_name
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(
+        description=""Generate BLS keys proof of possession."")",,2018-08-22 11:32:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211856565,https://github.com/hyperledger/indy-node/pull/911#discussion_r211856565,Toktar
https://github.com/hyperledger/indy-node/pull/903,https://github.com/hyperledger/indy-node/pull/903,from a running node,0bd1986e40aeb5ed58036c5cbd70271e02d2ac2e,2018-08-20 07:48:30,211168251,"@@ -0,0 +1,38 @@
+# Add Node to Existing Pool
+
+## Node preparation
+
+1. Add this files from running node:",,2018-08-21 12:59:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211168251,https://github.com/hyperledger/indy-node/pull/903#discussion_r211168251,ashcherbakov
https://github.com/hyperledger/indy-node/pull/903,https://github.com/hyperledger/indy-node/pull/903,on the new node,0bd1986e40aeb5ed58036c5cbd70271e02d2ac2e,2018-08-20 07:48:51,211168392,"@@ -0,0 +1,38 @@
+# Add Node to Existing Pool
+
+## Node preparation
+
+1. Add this files from running node:
+```
+/var/lib/indy/network_name/pool_transactions_genesis
+/var/lib/indy/network_name/domain_transactions_genesis
+```
+
+2. Initialize keys, aliases and ports on new nodes using init_indy_node script.",,2018-08-21 12:59:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211168392,https://github.com/hyperledger/indy-node/pull/903#discussion_r211168392,ashcherbakov
https://github.com/hyperledger/indy-node/pull/903,https://github.com/hyperledger/indy-node/pull/903,"When the node starts for the first time, it reads the content of genesis `pool_transactions_sandbox` and `transactions_sandbox` files and adds it to the ledger. The Node reads genesis transactions only once during the first start-up, so make sure the genesis files are correct before starting the service.
",0bd1986e40aeb5ed58036c5cbd70271e02d2ac2e,2018-08-20 08:08:35,211173204,"@@ -0,0 +1,38 @@
+# Add Node to Existing Pool
+
+## Node preparation
+
+1. Add this files from running node:
+```
+/var/lib/indy/network_name/pool_transactions_genesis
+/var/lib/indy/network_name/domain_transactions_genesis
+```
+
+2. Initialize keys, aliases and ports on new nodes using init_indy_node script.
+Example:
+```
+sudo su - indy -c ""init_indy_node NewNode 0.0.0.0 9701 0.0.0.0 9702 0000000000000000000000000NewNode""
+```
+
+3. Starting the node the first time will read in the pool_transactions_sandbox and transactions_sandbox files into the ledger. It only reads it the one time so make sure the first are correct before starting the service.",,2018-08-21 12:59:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211173204,https://github.com/hyperledger/indy-node/pull/903#discussion_r211173204,ashcherbakov
https://github.com/hyperledger/indy-node/pull/903,https://github.com/hyperledger/indy-node/pull/903,(only Steward can add a new Validator Node; a Steward can add one and only one Validator Node),0bd1986e40aeb5ed58036c5cbd70271e02d2ac2e,2018-08-20 08:09:23,211173404,"@@ -0,0 +1,38 @@
+# Add Node to Existing Pool
+
+## Node preparation
+
+1. Add this files from running node:
+```
+/var/lib/indy/network_name/pool_transactions_genesis
+/var/lib/indy/network_name/domain_transactions_genesis
+```
+
+2. Initialize keys, aliases and ports on new nodes using init_indy_node script.
+Example:
+```
+sudo su - indy -c ""init_indy_node NewNode 0.0.0.0 9701 0.0.0.0 9702 0000000000000000000000000NewNode""
+```
+
+3. Starting the node the first time will read in the pool_transactions_sandbox and transactions_sandbox files into the ledger. It only reads it the one time so make sure the first are correct before starting the service.
+```
+sudo systemctl start indy-node
+sudo systemctl status indy-node
+sudo systemctl enable indy-node
+```
+
+## Add Node to the Pool
+
+1. As Trustee add another Steward if needed (only Steward can add new Validator, and only one)",,2018-08-21 12:59:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211173404,https://github.com/hyperledger/indy-node/pull/903#discussion_r211173404,ashcherbakov
https://github.com/hyperledger/indy-node/pull/903,https://github.com/hyperledger/indy-node/pull/903,"Using Indy CLI (<provide a link>, run the following command as Steward:",0bd1986e40aeb5ed58036c5cbd70271e02d2ac2e,2018-08-20 08:10:00,211173553,"@@ -0,0 +1,38 @@
+# Add Node to Existing Pool
+
+## Node preparation
+
+1. Add this files from running node:
+```
+/var/lib/indy/network_name/pool_transactions_genesis
+/var/lib/indy/network_name/domain_transactions_genesis
+```
+
+2. Initialize keys, aliases and ports on new nodes using init_indy_node script.
+Example:
+```
+sudo su - indy -c ""init_indy_node NewNode 0.0.0.0 9701 0.0.0.0 9702 0000000000000000000000000NewNode""
+```
+
+3. Starting the node the first time will read in the pool_transactions_sandbox and transactions_sandbox files into the ledger. It only reads it the one time so make sure the first are correct before starting the service.
+```
+sudo systemctl start indy-node
+sudo systemctl status indy-node
+sudo systemctl enable indy-node
+```
+
+## Add Node to the Pool
+
+1. As Trustee add another Steward if needed (only Steward can add new Validator, and only one)
+2. As Steward run command like this:",,2018-08-21 12:59:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211173553,https://github.com/hyperledger/indy-node/pull/903#discussion_r211173553,ashcherbakov
https://github.com/hyperledger/indy-node/pull/903,https://github.com/hyperledger/indy-node/pull/903,Dot at the end of the sentence,0bd1986e40aeb5ed58036c5cbd70271e02d2ac2e,2018-08-20 08:12:31,211174174,"@@ -0,0 +1,38 @@
+# Add Node to Existing Pool
+
+## Node preparation
+
+1. Add this files from running node:
+```
+/var/lib/indy/network_name/pool_transactions_genesis
+/var/lib/indy/network_name/domain_transactions_genesis
+```
+
+2. Initialize keys, aliases and ports on new nodes using init_indy_node script.
+Example:
+```
+sudo su - indy -c ""init_indy_node NewNode 0.0.0.0 9701 0.0.0.0 9702 0000000000000000000000000NewNode""
+```
+
+3. Starting the node the first time will read in the pool_transactions_sandbox and transactions_sandbox files into the ledger. It only reads it the one time so make sure the first are correct before starting the service.
+```
+sudo systemctl start indy-node
+sudo systemctl status indy-node
+sudo systemctl enable indy-node
+```
+
+## Add Node to the Pool
+
+1. As Trustee add another Steward if needed (only Steward can add new Validator, and only one)
+2. As Steward run command like this:
+```
+ledger node target=6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G client_port=9702 client_ip=10.255.255.255 alias=NewNode node_ip=10.0.0.10.255.255.255 node_port=9701 services=VALIDATOR blskey=zi65fRHZjK2R8wdJfDzeWVgcf9imXUsMSEY64LQ4HyhDMsSn3Br1vhnwXHE7NyGjxVnwx4FGPqxpzY8HrQ2PnrL9tu4uD34rjgPEnFXnsGAp8aF68R4CcfsmUXfuU51hogE7dZCvaF9GPou86EWrTKpW5ow3ifq16Swpn5nKMXHTKj
+```
+- `alias` specifies unique Node name
+- `target` specifies public key from `init_indy_node` script
+- `blskey` specifies BLS key from `init_indy_node` script
+
+## Make sure that Node is workable
+
+Do `systemctl restart indy-node` and verify that node completed catch-up successfully ",,2018-08-21 12:59:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211174174,https://github.com/hyperledger/indy-node/pull/903#discussion_r211174174,ashcherbakov
https://github.com/hyperledger/indy-node/pull/903,https://github.com/hyperledger/indy-node/pull/903,We probably need to mention `blskey_pop` as well,0bd1986e40aeb5ed58036c5cbd70271e02d2ac2e,2018-08-20 08:13:04,211174325,"@@ -0,0 +1,38 @@
+# Add Node to Existing Pool
+
+## Node preparation
+
+1. Add this files from running node:
+```
+/var/lib/indy/network_name/pool_transactions_genesis
+/var/lib/indy/network_name/domain_transactions_genesis
+```
+
+2. Initialize keys, aliases and ports on new nodes using init_indy_node script.
+Example:
+```
+sudo su - indy -c ""init_indy_node NewNode 0.0.0.0 9701 0.0.0.0 9702 0000000000000000000000000NewNode""
+```
+
+3. Starting the node the first time will read in the pool_transactions_sandbox and transactions_sandbox files into the ledger. It only reads it the one time so make sure the first are correct before starting the service.
+```
+sudo systemctl start indy-node
+sudo systemctl status indy-node
+sudo systemctl enable indy-node
+```
+
+## Add Node to the Pool
+
+1. As Trustee add another Steward if needed (only Steward can add new Validator, and only one)
+2. As Steward run command like this:
+```
+ledger node target=6G9QhQa3HWjRKeRmEvEkLbWWf2t7cw6KLtafzi494G4G client_port=9702 client_ip=10.255.255.255 alias=NewNode node_ip=10.0.0.10.255.255.255 node_port=9701 services=VALIDATOR blskey=zi65fRHZjK2R8wdJfDzeWVgcf9imXUsMSEY64LQ4HyhDMsSn3Br1vhnwXHE7NyGjxVnwx4FGPqxpzY8HrQ2PnrL9tu4uD34rjgPEnFXnsGAp8aF68R4CcfsmUXfuU51hogE7dZCvaF9GPou86EWrTKpW5ow3ifq16Swpn5nKMXHTKj",,2018-08-21 12:59:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/211174325,https://github.com/hyperledger/indy-node/pull/903#discussion_r211174325,ashcherbakov
https://github.com/hyperledger/indy-node/pull/896,https://github.com/hyperledger/indy-node/pull/896,Add space between # and Current network to make flake8 happy,dd28a182e67193074283a955bd44deaf305f0d7e,2018-08-16 09:13:54,210527860,"@@ -0,0 +1,26 @@
+#Current network",,2018-08-16 09:17:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/210527860,https://github.com/hyperledger/indy-node/pull/896#discussion_r210527860,skhoroshavin
https://github.com/hyperledger/indy-node/pull/895,https://github.com/hyperledger/indy-node/pull/895,"For now it may be better to have a hard-coded constant here, so that we can provide the script as is for debug purposes to test pools without a need to re-install IndyNode.
Add a TODO comment to get rid of the constant.",9f3f81667d58c67793757dc66f910200452bd9e4,2018-08-14 13:33:39,209952131,"@@ -89,6 +88,7 @@ def get_ledger_dir(node_name, client_name, network):
 
 def get_storage(type_, ledger_data_dir):
     config = getConfig()
+    postfix = config.transactions_file_base_postfix",,2018-08-14 13:48:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/209952131,https://github.com/hyperledger/indy-node/pull/895#discussion_r209952131,ashcherbakov
https://github.com/hyperledger/indy-node/pull/895,https://github.com/hyperledger/indy-node/pull/895,"Can't we just get the list of `additional_storages` by something like
```
additional_storages = [dir_name[:dir_name.find(postfix) for dir_name in os.listdir(ledger_data_dir) if postfix in dir_name]
```",9f3f81667d58c67793757dc66f910200452bd9e4,2018-08-14 13:36:22,209953076,"@@ -109,6 +111,20 @@ def get_storage(type_, ledger_data_dir):
                                 read_only=True)
 
 
+def get_additional_storages(ledger_data_dir):
+    config = getConfig()
+    postfix = config.transactions_file_base_postfix
+
+    additional_storages = []
+    dir_names = [name for name in os.listdir(ledger_data_dir)",,2018-08-14 13:48:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/209953076,https://github.com/hyperledger/indy-node/pull/895#discussion_r209953076,ashcherbakov
https://github.com/hyperledger/indy-node/pull/895,https://github.com/hyperledger/indy-node/pull/895,ok,9f3f81667d58c67793757dc66f910200452bd9e4,2018-08-14 13:37:52,209953628,"@@ -89,6 +88,7 @@ def get_ledger_dir(node_name, client_name, network):
 
 def get_storage(type_, ledger_data_dir):
     config = getConfig()
+    postfix = config.transactions_file_base_postfix",,2018-08-14 13:48:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/209953628,https://github.com/hyperledger/indy-node/pull/895#discussion_r209953628,ArtObr
https://github.com/hyperledger/indy-node/pull/895,https://github.com/hyperledger/indy-node/pull/895,ok,9f3f81667d58c67793757dc66f910200452bd9e4,2018-08-14 13:41:34,209954951,"@@ -109,6 +111,20 @@ def get_storage(type_, ledger_data_dir):
                                 read_only=True)
 
 
+def get_additional_storages(ledger_data_dir):
+    config = getConfig()
+    postfix = config.transactions_file_base_postfix
+
+    additional_storages = []
+    dir_names = [name for name in os.listdir(ledger_data_dir)",,2018-08-14 13:48:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/209954951,https://github.com/hyperledger/indy-node/pull/895#discussion_r209954951,ArtObr
https://github.com/hyperledger/indy-node/pull/891,https://github.com/hyperledger/indy-node/pull/891,"Would be great to add `#! /usr/bin/env python3` as a first line, make file executable and remove `.py` extensions to make it more like other scripts",cc4f871f32df4ee2b1c3d74fb15e24cc78d015fe,2018-08-13 09:52:56,209550955,"@@ -0,0 +1,72 @@
+from matplotlib import pyplot as plt",,2018-08-13 10:53:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/209550955,https://github.com/hyperledger/indy-node/pull/891#discussion_r209550955,skhoroshavin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,"`Upgrader.getVersion()` already handles package name, doesn't it?",714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 10:19:22,207841294,"@@ -55,6 +57,20 @@ def _doStaticValidationPoolUpgrade(self, identifier, reqId, operation):
 
         # TODO: Check if cancel is submitted before start
 
+    def curr_pkt_info(self, pkg_name):
+        if pkg_name == ""indy-node"":
+            return Upgrader.getVersion(), [""indy-node""]",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207841294,https://github.com/hyperledger/indy-node/pull/869#discussion_r207841294,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,"Please use a constant with ""indy-node"" value",714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 10:29:10,207843919,"@@ -55,6 +57,20 @@ def _doStaticValidationPoolUpgrade(self, identifier, reqId, operation):
 
         # TODO: Check if cancel is submitted before start
 
+    def curr_pkt_info(self, pkg_name):
+        if pkg_name == ""indy-node"":",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207843919,https://github.com/hyperledger/indy-node/pull/869#discussion_r207843919,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,Are we going to call 3d party tools to get dependencies during the static validation? I'm not sure that this is a good option...,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:23:29,207931630,"@@ -55,6 +57,20 @@ def _doStaticValidationPoolUpgrade(self, identifier, reqId, operation):
 
         # TODO: Check if cancel is submitted before start
 
+    def curr_pkt_info(self, pkg_name):
+        if pkg_name == ""indy-node"":
+            return Upgrader.getVersion(), [""indy-node""]
+        return NodeControlUtil.curr_pkt_info(pkg_name)
+
+    def get_dependencies(self, pkg_name, version):
+        base_deps = [""indy-node"", ""indy-plenum""]
+        if pkg_name == ""indy-node"":
+            return base_deps
+        deps = []
+        NodeControlUtil.dep_tree_traverse(",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207931630,https://github.com/hyperledger/indy-node/pull/869#discussion_r207931630,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,"`curr_pkt_info` returns a version only, doesn't it?",714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:24:48,207932072,"@@ -70,7 +86,23 @@ def validate(self, req: Request):
                 req.reqId,
                 ""Nym {} not added to the ledger yet"".format(origin))
         if typ == POOL_UPGRADE:
-            currentVersion = Upgrader.getVersion()
+            pkt_to_upgrade = req.operation.get(PACKAGE, getConfig().UPGRADE_ENTRY)
+            if pkt_to_upgrade:
+                currentVersion, cur_deps = self.curr_pkt_info(pkt_to_upgrade)",51,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207932072,https://github.com/hyperledger/indy-node/pull/869#discussion_r207932072,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,Why is it removed?,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:26:32,207932722,"@@ -9,7 +9,6 @@ def transform(tool):
 
     nct = NCT(backup_dir=tdir, backup_target=tdir, transform=transform)
     try:
-        assert nct.tool.ext_upgrade is False",4,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207932722,https://github.com/hyperledger/indy-node/pull/869#discussion_r207932722,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,Why is it removed?,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:26:46,207932806,"@@ -32,7 +32,6 @@ def transform(tool):
     try:
         assert EXT_PKT_VERSION, EXT_PKT_DEPS == nct.tool._ext_info()
         nct.tool._ext_init()
-        assert nct.tool.ext_upgrade is True",4,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207932806,https://github.com/hyperledger/indy-node/pull/869#discussion_r207932806,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,Why is it always from config? Why not from POOL_UPGRADE command?,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:30:07,207934267,"@@ -45,7 +42,7 @@ def __init__(
         self.config = config or getConfig()
 
         assert self.config.UPGRADE_ENTRY, ""UPGRADE_ENTRY config parameter must be set""
-        self.ext_upgrade = self.config.UPGRADE_ENTRY not in PACKAGES_TO_HOLD
+        self.upgrade_entry = self.config.UPGRADE_ENTRY",28,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207934267,https://github.com/hyperledger/indy-node/pull/869#discussion_r207934267,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,Do we have a test when package name is not equal to indy-node? Can we have all existing tests parametrized so that we test both indy-node and a custom package?  ,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:35:15,207936058,"@@ -55,6 +57,20 @@ def _doStaticValidationPoolUpgrade(self, identifier, reqId, operation):
 
         # TODO: Check if cancel is submitted before start
 
+    def curr_pkt_info(self, pkg_name):
+        if pkg_name == ""indy-node"":",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207936058,https://github.com/hyperledger/indy-node/pull/869#discussion_r207936058,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,only indy-node version is handled by default. to get top level package version we need to ask packet manager,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:43:57,207939201,"@@ -55,6 +57,20 @@ def _doStaticValidationPoolUpgrade(self, identifier, reqId, operation):
 
         # TODO: Check if cancel is submitted before start
 
+    def curr_pkt_info(self, pkg_name):
+        if pkg_name == ""indy-node"":
+            return Upgrader.getVersion(), [""indy-node""]",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207939201,https://github.com/hyperledger/indy-node/pull/869#discussion_r207939201,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,"yes we are for now. if we do not check it here will need to check it during the upgrade and raise ex, but we just told that txn was validated and fine... I think it could be strange for user...
But I don't mind to remove it. Should I?",714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:47:12,207940325,"@@ -55,6 +57,20 @@ def _doStaticValidationPoolUpgrade(self, identifier, reqId, operation):
 
         # TODO: Check if cancel is submitted before start
 
+    def curr_pkt_info(self, pkg_name):
+        if pkg_name == ""indy-node"":
+            return Upgrader.getVersion(), [""indy-node""]
+        return NodeControlUtil.curr_pkt_info(pkg_name)
+
+    def get_dependencies(self, pkg_name, version):
+        base_deps = [""indy-node"", ""indy-plenum""]
+        if pkg_name == ""indy-node"":
+            return base_deps
+        deps = []
+        NodeControlUtil.dep_tree_traverse(",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207940325,https://github.com/hyperledger/indy-node/pull/869#discussion_r207940325,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,version and list of dependencies ,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:47:51,207940562,"@@ -70,7 +86,23 @@ def validate(self, req: Request):
                 req.reqId,
                 ""Nym {} not added to the ledger yet"".format(origin))
         if typ == POOL_UPGRADE:
-            currentVersion = Upgrader.getVersion()
+            pkt_to_upgrade = req.operation.get(PACKAGE, getConfig().UPGRADE_ENTRY)
+            if pkt_to_upgrade:
+                currentVersion, cur_deps = self.curr_pkt_info(pkt_to_upgrade)",51,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207940562,https://github.com/hyperledger/indy-node/pull/869#discussion_r207940562,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,flag was removed from the class at all,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:48:24,207940720,"@@ -9,7 +9,6 @@ def transform(tool):
 
     nct = NCT(backup_dir=tdir, backup_target=tdir, transform=transform)
     try:
-        assert nct.tool.ext_upgrade is False",4,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207940720,https://github.com/hyperledger/indy-node/pull/869#discussion_r207940720,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,flag was removed from the class at all,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:48:34,207940770,"@@ -32,7 +32,6 @@ def transform(tool):
     try:
         assert EXT_PKT_VERSION, EXT_PKT_DEPS == nct.tool._ext_info()
         nct.tool._ext_init()
-        assert nct.tool.ext_upgrade is True",4,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207940770,https://github.com/hyperledger/indy-node/pull/869#discussion_r207940770,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,this is initialization stage. proper name will be provided by the node via upgrade message,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:49:48,207941193,"@@ -45,7 +42,7 @@ def __init__(
         self.config = config or getConfig()
 
         assert self.config.UPGRADE_ENTRY, ""UPGRADE_ENTRY config parameter must be set""
-        self.ext_upgrade = self.config.UPGRADE_ENTRY not in PACKAGES_TO_HOLD
+        self.upgrade_entry = self.config.UPGRADE_ENTRY",28,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207941193,https://github.com/hyperledger/indy-node/pull/869#discussion_r207941193,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,we have some,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-06 15:50:30,207941418,"@@ -55,6 +57,20 @@ def _doStaticValidationPoolUpgrade(self, identifier, reqId, operation):
 
         # TODO: Check if cancel is submitted before start
 
+    def curr_pkt_info(self, pkg_name):
+        if pkg_name == ""indy-node"":",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207941418,https://github.com/hyperledger/indy-node/pull/869#discussion_r207941418,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,Can we check that it equals to `init_len  + 1`?,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 08:25:39,208496649,"@@ -40,11 +40,13 @@ def patched_process_request(request: Request, frm: str):
     slow_node.nodeMsgRouter.routes[Propagate] = patched_process_propagate
     slow_node.clientMsgRouter.routes[Request] = patched_process_request
 
+    init_len = len(list(slow_node.upgrader._actionLog))
+
     sdk_ensure_upgrade_sent(looper, sdk_pool_handle, sdk_wallet_trustee,
                             validUpgradeExpForceTrue)
 
     looper.runFor(waits.expectedUpgradeScheduled())
 
     checkUpgradeScheduled([slow_node], validUpgradeExpForceTrue[VERSION])
-    assert len(list(slow_node.upgrader._actionLog)) == 1
+    assert len(list(slow_node.upgrader._actionLog)) > init_len",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208496649,https://github.com/hyperledger/indy-node/pull/869#discussion_r208496649,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,"It looks like it can be moved to a helper method, as there are other tests with the same mocking.
Also it's better to have it one place when we will support other platforms (not depend on dpkg).",714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 08:40:15,208500910,"@@ -16,46 +19,89 @@ def nodeIds(nodeSet):
     return nodeSet[0].poolManager.nodeIds
 
 
-@pytest.fixture(scope='module')
-def validUpgrade(nodeIds, tconf):
+EXT_PKT_NAME = 'SomeTopLevelPkt'
+
+@pytest.fixture(scope='function', params=[EXT_PKT_NAME, APP_NAME])
+def validUpgrade(nodeIds, tconf, monkeypatch, request):
     schedule = {}
     unow = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
     startAt = unow + timedelta(seconds=100)
     acceptableDiff = tconf.MinSepBetweenNodeUpgrades + 1
     for i in nodeIds:
         schedule[i] = datetime.isoformat(startAt)
         startAt = startAt + timedelta(seconds=acceptableDiff + 3)
-    return dict(name='upgrade-13', version=bumpedVersion(), action=START,
-                schedule=schedule,
-                # sha256=get_valid_code_hash(),
+
+    vers = None
+
+    if request.param != APP_NAME:
+        EXT_PKT_VERSION = '7.88.999'",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208500910,https://github.com/hyperledger/indy-node/pull/869#discussion_r208500910,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,It looks like we use the same lambda in all (or most) of the tests. Maybe move it to a helper method (or extend `count_action_log_entries`)?,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 08:41:34,208501325,"@@ -32,6 +32,6 @@ def test_forced_upgrade_handled_once_if_ordered_and_then_request_received(
     looper.runFor(waits.expectedUpgradeScheduled())
 
     checkUpgradeScheduled([slow_node], validUpgradeExpForceTrue[VERSION])
-    assert len(list(slow_node.upgrader._actionLog)) == 1
-    assert slow_node.upgrader._actionLog.lastEvent[1] == \
-           UpgradeLog.SCHEDULED
+    assert count_action_log_entries(list(slow_node.upgrader._actionLog),",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208501325,https://github.com/hyperledger/indy-node/pull/869#discussion_r208501325,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,`upgr1[VERSION]` twice?,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 08:43:07,208501823,"@@ -4,16 +4,16 @@
 from stp_core.loop.eventually import eventually
 from plenum.common.constants import VERSION
 
-from indy_node.test.upgrade.helper import codeVersion, checkUpgradeScheduled, \
-    sdk_ensure_upgrade_sent
+from indy_node.test.upgrade.helper import checkUpgradeScheduled, \
+    sdk_ensure_upgrade_sent, lowerVersion
 from indy_common.constants import REINSTALL
 
 
 def test_do_upgrade_to_the_same_version_if_reinstall(looper, tconf, nodeSet,
                                                      validUpgrade, sdk_pool_handle,
                                                      sdk_wallet_trustee):
     upgr1 = deepcopy(validUpgrade)
-    upgr1[VERSION] = codeVersion()
+    upgr1[VERSION] = upgr1[VERSION] = lowerVersion(validUpgrade['version'])",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208501823,https://github.com/hyperledger/indy-node/pull/869#discussion_r208501823,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,Please add a test where package name is not specified (a default value should be used),714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 09:01:53,208507620,"@@ -100,9 +100,8 @@ def test_force_false_upgrade(
 ",2,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208507620,https://github.com/hyperledger/indy-node/pull/869#discussion_r208507620,ashcherbakov
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,done,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 09:04:43,208508463,"@@ -4,16 +4,16 @@
 from stp_core.loop.eventually import eventually
 from plenum.common.constants import VERSION
 
-from indy_node.test.upgrade.helper import codeVersion, checkUpgradeScheduled, \
-    sdk_ensure_upgrade_sent
+from indy_node.test.upgrade.helper import checkUpgradeScheduled, \
+    sdk_ensure_upgrade_sent, lowerVersion
 from indy_common.constants import REINSTALL
 
 
 def test_do_upgrade_to_the_same_version_if_reinstall(looper, tconf, nodeSet,
                                                      validUpgrade, sdk_pool_handle,
                                                      sdk_wallet_trustee):
     upgr1 = deepcopy(validUpgrade)
-    upgr1[VERSION] = codeVersion()
+    upgr1[VERSION] = upgr1[VERSION] = lowerVersion(validUpgrade['version'])",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208508463,https://github.com/hyperledger/indy-node/pull/869#discussion_r208508463,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,done,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 09:31:57,208516305,"@@ -40,11 +40,13 @@ def patched_process_request(request: Request, frm: str):
     slow_node.nodeMsgRouter.routes[Propagate] = patched_process_propagate
     slow_node.clientMsgRouter.routes[Request] = patched_process_request
 
+    init_len = len(list(slow_node.upgrader._actionLog))
+
     sdk_ensure_upgrade_sent(looper, sdk_pool_handle, sdk_wallet_trustee,
                             validUpgradeExpForceTrue)
 
     looper.runFor(waits.expectedUpgradeScheduled())
 
     checkUpgradeScheduled([slow_node], validUpgradeExpForceTrue[VERSION])
-    assert len(list(slow_node.upgrader._actionLog)) == 1
+    assert len(list(slow_node.upgrader._actionLog)) > init_len",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208516305,https://github.com/hyperledger/indy-node/pull/869#discussion_r208516305,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,done,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 09:38:32,208518128,"@@ -32,6 +32,6 @@ def test_forced_upgrade_handled_once_if_ordered_and_then_request_received(
     looper.runFor(waits.expectedUpgradeScheduled())
 
     checkUpgradeScheduled([slow_node], validUpgradeExpForceTrue[VERSION])
-    assert len(list(slow_node.upgrader._actionLog)) == 1
-    assert slow_node.upgrader._actionLog.lastEvent[1] == \
-           UpgradeLog.SCHEDULED
+    assert count_action_log_entries(list(slow_node.upgrader._actionLog),",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208518128,https://github.com/hyperledger/indy-node/pull/869#discussion_r208518128,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,done,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 11:06:10,208540891,"@@ -16,46 +19,89 @@ def nodeIds(nodeSet):
     return nodeSet[0].poolManager.nodeIds
 
 
-@pytest.fixture(scope='module')
-def validUpgrade(nodeIds, tconf):
+EXT_PKT_NAME = 'SomeTopLevelPkt'
+
+@pytest.fixture(scope='function', params=[EXT_PKT_NAME, APP_NAME])
+def validUpgrade(nodeIds, tconf, monkeypatch, request):
     schedule = {}
     unow = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
     startAt = unow + timedelta(seconds=100)
     acceptableDiff = tconf.MinSepBetweenNodeUpgrades + 1
     for i in nodeIds:
         schedule[i] = datetime.isoformat(startAt)
         startAt = startAt + timedelta(seconds=acceptableDiff + 3)
-    return dict(name='upgrade-13', version=bumpedVersion(), action=START,
-                schedule=schedule,
-                # sha256=get_valid_code_hash(),
+
+    vers = None
+
+    if request.param != APP_NAME:
+        EXT_PKT_VERSION = '7.88.999'",,2018-08-08 11:08:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208540891,https://github.com/hyperledger/indy-node/pull/869#discussion_r208540891,dsurnin
https://github.com/hyperledger/indy-node/pull/869,https://github.com/hyperledger/indy-node/pull/869,there are several tests which use send_upgrade_cmd func - it uses default for package parameter,714499ee4f0b35d378971df64602d323949b5b7c,2018-08-08 11:14:08,208542701,"@@ -100,9 +100,8 @@ def test_force_false_upgrade(
 ",2,2018-08-08 11:14:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208542701,https://github.com/hyperledger/indy-node/pull/869#discussion_r208542701,dsurnin
https://github.com/hyperledger/indy-node/pull/868,https://github.com/hyperledger/indy-node/pull/868,"If the scripts need to be installed with the node package, they should be added to `setup.py` (`scripts` field).",b5e64956f83badd23df6d2d4372781e52b275536,2018-08-06 07:53:43,207801361,"@@ -0,0 +1,138 @@
+#!/usr/bin/python3
+",2,2018-08-06 07:53:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207801361,https://github.com/hyperledger/indy-node/pull/868#discussion_r207801361,ashcherbakov
https://github.com/hyperledger/indy-node/pull/867,https://github.com/hyperledger/indy-node/pull/867,This method should be implemented in RGSeqReqs as well to allow payment reqs be notified in case of grouped reqs,7f0147552921acfa03cf98da97161052997571fb,2018-08-06 07:58:44,207802667,"@@ -265,6 +304,9 @@ def _gen_req_data(self):
     async def on_batch_completed(self, pool_handle, wallet_handle, submitter_did):
         pass
 
+    async def on_request_replied(self, req, resp_or_exp):",118,2018-08-07 11:15:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207802667,https://github.com/hyperledger/indy-node/pull/867#discussion_r207802667,dsurnin
https://github.com/hyperledger/indy-node/pull/867,https://github.com/hyperledger/indy-node/pull/867,Done.,7f0147552921acfa03cf98da97161052997571fb,2018-08-07 08:06:39,208134700,"@@ -265,6 +304,9 @@ def _gen_req_data(self):
     async def on_batch_completed(self, pool_handle, wallet_handle, submitter_did):
         pass
 
+    async def on_request_replied(self, req, resp_or_exp):",118,2018-08-07 11:15:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208134700,https://github.com/hyperledger/indy-node/pull/867#discussion_r208134700,spivachuk
https://github.com/hyperledger/indy-node/pull/867,https://github.com/hyperledger/indy-node/pull/867,"Should we add this to `create_req_generator`?
",7f0147552921acfa03cf98da97161052997571fb,2018-08-07 08:48:26,208147088,"@@ -608,14 +661,260 @@ class RGGetRevocRegDelta(RGGetEntryRevoc):
         return req
 
 
+class RGBasePayment(RequestGenerator, metaclass=ABCMeta):
+    TRUSTEE_ROLE_CODE = ""0""
+
+    DEFAULT_PAYMENT_METHOD = ""sov""
+    DEFAULT_PAYMENT_ADDRS_COUNT = 10
+
+    NUMBER_OF_TRUSTEES_FOR_MINT = 4
+    MINT_RECIPIENTS_LIMIT = 100
+    AMOUNT_LIMIT = 100
+
+    def __init__(self, *args,
+                 payment_method=DEFAULT_PAYMENT_METHOD,
+                 payment_addrs_count=DEFAULT_PAYMENT_ADDRS_COUNT,
+                 **kwargs):
+
+        super().__init__(*args, **kwargs)
+
+        init_libsovtoken_once()
+
+        self._pool_handle = None
+        self._wallet_handle = None
+        self._submitter_did = None
+
+        self._payment_method = payment_method
+        self._payment_addrs_count = payment_addrs_count
+        self._payment_addresses = []
+
+    async def on_pool_create(self, pool_handle, wallet_handle, submitter_did, *args, **kwargs):
+        await super().on_pool_create(pool_handle, wallet_handle, submitter_did, *args, **kwargs)
+
+        self._pool_handle = pool_handle
+        self._wallet_handle = wallet_handle
+        self._submitter_did = submitter_did
+
+        await self.__ensure_submitter_is_trustee()
+        additional_trustees_dids = await self.__create_additional_trustees()
+        await self.__create_payment_addresses()
+        for payment_addrs_chunk in divide_sequence_into_chunks(self._payment_addresses,
+                                                               RGBasePayment.MINT_RECIPIENTS_LIMIT):
+            await self.__mint_sources(payment_addrs_chunk, [self._submitter_did, *additional_trustees_dids])
+
+    async def __ensure_submitter_is_trustee(self):
+        get_nym_req = await ledger.build_get_nym_request(self._submitter_did, self._submitter_did)
+        get_nym_resp = await ledger.sign_and_submit_request(self._pool_handle,
+                                                            self._wallet_handle,
+                                                            self._submitter_did,
+                                                            get_nym_req)
+        get_nym_resp_obj = json.loads(get_nym_resp)
+        ensure_is_reply(get_nym_resp_obj)
+        res_data = json.loads(get_nym_resp_obj[""result""][""data""])
+        if res_data[""role""] != RGBasePayment.TRUSTEE_ROLE_CODE:
+            raise Exception(""Submitter role must be TRUSTEE since ""
+                            ""submitter have to create additional trustees to mint sources."")
+
+    async def __create_additional_trustees(self):
+        trustee_dids = []
+
+        for i in range(RGBasePayment.NUMBER_OF_TRUSTEES_FOR_MINT - 1):
+            tr_did, tr_verkey = await did.create_and_store_my_did(self._wallet_handle, '{}')
+
+            nym_req = await ledger.build_nym_request(self._submitter_did, tr_did, tr_verkey, None, ""TRUSTEE"")
+            nym_resp = await ledger.sign_and_submit_request(self._pool_handle,
+                                                            self._wallet_handle,
+                                                            self._submitter_did, nym_req)
+            ensure_is_reply(nym_resp)
+
+            trustee_dids.append(tr_did)
+
+        return trustee_dids
+
+    async def __create_payment_addresses(self):
+        for i in range(self._payment_addrs_count):
+            self._payment_addresses.append(
+                await payment.create_payment_address(self._wallet_handle, self._payment_method, '{}'))
+
+    async def __mint_sources(self, payment_addresses, trustees_dids):
+        outputs = []
+        for payment_address in payment_addresses:
+            outputs.append({""recipient"": payment_address, ""amount"": random.randint(1, RGBasePayment.AMOUNT_LIMIT)})
+
+        mint_req, _ = await payment.build_mint_req(self._wallet_handle,
+                                                   self._submitter_did,
+                                                   json.dumps(outputs),
+                                                   None)
+
+        for trustee_did in trustees_dids:
+            mint_req = await ledger.multi_sign_request(self._wallet_handle, trustee_did, mint_req)
+
+        mint_resp = await ledger.submit_request(self._pool_handle, mint_req)
+        ensure_is_reply(mint_resp)
+
+    async def _get_payment_sources(self, payment_address):
+        get_payment_sources_req, _ = \
+            await payment.build_get_payment_sources_request(self._wallet_handle,
+                                                            self._submitter_did,
+                                                            payment_address)
+        get_payment_sources_resp = \
+            await ledger.sign_and_submit_request(self._pool_handle,
+                                                 self._wallet_handle,
+                                                 self._submitter_did,
+                                                 get_payment_sources_req)
+        ensure_is_reply(get_payment_sources_resp)
+
+        source_infos_json = \
+            await payment.parse_get_payment_sources_response(self._payment_method,
+                                                             get_payment_sources_resp)
+        source_infos = json.loads(source_infos_json)
+        payment_sources = []
+        for source_info in source_infos:
+            payment_sources.append((source_info[""source""], source_info[""amount""]))
+        return payment_sources
+
+
+class RGGetPaymentSources(RGBasePayment):
+    def _gen_req_data(self):
+        return random.choice(self._payment_addresses)
+
+    async def _gen_req(self, submit_did, req_data):
+        payment_address = req_data
+        req, _ = await payment.build_get_payment_sources_request(self._wallet_handle,
+                                                                 self._submitter_did,
+                                                                 payment_address)
+        return req
+
+
+class RGPayment(RGBasePayment):",284,2018-08-07 11:15:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208147088,https://github.com/hyperledger/indy-node/pull/867#discussion_r208147088,ashcherbakov
https://github.com/hyperledger/indy-node/pull/867,https://github.com/hyperledger/indy-node/pull/867,Please extend docs with Payment requests (write a how-to send payment txns).,7f0147552921acfa03cf98da97161052997571fb,2018-08-07 08:48:59,208147269,"@@ -608,14 +661,260 @@ class RGGetRevocRegDelta(RGGetEntryRevoc):
         return req
 
 
+class RGBasePayment(RequestGenerator, metaclass=ABCMeta):
+    TRUSTEE_ROLE_CODE = ""0""
+
+    DEFAULT_PAYMENT_METHOD = ""sov""
+    DEFAULT_PAYMENT_ADDRS_COUNT = 10
+
+    NUMBER_OF_TRUSTEES_FOR_MINT = 4
+    MINT_RECIPIENTS_LIMIT = 100
+    AMOUNT_LIMIT = 100
+
+    def __init__(self, *args,
+                 payment_method=DEFAULT_PAYMENT_METHOD,
+                 payment_addrs_count=DEFAULT_PAYMENT_ADDRS_COUNT,
+                 **kwargs):
+
+        super().__init__(*args, **kwargs)
+
+        init_libsovtoken_once()
+
+        self._pool_handle = None
+        self._wallet_handle = None
+        self._submitter_did = None
+
+        self._payment_method = payment_method
+        self._payment_addrs_count = payment_addrs_count
+        self._payment_addresses = []
+
+    async def on_pool_create(self, pool_handle, wallet_handle, submitter_did, *args, **kwargs):
+        await super().on_pool_create(pool_handle, wallet_handle, submitter_did, *args, **kwargs)
+
+        self._pool_handle = pool_handle
+        self._wallet_handle = wallet_handle
+        self._submitter_did = submitter_did
+
+        await self.__ensure_submitter_is_trustee()
+        additional_trustees_dids = await self.__create_additional_trustees()
+        await self.__create_payment_addresses()
+        for payment_addrs_chunk in divide_sequence_into_chunks(self._payment_addresses,
+                                                               RGBasePayment.MINT_RECIPIENTS_LIMIT):
+            await self.__mint_sources(payment_addrs_chunk, [self._submitter_did, *additional_trustees_dids])
+
+    async def __ensure_submitter_is_trustee(self):
+        get_nym_req = await ledger.build_get_nym_request(self._submitter_did, self._submitter_did)
+        get_nym_resp = await ledger.sign_and_submit_request(self._pool_handle,
+                                                            self._wallet_handle,
+                                                            self._submitter_did,
+                                                            get_nym_req)
+        get_nym_resp_obj = json.loads(get_nym_resp)
+        ensure_is_reply(get_nym_resp_obj)
+        res_data = json.loads(get_nym_resp_obj[""result""][""data""])
+        if res_data[""role""] != RGBasePayment.TRUSTEE_ROLE_CODE:
+            raise Exception(""Submitter role must be TRUSTEE since ""
+                            ""submitter have to create additional trustees to mint sources."")
+
+    async def __create_additional_trustees(self):
+        trustee_dids = []
+
+        for i in range(RGBasePayment.NUMBER_OF_TRUSTEES_FOR_MINT - 1):
+            tr_did, tr_verkey = await did.create_and_store_my_did(self._wallet_handle, '{}')
+
+            nym_req = await ledger.build_nym_request(self._submitter_did, tr_did, tr_verkey, None, ""TRUSTEE"")
+            nym_resp = await ledger.sign_and_submit_request(self._pool_handle,
+                                                            self._wallet_handle,
+                                                            self._submitter_did, nym_req)
+            ensure_is_reply(nym_resp)
+
+            trustee_dids.append(tr_did)
+
+        return trustee_dids
+
+    async def __create_payment_addresses(self):
+        for i in range(self._payment_addrs_count):
+            self._payment_addresses.append(
+                await payment.create_payment_address(self._wallet_handle, self._payment_method, '{}'))
+
+    async def __mint_sources(self, payment_addresses, trustees_dids):
+        outputs = []
+        for payment_address in payment_addresses:
+            outputs.append({""recipient"": payment_address, ""amount"": random.randint(1, RGBasePayment.AMOUNT_LIMIT)})
+
+        mint_req, _ = await payment.build_mint_req(self._wallet_handle,
+                                                   self._submitter_did,
+                                                   json.dumps(outputs),
+                                                   None)
+
+        for trustee_did in trustees_dids:
+            mint_req = await ledger.multi_sign_request(self._wallet_handle, trustee_did, mint_req)
+
+        mint_resp = await ledger.submit_request(self._pool_handle, mint_req)
+        ensure_is_reply(mint_resp)
+
+    async def _get_payment_sources(self, payment_address):
+        get_payment_sources_req, _ = \
+            await payment.build_get_payment_sources_request(self._wallet_handle,
+                                                            self._submitter_did,
+                                                            payment_address)
+        get_payment_sources_resp = \
+            await ledger.sign_and_submit_request(self._pool_handle,
+                                                 self._wallet_handle,
+                                                 self._submitter_did,
+                                                 get_payment_sources_req)
+        ensure_is_reply(get_payment_sources_resp)
+
+        source_infos_json = \
+            await payment.parse_get_payment_sources_response(self._payment_method,
+                                                             get_payment_sources_resp)
+        source_infos = json.loads(source_infos_json)
+        payment_sources = []
+        for source_info in source_infos:
+            payment_sources.append((source_info[""source""], source_info[""amount""]))
+        return payment_sources
+
+",271,2018-08-07 11:15:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208147269,https://github.com/hyperledger/indy-node/pull/867#discussion_r208147269,ashcherbakov
https://github.com/hyperledger/indy-node/pull/867,https://github.com/hyperledger/indy-node/pull/867,Added missed entries to the map.,7f0147552921acfa03cf98da97161052997571fb,2018-08-07 11:16:26,208190324,"@@ -608,14 +661,260 @@ class RGGetRevocRegDelta(RGGetEntryRevoc):
         return req
 
 
+class RGBasePayment(RequestGenerator, metaclass=ABCMeta):
+    TRUSTEE_ROLE_CODE = ""0""
+
+    DEFAULT_PAYMENT_METHOD = ""sov""
+    DEFAULT_PAYMENT_ADDRS_COUNT = 10
+
+    NUMBER_OF_TRUSTEES_FOR_MINT = 4
+    MINT_RECIPIENTS_LIMIT = 100
+    AMOUNT_LIMIT = 100
+
+    def __init__(self, *args,
+                 payment_method=DEFAULT_PAYMENT_METHOD,
+                 payment_addrs_count=DEFAULT_PAYMENT_ADDRS_COUNT,
+                 **kwargs):
+
+        super().__init__(*args, **kwargs)
+
+        init_libsovtoken_once()
+
+        self._pool_handle = None
+        self._wallet_handle = None
+        self._submitter_did = None
+
+        self._payment_method = payment_method
+        self._payment_addrs_count = payment_addrs_count
+        self._payment_addresses = []
+
+    async def on_pool_create(self, pool_handle, wallet_handle, submitter_did, *args, **kwargs):
+        await super().on_pool_create(pool_handle, wallet_handle, submitter_did, *args, **kwargs)
+
+        self._pool_handle = pool_handle
+        self._wallet_handle = wallet_handle
+        self._submitter_did = submitter_did
+
+        await self.__ensure_submitter_is_trustee()
+        additional_trustees_dids = await self.__create_additional_trustees()
+        await self.__create_payment_addresses()
+        for payment_addrs_chunk in divide_sequence_into_chunks(self._payment_addresses,
+                                                               RGBasePayment.MINT_RECIPIENTS_LIMIT):
+            await self.__mint_sources(payment_addrs_chunk, [self._submitter_did, *additional_trustees_dids])
+
+    async def __ensure_submitter_is_trustee(self):
+        get_nym_req = await ledger.build_get_nym_request(self._submitter_did, self._submitter_did)
+        get_nym_resp = await ledger.sign_and_submit_request(self._pool_handle,
+                                                            self._wallet_handle,
+                                                            self._submitter_did,
+                                                            get_nym_req)
+        get_nym_resp_obj = json.loads(get_nym_resp)
+        ensure_is_reply(get_nym_resp_obj)
+        res_data = json.loads(get_nym_resp_obj[""result""][""data""])
+        if res_data[""role""] != RGBasePayment.TRUSTEE_ROLE_CODE:
+            raise Exception(""Submitter role must be TRUSTEE since ""
+                            ""submitter have to create additional trustees to mint sources."")
+
+    async def __create_additional_trustees(self):
+        trustee_dids = []
+
+        for i in range(RGBasePayment.NUMBER_OF_TRUSTEES_FOR_MINT - 1):
+            tr_did, tr_verkey = await did.create_and_store_my_did(self._wallet_handle, '{}')
+
+            nym_req = await ledger.build_nym_request(self._submitter_did, tr_did, tr_verkey, None, ""TRUSTEE"")
+            nym_resp = await ledger.sign_and_submit_request(self._pool_handle,
+                                                            self._wallet_handle,
+                                                            self._submitter_did, nym_req)
+            ensure_is_reply(nym_resp)
+
+            trustee_dids.append(tr_did)
+
+        return trustee_dids
+
+    async def __create_payment_addresses(self):
+        for i in range(self._payment_addrs_count):
+            self._payment_addresses.append(
+                await payment.create_payment_address(self._wallet_handle, self._payment_method, '{}'))
+
+    async def __mint_sources(self, payment_addresses, trustees_dids):
+        outputs = []
+        for payment_address in payment_addresses:
+            outputs.append({""recipient"": payment_address, ""amount"": random.randint(1, RGBasePayment.AMOUNT_LIMIT)})
+
+        mint_req, _ = await payment.build_mint_req(self._wallet_handle,
+                                                   self._submitter_did,
+                                                   json.dumps(outputs),
+                                                   None)
+
+        for trustee_did in trustees_dids:
+            mint_req = await ledger.multi_sign_request(self._wallet_handle, trustee_did, mint_req)
+
+        mint_resp = await ledger.submit_request(self._pool_handle, mint_req)
+        ensure_is_reply(mint_resp)
+
+    async def _get_payment_sources(self, payment_address):
+        get_payment_sources_req, _ = \
+            await payment.build_get_payment_sources_request(self._wallet_handle,
+                                                            self._submitter_did,
+                                                            payment_address)
+        get_payment_sources_resp = \
+            await ledger.sign_and_submit_request(self._pool_handle,
+                                                 self._wallet_handle,
+                                                 self._submitter_did,
+                                                 get_payment_sources_req)
+        ensure_is_reply(get_payment_sources_resp)
+
+        source_infos_json = \
+            await payment.parse_get_payment_sources_response(self._payment_method,
+                                                             get_payment_sources_resp)
+        source_infos = json.loads(source_infos_json)
+        payment_sources = []
+        for source_info in source_infos:
+            payment_sources.append((source_info[""source""], source_info[""amount""]))
+        return payment_sources
+
+
+class RGGetPaymentSources(RGBasePayment):
+    def _gen_req_data(self):
+        return random.choice(self._payment_addresses)
+
+    async def _gen_req(self, submit_did, req_data):
+        payment_address = req_data
+        req, _ = await payment.build_get_payment_sources_request(self._wallet_handle,
+                                                                 self._submitter_did,
+                                                                 payment_address)
+        return req
+
+
+class RGPayment(RGBasePayment):",284,2018-08-07 11:16:26,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/208190324,https://github.com/hyperledger/indy-node/pull/867#discussion_r208190324,spivachuk
https://github.com/hyperledger/indy-node/pull/860,https://github.com/hyperledger/indy-node/pull/860,This rule is only about creation of new NYMs with empty role (common users). What about other roles? We need to clarify the requirement.,8a6ebfb907546d13a9c7937383a86a619fdb7f00,2018-08-03 08:41:55,207478991,"@@ -67,7 +67,8 @@ def generate_auth_map(valid_roles, need_permission=None):
         '{}_<any>_<any>_<any>'.format(VALIDATOR_INFO):
             {TRUSTEE: [], STEWARD: []},
     }
-    if need_permission is False or (need_permission is None and not getConfig().WRITES_REQUIRE_TRUST_ANCHOR):
+    if anyone_can_write is True or (anyone_can_write is None and getConfig().ANYONE_CAN_WRITE):
+        auth_map['{}_role__'.format(NYM)][None] = []",15,2018-08-07 08:10:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207478991,https://github.com/hyperledger/indy-node/pull/860#discussion_r207478991,ashcherbakov
https://github.com/hyperledger/indy-node/pull/860,https://github.com/hyperledger/indy-node/pull/860,Why is it in `anoncreds` module?,8a6ebfb907546d13a9c7937383a86a619fdb7f00,2018-08-03 08:45:15,207479798,"@@ -0,0 +1,88 @@
+import json
+import pytest
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check, \
+    sdk_get_and_check_replies, sdk_sign_and_submit_req
+from plenum.common.exceptions import RequestRejectedException
+
+from indy_common.auth import Authoriser
+from indy.anoncreds import issuer_create_schema
+from indy.ledger import build_schema_request
+
+from indy_node.test.anon_creds.conftest import claim_def
+from indy_client.test.test_nym_attrib import attributeData, attributeName, attributeValue
+",,2018-08-07 08:10:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207479798,https://github.com/hyperledger/indy-node/pull/860#discussion_r207479798,ashcherbakov
https://github.com/hyperledger/indy-node/pull/860,https://github.com/hyperledger/indy-node/pull/860,It's better to move the checks for ATTRIBs into a separate test method. Keep tests as small as possible.,8a6ebfb907546d13a9c7937383a86a619fdb7f00,2018-08-03 08:47:31,207480435,"@@ -0,0 +1,88 @@
+import json
+import pytest
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check, \
+    sdk_get_and_check_replies, sdk_sign_and_submit_req
+from plenum.common.exceptions import RequestRejectedException
+
+from indy_common.auth import Authoriser
+from indy.anoncreds import issuer_create_schema
+from indy.ledger import build_schema_request
+
+from indy_node.test.anon_creds.conftest import claim_def
+from indy_client.test.test_nym_attrib import attributeData, attributeName, attributeValue
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    # We need to reset authorization map to set new authorization rules
+    Authoriser.auth_map = None
+    OLD_ANYONE_CAN_WRITE = tconf.ANYONE_CAN_WRITE
+    tconf.ANYONE_CAN_WRITE = True
+
+    yield tconf
+
+    tconf.ANYONE_CAN_WRITE = OLD_ANYONE_CAN_WRITE
+    Authoriser.auth_map = None
+
+
+def test_client_can_send_nym(looper,
+                             txnPoolNodeSet,
+                             sdk_wallet_client,
+                             sdk_wallet_trust_anchor,
+                             sdk_pool_handle,
+                             attributeData):
+    # client can create another client NYM when ANYONE_CAN_WRITE set to True
+    sdk_new_client_wallet = sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_client)
+    _, new_client_did = sdk_new_client_wallet
+
+    # client as an owner can add attribute to his NYM",,2018-08-07 08:10:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207480435,https://github.com/hyperledger/indy-node/pull/860#discussion_r207480435,ashcherbakov
https://github.com/hyperledger/indy-node/pull/860,https://github.com/hyperledger/indy-node/pull/860,What about revocation txns? Can client send them?,8a6ebfb907546d13a9c7937383a86a619fdb7f00,2018-08-03 08:48:18,207480674,"@@ -0,0 +1,88 @@
+import json
+import pytest
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check, \
+    sdk_get_and_check_replies, sdk_sign_and_submit_req
+from plenum.common.exceptions import RequestRejectedException
+
+from indy_common.auth import Authoriser
+from indy.anoncreds import issuer_create_schema
+from indy.ledger import build_schema_request
+
+from indy_node.test.anon_creds.conftest import claim_def
+from indy_client.test.test_nym_attrib import attributeData, attributeName, attributeValue
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    # We need to reset authorization map to set new authorization rules
+    Authoriser.auth_map = None
+    OLD_ANYONE_CAN_WRITE = tconf.ANYONE_CAN_WRITE
+    tconf.ANYONE_CAN_WRITE = True
+
+    yield tconf
+
+    tconf.ANYONE_CAN_WRITE = OLD_ANYONE_CAN_WRITE
+    Authoriser.auth_map = None
+
+
+def test_client_can_send_nym(looper,
+                             txnPoolNodeSet,
+                             sdk_wallet_client,
+                             sdk_wallet_trust_anchor,
+                             sdk_pool_handle,
+                             attributeData):
+    # client can create another client NYM when ANYONE_CAN_WRITE set to True
+    sdk_new_client_wallet = sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_client)
+    _, new_client_did = sdk_new_client_wallet
+
+    # client as an owner can add attribute to his NYM
+    sdk_add_attribute_and_check(looper, sdk_pool_handle, sdk_new_client_wallet,
+                                attributeData, new_client_did)
+
+    # another client or trust anchor cannot add attribute to another NYM
+    with pytest.raises(RequestRejectedException) as e:
+        sdk_add_attribute_and_check(looper, sdk_pool_handle, sdk_wallet_trust_anchor,
+                                    attributeData, new_client_did)
+    assert e.match('Only identity owner/guardian can add attribute for that identity')
+
+    with pytest.raises(RequestRejectedException) as e:
+        sdk_add_attribute_and_check(looper, sdk_pool_handle, sdk_wallet_client,
+                                    attributeData, new_client_did)
+    assert e.match('Only identity owner/guardian can add attribute for that identity')
+
+
+def test_client_can_send_schema(looper,
+                                txnPoolNodeSet,
+                                sdk_wallet_client,
+                                sdk_wallet_trust_anchor,
+                                sdk_pool_handle):
+    # Trust anchor can create schema in any case
+    _, identifier = sdk_wallet_trust_anchor
+    _, schema_json = looper.loop.run_until_complete(
+        issuer_create_schema(identifier, ""name"", ""1.0"", json.dumps([""first"", ""last""])))
+    request = looper.loop.run_until_complete(build_schema_request(identifier, schema_json))
+    sdk_get_and_check_replies(looper, [sdk_sign_and_submit_req(sdk_pool_handle, sdk_wallet_trust_anchor, request)])
+
+    # Client can create schema if ANYONE_CAN_WRITE flag set to False
+    _, identifier = sdk_wallet_client
+    _, schema_json = looper.loop.run_until_complete(
+        issuer_create_schema(identifier, ""name"", ""1.0"", json.dumps([""first"", ""last""])))
+    request = looper.loop.run_until_complete(build_schema_request(identifier, schema_json))
+    sdk_get_and_check_replies(looper, [sdk_sign_and_submit_req(sdk_pool_handle, sdk_wallet_client, request)])
+",,2018-08-07 08:10:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207480674,https://github.com/hyperledger/indy-node/pull/860#discussion_r207480674,ashcherbakov
https://github.com/hyperledger/indy-node/pull/860,https://github.com/hyperledger/indy-node/pull/860,"If any NYMs, SCHEMAs, CLAIM_DEFs, and revocation txns can be created with ANYONE_CAN_WRITE=True, then maybe we should not modify this map, but rather add a check to `authorised`, so that if `typ` is one from the list above, then return True immediately.",8a6ebfb907546d13a9c7937383a86a619fdb7f00,2018-08-03 08:53:00,207481816,"@@ -67,7 +67,8 @@ def generate_auth_map(valid_roles, need_permission=None):
         '{}_<any>_<any>_<any>'.format(VALIDATOR_INFO):
             {TRUSTEE: [], STEWARD: []},
     }
-    if need_permission is False or (need_permission is None and not getConfig().WRITES_REQUIRE_TRUST_ANCHOR):
+    if anyone_can_write is True or (anyone_can_write is None and getConfig().ANYONE_CAN_WRITE):
+        auth_map['{}_role__'.format(NYM)][None] = []",15,2018-08-07 08:10:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207481816,https://github.com/hyperledger/indy-node/pull/860#discussion_r207481816,ashcherbakov
https://github.com/hyperledger/indy-node/pull/860,https://github.com/hyperledger/indy-node/pull/860,Moved to write_permission module,8a6ebfb907546d13a9c7937383a86a619fdb7f00,2018-08-03 09:20:37,207488826,"@@ -0,0 +1,88 @@
+import json
+import pytest
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check, \
+    sdk_get_and_check_replies, sdk_sign_and_submit_req
+from plenum.common.exceptions import RequestRejectedException
+
+from indy_common.auth import Authoriser
+from indy.anoncreds import issuer_create_schema
+from indy.ledger import build_schema_request
+
+from indy_node.test.anon_creds.conftest import claim_def
+from indy_client.test.test_nym_attrib import attributeData, attributeName, attributeValue
+",,2018-08-07 08:10:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207488826,https://github.com/hyperledger/indy-node/pull/860#discussion_r207488826,ArtObr
https://github.com/hyperledger/indy-node/pull/860,https://github.com/hyperledger/indy-node/pull/860,Ok,8a6ebfb907546d13a9c7937383a86a619fdb7f00,2018-08-03 09:30:29,207491392,"@@ -0,0 +1,88 @@
+import json
+import pytest
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check, \
+    sdk_get_and_check_replies, sdk_sign_and_submit_req
+from plenum.common.exceptions import RequestRejectedException
+
+from indy_common.auth import Authoriser
+from indy.anoncreds import issuer_create_schema
+from indy.ledger import build_schema_request
+
+from indy_node.test.anon_creds.conftest import claim_def
+from indy_client.test.test_nym_attrib import attributeData, attributeName, attributeValue
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    # We need to reset authorization map to set new authorization rules
+    Authoriser.auth_map = None
+    OLD_ANYONE_CAN_WRITE = tconf.ANYONE_CAN_WRITE
+    tconf.ANYONE_CAN_WRITE = True
+
+    yield tconf
+
+    tconf.ANYONE_CAN_WRITE = OLD_ANYONE_CAN_WRITE
+    Authoriser.auth_map = None
+
+
+def test_client_can_send_nym(looper,
+                             txnPoolNodeSet,
+                             sdk_wallet_client,
+                             sdk_wallet_trust_anchor,
+                             sdk_pool_handle,
+                             attributeData):
+    # client can create another client NYM when ANYONE_CAN_WRITE set to True
+    sdk_new_client_wallet = sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_client)
+    _, new_client_did = sdk_new_client_wallet
+
+    # client as an owner can add attribute to his NYM",,2018-08-07 08:10:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207491392,https://github.com/hyperledger/indy-node/pull/860#discussion_r207491392,ArtObr
https://github.com/hyperledger/indy-node/pull/860,https://github.com/hyperledger/indy-node/pull/860,He can. Relevant tests will be added,8a6ebfb907546d13a9c7937383a86a619fdb7f00,2018-08-03 09:38:18,207493270,"@@ -0,0 +1,88 @@
+import json
+import pytest
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.pool_transactions.helper import sdk_add_new_nym
+from plenum.test.helper import sdk_sign_request_from_dict, sdk_send_and_check, \
+    sdk_get_and_check_replies, sdk_sign_and_submit_req
+from plenum.common.exceptions import RequestRejectedException
+
+from indy_common.auth import Authoriser
+from indy.anoncreds import issuer_create_schema
+from indy.ledger import build_schema_request
+
+from indy_node.test.anon_creds.conftest import claim_def
+from indy_client.test.test_nym_attrib import attributeData, attributeName, attributeValue
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    # We need to reset authorization map to set new authorization rules
+    Authoriser.auth_map = None
+    OLD_ANYONE_CAN_WRITE = tconf.ANYONE_CAN_WRITE
+    tconf.ANYONE_CAN_WRITE = True
+
+    yield tconf
+
+    tconf.ANYONE_CAN_WRITE = OLD_ANYONE_CAN_WRITE
+    Authoriser.auth_map = None
+
+
+def test_client_can_send_nym(looper,
+                             txnPoolNodeSet,
+                             sdk_wallet_client,
+                             sdk_wallet_trust_anchor,
+                             sdk_pool_handle,
+                             attributeData):
+    # client can create another client NYM when ANYONE_CAN_WRITE set to True
+    sdk_new_client_wallet = sdk_add_new_nym(looper, sdk_pool_handle, sdk_wallet_client)
+    _, new_client_did = sdk_new_client_wallet
+
+    # client as an owner can add attribute to his NYM
+    sdk_add_attribute_and_check(looper, sdk_pool_handle, sdk_new_client_wallet,
+                                attributeData, new_client_did)
+
+    # another client or trust anchor cannot add attribute to another NYM
+    with pytest.raises(RequestRejectedException) as e:
+        sdk_add_attribute_and_check(looper, sdk_pool_handle, sdk_wallet_trust_anchor,
+                                    attributeData, new_client_did)
+    assert e.match('Only identity owner/guardian can add attribute for that identity')
+
+    with pytest.raises(RequestRejectedException) as e:
+        sdk_add_attribute_and_check(looper, sdk_pool_handle, sdk_wallet_client,
+                                    attributeData, new_client_did)
+    assert e.match('Only identity owner/guardian can add attribute for that identity')
+
+
+def test_client_can_send_schema(looper,
+                                txnPoolNodeSet,
+                                sdk_wallet_client,
+                                sdk_wallet_trust_anchor,
+                                sdk_pool_handle):
+    # Trust anchor can create schema in any case
+    _, identifier = sdk_wallet_trust_anchor
+    _, schema_json = looper.loop.run_until_complete(
+        issuer_create_schema(identifier, ""name"", ""1.0"", json.dumps([""first"", ""last""])))
+    request = looper.loop.run_until_complete(build_schema_request(identifier, schema_json))
+    sdk_get_and_check_replies(looper, [sdk_sign_and_submit_req(sdk_pool_handle, sdk_wallet_trust_anchor, request)])
+
+    # Client can create schema if ANYONE_CAN_WRITE flag set to False
+    _, identifier = sdk_wallet_client
+    _, schema_json = looper.loop.run_until_complete(
+        issuer_create_schema(identifier, ""name"", ""1.0"", json.dumps([""first"", ""last""])))
+    request = looper.loop.run_until_complete(build_schema_request(identifier, schema_json))
+    sdk_get_and_check_replies(looper, [sdk_sign_and_submit_req(sdk_pool_handle, sdk_wallet_client, request)])
+",,2018-08-07 08:10:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207493270,https://github.com/hyperledger/indy-node/pull/860#discussion_r207493270,ArtObr
https://github.com/hyperledger/indy-node/pull/860,https://github.com/hyperledger/indy-node/pull/860,asked,8a6ebfb907546d13a9c7937383a86a619fdb7f00,2018-08-03 10:54:58,207510189,"@@ -67,7 +67,8 @@ def generate_auth_map(valid_roles, need_permission=None):
         '{}_<any>_<any>_<any>'.format(VALIDATOR_INFO):
             {TRUSTEE: [], STEWARD: []},
     }
-    if need_permission is False or (need_permission is None and not getConfig().WRITES_REQUIRE_TRUST_ANCHOR):
+    if anyone_can_write is True or (anyone_can_write is None and getConfig().ANYONE_CAN_WRITE):
+        auth_map['{}_role__'.format(NYM)][None] = []",15,2018-08-07 08:10:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/207510189,https://github.com/hyperledger/indy-node/pull/860#discussion_r207510189,ArtObr
https://github.com/hyperledger/indy-node/pull/853,https://github.com/hyperledger/indy-node/pull/853,why do divide to time here? Do we consider all metrics per second?,ba139e9bb26e52c2e3872c6cb07868feaa14ea2b,2018-07-31 07:44:54,206424895,"@@ -72,56 +80,107 @@ def make_copy_of_data(data_dir):
     return read_copy_data_dir
 
 
-def process_storage(storage, min_ts, max_ts):
-    stats = load_metrics_from_kv_store(storage, min_ts, max_ts)
+def process_storage(storage, args):
+    stats = load_metrics_from_kv_store(storage, args.min_ts, args.max_ts, timedelta(seconds=args.step))
+
+    with open(args.output, 'w') as f:
+        columns = [
+            ""timestamp"",
+            ""avg_looper_run_time_spent"",
+            ""avg_three_pc_batch_size"",
+            ""avg_incoming_node_message_size"",
+            ""avg_outgoing_node_message_size"",
+            ""avg_incoming_client_message_size"",
+            ""avg_outgoing_client_message_size"",
+            ""node_stack_messages_processed"",
+            ""client_stack_messages_processed"",
+            ""three_pc_batch_count"",
+            ""requests_count"",
+            ""incoming_node_messages"",
+            ""incoming_node_traffic"",
+            ""outgoing_node_messages"",
+            ""outgoing_node_traffic"",
+            ""incoming_client_messages"",
+            ""incoming_client_traffic"",
+            ""outgoing_client_messages"",
+            ""outgoing_client_traffic""
+        ]
+        f.write("","".join(columns))
+        f.write(""\n"")
+        for ts, frame in sorted(stats.frames(), key=lambda v: v[0]):
+            row = [
+                ts.replace(microsecond=0),
+                frame.get(MetricsType.LOOPER_RUN_TIME_SPENT).avg,
+                frame.get(MetricsType.THREE_PC_BATCH_SIZE).avg,
+                frame.get(MetricsType.INCOMING_NODE_MESSAGE_SIZE).avg,
+                frame.get(MetricsType.OUTGOING_NODE_MESSAGE_SIZE).avg,
+                frame.get(MetricsType.INCOMING_CLIENT_MESSAGE_SIZE).avg,
+                frame.get(MetricsType.OUTGOING_CLIENT_MESSAGE_SIZE).avg,
+                frame.get(MetricsType.NODE_STACK_MESSAGES_PROCESSED).sum / stats.timestep.total_seconds(),",81,2018-07-31 09:30:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/206424895,https://github.com/hyperledger/indy-node/pull/853#discussion_r206424895,ashcherbakov
https://github.com/hyperledger/indy-node/pull/853,https://github.com/hyperledger/indy-node/pull/853,"Some of them (not all) are per second, it gives more consistent results when changing time windows. ",ba139e9bb26e52c2e3872c6cb07868feaa14ea2b,2018-07-31 07:48:10,206425889,"@@ -72,56 +80,107 @@ def make_copy_of_data(data_dir):
     return read_copy_data_dir
 
 
-def process_storage(storage, min_ts, max_ts):
-    stats = load_metrics_from_kv_store(storage, min_ts, max_ts)
+def process_storage(storage, args):
+    stats = load_metrics_from_kv_store(storage, args.min_ts, args.max_ts, timedelta(seconds=args.step))
+
+    with open(args.output, 'w') as f:
+        columns = [
+            ""timestamp"",
+            ""avg_looper_run_time_spent"",
+            ""avg_three_pc_batch_size"",
+            ""avg_incoming_node_message_size"",
+            ""avg_outgoing_node_message_size"",
+            ""avg_incoming_client_message_size"",
+            ""avg_outgoing_client_message_size"",
+            ""node_stack_messages_processed"",
+            ""client_stack_messages_processed"",
+            ""three_pc_batch_count"",
+            ""requests_count"",
+            ""incoming_node_messages"",
+            ""incoming_node_traffic"",
+            ""outgoing_node_messages"",
+            ""outgoing_node_traffic"",
+            ""incoming_client_messages"",
+            ""incoming_client_traffic"",
+            ""outgoing_client_messages"",
+            ""outgoing_client_traffic""
+        ]
+        f.write("","".join(columns))
+        f.write(""\n"")
+        for ts, frame in sorted(stats.frames(), key=lambda v: v[0]):
+            row = [
+                ts.replace(microsecond=0),
+                frame.get(MetricsType.LOOPER_RUN_TIME_SPENT).avg,
+                frame.get(MetricsType.THREE_PC_BATCH_SIZE).avg,
+                frame.get(MetricsType.INCOMING_NODE_MESSAGE_SIZE).avg,
+                frame.get(MetricsType.OUTGOING_NODE_MESSAGE_SIZE).avg,
+                frame.get(MetricsType.INCOMING_CLIENT_MESSAGE_SIZE).avg,
+                frame.get(MetricsType.OUTGOING_CLIENT_MESSAGE_SIZE).avg,
+                frame.get(MetricsType.NODE_STACK_MESSAGES_PROCESSED).sum / stats.timestep.total_seconds(),",81,2018-07-31 09:30:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/206425889,https://github.com/hyperledger/indy-node/pull/853#discussion_r206425889,skhoroshavin
https://github.com/hyperledger/indy-node/pull/853,https://github.com/hyperledger/indy-node/pull/853,Please mention that this is per second,ba139e9bb26e52c2e3872c6cb07868feaa14ea2b,2018-07-31 09:28:58,206456977,"@@ -72,56 +80,107 @@ def make_copy_of_data(data_dir):
     return read_copy_data_dir
 
 
-def process_storage(storage, min_ts, max_ts):
-    stats = load_metrics_from_kv_store(storage, min_ts, max_ts)
+def process_storage(storage, args):
+    stats = load_metrics_from_kv_store(storage, args.min_ts, args.max_ts, timedelta(seconds=args.step))
+
+    with open(args.output, 'w') as f:
+        columns = [
+            ""timestamp"",
+            ""avg_looper_run_time_spent"",
+            ""avg_three_pc_batch_size"",
+            ""avg_incoming_node_message_size"",
+            ""avg_outgoing_node_message_size"",
+            ""avg_incoming_client_message_size"",
+            ""avg_outgoing_client_message_size"",
+            ""node_stack_messages_processed"",
+            ""client_stack_messages_processed"",
+            ""three_pc_batch_count"",
+            ""requests_count"",
+            ""incoming_node_messages"",",,2018-07-31 09:30:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/206456977,https://github.com/hyperledger/indy-node/pull/853#discussion_r206456977,ashcherbakov
https://github.com/hyperledger/indy-node/pull/849,https://github.com/hyperledger/indy-node/pull/849,Should we install the script with the node (add it to setup.py?),316f39bf05f4dcd5cb36ebbb09af6fa01912d50f,2018-07-30 12:47:41,206119523,"@@ -0,0 +1,165 @@
+#! /usr/bin/env python3
+""""""
+Convenience script for gathering metrics data
+
+""""""
+import argparse
+import logging
+import os
+import shutil
+from datetime import datetime
+
+from indy_common.config_util import getConfig
+from plenum.common.constants import KeyValueStorageType
+from plenum.common.metrics_collector import MetricsType
+from plenum.common.metrics_stats import load_metrics_from_kv_store
+from storage.helper import initKeyValueStorage
+
+logging.root.handlers = []
+logger = logging.getLogger()
+logger.propagate = False
+logger.disabled = True
+
+",23,2018-07-30 12:47:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/206119523,https://github.com/hyperledger/indy-node/pull/849#discussion_r206119523,ashcherbakov
https://github.com/hyperledger/indy-node/pull/843,https://github.com/hyperledger/indy-node/pull/843,Please add unit tests for this.,bf83516858e950c71c70499b2c429f2d5c448257,2018-07-26 15:32:23,205502825,"@@ -81,6 +88,40 @@ def __init__(
         # Listen for incoming connections
         self.server.listen(1)
 
+    @classmethod
+    def _get_ext_info(cls, package):
+        cmd = compose_cmd(['dpkg', '-s', package])
+        ret = cls._run_shell_command(cmd)
+        if ret.returncode != 0:
+            raise Exception('cannot get package info since {} returned {}'
+                            .format(cmd, ret.returncode))
+        return ret.stdout.strip()
+
+    def _ext_info(self):",40,2018-08-01 10:42:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/205502825,https://github.com/hyperledger/indy-node/pull/843#discussion_r205502825,ashcherbakov
https://github.com/hyperledger/indy-node/pull/843,https://github.com/hyperledger/indy-node/pull/843,Please extend the node_control_tool's tests when `UPGRADE_ENTRY ` is specified.,bf83516858e950c71c70499b2c429f2d5c448257,2018-07-26 15:33:20,205503188,"@@ -43,6 +43,11 @@ def __init__(
             hold_ext: str = '',
             config=None):
         self.config = config or getConfig()
+
+        assert self.config.UPGRADE_ENTRY",,2018-08-01 10:42:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/205503188,https://github.com/hyperledger/indy-node/pull/843#discussion_r205503188,ashcherbakov
https://github.com/hyperledger/indy-node/pull/843,https://github.com/hyperledger/indy-node/pull/843,"Please add a test that dependencies are resolved correctly if indy-node is one of the dependencies for top-level package.
See `testNodeControlResolvesDependencies` as example.",bf83516858e950c71c70499b2c429f2d5c448257,2018-07-30 07:40:17,206038567,"@@ -81,6 +86,48 @@ def __init__(
         # Listen for incoming connections
         self.server.listen(1)
 
+    def _ext_init(self):
+        self.ext_upgrade = self.config.UPGRADE_ENTRY not in PACKAGES_TO_HOLD
+        self._update_package_cache()
+        self.ext_ver, ext_deps = self._ext_info()
+        self.deps = ext_deps + self.deps",27,2018-08-01 10:42:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/206038567,https://github.com/hyperledger/indy-node/pull/843#discussion_r206038567,ashcherbakov
https://github.com/hyperledger/indy-node/pull/843,https://github.com/hyperledger/indy-node/pull/843,"Please also check `nct.tool.ext_upgrade`, `assert nct.tool.ext_ver`, `nct.tool.deps`, `nct.tool.packages_to_hold`",bf83516858e950c71c70499b2c429f2d5c448257,2018-07-30 07:41:17,206038785,"@@ -0,0 +1,35 @@
+import pytest
+from indy_node.test.upgrade.helper import NodeControlToolExecutor as NCT, \
+    nodeControlGeneralMonkeypatching
+
+
+EXT_PKT_VERSION = '7.88.999'
+EXT_PKT_NAME = 'SomeTopLevelPkt'
+EXT_PKT_DEPS = ['aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh']
+PACKAGE_MNG_EXT_PTK_OUTPUT = ""Package: {}\nStatus: install ok installed\nPriority: extra\nSection: default\n"" \
+                             ""Installed-Size: 21\nMaintainer: EXT_PKT_NAME-fond\nArchitecture: amd64\nVersion: {}\n"" \
+                             ""Depends: {}, {} (= 1.1.1), {} (< 1.1.1), {} (<= 1.1.1), {} (> 1.1.1), {} (>= 1.1.1),"" \
+                             "" {} (<< 1.1.1), {} (>> 1.1.1)\nDescription: EXT_PKT_DEPS-desc\n"" \
+                             ""License: EXT_PKT_DEPS-lic\nVendor: none\n"".\
+    format(EXT_PKT_NAME, EXT_PKT_VERSION, EXT_PKT_DEPS[0], EXT_PKT_DEPS[1],
+           EXT_PKT_DEPS[2], EXT_PKT_DEPS[3], EXT_PKT_DEPS[4], EXT_PKT_DEPS[5],
+           EXT_PKT_DEPS[6], EXT_PKT_DEPS[7], EXT_PKT_DEPS[7])
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    oldv = tconf.UPGRADE_ENTRY
+    tconf.UPGRADE_ENTRY = EXT_PKT_NAME
+    yield tconf
+    tconf.UPGRADE_ENTRY = oldv
+
+
+def test_upg_ext_info(tdir, monkeypatch, tconf):
+    def transform(tool):
+        nodeControlGeneralMonkeypatching(tool, monkeypatch, tdir, PACKAGE_MNG_EXT_PTK_OUTPUT)
+
+    nct = NCT(backup_dir=tdir, backup_target=tdir, transform=transform)
+    try:
+        assert EXT_PKT_VERSION, EXT_PKT_DEPS == nct.tool._ext_info()",33,2018-08-01 10:42:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/206038785,https://github.com/hyperledger/indy-node/pull/843#discussion_r206038785,ashcherbakov
https://github.com/hyperledger/indy-node/pull/843,https://github.com/hyperledger/indy-node/pull/843,Please add a couple of other dependencies in addition to indy-node to check that they also taken into account,bf83516858e950c71c70499b2c429f2d5c448257,2018-07-31 07:57:05,206428489,"@@ -0,0 +1,53 @@
+import pytest
+from indy_node.utils.node_control_tool import NodeControlTool
+from plenum.test.helper import randomText
+
+
+EXT_PKT_VERSION = '7.88.999'
+EXT_PKT_NAME = 'SomeTopLevelPkt'
+node_package = ('indy-node', '0.0.1')
+PACKAGE_MNG_EXT_PTK_OUTPUT = ""Package: {}\nStatus: install ok installed\nPriority: extra\nSection: default\n"" \
+                             ""Installed-Size: 21\nMaintainer: EXT_PKT_NAME-fond\nArchitecture: amd64\nVersion: {}\n"" \
+                             ""Depends: {}\nDescription: EXT_PKT_DEPS-desc\n"" \",,2018-08-01 10:42:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/206428489,https://github.com/hyperledger/indy-node/pull/843#discussion_r206428489,ashcherbakov
https://github.com/hyperledger/indy-node/pull/822,https://github.com/hyperledger/indy-node/pull/822,except from Gamma?,3b261540a8c4a6b7fdd17017255c75d19bf86c8e,2018-07-17 11:22:25,202984112,"@@ -0,0 +1,34 @@
+from indy_node.test import waits
+from indy_node.test.upgrade.helper import checkUpgradeScheduled, \
+    sdk_send_upgrade
+from plenum.common.constants import VERSION
+from plenum.test.delayers import req_delay, ppDelay, pDelay, cDelay, ppgDelay
+from plenum.test.test_node import getNonPrimaryReplicas
+from stp_core.loop.eventually import eventually
+
+
+def test_node_handles_forced_upgrade_on_propagate(
+        looper, nodeSet, sdk_pool_handle, sdk_wallet_trustee,
+        validUpgradeExpForceTrue):
+    """"""
+    Verifies that POOL_UPGRADE force=true request is handled immediately when
+    the node receives it in a PROPAGATE from any other node
+    """"""
+    slow_node = getNonPrimaryReplicas(nodeSet, instId=0)[-1].node
+
+    # Stash all except propagates from Alpha",,2018-07-18 08:45:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/202984112,https://github.com/hyperledger/indy-node/pull/822#discussion_r202984112,ashcherbakov
https://github.com/hyperledger/indy-node/pull/822,https://github.com/hyperledger/indy-node/pull/822,"Yes, corrected the comment.",3b261540a8c4a6b7fdd17017255c75d19bf86c8e,2018-07-17 11:29:53,202986172,"@@ -0,0 +1,34 @@
+from indy_node.test import waits
+from indy_node.test.upgrade.helper import checkUpgradeScheduled, \
+    sdk_send_upgrade
+from plenum.common.constants import VERSION
+from plenum.test.delayers import req_delay, ppDelay, pDelay, cDelay, ppgDelay
+from plenum.test.test_node import getNonPrimaryReplicas
+from stp_core.loop.eventually import eventually
+
+
+def test_node_handles_forced_upgrade_on_propagate(
+        looper, nodeSet, sdk_pool_handle, sdk_wallet_trustee,
+        validUpgradeExpForceTrue):
+    """"""
+    Verifies that POOL_UPGRADE force=true request is handled immediately when
+    the node receives it in a PROPAGATE from any other node
+    """"""
+    slow_node = getNonPrimaryReplicas(nodeSet, instId=0)[-1].node
+
+    # Stash all except propagates from Alpha",,2018-07-18 08:45:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/202986172,https://github.com/hyperledger/indy-node/pull/822#discussion_r202986172,spivachuk
https://github.com/hyperledger/indy-node/pull/822,https://github.com/hyperledger/indy-node/pull/822,A better name is `can_write_txn` (see comments in plenum),3b261540a8c4a6b7fdd17017255c75d19bf86c8e,2018-07-18 08:08:48,203286366,"@@ -300,30 +297,8 @@ def defaultNodeAuthNr(self):
         c += self.restarter.service()
         return c
 
-    def processRequest(self, request: Request, frm: str):
-        if self.is_query(request.operation[TXN_TYPE]):
-            self.process_query(request, frm)
-            self.total_read_request_number += 1
-        elif self.is_action(request.operation[TXN_TYPE]):
-            self.process_action(request, frm)
-        else:
-            # forced request should be processed before consensus
-            if (request.operation[TXN_TYPE] in [
-                    POOL_UPGRADE, POOL_CONFIG]) and request.isForced():
-                self.configReqHandler.validate(request)
-                self.configReqHandler.applyForced(request)
-            # here we should have write transactions that should be processed
-            # pool_restart should not be written to ledger
-            # only on writable pool
-            if self.poolCfg.isWritable() or (request.operation[TXN_TYPE] in [
-                    POOL_UPGRADE, POOL_CONFIG]):
-                super().processRequest(request, frm)
-
-            else:
-                raise InvalidClientRequest(
-                    request.identifier,
-                    request.reqId,
-                    'Pool is in readonly mode, try again in 60 seconds')
+    def is_txn_writable(self, txn_type):",53,2018-07-18 08:45:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/203286366,https://github.com/hyperledger/indy-node/pull/822#discussion_r203286366,ashcherbakov
https://github.com/hyperledger/indy-node/pull/821,https://github.com/hyperledger/indy-node/pull/821,Please add a test that restart actually happens when we notice inconsistent 3PC state and that the node joins the pool successfully after this.,0cc88ec1292441488182c1c6c0ecb3d08b503b75,2018-07-18 08:08:16,203286221,"@@ -106,6 +106,9 @@ def getPoolConfig(self):
     def initPoolManager(self, ha, cliname, cliha):
         HasPoolManager.__init__(self, ha, cliname, cliha)
 
+    def on_inconsistent_3pc_state(self):",4,2018-07-18 13:27:03,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/203286221,https://github.com/hyperledger/indy-node/pull/821#discussion_r203286221,ashcherbakov
https://github.com/hyperledger/indy-node/pull/821,https://github.com/hyperledger/indy-node/pull/821,done,0cc88ec1292441488182c1c6c0ecb3d08b503b75,2018-07-18 12:28:44,203358515,"@@ -106,6 +106,9 @@ def getPoolConfig(self):
     def initPoolManager(self, ha, cliname, cliha):
         HasPoolManager.__init__(self, ha, cliname, cliha)
 
+    def on_inconsistent_3pc_state(self):",4,2018-07-18 13:27:03,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/203358515,https://github.com/hyperledger/indy-node/pull/821#discussion_r203358515,skhoroshavin
https://github.com/hyperledger/indy-node/pull/819,https://github.com/hyperledger/indy-node/pull/819,Why do we set it here and not in plenum?,1a977dac9f8461e11ea88a6dd4e282b3a388f236,2018-07-16 07:45:20,202594565,"@@ -102,3 +102,6 @@
 default logging level for node
 '''
 logLevel = logging.INFO
+
+ZMQ_CLIENT_QUEUE_SIZE = 3000  # messages (0 - no limit)",5,2018-07-16 07:45:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/202594565,https://github.com/hyperledger/indy-node/pull/819#discussion_r202594565,ashcherbakov
https://github.com/hyperledger/indy-node/pull/819,https://github.com/hyperledger/indy-node/pull/819,"Just for convenience - only one build instead of two: plenum, node with plenum",1a977dac9f8461e11ea88a6dd4e282b3a388f236,2018-07-16 08:00:23,202597559,"@@ -102,3 +102,6 @@
 default logging level for node
 '''
 logLevel = logging.INFO
+
+ZMQ_CLIENT_QUEUE_SIZE = 3000  # messages (0 - no limit)",5,2018-07-16 08:00:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/202597559,https://github.com/hyperledger/indy-node/pull/819#discussion_r202597559,dsurnin
https://github.com/hyperledger/indy-node/pull/810,https://github.com/hyperledger/indy-node/pull/810,"So, do we always print additional data in json mode? What if this is not verbose mode?",425e870c2561e246d631f1bf2bf28249f85487d6,2018-07-09 07:00:49,200896784,"@@ -794,19 +795,47 @@ def main():
     if not info_paths:
         print('There are no info files in {}'.format(args.basedir))
         return
-    for file_path in info_paths:
-        logger.info(""Reading file {} ..."".format(file_path))
-        if args.verbose:
+    if args.json:",,2018-07-09 10:36:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/200896784,https://github.com/hyperledger/indy-node/pull/810#discussion_r200896784,ashcherbakov
https://github.com/hyperledger/indy-node/pull/810,https://github.com/hyperledger/indy-node/pull/810,Looks like duplicate code as above,425e870c2561e246d631f1bf2bf28249f85487d6,2018-07-09 07:01:08,200896878,"@@ -794,19 +795,47 @@ def main():
     if not info_paths:
         print('There are no info files in {}'.format(args.basedir))
         return
-    for file_path in info_paths:
-        logger.info(""Reading file {} ..."".format(file_path))
-        if args.verbose:
+    if args.json:
+        output_data = {}
+        for file_path in info_paths + additional_paths:
             with open(file_path) as f_stats:
-                print(""{}"".format(os.linesep).join(create_print_tree(json.load(f_stats), lines=[])))
-        else:
-            print(get_stats_from_file(file_path, args.verbose, args.json, args.nagios))
+                logger.info(""Reading file {} ..."".format(file_path))
+                raw_data = f_stats.read()
+                try:
+                    json_data = json.loads(raw_data)
+                except json.JSONDecodeError:
+                    print(""File {} has an invalid json format"".format(file_path))
+                    continue
+                output_data.update(json_data)
+        if output_data:
+            print(json.dumps(output_data))
+        sys.exit(0)
+
+    for file_path in info_paths:
+        with open(file_path) as f_stats:",,2018-07-09 10:36:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/200896878,https://github.com/hyperledger/indy-node/pull/810#discussion_r200896878,ashcherbakov
https://github.com/hyperledger/indy-node/pull/810,https://github.com/hyperledger/indy-node/pull/810,"according with Corin's comment, --json options should be the highest verbosity.
https://jira.hyperledger.org/browse/INDY-1443?focusedCommentId=46831&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-46831",425e870c2561e246d631f1bf2bf28249f85487d6,2018-07-09 07:49:49,200908802,"@@ -794,19 +795,47 @@ def main():
     if not info_paths:
         print('There are no info files in {}'.format(args.basedir))
         return
-    for file_path in info_paths:
-        logger.info(""Reading file {} ..."".format(file_path))
-        if args.verbose:
+    if args.json:",,2018-07-09 10:36:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/200908802,https://github.com/hyperledger/indy-node/pull/810#discussion_r200908802,anikitinDSR
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,Should it be 1.4.0?,ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 12:06:21,204727480,"@@ -8,10 +8,10 @@
 ## Requirements
 
 * native libs
-    * libindy >= 1.4.0~588 (master repo)
+    * libindy >= 1.4.0~626 (master repo)
 
 * python lib
-    * python3-indy >= 1.4.0.dev588
+    * python3-indy >= 1.5.0.dev626",9,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204727480,https://github.com/hyperledger/indy-node/pull/806#discussion_r204727480,ashcherbakov
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,"script uses master branch, it is 1.5.0",ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 13:00:23,204744693,"@@ -8,10 +8,10 @@
 ## Requirements
 
 * native libs
-    * libindy >= 1.4.0~588 (master repo)
+    * libindy >= 1.4.0~626 (master repo)
 
 * python lib
-    * python3-indy >= 1.4.0.dev588
+    * python3-indy >= 1.5.0.dev626",9,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204744693,https://github.com/hyperledger/indy-node/pull/806#discussion_r204744693,dsurnin
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,This looks like duplicate code in multiple places. Can we use some utility/helper method?,ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 13:14:36,204749662,"@@ -302,8 +317,13 @@ def _rand_data(self):
 
     def _from_file_str_data(self, file_str):
         req_json = super()._from_file_str_data(file_str)
-        req_did = json.loads(req_json)['result']['txn']['data']['dest']
-        return req_did
+        if req_json is None:
+            return None
+        tmp = json.loads(req_json)
+        txn = tmp.get('result', {}).get('txn', {}) or tmp.get('txn', {})",,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204749662,https://github.com/hyperledger/indy-node/pull/806#discussion_r204749662,ashcherbakov
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,This looks like duplicate code in multiple places. Can we use some utility/helper method?,ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 13:14:40,204749688,"@@ -323,7 +343,13 @@ class RGSchema(RequestGenerator):
 
     def _from_file_str_data(self, file_str):
         req_json = super()._from_file_str_data(file_str)
-        schema_id = json.loads(req_json)['result']['txnMetadata']['txnId']
+        if req_json is None:
+            return None
+        tmp = json.loads(req_json)
+        txn_type = (tmp.get('result', {}).get('txn', {}) or tmp.get('txn', {})).get('type', None)
+        if txn_type not in [""101"", ""107""]:
+            return None
+        schema_id = (tmp.get('result', {}).get('txnMetadata', {}) or tmp.get('txnMetadata', {})).get('txnId', None)",,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204749688,https://github.com/hyperledger/indy-node/pull/806#discussion_r204749688,ashcherbakov
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,"So, GetRevocRegEntry request consists of GET and WRITE every time, right?
Should we mention this specific in docs, so that QA can calculate the expected load from the script appropriately?",ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 13:19:07,204751130,"@@ -470,42 +521,74 @@ def __init__(self, *args, **kwargs):
             ""sex"": {""raw"": ""value1"", ""encoded"": ""123""},
             ""height"": {""raw"": ""value1"", ""encoded"": ""456""}
         })
+        self._max_cred_num = None
+        self._submitter_did = None
+        self._pool_handle = None
+        self._cred_offer_json = None
+        self._tails_writer = None
+
+    async def _upd_revoc_reg(self):",295,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204751130,https://github.com/hyperledger/indy-node/pull/806#discussion_r204751130,ashcherbakov
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,Why do we need this line now and didn't need it before?,ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 13:21:54,204752114,"@@ -751,6 +842,8 @@ def req_send(self, start_new_batch: bool = False):
         self._closing = True
         if len(self._send_q) > 0:
             await asyncio.gather(*self._send_q, return_exceptions=True)
+        if len(self._gen_q) > 0:",433,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204752114,https://github.com/hyperledger/indy-node/pull/806#discussion_r204752114,ashcherbakov
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,done,ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 14:31:26,204780044,"@@ -302,8 +317,13 @@ def _rand_data(self):
 
     def _from_file_str_data(self, file_str):
         req_json = super()._from_file_str_data(file_str)
-        req_did = json.loads(req_json)['result']['txn']['data']['dest']
-        return req_did
+        if req_json is None:
+            return None
+        tmp = json.loads(req_json)
+        txn = tmp.get('result', {}).get('txn', {}) or tmp.get('txn', {})",,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204780044,https://github.com/hyperledger/indy-node/pull/806#discussion_r204780044,dsurnin
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,done,ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 14:31:34,204780090,"@@ -323,7 +343,13 @@ class RGSchema(RequestGenerator):
 
     def _from_file_str_data(self, file_str):
         req_json = super()._from_file_str_data(file_str)
-        schema_id = json.loads(req_json)['result']['txnMetadata']['txnId']
+        if req_json is None:
+            return None
+        tmp = json.loads(req_json)
+        txn_type = (tmp.get('result', {}).get('txn', {}) or tmp.get('txn', {})).get('type', None)
+        if txn_type not in [""101"", ""107""]:
+            return None
+        schema_id = (tmp.get('result', {}).get('txnMetadata', {}) or tmp.get('txnMetadata', {})).get('txnId', None)",,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204780090,https://github.com/hyperledger/indy-node/pull/806#discussion_r204780090,dsurnin
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,done,ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 14:57:45,204790502,"@@ -470,42 +521,74 @@ def __init__(self, *args, **kwargs):
             ""sex"": {""raw"": ""value1"", ""encoded"": ""123""},
             ""height"": {""raw"": ""value1"", ""encoded"": ""456""}
         })
+        self._max_cred_num = None
+        self._submitter_did = None
+        self._pool_handle = None
+        self._cred_offer_json = None
+        self._tails_writer = None
+
+    async def _upd_revoc_reg(self):",295,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204790502,https://github.com/hyperledger/indy-node/pull/806#discussion_r204790502,dsurnin
https://github.com/hyperledger/indy-node/pull/806,https://github.com/hyperledger/indy-node/pull/806,this line was added to prevent crashing during the finalization step in case of time consuming requests like revoc_reg,ad33b4daec840e64c94ff6a197da4249f813f341,2018-07-24 15:03:07,204792827,"@@ -751,6 +842,8 @@ def req_send(self, start_new_batch: bool = False):
         self._closing = True
         if len(self._send_q) > 0:
             await asyncio.gather(*self._send_q, return_exceptions=True)
+        if len(self._gen_q) > 0:",433,2018-07-24 15:47:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/204792827,https://github.com/hyperledger/indy-node/pull/806#discussion_r204792827,dsurnin
https://github.com/hyperledger/indy-node/pull/798,https://github.com/hyperledger/indy-node/pull/798,Rise it from 110 to 150 simultaneous connections.,822c2307e40b68bd76bcf89191d35842afe81b78,2018-07-02 13:49:39,199503385,"@@ -0,0 +1,23 @@
+# Test for checking, that there is limit of simultaneous client connections
+
+**Steps to reproduce:**
+ - Using scrips from environment/docker/pool start up the pool:
+    - ``$ cd environment/docker/pool``
+    - ``$ ./pool_start.sh``
+    - ``$ docker exec -it -u root node1 setup_indy_node_iptables && setup_iptables 9702 100``
+    - ``$ docker exec -it -u root node2 setup_indy_node_iptables && setup_iptables 9704 100``
+    - ``$ docker exec -it -u root node3 setup_indy_node_iptables && setup_iptables 9706 100``
+    - ``$ docker exec -it -u root node4 setup_indy_node_iptables && setup_iptables 9708 100``
+    
+ - Start another docker container, which contains script for creating N simultaneous client connection:
+    - ``docker run -itd --privileged --name indy-cli indycore bash``
+    - ``docker cp ../../scripts/client-connections/just_connect_N_times.py indy-cli:/tmp``
+    - ``docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis /tmp``
+    - ``docker cp /tmp/pool_transactions_genesis indy-cli:/tmp``
+    - ``docker exec -it -u root indy-cli python3 just_connect_N_times.py -g /tmp/pool_transactions_genesis -c 110``
+    - this script will try to create 110 simultaneous connections to pool.    ",,2018-07-03 12:56:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/199503385,https://github.com/hyperledger/indy-node/pull/798#discussion_r199503385,sergey-shilov
https://github.com/hyperledger/indy-node/pull/798,https://github.com/hyperledger/indy-node/pull/798, When 50 second IS left...,822c2307e40b68bd76bcf89191d35842afe81b78,2018-07-02 13:50:10,199503533,"@@ -0,0 +1,23 @@
+# Test for checking, that there is limit of simultaneous client connections
+
+**Steps to reproduce:**
+ - Using scrips from environment/docker/pool start up the pool:
+    - ``$ cd environment/docker/pool``
+    - ``$ ./pool_start.sh``
+    - ``$ docker exec -it -u root node1 setup_indy_node_iptables && setup_iptables 9702 100``
+    - ``$ docker exec -it -u root node2 setup_indy_node_iptables && setup_iptables 9704 100``
+    - ``$ docker exec -it -u root node3 setup_indy_node_iptables && setup_iptables 9706 100``
+    - ``$ docker exec -it -u root node4 setup_indy_node_iptables && setup_iptables 9708 100``
+    
+ - Start another docker container, which contains script for creating N simultaneous client connection:
+    - ``docker run -itd --privileged --name indy-cli indycore bash``
+    - ``docker cp ../../scripts/client-connections/just_connect_N_times.py indy-cli:/tmp``
+    - ``docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis /tmp``
+    - ``docker cp /tmp/pool_transactions_genesis indy-cli:/tmp``
+    - ``docker exec -it -u root indy-cli python3 just_connect_N_times.py -g /tmp/pool_transactions_genesis -c 110``
+    - this script will try to create 110 simultaneous connections to pool.    
+ - As default, indy-sdk has a connection timeout about 50 seconds. In that case, we expect, that limited count of client will be connected to the pool and 
+ other not. When 50 second was left, process with client connection will return error 307 (PoolLedgerTimeout).",,2018-07-03 12:56:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/199503533,https://github.com/hyperledger/indy-node/pull/798#discussion_r199503533,sergey-shilov
https://github.com/hyperledger/indy-node/pull/798,https://github.com/hyperledger/indy-node/pull/798,Each client is run in a different process.,822c2307e40b68bd76bcf89191d35842afe81b78,2018-07-02 13:50:55,199503748,"@@ -0,0 +1,23 @@
+# Test for checking, that there is limit of simultaneous client connections
+
+**Steps to reproduce:**
+ - Using scrips from environment/docker/pool start up the pool:
+    - ``$ cd environment/docker/pool``
+    - ``$ ./pool_start.sh``
+    - ``$ docker exec -it -u root node1 setup_indy_node_iptables && setup_iptables 9702 100``
+    - ``$ docker exec -it -u root node2 setup_indy_node_iptables && setup_iptables 9704 100``
+    - ``$ docker exec -it -u root node3 setup_indy_node_iptables && setup_iptables 9706 100``
+    - ``$ docker exec -it -u root node4 setup_indy_node_iptables && setup_iptables 9708 100``
+    
+ - Start another docker container, which contains script for creating N simultaneous client connection:
+    - ``docker run -itd --privileged --name indy-cli indycore bash``
+    - ``docker cp ../../scripts/client-connections/just_connect_N_times.py indy-cli:/tmp``
+    - ``docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis /tmp``
+    - ``docker cp /tmp/pool_transactions_genesis indy-cli:/tmp``
+    - ``docker exec -it -u root indy-cli python3 just_connect_N_times.py -g /tmp/pool_transactions_genesis -c 110``
+    - this script will try to create 110 simultaneous connections to pool.    
+ - As default, indy-sdk has a connection timeout about 50 seconds. In that case, we expect, that limited count of client will be connected to the pool and 
+ other not. When 50 second was left, process with client connection will return error 307 (PoolLedgerTimeout).
+ Each of clients is run from different process. ",,2018-07-03 12:56:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/199503748,https://github.com/hyperledger/indy-node/pull/798#discussion_r199503748,sergey-shilov
https://github.com/hyperledger/indy-node/pull/798,https://github.com/hyperledger/indy-node/pull/798,"Add a note that max number of connected clients to a pool is conn_limit * (n/(n - f)), so for this particular test settings max number of connected clients is 132.",822c2307e40b68bd76bcf89191d35842afe81b78,2018-07-02 13:53:40,199504623,"@@ -0,0 +1,23 @@
+# Test for checking, that there is limit of simultaneous client connections
+
+**Steps to reproduce:**
+ - Using scrips from environment/docker/pool start up the pool:
+    - ``$ cd environment/docker/pool``
+    - ``$ ./pool_start.sh``
+    - ``$ docker exec -it -u root node1 setup_indy_node_iptables && setup_iptables 9702 100``
+    - ``$ docker exec -it -u root node2 setup_indy_node_iptables && setup_iptables 9704 100``
+    - ``$ docker exec -it -u root node3 setup_indy_node_iptables && setup_iptables 9706 100``
+    - ``$ docker exec -it -u root node4 setup_indy_node_iptables && setup_iptables 9708 100``
+    
+ - Start another docker container, which contains script for creating N simultaneous client connection:
+    - ``docker run -itd --privileged --name indy-cli indycore bash``
+    - ``docker cp ../../scripts/client-connections/just_connect_N_times.py indy-cli:/tmp``
+    - ``docker cp node1:/var/lib/indy/sandbox/pool_transactions_genesis /tmp``
+    - ``docker cp /tmp/pool_transactions_genesis indy-cli:/tmp``
+    - ``docker exec -it -u root indy-cli python3 just_connect_N_times.py -g /tmp/pool_transactions_genesis -c 110``
+    - this script will try to create 110 simultaneous connections to pool.    ",,2018-07-03 12:56:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/199504623,https://github.com/hyperledger/indy-node/pull/798#discussion_r199504623,sergey-shilov
https://github.com/hyperledger/indy-node/pull/793,https://github.com/hyperledger/indy-node/pull/793,A typo `g`?,a13528bdd71fcb31ccea5bf3c6939aff5d65ab05,2018-06-29 06:28:28,199063659,"@@ -56,7 +56,7 @@
     data_files=[(
         (BASE_DIR, ['data/nssm_original.exe'])
     )],
-    install_requires=['indy-plenum-dev==1.4.419',
+    install_requires=['indy-plenum-dev==1.4.420g',",,2018-06-29 16:03:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/199063659,https://github.com/hyperledger/indy-node/pull/793#discussion_r199063659,ashcherbakov
https://github.com/hyperledger/indy-node/pull/793,https://github.com/hyperledger/indy-node/pull/793,"Yes, i realised but was waiting for another release. Thanks for catching that",a13528bdd71fcb31ccea5bf3c6939aff5d65ab05,2018-06-29 14:15:54,199173311,"@@ -56,7 +56,7 @@
     data_files=[(
         (BASE_DIR, ['data/nssm_original.exe'])
     )],
-    install_requires=['indy-plenum-dev==1.4.419',
+    install_requires=['indy-plenum-dev==1.4.420g',",,2018-06-29 16:03:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/199173311,https://github.com/hyperledger/indy-node/pull/793#discussion_r199173311,lovesh
https://github.com/hyperledger/indy-node/pull/788,https://github.com/hyperledger/indy-node/pull/788,Please mention that Pool upgrade should be performed simultaneously for all nodes due to txn format changes.,7d6ebe647b253c4476b706c5e4d80acff973756c,2018-06-26 08:55:40,198063995,"@@ -23,3 +23,19 @@ Migration scripts, which would be called automatically during pool upgrade proce
 
  - **From levelDb to Rocksdb**: 
     [1_3_396_to_1_3_397.py](https://github.com/hyperledger/indy-node/blob/master/data/migrations/deb/1_3_396_to_1_3_397.py)
+",,2018-06-26 13:04:01,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/198063995,https://github.com/hyperledger/indy-node/pull/788#discussion_r198063995,ashcherbakov
https://github.com/hyperledger/indy-node/pull/779,https://github.com/hyperledger/indy-node/pull/779,STATE_PROOF must be present even when there is no value returned (proof of non-existence).,98f3edcd525608b10762cbc89980bd996ee35c7f,2018-06-22 07:04:33,197356652,"@@ -1,6 +1,30 @@
 from indy_common.types import SafeRequest
+from plenum.common.constants import TXN_TIME, STATE_PROOF, DATA
+from plenum.common.types import f
 
 
 def test_validate_get_revoc_reg_entry(build_get_revoc_reg_entry):
     req = build_get_revoc_reg_entry
     SafeRequest(**req)
+
+
+def test_get_revoc_reg_entry_without_any_rev_entry(send_revoc_reg_def_by_default,
+                                                   build_get_revoc_reg_entry,
+                                                   txnPoolNodeSet):
+    req = build_get_revoc_reg_entry
+    req_handler = txnPoolNodeSet[0].getDomainReqHandler()
+    req_handler.handleGetRevocRegReq(SafeRequest(**req))
+
+
+def test_get_revoc_reg_entry_without_any_entry_return_none(send_revoc_reg_def_by_default,
+                                                           build_get_revoc_reg_entry,
+                                                           txnPoolNodeSet):
+    req = build_get_revoc_reg_entry
+    req_handler = txnPoolNodeSet[0].getDomainReqHandler()
+    result = req_handler.handleGetRevocRegReq(SafeRequest(**req))
+    assert result[DATA] is None
+    assert result[f.SEQ_NO.nm] is None
+    assert result[TXN_TIME] is None
+    assert STATE_PROOF not in result",28,2018-06-22 07:04:33,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/197356652,https://github.com/hyperledger/indy-node/pull/779#discussion_r197356652,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Maybe `If 'num' param omitted only one batch will be sent.`?,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:26:56,196724683,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196724683,https://github.com/hyperledger/indy-node/pull/776#discussion_r196724683,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Better to rename to `cred_def`,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:28:08,196724969,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196724969,https://github.com/hyperledger/indy-node/pull/776#discussion_r196724969,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Better to rename to `revoc_reg_def`,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:29:26,196725373,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196725373,https://github.com/hyperledger/indy-node/pull/776#discussion_r196725373,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Better to rename to `revoc_reg_entry`,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:29:35,196725415,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196725415,https://github.com/hyperledger/indy-node/pull/776#discussion_r196725415,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Better to rename to `get_cred_def`,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:29:47,196725473,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196725473,https://github.com/hyperledger/indy-node/pull/776#discussion_r196725473,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Better to rename to `get_revoc_reg_def`,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:30:01,196725543,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196725543,https://github.com/hyperledger/indy-node/pull/776#discussion_r196725543,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Better to rename to `get_revoc_reg`,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:30:12,196725607,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196725607,https://github.com/hyperledger/indy-node/pull/776#discussion_r196725607,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Do we have `get_revoc_reg_delta`?,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:30:54,196725778,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196725778,https://github.com/hyperledger/indy-node/pull/776#discussion_r196725778,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Should be `TXN_TYPE `,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:32:08,196726064,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples
+
+To be able to send txns of one type only with randomly generated data:
+```
+python3 perf_processes.py -k TXN_TYPE
+```
+where TXN_TYPE is one from the list above
+
+To be able to send txns of one type only with data read from file use JSON obj:
+```
+python3 perf_processes.py -k ""{\""TXN_TYPE1\"": {\""file_name\"": ""/path/to/file""}}""",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196726064,https://github.com/hyperledger/indy-node/pull/776#discussion_r196726064,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Please clarify how the file should look like (provide an example),f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:32:54,196726211,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples
+
+To be able to send txns of one type only with randomly generated data:
+```
+python3 perf_processes.py -k TXN_TYPE
+```
+where TXN_TYPE is one from the list above
+
+To be able to send txns of one type only with data read from file use JSON obj:
+```
+python3 perf_processes.py -k ""{\""TXN_TYPE1\"": {\""file_name\"": ""/path/to/file""}}""",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196726211,https://github.com/hyperledger/indy-node/pull/776#discussion_r196726211,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Please use ordered list for each of the examples,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:33:19,196726315,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples
+
+To be able to send txns of one type only with randomly generated data:",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196726315,https://github.com/hyperledger/indy-node/pull/776#discussion_r196726315,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,"Please include other params (such as -c, -n, -t) to Examples.
In particular, provide examples of how to emulate multiple clients sending requests to the pool (with delays and without delays)",f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 10:36:47,196727163,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196727163,https://github.com/hyperledger/indy-node/pull/776#discussion_r196727163,ashcherbakov
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Need to add information that in the end of 'total' file there are some requests which were created in advance and were not send.,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:37:01,196759192,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196759192,https://github.com/hyperledger/indy-node/pull/776#discussion_r196759192,ozheregelya
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,Load script will not work with libindy 1.4.0 (stable). It works with libindy >= 1.4.0~588 (master) and python3-indy >= 1.4.0.dev588.,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:40:41,196760524,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196760524,https://github.com/hyperledger/indy-node/pull/776#discussion_r196760524,ozheregelya
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,May be it make sense to add default values of parameters? ,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:43:12,196761241,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196761241,https://github.com/hyperledger/indy-node/pull/776#discussion_r196761241,ozheregelya
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:44:48,196761786,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196761786,https://github.com/hyperledger/indy-node/pull/776#discussion_r196761786,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,"Should be `\""/path/to/file\""` instead of `""/path/to/file""`.",f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:46:19,196762274,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples
+
+To be able to send txns of one type only with randomly generated data:
+```
+python3 perf_processes.py -k TXN_TYPE
+```
+where TXN_TYPE is one from the list above
+
+To be able to send txns of one type only with data read from file use JSON obj:
+```
+python3 perf_processes.py -k ""{\""TXN_TYPE1\"": {\""file_name\"": ""/path/to/file""}}""
+```
+where TXN_TYPE is one from the list above
+
+To be able to send txns of several types sequentially with randomly generated data use JSON array:
+```
+python3 perf_processes.py -k ""[\""TXN_TYPE1\"", \""TXN_TYPE2\"", ...]""
+```
+where TXN_TYPE1 and TXN_TYPE2 are ones from the list above. TXN_TYPE1 and TXN_TYPE2 could be the same.
+Tnxs will be sent in specified order TXN_TYPE1, TXN_TYPE2, ..., TXN_TYPE1, TXN_TYPE2, ..., etc.
+
+To be able to send txns of several types sequentially with data read from file and randomly generated data use JSON array:
+```
+python3 perf_processes.py -k ""[{\""TXN_TYPE1\"": {\""file_name\"": ""/path/to/file""}}, \""TXN_TYPE2\"", ...]""",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196762274,https://github.com/hyperledger/indy-node/pull/776#discussion_r196762274,ozheregelya
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:46:52,196762460,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196762460,https://github.com/hyperledger/indy-node/pull/776#discussion_r196762460,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:52:02,196764001,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196764001,https://github.com/hyperledger/indy-node/pull/776#discussion_r196764001,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:53:30,196764437,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196764437,https://github.com/hyperledger/indy-node/pull/776#discussion_r196764437,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,No for the moment,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:54:35,196764740,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196764740,https://github.com/hyperledger/indy-node/pull/776#discussion_r196764740,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 12:56:25,196765287,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples
+
+To be able to send txns of one type only with randomly generated data:
+```
+python3 perf_processes.py -k TXN_TYPE
+```
+where TXN_TYPE is one from the list above
+
+To be able to send txns of one type only with data read from file use JSON obj:
+```
+python3 perf_processes.py -k ""{\""TXN_TYPE1\"": {\""file_name\"": ""/path/to/file""}}""",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196765287,https://github.com/hyperledger/indy-node/pull/776#discussion_r196765287,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:00:21,196766427,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples
+
+To be able to send txns of one type only with randomly generated data:
+```
+python3 perf_processes.py -k TXN_TYPE
+```
+where TXN_TYPE is one from the list above
+
+To be able to send txns of one type only with data read from file use JSON obj:
+```
+python3 perf_processes.py -k ""{\""TXN_TYPE1\"": {\""file_name\"": ""/path/to/file""}}""
+```
+where TXN_TYPE is one from the list above
+
+To be able to send txns of several types sequentially with randomly generated data use JSON array:
+```
+python3 perf_processes.py -k ""[\""TXN_TYPE1\"", \""TXN_TYPE2\"", ...]""
+```
+where TXN_TYPE1 and TXN_TYPE2 are ones from the list above. TXN_TYPE1 and TXN_TYPE2 could be the same.
+Tnxs will be sent in specified order TXN_TYPE1, TXN_TYPE2, ..., TXN_TYPE1, TXN_TYPE2, ..., etc.
+
+To be able to send txns of several types sequentially with data read from file and randomly generated data use JSON array:
+```
+python3 perf_processes.py -k ""[{\""TXN_TYPE1\"": {\""file_name\"": ""/path/to/file""}}, \""TXN_TYPE2\"", ...]""",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196766427,https://github.com/hyperledger/indy-node/pull/776#discussion_r196766427,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:04:16,196767604,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples
+
+To be able to send txns of one type only with randomly generated data:",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196767604,https://github.com/hyperledger/indy-node/pull/776#discussion_r196767604,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:15:23,196771542,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196771542,https://github.com/hyperledger/indy-node/pull/776#discussion_r196771542,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:16:21,196771858,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196771858,https://github.com/hyperledger/indy-node/pull/776#discussion_r196771858,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:16:37,196771928,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196771928,https://github.com/hyperledger/indy-node/pull/776#discussion_r196771928,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:17:43,196772291,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196772291,https://github.com/hyperledger/indy-node/pull/776#discussion_r196772291,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:18:35,196772555,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196772555,https://github.com/hyperledger/indy-node/pull/776#discussion_r196772555,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:19:12,196772780,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196772780,https://github.com/hyperledger/indy-node/pull/776#discussion_r196772780,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:29:00,196776121,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196776121,https://github.com/hyperledger/indy-node/pull/776#discussion_r196776121,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,implemented,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 13:57:35,196789283,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196789283,https://github.com/hyperledger/indy-node/pull/776#discussion_r196789283,dsurnin
https://github.com/hyperledger/indy-node/pull/776,https://github.com/hyperledger/indy-node/pull/776,fixed,f506263edd8dd1b412260e223a9aae62107e101a,2018-06-20 14:25:16,196799707,"@@ -0,0 +1,114 @@
+# Processes based load script
+
+* [Requirements](#requirements)
+* [Parameters description](#parameters-description)
+* [Examples](#examples)
+
+## Requirements
+
+* native libs
+    * libindy >= 1.4.0
+
+* python lib
+    * python3-indy >= 1.4.0
+    * libnacl == 1.6.1
+    
+## Parameters description
+
+'-c', '--clients' : Number of independent processes to run.
+Each process will use its own pool handle and wallet and will send requested number of specified pool txns.
+If less or equal than 0 value provided the number of processes will be equal to number available CPUs.
+Default value is 0.
+
+'-g', '--genesis' : Path to file with genesis txns for the pool to connect to.
+
+'-s', '--seed' : Seed that will be used to generate submitter did.
+
+'-w', '--wallet_key' : Key to access encrypted wallet
+
+'-n', '--num' : Number or txns in one batch. If timeout param omitted only one batch will be sent.
+
+'-t', '--timeout' : Timeout between batches. If omitted only one batch will be sent.
+
+'-d', '--directory' : Directory to store output csv files:
+* args - full command line of test run
+* total - status of all sent txns with timestamps of each step
+* successful - request and response for successful txns
+* failed - request and error provided by libindy
+* nack_reject - request and error provided by pool
+
+'--sep' : Separator that will be used in output csv file.
+Do not use "","" - it will be in conflict with JSON values
+
+'-b', '--bg_tasks' : Number of event loop tasks each process will create.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Should not be less than 2.
+
+'-r', '--refresh' : Specifies the rate overall statistics is being updated in number of processed txns.
+If one runs huge amount of processes from a single machine this param could be decreased to reduces amount of used memory.
+Small values require lots of input/output.
+Should not be less than 10.
+
+'-k', '--kind' : Specifies the type of requests to be sent to pool.
+Supported txns:
+* nym - Create did
+* schema - Create schema
+* attrib - Create attribute
+* definition - Create credential definition
+* def_revoc - Create revocation registry
+* entry_revoc - Create revocation registry entry
+* get_nym - Get did
+* get_attrib - Get attribute
+* get_schema - Get schema
+* get_definition - Get credential definition
+* get_def_revoc - Get revocation registry
+* get_entry_revoc - Get revocation registry entry
+
+## Examples
+
+To be able to send txns of one type only with randomly generated data:
+```
+python3 perf_processes.py -k TXN_TYPE
+```
+where TXN_TYPE is one from the list above
+
+To be able to send txns of one type only with data read from file use JSON obj:
+```
+python3 perf_processes.py -k ""{\""TXN_TYPE1\"": {\""file_name\"": ""/path/to/file""}}""",,2018-06-21 14:49:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196799707,https://github.com/hyperledger/indy-node/pull/776#discussion_r196799707,dsurnin
https://github.com/hyperledger/indy-node/pull/775,https://github.com/hyperledger/indy-node/pull/775,Do we add txnId for genesis txns as well? We should not.,97c89c3920ce26d8e03012a7c831f9b19d4f1884,2018-06-20 10:25:02,196724177,"@@ -105,6 +106,32 @@ def add_tag_into_cred_def_id(val):
     return new_val
 
 
+def gen_txn_path(txn):
+    txn_type = get_type(txn)
+    if txn_type not in DomainReqHandler.write_types:
+        return None
+
+    if txn_type == NYM:",34,2018-06-20 10:25:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196724177,https://github.com/hyperledger/indy-node/pull/775#discussion_r196724177,ashcherbakov
https://github.com/hyperledger/indy-node/pull/775,https://github.com/hyperledger/indy-node/pull/775,"No. before calling `gen_txn_path` we check, that reqId exist",97c89c3920ce26d8e03012a7c831f9b19d4f1884,2018-06-20 10:31:08,196725827,"@@ -105,6 +106,32 @@ def add_tag_into_cred_def_id(val):
     return new_val
 
 
+def gen_txn_path(txn):
+    txn_type = get_type(txn)
+    if txn_type not in DomainReqHandler.write_types:
+        return None
+
+    if txn_type == NYM:",34,2018-06-20 10:31:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196725827,https://github.com/hyperledger/indy-node/pull/775#discussion_r196725827,anikitinDSR
https://github.com/hyperledger/indy-node/pull/774,https://github.com/hyperledger/indy-node/pull/774,"`that`, not `tha`",51c8b9ab30c484b47a078537312e46ed2c81c667,2018-06-21 07:12:26,197031246,"@@ -365,9 +360,11 @@ creation of new DIDs, setting and rotation of verification key, setting and chan
     
   A TRUSTEE can change any Nym's role to None, this stopping it from making any writes (see [roles](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0)).
   
-- `verkey` (base58-encoded string; optional): 
+- `verkey` (base58-encoded string, possibly starting with ""~""; optional):
 
-    Target verification key as base58-encoded string. If not set, then either the target identifier
+    Target verification key as base58-encoded string. It can start with ""~"", which means tha",,2018-06-21 11:05:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/197031246,https://github.com/hyperledger/indy-node/pull/774#discussion_r197031246,ashcherbakov
https://github.com/hyperledger/indy-node/pull/774,https://github.com/hyperledger/indy-node/pull/774,"It would be great to check that for each type of ATTRIB txn a correct reply is returned (raw for raw, hash for hash, etc.)",51c8b9ab30c484b47a078537312e46ed2c81c667,2018-06-21 07:21:05,197033098,"@@ -0,0 +1,37 @@
+import json
+
+from indy.ledger import build_attrib_request, sign_request, submit_request
+from indy_node.test.api.helper import validate_write_reply, validate_attrib_txn
+from hashlib import sha256
+
+
+def execute_attrib_txn(looper, sdk_pool_handle, sdk_wallet_steward, xhash, raw, enc):
+    wallet_handle, identifier = sdk_wallet_steward
+
+    request = looper.loop.run_until_complete(build_attrib_request(identifier, identifier, xhash, raw, enc))
+    req_signed = looper.loop.run_until_complete(sign_request(wallet_handle, identifier, request))
+    return json.loads(looper.loop.run_until_complete(submit_request(sdk_pool_handle, req_signed)))
+
+
+def test_attrib_xhash_reply_is_valid(looper, sdk_pool_handle, sdk_wallet_steward):
+    reply = execute_attrib_txn(looper, sdk_pool_handle, sdk_wallet_steward,
+                               sha256(""Hello, world"".encode()).hexdigest(), None, None)
+
+    validate_write_reply(reply)
+    validate_attrib_txn(reply['result']['txn'])",,2018-06-21 11:05:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/197033098,https://github.com/hyperledger/indy-node/pull/774#discussion_r197033098,ashcherbakov
https://github.com/hyperledger/indy-node/pull/771,https://github.com/hyperledger/indy-node/pull/771,"This is an API method defined in Plenum...
Please be careful when renaming API methods",a5bff86c30af67dfe25e344cb284a44be0bf8e0b,2018-07-02 08:12:13,199415174,"@@ -333,7 +333,7 @@ def executeDomainTxns(self, ppTime, reqs: List[Request], stateRoot,
         :param ppTime: the time at which PRE-PREPARE was sent
         :param req: the client REQUEST
         """"""
-        return self.default_executer(DOMAIN_LEDGER_ID, ppTime, reqs,
+        return self.default_executor(DOMAIN_LEDGER_ID, ppTime, reqs,",,2018-07-17 13:48:34,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/199415174,https://github.com/hyperledger/indy-node/pull/771#discussion_r199415174,ashcherbakov
https://github.com/hyperledger/indy-node/pull/771,https://github.com/hyperledger/indy-node/pull/771,This is an API method defined in Plenum...,a5bff86c30af67dfe25e344cb284a44be0bf8e0b,2018-07-02 08:12:23,199415199,"@@ -9,7 +9,7 @@ class HasPoolManager(PHasPoolManager):
     def __init__(self, ha=None, cliname=None, cliha=None):
         self.poolManager = TxnPoolManager(self, ha=ha, cliname=cliname,
                                           cliha=cliha)
-        self.requestExecuter[POOL_LEDGER_ID] = \
+        self.requestExecutor[POOL_LEDGER_ID] = \",,2018-07-17 13:48:34,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/199415199,https://github.com/hyperledger/indy-node/pull/771#discussion_r199415199,ashcherbakov
https://github.com/hyperledger/indy-node/pull/768,https://github.com/hyperledger/indy-node/pull/768,"`Could be combined in form of ""{req_type1: num, ...}"" '` is not clear enough. Please provide example containing more than one entry in the dict.
Also should it be `req_type1: nym`?",c0fd8710eb249665e18b7086707cbf0375a6b8f0,2018-06-18 14:58:13,196110289,"@@ -56,10 +58,9 @@ def check_seed(seed: str):
                     type=check_seed, required=False, dest='seed')
 
 parser.add_argument('-k', '--kind',
-                    help='Kind of request kind to use. One of [""nym"", ""schema"", ""attrib"", ""rand""]'
-                         'Default value is ""nym""',
-                    default=""nym"", choices=['nym', 'schema', 'attrib', 'rand'],
-                    required=False, dest='req_kind')
+                    help='Kind of request to send. One of [""nym"", ""schema"", ""attrib"", ""get_nym""] '
+                         'Default value is ""nym"". Could be combined in form of ""{req_type1: num, ...}"" ',",37,2018-06-18 15:55:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196110289,https://github.com/hyperledger/indy-node/pull/768#discussion_r196110289,ashcherbakov
https://github.com/hyperledger/indy-node/pull/768,https://github.com/hyperledger/indy-node/pull/768,"Why default is it False, not `0`?",c0fd8710eb249665e18b7086707cbf0375a6b8f0,2018-06-18 14:58:38,196110441,"@@ -145,8 +152,10 @@ def reply(self, req_id, reply_or_exception):
             elif resp[""op""] == ""REPLY"":
                 self._req_succ += 1
                 status = ""succ""
-                server_time = int(resp['result']['txnTime'])
-                self._reqs[req_id][""server_reply""] = server_time
+                srv_tm = \
+                    resp['result'].get('txnTime', False) or resp['result'].get('txnMetadata', {}).get('txnTime', False)",102,2018-06-18 15:55:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196110441,https://github.com/hyperledger/indy-node/pull/768#discussion_r196110441,ashcherbakov
https://github.com/hyperledger/indy-node/pull/768,https://github.com/hyperledger/indy-node/pull/768,Where do we stop the loop? Is it intended that there is `while True` here?,c0fd8710eb249665e18b7086707cbf0375a6b8f0,2018-06-18 15:04:58,196112854,"@@ -169,12 +178,297 @@ def dump_stat(self, dump_all: bool = False):
         srv_time = self._server_max_txn_time - self._server_min_txn_time
         ret_val[""server_time""] = srv_time if srv_time >= 0 else 0
         ret_val[""reqs""] = []
-        reqs = [k for k, v in self._reqs.items() if ""status"" in v or dump_all]
+        reqs = [k for k, v in self._client_stat_reqs.items() if ""status"" in v or dump_all]
         for r in reqs:
-            ret_val[""reqs""].append((r, self._reqs.pop(r)))
+            ret_val[""reqs""].append((r, self._client_stat_reqs.pop(r)))
         return ret_val
 
 
+class RequestGenerator(metaclass=ABCMeta):
+    def __init__(self, file_name: str = None, client_stat: ClientStatistic = None, **kwargs):
+        self._client_stat = client_stat
+        if not isinstance(self._client_stat, ClientStatistic):
+            raise RuntimeError(""Bad Statistic obj"")
+        random.seed()
+        self.file_name = check_fs(is_dir=False, fs_name=file_name) if file_name is not None else None
+
+    # Copied from Plenum
+    def random_string(self, sz: int) -> str:
+        assert (sz > 0), ""Expected random string size cannot be less than 1""
+        rv = libnacl.randombytes(sz // 2).hex()
+        return rv if sz % 2 == 0 else rv + hex(libnacl.randombytes_uniform(15))[-1]
+
+    # Copied from Plenum
+    def rawToFriendly(self, raw):
+        return base58.b58encode(raw).decode(""utf-8"")
+
+    async def on_pool_create(self, pool_handle, wallet_handle, submitter_did, *args, **kwargs):
+        pass
+
+    def _rand_data(self):
+        return self.random_string(32)
+
+    def _from_file_str_data(self, file_str):
+        return file_str
+
+    def _gen_req_data(self):
+        if self.file_name is not None:
+            with open(self.file_name, ""rt"") as data_file:
+                while True:",,2018-06-18 15:55:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196112854,https://github.com/hyperledger/indy-node/pull/768#discussion_r196112854,ashcherbakov
https://github.com/hyperledger/indy-node/pull/768,https://github.com/hyperledger/indy-node/pull/768,Please provide documentation with real example on how to use the script (consider multiple examples and modes),c0fd8710eb249665e18b7086707cbf0375a6b8f0,2018-06-18 15:10:37,196115050,"@@ -56,10 +58,9 @@ def check_seed(seed: str):
                     type=check_seed, required=False, dest='seed')
 
 parser.add_argument('-k', '--kind',",31,2018-06-18 15:55:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196115050,https://github.com/hyperledger/indy-node/pull/768#discussion_r196115050,ashcherbakov
https://github.com/hyperledger/indy-node/pull/768,https://github.com/hyperledger/indy-node/pull/768,I just prefer to have conversion from bool to int rather than conversion from int to bool,c0fd8710eb249665e18b7086707cbf0375a6b8f0,2018-06-19 06:42:44,196309402,"@@ -145,8 +152,10 @@ def reply(self, req_id, reply_or_exception):
             elif resp[""op""] == ""REPLY"":
                 self._req_succ += 1
                 status = ""succ""
-                server_time = int(resp['result']['txnTime'])
-                self._reqs[req_id][""server_reply""] = server_time
+                srv_tm = \
+                    resp['result'].get('txnTime', False) or resp['result'].get('txnMetadata', {}).get('txnTime', False)",102,2018-06-19 06:42:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196309402,https://github.com/hyperledger/indy-node/pull/768#discussion_r196309402,dsurnin
https://github.com/hyperledger/indy-node/pull/768,https://github.com/hyperledger/indy-node/pull/768,it will be a huge description and I think format could be changed after QA will check it in details,c0fd8710eb249665e18b7086707cbf0375a6b8f0,2018-06-19 06:44:37,196309728,"@@ -56,10 +58,9 @@ def check_seed(seed: str):
                     type=check_seed, required=False, dest='seed')
 
 parser.add_argument('-k', '--kind',
-                    help='Kind of request kind to use. One of [""nym"", ""schema"", ""attrib"", ""rand""]'
-                         'Default value is ""nym""',
-                    default=""nym"", choices=['nym', 'schema', 'attrib', 'rand'],
-                    required=False, dest='req_kind')
+                    help='Kind of request to send. One of [""nym"", ""schema"", ""attrib"", ""get_nym""] '
+                         'Default value is ""nym"". Could be combined in form of ""{req_type1: num, ...}"" ',",37,2018-06-19 06:44:37,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/196309728,https://github.com/hyperledger/indy-node/pull/768#discussion_r196309728,dsurnin
https://github.com/hyperledger/indy-node/pull/761,https://github.com/hyperledger/indy-node/pull/761,Do you mean `libindy_crypto_ver`?,b902941e876323ed9bd1afea744b512b5a21777b,2018-06-14 06:44:20,195316017,"@@ -4,9 +4,10 @@
   vars:
     pool_prefix: live_node
     pool_size: ""{{ groups['pool']|count }}""
-    node_ver: 1.3.388
-    plenum_ver: 1.2.331
-    crypto_ver: 0.4.0
+    node_ver: 1.3.448
+    plenum_ver: 1.2.390
+    crypto_ver: 0.4.1
+    libindy_ver: 0.4.0",,2018-06-14 09:32:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/195316017,https://github.com/hyperledger/indy-node/pull/761#discussion_r195316017,ashcherbakov
https://github.com/hyperledger/indy-node/pull/761,https://github.com/hyperledger/indy-node/pull/761,Do you mean `python_indy_crypto_ver`? Why it's different from `libindy_crypto_ver`?,b902941e876323ed9bd1afea744b512b5a21777b,2018-06-14 06:45:05,195316155,"@@ -4,9 +4,10 @@
   vars:
     pool_prefix: live_node
     pool_size: ""{{ groups['pool']|count }}""
-    node_ver: 1.3.388
-    plenum_ver: 1.2.331
-    crypto_ver: 0.4.0
+    node_ver: 1.3.448
+    plenum_ver: 1.2.390
+    crypto_ver: 0.4.1",,2018-06-14 09:32:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/195316155,https://github.com/hyperledger/indy-node/pull/761#discussion_r195316155,ashcherbakov
https://github.com/hyperledger/indy-node/pull/755,https://github.com/hyperledger/indy-node/pull/755,"You can provide default value as a second arg to get
result.get(DATA, {})",2215b3868d7965d0b3cd5f23f797cab4a92d336d,2018-06-13 07:50:24,194985062,"@@ -38,7 +40,7 @@ def _ensureReqCompleted(reqKey, client, clbk):
 
 
 def _getData(result, error):
-    data = result.get(DATA) if result.get(DATA) else {}
+    data = result.get(DATA) or {}",,2018-06-13 10:30:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194985062,https://github.com/hyperledger/indy-node/pull/755#discussion_r194985062,dsurnin
https://github.com/hyperledger/indy-node/pull/754,https://github.com/hyperledger/indy-node/pull/754,Please remove column at the end,dff2f2d543d4a3c557fc4c0d7e8a10711b452d50,2018-06-09 13:45:39,194227994,"@@ -0,0 +1,15 @@
+# List of broken changes for migration from indy-node 1.3 to 1.4:",,2018-06-13 10:46:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194227994,https://github.com/hyperledger/indy-node/pull/754#discussion_r194227994,ashcherbakov
https://github.com/hyperledger/indy-node/pull/754,https://github.com/hyperledger/indy-node/pull/754,`then default will be used`,dff2f2d543d4a3c557fc4c0d7e8a10711b452d50,2018-06-09 13:46:22,194228018,"@@ -0,0 +1,15 @@
+# List of broken changes for migration from indy-node 1.3 to 1.4:
+
+-**Another format of REPLY for ""WRITE"" transactions**. New REPLY format you can see in:
+ [REPLY for ""WRITE"" txns](https://github.com/hyperledger/indy-node/blob/master/docs/requests.md#reply-structure-for-write-requests).
+ The main goal for this changes is to divide data and metadata.
+
+-**Change key of ReqIdrToTxn store**.   For now, ReqIdrToTxn store request from client as a map of:
+ (digest) -> (ledger_id<some_delimiter>txn seq_no). Digest is a sha256 hash of (reqId, DID, operation). 
+ Also, digest was moved to transaction metadata section.
+ 
+-**Added tag for CLAIM_DEF**. 'TAG' is a part of key for state tree. If this field exist in incoming transaction, then it will be used. If not, then default.  ",,2018-06-13 10:46:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194228018,https://github.com/hyperledger/indy-node/pull/754#discussion_r194228018,ashcherbakov
https://github.com/hyperledger/indy-node/pull/754,https://github.com/hyperledger/indy-node/pull/754,Please also include the reference to `requests.md ` here,dff2f2d543d4a3c557fc4c0d7e8a10711b452d50,2018-06-09 13:46:55,194228039,"@@ -0,0 +1,15 @@
+# List of broken changes for migration from indy-node 1.3 to 1.4:
+
+-**Another format of REPLY for ""WRITE"" transactions**. New REPLY format you can see in:
+ [REPLY for ""WRITE"" txns](https://github.com/hyperledger/indy-node/blob/master/docs/requests.md#reply-structure-for-write-requests).
+ The main goal for this changes is to divide data and metadata.
+
+-**Change key of ReqIdrToTxn store**.   For now, ReqIdrToTxn store request from client as a map of:
+ (digest) -> (ledger_id<some_delimiter>txn seq_no). Digest is a sha256 hash of (reqId, DID, operation). 
+ Also, digest was moved to transaction metadata section.
+ 
+-**Added tag for CLAIM_DEF**. 'TAG' is a part of key for state tree. If this field exist in incoming transaction, then it will be used. If not, then default.  
+Full CLAIM_DEF format description you can see in: [CLAIM_DEF](https://github.com/hyperledger/indy-node/blob/master/docs/transactions.md#claim_def)",,2018-06-13 10:46:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194228039,https://github.com/hyperledger/indy-node/pull/754#discussion_r194228039,ashcherbakov
https://github.com/hyperledger/indy-node/pull/754,https://github.com/hyperledger/indy-node/pull/754,storages,dff2f2d543d4a3c557fc4c0d7e8a10711b452d50,2018-06-09 13:47:12,194228047,"@@ -0,0 +1,15 @@
+# List of broken changes for migration from indy-node 1.3 to 1.4:
+
+-**Another format of REPLY for ""WRITE"" transactions**. New REPLY format you can see in:
+ [REPLY for ""WRITE"" txns](https://github.com/hyperledger/indy-node/blob/master/docs/requests.md#reply-structure-for-write-requests).
+ The main goal for this changes is to divide data and metadata.
+
+-**Change key of ReqIdrToTxn store**.   For now, ReqIdrToTxn store request from client as a map of:
+ (digest) -> (ledger_id<some_delimiter>txn seq_no). Digest is a sha256 hash of (reqId, DID, operation). 
+ Also, digest was moved to transaction metadata section.
+ 
+-**Added tag for CLAIM_DEF**. 'TAG' is a part of key for state tree. If this field exist in incoming transaction, then it will be used. If not, then default.  
+Full CLAIM_DEF format description you can see in: [CLAIM_DEF](https://github.com/hyperledger/indy-node/blob/master/docs/transactions.md#claim_def)
+
+-**Migration fom levelDB to RocksDB**. Rocksdb has a native 'seek' methods, more flexible, has snapshots support and works well on Windows.
+For now, all of internal node's storage use this db as a default key-value storage.  ",,2018-06-13 10:46:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194228047,https://github.com/hyperledger/indy-node/pull/754#discussion_r194228047,ashcherbakov
https://github.com/hyperledger/indy-node/pull/754,https://github.com/hyperledger/indy-node/pull/754, ReqIdrToTxn stores,dff2f2d543d4a3c557fc4c0d7e8a10711b452d50,2018-06-09 13:47:28,194228056,"@@ -0,0 +1,15 @@
+# List of broken changes for migration from indy-node 1.3 to 1.4:
+
+-**Another format of REPLY for ""WRITE"" transactions**. New REPLY format you can see in:
+ [REPLY for ""WRITE"" txns](https://github.com/hyperledger/indy-node/blob/master/docs/requests.md#reply-structure-for-write-requests).
+ The main goal for this changes is to divide data and metadata.
+
+-**Change key of ReqIdrToTxn store**.   For now, ReqIdrToTxn store request from client as a map of:",,2018-06-13 10:46:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194228056,https://github.com/hyperledger/indy-node/pull/754#discussion_r194228056,ashcherbakov
https://github.com/hyperledger/indy-node/pull/754,https://github.com/hyperledger/indy-node/pull/754,"Please mention a migration script that will be called during upgrade. 
Please mention that it will be called automatically if a Node is updated via POOL_UPGRADE txn, and that it needs to be called manually if a node was updated manually.",dff2f2d543d4a3c557fc4c0d7e8a10711b452d50,2018-06-09 13:48:52,194228088,"@@ -0,0 +1,15 @@
+# List of broken changes for migration from indy-node 1.3 to 1.4:
+",,2018-06-13 10:46:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194228088,https://github.com/hyperledger/indy-node/pull/754#discussion_r194228088,ashcherbakov
https://github.com/hyperledger/indy-node/pull/754,https://github.com/hyperledger/indy-node/pull/754,"It should be
`**Change key of ReqIdrToTxn store**.   For now, ReqIdrToTxn stores .....`",dff2f2d543d4a3c557fc4c0d7e8a10711b452d50,2018-06-13 07:59:49,194987551,"@@ -1,15 +1,25 @@
-# List of broken changes for migration from indy-node 1.3 to 1.4:
+# List of broken changes for migration from indy-node 1.3 to 1.4
 
 -**Another format of REPLY for ""WRITE"" transactions**. New REPLY format you can see in:
  [REPLY for ""WRITE"" txns](https://github.com/hyperledger/indy-node/blob/master/docs/requests.md#reply-structure-for-write-requests).
  The main goal for this changes is to divide data and metadata.
 
--**Change key of ReqIdrToTxn store**.   For now, ReqIdrToTxn store request from client as a map of:
+-**Change key of ReqIdrToTxn stores**.   For now, ReqIdrToTxn store request from client as a map of:",,2018-06-13 10:46:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194987551,https://github.com/hyperledger/indy-node/pull/754#discussion_r194987551,ashcherbakov
https://github.com/hyperledger/indy-node/pull/754,https://github.com/hyperledger/indy-node/pull/754,`If this field exists`,dff2f2d543d4a3c557fc4c0d7e8a10711b452d50,2018-06-13 08:00:17,194987656,"@@ -1,15 +1,25 @@
-# List of broken changes for migration from indy-node 1.3 to 1.4:
+# List of broken changes for migration from indy-node 1.3 to 1.4
 
 -**Another format of REPLY for ""WRITE"" transactions**. New REPLY format you can see in:
  [REPLY for ""WRITE"" txns](https://github.com/hyperledger/indy-node/blob/master/docs/requests.md#reply-structure-for-write-requests).
  The main goal for this changes is to divide data and metadata.
 
--**Change key of ReqIdrToTxn store**.   For now, ReqIdrToTxn store request from client as a map of:
+-**Change key of ReqIdrToTxn stores**.   For now, ReqIdrToTxn store request from client as a map of:
  (digest) -> (ledger_id<some_delimiter>txn seq_no). Digest is a sha256 hash of (reqId, DID, operation). 
  Also, digest was moved to transaction metadata section.
  
--**Added tag for CLAIM_DEF**. 'TAG' is a part of key for state tree. If this field exist in incoming transaction, then it will be used. If not, then default.  
+-**Added tag for CLAIM_DEF**. 'TAG' is a part of key for state tree. If this field exist in incoming transaction, then it will be used. If not, then default will be used.  ",,2018-06-13 10:46:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194987656,https://github.com/hyperledger/indy-node/pull/754#discussion_r194987656,ashcherbakov
https://github.com/hyperledger/indy-node/pull/754,https://github.com/hyperledger/indy-node/pull/754,`Full CLAIM_DEF format description can be found in [CLAIM_DEF txn format](https://github.com/hyperledger/indy-node/blob/master/docs/transactions.md#claim_def) and [CLAIM_DEF request format](https://github.com/hyperledger/indy-node/blob/master/docs/requests.md#claim_def)`,dff2f2d543d4a3c557fc4c0d7e8a10711b452d50,2018-06-13 08:01:34,194987984,"@@ -1,15 +1,25 @@
-# List of broken changes for migration from indy-node 1.3 to 1.4:
+# List of broken changes for migration from indy-node 1.3 to 1.4
 
 -**Another format of REPLY for ""WRITE"" transactions**. New REPLY format you can see in:
  [REPLY for ""WRITE"" txns](https://github.com/hyperledger/indy-node/blob/master/docs/requests.md#reply-structure-for-write-requests).
  The main goal for this changes is to divide data and metadata.
 
--**Change key of ReqIdrToTxn store**.   For now, ReqIdrToTxn store request from client as a map of:
+-**Change key of ReqIdrToTxn stores**.   For now, ReqIdrToTxn store request from client as a map of:
  (digest) -> (ledger_id<some_delimiter>txn seq_no). Digest is a sha256 hash of (reqId, DID, operation). 
  Also, digest was moved to transaction metadata section.
  
--**Added tag for CLAIM_DEF**. 'TAG' is a part of key for state tree. If this field exist in incoming transaction, then it will be used. If not, then default.  
+-**Added tag for CLAIM_DEF**. 'TAG' is a part of key for state tree. If this field exist in incoming transaction, then it will be used. If not, then default will be used.  
 Full CLAIM_DEF format description you can see in: [CLAIM_DEF](https://github.com/hyperledger/indy-node/blob/master/docs/transactions.md#claim_def)",,2018-06-13 10:46:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/194987984,https://github.com/hyperledger/indy-node/pull/754#discussion_r194987984,ashcherbakov
https://github.com/hyperledger/indy-node/pull/743,https://github.com/hyperledger/indy-node/pull/743,Why is it not `reqIdToTxnStorage`,2712e2bd642dd7b70e14454902c4c60d96984fea,2018-06-05 13:28:12,193070843,"@@ -54,10 +67,59 @@ def get_node_name():
     return node_name
 
 
+def get_ledger_id_by_txn_type(txn_type):
+
+    def get_types_for_req_handler(req_handler):
+        return list(req_handler.write_types) + list(req_handler.query_types)
+
+    if txn_type in get_types_for_req_handler(PoolRequestHandler):
+        return POOL_LEDGER_ID
+    elif txn_type in get_types_for_req_handler(DomainReqHandler):
+        return DOMAIN_LEDGER_ID
+    elif txn_type in get_types_for_req_handler(ConfigReqHandler):
+        return CONFIG_LEDGER_ID
+    else:
+        logger.error(""Unknown txn_type: {}"".format(txn_type))
+        logger.error(""Cannot write txn into SeqNoDB, because cannot define ledger_id"")
+        sys.exit(1)
+
+
 def migrate_txn_log(db_dir, db_name):
+
+    def put_into_seq_no_db(txn):
+        # If there is no reqId, then it's genesis txn
+        if get_req_id(txn) is None:
+            return
+        txn_new = copy.deepcopy(txn)
+        operation = get_payload_data(txn_new)
+        operation[TXN_TYPE] = get_type(txn_new)
+        dct = {
+            f.IDENTIFIER.nm: get_from(txn_new),
+            f.REQ_ID.nm: get_req_id(txn_new),
+            OPERATION: operation,
+        }
+        if get_protocol_version(txn_new) is not None:
+            dct[f.PROTOCOL_VERSION.nm] = get_protocol_version(txn_new)
+        digest = sha256(serialize_msg_for_signing(dct)).hexdigest().encode()
+        seq_no = get_seq_no(txn_new).encode()
+        ledger_id = get_ledger_id_by_txn_type(operation[TXN_TYPE])
+        line_to_record = str(ledger_id) + ReqIdrToTxn.delimiter + str(seq_no)
+        dest_seq_no_db_storage.put(digest, line_to_record)
+        return digest
+
     new_db_name = db_name + '_new'
     old_path = os.path.join(db_dir, db_name)
     new_path = os.path.join(db_dir, new_db_name)
+    new_seqno_db_name = config.stateTsDbName + '_new'",,2018-06-06 07:56:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/193070843,https://github.com/hyperledger/indy-node/pull/743#discussion_r193070843,ashcherbakov
https://github.com/hyperledger/indy-node/pull/743,https://github.com/hyperledger/indy-node/pull/743,Why is it not `reqIdToTxnStorage`?,2712e2bd642dd7b70e14454902c4c60d96984fea,2018-06-05 13:31:48,193072156,"@@ -106,12 +174,29 @@ def migrate_txn_log(db_dir, db_name):
         logger.error(""Could not rename temporary new ledger from '{}' to '{}'""
                      .format(new_path, old_path))
         return False
-
-    set_own_perm(""indy"", old_path)
+    try:
+        set_own_perm(""indy"", old_path)
+    except Exception:
+        pass
 
     return True
 
 
+def rename_seq_no_db(db_dir):
+    old_seqno_path = os.path.join(db_dir, config.stateTsDbName)",,2018-06-06 07:56:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/193072156,https://github.com/hyperledger/indy-node/pull/743#discussion_r193072156,ashcherbakov
https://github.com/hyperledger/indy-node/pull/743,https://github.com/hyperledger/indy-node/pull/743,Do we remove old `seqNoDb`?,2712e2bd642dd7b70e14454902c4c60d96984fea,2018-06-05 13:32:42,193072497,"@@ -106,12 +174,29 @@ def migrate_txn_log(db_dir, db_name):
         logger.error(""Could not rename temporary new ledger from '{}' to '{}'""
                      .format(new_path, old_path))
         return False
-
-    set_own_perm(""indy"", old_path)
+    try:
+        set_own_perm(""indy"", old_path)
+    except Exception:
+        pass
 
     return True
 
 
+def rename_seq_no_db(db_dir):
+    old_seqno_path = os.path.join(db_dir, config.stateTsDbName)
+    new_seqno_db_name = config.stateTsDbName + '_new'
+    new_seqno_path = os.path.join(db_dir, new_seqno_db_name)
+    try:
+        shutil.move(new_seqno_path, old_seqno_path)",,2018-06-06 07:56:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/193072497,https://github.com/hyperledger/indy-node/pull/743#discussion_r193072497,ashcherbakov
https://github.com/hyperledger/indy-node/pull/743,https://github.com/hyperledger/indy-node/pull/743,Why is it commented?,2712e2bd642dd7b70e14454902c4c60d96984fea,2018-06-05 13:33:02,193072604,"@@ -196,6 +280,9 @@ def migrate_all():
         logger.error(""Txn log migration from old to new format failed!"")
         return False
 
+    # Rename new seq_no_db into old
+    # rename_seq_no_db(ledger_dir)",,2018-06-06 07:56:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/193072604,https://github.com/hyperledger/indy-node/pull/743#discussion_r193072604,ashcherbakov
https://github.com/hyperledger/indy-node/pull/743,https://github.com/hyperledger/indy-node/pull/743,"Should we do it for genesis txns as well? If we do, then we will have to migrate sovrin genesis txns and generation of tests txns...
",2712e2bd642dd7b70e14454902c4c60d96984fea,2018-06-06 07:01:32,193309879,"@@ -77,17 +138,23 @@ def migrate_txn_log(db_dir, db_name):
     # put values from old ledger to the new one
     try:
         for key, val in src_storage.iterator():
+            key = key.decode()
             val = ledger_txn_serializer.deserialize(val)
             new_val = transform_to_new_format(txn=val, seq_no=int(key))
+            digest = put_into_seq_no_db(new_val)
+            # add digest into txn
+            new_val[TXN_PAYLOAD][TXN_PAYLOAD_METADATA][TXN_PAYLOAD_METADATA_DIGEST] = digest",,2018-06-06 07:56:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/193309879,https://github.com/hyperledger/indy-node/pull/743#discussion_r193309879,ashcherbakov
https://github.com/hyperledger/indy-node/pull/739,https://github.com/hyperledger/indy-node/pull/739,Did we remove it intentionally?,a0f78b42b778d62faebb5b843049eaf5bab00780,2018-06-04 14:25:07,192758782,"@@ -1,60 +0,0 @@
-import json",1,2018-06-04 14:25:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192758782,https://github.com/hyperledger/indy-node/pull/739#discussion_r192758782,ashcherbakov
https://github.com/hyperledger/indy-node/pull/739,https://github.com/hyperledger/indy-node/pull/739,Yes. This is obsolete tests which were written before https://github.com/hyperledger/indy-post-install-automation ,a0f78b42b778d62faebb5b843049eaf5bab00780,2018-06-05 08:34:06,192989102,"@@ -1,60 +0,0 @@
-import json",1,2018-06-05 08:34:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192989102,https://github.com/hyperledger/indy-node/pull/739#discussion_r192989102,ozheregelya
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"From Alex:
We use pytest for testing. Can we switch to pytest to execute the test during CI?",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:41:48,192198563,"@@ -0,0 +1,782 @@
+#!/usr/bin/env python3
+
+import sys
+import os
+import argparse
+import logging
+import datetime
+import time
+from collections import namedtuple
+import tempfile
+import subprocess
+import atexit
+import shutil
+
+from io import StringIO
+
+from plenum.server.general_config import ubuntu_platform_config
+
+logger = logging.getLogger()
+
+ArchiveEntry = namedtuple('archive_entry', ['abs_fs_path', 'archive_path', 'include'])
+
+ENV_COLLECTION_CMD = [
+    (""python_version"", ['python3', '-V']),
+    (""pip_freeze"", ['pip3', 'freeze']),
+    (""app_install"", ['apt', 'list', '--installed']),
+    (""validator_info"", ['validator-info', '-v']),
+]
+
+
+# ***************
+# *  Command-line Argument Parsing
+# ***************
+def str2bool(v):
+    if v.lower() in ('yes', 'true', 't', 'y', '1'):
+        return True
+    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
+        return False
+    else:
+        raise argparse.ArgumentTypeError(
+            'Boolean value (yes, no, true, false, y, n, 1, or 0) expected.')
+
+
+LOG_LEVEL_HELP = """"""Logging level.
+                      [LOG-LEVEL]: notset, debug, info, warning, error, critical
+                      Default: warning""""""
+levels = {
+    'notset': logging.NOTSET,
+    'debug': logging.DEBUG,
+    'info': logging.INFO,
+    'warning': logging.WARNING,
+    'error': logging.ERROR,
+    'critical': logging.CRITICAL
+}
+
+
+def log_level(v):
+    if v.lower() in levels.keys():
+        return levels[v.lower()]
+    else:
+        raise argparse.ArgumentTypeError(
+            'Expected one of the following: {}.'.format(
+                ', '.join(levels.keys())))
+
+
+def program_args():
+    parser = argparse.ArgumentParser()
+
+    parser.add_argument('-t', '--test', action='store_true',
+                        default=False, help='Runs unit tests and exits.')
+
+    parser.add_argument('-l', '--log-level', type=log_level, nargs='?',
+                        const=logging.INFO, default=logging.INFO, help=LOG_LEVEL_HELP)
+
+    parser.add_argument('-o', '--output-dir', default=os.getcwd(),
+                        help='the directory where the captured file will be writen to. Default: CWD')
+    parser.add_argument('-n', '--node-name',
+                        help='The name of the node to be captured, required if the script finds more than one node.')
+    parser.add_argument('-r', '--root-dir', default='/',
+                        help='The root to look for node artifacts. Default: /')
+
+    parser.add_argument('-x', '--exclude-recording', action='store_true',
+                        help='Will exclude recording data from capture.')
+    parser.add_argument('-d', '--dry-run', action='store_true',
+                        default=False, help='Will not create archive file but will collect files to be collected')
+
+    return parser
+
+
+def parse_args(argv=None, parser=program_args()):
+    return parser.parse_args(args=argv)
+
+
+def get_system_dirs():
+    # TODO detect the system someday (help support windows)
+    return ubuntu_platform_config
+
+
+# ***************
+# *  Capture File Collection
+# ***************
+def _log_capture(collection):
+    for entry in collection:
+        logger.info(""%s found at %s"" % (entry.archive_path, entry.abs_fs_path))
+        for file in entry.include:
+            logger.info(""    %s"" % file)
+
+
+def _collect_files(dir_type, directory, archive_path, filter_fn, recursive=True):
+    if not os.path.exists(directory):
+        return None
+
+    rtn = ArchiveEntry(directory, archive_path, [])
+
+    try:
+        for root, dirs, files in os.walk(directory):
+            rel_path = os.path.relpath(root, directory)
+            files = [os.path.join(rel_path, f) for f in files]
+            files = filter(filter_fn, files)
+            rtn.include.extend(files)
+            if recursive is not True:
+                break
+    except FileNotFoundError:
+        logger.warning(""Unable to find a %s directory for pool! Looked for '%s'"", dir_type, directory)
+
+    return rtn
+
+
+def _run_env_capture_cmd(output_file, cmd, entry):
+    try:
+        with open(output_file, 'w') as f:
+            subprocess.run(cmd,
+                           check=True,
+                           stderr=subprocess.STDOUT,
+                           stdout=f
+                           )
+    except (subprocess.CalledProcessError, FileNotFoundError) as e:
+        logger.warning(""Unable to capture env data: cmd '%s' - error: %s"", ' '.join(cmd), str(e))
+    finally:
+        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
+            entry.include.append(output_file)
+
+
+def collect_env(args):
+    logger.info(""Collecting Env Files"")
+    d = tempfile.mkdtemp()
+    TEMP_DIRS.append(d)
+    rtn = ArchiveEntry(d, '/capture', [])
+    for filename, cmd in ENV_COLLECTION_CMD:
+        _run_env_capture_cmd(os.path.join(d, filename),
+                             cmd,
+                             rtn)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_logs(args):
+    log_dir = indy_log_dir(args)
+    log_dir = os.path.join(log_dir, args.pool_name)
+
+    def log_filter(f):
+        return f.startswith(os.path.join('.', args.node_name))
+
+    logger.info(""Collecting Log Files"")
+    rtn = _collect_files('log',
+                         log_dir,
+                         '/log',
+                         log_filter,
+                         recursive=False)
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Log"")
+    return rtn
+
+
+def collect_config(args):
+    d = indy_config_dir(args)
+
+    def file_filter(_f):
+        return True
+
+    logger.info(""Collecting Config Files"")
+    rtn = _collect_files('config', d, '/config', file_filter, recursive=False)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Config"")
+
+    return rtn
+
+
+def collect_data(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, args.pool_name)
+
+    def file_filter(f):
+        if f.startswith('data/'):
+            if f.startswith(os.path.join('data/', args.node_name + '/')) \
+                    or f.startswith(os.path.join('data/', args.node_name + 'C/')):
+
+                if 'recorder' in f:
+                    return not args.exclude_recording
+                return True
+            else:
+                return False
+
+        return True
+
+    logger.info(""Collecting Data Files"")
+    rtn = _collect_files('application data', d, '/', file_filter, recursive=True)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Data"")
+
+    return rtn
+
+
+def collect_plugins(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, 'plugins')
+
+    def file_filter(f):
+        return True
+
+    logger.info(""Collecting Plugins Files"")
+    rtn = _collect_files('plugin data', d, '/plugins', file_filter, recursive=True)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Plugins"")
+
+    return rtn
+
+
+COLLECT_FN = [
+    collect_env,
+    collect_logs,
+    collect_config,
+    collect_data,
+    collect_plugins,
+]
+
+
+def collect_capture_files(args):
+    rtn = []
+    logger.info(""Collecting file to be captured"")
+    for fn in COLLECT_FN:
+        val = fn(args)
+        if val:
+            rtn.append(val)
+    logger.info(""Collection complete"")
+    return rtn
+
+
+# ***************
+# *  Indy Directories
+# ***************
+def _find_dir(args, dir_location, name):
+    dir_location = dir_location.lstrip(""/"")
+    rtn = os.path.join(args.root_dir, dir_location)
+    logger.debug(""using %s dir: %s"", name, rtn)
+    return rtn
+
+
+def indy_app_dir(args):
+    return _find_dir(args, get_system_dirs().NODE_INFO_DIR, ""application dir"")
+
+
+def indy_log_dir(args):
+    return _find_dir(args, get_system_dirs().LOG_DIR, ""logging dir"")
+
+
+def indy_config_dir(args):
+    return _find_dir(args, '/etc/indy', ""config dir"")
+
+
+# ***************
+# *  Capture File Output File Name
+# ***************
+def capture_file_name(args):
+    if (not hasattr(args, 'node_name') or not hasattr(args, 'pool_name')) or \
+            (args.node_name is None or args.pool_name is None):
+        logger.error(""node_name or pool_name has not been specified, can not create capture file name. Object: %s"",
+                     str(args))
+        raise Exception(""Can not create capture file name!"")
+
+    rtn = ""%s.%s.%s"" % (args.node_name, args.pool_name, datetime.datetime.now().strftime(""%Y%m%d%H%M%S""))
+    return rtn
+
+
+# ***************
+# *  Node Discovery
+# ***************
+def find_node_name(args):
+    nodes = []
+
+    def find_nodes_in_pool_dir(pool_name):
+        data_dir = os.path.join(indy_app_dir(args), pool_name, ""data"")
+
+        try:
+            possible_nodes = sorted(os.listdir(data_dir))
+        except FileNotFoundError:
+            logger.warning(""Did not find a data directory for pool '%s'! (Likely not an issue) Looked for '%s'"",
+                           pool_name, data_dir)
+            return []
+
+        possible_nodes = list(filter(is_dir_check(data_dir), possible_nodes))
+        logger.debug(""possible node names in %s: %s"", pool_name, possible_nodes)
+        node_names = set()
+        while len(possible_nodes) is not 0:
+            a_name = possible_nodes.pop(0)
+            if a_name + 'C' in possible_nodes:
+                possible_nodes.remove(a_name + 'C')
+            node_names.add((a_name, pool_name))
+
+
+        return node_names
+
+    def is_dir_check(base_dir):
+        def is_dir(d):
+            return os.path.isdir(os.path.join(base_dir, d))
+
+        return is_dir
+
+    app_dir = indy_app_dir(args)
+    try:
+        pool_dirs = list(filter(is_dir_check(indy_app_dir(args)), os.listdir(app_dir)))
+    except FileNotFoundError:
+        logger.error(""Unable to find indy application directory! Looked for '%s'"", app_dir)
+        raise
+
+    for pool in pool_dirs:
+        # ignore plugins dir - it is not a pool directory
+        if ""plugins"" == pool:
+            continue
+
+        nodes.extend(find_nodes_in_pool_dir(pool))
+
+    if args.node_name is None:
+        if len(nodes) == 1:
+            node_name, pool = nodes.pop()
+            args.node_name = node_name
+            args.pool_name = pool
+        elif len(nodes) == 0:
+            logger.error(""No nodes where found. Check root dir?"", nodes)
+            sys.exit(-1)
+        else:
+            logger.error(""Found more than one node and a node name was not specified! Found -- %s"", nodes)
+            sys.exit(-1)
+    else:
+        for node in nodes:
+            if args.node_name == node[0]:
+                args.pool_name = node[1]
+                break
+        else:
+            logger.error(""Node with name '%s' was not found, can not continue! Found -- %s"", args.node_name, nodes)
+            sys.exit(-1)
+
+    logger.info(""Capturing Node '%s' for pool '%s'"", args.node_name, args.pool_name)
+
+
+TEMP_DIRS = []
+
+
+# Clean up anything that is created by this script (excluding the output file)
+def clean_up():
+    while TEMP_DIRS:
+        shutil.rmtree(TEMP_DIRS.pop())
+
+        # raise Exception(""TEST"")
+
+
+# ***************
+# *  Init Details
+# ***************
+def init(args):
+    # print warning
+    print(""!"" * 20 + "" WARNING "" + '!' * 21)
+    print(""!"" * 2 + ""  "" + ""This tool captures node state replay and diagnostic purposes (for development and QA)"")
+    print(""!"" * 2 + ""  "" + ""By the nature of these needs, that includes sensitive data (including secret keys)"")
+    print(""!"" * 2 + ""  "" + ""DO NOT USE THIS TOOL on nodes that need to be secure"")
+    print(""!"" * 50)
+    time.sleep(1)
+
+    logger.setLevel(args.log_level)
+    logger.debug(""args: %s"", args)
+    find_node_name(args)
+
+    atexit.register(clean_up)
+
+
+def build_archive_cmd(output_file, files):
+    cmd = ['tar']
+    flags = 'cfz'
+    if logger.level == logging.DEBUG:
+        flags += 'v'
+    cmd.append(flags)
+    cmd.append(output_file)
+    cmd.append('--show-transformed-names')
+    cmd.extend([""-C"", ""/""])
+
+    for entry in files:
+        fs_path_pattern = entry.abs_fs_path.strip('/')
+        archive_path_pattern = entry.archive_path.lstrip('/')
+        if archive_path_pattern:
+            archive_path_pattern += '/'  # Add slash for directories otherwise leave blank
+
+        if entry.include:
+            cmd.append('--xform')
+            cmd.append(""s|%s/|%s|1"" % (fs_path_pattern, archive_path_pattern))
+            for file in entry.include:
+                f_path = os.path.join(entry.abs_fs_path, file)
+                f_path = os.path.abspath(f_path)
+                f_path = f_path.lstrip('/')
+                cmd.append(f_path)
+        else:
+            cmd.append('--xform')
+            cmd.append(""s|%s|%s|1"" % (fs_path_pattern, archive_path_pattern))
+            f_path = entry.abs_fs_path.strip('/')
+            cmd.append(f_path + '/')  # Add slash to end for sed expression matching
+
+    return cmd
+
+
+# ***************
+# *  Running the archive command
+# ***************
+def run_cmd(cmd):
+    logger.info(""Running archive command"")
+    try:
+        subprocess.run(cmd, check=True)
+        # os.system(' '.join(cmd))
+    except Exception as e:
+        logger.error(""Unable to complete archive command: %s"", str(e))
+    else:
+        logger.info(""Archive command complete"")
+
+
+def do_capture(args, files):
+    output_file = os.path.join(args.output_dir, capture_file_name(args) + '.tar.gz')
+    logger.info(""Writing archive to '%s'"" % output_file)
+
+    logger.info(""Building archive command"")
+    cmd = build_archive_cmd(output_file, files)
+    logger.debug(""Archive command to be run:"")
+    logger.debug(' '.join(cmd))
+
+    if args.dry_run:
+        logger.info(""Dry-run"")
+        logger.info(""Collected following files:"")
+        _log_capture(files)
+        return
+    else:
+        # if os.getuid() is not 0:
+        # TODO Need to be more clever, only need to be super user when on a bare metal box
+        # logger.error(""Must be run as super user (sudo) to capture all files."")
+        # raise Exception(""Not Super User"")
+        run_cmd(cmd)
+
+
+def main(args):
+    try:
+        init(args)
+    except:
+        logger.error('Unable to initialize script')
+        raise
+
+    try:
+        files = collect_capture_files(args)
+    except:
+        logger.error('Unable to collect the files for this capture')
+        raise
+
+    try:
+        do_capture(args, files)
+    except:
+        logger.error('Unable to build capture archive')
+        raise
+
+
+# ***************",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192198563,https://github.com/hyperledger/indy-node/pull/737#discussion_r192198563,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"From Alex:
And please move tests to a separate folder (like in other places in code)",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:42:36,192198783,"@@ -0,0 +1,782 @@
+#!/usr/bin/env python3
+
+import sys
+import os
+import argparse
+import logging
+import datetime
+import time
+from collections import namedtuple
+import tempfile
+import subprocess
+import atexit
+import shutil
+
+from io import StringIO
+
+from plenum.server.general_config import ubuntu_platform_config
+
+logger = logging.getLogger()
+
+ArchiveEntry = namedtuple('archive_entry', ['abs_fs_path', 'archive_path', 'include'])
+
+ENV_COLLECTION_CMD = [
+    (""python_version"", ['python3', '-V']),
+    (""pip_freeze"", ['pip3', 'freeze']),
+    (""app_install"", ['apt', 'list', '--installed']),
+    (""validator_info"", ['validator-info', '-v']),
+]
+
+
+# ***************
+# *  Command-line Argument Parsing
+# ***************
+def str2bool(v):
+    if v.lower() in ('yes', 'true', 't', 'y', '1'):
+        return True
+    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
+        return False
+    else:
+        raise argparse.ArgumentTypeError(
+            'Boolean value (yes, no, true, false, y, n, 1, or 0) expected.')
+
+
+LOG_LEVEL_HELP = """"""Logging level.
+                      [LOG-LEVEL]: notset, debug, info, warning, error, critical
+                      Default: warning""""""
+levels = {
+    'notset': logging.NOTSET,
+    'debug': logging.DEBUG,
+    'info': logging.INFO,
+    'warning': logging.WARNING,
+    'error': logging.ERROR,
+    'critical': logging.CRITICAL
+}
+
+
+def log_level(v):
+    if v.lower() in levels.keys():
+        return levels[v.lower()]
+    else:
+        raise argparse.ArgumentTypeError(
+            'Expected one of the following: {}.'.format(
+                ', '.join(levels.keys())))
+
+
+def program_args():
+    parser = argparse.ArgumentParser()
+
+    parser.add_argument('-t', '--test', action='store_true',
+                        default=False, help='Runs unit tests and exits.')
+
+    parser.add_argument('-l', '--log-level', type=log_level, nargs='?',
+                        const=logging.INFO, default=logging.INFO, help=LOG_LEVEL_HELP)
+
+    parser.add_argument('-o', '--output-dir', default=os.getcwd(),
+                        help='the directory where the captured file will be writen to. Default: CWD')
+    parser.add_argument('-n', '--node-name',
+                        help='The name of the node to be captured, required if the script finds more than one node.')
+    parser.add_argument('-r', '--root-dir', default='/',
+                        help='The root to look for node artifacts. Default: /')
+
+    parser.add_argument('-x', '--exclude-recording', action='store_true',
+                        help='Will exclude recording data from capture.')
+    parser.add_argument('-d', '--dry-run', action='store_true',
+                        default=False, help='Will not create archive file but will collect files to be collected')
+
+    return parser
+
+
+def parse_args(argv=None, parser=program_args()):
+    return parser.parse_args(args=argv)
+
+
+def get_system_dirs():
+    # TODO detect the system someday (help support windows)
+    return ubuntu_platform_config
+
+
+# ***************
+# *  Capture File Collection
+# ***************
+def _log_capture(collection):
+    for entry in collection:
+        logger.info(""%s found at %s"" % (entry.archive_path, entry.abs_fs_path))
+        for file in entry.include:
+            logger.info(""    %s"" % file)
+
+
+def _collect_files(dir_type, directory, archive_path, filter_fn, recursive=True):
+    if not os.path.exists(directory):
+        return None
+
+    rtn = ArchiveEntry(directory, archive_path, [])
+
+    try:
+        for root, dirs, files in os.walk(directory):
+            rel_path = os.path.relpath(root, directory)
+            files = [os.path.join(rel_path, f) for f in files]
+            files = filter(filter_fn, files)
+            rtn.include.extend(files)
+            if recursive is not True:
+                break
+    except FileNotFoundError:
+        logger.warning(""Unable to find a %s directory for pool! Looked for '%s'"", dir_type, directory)
+
+    return rtn
+
+
+def _run_env_capture_cmd(output_file, cmd, entry):
+    try:
+        with open(output_file, 'w') as f:
+            subprocess.run(cmd,
+                           check=True,
+                           stderr=subprocess.STDOUT,
+                           stdout=f
+                           )
+    except (subprocess.CalledProcessError, FileNotFoundError) as e:
+        logger.warning(""Unable to capture env data: cmd '%s' - error: %s"", ' '.join(cmd), str(e))
+    finally:
+        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
+            entry.include.append(output_file)
+
+
+def collect_env(args):
+    logger.info(""Collecting Env Files"")
+    d = tempfile.mkdtemp()
+    TEMP_DIRS.append(d)
+    rtn = ArchiveEntry(d, '/capture', [])
+    for filename, cmd in ENV_COLLECTION_CMD:
+        _run_env_capture_cmd(os.path.join(d, filename),
+                             cmd,
+                             rtn)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_logs(args):
+    log_dir = indy_log_dir(args)
+    log_dir = os.path.join(log_dir, args.pool_name)
+
+    def log_filter(f):
+        return f.startswith(os.path.join('.', args.node_name))
+
+    logger.info(""Collecting Log Files"")
+    rtn = _collect_files('log',
+                         log_dir,
+                         '/log',
+                         log_filter,
+                         recursive=False)
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Log"")
+    return rtn
+
+
+def collect_config(args):
+    d = indy_config_dir(args)
+
+    def file_filter(_f):
+        return True
+
+    logger.info(""Collecting Config Files"")
+    rtn = _collect_files('config', d, '/config', file_filter, recursive=False)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Config"")
+
+    return rtn
+
+
+def collect_data(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, args.pool_name)
+
+    def file_filter(f):
+        if f.startswith('data/'):
+            if f.startswith(os.path.join('data/', args.node_name + '/')) \
+                    or f.startswith(os.path.join('data/', args.node_name + 'C/')):
+
+                if 'recorder' in f:
+                    return not args.exclude_recording
+                return True
+            else:
+                return False
+
+        return True
+
+    logger.info(""Collecting Data Files"")
+    rtn = _collect_files('application data', d, '/', file_filter, recursive=True)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Data"")
+
+    return rtn
+
+
+def collect_plugins(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, 'plugins')
+
+    def file_filter(f):
+        return True
+
+    logger.info(""Collecting Plugins Files"")
+    rtn = _collect_files('plugin data', d, '/plugins', file_filter, recursive=True)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Plugins"")
+
+    return rtn
+
+
+COLLECT_FN = [
+    collect_env,
+    collect_logs,
+    collect_config,
+    collect_data,
+    collect_plugins,
+]
+
+
+def collect_capture_files(args):
+    rtn = []
+    logger.info(""Collecting file to be captured"")
+    for fn in COLLECT_FN:
+        val = fn(args)
+        if val:
+            rtn.append(val)
+    logger.info(""Collection complete"")
+    return rtn
+
+
+# ***************
+# *  Indy Directories
+# ***************
+def _find_dir(args, dir_location, name):
+    dir_location = dir_location.lstrip(""/"")
+    rtn = os.path.join(args.root_dir, dir_location)
+    logger.debug(""using %s dir: %s"", name, rtn)
+    return rtn
+
+
+def indy_app_dir(args):
+    return _find_dir(args, get_system_dirs().NODE_INFO_DIR, ""application dir"")
+
+
+def indy_log_dir(args):
+    return _find_dir(args, get_system_dirs().LOG_DIR, ""logging dir"")
+
+
+def indy_config_dir(args):
+    return _find_dir(args, '/etc/indy', ""config dir"")
+
+
+# ***************
+# *  Capture File Output File Name
+# ***************
+def capture_file_name(args):
+    if (not hasattr(args, 'node_name') or not hasattr(args, 'pool_name')) or \
+            (args.node_name is None or args.pool_name is None):
+        logger.error(""node_name or pool_name has not been specified, can not create capture file name. Object: %s"",
+                     str(args))
+        raise Exception(""Can not create capture file name!"")
+
+    rtn = ""%s.%s.%s"" % (args.node_name, args.pool_name, datetime.datetime.now().strftime(""%Y%m%d%H%M%S""))
+    return rtn
+
+
+# ***************
+# *  Node Discovery
+# ***************
+def find_node_name(args):
+    nodes = []
+
+    def find_nodes_in_pool_dir(pool_name):
+        data_dir = os.path.join(indy_app_dir(args), pool_name, ""data"")
+
+        try:
+            possible_nodes = sorted(os.listdir(data_dir))
+        except FileNotFoundError:
+            logger.warning(""Did not find a data directory for pool '%s'! (Likely not an issue) Looked for '%s'"",
+                           pool_name, data_dir)
+            return []
+
+        possible_nodes = list(filter(is_dir_check(data_dir), possible_nodes))
+        logger.debug(""possible node names in %s: %s"", pool_name, possible_nodes)
+        node_names = set()
+        while len(possible_nodes) is not 0:
+            a_name = possible_nodes.pop(0)
+            if a_name + 'C' in possible_nodes:
+                possible_nodes.remove(a_name + 'C')
+            node_names.add((a_name, pool_name))
+
+
+        return node_names
+
+    def is_dir_check(base_dir):
+        def is_dir(d):
+            return os.path.isdir(os.path.join(base_dir, d))
+
+        return is_dir
+
+    app_dir = indy_app_dir(args)
+    try:
+        pool_dirs = list(filter(is_dir_check(indy_app_dir(args)), os.listdir(app_dir)))
+    except FileNotFoundError:
+        logger.error(""Unable to find indy application directory! Looked for '%s'"", app_dir)
+        raise
+
+    for pool in pool_dirs:
+        # ignore plugins dir - it is not a pool directory
+        if ""plugins"" == pool:
+            continue
+
+        nodes.extend(find_nodes_in_pool_dir(pool))
+
+    if args.node_name is None:
+        if len(nodes) == 1:
+            node_name, pool = nodes.pop()
+            args.node_name = node_name
+            args.pool_name = pool
+        elif len(nodes) == 0:
+            logger.error(""No nodes where found. Check root dir?"", nodes)
+            sys.exit(-1)
+        else:
+            logger.error(""Found more than one node and a node name was not specified! Found -- %s"", nodes)
+            sys.exit(-1)
+    else:
+        for node in nodes:
+            if args.node_name == node[0]:
+                args.pool_name = node[1]
+                break
+        else:
+            logger.error(""Node with name '%s' was not found, can not continue! Found -- %s"", args.node_name, nodes)
+            sys.exit(-1)
+
+    logger.info(""Capturing Node '%s' for pool '%s'"", args.node_name, args.pool_name)
+
+
+TEMP_DIRS = []
+
+
+# Clean up anything that is created by this script (excluding the output file)
+def clean_up():
+    while TEMP_DIRS:
+        shutil.rmtree(TEMP_DIRS.pop())
+
+        # raise Exception(""TEST"")
+
+
+# ***************
+# *  Init Details
+# ***************
+def init(args):
+    # print warning
+    print(""!"" * 20 + "" WARNING "" + '!' * 21)
+    print(""!"" * 2 + ""  "" + ""This tool captures node state replay and diagnostic purposes (for development and QA)"")
+    print(""!"" * 2 + ""  "" + ""By the nature of these needs, that includes sensitive data (including secret keys)"")
+    print(""!"" * 2 + ""  "" + ""DO NOT USE THIS TOOL on nodes that need to be secure"")
+    print(""!"" * 50)
+    time.sleep(1)
+
+    logger.setLevel(args.log_level)
+    logger.debug(""args: %s"", args)
+    find_node_name(args)
+
+    atexit.register(clean_up)
+
+
+def build_archive_cmd(output_file, files):
+    cmd = ['tar']
+    flags = 'cfz'
+    if logger.level == logging.DEBUG:
+        flags += 'v'
+    cmd.append(flags)
+    cmd.append(output_file)
+    cmd.append('--show-transformed-names')
+    cmd.extend([""-C"", ""/""])
+
+    for entry in files:
+        fs_path_pattern = entry.abs_fs_path.strip('/')
+        archive_path_pattern = entry.archive_path.lstrip('/')
+        if archive_path_pattern:
+            archive_path_pattern += '/'  # Add slash for directories otherwise leave blank
+
+        if entry.include:
+            cmd.append('--xform')
+            cmd.append(""s|%s/|%s|1"" % (fs_path_pattern, archive_path_pattern))
+            for file in entry.include:
+                f_path = os.path.join(entry.abs_fs_path, file)
+                f_path = os.path.abspath(f_path)
+                f_path = f_path.lstrip('/')
+                cmd.append(f_path)
+        else:
+            cmd.append('--xform')
+            cmd.append(""s|%s|%s|1"" % (fs_path_pattern, archive_path_pattern))
+            f_path = entry.abs_fs_path.strip('/')
+            cmd.append(f_path + '/')  # Add slash to end for sed expression matching
+
+    return cmd
+
+
+# ***************
+# *  Running the archive command
+# ***************
+def run_cmd(cmd):
+    logger.info(""Running archive command"")
+    try:
+        subprocess.run(cmd, check=True)
+        # os.system(' '.join(cmd))
+    except Exception as e:
+        logger.error(""Unable to complete archive command: %s"", str(e))
+    else:
+        logger.info(""Archive command complete"")
+
+
+def do_capture(args, files):
+    output_file = os.path.join(args.output_dir, capture_file_name(args) + '.tar.gz')
+    logger.info(""Writing archive to '%s'"" % output_file)
+
+    logger.info(""Building archive command"")
+    cmd = build_archive_cmd(output_file, files)
+    logger.debug(""Archive command to be run:"")
+    logger.debug(' '.join(cmd))
+
+    if args.dry_run:
+        logger.info(""Dry-run"")
+        logger.info(""Collected following files:"")
+        _log_capture(files)
+        return
+    else:
+        # if os.getuid() is not 0:
+        # TODO Need to be more clever, only need to be super user when on a bare metal box
+        # logger.error(""Must be run as super user (sudo) to capture all files."")
+        # raise Exception(""Not Super User"")
+        run_cmd(cmd)
+
+
+def main(args):
+    try:
+        init(args)
+    except:
+        logger.error('Unable to initialize script')
+        raise
+
+    try:
+        files = collect_capture_files(args)
+    except:
+        logger.error('Unable to collect the files for this capture')
+        raise
+
+    try:
+        do_capture(args, files)
+    except:
+        logger.error('Unable to build capture archive')
+        raise
+
+
+# ***************",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192198783,https://github.com/hyperledger/indy-node/pull/737#discussion_r192198783,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"nscapture was written as a stand-alone script. It is not a python module. It is outside the view of pytest. I choose unittest so there was no dependency to run the test. Also, unittest was easier to run via a command line option (-t). I'm welcome to discuss how to do this better but simply putting them in a directory and using pytest would not accomplish my portable stand-alone CLI script requirement requirements.

The tests are exercised in the CI system in indy_node/test/tools/test_nsrepay.py",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:42:42,192198815,"@@ -0,0 +1,782 @@
+#!/usr/bin/env python3
+
+import sys
+import os
+import argparse
+import logging
+import datetime
+import time
+from collections import namedtuple
+import tempfile
+import subprocess
+import atexit
+import shutil
+
+from io import StringIO
+
+from plenum.server.general_config import ubuntu_platform_config
+
+logger = logging.getLogger()
+
+ArchiveEntry = namedtuple('archive_entry', ['abs_fs_path', 'archive_path', 'include'])
+
+ENV_COLLECTION_CMD = [
+    (""python_version"", ['python3', '-V']),
+    (""pip_freeze"", ['pip3', 'freeze']),
+    (""app_install"", ['apt', 'list', '--installed']),
+    (""validator_info"", ['validator-info', '-v']),
+]
+
+
+# ***************
+# *  Command-line Argument Parsing
+# ***************
+def str2bool(v):
+    if v.lower() in ('yes', 'true', 't', 'y', '1'):
+        return True
+    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
+        return False
+    else:
+        raise argparse.ArgumentTypeError(
+            'Boolean value (yes, no, true, false, y, n, 1, or 0) expected.')
+
+
+LOG_LEVEL_HELP = """"""Logging level.
+                      [LOG-LEVEL]: notset, debug, info, warning, error, critical
+                      Default: warning""""""
+levels = {
+    'notset': logging.NOTSET,
+    'debug': logging.DEBUG,
+    'info': logging.INFO,
+    'warning': logging.WARNING,
+    'error': logging.ERROR,
+    'critical': logging.CRITICAL
+}
+
+
+def log_level(v):
+    if v.lower() in levels.keys():
+        return levels[v.lower()]
+    else:
+        raise argparse.ArgumentTypeError(
+            'Expected one of the following: {}.'.format(
+                ', '.join(levels.keys())))
+
+
+def program_args():
+    parser = argparse.ArgumentParser()
+
+    parser.add_argument('-t', '--test', action='store_true',
+                        default=False, help='Runs unit tests and exits.')
+
+    parser.add_argument('-l', '--log-level', type=log_level, nargs='?',
+                        const=logging.INFO, default=logging.INFO, help=LOG_LEVEL_HELP)
+
+    parser.add_argument('-o', '--output-dir', default=os.getcwd(),
+                        help='the directory where the captured file will be writen to. Default: CWD')
+    parser.add_argument('-n', '--node-name',
+                        help='The name of the node to be captured, required if the script finds more than one node.')
+    parser.add_argument('-r', '--root-dir', default='/',
+                        help='The root to look for node artifacts. Default: /')
+
+    parser.add_argument('-x', '--exclude-recording', action='store_true',
+                        help='Will exclude recording data from capture.')
+    parser.add_argument('-d', '--dry-run', action='store_true',
+                        default=False, help='Will not create archive file but will collect files to be collected')
+
+    return parser
+
+
+def parse_args(argv=None, parser=program_args()):
+    return parser.parse_args(args=argv)
+
+
+def get_system_dirs():
+    # TODO detect the system someday (help support windows)
+    return ubuntu_platform_config
+
+
+# ***************
+# *  Capture File Collection
+# ***************
+def _log_capture(collection):
+    for entry in collection:
+        logger.info(""%s found at %s"" % (entry.archive_path, entry.abs_fs_path))
+        for file in entry.include:
+            logger.info(""    %s"" % file)
+
+
+def _collect_files(dir_type, directory, archive_path, filter_fn, recursive=True):
+    if not os.path.exists(directory):
+        return None
+
+    rtn = ArchiveEntry(directory, archive_path, [])
+
+    try:
+        for root, dirs, files in os.walk(directory):
+            rel_path = os.path.relpath(root, directory)
+            files = [os.path.join(rel_path, f) for f in files]
+            files = filter(filter_fn, files)
+            rtn.include.extend(files)
+            if recursive is not True:
+                break
+    except FileNotFoundError:
+        logger.warning(""Unable to find a %s directory for pool! Looked for '%s'"", dir_type, directory)
+
+    return rtn
+
+
+def _run_env_capture_cmd(output_file, cmd, entry):
+    try:
+        with open(output_file, 'w') as f:
+            subprocess.run(cmd,
+                           check=True,
+                           stderr=subprocess.STDOUT,
+                           stdout=f
+                           )
+    except (subprocess.CalledProcessError, FileNotFoundError) as e:
+        logger.warning(""Unable to capture env data: cmd '%s' - error: %s"", ' '.join(cmd), str(e))
+    finally:
+        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
+            entry.include.append(output_file)
+
+
+def collect_env(args):
+    logger.info(""Collecting Env Files"")
+    d = tempfile.mkdtemp()
+    TEMP_DIRS.append(d)
+    rtn = ArchiveEntry(d, '/capture', [])
+    for filename, cmd in ENV_COLLECTION_CMD:
+        _run_env_capture_cmd(os.path.join(d, filename),
+                             cmd,
+                             rtn)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_logs(args):
+    log_dir = indy_log_dir(args)
+    log_dir = os.path.join(log_dir, args.pool_name)
+
+    def log_filter(f):
+        return f.startswith(os.path.join('.', args.node_name))
+
+    logger.info(""Collecting Log Files"")
+    rtn = _collect_files('log',
+                         log_dir,
+                         '/log',
+                         log_filter,
+                         recursive=False)
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Log"")
+    return rtn
+
+
+def collect_config(args):
+    d = indy_config_dir(args)
+
+    def file_filter(_f):
+        return True
+
+    logger.info(""Collecting Config Files"")
+    rtn = _collect_files('config', d, '/config', file_filter, recursive=False)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Config"")
+
+    return rtn
+
+
+def collect_data(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, args.pool_name)
+
+    def file_filter(f):
+        if f.startswith('data/'):
+            if f.startswith(os.path.join('data/', args.node_name + '/')) \
+                    or f.startswith(os.path.join('data/', args.node_name + 'C/')):
+
+                if 'recorder' in f:
+                    return not args.exclude_recording
+                return True
+            else:
+                return False
+
+        return True
+
+    logger.info(""Collecting Data Files"")
+    rtn = _collect_files('application data', d, '/', file_filter, recursive=True)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Data"")
+
+    return rtn
+
+
+def collect_plugins(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, 'plugins')
+
+    def file_filter(f):
+        return True
+
+    logger.info(""Collecting Plugins Files"")
+    rtn = _collect_files('plugin data', d, '/plugins', file_filter, recursive=True)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Plugins"")
+
+    return rtn
+
+
+COLLECT_FN = [
+    collect_env,
+    collect_logs,
+    collect_config,
+    collect_data,
+    collect_plugins,
+]
+
+
+def collect_capture_files(args):
+    rtn = []
+    logger.info(""Collecting file to be captured"")
+    for fn in COLLECT_FN:
+        val = fn(args)
+        if val:
+            rtn.append(val)
+    logger.info(""Collection complete"")
+    return rtn
+
+
+# ***************
+# *  Indy Directories
+# ***************
+def _find_dir(args, dir_location, name):
+    dir_location = dir_location.lstrip(""/"")
+    rtn = os.path.join(args.root_dir, dir_location)
+    logger.debug(""using %s dir: %s"", name, rtn)
+    return rtn
+
+
+def indy_app_dir(args):
+    return _find_dir(args, get_system_dirs().NODE_INFO_DIR, ""application dir"")
+
+
+def indy_log_dir(args):
+    return _find_dir(args, get_system_dirs().LOG_DIR, ""logging dir"")
+
+
+def indy_config_dir(args):
+    return _find_dir(args, '/etc/indy', ""config dir"")
+
+
+# ***************
+# *  Capture File Output File Name
+# ***************
+def capture_file_name(args):
+    if (not hasattr(args, 'node_name') or not hasattr(args, 'pool_name')) or \
+            (args.node_name is None or args.pool_name is None):
+        logger.error(""node_name or pool_name has not been specified, can not create capture file name. Object: %s"",
+                     str(args))
+        raise Exception(""Can not create capture file name!"")
+
+    rtn = ""%s.%s.%s"" % (args.node_name, args.pool_name, datetime.datetime.now().strftime(""%Y%m%d%H%M%S""))
+    return rtn
+
+
+# ***************
+# *  Node Discovery
+# ***************
+def find_node_name(args):
+    nodes = []
+
+    def find_nodes_in_pool_dir(pool_name):
+        data_dir = os.path.join(indy_app_dir(args), pool_name, ""data"")
+
+        try:
+            possible_nodes = sorted(os.listdir(data_dir))
+        except FileNotFoundError:
+            logger.warning(""Did not find a data directory for pool '%s'! (Likely not an issue) Looked for '%s'"",
+                           pool_name, data_dir)
+            return []
+
+        possible_nodes = list(filter(is_dir_check(data_dir), possible_nodes))
+        logger.debug(""possible node names in %s: %s"", pool_name, possible_nodes)
+        node_names = set()
+        while len(possible_nodes) is not 0:
+            a_name = possible_nodes.pop(0)
+            if a_name + 'C' in possible_nodes:
+                possible_nodes.remove(a_name + 'C')
+            node_names.add((a_name, pool_name))
+
+
+        return node_names
+
+    def is_dir_check(base_dir):
+        def is_dir(d):
+            return os.path.isdir(os.path.join(base_dir, d))
+
+        return is_dir
+
+    app_dir = indy_app_dir(args)
+    try:
+        pool_dirs = list(filter(is_dir_check(indy_app_dir(args)), os.listdir(app_dir)))
+    except FileNotFoundError:
+        logger.error(""Unable to find indy application directory! Looked for '%s'"", app_dir)
+        raise
+
+    for pool in pool_dirs:
+        # ignore plugins dir - it is not a pool directory
+        if ""plugins"" == pool:
+            continue
+
+        nodes.extend(find_nodes_in_pool_dir(pool))
+
+    if args.node_name is None:
+        if len(nodes) == 1:
+            node_name, pool = nodes.pop()
+            args.node_name = node_name
+            args.pool_name = pool
+        elif len(nodes) == 0:
+            logger.error(""No nodes where found. Check root dir?"", nodes)
+            sys.exit(-1)
+        else:
+            logger.error(""Found more than one node and a node name was not specified! Found -- %s"", nodes)
+            sys.exit(-1)
+    else:
+        for node in nodes:
+            if args.node_name == node[0]:
+                args.pool_name = node[1]
+                break
+        else:
+            logger.error(""Node with name '%s' was not found, can not continue! Found -- %s"", args.node_name, nodes)
+            sys.exit(-1)
+
+    logger.info(""Capturing Node '%s' for pool '%s'"", args.node_name, args.pool_name)
+
+
+TEMP_DIRS = []
+
+
+# Clean up anything that is created by this script (excluding the output file)
+def clean_up():
+    while TEMP_DIRS:
+        shutil.rmtree(TEMP_DIRS.pop())
+
+        # raise Exception(""TEST"")
+
+
+# ***************
+# *  Init Details
+# ***************
+def init(args):
+    # print warning
+    print(""!"" * 20 + "" WARNING "" + '!' * 21)
+    print(""!"" * 2 + ""  "" + ""This tool captures node state replay and diagnostic purposes (for development and QA)"")
+    print(""!"" * 2 + ""  "" + ""By the nature of these needs, that includes sensitive data (including secret keys)"")
+    print(""!"" * 2 + ""  "" + ""DO NOT USE THIS TOOL on nodes that need to be secure"")
+    print(""!"" * 50)
+    time.sleep(1)
+
+    logger.setLevel(args.log_level)
+    logger.debug(""args: %s"", args)
+    find_node_name(args)
+
+    atexit.register(clean_up)
+
+
+def build_archive_cmd(output_file, files):
+    cmd = ['tar']
+    flags = 'cfz'
+    if logger.level == logging.DEBUG:
+        flags += 'v'
+    cmd.append(flags)
+    cmd.append(output_file)
+    cmd.append('--show-transformed-names')
+    cmd.extend([""-C"", ""/""])
+
+    for entry in files:
+        fs_path_pattern = entry.abs_fs_path.strip('/')
+        archive_path_pattern = entry.archive_path.lstrip('/')
+        if archive_path_pattern:
+            archive_path_pattern += '/'  # Add slash for directories otherwise leave blank
+
+        if entry.include:
+            cmd.append('--xform')
+            cmd.append(""s|%s/|%s|1"" % (fs_path_pattern, archive_path_pattern))
+            for file in entry.include:
+                f_path = os.path.join(entry.abs_fs_path, file)
+                f_path = os.path.abspath(f_path)
+                f_path = f_path.lstrip('/')
+                cmd.append(f_path)
+        else:
+            cmd.append('--xform')
+            cmd.append(""s|%s|%s|1"" % (fs_path_pattern, archive_path_pattern))
+            f_path = entry.abs_fs_path.strip('/')
+            cmd.append(f_path + '/')  # Add slash to end for sed expression matching
+
+    return cmd
+
+
+# ***************
+# *  Running the archive command
+# ***************
+def run_cmd(cmd):
+    logger.info(""Running archive command"")
+    try:
+        subprocess.run(cmd, check=True)
+        # os.system(' '.join(cmd))
+    except Exception as e:
+        logger.error(""Unable to complete archive command: %s"", str(e))
+    else:
+        logger.info(""Archive command complete"")
+
+
+def do_capture(args, files):
+    output_file = os.path.join(args.output_dir, capture_file_name(args) + '.tar.gz')
+    logger.info(""Writing archive to '%s'"" % output_file)
+
+    logger.info(""Building archive command"")
+    cmd = build_archive_cmd(output_file, files)
+    logger.debug(""Archive command to be run:"")
+    logger.debug(' '.join(cmd))
+
+    if args.dry_run:
+        logger.info(""Dry-run"")
+        logger.info(""Collected following files:"")
+        _log_capture(files)
+        return
+    else:
+        # if os.getuid() is not 0:
+        # TODO Need to be more clever, only need to be super user when on a bare metal box
+        # logger.error(""Must be run as super user (sudo) to capture all files."")
+        # raise Exception(""Not Super User"")
+        run_cmd(cmd)
+
+
+def main(args):
+    try:
+        init(args)
+    except:
+        logger.error('Unable to initialize script')
+        raise
+
+    try:
+        files = collect_capture_files(args)
+    except:
+        logger.error('Unable to collect the files for this capture')
+        raise
+
+    try:
+        do_capture(args, files)
+    except:
+        logger.error('Unable to build capture archive')
+        raise
+
+
+# ***************",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192198815,https://github.com/hyperledger/indy-node/pull/737#discussion_r192198815,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"FROM ALEX:
We already have documentation on how to work with the code and install it for development:
https://github.com/hyperledger/indy-node/tree/master/dev-setup/ubuntu
https://github.com/hyperledger/indy-node/blob/master/docs/setup-dev.md

Why duplicate it here? It would be better to modify existing docs if there are some issues there.",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:43:46,192199182,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192199182,https://github.com/hyperledger/indy-node/pull/737#discussion_r192199182,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"These tools are not intended as solely as development tools. They are stand-alone tools. Their requirement should be equal or less than to running the node.

So they may be duplication since they would be installed with the node.",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:44:11,192199292,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192199292,https://github.com/hyperledger/indy-node/pull/737#discussion_r192199292,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"FROM ALEX
I think in most of the cases this script will be run on a real installation from deb packages (for example in Docker), not with local nodes.

",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:45:19,192199622,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192199622,https://github.com/hyperledger/indy-node/pull/737#discussion_r192199622,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"FROM ALEX
We migrated to Rocks DB now, so Leveldb is not used anymore.",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:46:15,192199874,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192199874,https://github.com/hyperledger/indy-node/pull/737#discussion_r192199874,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"The script was written during the transition. Do you think it worth ripping Leveldb? Have we ripped out LevelDB in the node code? Is it no longer possible to run the node with LevelDB? If so, we should rip it out. @ckochenower",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:46:23,192199916,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192199916,https://github.com/hyperledger/indy-node/pull/737#discussion_r192199916,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"FROM ALEX:
Please note that KeyValueStorageRocksdbIntKeys is used for the ledger",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:46:56,192200071,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]
+
+        # Traverse directory sin
+        # TODO: 1. Optimize using multiprocessing module. At minimum, all
+        #       directories can be transformed and scrubbed in parallel.
+        #       https://docs.python.org/3/library/multiprocessing.html
+        #
+        #       2. Files in Non-LevelDB/RocksDB directories can be transformed
+        #          and scrubbed in parallel.
+        for dirName, subdirList, fileList in os.walk(abspath(sin)):
+            if (dirName in self.skipdirs):
+                logger.debug(""Skipping dirName: {}"".format(dirName))
+                break
+
+            if self.log_level <= logging.INFO:
+                logger.info(""dirName: {}"".format(dirName))
+
+            # Skip specific directories
+            subdirList[:] = [x for x in subdirList if x not in self.skipdirs]
+            # Skip specific files
+            fileList[:] = [x for x in fileList if x not in self.skipfiles]
+    
+            # Check if all of the leveldb_rocksdb_filenames are found in
+            # fileList set is_leveldb_rocksdb_dir and break if any of the
+            # filenames are not found
+            is_leveldb_rocksdb_dir = True
+            for filename in leveldb_rocksdb_filenames:
+                if filename not in fileList:
+                    is_leveldb_rocksdb_dir = False
+                    break
+    
+            (dirname, filename, name, extension) = self.split_name(dirName)
+            # Do not include recordings in diff
+            if (filename == ""recorder"" and dirname.endswith(
+                ""/{}"".format(sname))):
+                subdirList[:] = []
+                continue
+
+            if (is_leveldb_rocksdb_dir):
+                logger.debug(""{} is a LevelDB/RocksDB directory!""
+                    .format(dirName))
+
+                # Use ""nodename"" in place of the node's name when a directory
+                # (dirName in this case) matches the node name (sname)
+                if (sname == filename):
+                    filename = ""nodename""
+
+                if (filename.endswith(""_transactions"")):
+                    logger.debug(""{} is a transaction LevelDB/RocksDB instance!""
+                        .format(filename))
+                    # utf-8 - call ""getAllTxn()"" in ledger.py in the ledger
+                    #         module/package in indy-plenum.
+                    # Create a Ledger domain object from the ledger directory 
+                    # 'filename' takes the form {fileNamePrefix}_transactions
+                    # where fileNamePrefix is one of the following:
+                    #    config, pool, domain
+                    # FileHashStore requires a fileNamePrefix.
+                    fileNamePrefix = filename.split(""_"")[0]
+                    ledger = Ledger(
+                        CompactMerkleTree(
+                            # The FileHashStore reads
+                            # {fileNamePrefix}_merkleLeaves and
+                            # {fileNamePrefix}_merkleNodes from dataDir
+                            hashStore=FileHashStore(
+                                dataDir=dirname,
+                                fileNamePrefix=fileNamePrefix
+                            )
+                        ),
+                        dataDir=dirname,
+                        fileName=filename
+                    )
+
+                    out_filename = join(sout, filename)
+                    with open(out_filename, ""a"") as file_handle:
+                        for txn in ledger.getAllTxn():
+                            logger.info(""Writing >txn={}< to {}"".format(
+                                str(txn), out_filename))
+                            file_handle.write(str(txn))
+                    ledger.stop()
+                else:
+                    debug_msg = (""{} is NOT a transaction LevelDB/RocksDB""
+                                 ""instance!"")
+                    logger.debug(debug_msg.format(filename))
+                    # Assume utf-8 decoding by default.
+                    # utf-8 - use standard leveldb/rocksdb iterator() and utf-8
+                    #         decoding.
+                    opened = False
+                    try:
+                        debug_msg = (""Opening {} as a LevelDB instance with""",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192200071,https://github.com/hyperledger/indy-node/pull/737#discussion_r192200071,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"FROM ALEX:
RocksDB-based hash store is actually used by default and in production (see initHashStore)",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:47:53,192200327,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]
+
+        # Traverse directory sin
+        # TODO: 1. Optimize using multiprocessing module. At minimum, all
+        #       directories can be transformed and scrubbed in parallel.
+        #       https://docs.python.org/3/library/multiprocessing.html
+        #
+        #       2. Files in Non-LevelDB/RocksDB directories can be transformed
+        #          and scrubbed in parallel.
+        for dirName, subdirList, fileList in os.walk(abspath(sin)):
+            if (dirName in self.skipdirs):
+                logger.debug(""Skipping dirName: {}"".format(dirName))
+                break
+
+            if self.log_level <= logging.INFO:
+                logger.info(""dirName: {}"".format(dirName))
+
+            # Skip specific directories
+            subdirList[:] = [x for x in subdirList if x not in self.skipdirs]
+            # Skip specific files
+            fileList[:] = [x for x in fileList if x not in self.skipfiles]
+    
+            # Check if all of the leveldb_rocksdb_filenames are found in
+            # fileList set is_leveldb_rocksdb_dir and break if any of the
+            # filenames are not found
+            is_leveldb_rocksdb_dir = True
+            for filename in leveldb_rocksdb_filenames:
+                if filename not in fileList:
+                    is_leveldb_rocksdb_dir = False
+                    break
+    
+            (dirname, filename, name, extension) = self.split_name(dirName)
+            # Do not include recordings in diff
+            if (filename == ""recorder"" and dirname.endswith(
+                ""/{}"".format(sname))):
+                subdirList[:] = []
+                continue
+
+            if (is_leveldb_rocksdb_dir):
+                logger.debug(""{} is a LevelDB/RocksDB directory!""
+                    .format(dirName))
+
+                # Use ""nodename"" in place of the node's name when a directory
+                # (dirName in this case) matches the node name (sname)
+                if (sname == filename):
+                    filename = ""nodename""
+
+                if (filename.endswith(""_transactions"")):
+                    logger.debug(""{} is a transaction LevelDB/RocksDB instance!""
+                        .format(filename))
+                    # utf-8 - call ""getAllTxn()"" in ledger.py in the ledger
+                    #         module/package in indy-plenum.
+                    # Create a Ledger domain object from the ledger directory 
+                    # 'filename' takes the form {fileNamePrefix}_transactions
+                    # where fileNamePrefix is one of the following:
+                    #    config, pool, domain
+                    # FileHashStore requires a fileNamePrefix.
+                    fileNamePrefix = filename.split(""_"")[0]
+                    ledger = Ledger(
+                        CompactMerkleTree(
+                            # The FileHashStore reads
+                            # {fileNamePrefix}_merkleLeaves and
+                            # {fileNamePrefix}_merkleNodes from dataDir
+                            hashStore=FileHashStore(",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192200327,https://github.com/hyperledger/indy-node/pull/737#discussion_r192200327,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"FROM ALEX
- Please split the method into a number of smaller ones
- Please avoid too may hierarchical indentation (if-else-if-else-try-if-else....)",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:48:51,192200596,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192200596,https://github.com/hyperledger/indy-node/pull/737#discussion_r192200596,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"We can put some TODO comment to do this. But I don't think we should hold up the PR till this is done.
Alex, I agree with the suggestions but are you ok if we put it on our TODO list?",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:48:59,192200640,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192200640,https://github.com/hyperledger/indy-node/pull/737#discussion_r192200640,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"FROM ALEX:
For me it looks like the method is overcomplicated. The type of the transaction log, hash store and other storages can be get from config file. Why don't we get it from there instead of trying all variants in try-else style?",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:49:34,192200810,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]
+
+        # Traverse directory sin
+        # TODO: 1. Optimize using multiprocessing module. At minimum, all
+        #       directories can be transformed and scrubbed in parallel.
+        #       https://docs.python.org/3/library/multiprocessing.html
+        #
+        #       2. Files in Non-LevelDB/RocksDB directories can be transformed
+        #          and scrubbed in parallel.
+        for dirName, subdirList, fileList in os.walk(abspath(sin)):
+            if (dirName in self.skipdirs):
+                logger.debug(""Skipping dirName: {}"".format(dirName))
+                break
+
+            if self.log_level <= logging.INFO:
+                logger.info(""dirName: {}"".format(dirName))
+
+            # Skip specific directories
+            subdirList[:] = [x for x in subdirList if x not in self.skipdirs]
+            # Skip specific files
+            fileList[:] = [x for x in fileList if x not in self.skipfiles]
+    
+            # Check if all of the leveldb_rocksdb_filenames are found in
+            # fileList set is_leveldb_rocksdb_dir and break if any of the
+            # filenames are not found
+            is_leveldb_rocksdb_dir = True
+            for filename in leveldb_rocksdb_filenames:
+                if filename not in fileList:
+                    is_leveldb_rocksdb_dir = False
+                    break
+    
+            (dirname, filename, name, extension) = self.split_name(dirName)
+            # Do not include recordings in diff
+            if (filename == ""recorder"" and dirname.endswith(
+                ""/{}"".format(sname))):
+                subdirList[:] = []
+                continue
+
+            if (is_leveldb_rocksdb_dir):
+                logger.debug(""{} is a LevelDB/RocksDB directory!""
+                    .format(dirName))
+
+                # Use ""nodename"" in place of the node's name when a directory
+                # (dirName in this case) matches the node name (sname)
+                if (sname == filename):",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192200810,https://github.com/hyperledger/indy-node/pull/737#discussion_r192200810,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,Initial we were not capturing the configuration. (not part of nsdiff original scope) So that is why we had a try-fail cycle. I think the try-fail gives us better resiliency at not much cost in the complexity of the code. But we can add TODOs to simplify this. But I don't think that this should hold this back.,402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:49:42,192200848,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]
+
+        # Traverse directory sin
+        # TODO: 1. Optimize using multiprocessing module. At minimum, all
+        #       directories can be transformed and scrubbed in parallel.
+        #       https://docs.python.org/3/library/multiprocessing.html
+        #
+        #       2. Files in Non-LevelDB/RocksDB directories can be transformed
+        #          and scrubbed in parallel.
+        for dirName, subdirList, fileList in os.walk(abspath(sin)):
+            if (dirName in self.skipdirs):
+                logger.debug(""Skipping dirName: {}"".format(dirName))
+                break
+
+            if self.log_level <= logging.INFO:
+                logger.info(""dirName: {}"".format(dirName))
+
+            # Skip specific directories
+            subdirList[:] = [x for x in subdirList if x not in self.skipdirs]
+            # Skip specific files
+            fileList[:] = [x for x in fileList if x not in self.skipfiles]
+    
+            # Check if all of the leveldb_rocksdb_filenames are found in
+            # fileList set is_leveldb_rocksdb_dir and break if any of the
+            # filenames are not found
+            is_leveldb_rocksdb_dir = True
+            for filename in leveldb_rocksdb_filenames:
+                if filename not in fileList:
+                    is_leveldb_rocksdb_dir = False
+                    break
+    
+            (dirname, filename, name, extension) = self.split_name(dirName)
+            # Do not include recordings in diff
+            if (filename == ""recorder"" and dirname.endswith(
+                ""/{}"".format(sname))):
+                subdirList[:] = []
+                continue
+
+            if (is_leveldb_rocksdb_dir):
+                logger.debug(""{} is a LevelDB/RocksDB directory!""
+                    .format(dirName))
+
+                # Use ""nodename"" in place of the node's name when a directory
+                # (dirName in this case) matches the node name (sname)
+                if (sname == filename):",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192200848,https://github.com/hyperledger/indy-node/pull/737#discussion_r192200848,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"FROM ALEX:
Please specify what exactly is compared:

- txn log (for all ledgers)
- hash store (for all ledgers)
- all states
- state_signature (BLS)
- attr_store
- seq_no_db
- ts_store
- ????",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-05-31 18:51:22,192201338,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:",5,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192201338,https://github.com/hyperledger/indy-node/pull/737#discussion_r192201338,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,@ckochenower added some doc in the comments to address this.,402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-06-01 04:19:12,192295116,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:",5,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192295116,https://github.com/hyperledger/indy-node/pull/737#discussion_r192295116,devin-fisher
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,But you can reference to the documentation in indy-node instead of duplicating it. We should support it up-to-date in one place only.,402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-06-04 14:47:47,192767461,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192767461,https://github.com/hyperledger/indy-node/pull/737#discussion_r192767461,ashcherbakov
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,OK. We can create a ticket for more enhancements.,402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-06-04 15:47:09,192789274,"@@ -0,0 +1,782 @@
+#!/usr/bin/env python3
+
+import sys
+import os
+import argparse
+import logging
+import datetime
+import time
+from collections import namedtuple
+import tempfile
+import subprocess
+import atexit
+import shutil
+
+from io import StringIO
+
+from plenum.server.general_config import ubuntu_platform_config
+
+logger = logging.getLogger()
+
+ArchiveEntry = namedtuple('archive_entry', ['abs_fs_path', 'archive_path', 'include'])
+
+ENV_COLLECTION_CMD = [
+    (""python_version"", ['python3', '-V']),
+    (""pip_freeze"", ['pip3', 'freeze']),
+    (""app_install"", ['apt', 'list', '--installed']),
+    (""validator_info"", ['validator-info', '-v']),
+]
+
+
+# ***************
+# *  Command-line Argument Parsing
+# ***************
+def str2bool(v):
+    if v.lower() in ('yes', 'true', 't', 'y', '1'):
+        return True
+    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
+        return False
+    else:
+        raise argparse.ArgumentTypeError(
+            'Boolean value (yes, no, true, false, y, n, 1, or 0) expected.')
+
+
+LOG_LEVEL_HELP = """"""Logging level.
+                      [LOG-LEVEL]: notset, debug, info, warning, error, critical
+                      Default: warning""""""
+levels = {
+    'notset': logging.NOTSET,
+    'debug': logging.DEBUG,
+    'info': logging.INFO,
+    'warning': logging.WARNING,
+    'error': logging.ERROR,
+    'critical': logging.CRITICAL
+}
+
+
+def log_level(v):
+    if v.lower() in levels.keys():
+        return levels[v.lower()]
+    else:
+        raise argparse.ArgumentTypeError(
+            'Expected one of the following: {}.'.format(
+                ', '.join(levels.keys())))
+
+
+def program_args():
+    parser = argparse.ArgumentParser()
+
+    parser.add_argument('-t', '--test', action='store_true',
+                        default=False, help='Runs unit tests and exits.')
+
+    parser.add_argument('-l', '--log-level', type=log_level, nargs='?',
+                        const=logging.INFO, default=logging.INFO, help=LOG_LEVEL_HELP)
+
+    parser.add_argument('-o', '--output-dir', default=os.getcwd(),
+                        help='the directory where the captured file will be writen to. Default: CWD')
+    parser.add_argument('-n', '--node-name',
+                        help='The name of the node to be captured, required if the script finds more than one node.')
+    parser.add_argument('-r', '--root-dir', default='/',
+                        help='The root to look for node artifacts. Default: /')
+
+    parser.add_argument('-x', '--exclude-recording', action='store_true',
+                        help='Will exclude recording data from capture.')
+    parser.add_argument('-d', '--dry-run', action='store_true',
+                        default=False, help='Will not create archive file but will collect files to be collected')
+
+    return parser
+
+
+def parse_args(argv=None, parser=program_args()):
+    return parser.parse_args(args=argv)
+
+
+def get_system_dirs():
+    # TODO detect the system someday (help support windows)
+    return ubuntu_platform_config
+
+
+# ***************
+# *  Capture File Collection
+# ***************
+def _log_capture(collection):
+    for entry in collection:
+        logger.info(""%s found at %s"" % (entry.archive_path, entry.abs_fs_path))
+        for file in entry.include:
+            logger.info(""    %s"" % file)
+
+
+def _collect_files(dir_type, directory, archive_path, filter_fn, recursive=True):
+    if not os.path.exists(directory):
+        return None
+
+    rtn = ArchiveEntry(directory, archive_path, [])
+
+    try:
+        for root, dirs, files in os.walk(directory):
+            rel_path = os.path.relpath(root, directory)
+            files = [os.path.join(rel_path, f) for f in files]
+            files = filter(filter_fn, files)
+            rtn.include.extend(files)
+            if recursive is not True:
+                break
+    except FileNotFoundError:
+        logger.warning(""Unable to find a %s directory for pool! Looked for '%s'"", dir_type, directory)
+
+    return rtn
+
+
+def _run_env_capture_cmd(output_file, cmd, entry):
+    try:
+        with open(output_file, 'w') as f:
+            subprocess.run(cmd,
+                           check=True,
+                           stderr=subprocess.STDOUT,
+                           stdout=f
+                           )
+    except (subprocess.CalledProcessError, FileNotFoundError) as e:
+        logger.warning(""Unable to capture env data: cmd '%s' - error: %s"", ' '.join(cmd), str(e))
+    finally:
+        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
+            entry.include.append(output_file)
+
+
+def collect_env(args):
+    logger.info(""Collecting Env Files"")
+    d = tempfile.mkdtemp()
+    TEMP_DIRS.append(d)
+    rtn = ArchiveEntry(d, '/capture', [])
+    for filename, cmd in ENV_COLLECTION_CMD:
+        _run_env_capture_cmd(os.path.join(d, filename),
+                             cmd,
+                             rtn)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_logs(args):
+    log_dir = indy_log_dir(args)
+    log_dir = os.path.join(log_dir, args.pool_name)
+
+    def log_filter(f):
+        return f.startswith(os.path.join('.', args.node_name))
+
+    logger.info(""Collecting Log Files"")
+    rtn = _collect_files('log',
+                         log_dir,
+                         '/log',
+                         log_filter,
+                         recursive=False)
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Log"")
+    return rtn
+
+
+def collect_config(args):
+    d = indy_config_dir(args)
+
+    def file_filter(_f):
+        return True
+
+    logger.info(""Collecting Config Files"")
+    rtn = _collect_files('config', d, '/config', file_filter, recursive=False)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Config"")
+
+    return rtn
+
+
+def collect_data(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, args.pool_name)
+
+    def file_filter(f):
+        if f.startswith('data/'):
+            if f.startswith(os.path.join('data/', args.node_name + '/')) \
+                    or f.startswith(os.path.join('data/', args.node_name + 'C/')):
+
+                if 'recorder' in f:
+                    return not args.exclude_recording
+                return True
+            else:
+                return False
+
+        return True
+
+    logger.info(""Collecting Data Files"")
+    rtn = _collect_files('application data', d, '/', file_filter, recursive=True)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Data"")
+
+    return rtn
+
+
+def collect_plugins(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, 'plugins')
+
+    def file_filter(f):
+        return True
+
+    logger.info(""Collecting Plugins Files"")
+    rtn = _collect_files('plugin data', d, '/plugins', file_filter, recursive=True)
+
+    if rtn:
+        logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    else:
+        logger.warning(""Unable to collect files from Plugins"")
+
+    return rtn
+
+
+COLLECT_FN = [
+    collect_env,
+    collect_logs,
+    collect_config,
+    collect_data,
+    collect_plugins,
+]
+
+
+def collect_capture_files(args):
+    rtn = []
+    logger.info(""Collecting file to be captured"")
+    for fn in COLLECT_FN:
+        val = fn(args)
+        if val:
+            rtn.append(val)
+    logger.info(""Collection complete"")
+    return rtn
+
+
+# ***************
+# *  Indy Directories
+# ***************
+def _find_dir(args, dir_location, name):
+    dir_location = dir_location.lstrip(""/"")
+    rtn = os.path.join(args.root_dir, dir_location)
+    logger.debug(""using %s dir: %s"", name, rtn)
+    return rtn
+
+
+def indy_app_dir(args):
+    return _find_dir(args, get_system_dirs().NODE_INFO_DIR, ""application dir"")
+
+
+def indy_log_dir(args):
+    return _find_dir(args, get_system_dirs().LOG_DIR, ""logging dir"")
+
+
+def indy_config_dir(args):
+    return _find_dir(args, '/etc/indy', ""config dir"")
+
+
+# ***************
+# *  Capture File Output File Name
+# ***************
+def capture_file_name(args):
+    if (not hasattr(args, 'node_name') or not hasattr(args, 'pool_name')) or \
+            (args.node_name is None or args.pool_name is None):
+        logger.error(""node_name or pool_name has not been specified, can not create capture file name. Object: %s"",
+                     str(args))
+        raise Exception(""Can not create capture file name!"")
+
+    rtn = ""%s.%s.%s"" % (args.node_name, args.pool_name, datetime.datetime.now().strftime(""%Y%m%d%H%M%S""))
+    return rtn
+
+
+# ***************
+# *  Node Discovery
+# ***************
+def find_node_name(args):
+    nodes = []
+
+    def find_nodes_in_pool_dir(pool_name):
+        data_dir = os.path.join(indy_app_dir(args), pool_name, ""data"")
+
+        try:
+            possible_nodes = sorted(os.listdir(data_dir))
+        except FileNotFoundError:
+            logger.warning(""Did not find a data directory for pool '%s'! (Likely not an issue) Looked for '%s'"",
+                           pool_name, data_dir)
+            return []
+
+        possible_nodes = list(filter(is_dir_check(data_dir), possible_nodes))
+        logger.debug(""possible node names in %s: %s"", pool_name, possible_nodes)
+        node_names = set()
+        while len(possible_nodes) is not 0:
+            a_name = possible_nodes.pop(0)
+            if a_name + 'C' in possible_nodes:
+                possible_nodes.remove(a_name + 'C')
+            node_names.add((a_name, pool_name))
+
+
+        return node_names
+
+    def is_dir_check(base_dir):
+        def is_dir(d):
+            return os.path.isdir(os.path.join(base_dir, d))
+
+        return is_dir
+
+    app_dir = indy_app_dir(args)
+    try:
+        pool_dirs = list(filter(is_dir_check(indy_app_dir(args)), os.listdir(app_dir)))
+    except FileNotFoundError:
+        logger.error(""Unable to find indy application directory! Looked for '%s'"", app_dir)
+        raise
+
+    for pool in pool_dirs:
+        # ignore plugins dir - it is not a pool directory
+        if ""plugins"" == pool:
+            continue
+
+        nodes.extend(find_nodes_in_pool_dir(pool))
+
+    if args.node_name is None:
+        if len(nodes) == 1:
+            node_name, pool = nodes.pop()
+            args.node_name = node_name
+            args.pool_name = pool
+        elif len(nodes) == 0:
+            logger.error(""No nodes where found. Check root dir?"", nodes)
+            sys.exit(-1)
+        else:
+            logger.error(""Found more than one node and a node name was not specified! Found -- %s"", nodes)
+            sys.exit(-1)
+    else:
+        for node in nodes:
+            if args.node_name == node[0]:
+                args.pool_name = node[1]
+                break
+        else:
+            logger.error(""Node with name '%s' was not found, can not continue! Found -- %s"", args.node_name, nodes)
+            sys.exit(-1)
+
+    logger.info(""Capturing Node '%s' for pool '%s'"", args.node_name, args.pool_name)
+
+
+TEMP_DIRS = []
+
+
+# Clean up anything that is created by this script (excluding the output file)
+def clean_up():
+    while TEMP_DIRS:
+        shutil.rmtree(TEMP_DIRS.pop())
+
+        # raise Exception(""TEST"")
+
+
+# ***************
+# *  Init Details
+# ***************
+def init(args):
+    # print warning
+    print(""!"" * 20 + "" WARNING "" + '!' * 21)
+    print(""!"" * 2 + ""  "" + ""This tool captures node state replay and diagnostic purposes (for development and QA)"")
+    print(""!"" * 2 + ""  "" + ""By the nature of these needs, that includes sensitive data (including secret keys)"")
+    print(""!"" * 2 + ""  "" + ""DO NOT USE THIS TOOL on nodes that need to be secure"")
+    print(""!"" * 50)
+    time.sleep(1)
+
+    logger.setLevel(args.log_level)
+    logger.debug(""args: %s"", args)
+    find_node_name(args)
+
+    atexit.register(clean_up)
+
+
+def build_archive_cmd(output_file, files):
+    cmd = ['tar']
+    flags = 'cfz'
+    if logger.level == logging.DEBUG:
+        flags += 'v'
+    cmd.append(flags)
+    cmd.append(output_file)
+    cmd.append('--show-transformed-names')
+    cmd.extend([""-C"", ""/""])
+
+    for entry in files:
+        fs_path_pattern = entry.abs_fs_path.strip('/')
+        archive_path_pattern = entry.archive_path.lstrip('/')
+        if archive_path_pattern:
+            archive_path_pattern += '/'  # Add slash for directories otherwise leave blank
+
+        if entry.include:
+            cmd.append('--xform')
+            cmd.append(""s|%s/|%s|1"" % (fs_path_pattern, archive_path_pattern))
+            for file in entry.include:
+                f_path = os.path.join(entry.abs_fs_path, file)
+                f_path = os.path.abspath(f_path)
+                f_path = f_path.lstrip('/')
+                cmd.append(f_path)
+        else:
+            cmd.append('--xform')
+            cmd.append(""s|%s|%s|1"" % (fs_path_pattern, archive_path_pattern))
+            f_path = entry.abs_fs_path.strip('/')
+            cmd.append(f_path + '/')  # Add slash to end for sed expression matching
+
+    return cmd
+
+
+# ***************
+# *  Running the archive command
+# ***************
+def run_cmd(cmd):
+    logger.info(""Running archive command"")
+    try:
+        subprocess.run(cmd, check=True)
+        # os.system(' '.join(cmd))
+    except Exception as e:
+        logger.error(""Unable to complete archive command: %s"", str(e))
+    else:
+        logger.info(""Archive command complete"")
+
+
+def do_capture(args, files):
+    output_file = os.path.join(args.output_dir, capture_file_name(args) + '.tar.gz')
+    logger.info(""Writing archive to '%s'"" % output_file)
+
+    logger.info(""Building archive command"")
+    cmd = build_archive_cmd(output_file, files)
+    logger.debug(""Archive command to be run:"")
+    logger.debug(' '.join(cmd))
+
+    if args.dry_run:
+        logger.info(""Dry-run"")
+        logger.info(""Collected following files:"")
+        _log_capture(files)
+        return
+    else:
+        # if os.getuid() is not 0:
+        # TODO Need to be more clever, only need to be super user when on a bare metal box
+        # logger.error(""Must be run as super user (sudo) to capture all files."")
+        # raise Exception(""Not Super User"")
+        run_cmd(cmd)
+
+
+def main(args):
+    try:
+        init(args)
+    except:
+        logger.error('Unable to initialize script')
+        raise
+
+    try:
+        files = collect_capture_files(args)
+    except:
+        logger.error('Unable to collect the files for this capture')
+        raise
+
+    try:
+        do_capture(args, files)
+    except:
+        logger.error('Unable to build capture archive')
+        raise
+
+
+# ***************",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192789274,https://github.com/hyperledger/indy-node/pull/737#discussion_r192789274,ashcherbakov
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,It's still possible to run the code with leveldb. The DB is defined in config file.,402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-06-04 15:47:53,192789535,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192789535,https://github.com/hyperledger/indy-node/pull/737#discussion_r192789535,ashcherbakov
https://github.com/hyperledger/indy-node/pull/737,https://github.com/hyperledger/indy-node/pull/737,"Well, if this takes too much time for re-factroing then fine, we can do it later with a ticket and TODO comment. However, I would prefer to have a cleaner and more readable code (maybe do it together with the next item)?",402232e12e6ef7281155e2fea9b814d9d75c8c7b,2018-06-04 15:55:19,192792091,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):",,2018-06-13 11:12:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192792091,https://github.com/hyperledger/indy-node/pull/737#discussion_r192792091,ashcherbakov
https://github.com/hyperledger/indy-node/pull/735,https://github.com/hyperledger/indy-node/pull/735,"So, can we remove `idrCache` at all then? Why do we need it?",c1f376e2b47b6a8cb945d0b883b9e9204c93f98a,2018-05-31 10:08:52,192050645,"@@ -423,18 +423,17 @@ def add_query_handler(self, txn_type, handler: Callable):
 
     def handleGetNymReq(self, request: Request):
         nym = request.operation[TARGET_NYM]
-        nymData = self.idrCache.getNym(nym, isCommitted=True)
         path = domain.make_state_path_for_nym(nym)
-        if nymData:
-            nymData[TARGET_NYM] = nym
-            data = self.stateSerializer.serialize(nymData)
-            seq_no = nymData[f.SEQ_NO.nm]
-            update_time = nymData[TXN_TIME]
-            proof = self.make_proof(path)
+        nym_data, proof = self.get_value_from_state(path, with_proof=True)",41,2018-06-04 09:31:10,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192050645,https://github.com/hyperledger/indy-node/pull/735#discussion_r192050645,ashcherbakov
https://github.com/hyperledger/indy-node/pull/735,https://github.com/hyperledger/indy-node/pull/735,Please generate the proof on non-existence here,c1f376e2b47b6a8cb945d0b883b9e9204c93f98a,2018-05-31 10:09:19,192050763,"@@ -423,18 +423,17 @@ def add_query_handler(self, txn_type, handler: Callable):
 
     def handleGetNymReq(self, request: Request):
         nym = request.operation[TARGET_NYM]
-        nymData = self.idrCache.getNym(nym, isCommitted=True)
         path = domain.make_state_path_for_nym(nym)
-        if nymData:
-            nymData[TARGET_NYM] = nym
-            data = self.stateSerializer.serialize(nymData)
-            seq_no = nymData[f.SEQ_NO.nm]
-            update_time = nymData[TXN_TIME]
-            proof = self.make_proof(path)
+        nym_data, proof = self.get_value_from_state(path, with_proof=True)
+        if nym_data:
+            nym_data = self.stateSerializer.deserialize(nym_data)
+            nym_data[TARGET_NYM] = nym
+            data = self.stateSerializer.serialize(nym_data)
+            seq_no = nym_data[f.SEQ_NO.nm]
+            update_time = nym_data[TXN_TIME]
         else:",48,2018-06-04 09:31:10,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192050763,https://github.com/hyperledger/indy-node/pull/735#discussion_r192050763,ashcherbakov
https://github.com/hyperledger/indy-node/pull/735,https://github.com/hyperledger/indy-node/pull/735,"For validation, we dont query trie since its expensive to query",c1f376e2b47b6a8cb945d0b883b9e9204c93f98a,2018-05-31 16:55:36,192167228,"@@ -423,18 +423,17 @@ def add_query_handler(self, txn_type, handler: Callable):
 
     def handleGetNymReq(self, request: Request):
         nym = request.operation[TARGET_NYM]
-        nymData = self.idrCache.getNym(nym, isCommitted=True)
         path = domain.make_state_path_for_nym(nym)
-        if nymData:
-            nymData[TARGET_NYM] = nym
-            data = self.stateSerializer.serialize(nymData)
-            seq_no = nymData[f.SEQ_NO.nm]
-            update_time = nymData[TXN_TIME]
-            proof = self.make_proof(path)
+        nym_data, proof = self.get_value_from_state(path, with_proof=True)",41,2018-06-04 09:31:10,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192167228,https://github.com/hyperledger/indy-node/pull/735#discussion_r192167228,lovesh
https://github.com/hyperledger/indy-node/pull/735,https://github.com/hyperledger/indy-node/pull/735,"Its there in `nym_data, proof = self.get_value_from_state(path, with_proof=True)`. I dont see an existing test for proof of absence, i can add one",c1f376e2b47b6a8cb945d0b883b9e9204c93f98a,2018-05-31 16:57:15,192167683,"@@ -423,18 +423,17 @@ def add_query_handler(self, txn_type, handler: Callable):
 
     def handleGetNymReq(self, request: Request):
         nym = request.operation[TARGET_NYM]
-        nymData = self.idrCache.getNym(nym, isCommitted=True)
         path = domain.make_state_path_for_nym(nym)
-        if nymData:
-            nymData[TARGET_NYM] = nym
-            data = self.stateSerializer.serialize(nymData)
-            seq_no = nymData[f.SEQ_NO.nm]
-            update_time = nymData[TXN_TIME]
-            proof = self.make_proof(path)
+        nym_data, proof = self.get_value_from_state(path, with_proof=True)
+        if nym_data:
+            nym_data = self.stateSerializer.deserialize(nym_data)
+            nym_data[TARGET_NYM] = nym
+            data = self.stateSerializer.serialize(nym_data)
+            seq_no = nym_data[f.SEQ_NO.nm]
+            update_time = nym_data[TXN_TIME]
         else:",48,2018-06-04 09:31:10,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192167683,https://github.com/hyperledger/indy-node/pull/735#discussion_r192167683,lovesh
https://github.com/hyperledger/indy-node/pull/735,https://github.com/hyperledger/indy-node/pull/735,Updated `test_state_proofs_for_get_nym`,c1f376e2b47b6a8cb945d0b883b9e9204c93f98a,2018-05-31 19:26:23,192210639,"@@ -423,18 +423,17 @@ def add_query_handler(self, txn_type, handler: Callable):
 
     def handleGetNymReq(self, request: Request):
         nym = request.operation[TARGET_NYM]
-        nymData = self.idrCache.getNym(nym, isCommitted=True)
         path = domain.make_state_path_for_nym(nym)
-        if nymData:
-            nymData[TARGET_NYM] = nym
-            data = self.stateSerializer.serialize(nymData)
-            seq_no = nymData[f.SEQ_NO.nm]
-            update_time = nymData[TXN_TIME]
-            proof = self.make_proof(path)
+        nym_data, proof = self.get_value_from_state(path, with_proof=True)
+        if nym_data:
+            nym_data = self.stateSerializer.deserialize(nym_data)
+            nym_data[TARGET_NYM] = nym
+            data = self.stateSerializer.serialize(nym_data)
+            seq_no = nym_data[f.SEQ_NO.nm]
+            update_time = nym_data[TXN_TIME]
         else:",48,2018-06-04 09:31:10,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192210639,https://github.com/hyperledger/indy-node/pull/735#discussion_r192210639,lovesh
https://github.com/hyperledger/indy-node/pull/733,https://github.com/hyperledger/indy-node/pull/733,"please, insert a whitespace for right indent.",dde2adfebad21575d063c89d1a1bcdcf6438efa8,2018-05-30 15:07:15,191805928,"@@ -536,14 +536,53 @@ def accept_client(client_reader, client_writer):
     task.add_done_callback(client_done)
 
 
-def get_stats_from_file(fpath, verbose, _json):
+def nagios(vstats):
+    state = '2'
+    running = ""{}"".format(vstats['state'])
+    if ""running"" == running:
+        state = '0'
+
+    lines = [
+        ""{} {}_Total_Config_Transactions config_transactions={} {} Total Config Transactions"".format(
+                state,vstats['Node_info']['Name'],vstats['Node_info']['Metrics']['transaction-count']['config'],vstats['Node_info']['Name'])
+    ] + [
+        ""{} {}_Total_Ledger_Transactions ledger_transactions={} {} Total Ledger Transactions"".format(
+            state,vstats['Node_info']['Name'],vstats['Node_info']['Metrics']['transaction-count']['ledger'],vstats['Node_info']['Name'])
+    ] + [
+        ""{} {}_Total_Pool_Transactions pool_transactions={} {} Total Pool Transactions"".format(
+            state,vstats['Node_info']['Name'],vstats['Node_info']['Metrics']['transaction-count']['pool'],vstats['Node_info']['Name'])
+    ] + [
+        ""{} {}_Read_Transactions_per_second read_transactions_per_second={} {} Read Transactions/Second"".format(
+            state,vstats['Node_info']['Name'],vstats['Node_info']['Metrics']['average-per-second']['read-transactions'],vstats['Node_info']['Name'])
+    ] + [
+        ""{} {}_Write_Transactions_per_second write_transactions_per_second={} {} Write Transactions/Second"".format(
+            state,vstats['Node_info']['Name'],vstats['Node_info']['Metrics']['average-per-second']['write-transactions'],vstats['Node_info']['Name'])
+    ] + [
+        ""{} {}_Number_of_Validators number_of_validators={} {} Number of Validators"".format(
+            state,vstats['Node_info']['Name'],vstats['Pool_info']['Total_nodes_count'],vstats['Node_info']['Name'])
+    ] + [
+        ""{} {}_Reachable_Validators reachable_validators={} {} Reachable Validators"".format(
+            state,vstats['Node_info']['Name'],vstats['Pool_info']['Reachable_nodes_count'],vstats['Node_info']['Name'])
+    ] + [
+        ""{} {}_Unreachable_Validators unreachable_validators={} {} Unreachable Validators"".format(
+            state,vstats['Node_info']['Name'],vstats['Pool_info']['Unreachable_nodes_count'],vstats['Node_info']['Name'])
+    ]
+    return ""\n"".join(lines);
+
+
+def get_stats_from_file(fpath, verbose, _json, _nagios):
     with open(fpath) as f:
         stats = json.loads(f.read())
 
     logger.debug(""Data {}"".format(stats))
     vstats = ValidatorStats(stats, verbose)
 
-    return (json.dumps(vstats, indent=2, cls=NewEncoder) if _json else vstats)
+    if _json:
+        return json.dumps(vstats, indent=2, cls=NewEncoder)
+    if _nagios:
+       return nagios(vstats)",,2018-06-01 10:40:29,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/191805928,https://github.com/hyperledger/indy-node/pull/733#discussion_r191805928,anikitinDSR
https://github.com/hyperledger/indy-node/pull/731,https://github.com/hyperledger/indy-node/pull/731,"Do we need to decode before casting into int?
like `int(key.decode())`",1ef3ff0a2e71f6f46467f2f0210e983bfc2a6df1,2018-05-29 16:11:14,191483993,"@@ -78,7 +78,7 @@ def migrate_txn_log(db_dir, db_name):
     try:
         for key, val in src_storage.iterator():
             val = ledger_txn_serializer.deserialize(val)
-            new_val = transform_to_new_format(txn=val, seq_no=key)
+            new_val = transform_to_new_format(txn=val, seq_no=int(key))",5,2018-05-29 16:11:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/191483993,https://github.com/hyperledger/indy-node/pull/731#discussion_r191483993,anikitinDSR
https://github.com/hyperledger/indy-node/pull/731,https://github.com/hyperledger/indy-node/pull/731,int() can handle byte as an input,1ef3ff0a2e71f6f46467f2f0210e983bfc2a6df1,2018-05-29 16:27:25,191489214,"@@ -78,7 +78,7 @@ def migrate_txn_log(db_dir, db_name):
     try:
         for key, val in src_storage.iterator():
             val = ledger_txn_serializer.deserialize(val)
-            new_val = transform_to_new_format(txn=val, seq_no=key)
+            new_val = transform_to_new_format(txn=val, seq_no=int(key))",5,2018-05-29 16:27:25,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/191489214,https://github.com/hyperledger/indy-node/pull/731#discussion_r191489214,ashcherbakov
https://github.com/hyperledger/indy-node/pull/730,https://github.com/hyperledger/indy-node/pull/730,We need to have proof of non-existence here,e07b967ddbbb52fd6188472dfc80f3cd118f0bf9,2018-05-29 15:19:04,191466224,"@@ -421,18 +421,18 @@ def add_query_handler(self, txn_type, handler: Callable):
 
     def handleGetNymReq(self, request: Request):
         nym = request.operation[TARGET_NYM]
-        nymData = self.idrCache.getNym(nym, isCommitted=True)
         path = domain.make_state_path_for_nym(nym)
-        if nymData:
-            nymData[TARGET_NYM] = nym
-            data = self.stateSerializer.serialize(nymData)
-            seq_no = nymData[f.SEQ_NO.nm]
-            update_time = nymData[TXN_TIME]
-            proof = self.make_proof(path)
+        nym_data, proof = self.get_value_from_state(path, with_proof=True)
+        if nym_data:
+            nym_data = self.stateSerializer.deserialize(nym_data)
+            nym_data[TARGET_NYM] = nym
+            data = self.stateSerializer.serialize(nym_data)
+            seq_no = nym_data[f.SEQ_NO.nm]
+            update_time = nym_data[TXN_TIME]
         else:
             data = None
             seq_no = None
-            proof = self.make_proof(path)
+            proof = None",23,2018-05-29 15:46:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/191466224,https://github.com/hyperledger/indy-node/pull/730#discussion_r191466224,ashcherbakov
https://github.com/hyperledger/indy-node/pull/730,https://github.com/hyperledger/indy-node/pull/730,Why don't we use IDR Cache anymore?,e07b967ddbbb52fd6188472dfc80f3cd118f0bf9,2018-05-29 15:19:20,191466347,"@@ -421,18 +421,18 @@ def add_query_handler(self, txn_type, handler: Callable):
 
     def handleGetNymReq(self, request: Request):
         nym = request.operation[TARGET_NYM]
-        nymData = self.idrCache.getNym(nym, isCommitted=True)",4,2018-05-29 15:46:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/191466347,https://github.com/hyperledger/indy-node/pull/730#discussion_r191466347,ashcherbakov
https://github.com/hyperledger/indy-node/pull/730,https://github.com/hyperledger/indy-node/pull/730,Because same data is present in state trie too.,e07b967ddbbb52fd6188472dfc80f3cd118f0bf9,2018-05-31 05:09:14,191990505,"@@ -421,18 +421,18 @@ def add_query_handler(self, txn_type, handler: Callable):
 
     def handleGetNymReq(self, request: Request):
         nym = request.operation[TARGET_NYM]
-        nymData = self.idrCache.getNym(nym, isCommitted=True)",4,2018-05-31 05:09:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/191990505,https://github.com/hyperledger/indy-node/pull/730#discussion_r191990505,lovesh
https://github.com/hyperledger/indy-node/pull/730,https://github.com/hyperledger/indy-node/pull/730,Adding,e07b967ddbbb52fd6188472dfc80f3cd118f0bf9,2018-05-31 05:09:19,191990512,"@@ -421,18 +421,18 @@ def add_query_handler(self, txn_type, handler: Callable):
 
     def handleGetNymReq(self, request: Request):
         nym = request.operation[TARGET_NYM]
-        nymData = self.idrCache.getNym(nym, isCommitted=True)
         path = domain.make_state_path_for_nym(nym)
-        if nymData:
-            nymData[TARGET_NYM] = nym
-            data = self.stateSerializer.serialize(nymData)
-            seq_no = nymData[f.SEQ_NO.nm]
-            update_time = nymData[TXN_TIME]
-            proof = self.make_proof(path)
+        nym_data, proof = self.get_value_from_state(path, with_proof=True)
+        if nym_data:
+            nym_data = self.stateSerializer.deserialize(nym_data)
+            nym_data[TARGET_NYM] = nym
+            data = self.stateSerializer.serialize(nym_data)
+            seq_no = nym_data[f.SEQ_NO.nm]
+            update_time = nym_data[TXN_TIME]
         else:
             data = None
             seq_no = None
-            proof = self.make_proof(path)
+            proof = None",23,2018-05-31 05:09:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/191990512,https://github.com/hyperledger/indy-node/pull/730#discussion_r191990512,lovesh
https://github.com/hyperledger/indy-node/pull/708,https://github.com/hyperledger/indy-node/pull/708,Please use `get_txn_time` helper method,302c9a6d5a3579b40a4c17ec3742d37ac1997aca,2018-05-23 08:18:52,190159714,"@@ -82,11 +82,12 @@ def test_send_with_from_by_demand(looper,
         sdk_pool_handle)[0]
     reg_delta_req = copy.deepcopy(build_get_revoc_reg_delta)
     reg_delta_req['operation'][REVOC_REG_DEF_ID] = rev_reg_req1['operation'][REVOC_REG_DEF_ID]
-    reg_delta_req['operation'][FROM] = rev_reg_reply1['result'][TXN_TIME]
-    reg_delta_req['operation'][TO] = rev_reg_reply3['result'][TXN_TIME] + 1000
+    reg_delta_req['operation'][FROM] = rev_reg_reply1['result'][TXN_METADATA][TXN_TIME]",,2018-05-24 15:41:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/190159714,https://github.com/hyperledger/indy-node/pull/708#discussion_r190159714,ashcherbakov
https://github.com/hyperledger/indy-node/pull/708,https://github.com/hyperledger/indy-node/pull/708,Why don't we remove validation of `reply_to`?,302c9a6d5a3579b40a4c17ec3742d37ac1997aca,2018-05-23 08:21:59,190160556,"@@ -73,14 +75,13 @@ def check_valid_proof(reply):
     assert MULTI_SIGNATURE_VALUE_TIMESTAMP in multi_sig_value
     assert multi_sig_value[MULTI_SIGNATURE_VALUE_TIMESTAMP]
     if result[TYPE] == GET_REVOC_REG_DELTA:
-        if STATE_PROOF_FROM in result[DATA] and result[DATA][STATE_PROOF_FROM]:
-            reply_from = {DATA: result['data'][VALUE][ACCUM_FROM],
-                          STATE_PROOF: result['data'][STATE_PROOF_FROM],
-                          TYPE: result[TYPE]}
-            assert validate_proof(reply_from)
-        reply_to = {DATA: result['data'][VALUE][ACCUM_TO],
-                    STATE_PROOF: result[STATE_PROOF],
-                    TYPE: result[TYPE]}
-        assert validate_proof(reply_to)
+        reply_from = {DATA: result['data'][VALUE][ACCUM_TO],",,2018-05-24 15:41:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/190160556,https://github.com/hyperledger/indy-node/pull/708#discussion_r190160556,ashcherbakov
https://github.com/hyperledger/indy-node/pull/708,https://github.com/hyperledger/indy-node/pull/708,Please use `get_payload_data` helper method,302c9a6d5a3579b40a4c17ec3742d37ac1997aca,2018-05-23 08:22:39,190160728,"@@ -82,11 +82,12 @@ def test_send_with_from_by_demand(looper,
         sdk_pool_handle)[0]
     reg_delta_req = copy.deepcopy(build_get_revoc_reg_delta)
     reg_delta_req['operation'][REVOC_REG_DEF_ID] = rev_reg_req1['operation'][REVOC_REG_DEF_ID]
-    reg_delta_req['operation'][FROM] = rev_reg_reply1['result'][TXN_TIME]
-    reg_delta_req['operation'][TO] = rev_reg_reply3['result'][TXN_TIME] + 1000
+    reg_delta_req['operation'][FROM] = rev_reg_reply1['result'][TXN_METADATA][TXN_TIME]
+    reg_delta_req['operation'][TO] = rev_reg_reply3['result'][TXN_METADATA][TXN_TIME] + 1000
     get_reply = sdk_send_and_check([json.dumps(reg_delta_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0][1]
     assert get_reply['result'][DATA][STATE_PROOF_FROM]
     assert get_reply['result'][DATA][VALUE][REVOKED] == [1, 2, 3]
     assert get_reply['result'][DATA][VALUE][ISSUED] == [10, 11]
     assert get_reply['result'][DATA][VALUE][ACCUM_TO][VALUE][ACCUM] == rev_reg_req3['operation'][VALUE][ACCUM]
-    assert get_reply['result'][DATA][VALUE][ACCUM_FROM][VALUE][ACCUM] == rev_reg_reply1['result'][VALUE][ACCUM]
+    assert get_reply['result'][DATA][VALUE][ACCUM_FROM][VALUE][ACCUM] == \",28,2018-05-24 15:41:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/190160728,https://github.com/hyperledger/indy-node/pull/708#discussion_r190160728,ashcherbakov
https://github.com/hyperledger/indy-node/pull/708,https://github.com/hyperledger/indy-node/pull/708,Please use get_txn_time helper method,302c9a6d5a3579b40a4c17ec3742d37ac1997aca,2018-05-23 08:24:54,190161329,"@@ -87,10 +88,11 @@ def test_state_proof_returned_for_get_revoc_reg_delta(looper,
         sdk_pool_handle)[0]
     reg_delta_req = copy.deepcopy(build_get_revoc_reg_delta)
     reg_delta_req['operation'][REVOC_REG_DEF_ID] = rev_reg_req1['operation'][REVOC_REG_DEF_ID]
-    reg_delta_req['operation'][FROM] = rev_reg_reply1['result'][TXN_TIME]
-    reg_delta_req['operation'][TO] = rev_reg_reply3['result'][TXN_TIME] + 1000
-    get_reply = sdk_send_and_check([json.dumps(reg_delta_req)], looper, txnPoolNodeSet, sdk_pool_handle)[0][1]
-    check_valid_proof(get_reply)
+    reg_delta_req['operation'][FROM] = rev_reg_reply1['result'][TXN_METADATA][TXN_TIME]",,2018-05-24 15:41:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/190161329,https://github.com/hyperledger/indy-node/pull/708#discussion_r190161329,ashcherbakov
https://github.com/hyperledger/indy-node/pull/708,https://github.com/hyperledger/indy-node/pull/708,"So, did we change the format of Reply? Does master have exactly the same fields and names?",302c9a6d5a3579b40a4c17ec3742d37ac1997aca,2018-05-25 07:03:24,190806212,"@@ -628,6 +629,8 @@ def handleGetRevocRegDelta(self, request: Request):
                 if req_ts_from and accum_from.value:
                     reply[STATE_PROOF_FROM] = accum_from.proof
                     reply[VALUE][ACCUM_FROM] = accum_from.value
+                    reply[VALUE][SEQ_NO_FROM] = accum_from.seq_no",14,2018-05-25 07:10:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/190806212,https://github.com/hyperledger/indy-node/pull/708#discussion_r190806212,ashcherbakov
https://github.com/hyperledger/indy-node/pull/708,https://github.com/hyperledger/indy-node/pull/708,Where do we use these methods?,302c9a6d5a3579b40a4c17ec3742d37ac1997aca,2018-05-25 07:06:24,190806706,"@@ -194,6 +194,57 @@ def prepare_get_claim_def_for_state(reply):
     return path, value_bytes
 
 
+def prepare_get_revoc_def_for_state(reply):",4,2018-05-25 07:10:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/190806706,https://github.com/hyperledger/indy-node/pull/708#discussion_r190806706,ashcherbakov
https://github.com/hyperledger/indy-node/pull/708,https://github.com/hyperledger/indy-node/pull/708,"Why don't we call `prepare_get_revoc_def_for_state`? `result` is a result of get request, but `prepare_revoc_def_for_state` assumes `txn` as an argument.",302c9a6d5a3579b40a4c17ec3742d37ac1997aca,2018-05-25 07:08:07,190807000,"@@ -1,25 +1,36 @@
+from plenum.common.types import f
+
 from plenum.common.constants import STATE_PROOF, ROOT_HASH, MULTI_SIGNATURE, PROOF_NODES, MULTI_SIGNATURE_SIGNATURE, \
     MULTI_SIGNATURE_PARTICIPANTS, MULTI_SIGNATURE_VALUE, MULTI_SIGNATURE_VALUE_LEDGER_ID, \
     MULTI_SIGNATURE_VALUE_STATE_ROOT, MULTI_SIGNATURE_VALUE_TXN_ROOT, MULTI_SIGNATURE_VALUE_POOL_STATE_ROOT, \
-    MULTI_SIGNATURE_VALUE_TIMESTAMP, TYPE, DATA
+    MULTI_SIGNATURE_VALUE_TIMESTAMP, TYPE, DATA, TXN_TIME, TXN_PAYLOAD, TXN_PAYLOAD_METADATA, TXN_PAYLOAD_METADATA_FROM, \
+    TXN_PAYLOAD_DATA, TXN_METADATA, TXN_METADATA_SEQ_NO, TXN_METADATA_TIME
 from indy_common.constants import VALUE, GET_REVOC_REG_DEF, GET_REVOC_REG, GET_REVOC_REG_DELTA, \
-    ACCUM_FROM, ACCUM_TO, STATE_PROOF_FROM, ISSUED
+    ACCUM_TO, ISSUED, STATE_PROOF_FROM, ACCUM_FROM
 from common.serializers.serialization import state_roots_serializer, proof_nodes_serializer
 from state.pruning_state import PruningState
 from indy_common.state import domain
 
 
+def add_txn_specific_fileds(result):
+    result[TXN_PAYLOAD] = {TXN_PAYLOAD_METADATA: {TXN_PAYLOAD_METADATA_FROM: result[f.IDENTIFIER.nm]}}
+    result[TXN_PAYLOAD][TXN_PAYLOAD_DATA] = result[TXN_PAYLOAD_DATA]
+    result[TXN_METADATA] = {TXN_METADATA_SEQ_NO: result[TXN_METADATA_SEQ_NO]}
+    result[TXN_METADATA][TXN_METADATA_TIME] = result[TXN_METADATA_TIME]
+
+
 def prepare_for_state(result):
     request_type = result[TYPE]
+    add_txn_specific_fileds(result)
     if request_type == GET_REVOC_REG_DEF:
-        return domain.prepare_revoc_def_for_state(result['data'])
+        return domain.prepare_revoc_def_for_state(result)",29,2018-05-25 07:10:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/190807000,https://github.com/hyperledger/indy-node/pull/708#discussion_r190807000,ashcherbakov
https://github.com/hyperledger/indy-node/pull/708,https://github.com/hyperledger/indy-node/pull/708,Why we didn't need these fields before?,302c9a6d5a3579b40a4c17ec3742d37ac1997aca,2018-05-25 07:10:11,190807332,"@@ -74,13 +85,21 @@ def check_valid_proof(reply):
     assert multi_sig_value[MULTI_SIGNATURE_VALUE_TIMESTAMP]
     if result[TYPE] == GET_REVOC_REG_DELTA:
         if STATE_PROOF_FROM in result[DATA] and result[DATA][STATE_PROOF_FROM]:
-            reply_from = {DATA: result['data'][VALUE][ACCUM_FROM],
-                          STATE_PROOF: result['data'][STATE_PROOF_FROM],
-                          TYPE: result[TYPE]}
+            reply_from = {DATA: result[DATA][VALUE][ACCUM_FROM],
+                          STATE_PROOF: result[DATA][STATE_PROOF_FROM],
+                          TYPE: result[TYPE],
+                          f.IDENTIFIER.nm: result[f.IDENTIFIER.nm],
+                          f.SEQ_NO.nm: result[DATA][VALUE][f.SEQ_NO.nm + 'From'],",55,2018-05-25 07:10:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/190807332,https://github.com/hyperledger/indy-node/pull/708#discussion_r190807332,ashcherbakov
https://github.com/hyperledger/indy-node/pull/708,https://github.com/hyperledger/indy-node/pull/708,Maybe we can just add SEQ_NO to ACCUM txn value to avoid changes in SDK to support the new format...,302c9a6d5a3579b40a4c17ec3742d37ac1997aca,2018-05-25 08:25:53,190823568,"@@ -628,6 +629,8 @@ def handleGetRevocRegDelta(self, request: Request):
                 if req_ts_from and accum_from.value:
                     reply[STATE_PROOF_FROM] = accum_from.proof
                     reply[VALUE][ACCUM_FROM] = accum_from.value
+                    reply[VALUE][SEQ_NO_FROM] = accum_from.seq_no",14,2018-05-25 08:25:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/190823568,https://github.com/hyperledger/indy-node/pull/708#discussion_r190823568,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,Please remove this constant,fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 10:12:27,192051512,"@@ -0,0 +1,142 @@
+import importlib
+import json
+import os
+import shutil
+import tempfile
+
+from indy_common.config_helper import NodeConfigHelper
+from indy_node.server.config_helper import create_config_dirs
+from plenum.recorder.src.replayer import get_recorders_from_node_data_dir, \
+    prepare_node_for_replay_and_replay
+from stp_core.common.log import getlogger, Logger
+
+from stp_core.types import HA
+
+from stp_core.loop.looper import Looper
+
+from indy_node.server.node import Node
+
+from plenum.server.replicas import Replicas
+
+from plenum.server.replica import Replica
+
+from indy_common.config_util import getConfig
+from plenum.recorder.src.replayable_node import create_replayable_node_class
+
+RecordingZipFilePath = '/home/lovesh/rec.zip'
+
+ReplayBaseDirPath = '/home/lovesh/tmp'
+
+
+def process_recording_zip():
+    # Unzip the recording file
+    return
+
+
+def get_updated_config():
+    # Update current config with config file from the recording zip
+    return getConfig()
+
+
+def setup_logging():
+    pass
+
+
+def update_loaded_config(config):
+    config.USE_WITH_STACK = 2
+    import stp_zmq.kit_zstack
+    importlib.reload(stp_zmq.kit_zstack)
+    import plenum.common.stacks
+    importlib.reload(plenum.common.stacks)
+    import plenum.server.node
+    importlib.reload(plenum.server.node)
+    import indy_node.server.node
+    importlib.reload(indy_node.server.node)
+
+
+def replay_node():
+    orig_node_dir = '/home/lovesh/Downloads/Node3.20180517222134/'",58,2018-05-31 11:11:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192051512,https://github.com/hyperledger/indy-node/pull/703#discussion_r192051512,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"There is `config_helper` to deal with these paths, so please don't use constants explicitly and use helper methods as this is configurable values.",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 10:17:00,192052564,"@@ -0,0 +1,142 @@
+import importlib
+import json
+import os
+import shutil
+import tempfile
+
+from indy_common.config_helper import NodeConfigHelper
+from indy_node.server.config_helper import create_config_dirs
+from plenum.recorder.src.replayer import get_recorders_from_node_data_dir, \
+    prepare_node_for_replay_and_replay
+from stp_core.common.log import getlogger, Logger
+
+from stp_core.types import HA
+
+from stp_core.loop.looper import Looper
+
+from indy_node.server.node import Node
+
+from plenum.server.replicas import Replicas
+
+from plenum.server.replica import Replica
+
+from indy_common.config_util import getConfig
+from plenum.recorder.src.replayable_node import create_replayable_node_class
+
+RecordingZipFilePath = '/home/lovesh/rec.zip'
+
+ReplayBaseDirPath = '/home/lovesh/tmp'
+
+
+def process_recording_zip():
+    # Unzip the recording file
+    return
+
+
+def get_updated_config():
+    # Update current config with config file from the recording zip
+    return getConfig()
+
+
+def setup_logging():
+    pass
+
+
+def update_loaded_config(config):
+    config.USE_WITH_STACK = 2
+    import stp_zmq.kit_zstack
+    importlib.reload(stp_zmq.kit_zstack)
+    import plenum.common.stacks
+    importlib.reload(plenum.common.stacks)
+    import plenum.server.node
+    importlib.reload(plenum.server.node)
+    import indy_node.server.node
+    importlib.reload(indy_node.server.node)
+
+
+def replay_node():
+    orig_node_dir = '/home/lovesh/Downloads/Node3.20180517222134/'
+    replaying_node_name = 'Node3'
+
+    pool_name = 'sandbox'
+
+    replay_node_dir = tempfile.TemporaryDirectory().name
+    print(replay_node_dir)
+    # with tempfile.TemporaryDirectory() as replay_node_dir:
+    general_config_dir = create_config_dirs(replay_node_dir)
+    config = getConfig(general_config_dir)
+    update_loaded_config(config)
+    pool_dir = os.path.join(replay_node_dir, pool_name)
+    orig_node_pool_dir = os.path.join(orig_node_dir, pool_name)
+
+    # for d in (pool_dir, data_dir):
+    #     os.makedirs(d, exist_ok=True)
+    #
+    # for file in os.listdir(orig_node_pool_dir):
+    #     if file.endswith('.json') or file.endswith('_genesis'):
+    #         shutil.copy(os.path.join(orig_node_pool_dir, file), pool_dir)
+    #
+    # shutil.copytree(os.path.join(orig_node_pool_dir, 'keys'),
+    #                 os.path.join(pool_dir, 'keys'))
+    # shutil.copytree(os.path.join(orig_node_dir, 'plugins'),
+    #                 os.path.join(replay_node_dir, 'plugins'))
+    trg_var_dir = os.path.join(replay_node_dir, 'var', 'lib', 'indy', pool_name)",83,2018-05-31 11:11:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192052564,https://github.com/hyperledger/indy-node/pull/703#discussion_r192052564,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,Why this script not in plenum?,fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 10:20:40,192053398,"@@ -0,0 +1,142 @@
+import importlib
+import json
+import os
+import shutil
+import tempfile
+
+from indy_common.config_helper import NodeConfigHelper
+from indy_node.server.config_helper import create_config_dirs
+from plenum.recorder.src.replayer import get_recorders_from_node_data_dir, \
+    prepare_node_for_replay_and_replay
+from stp_core.common.log import getlogger, Logger
+
+from stp_core.types import HA
+
+from stp_core.loop.looper import Looper
+
+from indy_node.server.node import Node
+
+from plenum.server.replicas import Replicas
+
+from plenum.server.replica import Replica
+
+from indy_common.config_util import getConfig
+from plenum.recorder.src.replayable_node import create_replayable_node_class
+
+RecordingZipFilePath = '/home/lovesh/rec.zip'
+
+ReplayBaseDirPath = '/home/lovesh/tmp'
+
+
+def process_recording_zip():
+    # Unzip the recording file
+    return
+
+
+def get_updated_config():
+    # Update current config with config file from the recording zip
+    return getConfig()
+
+
+def setup_logging():
+    pass
+
+
+def update_loaded_config(config):
+    config.USE_WITH_STACK = 2
+    import stp_zmq.kit_zstack
+    importlib.reload(stp_zmq.kit_zstack)
+    import plenum.common.stacks
+    importlib.reload(plenum.common.stacks)
+    import plenum.server.node
+    importlib.reload(plenum.server.node)
+    import indy_node.server.node
+    importlib.reload(indy_node.server.node)
+
+
+def replay_node():",57,2018-05-31 11:11:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192053398,https://github.com/hyperledger/indy-node/pull/703#discussion_r192053398,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,We use pytest for testing. Can we switch to pytest to execute the test during CI?,fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 10:30:29,192055735,"@@ -0,0 +1,670 @@
+#!/usr/bin/env python3
+
+import sys
+import os
+import argparse
+import logging
+import datetime
+import time
+from collections import namedtuple
+import tempfile
+import subprocess
+import atexit
+import shutil
+
+from io import StringIO
+
+from plenum.server.general_config import ubuntu_platform_config
+
+logger = logging.getLogger()
+
+ArchiveEntry = namedtuple('archive_entry', ['abs_fs_path', 'archive_path', 'include'])
+
+ENV_COLLECTION_CMD = [
+    (""python_version"", ['python3', '-V']),
+    (""pip_freeze"", ['pip3', 'freeze']),
+    (""app_install"", ['apt', 'list', '--installed']),
+    (""validator_info"", ['validator-info', '-v']),
+]
+
+
+# ***************
+# *  Command-line Argument Parsing
+# ***************
+def str2bool(v):
+    if v.lower() in ('yes', 'true', 't', 'y', '1'):
+        return True
+    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
+        return False
+    else:
+        raise argparse.ArgumentTypeError(
+            'Boolean value (yes, no, true, false, y, n, 1, or 0) expected.')
+
+LOG_LEVEL_HELP = """"""Logging level.
+                      [LOG-LEVEL]: notset, debug, info, warning, error, critical
+                      Default: warning""""""
+levels = {
+   'notset': logging.NOTSET,
+   'debug': logging.DEBUG,
+   'info': logging.INFO,
+   'warning': logging.WARNING,
+   'error': logging.ERROR,
+   'critical': logging.CRITICAL
+}
+
+
+def log_level(v):
+    if v.lower() in levels.keys():
+        return levels[v.lower()]
+    else:
+        raise argparse.ArgumentTypeError(
+            'Expected one of the following: {}.'.format(
+                ', '.join(levels.keys())))
+
+
+def program_args():
+    parser = argparse.ArgumentParser()
+
+    parser.add_argument('-t', '--test', action='store_true',
+                        default=False, help='Runs unit tests and exits.')
+
+    parser.add_argument('-l', '--log-level', type=log_level, nargs='?',
+                        const=logging.INFO, default=logging.INFO, help=LOG_LEVEL_HELP)
+
+    parser.add_argument('-o', '--output-dir', default=os.getcwd(),
+                        help='the directory where the captured file will be writen to. Default: CWD')
+    parser.add_argument('-n', '--node-name',
+                        help='The name of the node to be captured, required if the script finds more than one node.')
+    parser.add_argument('-r', '--root-dir', default='/',
+                        help='The root to look for node artifacts. Default: /')
+
+    parser.add_argument('-x', '--exclude-recording', action='store_true',
+                        help='Will exclude recording data from capture.')
+    parser.add_argument('-d', '--dry-run', action='store_true',
+                        default=False, help='Will not create archive file but will collect files to be collected')
+
+    return parser
+
+
+def parse_args(argv=None, parser=program_args()):
+    return parser.parse_args(args=argv)
+
+
+def get_system_dirs():
+    # TODO detect the system someday (help support windows)
+    return ubuntu_platform_config
+
+
+# ***************
+# *  Capture File Collection
+# ***************
+def _log_capture(collection):
+    for entry in collection:
+        logger.info(""%s found at %s"" % (entry.archive_path, entry.abs_fs_path))
+        for file in entry.include:
+            logger.info(""    %s"" % file)
+
+
+def _collect_files(dir_type, directory, archive_path, filter_fn, recursive=True):
+    rtn = ArchiveEntry(directory, archive_path, [])
+
+    try:
+        for root, dirs, files in os.walk(directory):
+            rel_path = os.path.relpath(root, directory)
+            files = [os.path.join(rel_path, f) for f in files]
+            files = filter(filter_fn, files)
+            rtn.include.extend(files)
+            if recursive is not True:
+                break
+    except FileNotFoundError:
+        logger.warning(""Unable to find a %s directory for pool! Looked for '%s'"", dir_type, directory)
+
+    return rtn
+
+
+def _run_env_capture_cmd(output_file, cmd, entry):
+    try:
+        with open(output_file, 'w') as f:
+            subprocess.run(cmd,
+                           check=True,
+                           stderr=subprocess.STDOUT,
+                           stdout=f
+                           )
+    except (subprocess.CalledProcessError, FileNotFoundError) as e:
+        logger.warning(""Unable to capture env data: cmd '%s' - error: %s"", ' '.join(cmd), str(e))
+    finally:
+        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
+            entry.include.append(output_file)
+
+
+def collect_env(args):
+    logger.info(""Collecting Env Files"")
+    d = tempfile.mkdtemp()
+    TEMP_DIRS.append(d)
+    rtn = ArchiveEntry(d, '/capture', [])
+    for filename, cmd in ENV_COLLECTION_CMD:
+        _run_env_capture_cmd(os.path.join(d, filename),
+                             cmd,
+                             rtn)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_logs(args):
+    log_dir = indy_log_dir(args)
+    log_dir = os.path.join(log_dir, args.pool_name)
+
+    def log_filter(f):
+        return f.startswith(os.path.join('.', args.node_name))
+
+    logger.info(""Collecting Log Files"")
+    rtn = _collect_files('logger.info(""Collected %s files to captured"", str(len(rtn.include)))log',
+                         log_dir,
+                         '/log',
+                         log_filter,
+                         recursive=False)
+
+    return rtn
+
+
+def collect_config(args):
+    d = indy_config_dir(args)
+
+    def file_filter(_f):
+        return True
+
+    logger.info(""Collecting Config Files"")
+    rtn = _collect_files('config', d, '/config', file_filter, recursive=False)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_data(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, args.pool_name)
+
+    def file_filter(f):
+        if f.startswith('data/'):
+            if f.startswith(os.path.join('data/', args.node_name+'/')) \
+               or f.startswith(os.path.join('data/', args.node_name+'C/')):
+
+                if 'recorder' in f:
+                    return not args.exclude_recording
+                return True
+            else:
+                return False
+
+        return True
+
+    logger.info(""Collecting Data Files"")
+    rtn = _collect_files('application data', d, '/', file_filter, recursive=True)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_plugins(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, 'plugins')
+
+    def file_filter(f):
+        return True
+
+    logger.info(""Collecting Plugins Files"")
+    rtn = _collect_files('plugin data', d, '/plugins', file_filter, recursive=True)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_capture_files(args):
+    rtn = []
+    logger.info(""Collecting file to be captured"")
+    rtn.append(collect_env(args))
+    rtn.append(collect_logs(args))
+    rtn.append(collect_config(args))
+    rtn.append(collect_data(args))
+    rtn.append(collect_plugins(args))
+    logger.info(""Collection complete"")
+    return rtn
+
+
+# ***************
+# *  Indy Directories
+# ***************
+def _find_dir(args, dir_location, name):
+    dir_location = dir_location.lstrip(""/"")
+    rtn = os.path.join(args.root_dir, dir_location)
+    logger.debug(""using %s dir: %s"", name, rtn)
+    return rtn
+
+
+def indy_app_dir(args):
+    return _find_dir(args, get_system_dirs().NODE_INFO_DIR, ""application dir"")
+
+
+def indy_log_dir(args):
+    return _find_dir(args, get_system_dirs().LOG_DIR, ""logging dir"")
+
+
+def indy_config_dir(args):
+    return _find_dir(args, '/etc/indy', ""config dir"")
+
+
+# ***************
+# *  Capture File Output File Name
+# ***************
+def capture_file_name(args):
+
+    if (not hasattr(args, 'node_name') or not hasattr(args, 'pool_name')) or \
+       (args.node_name is None or args.pool_name is None):
+        logger.error(""node_name or pool_name has not been specified, can not create capture file name. Object: %s"",
+                     str(args))
+        raise Exception(""Can not create capture file name!"")
+
+    rtn = ""%s.%s.%s"" % (args.node_name, args.pool_name, datetime.datetime.now().strftime(""%Y%m%d%H%M%S""))
+    return rtn
+
+
+# ***************
+# *  Node Discovery
+# ***************
+def find_node_name(args):
+    nodes = []
+
+    def find_nodes_in_pool_dir(pool_name):
+        data_dir = os.path.join(indy_app_dir(args), pool_name, ""data"")
+
+        try:
+            possible_nodes = sorted(os.listdir(data_dir))
+        except FileNotFoundError:
+            logger.warning(""Did not find a data directory for pool '%s'! (Likely not an issue) Looked for '%s'"",
+                           pool_name, data_dir)
+            return []
+
+        possible_nodes = list(filter(is_dir_check(data_dir), possible_nodes))
+        logger.debug(""possible node names in %s: %s"", pool_name, possible_nodes)
+        node_names = set()
+        while len(possible_nodes) is not 0:
+            try:
+                a_name = possible_nodes.pop(0)
+                possible_nodes.remove(a_name + 'C')
+                node_names.add((a_name, pool_name))
+            except ValueError:
+                logger.warning(""Possible Node don't have client dir"")
+
+        return node_names
+
+    def is_dir_check(base_dir):
+        def is_dir(d):
+            return os.path.isdir(os.path.join(base_dir, d))
+        return is_dir
+
+    app_dir = indy_app_dir(args)
+    try:
+        pool_dirs = list(filter(is_dir_check(indy_app_dir(args)), os.listdir(app_dir)))
+    except FileNotFoundError:
+        logger.error(""Unable to find indy application directory! Looked for '%s'"", app_dir)
+        raise
+
+    for pool in pool_dirs:
+        # ignore plugins dir - it is not a pool directory
+        if ""plugins"" == pool:
+            continue
+
+        nodes.extend(find_nodes_in_pool_dir(pool))
+
+    if args.node_name is None:
+        if len(nodes) == 1:
+            node_name, pool = nodes.pop()
+            args.node_name = node_name
+            args.pool_name = pool
+        elif len(nodes) == 0:
+            logger.error(""No nodes where found. Check root dir?"", nodes)
+            sys.exit(-1)
+        else:
+            logger.error(""Found more than one node and a node name was not specified! Found -- %s"", nodes)
+            sys.exit(-1)
+    else:
+        for node in nodes:
+            if args.node_name == node[0]:
+                args.pool_name = node[1]
+                break
+        else:
+            logger.error(""Node with name '%s' was not found, can not continue! Found -- %s"", args.node_name, nodes)
+            sys.exit(-1)
+
+    logger.info(""Capturing Node '%s' for pool '%s'"", args.node_name, args.pool_name)
+
+
+TEMP_DIRS = []
+
+
+# Clean up anything that is created by this script (excluding the output file)
+def clean_up():
+    while TEMP_DIRS:
+        shutil.rmtree(TEMP_DIRS.pop())
+
+    # raise Exception(""TEST"")
+
+
+# ***************
+# *  Init Details
+# ***************
+def init(args):
+    # print warning
+    print(""!"" * 20 + "" WARNING "" + '!' * 21)
+    print(""!"" * 2 + ""  "" + ""This tool captures node state replay and diagnostic purposes (for development and QA)"")
+    print(""!"" * 2 + ""  "" + ""By the nature of these needs, that includes sensitive data (including secret keys)"")
+    print(""!"" * 2 + ""  "" + ""DO NOT USE THIS TOOL on nodes that need to be secure"")
+    print(""!"" * 50)
+    time.sleep(1)
+
+    logger.setLevel(args.log_level)
+    logger.debug(""args: %s"", args)
+    find_node_name(args)
+
+    atexit.register(clean_up)
+
+
+def build_archive_cmd(output_file, files):
+    cmd = ['tar']
+    flags = 'cfz'
+    if logger.level == logging.DEBUG:
+        flags += 'v'
+    cmd.append(flags)
+    cmd.append(output_file)
+    cmd.append('--show-transformed-names')
+    cmd.extend([""-C"", ""/""])
+
+    for entry in files:
+        fs_path_pattern = entry.abs_fs_path + '/'
+        fs_path_pattern = fs_path_pattern.lstrip('/')
+        archive_path_pattern = entry.archive_path + '/'
+        archive_path_pattern = archive_path_pattern.lstrip('/')
+        cmd.append('--xform')
+        cmd.append(""s|%s|%s|1"" % (fs_path_pattern, archive_path_pattern))
+        for file in entry.include:
+            f_path = os.path.join(entry.abs_fs_path, file)
+            f_path = os.path.abspath(f_path)
+            f_path = f_path.lstrip('/')
+            cmd.append(f_path)
+
+    return cmd
+
+
+# ***************
+# *  Running the archive command
+# ***************
+def run_cmd(cmd):
+    logger.info(""Running archive command"")
+    try:
+        subprocess.run(cmd, check=True)
+        # os.system(' '.join(cmd))
+    except Exception as e:
+        logger.error(""Unable to complete archive command: %s"", str(e))
+    else:
+        logger.info(""Archive command complete"")
+
+
+def do_capture(args, files):
+    output_file = os.path.join(args.output_dir, capture_file_name(args) + '.tar.gz')
+    logger.info(""Writing archive to '%s'"" % output_file)
+
+    logger.info(""Building archive command"")
+    cmd = build_archive_cmd(output_file, files)
+    logger.debug(""Archive command to be run:"")
+    logger.debug(' '.join(cmd))
+
+    if args.dry_run:
+        logger.info(""Dry-run"")
+        logger.info(""Collected following files:"")
+        _log_capture(files)
+        return
+    else:
+        if os.getuid() is not 0:
+            logger.error(""Must be run as super user (sudo) to capture all files."")
+            raise Exception(""Not Super User"")
+        run_cmd(cmd)
+
+
+def main(args):
+    try:
+        init(args)
+    except:
+        logger.error('Unable to initialize script')
+        raise
+
+    try:
+        files = collect_capture_files(args)
+    except:
+        logger.error('Unable to collect the files for this capture')
+        raise
+
+    try:
+        do_capture(args, files)
+    except:
+        logger.error('Unable to build capture archive')
+        raise
+
+
+# ***************
+# *  UNIT TESTS !!!!! (use -t to run them)
+# ***************
+def test():
+    print(""The 'unittest' module is not available!\nUnable to run tests!"")
+    sys.exit(0)
+
+try:
+    import unittest
+
+    def test():
+        unittest.main(argv=['capture_test'])
+        sys.exit(0)
+
+    def _touch(path, content):
+        d = os.path.dirname(path)
+        os.makedirs(d, exist_ok=True)
+        with open(path, 'w') as f:
+            f.write(content)
+
+    class TestCapture(unittest.TestCase):",469,2018-05-31 11:11:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192055735,https://github.com/hyperledger/indy-node/pull/703#discussion_r192055735,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,And please move tests to a separate folder (like in other places in code),fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 10:30:59,192055845,"@@ -0,0 +1,670 @@
+#!/usr/bin/env python3
+
+import sys
+import os
+import argparse
+import logging
+import datetime
+import time
+from collections import namedtuple
+import tempfile
+import subprocess
+import atexit
+import shutil
+
+from io import StringIO
+
+from plenum.server.general_config import ubuntu_platform_config
+
+logger = logging.getLogger()
+
+ArchiveEntry = namedtuple('archive_entry', ['abs_fs_path', 'archive_path', 'include'])
+
+ENV_COLLECTION_CMD = [
+    (""python_version"", ['python3', '-V']),
+    (""pip_freeze"", ['pip3', 'freeze']),
+    (""app_install"", ['apt', 'list', '--installed']),
+    (""validator_info"", ['validator-info', '-v']),
+]
+
+
+# ***************
+# *  Command-line Argument Parsing
+# ***************
+def str2bool(v):
+    if v.lower() in ('yes', 'true', 't', 'y', '1'):
+        return True
+    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
+        return False
+    else:
+        raise argparse.ArgumentTypeError(
+            'Boolean value (yes, no, true, false, y, n, 1, or 0) expected.')
+
+LOG_LEVEL_HELP = """"""Logging level.
+                      [LOG-LEVEL]: notset, debug, info, warning, error, critical
+                      Default: warning""""""
+levels = {
+   'notset': logging.NOTSET,
+   'debug': logging.DEBUG,
+   'info': logging.INFO,
+   'warning': logging.WARNING,
+   'error': logging.ERROR,
+   'critical': logging.CRITICAL
+}
+
+
+def log_level(v):
+    if v.lower() in levels.keys():
+        return levels[v.lower()]
+    else:
+        raise argparse.ArgumentTypeError(
+            'Expected one of the following: {}.'.format(
+                ', '.join(levels.keys())))
+
+
+def program_args():
+    parser = argparse.ArgumentParser()
+
+    parser.add_argument('-t', '--test', action='store_true',
+                        default=False, help='Runs unit tests and exits.')
+
+    parser.add_argument('-l', '--log-level', type=log_level, nargs='?',
+                        const=logging.INFO, default=logging.INFO, help=LOG_LEVEL_HELP)
+
+    parser.add_argument('-o', '--output-dir', default=os.getcwd(),
+                        help='the directory where the captured file will be writen to. Default: CWD')
+    parser.add_argument('-n', '--node-name',
+                        help='The name of the node to be captured, required if the script finds more than one node.')
+    parser.add_argument('-r', '--root-dir', default='/',
+                        help='The root to look for node artifacts. Default: /')
+
+    parser.add_argument('-x', '--exclude-recording', action='store_true',
+                        help='Will exclude recording data from capture.')
+    parser.add_argument('-d', '--dry-run', action='store_true',
+                        default=False, help='Will not create archive file but will collect files to be collected')
+
+    return parser
+
+
+def parse_args(argv=None, parser=program_args()):
+    return parser.parse_args(args=argv)
+
+
+def get_system_dirs():
+    # TODO detect the system someday (help support windows)
+    return ubuntu_platform_config
+
+
+# ***************
+# *  Capture File Collection
+# ***************
+def _log_capture(collection):
+    for entry in collection:
+        logger.info(""%s found at %s"" % (entry.archive_path, entry.abs_fs_path))
+        for file in entry.include:
+            logger.info(""    %s"" % file)
+
+
+def _collect_files(dir_type, directory, archive_path, filter_fn, recursive=True):
+    rtn = ArchiveEntry(directory, archive_path, [])
+
+    try:
+        for root, dirs, files in os.walk(directory):
+            rel_path = os.path.relpath(root, directory)
+            files = [os.path.join(rel_path, f) for f in files]
+            files = filter(filter_fn, files)
+            rtn.include.extend(files)
+            if recursive is not True:
+                break
+    except FileNotFoundError:
+        logger.warning(""Unable to find a %s directory for pool! Looked for '%s'"", dir_type, directory)
+
+    return rtn
+
+
+def _run_env_capture_cmd(output_file, cmd, entry):
+    try:
+        with open(output_file, 'w') as f:
+            subprocess.run(cmd,
+                           check=True,
+                           stderr=subprocess.STDOUT,
+                           stdout=f
+                           )
+    except (subprocess.CalledProcessError, FileNotFoundError) as e:
+        logger.warning(""Unable to capture env data: cmd '%s' - error: %s"", ' '.join(cmd), str(e))
+    finally:
+        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
+            entry.include.append(output_file)
+
+
+def collect_env(args):
+    logger.info(""Collecting Env Files"")
+    d = tempfile.mkdtemp()
+    TEMP_DIRS.append(d)
+    rtn = ArchiveEntry(d, '/capture', [])
+    for filename, cmd in ENV_COLLECTION_CMD:
+        _run_env_capture_cmd(os.path.join(d, filename),
+                             cmd,
+                             rtn)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_logs(args):
+    log_dir = indy_log_dir(args)
+    log_dir = os.path.join(log_dir, args.pool_name)
+
+    def log_filter(f):
+        return f.startswith(os.path.join('.', args.node_name))
+
+    logger.info(""Collecting Log Files"")
+    rtn = _collect_files('logger.info(""Collected %s files to captured"", str(len(rtn.include)))log',
+                         log_dir,
+                         '/log',
+                         log_filter,
+                         recursive=False)
+
+    return rtn
+
+
+def collect_config(args):
+    d = indy_config_dir(args)
+
+    def file_filter(_f):
+        return True
+
+    logger.info(""Collecting Config Files"")
+    rtn = _collect_files('config', d, '/config', file_filter, recursive=False)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_data(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, args.pool_name)
+
+    def file_filter(f):
+        if f.startswith('data/'):
+            if f.startswith(os.path.join('data/', args.node_name+'/')) \
+               or f.startswith(os.path.join('data/', args.node_name+'C/')):
+
+                if 'recorder' in f:
+                    return not args.exclude_recording
+                return True
+            else:
+                return False
+
+        return True
+
+    logger.info(""Collecting Data Files"")
+    rtn = _collect_files('application data', d, '/', file_filter, recursive=True)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_plugins(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, 'plugins')
+
+    def file_filter(f):
+        return True
+
+    logger.info(""Collecting Plugins Files"")
+    rtn = _collect_files('plugin data', d, '/plugins', file_filter, recursive=True)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_capture_files(args):
+    rtn = []
+    logger.info(""Collecting file to be captured"")
+    rtn.append(collect_env(args))
+    rtn.append(collect_logs(args))
+    rtn.append(collect_config(args))
+    rtn.append(collect_data(args))
+    rtn.append(collect_plugins(args))
+    logger.info(""Collection complete"")
+    return rtn
+
+
+# ***************
+# *  Indy Directories
+# ***************
+def _find_dir(args, dir_location, name):
+    dir_location = dir_location.lstrip(""/"")
+    rtn = os.path.join(args.root_dir, dir_location)
+    logger.debug(""using %s dir: %s"", name, rtn)
+    return rtn
+
+
+def indy_app_dir(args):
+    return _find_dir(args, get_system_dirs().NODE_INFO_DIR, ""application dir"")
+
+
+def indy_log_dir(args):
+    return _find_dir(args, get_system_dirs().LOG_DIR, ""logging dir"")
+
+
+def indy_config_dir(args):
+    return _find_dir(args, '/etc/indy', ""config dir"")
+
+
+# ***************
+# *  Capture File Output File Name
+# ***************
+def capture_file_name(args):
+
+    if (not hasattr(args, 'node_name') or not hasattr(args, 'pool_name')) or \
+       (args.node_name is None or args.pool_name is None):
+        logger.error(""node_name or pool_name has not been specified, can not create capture file name. Object: %s"",
+                     str(args))
+        raise Exception(""Can not create capture file name!"")
+
+    rtn = ""%s.%s.%s"" % (args.node_name, args.pool_name, datetime.datetime.now().strftime(""%Y%m%d%H%M%S""))
+    return rtn
+
+
+# ***************
+# *  Node Discovery
+# ***************
+def find_node_name(args):
+    nodes = []
+
+    def find_nodes_in_pool_dir(pool_name):
+        data_dir = os.path.join(indy_app_dir(args), pool_name, ""data"")
+
+        try:
+            possible_nodes = sorted(os.listdir(data_dir))
+        except FileNotFoundError:
+            logger.warning(""Did not find a data directory for pool '%s'! (Likely not an issue) Looked for '%s'"",
+                           pool_name, data_dir)
+            return []
+
+        possible_nodes = list(filter(is_dir_check(data_dir), possible_nodes))
+        logger.debug(""possible node names in %s: %s"", pool_name, possible_nodes)
+        node_names = set()
+        while len(possible_nodes) is not 0:
+            try:
+                a_name = possible_nodes.pop(0)
+                possible_nodes.remove(a_name + 'C')
+                node_names.add((a_name, pool_name))
+            except ValueError:
+                logger.warning(""Possible Node don't have client dir"")
+
+        return node_names
+
+    def is_dir_check(base_dir):
+        def is_dir(d):
+            return os.path.isdir(os.path.join(base_dir, d))
+        return is_dir
+
+    app_dir = indy_app_dir(args)
+    try:
+        pool_dirs = list(filter(is_dir_check(indy_app_dir(args)), os.listdir(app_dir)))
+    except FileNotFoundError:
+        logger.error(""Unable to find indy application directory! Looked for '%s'"", app_dir)
+        raise
+
+    for pool in pool_dirs:
+        # ignore plugins dir - it is not a pool directory
+        if ""plugins"" == pool:
+            continue
+
+        nodes.extend(find_nodes_in_pool_dir(pool))
+
+    if args.node_name is None:
+        if len(nodes) == 1:
+            node_name, pool = nodes.pop()
+            args.node_name = node_name
+            args.pool_name = pool
+        elif len(nodes) == 0:
+            logger.error(""No nodes where found. Check root dir?"", nodes)
+            sys.exit(-1)
+        else:
+            logger.error(""Found more than one node and a node name was not specified! Found -- %s"", nodes)
+            sys.exit(-1)
+    else:
+        for node in nodes:
+            if args.node_name == node[0]:
+                args.pool_name = node[1]
+                break
+        else:
+            logger.error(""Node with name '%s' was not found, can not continue! Found -- %s"", args.node_name, nodes)
+            sys.exit(-1)
+
+    logger.info(""Capturing Node '%s' for pool '%s'"", args.node_name, args.pool_name)
+
+
+TEMP_DIRS = []
+
+
+# Clean up anything that is created by this script (excluding the output file)
+def clean_up():
+    while TEMP_DIRS:
+        shutil.rmtree(TEMP_DIRS.pop())
+
+    # raise Exception(""TEST"")
+
+
+# ***************
+# *  Init Details
+# ***************
+def init(args):
+    # print warning
+    print(""!"" * 20 + "" WARNING "" + '!' * 21)
+    print(""!"" * 2 + ""  "" + ""This tool captures node state replay and diagnostic purposes (for development and QA)"")
+    print(""!"" * 2 + ""  "" + ""By the nature of these needs, that includes sensitive data (including secret keys)"")
+    print(""!"" * 2 + ""  "" + ""DO NOT USE THIS TOOL on nodes that need to be secure"")
+    print(""!"" * 50)
+    time.sleep(1)
+
+    logger.setLevel(args.log_level)
+    logger.debug(""args: %s"", args)
+    find_node_name(args)
+
+    atexit.register(clean_up)
+
+
+def build_archive_cmd(output_file, files):
+    cmd = ['tar']
+    flags = 'cfz'
+    if logger.level == logging.DEBUG:
+        flags += 'v'
+    cmd.append(flags)
+    cmd.append(output_file)
+    cmd.append('--show-transformed-names')
+    cmd.extend([""-C"", ""/""])
+
+    for entry in files:
+        fs_path_pattern = entry.abs_fs_path + '/'
+        fs_path_pattern = fs_path_pattern.lstrip('/')
+        archive_path_pattern = entry.archive_path + '/'
+        archive_path_pattern = archive_path_pattern.lstrip('/')
+        cmd.append('--xform')
+        cmd.append(""s|%s|%s|1"" % (fs_path_pattern, archive_path_pattern))
+        for file in entry.include:
+            f_path = os.path.join(entry.abs_fs_path, file)
+            f_path = os.path.abspath(f_path)
+            f_path = f_path.lstrip('/')
+            cmd.append(f_path)
+
+    return cmd
+
+
+# ***************
+# *  Running the archive command
+# ***************
+def run_cmd(cmd):
+    logger.info(""Running archive command"")
+    try:
+        subprocess.run(cmd, check=True)
+        # os.system(' '.join(cmd))
+    except Exception as e:
+        logger.error(""Unable to complete archive command: %s"", str(e))
+    else:
+        logger.info(""Archive command complete"")
+
+
+def do_capture(args, files):
+    output_file = os.path.join(args.output_dir, capture_file_name(args) + '.tar.gz')
+    logger.info(""Writing archive to '%s'"" % output_file)
+
+    logger.info(""Building archive command"")
+    cmd = build_archive_cmd(output_file, files)
+    logger.debug(""Archive command to be run:"")
+    logger.debug(' '.join(cmd))
+
+    if args.dry_run:
+        logger.info(""Dry-run"")
+        logger.info(""Collected following files:"")
+        _log_capture(files)
+        return
+    else:
+        if os.getuid() is not 0:
+            logger.error(""Must be run as super user (sudo) to capture all files."")
+            raise Exception(""Not Super User"")
+        run_cmd(cmd)
+
+
+def main(args):
+    try:
+        init(args)
+    except:
+        logger.error('Unable to initialize script')
+        raise
+
+    try:
+        files = collect_capture_files(args)
+    except:
+        logger.error('Unable to collect the files for this capture')
+        raise
+
+    try:
+        do_capture(args, files)
+    except:
+        logger.error('Unable to build capture archive')
+        raise
+
+
+# ***************
+# *  UNIT TESTS !!!!! (use -t to run them)
+# ***************
+def test():
+    print(""The 'unittest' module is not available!\nUnable to run tests!"")
+    sys.exit(0)
+
+try:
+    import unittest
+
+    def test():
+        unittest.main(argv=['capture_test'])
+        sys.exit(0)
+
+    def _touch(path, content):
+        d = os.path.dirname(path)
+        os.makedirs(d, exist_ok=True)
+        with open(path, 'w') as f:
+            f.write(content)
+
+    class TestCapture(unittest.TestCase):",469,2018-05-31 11:11:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192055845,https://github.com/hyperledger/indy-node/pull/703#discussion_r192055845,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,Please use utility (config_helper) to access node's dirs,fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 10:54:01,192060499,"@@ -0,0 +1,416 @@
+#!/usr/bin/env python
+#
+# README
+#
+# This script assumes:
+# --------------------
+#
+# 1. `USE_WITH_STACK=1` was set in `/etc/indy/indy_config.py` on the node where
+#     the recording took place.
+# 2. The 'recording' passed as the argument to this script has been captured by
+#    running `nscapture` AFTER stopping the node (indy-node service). There are
+#    plans to research how node state (recording in this case) can be captured
+#    without bringing down the indy-node service.
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, install indy-node and it's dependencies before running this script.
+#
+# TODO:
+# 
+# 1. Create an issue in indy-node stating that the following must be done on
+#    macos for pbc to compile (pbc has a dependency on openssl headers)
+#    > cd /usr/local/include 
+#    > ln -s ../opt/openssl/include/openssl .
+#    The above fix was taken from:
+#    https://www.anintegratedworld.com/mac-osx-fatal-error-opensslsha-h-file-not-found/
+#    Prehaps adding the above two lines between `brew install openssl` and the
+#    ""# PBC"" section of https://github.com/hyperledger/indy-anoncreds/blob/master/setup-charm-homebrew.sh
+#    would be sufficient?
+
+from indy_common.config_helper import NodeConfigHelper
+from indy_common.config_util import getConfig
+from indy_node.server.config_helper import create_config_dirs
+from indy_node.server.node import Node
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from os import listdir, makedirs
+from plenum.common.constants import CLIENT_STACK_SUFFIX, KeyValueStorageType
+from plenum.recorder.src.recorder import Recorder
+from plenum.recorder.src.replayable_node import prepare_directory_for_replay, \
+    create_replayable_node_class
+from plenum.recorder.src.replayer import get_recorders_from_node_data_dir, \
+    prepare_node_for_replay_and_replay
+from plenum.server.replicas import Replicas
+from plenum.server.replica import Replica
+from storage.kv_store_rocksdb_int_keys import KeyValueStorageRocksdbIntKeys
+from storage.helper import initKeyValueStorageIntKeys
+from stp_core.common.log import getlogger, Logger
+from stp_core.loop.looper import Looper
+from stp_core.types import HA
+from typing import Tuple
+
+import argparse
+import importlib
+import json
+import logging
+import os
+import shutil
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+# TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+#       Move to common module?
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+# TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+#       Move to common module?
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateReplayer():
+    logger = None
+    cleanup = True
+    log_level = logging.WARNING
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1_is_temp = False
+    s1_dirname = None
+    s1_filename = None
+    s1_name = None
+    s1_extension = None
+
+    def __init__(self, log_level=0, cleanup=True):
+        logger.setLevel(log_level)
+        self.cleanup = cleanup
+        logger.debug(""Initializing NodeStateReplayer..."")
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with abstract _cleanup function?
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp:
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with _eprint function?
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with print_zipfile function?
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with print_directory function?
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with _extract_tarball function?
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with _extract_zipfile function?
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with _extract_archive function?
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension )
+
+    def unpack_recording(self, s1=None):
+        # Validate inputs
+        validation_errors = []
+
+        # Capture the name of s1
+        self.s1 = s1
+        (self.s1_dirname, self.s1_filename, self.s1_name,
+         self.s1_extension) = self.split_name(s1)
+
+        # s1 must either be a tarball, zipfile, or a directory
+        if ( isfile(s1) ):
+            # If s1 is a file, it must be a tarball or a zipfile
+            # Extract s1 contents into a temporary directory
+            try:
+                tempdir = self._extract_archive(s1)
+            except ArchiveError as e:
+                validation_errors.append(e)
+            else:
+                self.s1tempdir = tempdir
+                self.s1dir = tempdir
+                self.s1_is_temp = True
+        elif ( isdir(s1) ):
+            if self.log_level <= logging.INFO:
+                self.print_directory(s1)
+            self.s1dir = s1
+        else:
+            s = ""{} must be a existing tarfile/zipfile or a directory.""
+            validation_errors.append(s.format(s1))
+
+        # Emit validation errors and exit
+        if validation_errors:
+            for validation_error in validation_errors:
+                self._eprint(validation_error)
+            self._cleanup()
+            exit(1)
+
+        return
+
+    def get_updated_config(self):
+        # Update current config with config file from the recording zip
+        return getConfig()
+
+    def get_recorders_from_node_data_dir(self, node_data_dir, node_name) -> Tuple[Recorder, Recorder]:
+        node_rec_path = join(node_data_dir, node_name, 'recorder')
+        client_stack_name = node_name + CLIENT_STACK_SUFFIX
+        client_rec_path = join(node_data_dir, client_stack_name, 'recorder')
+        # TODO: Change to rocksdb
+        client_rec_kv_store = initKeyValueStorageIntKeys(
+            KeyValueStorageType.Leveldb, client_rec_path, client_stack_name)
+        node_rec_kv_store = initKeyValueStorageIntKeys(
+            KeyValueStorageType.Leveldb,
+            node_rec_path,
+            node_name)
+
+        return Recorder(node_rec_kv_store, skip_metadata_write=True), \
+               Recorder(client_rec_kv_store, skip_metadata_write=True)
+
+    def update_loaded_config(self, config):
+        config.USE_WITH_STACK = 2
+        import stp_zmq.kit_zstack
+        importlib.reload(stp_zmq.kit_zstack)
+        import plenum.common.stacks
+        importlib.reload(plenum.common.stacks)
+        import plenum.server.node
+        importlib.reload(plenum.server.node)
+        import indy_node.server.node
+        importlib.reload(indy_node.server.node)
+
+    def replay_node(self, s1):
+        self.unpack_recording(s1)
+        node_name = self.s1_name
+
+        # Hardcode pool name. We just need an arbitrary pool name to use during
+        # replay.
+        pool_name = 'sandbox'
+
+        replay_node_dir = tempfile.TemporaryDirectory().name
+        logger.debug(""Temporary replay node directory {}"".format(
+            replay_node_dir))
+        # with tempfile.TemporaryDirectory() as replay_node_dir:
+        general_config_dir = create_config_dirs(replay_node_dir)
+        config = getConfig(general_config_dir)
+        self.update_loaded_config(config)
+        pool_dir = join(replay_node_dir, pool_name)
+        orig_node_pool_dir = self.s1dir
+
+        trg_var_dir = join(replay_node_dir, 'var', 'lib', 'indy', pool_name)",296,2018-05-31 11:11:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192060499,https://github.com/hyperledger/indy-node/pull/703#discussion_r192060499,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"We already have documentation on how to work with the code and install it for development:
https://github.com/hyperledger/indy-node/tree/master/dev-setup/ubuntu
https://github.com/hyperledger/indy-node/blob/master/docs/setup-dev.md

Why duplicate it here? It would be better to modify existing docs if there are some issues there.",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 10:57:52,192061290,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.",25,2018-05-31 18:44:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192061290,https://github.com/hyperledger/indy-node/pull/703#discussion_r192061290,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"I think in most of the cases this script will be run on a real installation from deb packages (for example in Docker), not with local nodes.",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 10:58:44,192061491,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:",40,2018-05-31 18:45:29,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192061491,https://github.com/hyperledger/indy-node/pull/703#discussion_r192061491,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"We migrated to Rocks DB now, so Leveldb is not used anymore.",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 11:00:21,192061888,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]",347,2018-05-31 18:47:03,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192061888,https://github.com/hyperledger/indy-node/pull/703#discussion_r192061888,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,Please note that KeyValueStorageRocksdbIntKeys is used for the ledger,fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 11:03:10,192062472,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]
+
+        # Traverse directory sin
+        # TODO: 1. Optimize using multiprocessing module. At minimum, all
+        #       directories can be transformed and scrubbed in parallel.
+        #       https://docs.python.org/3/library/multiprocessing.html
+        #
+        #       2. Files in Non-LevelDB/RocksDB directories can be transformed
+        #          and scrubbed in parallel.
+        for dirName, subdirList, fileList in os.walk(abspath(sin)):
+            if (dirName in self.skipdirs):
+                logger.debug(""Skipping dirName: {}"".format(dirName))
+                break
+
+            if self.log_level <= logging.INFO:
+                logger.info(""dirName: {}"".format(dirName))
+
+            # Skip specific directories
+            subdirList[:] = [x for x in subdirList if x not in self.skipdirs]
+            # Skip specific files
+            fileList[:] = [x for x in fileList if x not in self.skipfiles]
+    
+            # Check if all of the leveldb_rocksdb_filenames are found in
+            # fileList set is_leveldb_rocksdb_dir and break if any of the
+            # filenames are not found
+            is_leveldb_rocksdb_dir = True
+            for filename in leveldb_rocksdb_filenames:
+                if filename not in fileList:
+                    is_leveldb_rocksdb_dir = False
+                    break
+    
+            (dirname, filename, name, extension) = self.split_name(dirName)
+            # Do not include recordings in diff
+            if (filename == ""recorder"" and dirname.endswith(
+                ""/{}"".format(sname))):
+                subdirList[:] = []
+                continue
+
+            if (is_leveldb_rocksdb_dir):
+                logger.debug(""{} is a LevelDB/RocksDB directory!""
+                    .format(dirName))
+
+                # Use ""nodename"" in place of the node's name when a directory
+                # (dirName in this case) matches the node name (sname)
+                if (sname == filename):
+                    filename = ""nodename""
+
+                if (filename.endswith(""_transactions"")):
+                    logger.debug(""{} is a transaction LevelDB/RocksDB instance!""
+                        .format(filename))
+                    # utf-8 - call ""getAllTxn()"" in ledger.py in the ledger
+                    #         module/package in indy-plenum.
+                    # Create a Ledger domain object from the ledger directory 
+                    # 'filename' takes the form {fileNamePrefix}_transactions
+                    # where fileNamePrefix is one of the following:
+                    #    config, pool, domain
+                    # FileHashStore requires a fileNamePrefix.
+                    fileNamePrefix = filename.split(""_"")[0]
+                    ledger = Ledger(
+                        CompactMerkleTree(
+                            # The FileHashStore reads
+                            # {fileNamePrefix}_merkleLeaves and
+                            # {fileNamePrefix}_merkleNodes from dataDir
+                            hashStore=FileHashStore(
+                                dataDir=dirname,
+                                fileNamePrefix=fileNamePrefix
+                            )
+                        ),
+                        dataDir=dirname,
+                        fileName=filename
+                    )
+
+                    out_filename = join(sout, filename)
+                    with open(out_filename, ""a"") as file_handle:
+                        for txn in ledger.getAllTxn():
+                            logger.info(""Writing >txn={}< to {}"".format(
+                                str(txn), out_filename))
+                            file_handle.write(str(txn))
+                    ledger.stop()
+                else:
+                    debug_msg = (""{} is NOT a transaction LevelDB/RocksDB""
+                                 ""instance!"")
+                    logger.debug(debug_msg.format(filename))
+                    # Assume utf-8 decoding by default.
+                    # utf-8 - use standard leveldb/rocksdb iterator() and utf-8
+                    #         decoding.
+                    opened = False
+                    try:
+                        debug_msg = (""Opening {} as a LevelDB instance with""
+                                     "" initKeyValueStorage..."")
+                        logger.debug(debug_msg.format(filename))
+                        leveldb_rocksdb_handle = initKeyValueStorage(",438,2018-05-31 18:47:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192062472,https://github.com/hyperledger/indy-node/pull/703#discussion_r192062472,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,RocksDB-based hash store is actually used by default and in production (see `initHashStore`),fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 11:05:14,192063147,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]
+
+        # Traverse directory sin
+        # TODO: 1. Optimize using multiprocessing module. At minimum, all
+        #       directories can be transformed and scrubbed in parallel.
+        #       https://docs.python.org/3/library/multiprocessing.html
+        #
+        #       2. Files in Non-LevelDB/RocksDB directories can be transformed
+        #          and scrubbed in parallel.
+        for dirName, subdirList, fileList in os.walk(abspath(sin)):
+            if (dirName in self.skipdirs):
+                logger.debug(""Skipping dirName: {}"".format(dirName))
+                break
+
+            if self.log_level <= logging.INFO:
+                logger.info(""dirName: {}"".format(dirName))
+
+            # Skip specific directories
+            subdirList[:] = [x for x in subdirList if x not in self.skipdirs]
+            # Skip specific files
+            fileList[:] = [x for x in fileList if x not in self.skipfiles]
+    
+            # Check if all of the leveldb_rocksdb_filenames are found in
+            # fileList set is_leveldb_rocksdb_dir and break if any of the
+            # filenames are not found
+            is_leveldb_rocksdb_dir = True
+            for filename in leveldb_rocksdb_filenames:
+                if filename not in fileList:
+                    is_leveldb_rocksdb_dir = False
+                    break
+    
+            (dirname, filename, name, extension) = self.split_name(dirName)
+            # Do not include recordings in diff
+            if (filename == ""recorder"" and dirname.endswith(
+                ""/{}"".format(sname))):
+                subdirList[:] = []
+                continue
+
+            if (is_leveldb_rocksdb_dir):
+                logger.debug(""{} is a LevelDB/RocksDB directory!""
+                    .format(dirName))
+
+                # Use ""nodename"" in place of the node's name when a directory
+                # (dirName in this case) matches the node name (sname)
+                if (sname == filename):
+                    filename = ""nodename""
+
+                if (filename.endswith(""_transactions"")):
+                    logger.debug(""{} is a transaction LevelDB/RocksDB instance!""
+                        .format(filename))
+                    # utf-8 - call ""getAllTxn()"" in ledger.py in the ledger
+                    #         module/package in indy-plenum.
+                    # Create a Ledger domain object from the ledger directory 
+                    # 'filename' takes the form {fileNamePrefix}_transactions
+                    # where fileNamePrefix is one of the following:
+                    #    config, pool, domain
+                    # FileHashStore requires a fileNamePrefix.
+                    fileNamePrefix = filename.split(""_"")[0]
+                    ledger = Ledger(
+                        CompactMerkleTree(
+                            # The FileHashStore reads
+                            # {fileNamePrefix}_merkleLeaves and
+                            # {fileNamePrefix}_merkleNodes from dataDir
+                            hashStore=FileHashStore(",410,2018-05-31 18:50:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192063147,https://github.com/hyperledger/indy-node/pull/703#discussion_r192063147,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"1) Please split the method into a number of smaller ones
2) Please avoid too may hierarchical indentation (if-else-if-else-try-if-else....)",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 11:06:55,192063479,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):",307,2018-05-31 18:50:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192063479,https://github.com/hyperledger/indy-node/pull/703#discussion_r192063479,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"For me it looks like the method is overcomplicated. The type of the transaction log, hash store and other storages can be get from config file. Why don't we get it from there instead of trying all variants in try-else style?",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 11:08:25,192063753,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]
+
+        # Traverse directory sin
+        # TODO: 1. Optimize using multiprocessing module. At minimum, all
+        #       directories can be transformed and scrubbed in parallel.
+        #       https://docs.python.org/3/library/multiprocessing.html
+        #
+        #       2. Files in Non-LevelDB/RocksDB directories can be transformed
+        #          and scrubbed in parallel.
+        for dirName, subdirList, fileList in os.walk(abspath(sin)):
+            if (dirName in self.skipdirs):
+                logger.debug(""Skipping dirName: {}"".format(dirName))
+                break
+
+            if self.log_level <= logging.INFO:
+                logger.info(""dirName: {}"".format(dirName))
+
+            # Skip specific directories
+            subdirList[:] = [x for x in subdirList if x not in self.skipdirs]
+            # Skip specific files
+            fileList[:] = [x for x in fileList if x not in self.skipfiles]
+    
+            # Check if all of the leveldb_rocksdb_filenames are found in
+            # fileList set is_leveldb_rocksdb_dir and break if any of the
+            # filenames are not found
+            is_leveldb_rocksdb_dir = True
+            for filename in leveldb_rocksdb_filenames:
+                if filename not in fileList:
+                    is_leveldb_rocksdb_dir = False
+                    break
+    
+            (dirname, filename, name, extension) = self.split_name(dirName)
+            # Do not include recordings in diff
+            if (filename == ""recorder"" and dirname.endswith(
+                ""/{}"".format(sname))):
+                subdirList[:] = []
+                continue
+
+            if (is_leveldb_rocksdb_dir):
+                logger.debug(""{} is a LevelDB/RocksDB directory!""
+                    .format(dirName))
+
+                # Use ""nodename"" in place of the node's name when a directory
+                # (dirName in this case) matches the node name (sname)
+                if (sname == filename):
+                    filename = ""nodename""
+
+                if (filename.endswith(""_transactions"")):",394,2018-05-31 18:49:56,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192063753,https://github.com/hyperledger/indy-node/pull/703#discussion_r192063753,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"Please specify what exactly is compared:
- txn log (for all ledgers)
- hash store (for all ledgers)
- all states
- state_signature (BLS) 
- attr_store
- seq_no_db
- ts_store
????",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 11:10:27,192064110,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file",8,2018-05-31 18:51:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192064110,https://github.com/hyperledger/indy-node/pull/703#discussion_r192064110,ashcherbakov
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,It was moved. I thought I had closed this PR. See #737,fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 15:15:03,192135408,"@@ -0,0 +1,142 @@
+import importlib
+import json
+import os
+import shutil
+import tempfile
+
+from indy_common.config_helper import NodeConfigHelper
+from indy_node.server.config_helper import create_config_dirs
+from plenum.recorder.src.replayer import get_recorders_from_node_data_dir, \
+    prepare_node_for_replay_and_replay
+from stp_core.common.log import getlogger, Logger
+
+from stp_core.types import HA
+
+from stp_core.loop.looper import Looper
+
+from indy_node.server.node import Node
+
+from plenum.server.replicas import Replicas
+
+from plenum.server.replica import Replica
+
+from indy_common.config_util import getConfig
+from plenum.recorder.src.replayable_node import create_replayable_node_class
+
+RecordingZipFilePath = '/home/lovesh/rec.zip'
+
+ReplayBaseDirPath = '/home/lovesh/tmp'
+
+
+def process_recording_zip():
+    # Unzip the recording file
+    return
+
+
+def get_updated_config():
+    # Update current config with config file from the recording zip
+    return getConfig()
+
+
+def setup_logging():
+    pass
+
+
+def update_loaded_config(config):
+    config.USE_WITH_STACK = 2
+    import stp_zmq.kit_zstack
+    importlib.reload(stp_zmq.kit_zstack)
+    import plenum.common.stacks
+    importlib.reload(plenum.common.stacks)
+    import plenum.server.node
+    importlib.reload(plenum.server.node)
+    import indy_node.server.node
+    importlib.reload(indy_node.server.node)
+
+
+def replay_node():",57,2018-05-31 15:15:03,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192135408,https://github.com/hyperledger/indy-node/pull/703#discussion_r192135408,devin-fisher
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"nscapture was written as a stand-alone script. It is not a python module. It is outside the view of pytest. I choose unittest so there was no dependency to run the test. Also, unittest was easier to run via a command line option (-t). I'm welcome to discuss how to do this better but simply putting them in a directory and using pytest would not accomplish my portable stand-alone CLI script requirement requirements.

The tests are exercised in the CI system in indy_node/test/tools/test_nsrepay.py",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 15:22:15,192137942,"@@ -0,0 +1,670 @@
+#!/usr/bin/env python3
+
+import sys
+import os
+import argparse
+import logging
+import datetime
+import time
+from collections import namedtuple
+import tempfile
+import subprocess
+import atexit
+import shutil
+
+from io import StringIO
+
+from plenum.server.general_config import ubuntu_platform_config
+
+logger = logging.getLogger()
+
+ArchiveEntry = namedtuple('archive_entry', ['abs_fs_path', 'archive_path', 'include'])
+
+ENV_COLLECTION_CMD = [
+    (""python_version"", ['python3', '-V']),
+    (""pip_freeze"", ['pip3', 'freeze']),
+    (""app_install"", ['apt', 'list', '--installed']),
+    (""validator_info"", ['validator-info', '-v']),
+]
+
+
+# ***************
+# *  Command-line Argument Parsing
+# ***************
+def str2bool(v):
+    if v.lower() in ('yes', 'true', 't', 'y', '1'):
+        return True
+    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
+        return False
+    else:
+        raise argparse.ArgumentTypeError(
+            'Boolean value (yes, no, true, false, y, n, 1, or 0) expected.')
+
+LOG_LEVEL_HELP = """"""Logging level.
+                      [LOG-LEVEL]: notset, debug, info, warning, error, critical
+                      Default: warning""""""
+levels = {
+   'notset': logging.NOTSET,
+   'debug': logging.DEBUG,
+   'info': logging.INFO,
+   'warning': logging.WARNING,
+   'error': logging.ERROR,
+   'critical': logging.CRITICAL
+}
+
+
+def log_level(v):
+    if v.lower() in levels.keys():
+        return levels[v.lower()]
+    else:
+        raise argparse.ArgumentTypeError(
+            'Expected one of the following: {}.'.format(
+                ', '.join(levels.keys())))
+
+
+def program_args():
+    parser = argparse.ArgumentParser()
+
+    parser.add_argument('-t', '--test', action='store_true',
+                        default=False, help='Runs unit tests and exits.')
+
+    parser.add_argument('-l', '--log-level', type=log_level, nargs='?',
+                        const=logging.INFO, default=logging.INFO, help=LOG_LEVEL_HELP)
+
+    parser.add_argument('-o', '--output-dir', default=os.getcwd(),
+                        help='the directory where the captured file will be writen to. Default: CWD')
+    parser.add_argument('-n', '--node-name',
+                        help='The name of the node to be captured, required if the script finds more than one node.')
+    parser.add_argument('-r', '--root-dir', default='/',
+                        help='The root to look for node artifacts. Default: /')
+
+    parser.add_argument('-x', '--exclude-recording', action='store_true',
+                        help='Will exclude recording data from capture.')
+    parser.add_argument('-d', '--dry-run', action='store_true',
+                        default=False, help='Will not create archive file but will collect files to be collected')
+
+    return parser
+
+
+def parse_args(argv=None, parser=program_args()):
+    return parser.parse_args(args=argv)
+
+
+def get_system_dirs():
+    # TODO detect the system someday (help support windows)
+    return ubuntu_platform_config
+
+
+# ***************
+# *  Capture File Collection
+# ***************
+def _log_capture(collection):
+    for entry in collection:
+        logger.info(""%s found at %s"" % (entry.archive_path, entry.abs_fs_path))
+        for file in entry.include:
+            logger.info(""    %s"" % file)
+
+
+def _collect_files(dir_type, directory, archive_path, filter_fn, recursive=True):
+    rtn = ArchiveEntry(directory, archive_path, [])
+
+    try:
+        for root, dirs, files in os.walk(directory):
+            rel_path = os.path.relpath(root, directory)
+            files = [os.path.join(rel_path, f) for f in files]
+            files = filter(filter_fn, files)
+            rtn.include.extend(files)
+            if recursive is not True:
+                break
+    except FileNotFoundError:
+        logger.warning(""Unable to find a %s directory for pool! Looked for '%s'"", dir_type, directory)
+
+    return rtn
+
+
+def _run_env_capture_cmd(output_file, cmd, entry):
+    try:
+        with open(output_file, 'w') as f:
+            subprocess.run(cmd,
+                           check=True,
+                           stderr=subprocess.STDOUT,
+                           stdout=f
+                           )
+    except (subprocess.CalledProcessError, FileNotFoundError) as e:
+        logger.warning(""Unable to capture env data: cmd '%s' - error: %s"", ' '.join(cmd), str(e))
+    finally:
+        if os.path.exists(output_file) and os.path.getsize(output_file) > 0:
+            entry.include.append(output_file)
+
+
+def collect_env(args):
+    logger.info(""Collecting Env Files"")
+    d = tempfile.mkdtemp()
+    TEMP_DIRS.append(d)
+    rtn = ArchiveEntry(d, '/capture', [])
+    for filename, cmd in ENV_COLLECTION_CMD:
+        _run_env_capture_cmd(os.path.join(d, filename),
+                             cmd,
+                             rtn)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_logs(args):
+    log_dir = indy_log_dir(args)
+    log_dir = os.path.join(log_dir, args.pool_name)
+
+    def log_filter(f):
+        return f.startswith(os.path.join('.', args.node_name))
+
+    logger.info(""Collecting Log Files"")
+    rtn = _collect_files('logger.info(""Collected %s files to captured"", str(len(rtn.include)))log',
+                         log_dir,
+                         '/log',
+                         log_filter,
+                         recursive=False)
+
+    return rtn
+
+
+def collect_config(args):
+    d = indy_config_dir(args)
+
+    def file_filter(_f):
+        return True
+
+    logger.info(""Collecting Config Files"")
+    rtn = _collect_files('config', d, '/config', file_filter, recursive=False)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_data(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, args.pool_name)
+
+    def file_filter(f):
+        if f.startswith('data/'):
+            if f.startswith(os.path.join('data/', args.node_name+'/')) \
+               or f.startswith(os.path.join('data/', args.node_name+'C/')):
+
+                if 'recorder' in f:
+                    return not args.exclude_recording
+                return True
+            else:
+                return False
+
+        return True
+
+    logger.info(""Collecting Data Files"")
+    rtn = _collect_files('application data', d, '/', file_filter, recursive=True)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_plugins(args):
+    d = indy_app_dir(args)
+    d = os.path.join(d, 'plugins')
+
+    def file_filter(f):
+        return True
+
+    logger.info(""Collecting Plugins Files"")
+    rtn = _collect_files('plugin data', d, '/plugins', file_filter, recursive=True)
+    logger.info(""Collected %s files to captured"", str(len(rtn.include)))
+    return rtn
+
+
+def collect_capture_files(args):
+    rtn = []
+    logger.info(""Collecting file to be captured"")
+    rtn.append(collect_env(args))
+    rtn.append(collect_logs(args))
+    rtn.append(collect_config(args))
+    rtn.append(collect_data(args))
+    rtn.append(collect_plugins(args))
+    logger.info(""Collection complete"")
+    return rtn
+
+
+# ***************
+# *  Indy Directories
+# ***************
+def _find_dir(args, dir_location, name):
+    dir_location = dir_location.lstrip(""/"")
+    rtn = os.path.join(args.root_dir, dir_location)
+    logger.debug(""using %s dir: %s"", name, rtn)
+    return rtn
+
+
+def indy_app_dir(args):
+    return _find_dir(args, get_system_dirs().NODE_INFO_DIR, ""application dir"")
+
+
+def indy_log_dir(args):
+    return _find_dir(args, get_system_dirs().LOG_DIR, ""logging dir"")
+
+
+def indy_config_dir(args):
+    return _find_dir(args, '/etc/indy', ""config dir"")
+
+
+# ***************
+# *  Capture File Output File Name
+# ***************
+def capture_file_name(args):
+
+    if (not hasattr(args, 'node_name') or not hasattr(args, 'pool_name')) or \
+       (args.node_name is None or args.pool_name is None):
+        logger.error(""node_name or pool_name has not been specified, can not create capture file name. Object: %s"",
+                     str(args))
+        raise Exception(""Can not create capture file name!"")
+
+    rtn = ""%s.%s.%s"" % (args.node_name, args.pool_name, datetime.datetime.now().strftime(""%Y%m%d%H%M%S""))
+    return rtn
+
+
+# ***************
+# *  Node Discovery
+# ***************
+def find_node_name(args):
+    nodes = []
+
+    def find_nodes_in_pool_dir(pool_name):
+        data_dir = os.path.join(indy_app_dir(args), pool_name, ""data"")
+
+        try:
+            possible_nodes = sorted(os.listdir(data_dir))
+        except FileNotFoundError:
+            logger.warning(""Did not find a data directory for pool '%s'! (Likely not an issue) Looked for '%s'"",
+                           pool_name, data_dir)
+            return []
+
+        possible_nodes = list(filter(is_dir_check(data_dir), possible_nodes))
+        logger.debug(""possible node names in %s: %s"", pool_name, possible_nodes)
+        node_names = set()
+        while len(possible_nodes) is not 0:
+            try:
+                a_name = possible_nodes.pop(0)
+                possible_nodes.remove(a_name + 'C')
+                node_names.add((a_name, pool_name))
+            except ValueError:
+                logger.warning(""Possible Node don't have client dir"")
+
+        return node_names
+
+    def is_dir_check(base_dir):
+        def is_dir(d):
+            return os.path.isdir(os.path.join(base_dir, d))
+        return is_dir
+
+    app_dir = indy_app_dir(args)
+    try:
+        pool_dirs = list(filter(is_dir_check(indy_app_dir(args)), os.listdir(app_dir)))
+    except FileNotFoundError:
+        logger.error(""Unable to find indy application directory! Looked for '%s'"", app_dir)
+        raise
+
+    for pool in pool_dirs:
+        # ignore plugins dir - it is not a pool directory
+        if ""plugins"" == pool:
+            continue
+
+        nodes.extend(find_nodes_in_pool_dir(pool))
+
+    if args.node_name is None:
+        if len(nodes) == 1:
+            node_name, pool = nodes.pop()
+            args.node_name = node_name
+            args.pool_name = pool
+        elif len(nodes) == 0:
+            logger.error(""No nodes where found. Check root dir?"", nodes)
+            sys.exit(-1)
+        else:
+            logger.error(""Found more than one node and a node name was not specified! Found -- %s"", nodes)
+            sys.exit(-1)
+    else:
+        for node in nodes:
+            if args.node_name == node[0]:
+                args.pool_name = node[1]
+                break
+        else:
+            logger.error(""Node with name '%s' was not found, can not continue! Found -- %s"", args.node_name, nodes)
+            sys.exit(-1)
+
+    logger.info(""Capturing Node '%s' for pool '%s'"", args.node_name, args.pool_name)
+
+
+TEMP_DIRS = []
+
+
+# Clean up anything that is created by this script (excluding the output file)
+def clean_up():
+    while TEMP_DIRS:
+        shutil.rmtree(TEMP_DIRS.pop())
+
+    # raise Exception(""TEST"")
+
+
+# ***************
+# *  Init Details
+# ***************
+def init(args):
+    # print warning
+    print(""!"" * 20 + "" WARNING "" + '!' * 21)
+    print(""!"" * 2 + ""  "" + ""This tool captures node state replay and diagnostic purposes (for development and QA)"")
+    print(""!"" * 2 + ""  "" + ""By the nature of these needs, that includes sensitive data (including secret keys)"")
+    print(""!"" * 2 + ""  "" + ""DO NOT USE THIS TOOL on nodes that need to be secure"")
+    print(""!"" * 50)
+    time.sleep(1)
+
+    logger.setLevel(args.log_level)
+    logger.debug(""args: %s"", args)
+    find_node_name(args)
+
+    atexit.register(clean_up)
+
+
+def build_archive_cmd(output_file, files):
+    cmd = ['tar']
+    flags = 'cfz'
+    if logger.level == logging.DEBUG:
+        flags += 'v'
+    cmd.append(flags)
+    cmd.append(output_file)
+    cmd.append('--show-transformed-names')
+    cmd.extend([""-C"", ""/""])
+
+    for entry in files:
+        fs_path_pattern = entry.abs_fs_path + '/'
+        fs_path_pattern = fs_path_pattern.lstrip('/')
+        archive_path_pattern = entry.archive_path + '/'
+        archive_path_pattern = archive_path_pattern.lstrip('/')
+        cmd.append('--xform')
+        cmd.append(""s|%s|%s|1"" % (fs_path_pattern, archive_path_pattern))
+        for file in entry.include:
+            f_path = os.path.join(entry.abs_fs_path, file)
+            f_path = os.path.abspath(f_path)
+            f_path = f_path.lstrip('/')
+            cmd.append(f_path)
+
+    return cmd
+
+
+# ***************
+# *  Running the archive command
+# ***************
+def run_cmd(cmd):
+    logger.info(""Running archive command"")
+    try:
+        subprocess.run(cmd, check=True)
+        # os.system(' '.join(cmd))
+    except Exception as e:
+        logger.error(""Unable to complete archive command: %s"", str(e))
+    else:
+        logger.info(""Archive command complete"")
+
+
+def do_capture(args, files):
+    output_file = os.path.join(args.output_dir, capture_file_name(args) + '.tar.gz')
+    logger.info(""Writing archive to '%s'"" % output_file)
+
+    logger.info(""Building archive command"")
+    cmd = build_archive_cmd(output_file, files)
+    logger.debug(""Archive command to be run:"")
+    logger.debug(' '.join(cmd))
+
+    if args.dry_run:
+        logger.info(""Dry-run"")
+        logger.info(""Collected following files:"")
+        _log_capture(files)
+        return
+    else:
+        if os.getuid() is not 0:
+            logger.error(""Must be run as super user (sudo) to capture all files."")
+            raise Exception(""Not Super User"")
+        run_cmd(cmd)
+
+
+def main(args):
+    try:
+        init(args)
+    except:
+        logger.error('Unable to initialize script')
+        raise
+
+    try:
+        files = collect_capture_files(args)
+    except:
+        logger.error('Unable to collect the files for this capture')
+        raise
+
+    try:
+        do_capture(args, files)
+    except:
+        logger.error('Unable to build capture archive')
+        raise
+
+
+# ***************
+# *  UNIT TESTS !!!!! (use -t to run them)
+# ***************
+def test():
+    print(""The 'unittest' module is not available!\nUnable to run tests!"")
+    sys.exit(0)
+
+try:
+    import unittest
+
+    def test():
+        unittest.main(argv=['capture_test'])
+        sys.exit(0)
+
+    def _touch(path, content):
+        d = os.path.dirname(path)
+        os.makedirs(d, exist_ok=True)
+        with open(path, 'w') as f:
+            f.write(content)
+
+    class TestCapture(unittest.TestCase):",469,2018-05-31 15:22:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192137942,https://github.com/hyperledger/indy-node/pull/703#discussion_r192137942,devin-fisher
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,@ckochenower Yeah let definitely use it. I'm using it in nscapture. ,fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 15:27:01,192139582,"@@ -0,0 +1,416 @@
+#!/usr/bin/env python
+#
+# README
+#
+# This script assumes:
+# --------------------
+#
+# 1. `USE_WITH_STACK=1` was set in `/etc/indy/indy_config.py` on the node where
+#     the recording took place.
+# 2. The 'recording' passed as the argument to this script has been captured by
+#    running `nscapture` AFTER stopping the node (indy-node service). There are
+#    plans to research how node state (recording in this case) can be captured
+#    without bringing down the indy-node service.
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, install indy-node and it's dependencies before running this script.
+#
+# TODO:
+# 
+# 1. Create an issue in indy-node stating that the following must be done on
+#    macos for pbc to compile (pbc has a dependency on openssl headers)
+#    > cd /usr/local/include 
+#    > ln -s ../opt/openssl/include/openssl .
+#    The above fix was taken from:
+#    https://www.anintegratedworld.com/mac-osx-fatal-error-opensslsha-h-file-not-found/
+#    Prehaps adding the above two lines between `brew install openssl` and the
+#    ""# PBC"" section of https://github.com/hyperledger/indy-anoncreds/blob/master/setup-charm-homebrew.sh
+#    would be sufficient?
+
+from indy_common.config_helper import NodeConfigHelper
+from indy_common.config_util import getConfig
+from indy_node.server.config_helper import create_config_dirs
+from indy_node.server.node import Node
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from os import listdir, makedirs
+from plenum.common.constants import CLIENT_STACK_SUFFIX, KeyValueStorageType
+from plenum.recorder.src.recorder import Recorder
+from plenum.recorder.src.replayable_node import prepare_directory_for_replay, \
+    create_replayable_node_class
+from plenum.recorder.src.replayer import get_recorders_from_node_data_dir, \
+    prepare_node_for_replay_and_replay
+from plenum.server.replicas import Replicas
+from plenum.server.replica import Replica
+from storage.kv_store_rocksdb_int_keys import KeyValueStorageRocksdbIntKeys
+from storage.helper import initKeyValueStorageIntKeys
+from stp_core.common.log import getlogger, Logger
+from stp_core.loop.looper import Looper
+from stp_core.types import HA
+from typing import Tuple
+
+import argparse
+import importlib
+import json
+import logging
+import os
+import shutil
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+# TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+#       Move to common module?
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+# TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+#       Move to common module?
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateReplayer():
+    logger = None
+    cleanup = True
+    log_level = logging.WARNING
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1_is_temp = False
+    s1_dirname = None
+    s1_filename = None
+    s1_name = None
+    s1_extension = None
+
+    def __init__(self, log_level=0, cleanup=True):
+        logger.setLevel(log_level)
+        self.cleanup = cleanup
+        logger.debug(""Initializing NodeStateReplayer..."")
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with abstract _cleanup function?
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp:
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with _eprint function?
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with print_zipfile function?
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with print_directory function?
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with _extract_tarball function?
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with _extract_zipfile function?
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # TODO: Promote code reuse between nscapture, nsreplay, and nsdiff.
+    #       Create base class with _extract_archive function?
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension )
+
+    def unpack_recording(self, s1=None):
+        # Validate inputs
+        validation_errors = []
+
+        # Capture the name of s1
+        self.s1 = s1
+        (self.s1_dirname, self.s1_filename, self.s1_name,
+         self.s1_extension) = self.split_name(s1)
+
+        # s1 must either be a tarball, zipfile, or a directory
+        if ( isfile(s1) ):
+            # If s1 is a file, it must be a tarball or a zipfile
+            # Extract s1 contents into a temporary directory
+            try:
+                tempdir = self._extract_archive(s1)
+            except ArchiveError as e:
+                validation_errors.append(e)
+            else:
+                self.s1tempdir = tempdir
+                self.s1dir = tempdir
+                self.s1_is_temp = True
+        elif ( isdir(s1) ):
+            if self.log_level <= logging.INFO:
+                self.print_directory(s1)
+            self.s1dir = s1
+        else:
+            s = ""{} must be a existing tarfile/zipfile or a directory.""
+            validation_errors.append(s.format(s1))
+
+        # Emit validation errors and exit
+        if validation_errors:
+            for validation_error in validation_errors:
+                self._eprint(validation_error)
+            self._cleanup()
+            exit(1)
+
+        return
+
+    def get_updated_config(self):
+        # Update current config with config file from the recording zip
+        return getConfig()
+
+    def get_recorders_from_node_data_dir(self, node_data_dir, node_name) -> Tuple[Recorder, Recorder]:
+        node_rec_path = join(node_data_dir, node_name, 'recorder')
+        client_stack_name = node_name + CLIENT_STACK_SUFFIX
+        client_rec_path = join(node_data_dir, client_stack_name, 'recorder')
+        # TODO: Change to rocksdb
+        client_rec_kv_store = initKeyValueStorageIntKeys(
+            KeyValueStorageType.Leveldb, client_rec_path, client_stack_name)
+        node_rec_kv_store = initKeyValueStorageIntKeys(
+            KeyValueStorageType.Leveldb,
+            node_rec_path,
+            node_name)
+
+        return Recorder(node_rec_kv_store, skip_metadata_write=True), \
+               Recorder(client_rec_kv_store, skip_metadata_write=True)
+
+    def update_loaded_config(self, config):
+        config.USE_WITH_STACK = 2
+        import stp_zmq.kit_zstack
+        importlib.reload(stp_zmq.kit_zstack)
+        import plenum.common.stacks
+        importlib.reload(plenum.common.stacks)
+        import plenum.server.node
+        importlib.reload(plenum.server.node)
+        import indy_node.server.node
+        importlib.reload(indy_node.server.node)
+
+    def replay_node(self, s1):
+        self.unpack_recording(s1)
+        node_name = self.s1_name
+
+        # Hardcode pool name. We just need an arbitrary pool name to use during
+        # replay.
+        pool_name = 'sandbox'
+
+        replay_node_dir = tempfile.TemporaryDirectory().name
+        logger.debug(""Temporary replay node directory {}"".format(
+            replay_node_dir))
+        # with tempfile.TemporaryDirectory() as replay_node_dir:
+        general_config_dir = create_config_dirs(replay_node_dir)
+        config = getConfig(general_config_dir)
+        self.update_loaded_config(config)
+        pool_dir = join(replay_node_dir, pool_name)
+        orig_node_pool_dir = self.s1dir
+
+        trg_var_dir = join(replay_node_dir, 'var', 'lib', 'indy', pool_name)",296,2018-05-31 15:27:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192139582,https://github.com/hyperledger/indy-node/pull/703#discussion_r192139582,devin-fisher
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"These tools are not intended as solely as development tools. They are stand-alone tools. Their requirement should be equal or less than to running the node. 

So they may be duplication since they would be installed with the node.",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 15:30:15,192140636,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.",25,2018-05-31 18:44:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192140636,https://github.com/hyperledger/indy-node/pull/703#discussion_r192140636,devin-fisher
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"The script was written during the transition. Do you think it worth ripping Leveldb? Have we ripped out LevelDB in the node code? Is it no longer possible to run the node with LevelDB? If so, we should rip it out. @ckochenower ",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 15:32:42,192141492,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]",347,2018-05-31 18:47:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192141492,https://github.com/hyperledger/indy-node/pull/703#discussion_r192141492,devin-fisher
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,"We can put some TODO comment to do this. But I don't think we should hold up the PR till this is done.
Alex, I agree with the suggestions but are you ok if we put it on our TODO list?",fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 15:34:29,192142082,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):",307,2018-05-31 18:50:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192142082,https://github.com/hyperledger/indy-node/pull/703#discussion_r192142082,devin-fisher
https://github.com/hyperledger/indy-node/pull/703,https://github.com/hyperledger/indy-node/pull/703,Initial we were not capturing the configuration. (not part of nsdiff original scope) So that is why we had a try-fail cycle. I think the try-fail gives us better resiliency at not much cost in the complexity of the code. But we can add TODOs to simplify this. But I don't think that this should hold this back. ,fd465fbb34db3dc7052008677329647d16a95e5f,2018-05-31 17:07:54,192170720,"@@ -0,0 +1,875 @@
+#!/usr/bin/env python
+
+# README:
+#
+# This script assumes:
+# --------------------
+#
+# 1. The entirety of a node's state is bundled as a zip or tar file
+# 2. The zip/tar file has the name <node_name>.zip or <node_name>.tar.gz where
+#    <node_name> is the name of the node.
+# 3. Both zip/tar files to be compared are on the filesystem where nsdiff is
+#    installed. In other words, nsdiff does not attempt to connect or collect
+#    state data from remote nodes.
+# 4. nscapture is/was used to capture state passed as state1 and state2
+#
+# Installation:
+# -------------
+#
+# If this script is used on a server or workstation that has indy-node installed
+# and indy-node is known to be working, you do not need to install anything.
+# Otherwise, the following information will be helpful.
+#
+# This script depends on leveldb/rocksdb python bindings which in turn rely on
+# the leveldb C runtime libs and headers. You must install leveldb/rocksdb
+# dependencies. See Installation > Prerequisites section below.
+#
+# Until further notice, assume Python 3.5.2 is required and all references to
+# python3 or pip3 imply Python 3.5.2.
+# 
+# Note that anytime pip/pip3 is used to install python packages, the
+# python/python3 environment is changed without the knowledge of package
+# managers (apt, yum, brew, etc.). Side-effects of pip installations and
+# os-controlled updates (i.e. automatic updates) to your system's python have
+# the potential to cause instability/breakage of either your system or
+# development environment. Most modern operating systems depend on Python. If
+# you would prefer not to make changes to your system python/python3, please
+# consider setting up a Python Virtual Environment (highly recommended):
+#   https://docs.python.org/3/tutorial/venv.html
+#
+# Setting up a Python Virtualenv should be as easy as:
+# 1. Create a python virtual environment
+#    `python3.5 -m venv nsdiff-venv`
+# 2. Activate the virtual environment. This modifies a shell's environment.
+#    Therefore, must be run in each shell.
+#    `source nsdiff-venv/bin/activate`
+# 3. When the time comes to deactivate the environment
+#    `deactivate`
+#
+# Prerequisites: Python 3.5.x - pre-3.5.x and post-3.5.x (i.e. 3.6.x) won't
+#                work. 3.5.2 is recommended until further notice.
+#
+#     1. Install core dependencies. rocksdb is only required, because we will be
+#        pip installing indy-plenum and indy-plenum depends on both leveldb and
+#        rocksdb
+#            MacOS:
+#            `brew install leveldb rocksdb`
+#            Ubuntu:
+#            `sudo apt-get install libleveldb1v5 librocksdb4.1 libleveldb-dev librocksdb-dev`
+#
+#     2. Clone indy-plenum
+#            `git clone git@github.com:hyperledger/indy-plenum.git -b <branch>`
+#
+#   -- All of the following steps can be done in a Python Virtual Environment --
+#
+#     3. Install indy-plenum module within the python virtual environment:
+#        It is recommended that you do an ""editable"" install. Doing so allows
+#        changes/updates to be made to a clone (VCS) of the codebase without the
+#        need to reinstall after changes/updates:
+#        https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
+#
+#        indy-plenum may require a few packages/modules be installed via pip.
+#        The following were required for a python 3.5.2 installation:
+#
+#        `pip install pytest-runner python-rocksdb Cython rlp==0.6.0`
+#        TODO: Why does the setup.py in indy-plenum not correctly install
+#              pytest-runner, python-rocksdb, Cython, and rlp? At first glance,
+#              in indy-plenum/setup.py, the 'install-requires' section appears
+#              to contain python-rocksdb, and the 'setup-requires' section
+#              appears to contain pytest-runner. Cython is not explicitly
+#              declared anywhere in indy-plenum/setup.py. rlp does not designate
+#              a specific version and therefore defaults to the latest released
+#              version (currently >= 1.0.1). rlp version 0.6.0 is the latest
+#              version that appears to work with indy-plenum.
+#
+#        `pip install -e ${PWD}/indy-plenum`
+
+from __future__ import print_function
+from enum import Enum
+from ledger.compact_merkle_tree import CompactMerkleTree
+from ledger.hash_stores.file_hash_store import FileHashStore
+from ledger.ledger import Ledger
+from leveldb import LevelDBError
+from os import listdir, mkdir
+from os.path import abspath, basename, dirname, isfile, isdir, join, splitext
+from plenum.common.constants import KeyValueStorageType
+from shutil import copyfile
+from storage.helper import initKeyValueStorage, initKeyValueStorageIntKeys
+from state.pruning_state import PruningState
+
+import argparse
+import json
+import logging
+import os
+import shutil
+import subprocess
+import sys
+import tarfile
+import tempfile
+import zipfile
+
+logger = logging.getLogger()
+
+class Error(Exception):
+    """"""Base class for exceptions in this module.""""""
+    pass
+
+class ArchiveError(Error):
+    """"""Exception raised for errors encounterd while identifying and extracting
+    tarfiles and zipfiles.
+
+    Attributes:
+        message -- explanation of the error
+    """"""
+    def __init__(self, message):
+        self.message = message
+
+class NodeStateComparator():
+    logger = None
+    log_level = logging.WARNING
+    cleanup = True
+    datadir = ""./data/""
+
+    s1 = ""zipfile/tarfile""
+    s1tempdir = None
+    s1dir = None
+    s1_is_temp = False
+    s1_transformed_and_scrubbed = None
+
+    s2 = ""zipfile/tarfile""
+    s2tempdir = None
+    s2dir = None
+    s2_is_temp = False
+    s2_transformed_and_scrubbed = None
+    
+    # TODO: Do we want to skip additional content by default?
+    skipfiles = ['start_times']
+    skipdirs = ['combined_recorder']
+
+    def __init__(self, log_level=0, cleanup=True, datadir=""./data/"", skipfiles=[],
+        skipdirs=[]):
+        logger.setLevel(log_level)
+        logger.debug(""Initializing NodeStateComparator..."")
+        self.cleanup = cleanup
+        self.datadir = datadir
+        if (skipfiles):
+            self.skipfiles.extend(skipfiles)
+        if (skipdirs):
+            self.skipdirs.extend(skipdirs)
+
+
+    def _cleanup(self):
+        logger.debug(""Cleaning up..."")
+        # Clean-up temp dirs if tar/zip unpacked using a temp dir
+        if self.s1_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s1tempdir, self.s1))
+                shutil.rmtree(self.s1tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s1dir))
+        if self.s2_is_temp: 
+            if self.cleanup:
+                logger.info(""Removing temp dir {} containing {} contents""
+                    .format(self.s2tempdir, self.s2))
+                shutil.rmtree(self.s2tempdir)
+            else:
+                logger.debug(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+                print(""Skipping removal of temp directory {}"".format(
+                    self.s2dir))
+        # Clean-up temp dirs used to store transformed and scrubbed state data
+        if self.cleanup:
+            if self.s1_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s1_transformed_and_scrubbed,
+                        self.s1dir))
+                shutil.rmtree(self.s1_transformed_and_scrubbed)
+            if self.s2_transformed_and_scrubbed:
+                s = (""Removing temp dir {} containing transformed and""
+                     ""scrubbed contents from {}"")
+                logger.info(s.format(self.s2_transformed_and_scrubbed,
+                        self.s2dir))
+                shutil.rmtree(self.s2_transformed_and_scrubbed)
+        else:
+            skip_message = (""Skipping removal of transform and scrub temp""
+                            "" directory {}"")
+            logger.debug(skip_message.format(self.s1_transformed_and_scrubbed))
+            logger.debug(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(skip_message.format(self.s1_transformed_and_scrubbed))
+            print(skip_message.format(self.s2_transformed_and_scrubbed))
+            print(""It is up to you to remove the above temporary directories."")
+    
+    # Print an error message to stderr and conditionally exit
+    def _eprint(self, *args, **kwargs):
+        doexit = kwargs.pop('exit', None)
+        print(*args, file=sys.stderr, **kwargs)
+        if doexit:
+            self._cleanup()
+            exit(1)
+    
+    # Print the contents of a tarfile root directory. Does not traverse
+    # directories.
+    def print_tarfile(self, filename):
+        with tarfile.open(filename, ""r"") as tar:
+            for info in tar:
+                if info.isdir():
+                    file_type = 'directory'
+                elif info.isfile():
+                    file_type = 'file'
+                else:
+                    file_type = 'unknown'
+                logger.debug(""{} is a {}"".format(info.name, file_type))
+    
+    # Print the contents of a zipfile root directory. Does not traverse
+    # directories.
+    def print_zipfile(self, filename):
+        f = zipfile.ZipFile(filename)
+        for info in f.infolist():
+            logger.debug(info.filename)
+    
+    # Print the contents of a directory
+    def print_directory(self, dir):
+        onlyfiles = [f for f in listdir(dir) if isfile(join(dir, f))]
+        onlydirs = [f for f in listdir(dir) if isdir(join(dir, f))]
+        logger.debug(""In {}:"".format(dir))
+        for file in onlyfiles:
+            logger.debug(""\t{}"".format(file))
+        for dirent in onlydirs:
+            self.print_directory(join(dir, dirent))
+
+    # Extract a tarball
+    def _extract_tarball(self, file):
+        tempdir = None
+        logger.debug(""Extracting tarball {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_tarfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with tarfile.open(file, ""r"") as tar:
+                tar.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+
+    # Extract a zipfile
+    def _extract_zipfile(self, file):
+        tempdir = None
+        logger.debug(""Extracting zipfile {}"".format(file))
+        if self.log_level <= logging.INFO:
+            self.print_zipfile(file)
+        tempdir = tempfile.mkdtemp()
+        if ( tempdir ):
+            with zipfile.ZipFile(file, 'r') as zip:
+                zip.extractall(tempdir)
+        else:
+            s = ""Failed to create tempdir in which to unpack {}""
+            raise ArchiveError(s.format(file))
+        return tempdir
+    
+    # Extract a tarball/zipfile into a temprary directory
+    def _extract_archive(self, file):
+        logger.debug(""Extracting archive {}"".format(file))
+        # Is the file a tarfile (tar, gz2, zip, tar.gz, etc.) or zipfile?
+        if tarfile.is_tarfile(file):
+            return self._extract_tarball(file)
+        elif zipfile.is_zipfile(file):
+            return self._extract_zipfile(file)
+        else:
+            raise ArchiveError(""{} must be a tarfile or a zipfile"".format(file))
+    
+    def split_name(self, file):
+        abs_file = abspath(file)
+        baseName = basename(abs_file)
+        baseNameElements = baseName.split('.')
+        fileName = None
+        fileExtension = None
+        if len(baseNameElements) > 0:
+            fileName = baseNameElements[0]
+        if len(baseNameElements) > 1:
+            fileExtension = ""."".join(baseNameElements[1:])
+        return ( dirname(abs_file), baseName, fileName, fileExtension ) 
+
+    def _mkdir_p(self, path):
+        try:
+            os.makedirs(path)
+        except OSError as exc:  # Python >2.5
+            if exc.errno == errno.EEXIST and os.path.isdir(path):
+                pass
+            else:
+                raise
+    
+    def transform_and_scrub(self, sname, sin, sout):
+        """"""Convert all state data to a *nix diff-able form
+    
+        Keyword arguments:
+        sin -- A directory containing indy-node/plenum state data
+        sout -- A directory in which to write *nix-diff-able/friendly output
+    
+        Detect all LevelDB/RocksDB directories. The LevelDB directory structure
+        is described here:
+            https://github.com/google/leveldb/blob/master/doc/impl.md 
+
+            Each database is represented by a set of files stored in a
+            directory.
+       
+            By default, LevelDB/RocksDB uses a BytewiseComparator, which is the
+            expected outcome when calling initKeyValueStorage to create a
+            LevelDB/RocksDB instance/directory. initKeyValueStorageIntKeys
+            changes the comparator to an IntegerComparator. Therefore, the
+            LevelDB/RocksDB instances/directories may require one or the other.
+            First Attempt to open with initKeyValueStorage. If that throws an
+            error,try again with initKeyValueStorageIntKeys.
+       
+        Transform and scrub data in preparation for *nix diff
+           1. Marshall/Transform data from LevelDB/RocksDB directories to flat
+              files.  Use domain objects where possible to decode key/value
+              pairs.
+           2. Any subset of 'particpants' (nodes) can be used to create
+              state 'signature'(s). Therefore, scrub state_signature LevelDB
+              entries and exclude 'participants' and 'signature' fields;
+              preserving only the 'value' JSON element.
+           3. Scrub the node_info; preserving only the 'view' field.
+           4. Extract the last/latest (view no, ppSeqNo) tuple from the logs
+              emitted by replica.py and node.py. TODO: update this description
+              once we have concrete examples.
+           5. All other files and directories are unaltered.
+        """"""
+        logger.debug(""Transforming and scrubbing {} into {}"".format(sin, sout))
+    
+        # The set of filenames that must exist in a directory to be assumed a
+        # LevelDB/RocksDB instance. Will be used in the following for-loop.
+        leveldb_rocksdb_filenames = [ 'CURRENT', 'LOG' ]
+
+        # Traverse directory sin
+        # TODO: 1. Optimize using multiprocessing module. At minimum, all
+        #       directories can be transformed and scrubbed in parallel.
+        #       https://docs.python.org/3/library/multiprocessing.html
+        #
+        #       2. Files in Non-LevelDB/RocksDB directories can be transformed
+        #          and scrubbed in parallel.
+        for dirName, subdirList, fileList in os.walk(abspath(sin)):
+            if (dirName in self.skipdirs):
+                logger.debug(""Skipping dirName: {}"".format(dirName))
+                break
+
+            if self.log_level <= logging.INFO:
+                logger.info(""dirName: {}"".format(dirName))
+
+            # Skip specific directories
+            subdirList[:] = [x for x in subdirList if x not in self.skipdirs]
+            # Skip specific files
+            fileList[:] = [x for x in fileList if x not in self.skipfiles]
+    
+            # Check if all of the leveldb_rocksdb_filenames are found in
+            # fileList set is_leveldb_rocksdb_dir and break if any of the
+            # filenames are not found
+            is_leveldb_rocksdb_dir = True
+            for filename in leveldb_rocksdb_filenames:
+                if filename not in fileList:
+                    is_leveldb_rocksdb_dir = False
+                    break
+    
+            (dirname, filename, name, extension) = self.split_name(dirName)
+            # Do not include recordings in diff
+            if (filename == ""recorder"" and dirname.endswith(
+                ""/{}"".format(sname))):
+                subdirList[:] = []
+                continue
+
+            if (is_leveldb_rocksdb_dir):
+                logger.debug(""{} is a LevelDB/RocksDB directory!""
+                    .format(dirName))
+
+                # Use ""nodename"" in place of the node's name when a directory
+                # (dirName in this case) matches the node name (sname)
+                if (sname == filename):
+                    filename = ""nodename""
+
+                if (filename.endswith(""_transactions"")):",394,2018-05-31 18:50:02,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/192170720,https://github.com/hyperledger/indy-node/pull/703#discussion_r192170720,devin-fisher
https://github.com/hyperledger/indy-node/pull/699,https://github.com/hyperledger/indy-node/pull/699,Do we have an argument whether we are waiting for a reply from previous request before sending the next request?,a94a9b17db12eea60bf34426886d0cd605494004,2018-05-17 15:32:19,189002887,"@@ -0,0 +1,609 @@
+import shutil
+import json
+import time
+import datetime
+import os
+import sys
+import asyncio
+import argparse
+import multiprocessing
+import concurrent
+import signal
+import functools
+import base58
+import libnacl
+
+from indy import pool, wallet, did, ledger
+
+
+parser = argparse.ArgumentParser(
+    description='This script will execute the test base on the '
+                'mode that user passes to system.')
+
+parser.add_argument('-c', '--clients',
+                    help='Number of client you want to create. 0 or less means equal to number of available CPUs'
+                         'Default value is 0',
+                    default=0, type=int, required=False,
+                    dest='clients')
+
+
+def check_fs(is_dir: bool, fs_name: str):
+    pp = os.path.expanduser(fs_name)
+    rights = os.W_OK if is_dir else os.R_OK
+    chk_func = os.path.isdir if is_dir else os.path.isfile
+    if chk_func(pp) and os.access(pp, rights):
+        return pp
+    raise argparse.ArgumentTypeError(""{} not found or access error"".format(pp))
+
+
+parser.add_argument('-g', '--genesis',
+                    help='Path to genesis txns file'
+                         'Default value is ~/.indy-cli/networks/sandbox/pool_transactions_genesis',
+                    default=""~/.indy-cli/networks/sandbox/pool_transactions_genesis"",
+                    type=functools.partial(check_fs, False), required=False,
+                    dest='genesis_path')
+
+
+def check_seed(seed: str):
+    if len(seed) == 32:
+        return seed
+    raise argparse.ArgumentTypeError(""Seed must be 32 characters long but provided {}"".format(len(seed)))
+
+
+parser.add_argument('-s', '--seed',
+                    help='Seed to generate submitter did'
+                         'Default value is Trustee1',
+                    default=""000000000000000000000000Trustee1"",
+                    type=check_seed, required=False,
+                    dest='seed')
+
+parser.add_argument('-k', '--kind',
+                    help='Kind of request kind to use. One of [""nym"", ""schema"", ""attribute"", ""claim"", ""rand""]'
+                         'Default value is ""nym""',
+                    default=""nym"",
+                    choices=['nym', 'schema', 'attribute', 'claim', 'rand'],
+                    required=False, dest='req_kind')
+
+parser.add_argument('-n', '--num',
+                    help='How many transactions to submit.'
+                         'Default value is 100',
+                    default=100, type=int, required=False, dest='batch_size')
+
+parser.add_argument('-t', '--timeout',
+                    help='Timeout between batches.'
+                         'Default value is 0 - send once and finish',
+                    default=0, type=float, required=False, dest='batch_timeout')
+
+parser.add_argument('-r', '--refresh',
+                    help='Refresh stat rate in sec.'
+                         'Default value is 3',
+                    default=3, type=int, required=False, dest='refresh_rate')
+
+parser.add_argument('-b', '--bg_tasks',
+                    help='Number of background tasks per process, sending and generating.'
+                         'Default value is 10',
+                    default=10, type=int, required=False, dest='bg_tasks')
+
+parser.add_argument('-d', '--directory',
+                    help='Directory to save output files'
+                         'Default value is "".""',
+                    default=""."",
+                    type=functools.partial(check_fs, True), required=False,
+                    dest='out_dir')
+
+parser.add_argument('--sep',",,2018-05-18 07:38:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189002887,https://github.com/hyperledger/indy-node/pull/699#discussion_r189002887,ashcherbakov
https://github.com/hyperledger/indy-node/pull/699,https://github.com/hyperledger/indy-node/pull/699,Please mention that each client is a Process ,a94a9b17db12eea60bf34426886d0cd605494004,2018-05-17 15:34:43,189003682,"@@ -0,0 +1,609 @@
+import shutil
+import json
+import time
+import datetime
+import os
+import sys
+import asyncio
+import argparse
+import multiprocessing
+import concurrent
+import signal
+import functools
+import base58
+import libnacl
+
+from indy import pool, wallet, did, ledger
+
+
+parser = argparse.ArgumentParser(
+    description='This script will execute the test base on the '
+                'mode that user passes to system.')
+
+parser.add_argument('-c', '--clients',",,2018-05-18 07:38:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189003682,https://github.com/hyperledger/indy-node/pull/699#discussion_r189003682,ashcherbakov
https://github.com/hyperledger/indy-node/pull/699,https://github.com/hyperledger/indy-node/pull/699,Why don't we just sleep here?,a94a9b17db12eea60bf34426886d0cd605494004,2018-05-17 16:25:54,189021265,"@@ -0,0 +1,609 @@
+import shutil
+import json
+import time
+import datetime
+import os
+import sys
+import asyncio
+import argparse
+import multiprocessing
+import concurrent
+import signal
+import functools
+import base58
+import libnacl
+
+from indy import pool, wallet, did, ledger
+
+
+parser = argparse.ArgumentParser(
+    description='This script will execute the test base on the '
+                'mode that user passes to system.')
+
+parser.add_argument('-c', '--clients',
+                    help='Number of client you want to create. 0 or less means equal to number of available CPUs'
+                         'Default value is 0',
+                    default=0, type=int, required=False,
+                    dest='clients')
+
+
+def check_fs(is_dir: bool, fs_name: str):
+    pp = os.path.expanduser(fs_name)
+    rights = os.W_OK if is_dir else os.R_OK
+    chk_func = os.path.isdir if is_dir else os.path.isfile
+    if chk_func(pp) and os.access(pp, rights):
+        return pp
+    raise argparse.ArgumentTypeError(""{} not found or access error"".format(pp))
+
+
+parser.add_argument('-g', '--genesis',
+                    help='Path to genesis txns file'
+                         'Default value is ~/.indy-cli/networks/sandbox/pool_transactions_genesis',
+                    default=""~/.indy-cli/networks/sandbox/pool_transactions_genesis"",
+                    type=functools.partial(check_fs, False), required=False,
+                    dest='genesis_path')
+
+
+def check_seed(seed: str):
+    if len(seed) == 32:
+        return seed
+    raise argparse.ArgumentTypeError(""Seed must be 32 characters long but provided {}"".format(len(seed)))
+
+
+parser.add_argument('-s', '--seed',
+                    help='Seed to generate submitter did'
+                         'Default value is Trustee1',
+                    default=""000000000000000000000000Trustee1"",
+                    type=check_seed, required=False,
+                    dest='seed')
+
+parser.add_argument('-k', '--kind',
+                    help='Kind of request kind to use. One of [""nym"", ""schema"", ""attribute"", ""claim"", ""rand""]'
+                         'Default value is ""nym""',
+                    default=""nym"",
+                    choices=['nym', 'schema', 'attribute', 'claim', 'rand'],
+                    required=False, dest='req_kind')
+
+parser.add_argument('-n', '--num',
+                    help='How many transactions to submit.'
+                         'Default value is 100',
+                    default=100, type=int, required=False, dest='batch_size')
+
+parser.add_argument('-t', '--timeout',
+                    help='Timeout between batches.'
+                         'Default value is 0 - send once and finish',
+                    default=0, type=float, required=False, dest='batch_timeout')
+
+parser.add_argument('-r', '--refresh',
+                    help='Refresh stat rate in sec.'
+                         'Default value is 3',
+                    default=3, type=int, required=False, dest='refresh_rate')
+
+parser.add_argument('-b', '--bg_tasks',
+                    help='Number of background tasks per process, sending and generating.'
+                         'Default value is 10',
+                    default=10, type=int, required=False, dest='bg_tasks')
+
+parser.add_argument('-d', '--directory',
+                    help='Directory to save output files'
+                         'Default value is "".""',
+                    default=""."",
+                    type=functools.partial(check_fs, True), required=False,
+                    dest='out_dir')
+
+parser.add_argument('--sep',
+                    help='Value separator used in result file'
+                         'Default value is ""|""',
+                    default=""|"", type=str, required=False, dest='val_sep')
+
+
+class ClientStatistic:
+    def __init__(self):
+        self._req_prep = 0
+        self._req_sent = 0
+        self._req_succ = 0
+        self._req_fail = 0
+        self._req_nack = 0
+        self._req_rejc = 0
+
+        # inited as something big (datetime.datetime(9999, 1, 1) - datetime.datetime(1970, 1, 1)).total_seconds()
+        self._server_min_txn_time = 253370764800
+        self._server_max_txn_time = 0
+
+        self._reqs = dict()
+
+    def preparing(self, req_id):
+        self._reqs.setdefault(req_id, dict())[""client_preparing""] = time.time()
+
+    def prepared(self, req_id):
+        self._reqs.setdefault(req_id, dict())[""client_prepared""] = time.time()
+        self._req_prep += 1
+
+    def sent(self, req_id, req):
+        self._reqs.setdefault(req_id, dict())[""client_sent""] = time.time()
+        self._reqs[req_id][""req""] = req
+        self._req_sent += 1
+
+    def reply(self, req_id, reply_or_exception):
+        self._reqs.setdefault(req_id, dict())[""client_reply""] = time.time()
+        resp = reply_or_exception
+        if isinstance(reply_or_exception, str):
+            try:
+                resp = json.loads(reply_or_exception)
+            except Exception as e:
+                print(""Cannot parse response"", e)
+                resp = e
+
+        if isinstance(resp, Exception):
+            self._req_fail += 1
+            status = ""fail""
+        elif isinstance(resp, dict) and ""op"" in resp:
+            if resp[""op""] == ""REQNACK"":
+                self._req_nack += 1
+                status = ""nack""
+            elif resp[""op""] == ""REJECT"":
+                self._req_rejc += 1
+                status = ""reject""
+            elif resp[""op""] == ""REPLY"":
+                self._req_succ += 1
+                status = ""succ""
+                server_time = int(resp['result']['txnTime'])
+                self._reqs[req_id][""server_reply""] = server_time
+                self._server_min_txn_time = min(self._server_min_txn_time, server_time)
+                self._server_max_txn_time = max(self._server_max_txn_time, server_time)
+            else:
+                self._req_fail += 1
+                status = ""fail""
+        else:
+            self._req_fail += 1
+            status = ""fail""
+        self._reqs[req_id][""status""] = status
+        self._reqs[req_id][""resp""] = resp
+
+    def dump_stat(self, dump_all: bool = False):
+        ret_val = {}
+        ret_val[""total_prepared""] = self._req_prep
+        ret_val[""total_sent""] = self._req_sent
+        ret_val[""total_fail""] = self._req_fail
+        ret_val[""total_succ""] = self._req_succ
+        ret_val[""total_nacked""] = self._req_nack
+        ret_val[""total_rejected""] = self._req_rejc
+        srv_time = self._server_max_txn_time - self._server_min_txn_time
+        ret_val[""server_time""] = srv_time if srv_time >= 0 else 0
+        ret_val[""reqs""] = []
+        reqs = [k for k, v in self._reqs.items() if ""status"" in v or dump_all]
+        for r in reqs:
+            ret_val[""reqs""].append((r, self._reqs.pop(r)))
+        return ret_val
+
+
+class LoadClient:
+    def __init__(self, name, pipe_conn, batch_size, batch_timeout, req_kind, bg_tasks):
+        self._name = name
+        self._stat = ClientStatistic()
+        self._gen_lim = bg_tasks // 2
+        self._send_lim = bg_tasks // 2
+        self._pipe_conn = pipe_conn
+        self._pool_name = ""pool_{}"".format(os.getpid())
+        self._loop = asyncio.new_event_loop()
+        asyncio.set_event_loop(self._loop)
+        self._pool_handle = None
+        self._wallet_name = None
+        self._wallet_handle = None
+        self._test_did = None
+        self._test_verk = None
+        self._reqs = []
+        self._loop.add_reader(self._pipe_conn, self.read_cb)
+        self._closing = False
+        self._batch_size = batch_size
+        self._batch_timeout = batch_timeout
+        self._gen_q = []
+        self._send_q = []
+        self._req_generator = self.get_builder(req_kind)
+        assert self._req_generator is not None
+        self._bg_send_last = 0
+        self._sent_in_batch = None
+
+    async def run_test(self, genesis_path, seed):
+        pool_cfg = json.dumps({""genesis_txn"": genesis_path})
+        await pool.create_pool_ledger_config(self._pool_name, pool_cfg)
+        self._pool_handle = await pool.open_pool_ledger(self._pool_name, None)
+        self._wallet_name = ""{}_wallet"".format(self._pool_name)
+        await wallet.create_wallet(self._pool_name, self._wallet_name, None, None, None)
+        self._wallet_handle = await wallet.open_wallet(self._wallet_name, None, None)
+        self._test_did, self._test_verk = await did.create_and_store_my_did(self._wallet_handle, json.dumps({'seed': seed}))
+
+        self.gen_reqs()
+
+    def get_builder(self, req_kind):
+        if req_kind == 'nym':
+            return self.gen_signed_nym
+        if req_kind == 'rand':
+            return self.gen_signed_nym
+        return self.gen_signed_nym
+
+    def read_cb(self):
+        force_close = False
+        try:
+            flag = self._pipe_conn.recv()
+            if isinstance(flag, bool) and flag is False:
+                if self._closing is False:
+                    force_close = True
+            elif isinstance(flag, bool) and flag is True:
+                st = self._stat.dump_stat()
+                try:
+                    self._pipe_conn.send(st)
+                except Exception as e:
+                    print(""{} stat send error {}"".format(self._name, e))
+                    force_close = True
+        except Exception as e:
+            print(""{} Error {}"".format(self._name, e))
+            force_close = True
+        if force_close:
+            self._loop.create_task(self.stop_test())
+
+    # Copied from Plenum
+    def random_string(self, sz: int) -> str:
+        assert (sz > 0), ""Expected random string size cannot be less than 1""
+        rv = libnacl.randombytes(sz // 2).hex()
+        return rv if sz % 2 == 0 else rv + hex(libnacl.randombytes_uniform(15))[-1]
+
+    # Copied from Plenum
+    def rawToFriendly(self, raw):
+        return base58.b58encode(raw).decode(""utf-8"")
+
+    async def gen_signed_nym(self):
+        # print(""gen_signed_nym"")
+        if self._closing is True:
+            return
+
+        raw = libnacl.randombytes(16)
+        did = self.rawToFriendly(raw)
+
+        self._stat.preparing(did)
+        try:
+            req = await ledger.build_nym_request(self._test_did, did, None, None, None)
+            sig_req = await ledger.sign_request(self._wallet_handle, self._test_did, req)
+            self._reqs.append((did, sig_req))
+            self._stat.prepared(did)
+        except Exception as e:
+            self._stat.reply(did, e)
+            print(""{} prepare req error {}"".format(self._name, e))
+
+    def watch_queues(self):
+        if len(self._reqs) + len(self._gen_q) < self._batch_size:
+            self._loop.call_soon(self.gen_reqs)
+
+        if len(self._reqs) > 0 and len(self._send_q) < self._send_lim:
+            self._loop.call_soon(self.req_send)
+
+    def check_batch_avail(self, fut):
+        self._gen_q.remove(fut)
+
+        self.watch_queues()
+
+    def max_in_bg(self):
+        return min(500, 3 * self._batch_size)
+
+    def gen_reqs(self):
+        if self._closing:
+            return
+
+        avail_gens = self._gen_lim - len(self._gen_q)
+        if avail_gens <= 0 or len(self._gen_q) + len(self._reqs) > self.max_in_bg():
+            return
+
+        for i in range(0, min(avail_gens, self._batch_size)):
+            builder = self._loop.create_task(self._req_generator())
+            builder.add_done_callback(self.check_batch_avail)
+            self._gen_q.append(builder)
+
+    async def submit_req_update(self, req_id, req):
+        self._stat.sent(req_id, req)
+        try:
+            resp_or_exp = await ledger.submit_request(self._pool_handle, req)
+        except Exception as e:
+            resp_or_exp = e
+        self._stat.reply(req_id, resp_or_exp)
+
+    def done_submit(self, fut):
+        self._send_q.remove(fut)
+
+        self.watch_queues()
+
+    def req_send(self):
+        if self._closing:
+            return
+
+        avail_sndrs = self._send_lim - len(self._send_q)
+        if avail_sndrs <= 0:
+            return
+
+        if self._sent_in_batch is None:  # should wait for a timeout",385,2018-05-18 07:38:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189021265,https://github.com/hyperledger/indy-node/pull/699#discussion_r189021265,ashcherbakov
https://github.com/hyperledger/indy-node/pull/699,https://github.com/hyperledger/indy-node/pull/699,"we have a bunch of background tasks, so there is no need to sleep",a94a9b17db12eea60bf34426886d0cd605494004,2018-05-17 17:27:02,189038740,"@@ -0,0 +1,609 @@
+import shutil
+import json
+import time
+import datetime
+import os
+import sys
+import asyncio
+import argparse
+import multiprocessing
+import concurrent
+import signal
+import functools
+import base58
+import libnacl
+
+from indy import pool, wallet, did, ledger
+
+
+parser = argparse.ArgumentParser(
+    description='This script will execute the test base on the '
+                'mode that user passes to system.')
+
+parser.add_argument('-c', '--clients',
+                    help='Number of client you want to create. 0 or less means equal to number of available CPUs'
+                         'Default value is 0',
+                    default=0, type=int, required=False,
+                    dest='clients')
+
+
+def check_fs(is_dir: bool, fs_name: str):
+    pp = os.path.expanduser(fs_name)
+    rights = os.W_OK if is_dir else os.R_OK
+    chk_func = os.path.isdir if is_dir else os.path.isfile
+    if chk_func(pp) and os.access(pp, rights):
+        return pp
+    raise argparse.ArgumentTypeError(""{} not found or access error"".format(pp))
+
+
+parser.add_argument('-g', '--genesis',
+                    help='Path to genesis txns file'
+                         'Default value is ~/.indy-cli/networks/sandbox/pool_transactions_genesis',
+                    default=""~/.indy-cli/networks/sandbox/pool_transactions_genesis"",
+                    type=functools.partial(check_fs, False), required=False,
+                    dest='genesis_path')
+
+
+def check_seed(seed: str):
+    if len(seed) == 32:
+        return seed
+    raise argparse.ArgumentTypeError(""Seed must be 32 characters long but provided {}"".format(len(seed)))
+
+
+parser.add_argument('-s', '--seed',
+                    help='Seed to generate submitter did'
+                         'Default value is Trustee1',
+                    default=""000000000000000000000000Trustee1"",
+                    type=check_seed, required=False,
+                    dest='seed')
+
+parser.add_argument('-k', '--kind',
+                    help='Kind of request kind to use. One of [""nym"", ""schema"", ""attribute"", ""claim"", ""rand""]'
+                         'Default value is ""nym""',
+                    default=""nym"",
+                    choices=['nym', 'schema', 'attribute', 'claim', 'rand'],
+                    required=False, dest='req_kind')
+
+parser.add_argument('-n', '--num',
+                    help='How many transactions to submit.'
+                         'Default value is 100',
+                    default=100, type=int, required=False, dest='batch_size')
+
+parser.add_argument('-t', '--timeout',
+                    help='Timeout between batches.'
+                         'Default value is 0 - send once and finish',
+                    default=0, type=float, required=False, dest='batch_timeout')
+
+parser.add_argument('-r', '--refresh',
+                    help='Refresh stat rate in sec.'
+                         'Default value is 3',
+                    default=3, type=int, required=False, dest='refresh_rate')
+
+parser.add_argument('-b', '--bg_tasks',
+                    help='Number of background tasks per process, sending and generating.'
+                         'Default value is 10',
+                    default=10, type=int, required=False, dest='bg_tasks')
+
+parser.add_argument('-d', '--directory',
+                    help='Directory to save output files'
+                         'Default value is "".""',
+                    default=""."",
+                    type=functools.partial(check_fs, True), required=False,
+                    dest='out_dir')
+
+parser.add_argument('--sep',
+                    help='Value separator used in result file'
+                         'Default value is ""|""',
+                    default=""|"", type=str, required=False, dest='val_sep')
+
+
+class ClientStatistic:
+    def __init__(self):
+        self._req_prep = 0
+        self._req_sent = 0
+        self._req_succ = 0
+        self._req_fail = 0
+        self._req_nack = 0
+        self._req_rejc = 0
+
+        # inited as something big (datetime.datetime(9999, 1, 1) - datetime.datetime(1970, 1, 1)).total_seconds()
+        self._server_min_txn_time = 253370764800
+        self._server_max_txn_time = 0
+
+        self._reqs = dict()
+
+    def preparing(self, req_id):
+        self._reqs.setdefault(req_id, dict())[""client_preparing""] = time.time()
+
+    def prepared(self, req_id):
+        self._reqs.setdefault(req_id, dict())[""client_prepared""] = time.time()
+        self._req_prep += 1
+
+    def sent(self, req_id, req):
+        self._reqs.setdefault(req_id, dict())[""client_sent""] = time.time()
+        self._reqs[req_id][""req""] = req
+        self._req_sent += 1
+
+    def reply(self, req_id, reply_or_exception):
+        self._reqs.setdefault(req_id, dict())[""client_reply""] = time.time()
+        resp = reply_or_exception
+        if isinstance(reply_or_exception, str):
+            try:
+                resp = json.loads(reply_or_exception)
+            except Exception as e:
+                print(""Cannot parse response"", e)
+                resp = e
+
+        if isinstance(resp, Exception):
+            self._req_fail += 1
+            status = ""fail""
+        elif isinstance(resp, dict) and ""op"" in resp:
+            if resp[""op""] == ""REQNACK"":
+                self._req_nack += 1
+                status = ""nack""
+            elif resp[""op""] == ""REJECT"":
+                self._req_rejc += 1
+                status = ""reject""
+            elif resp[""op""] == ""REPLY"":
+                self._req_succ += 1
+                status = ""succ""
+                server_time = int(resp['result']['txnTime'])
+                self._reqs[req_id][""server_reply""] = server_time
+                self._server_min_txn_time = min(self._server_min_txn_time, server_time)
+                self._server_max_txn_time = max(self._server_max_txn_time, server_time)
+            else:
+                self._req_fail += 1
+                status = ""fail""
+        else:
+            self._req_fail += 1
+            status = ""fail""
+        self._reqs[req_id][""status""] = status
+        self._reqs[req_id][""resp""] = resp
+
+    def dump_stat(self, dump_all: bool = False):
+        ret_val = {}
+        ret_val[""total_prepared""] = self._req_prep
+        ret_val[""total_sent""] = self._req_sent
+        ret_val[""total_fail""] = self._req_fail
+        ret_val[""total_succ""] = self._req_succ
+        ret_val[""total_nacked""] = self._req_nack
+        ret_val[""total_rejected""] = self._req_rejc
+        srv_time = self._server_max_txn_time - self._server_min_txn_time
+        ret_val[""server_time""] = srv_time if srv_time >= 0 else 0
+        ret_val[""reqs""] = []
+        reqs = [k for k, v in self._reqs.items() if ""status"" in v or dump_all]
+        for r in reqs:
+            ret_val[""reqs""].append((r, self._reqs.pop(r)))
+        return ret_val
+
+
+class LoadClient:
+    def __init__(self, name, pipe_conn, batch_size, batch_timeout, req_kind, bg_tasks):
+        self._name = name
+        self._stat = ClientStatistic()
+        self._gen_lim = bg_tasks // 2
+        self._send_lim = bg_tasks // 2
+        self._pipe_conn = pipe_conn
+        self._pool_name = ""pool_{}"".format(os.getpid())
+        self._loop = asyncio.new_event_loop()
+        asyncio.set_event_loop(self._loop)
+        self._pool_handle = None
+        self._wallet_name = None
+        self._wallet_handle = None
+        self._test_did = None
+        self._test_verk = None
+        self._reqs = []
+        self._loop.add_reader(self._pipe_conn, self.read_cb)
+        self._closing = False
+        self._batch_size = batch_size
+        self._batch_timeout = batch_timeout
+        self._gen_q = []
+        self._send_q = []
+        self._req_generator = self.get_builder(req_kind)
+        assert self._req_generator is not None
+        self._bg_send_last = 0
+        self._sent_in_batch = None
+
+    async def run_test(self, genesis_path, seed):
+        pool_cfg = json.dumps({""genesis_txn"": genesis_path})
+        await pool.create_pool_ledger_config(self._pool_name, pool_cfg)
+        self._pool_handle = await pool.open_pool_ledger(self._pool_name, None)
+        self._wallet_name = ""{}_wallet"".format(self._pool_name)
+        await wallet.create_wallet(self._pool_name, self._wallet_name, None, None, None)
+        self._wallet_handle = await wallet.open_wallet(self._wallet_name, None, None)
+        self._test_did, self._test_verk = await did.create_and_store_my_did(self._wallet_handle, json.dumps({'seed': seed}))
+
+        self.gen_reqs()
+
+    def get_builder(self, req_kind):
+        if req_kind == 'nym':
+            return self.gen_signed_nym
+        if req_kind == 'rand':
+            return self.gen_signed_nym
+        return self.gen_signed_nym
+
+    def read_cb(self):
+        force_close = False
+        try:
+            flag = self._pipe_conn.recv()
+            if isinstance(flag, bool) and flag is False:
+                if self._closing is False:
+                    force_close = True
+            elif isinstance(flag, bool) and flag is True:
+                st = self._stat.dump_stat()
+                try:
+                    self._pipe_conn.send(st)
+                except Exception as e:
+                    print(""{} stat send error {}"".format(self._name, e))
+                    force_close = True
+        except Exception as e:
+            print(""{} Error {}"".format(self._name, e))
+            force_close = True
+        if force_close:
+            self._loop.create_task(self.stop_test())
+
+    # Copied from Plenum
+    def random_string(self, sz: int) -> str:
+        assert (sz > 0), ""Expected random string size cannot be less than 1""
+        rv = libnacl.randombytes(sz // 2).hex()
+        return rv if sz % 2 == 0 else rv + hex(libnacl.randombytes_uniform(15))[-1]
+
+    # Copied from Plenum
+    def rawToFriendly(self, raw):
+        return base58.b58encode(raw).decode(""utf-8"")
+
+    async def gen_signed_nym(self):
+        # print(""gen_signed_nym"")
+        if self._closing is True:
+            return
+
+        raw = libnacl.randombytes(16)
+        did = self.rawToFriendly(raw)
+
+        self._stat.preparing(did)
+        try:
+            req = await ledger.build_nym_request(self._test_did, did, None, None, None)
+            sig_req = await ledger.sign_request(self._wallet_handle, self._test_did, req)
+            self._reqs.append((did, sig_req))
+            self._stat.prepared(did)
+        except Exception as e:
+            self._stat.reply(did, e)
+            print(""{} prepare req error {}"".format(self._name, e))
+
+    def watch_queues(self):
+        if len(self._reqs) + len(self._gen_q) < self._batch_size:
+            self._loop.call_soon(self.gen_reqs)
+
+        if len(self._reqs) > 0 and len(self._send_q) < self._send_lim:
+            self._loop.call_soon(self.req_send)
+
+    def check_batch_avail(self, fut):
+        self._gen_q.remove(fut)
+
+        self.watch_queues()
+
+    def max_in_bg(self):
+        return min(500, 3 * self._batch_size)
+
+    def gen_reqs(self):
+        if self._closing:
+            return
+
+        avail_gens = self._gen_lim - len(self._gen_q)
+        if avail_gens <= 0 or len(self._gen_q) + len(self._reqs) > self.max_in_bg():
+            return
+
+        for i in range(0, min(avail_gens, self._batch_size)):
+            builder = self._loop.create_task(self._req_generator())
+            builder.add_done_callback(self.check_batch_avail)
+            self._gen_q.append(builder)
+
+    async def submit_req_update(self, req_id, req):
+        self._stat.sent(req_id, req)
+        try:
+            resp_or_exp = await ledger.submit_request(self._pool_handle, req)
+        except Exception as e:
+            resp_or_exp = e
+        self._stat.reply(req_id, resp_or_exp)
+
+    def done_submit(self, fut):
+        self._send_q.remove(fut)
+
+        self.watch_queues()
+
+    def req_send(self):
+        if self._closing:
+            return
+
+        avail_sndrs = self._send_lim - len(self._send_q)
+        if avail_sndrs <= 0:
+            return
+
+        if self._sent_in_batch is None:  # should wait for a timeout",385,2018-05-18 07:38:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189038740,https://github.com/hyperledger/indy-node/pull/699#discussion_r189038740,dsurnin
https://github.com/hyperledger/indy-node/pull/699,https://github.com/hyperledger/indy-node/pull/699,"Not yet, but I will implement it",a94a9b17db12eea60bf34426886d0cd605494004,2018-05-17 17:28:28,189039198,"@@ -0,0 +1,609 @@
+import shutil
+import json
+import time
+import datetime
+import os
+import sys
+import asyncio
+import argparse
+import multiprocessing
+import concurrent
+import signal
+import functools
+import base58
+import libnacl
+
+from indy import pool, wallet, did, ledger
+
+
+parser = argparse.ArgumentParser(
+    description='This script will execute the test base on the '
+                'mode that user passes to system.')
+
+parser.add_argument('-c', '--clients',
+                    help='Number of client you want to create. 0 or less means equal to number of available CPUs'
+                         'Default value is 0',
+                    default=0, type=int, required=False,
+                    dest='clients')
+
+
+def check_fs(is_dir: bool, fs_name: str):
+    pp = os.path.expanduser(fs_name)
+    rights = os.W_OK if is_dir else os.R_OK
+    chk_func = os.path.isdir if is_dir else os.path.isfile
+    if chk_func(pp) and os.access(pp, rights):
+        return pp
+    raise argparse.ArgumentTypeError(""{} not found or access error"".format(pp))
+
+
+parser.add_argument('-g', '--genesis',
+                    help='Path to genesis txns file'
+                         'Default value is ~/.indy-cli/networks/sandbox/pool_transactions_genesis',
+                    default=""~/.indy-cli/networks/sandbox/pool_transactions_genesis"",
+                    type=functools.partial(check_fs, False), required=False,
+                    dest='genesis_path')
+
+
+def check_seed(seed: str):
+    if len(seed) == 32:
+        return seed
+    raise argparse.ArgumentTypeError(""Seed must be 32 characters long but provided {}"".format(len(seed)))
+
+
+parser.add_argument('-s', '--seed',
+                    help='Seed to generate submitter did'
+                         'Default value is Trustee1',
+                    default=""000000000000000000000000Trustee1"",
+                    type=check_seed, required=False,
+                    dest='seed')
+
+parser.add_argument('-k', '--kind',
+                    help='Kind of request kind to use. One of [""nym"", ""schema"", ""attribute"", ""claim"", ""rand""]'
+                         'Default value is ""nym""',
+                    default=""nym"",
+                    choices=['nym', 'schema', 'attribute', 'claim', 'rand'],
+                    required=False, dest='req_kind')
+
+parser.add_argument('-n', '--num',
+                    help='How many transactions to submit.'
+                         'Default value is 100',
+                    default=100, type=int, required=False, dest='batch_size')
+
+parser.add_argument('-t', '--timeout',
+                    help='Timeout between batches.'
+                         'Default value is 0 - send once and finish',
+                    default=0, type=float, required=False, dest='batch_timeout')
+
+parser.add_argument('-r', '--refresh',
+                    help='Refresh stat rate in sec.'
+                         'Default value is 3',
+                    default=3, type=int, required=False, dest='refresh_rate')
+
+parser.add_argument('-b', '--bg_tasks',
+                    help='Number of background tasks per process, sending and generating.'
+                         'Default value is 10',
+                    default=10, type=int, required=False, dest='bg_tasks')
+
+parser.add_argument('-d', '--directory',
+                    help='Directory to save output files'
+                         'Default value is "".""',
+                    default=""."",
+                    type=functools.partial(check_fs, True), required=False,
+                    dest='out_dir')
+
+parser.add_argument('--sep',",,2018-05-18 07:38:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189039198,https://github.com/hyperledger/indy-node/pull/699#discussion_r189039198,dsurnin
https://github.com/hyperledger/indy-node/pull/699,https://github.com/hyperledger/indy-node/pull/699,fixed,a94a9b17db12eea60bf34426886d0cd605494004,2018-05-17 17:28:38,189039239,"@@ -0,0 +1,609 @@
+import shutil
+import json
+import time
+import datetime
+import os
+import sys
+import asyncio
+import argparse
+import multiprocessing
+import concurrent
+import signal
+import functools
+import base58
+import libnacl
+
+from indy import pool, wallet, did, ledger
+
+
+parser = argparse.ArgumentParser(
+    description='This script will execute the test base on the '
+                'mode that user passes to system.')
+
+parser.add_argument('-c', '--clients',",,2018-05-18 07:38:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189039239,https://github.com/hyperledger/indy-node/pull/699#discussion_r189039239,dsurnin
https://github.com/hyperledger/indy-node/pull/679,https://github.com/hyperledger/indy-node/pull/679,"as far as I remember one of the requirements for the migration script - it should do nothing and finishes without any error if it runs several times
Also we have reinstall command that should run smoothly as well.
I think we need to determine if ledgers are leveldb or rocksdb somehow to achieve the reinstall/rerun goal.
Probably the easiest way is to add some sign to the name of the directory or something similar.",986bcca7c3b9cbb2f5db0f4d56127cde1509ff42,2018-04-30 07:44:37,184925709,"@@ -0,0 +1,197 @@
+#!/usr/bin/python3.5
+import os
+import sys
+import shutil
+import traceback
+import tarfile
+import pwd
+import grp
+import stat
+
+from stp_core.common.log import getlogger
+from storage.kv_store_leveldb import KeyValueStorageLeveldb
+from storage.kv_store_rocksdb import KeyValueStorageRocksdb
+from storage.kv_store_leveldb_int_keys import KeyValueStorageLeveldbIntKeys
+from storage.kv_store_rocksdb_int_keys import KeyValueStorageRocksdbIntKeys
+
+from indy_common.config_util import getConfig
+from indy_common.config_helper import NodeConfigHelper
+
+
+logger = getlogger()
+
+ENV_FILE_PATH = ""/etc/indy/indy.env""
+ledger_types = ['pool', 'domain', 'config']
+
+
+def set_own_perm(usr, dir):
+    uid = pwd.getpwnam(usr).pw_uid
+    gid = grp.getgrnam(usr).gr_gid
+    perm_mask_rw = stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP
+    perm_mask_rwx = stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | stat.S_IRGRP | stat.S_IWGRP | stat.S_IXGRP
+
+    os.chown(dir, uid, gid)
+    os.chmod(dir, perm_mask_rwx)
+    for croot, sub_dirs, cfiles in os.walk(dir):
+        for fs_name in sub_dirs:
+            os.chown(os.path.join(croot, fs_name), uid, gid)
+            os.chmod(os.path.join(croot, fs_name), perm_mask_rwx)
+        for fs_name in cfiles:
+            os.chown(os.path.join(croot, fs_name), uid, gid)
+            os.chmod(os.path.join(croot, fs_name), perm_mask_rw)
+
+
+def get_node_name():
+    node_name = None
+    node_name_key = 'NODE_NAME'
+
+    if os.path.exists(ENV_FILE_PATH):
+        with open(ENV_FILE_PATH, ""r"") as fenv:
+            for line in fenv.readlines():
+                if line.find(node_name_key) != -1:
+                    node_name = line.split('=')[1].strip()
+                    break
+    else:
+        logger.error(""Path to env file does not exist"")
+
+    return node_name
+
+
+def archive_leveldb_ledger(node_name, leveldb_ledger_dir):
+    leveldb_ledger_archive_name = node_name + ""_ledger_leveldb.tar.gz""
+    leveldb_ledger_archive_path = os.path.join(""/tmp"", leveldb_ledger_archive_name)
+    tar = tarfile.open(leveldb_ledger_archive_path, ""w:gz"")
+    tar.add(leveldb_ledger_dir, arcname=node_name)
+    tar.close()
+    logger.info(""Archive of LevelDB-based ledger created: {}""
+                .format(leveldb_ledger_archive_path))
+
+
+def migrate_storage(level_db_dir, rocks_db_dir, db_name, is_db_int_keys):
+    if is_db_int_keys is True:
+        KeyValueStorageLeveldbCls = KeyValueStorageLeveldbIntKeys
+        KeyValueStorageRocksdbCls = KeyValueStorageRocksdbIntKeys
+    else:
+        KeyValueStorageLeveldbCls = KeyValueStorageLeveldb
+        KeyValueStorageRocksdbCls = KeyValueStorageRocksdb
+
+    try:
+        leveldb_storage = KeyValueStorageLeveldbCls(level_db_dir, db_name, read_only=True)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not open leveldb storage: {}"".format(os.path.join(level_db_dir, db_name)))
+        return False
+
+    try:
+        rocksdb_storage = KeyValueStorageRocksdbCls(rocks_db_dir, db_name)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not open rocksdb storage: {}"".format(os.path.join(rocks_db_dir, db_name)))
+        return False
+
+    try:
+        for key, val in leveldb_storage.iterator():
+            rocksdb_storage.put(key, val)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not put key/value to RocksDB storage '{}'"".format(db_name))
+        return False
+
+    leveldb_storage.close()
+    rocksdb_storage.close()
+
+    return True
+
+
+def migrate_storages(leveldb_ledger_dir, rocksdb_ledger_dir):
+    # Migrate transaction logs, they use integer keys
+    for ledger_type in ledger_types:
+        db_name = ledger_type + ""_transactions""
+        if not migrate_storage(leveldb_ledger_dir, rocksdb_ledger_dir, db_name, True):
+            logger.error(""Could not migrate {}, DB path: {}""
+                         .format(db_name, os.path.join(leveldb_ledger_dir, db_name)))
+            return False
+
+    # Migrate other storages with non-integer keys
+    for db_name in [""attr_db"", ""idr_cache_db"", ""seq_no_db"", ""state_signature""]:
+        if not migrate_storage(leveldb_ledger_dir, rocksdb_ledger_dir, db_name, False):
+            logger.error(""Could not migrate {}, DB path: {}""
+                         .format(db_name, os.path.join(leveldb_ledger_dir, db_name)))
+            return False
+
+    return True
+
+
+def migrate_all():
+    node_name = get_node_name()
+    if node_name is None:
+        logger.error(""Could not get node name"")
+        return False
+
+    config = getConfig()
+    config_helper = NodeConfigHelper(node_name, config)
+
+    leveldb_ledger_dir = config_helper.ledger_dir
+    rocksdb_ledger_dir = os.path.join(config_helper.ledger_data_dir, node_name + ""_rocksdb"")
+    if os.path.exists(rocksdb_ledger_dir):
+        logger.error(""Temporary directory for RocksDB-based ledger exists, please remove: {}""
+                     .format(rocksdb_ledger_dir))
+        return False
+
+    try:
+        os.mkdir(rocksdb_ledger_dir)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not create temporary directory for RocksDB-based ledger: {}""
+                     .format(rocksdb_ledger_dir))
+        return False
+
+    logger.info(""Starting migration of storages from LevelDB to RocksDB..."")
+
+    if migrate_storages(leveldb_ledger_dir, rocksdb_ledger_dir):
+        logger.info(""All storages migrated successfully from LevelDB to RocksDB"")
+    else:
+        logger.error(""Storages migration from LevelDB to RocksDB failed!"")
+        shutil.rmtree(rocksdb_ledger_dir)
+        return False
+
+    # Archiving LevelDB-based ledger
+    try:
+        archive_leveldb_ledger(node_name, leveldb_ledger_dir)
+    except Exception:
+        logger.warning(""Could not create an archive of LevelDB-based ledger, proceed anyway"")
+
+    # TODO: it whould be nice to open new RocksDB-based ledger
+    # and compare root hashes with LevelDB-based ledger here
+
+    # Remove LevelDB-based ledger
+    try:
+        shutil.rmtree(leveldb_ledger_dir)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not remove LevelDB-based ledger: {}""
+                     .format(leveldb_ledger_dir))
+        shutil.rmtree(rocksdb_ledger_dir)
+        return False
+
+    ledger_dir = leveldb_ledger_dir
+
+    try:
+        shutil.move(rocksdb_ledger_dir, ledger_dir)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not rename temporary RocksDB-based ledger from '{}' to '{}'""
+                     .format(rocksdb_ledger_dir, ledger_dir))
+        shutil.rmtree(rocksdb_ledger_dir)
+        return False
+
+    set_own_perm(""indy"", ledger_dir)
+
+    return True
+
+
+if migrate_all():",193,2018-04-30 07:44:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/184925709,https://github.com/hyperledger/indy-node/pull/679#discussion_r184925709,dsurnin
https://github.com/hyperledger/indy-node/pull/679,https://github.com/hyperledger/indy-node/pull/679,What about `state_ts_db`?,986bcca7c3b9cbb2f5db0f4d56127cde1509ff42,2018-05-03 15:44:43,185846913,"@@ -0,0 +1,197 @@
+#!/usr/bin/python3.5
+import os
+import sys
+import shutil
+import traceback
+import tarfile
+import pwd
+import grp
+import stat
+
+from stp_core.common.log import getlogger
+from storage.kv_store_leveldb import KeyValueStorageLeveldb
+from storage.kv_store_rocksdb import KeyValueStorageRocksdb
+from storage.kv_store_leveldb_int_keys import KeyValueStorageLeveldbIntKeys
+from storage.kv_store_rocksdb_int_keys import KeyValueStorageRocksdbIntKeys
+
+from indy_common.config_util import getConfig
+from indy_common.config_helper import NodeConfigHelper
+
+
+logger = getlogger()
+
+ENV_FILE_PATH = ""/etc/indy/indy.env""
+ledger_types = ['pool', 'domain', 'config']
+
+
+def set_own_perm(usr, dir):
+    uid = pwd.getpwnam(usr).pw_uid
+    gid = grp.getgrnam(usr).gr_gid
+    perm_mask_rw = stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP
+    perm_mask_rwx = stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | stat.S_IRGRP | stat.S_IWGRP | stat.S_IXGRP
+
+    os.chown(dir, uid, gid)
+    os.chmod(dir, perm_mask_rwx)
+    for croot, sub_dirs, cfiles in os.walk(dir):
+        for fs_name in sub_dirs:
+            os.chown(os.path.join(croot, fs_name), uid, gid)
+            os.chmod(os.path.join(croot, fs_name), perm_mask_rwx)
+        for fs_name in cfiles:
+            os.chown(os.path.join(croot, fs_name), uid, gid)
+            os.chmod(os.path.join(croot, fs_name), perm_mask_rw)
+
+
+def get_node_name():
+    node_name = None
+    node_name_key = 'NODE_NAME'
+
+    if os.path.exists(ENV_FILE_PATH):
+        with open(ENV_FILE_PATH, ""r"") as fenv:
+            for line in fenv.readlines():
+                if line.find(node_name_key) != -1:
+                    node_name = line.split('=')[1].strip()
+                    break
+    else:
+        logger.error(""Path to env file does not exist"")
+
+    return node_name
+
+
+def archive_leveldb_ledger(node_name, leveldb_ledger_dir):
+    leveldb_ledger_archive_name = node_name + ""_ledger_leveldb.tar.gz""
+    leveldb_ledger_archive_path = os.path.join(""/tmp"", leveldb_ledger_archive_name)
+    tar = tarfile.open(leveldb_ledger_archive_path, ""w:gz"")
+    tar.add(leveldb_ledger_dir, arcname=node_name)
+    tar.close()
+    logger.info(""Archive of LevelDB-based ledger created: {}""
+                .format(leveldb_ledger_archive_path))
+
+
+def migrate_storage(level_db_dir, rocks_db_dir, db_name, is_db_int_keys):
+    if is_db_int_keys is True:
+        KeyValueStorageLeveldbCls = KeyValueStorageLeveldbIntKeys
+        KeyValueStorageRocksdbCls = KeyValueStorageRocksdbIntKeys
+    else:
+        KeyValueStorageLeveldbCls = KeyValueStorageLeveldb
+        KeyValueStorageRocksdbCls = KeyValueStorageRocksdb
+
+    try:
+        leveldb_storage = KeyValueStorageLeveldbCls(level_db_dir, db_name, read_only=True)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not open leveldb storage: {}"".format(os.path.join(level_db_dir, db_name)))
+        return False
+
+    try:
+        rocksdb_storage = KeyValueStorageRocksdbCls(rocks_db_dir, db_name)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not open rocksdb storage: {}"".format(os.path.join(rocks_db_dir, db_name)))
+        return False
+
+    try:
+        for key, val in leveldb_storage.iterator():
+            rocksdb_storage.put(key, val)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not put key/value to RocksDB storage '{}'"".format(db_name))
+        return False
+
+    leveldb_storage.close()
+    rocksdb_storage.close()
+
+    return True
+
+
+def migrate_storages(leveldb_ledger_dir, rocksdb_ledger_dir):
+    # Migrate transaction logs, they use integer keys
+    for ledger_type in ledger_types:
+        db_name = ledger_type + ""_transactions""
+        if not migrate_storage(leveldb_ledger_dir, rocksdb_ledger_dir, db_name, True):
+            logger.error(""Could not migrate {}, DB path: {}""
+                         .format(db_name, os.path.join(leveldb_ledger_dir, db_name)))
+            return False
+
+    # Migrate other storages with non-integer keys
+    for db_name in [""attr_db"", ""idr_cache_db"", ""seq_no_db"", ""state_signature""]:",116,2018-05-03 15:44:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/185846913,https://github.com/hyperledger/indy-node/pull/679#discussion_r185846913,ashcherbakov
https://github.com/hyperledger/indy-node/pull/679,https://github.com/hyperledger/indy-node/pull/679,"This storage is already on RocksDB
",986bcca7c3b9cbb2f5db0f4d56127cde1509ff42,2018-05-04 08:52:30,186022757,"@@ -0,0 +1,197 @@
+#!/usr/bin/python3.5
+import os
+import sys
+import shutil
+import traceback
+import tarfile
+import pwd
+import grp
+import stat
+
+from stp_core.common.log import getlogger
+from storage.kv_store_leveldb import KeyValueStorageLeveldb
+from storage.kv_store_rocksdb import KeyValueStorageRocksdb
+from storage.kv_store_leveldb_int_keys import KeyValueStorageLeveldbIntKeys
+from storage.kv_store_rocksdb_int_keys import KeyValueStorageRocksdbIntKeys
+
+from indy_common.config_util import getConfig
+from indy_common.config_helper import NodeConfigHelper
+
+
+logger = getlogger()
+
+ENV_FILE_PATH = ""/etc/indy/indy.env""
+ledger_types = ['pool', 'domain', 'config']
+
+
+def set_own_perm(usr, dir):
+    uid = pwd.getpwnam(usr).pw_uid
+    gid = grp.getgrnam(usr).gr_gid
+    perm_mask_rw = stat.S_IRUSR | stat.S_IWUSR | stat.S_IRGRP | stat.S_IWGRP
+    perm_mask_rwx = stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR | stat.S_IRGRP | stat.S_IWGRP | stat.S_IXGRP
+
+    os.chown(dir, uid, gid)
+    os.chmod(dir, perm_mask_rwx)
+    for croot, sub_dirs, cfiles in os.walk(dir):
+        for fs_name in sub_dirs:
+            os.chown(os.path.join(croot, fs_name), uid, gid)
+            os.chmod(os.path.join(croot, fs_name), perm_mask_rwx)
+        for fs_name in cfiles:
+            os.chown(os.path.join(croot, fs_name), uid, gid)
+            os.chmod(os.path.join(croot, fs_name), perm_mask_rw)
+
+
+def get_node_name():
+    node_name = None
+    node_name_key = 'NODE_NAME'
+
+    if os.path.exists(ENV_FILE_PATH):
+        with open(ENV_FILE_PATH, ""r"") as fenv:
+            for line in fenv.readlines():
+                if line.find(node_name_key) != -1:
+                    node_name = line.split('=')[1].strip()
+                    break
+    else:
+        logger.error(""Path to env file does not exist"")
+
+    return node_name
+
+
+def archive_leveldb_ledger(node_name, leveldb_ledger_dir):
+    leveldb_ledger_archive_name = node_name + ""_ledger_leveldb.tar.gz""
+    leveldb_ledger_archive_path = os.path.join(""/tmp"", leveldb_ledger_archive_name)
+    tar = tarfile.open(leveldb_ledger_archive_path, ""w:gz"")
+    tar.add(leveldb_ledger_dir, arcname=node_name)
+    tar.close()
+    logger.info(""Archive of LevelDB-based ledger created: {}""
+                .format(leveldb_ledger_archive_path))
+
+
+def migrate_storage(level_db_dir, rocks_db_dir, db_name, is_db_int_keys):
+    if is_db_int_keys is True:
+        KeyValueStorageLeveldbCls = KeyValueStorageLeveldbIntKeys
+        KeyValueStorageRocksdbCls = KeyValueStorageRocksdbIntKeys
+    else:
+        KeyValueStorageLeveldbCls = KeyValueStorageLeveldb
+        KeyValueStorageRocksdbCls = KeyValueStorageRocksdb
+
+    try:
+        leveldb_storage = KeyValueStorageLeveldbCls(level_db_dir, db_name, read_only=True)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not open leveldb storage: {}"".format(os.path.join(level_db_dir, db_name)))
+        return False
+
+    try:
+        rocksdb_storage = KeyValueStorageRocksdbCls(rocks_db_dir, db_name)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not open rocksdb storage: {}"".format(os.path.join(rocks_db_dir, db_name)))
+        return False
+
+    try:
+        for key, val in leveldb_storage.iterator():
+            rocksdb_storage.put(key, val)
+    except Exception:
+        logger.error(traceback.print_exc())
+        logger.error(""Could not put key/value to RocksDB storage '{}'"".format(db_name))
+        return False
+
+    leveldb_storage.close()
+    rocksdb_storage.close()
+
+    return True
+
+
+def migrate_storages(leveldb_ledger_dir, rocksdb_ledger_dir):
+    # Migrate transaction logs, they use integer keys
+    for ledger_type in ledger_types:
+        db_name = ledger_type + ""_transactions""
+        if not migrate_storage(leveldb_ledger_dir, rocksdb_ledger_dir, db_name, True):
+            logger.error(""Could not migrate {}, DB path: {}""
+                         .format(db_name, os.path.join(leveldb_ledger_dir, db_name)))
+            return False
+
+    # Migrate other storages with non-integer keys
+    for db_name in [""attr_db"", ""idr_cache_db"", ""seq_no_db"", ""state_signature""]:",116,2018-05-04 08:52:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/186022757,https://github.com/hyperledger/indy-node/pull/679#discussion_r186022757,anikitinDSR
https://github.com/hyperledger/indy-node/pull/677,https://github.com/hyperledger/indy-node/pull/677,"Maybe we should check, that shutil.copytree complete successfully? What if we have really big ledger, and will raised  ""There is no space left on device"" error?",38771413187631c9de25d78f49efaf942d1cd6bc,2018-04-28 13:53:11,184854356,"@@ -153,15 +156,26 @@ def make_copy_of_ledger(data_dir):
 
 if __name__ == '__main__':
     args = read_args()
+    config = getConfig()
 
-    # TODO: works well only for small ledgers,
     ledger_data_dir = get_ledger_dir(args.node_name, args.client_name, args.network)
     read_copy_ledger_data_dir = None
     try:
-        read_copy_ledger_data_dir = make_copy_of_ledger(ledger_data_dir)
-        ledger = get_ledger(args.type, read_copy_ledger_data_dir)
+        # RocksDB supports real read-only mode and does not need to have a ledger copy.
+        if config.hashStore['type'].lower() != HS_ROCKSDB:
+            # NOTE: such approach works well only for small ledgers.
+            tmp = make_copy_of_ledger(ledger_data_dir)",37,2018-04-28 13:53:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/184854356,https://github.com/hyperledger/indy-node/pull/677#discussion_r184854356,anikitinDSR
https://github.com/hyperledger/indy-node/pull/677,https://github.com/hyperledger/indy-node/pull/677,"Hmm, I think it's already done. If exception is risen then we go directly to finally block. The read_copy_ledger_data_dir variable is empty in this case, so we do nothing, but a user will see the error message.",38771413187631c9de25d78f49efaf942d1cd6bc,2018-04-28 14:01:11,184854609,"@@ -153,15 +156,26 @@ def make_copy_of_ledger(data_dir):
 
 if __name__ == '__main__':
     args = read_args()
+    config = getConfig()
 
-    # TODO: works well only for small ledgers,
     ledger_data_dir = get_ledger_dir(args.node_name, args.client_name, args.network)
     read_copy_ledger_data_dir = None
     try:
-        read_copy_ledger_data_dir = make_copy_of_ledger(ledger_data_dir)
-        ledger = get_ledger(args.type, read_copy_ledger_data_dir)
+        # RocksDB supports real read-only mode and does not need to have a ledger copy.
+        if config.hashStore['type'].lower() != HS_ROCKSDB:
+            # NOTE: such approach works well only for small ledgers.
+            tmp = make_copy_of_ledger(ledger_data_dir)",37,2018-04-28 14:01:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/184854609,https://github.com/hyperledger/indy-node/pull/677#discussion_r184854609,sergey-shilov
https://github.com/hyperledger/indy-node/pull/672,https://github.com/hyperledger/indy-node/pull/672,"Maybe we should use some valid versions as default values, otherwise it's easy to forget to change them",8043faa52bc3397e46f1f762c97bb15c13e7f185,2018-04-28 11:05:45,184849886,"@@ -1,8 +1,12 @@
 - hosts: pool
+  gather_facts: no
 
   vars:
     pool_prefix: live_node
     pool_size: ""{{ groups['pool']|count }}""
+    node_ver: 1.3.388",7,2018-04-28 11:05:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/184849886,https://github.com/hyperledger/indy-node/pull/672#discussion_r184849886,ashcherbakov
https://github.com/hyperledger/indy-node/pull/672,https://github.com/hyperledger/indy-node/pull/672,"@ashcherbakov this is version I'm currently using in test pool, so it should be valid unless I misunderstand something. What should be really done is separation of configurable variables from playbooks, which is out of scope of this PR.",8043faa52bc3397e46f1f762c97bb15c13e7f185,2018-04-28 11:09:46,184849968,"@@ -1,8 +1,12 @@
 - hosts: pool
+  gather_facts: no
 
   vars:
     pool_prefix: live_node
     pool_size: ""{{ groups['pool']|count }}""
+    node_ver: 1.3.388",7,2018-04-28 11:09:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/184849968,https://github.com/hyperledger/indy-node/pull/672#discussion_r184849968,skhoroshavin
https://github.com/hyperledger/indy-node/pull/669,https://github.com/hyperledger/indy-node/pull/669,Do not delete this test,e9acaed50aa463b0b61875d6c1fd7165068cf6ff,2018-04-27 07:15:16,184608981,"@@ -1,365 +1,114 @@
+import json
 import pytest
-from plenum.common.signer_did import DidSigner
-from plenum.common.signer_simple import SimpleSigner
-from indy_client.client.wallet.wallet import Wallet
-from indy_client.test.cli.helper import prompt_is, addNym, ensureConnectedToTestEnv, createUuidIdentifier, \
-    createHalfKeyIdentifierAndAbbrevVerkey
-from indy_common.roles import Roles
-from plenum.common.constants import TARGET_NYM
-from indy_node.test.did.conftest import wallet, abbrevVerkey
-from indy_client.test.cli.helper import connect_and_check_output
 
+from indy.did import create_and_store_my_did, replace_keys_start, replace_keys_apply
+from indy.ledger import build_get_nym_request
+from indy_common.constants import TRUST_ANCHOR_STRING
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.helper import sdk_get_and_check_replies
+from plenum.test.pool_transactions.helper import sdk_sign_and_send_prepared_request, \
+    prepare_nym_request
 
-TRUST_ANCHOR_SEED = b'TRUST0NO0ONE00000000000000000000'
+TRUST_ANCHOR_SEED = 'TRUST0NO0ONE00000000000000000001'
 
-NYM_ADDED = 'Nym {dest} added'
-CURRENT_VERKEY_FOR_NYM = 'Current verkey for NYM {dest} is {verkey}'
-NOT_OWNER = 'is neither Trustee nor owner of'
 
-
-@pytest.fixture(""module"")
-def trust_anchor_did_signer():
-    return DidSigner(seed=TRUST_ANCHOR_SEED)
-
-
-@pytest.fixture(""module"")
-def trust_anchor_cid_signer():
-    return SimpleSigner(seed=TRUST_ANCHOR_SEED)
+def set_verkey(looper, sdk_pool_handle, sdk_wallet_sender, dest, verkey):
+    wh, _ = sdk_wallet_sender
+    nym_request, new_did = looper.loop.run_until_complete(
+        prepare_nym_request(sdk_wallet_sender, None,
+                            None, TRUST_ANCHOR_STRING, dest, verkey, False if verkey else True))
+    request_couple = sdk_sign_and_send_prepared_request(looper, sdk_wallet_sender,
+                                                        sdk_pool_handle, nym_request)
+    sdk_get_and_check_replies(looper, [request_couple])
+    return wh, new_did
 
 
 @pytest.fixture(""module"")
-def trustAnchorWallet(trustAnchorSigner):
-    w = Wallet(trustAnchorSigner.identifier)
-    w.addIdentifier(signer=trustAnchorSigner)
-    return w
-
-
-def testPoolNodesStarted(poolNodesStarted):",,2018-04-27 08:48:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/184608981,https://github.com/hyperledger/indy-node/pull/669#discussion_r184608981,dsurnin
https://github.com/hyperledger/indy-node/pull/669,https://github.com/hyperledger/indy-node/pull/669,Rewrite this test,e9acaed50aa463b0b61875d6c1fd7165068cf6ff,2018-04-27 07:37:32,184612985,"@@ -1,365 +1,114 @@
+import json
 import pytest
-from plenum.common.signer_did import DidSigner
-from plenum.common.signer_simple import SimpleSigner
-from indy_client.client.wallet.wallet import Wallet
-from indy_client.test.cli.helper import prompt_is, addNym, ensureConnectedToTestEnv, createUuidIdentifier, \
-    createHalfKeyIdentifierAndAbbrevVerkey
-from indy_common.roles import Roles
-from plenum.common.constants import TARGET_NYM
-from indy_node.test.did.conftest import wallet, abbrevVerkey
-from indy_client.test.cli.helper import connect_and_check_output
 
+from indy.did import create_and_store_my_did, replace_keys_start, replace_keys_apply
+from indy.ledger import build_get_nym_request
+from indy_common.constants import TRUST_ANCHOR_STRING
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.helper import sdk_get_and_check_replies
+from plenum.test.pool_transactions.helper import sdk_sign_and_send_prepared_request, \
+    prepare_nym_request
 
-TRUST_ANCHOR_SEED = b'TRUST0NO0ONE00000000000000000000'
+TRUST_ANCHOR_SEED = 'TRUST0NO0ONE00000000000000000001'
 
-NYM_ADDED = 'Nym {dest} added'
-CURRENT_VERKEY_FOR_NYM = 'Current verkey for NYM {dest} is {verkey}'
-NOT_OWNER = 'is neither Trustee nor owner of'
 
-
-@pytest.fixture(""module"")
-def trust_anchor_did_signer():
-    return DidSigner(seed=TRUST_ANCHOR_SEED)
-
-
-@pytest.fixture(""module"")
-def trust_anchor_cid_signer():
-    return SimpleSigner(seed=TRUST_ANCHOR_SEED)
+def set_verkey(looper, sdk_pool_handle, sdk_wallet_sender, dest, verkey):
+    wh, _ = sdk_wallet_sender
+    nym_request, new_did = looper.loop.run_until_complete(
+        prepare_nym_request(sdk_wallet_sender, None,
+                            None, TRUST_ANCHOR_STRING, dest, verkey, False if verkey else True))
+    request_couple = sdk_sign_and_send_prepared_request(looper, sdk_wallet_sender,
+                                                        sdk_pool_handle, nym_request)
+    sdk_get_and_check_replies(looper, [request_couple])
+    return wh, new_did
 
 
 @pytest.fixture(""module"")
-def trustAnchorWallet(trustAnchorSigner):
-    w = Wallet(trustAnchorSigner.identifier)
-    w.addIdentifier(signer=trustAnchorSigner)
-    return w
-
-
-def testPoolNodesStarted(poolNodesStarted):
-    pass
-
-
-@pytest.fixture(scope=""module"")
-def aliceCli(be, do, poolNodesStarted, aliceCLI, wallet):
-    be(aliceCLI)
-    do('prompt Alice', expect=prompt_is('Alice'))
-    addAndActivateCLIWallet(aliceCLI, wallet)
-    connect_and_check_output(do, aliceCLI.txn_dir)
-    return aliceCLI
-
-
-@pytest.fixture(scope=""module"")
-def trustAnchorCli(be, do, poolNodesStarted, earlCLI,
-                   trustAnchorWallet):
-    be(earlCLI)
-    do('prompt Earl', expect=prompt_is('Earl'))
-    addAndActivateCLIWallet(earlCLI, trustAnchorWallet)
-    connect_and_check_output(do, earlCLI.txn_dir)
-    return earlCLI
-
-
-def getNym(be, do, userCli, idr, expectedMsgs):
-    be(userCli)
-    do('send GET_NYM dest={}'.format(idr),
-       within=3,
-       expect=expectedMsgs
-       )
-
-
-def getNymNotFoundExpectedMsgs(idr):
-    return [""NYM {} not found"".format(idr)]
-
-
-def testGetDIDWithoutAddingIt(be, do, philCli, trust_anchor_did_signer):
-    ensureConnectedToTestEnv(be, do, philCli)
-    getNym(be, do, philCli, trust_anchor_did_signer.identifier,
-           getNymNotFoundExpectedMsgs(trust_anchor_did_signer.identifier))
-
-
-def testGetCIDWithoutAddingIt(be, do, philCli, trust_anchor_cid_signer):
-    ensureConnectedToTestEnv(be, do, philCli)
-    getNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           getNymNotFoundExpectedMsgs(trust_anchor_cid_signer.identifier))
-
+def trust_anchor_did_verkey(looper, sdk_wallet_client):
+    wh, _ = sdk_wallet_client
+    named_did, verkey = looper.loop.run_until_complete(
+        create_and_store_my_did(wh, json.dumps({'seed': TRUST_ANCHOR_SEED})))
+    return named_did, verkey
 
-def addAndActivateCLIWallet(cli, wallet):
-    cli.wallets[wallet.name] = wallet
-    cli.activeWallet = wallet
 
-
-@pytest.fixture(scope=""module"")
-def didAdded(be, do, philCli, trust_anchor_did_signer):
-    ensureConnectedToTestEnv(be, do, philCli)
-    addNym(be, do, philCli,
-           trust_anchor_did_signer.identifier,
-           role=Roles.TRUST_ANCHOR.name
-           )
-    return philCli
+def get_nym(looper, sdk_pool_handle, sdk_wallet_steward, t_did):
+    _, s_did = sdk_wallet_steward
+    get_nym_req = looper.loop.run_until_complete(build_get_nym_request(s_did, t_did))
+    req = sdk_sign_and_send_prepared_request(looper, sdk_wallet_steward,
+                                             sdk_pool_handle, get_nym_req)
+    return sdk_get_and_check_replies(looper, [req])
 
 
-def testAddDID(didAdded):
-    pass
+def test_get_nym_without_adding_it(looper, sdk_pool_handle, sdk_wallet_steward,
+                                   trust_anchor_did_verkey):
+    t_did, _ = trust_anchor_did_verkey
+    rep = get_nym(looper, sdk_pool_handle, sdk_wallet_steward, t_did)
+    assert not rep[0][1]['result']['data']
 
 
 @pytest.fixture(scope=""module"")
-def cidAdded(be, do, philCli, trust_anchor_cid_signer):
-    addNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           role=Roles.TRUST_ANCHOR.name)
-    return philCli
+def nym_added(looper, sdk_pool_handle, sdk_wallet_steward, trust_anchor_did_verkey):
+    dest, _ = trust_anchor_did_verkey
+    set_verkey(looper, sdk_pool_handle, sdk_wallet_steward, dest, None)
 
 
-def testAddCID(cidAdded):
+def test_add_nym(nym_added):
     pass
 
 
-def getNoVerkeyEverAssignedMsgs(idr):
-    return [""No verkey ever assigned to the DID {}"".format(idr)]
-
-
-def testGetDIDWithoutVerkey(be, do, philCli, didAdded,
-                            trust_anchor_did_signer):
-    getNym(be, do, philCli, trust_anchor_did_signer.identifier,
-           getNoVerkeyEverAssignedMsgs(trust_anchor_did_signer.identifier))
-
-
-def getVerkeyIsSameAsIdentifierMsgs(idr):
-    return [""Current verkey is same as DID {}"".format(idr)]
-
-
-def testGetCIDWithoutVerkey(be, do, philCli, cidAdded,
-                            trust_anchor_cid_signer):
-    getNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           getVerkeyIsSameAsIdentifierMsgs(trust_anchor_cid_signer.identifier))
+def test_get_nym_without_verkey(looper, sdk_pool_handle, sdk_wallet_steward, nym_added,
+                                trust_anchor_did_verkey):
+    t_did, _ = trust_anchor_did_verkey
+    rep = get_nym(looper, sdk_pool_handle, sdk_wallet_steward, t_did)
+    assert rep[0][1]['result']['data']
+    assert not json.loads(rep[0][1]['result']['data'])['verkey']
 
 
 @pytest.fixture(scope=""module"")
-def verkeyAddedToDID(be, do, philCli, didAdded, trust_anchor_did_signer):
-    addNym(be, do, philCli, trust_anchor_did_signer.identifier,
-           trust_anchor_did_signer.verkey)
+def verkey_added_to_nym(looper, sdk_pool_handle, sdk_wallet_steward, nym_added, trust_anchor_did_verkey):
+    wh, _ = sdk_wallet_steward
+    did, _ = trust_anchor_did_verkey
+    verkey = looper.loop.run_until_complete(replace_keys_start(wh, did, json.dumps({'': ''})))
+    set_verkey(looper, sdk_pool_handle, sdk_wallet_steward, did, verkey)
+    looper.loop.run_until_complete(replace_keys_apply(wh, did))
 
 
-def testAddVerkeyToExistingDID(verkeyAddedToDID):
+def test_add_verkey_to_existing_nym(verkey_added_to_nym):
     pass
 
 
-@pytest.fixture(scope=""module"")
-def verkeyAddedToCID(be, do, philCli, cidAdded, trust_anchor_cid_signer):
-    # newSigner = SimpleSigner(identifier=trust_anchor_cid_signer.identifier)
-    # new_verkey = newSigner.verkey
-
-    addNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           verkey=trust_anchor_cid_signer.verkey)
-    return trust_anchor_cid_signer
-
-
-def testAddVerkeyToExistingCID(verkeyAddedToCID):
-    pass
-
-
-def getCurrentVerkeyIsgMsgs(idr, verkey):
-    return [""Current verkey for NYM {} is {}"".format(idr, verkey)]
-
-
-def testGetDIDWithVerKey(be, do, philCli, verkeyAddedToDID,
-                         trust_anchor_did_signer):
-    getNym(be, do, philCli, trust_anchor_did_signer.identifier,
-           getCurrentVerkeyIsgMsgs(trust_anchor_did_signer.identifier,
-                                   trust_anchor_did_signer.verkey))
-
-
-def testGetCIDWithVerKey(be, do, philCli, verkeyAddedToCID,
-                         trust_anchor_cid_signer):
-    getNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           getCurrentVerkeyIsgMsgs(trust_anchor_cid_signer.identifier,
-                                   trust_anchor_cid_signer.verkey))
-
-
-def getNoActiveVerkeyFoundMsgs(idr):
-    return [""No active verkey found for the identifier {}"".format(idr)]
-
+def test_get_did_with_verkey(looper, sdk_pool_handle, sdk_wallet_steward, verkey_added_to_nym,
+                             trust_anchor_did_verkey):
+    t_did, _ = trust_anchor_did_verkey
+    rep = get_nym(looper, sdk_pool_handle, sdk_wallet_steward, t_did)
+    assert rep[0][1]['result']['data']
+    assert json.loads(rep[0][1]['result']['data'])['verkey']
 
-def addAttribToNym(be, do, userCli, idr, raw):
-    be(userCli)
-    do('send ATTRIB dest={} raw={}'.format(idr, raw),
-       within=5,
-       expect=[""Attribute added for nym {}"".format(idr)])
 
-
-@pytest.mark.skip(""INDY- This should not have worked"")
-def testSendAttribForDID(be, do, verkeyAddedToDID,
-                         trust_anchor_did_signer, aliceCli):
+def test_send_attrib_for_did(looper, sdk_pool_handle, sdk_wallet_steward,
+                             verkey_added_to_nym, trust_anchor_did_verkey):
     raw = '{""name"": ""Alice""}'
-    addAttribToNym(be, do, aliceCli, trust_anchor_did_signer.identifier, raw)
-
-
-@pytest.mark.skip(""INDY- This should not have worked"")
-def testSendAttribForCID(be, do, verkeyAddedToCID,
-                         trust_anchor_cid_signer, trustAnchorCli):
-    raw = '{""name"": ""Earl""}'
-    addAttribToNym(be, do, trustAnchorCli,
-                   trust_anchor_cid_signer.identifier, raw)
-
-
-@pytest.fixture(scope=""module"")
-def verkeyRemovedFromExistingDID(
-        be, do, verkeyAddedToDID, abbrevIdr, aliceCli):
-    be(aliceCli)
-    addNym(be, do, aliceCli, abbrevIdr, '')
-    getNym(be, do, aliceCli, abbrevIdr, getNoActiveVerkeyFoundMsgs(abbrevIdr))
-
-
-@pytest.mark.skip(reason=""verkey removal is not supported"")
-def testRemoveVerkeyFromDID(verkeyRemovedFromExistingDID):
-    pass
+    dest, _ = trust_anchor_did_verkey
+    wh, _ = sdk_wallet_steward
+    sdk_add_attribute_and_check(looper, sdk_pool_handle, (wh, dest), raw, dest)
 
 
 @pytest.fixture(scope=""module"")
-def verkeyRemovedFromExistingCID(
-        be,
-        do,
-        verkeyAddedToCID,
-        trustAnchorSigner,
-        trustAnchorCli,
-        trustAnchorWallet):
-    be(trustAnchorCli)
-    addNym(be, do, trustAnchorCli, trustAnchorSigner.identifier, '')
-    getNym(be, do, trustAnchorCli, trustAnchorSigner.identifier,
-           getNoActiveVerkeyFoundMsgs(trustAnchorSigner.identifier))
+def verkey_removed_from_existing_did(looper, sdk_pool_handle, sdk_wallet_steward,
+                                     verkey_added_to_nym, trust_anchor_did_verkey):
+    did, _ = trust_anchor_did_verkey
+    wh, _ = sdk_wallet_steward
+    set_verkey(looper, sdk_pool_handle, (wh, did), did, None)
 
 
-@pytest.mark.skip(reason=""verkey removal is not supported"")
-def testRemoveVerkeyFromCID(verkeyRemovedFromExistingCID):
+def test_remove_verkey_from_did(verkey_removed_from_existing_did):
     pass
 
 
 @pytest.mark.skip(
     reason=""SOV-568. Obsolete assumption, if an identity has set ""
-    ""its verkey to blank, no-one including ""
-    ""itself can change it"")
-def testNewverkeyAddedToDID(be, do, philCli, abbrevIdr,
-                            verkeyRemovedFromExistingDID):
-    newSigner = DidSigner()
-    addNym(be, do, philCli, abbrevIdr, newSigner.verkey)
-    getNym(be, do, philCli, abbrevIdr,
-           getCurrentVerkeyIsgMsgs(abbrevIdr, newSigner.verkey))
-
-
-@pytest.mark.skip(
-    reason=""SOV-568. Obsolete assumption, if an identity has set ""
-    ""its verkey to blank, no-one including ""
-    ""itself can change it"")
-def testNewverkeyAddedToCID(be, do, philCli, trustAnchorSigner,
-                            verkeyRemovedFromExistingCID):
-    newSigner = DidSigner()
-    addNym(be, do, philCli, trustAnchorSigner.identifier, newSigner.verkey)
-    getNym(
-        be,
-        do,
-        philCli,
-        trustAnchorSigner.identifier,
-        getCurrentVerkeyIsgMsgs(
-            trustAnchorSigner.identifier,
-            newSigner.verkey))
-
-
-def testNewKeyChangesWalletsDefaultId(be, do, poolNodesStarted, poolTxnData,
-                                      susanCLI):
-    mywallet = Wallet('my wallet')
-    keyseed = 'a' * 32
-    idr, _ = mywallet.addIdentifier(seed=keyseed.encode(""utf-8""))
-
-    be(susanCLI)
-
-    connect_and_check_output(do, susanCLI.txn_dir)
-
-    do('new key with seed {}'.format(keyseed))
-
-    do('send NYM dest={}'.format(idr))
-
-    do('new key with seed {}'.format(poolTxnData['seeds']['Steward1']))
-
-    do('send NYM dest={}'.format(idr), within=3,
-       expect=[""Nym {} added"".format(idr)])
-
-
-def test_send_same_nyms_only_first_gets_written(",370,2018-04-27 08:48:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/184612985,https://github.com/hyperledger/indy-node/pull/669#discussion_r184612985,dsurnin
https://github.com/hyperledger/indy-node/pull/669,https://github.com/hyperledger/indy-node/pull/669,Test rewritten,e9acaed50aa463b0b61875d6c1fd7165068cf6ff,2018-04-27 08:44:16,184626729,"@@ -1,365 +1,114 @@
+import json
 import pytest
-from plenum.common.signer_did import DidSigner
-from plenum.common.signer_simple import SimpleSigner
-from indy_client.client.wallet.wallet import Wallet
-from indy_client.test.cli.helper import prompt_is, addNym, ensureConnectedToTestEnv, createUuidIdentifier, \
-    createHalfKeyIdentifierAndAbbrevVerkey
-from indy_common.roles import Roles
-from plenum.common.constants import TARGET_NYM
-from indy_node.test.did.conftest import wallet, abbrevVerkey
-from indy_client.test.cli.helper import connect_and_check_output
 
+from indy.did import create_and_store_my_did, replace_keys_start, replace_keys_apply
+from indy.ledger import build_get_nym_request
+from indy_common.constants import TRUST_ANCHOR_STRING
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.helper import sdk_get_and_check_replies
+from plenum.test.pool_transactions.helper import sdk_sign_and_send_prepared_request, \
+    prepare_nym_request
 
-TRUST_ANCHOR_SEED = b'TRUST0NO0ONE00000000000000000000'
+TRUST_ANCHOR_SEED = 'TRUST0NO0ONE00000000000000000001'
 
-NYM_ADDED = 'Nym {dest} added'
-CURRENT_VERKEY_FOR_NYM = 'Current verkey for NYM {dest} is {verkey}'
-NOT_OWNER = 'is neither Trustee nor owner of'
 
-
-@pytest.fixture(""module"")
-def trust_anchor_did_signer():
-    return DidSigner(seed=TRUST_ANCHOR_SEED)
-
-
-@pytest.fixture(""module"")
-def trust_anchor_cid_signer():
-    return SimpleSigner(seed=TRUST_ANCHOR_SEED)
+def set_verkey(looper, sdk_pool_handle, sdk_wallet_sender, dest, verkey):
+    wh, _ = sdk_wallet_sender
+    nym_request, new_did = looper.loop.run_until_complete(
+        prepare_nym_request(sdk_wallet_sender, None,
+                            None, TRUST_ANCHOR_STRING, dest, verkey, False if verkey else True))
+    request_couple = sdk_sign_and_send_prepared_request(looper, sdk_wallet_sender,
+                                                        sdk_pool_handle, nym_request)
+    sdk_get_and_check_replies(looper, [request_couple])
+    return wh, new_did
 
 
 @pytest.fixture(""module"")
-def trustAnchorWallet(trustAnchorSigner):
-    w = Wallet(trustAnchorSigner.identifier)
-    w.addIdentifier(signer=trustAnchorSigner)
-    return w
-
-
-def testPoolNodesStarted(poolNodesStarted):",,2018-04-27 08:48:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/184626729,https://github.com/hyperledger/indy-node/pull/669#discussion_r184626729,ArtObr
https://github.com/hyperledger/indy-node/pull/669,https://github.com/hyperledger/indy-node/pull/669,Test rewritten,e9acaed50aa463b0b61875d6c1fd7165068cf6ff,2018-04-27 08:44:23,184626756,"@@ -1,365 +1,114 @@
+import json
 import pytest
-from plenum.common.signer_did import DidSigner
-from plenum.common.signer_simple import SimpleSigner
-from indy_client.client.wallet.wallet import Wallet
-from indy_client.test.cli.helper import prompt_is, addNym, ensureConnectedToTestEnv, createUuidIdentifier, \
-    createHalfKeyIdentifierAndAbbrevVerkey
-from indy_common.roles import Roles
-from plenum.common.constants import TARGET_NYM
-from indy_node.test.did.conftest import wallet, abbrevVerkey
-from indy_client.test.cli.helper import connect_and_check_output
 
+from indy.did import create_and_store_my_did, replace_keys_start, replace_keys_apply
+from indy.ledger import build_get_nym_request
+from indy_common.constants import TRUST_ANCHOR_STRING
+from indy_node.test.helper import sdk_add_attribute_and_check
+from plenum.test.helper import sdk_get_and_check_replies
+from plenum.test.pool_transactions.helper import sdk_sign_and_send_prepared_request, \
+    prepare_nym_request
 
-TRUST_ANCHOR_SEED = b'TRUST0NO0ONE00000000000000000000'
+TRUST_ANCHOR_SEED = 'TRUST0NO0ONE00000000000000000001'
 
-NYM_ADDED = 'Nym {dest} added'
-CURRENT_VERKEY_FOR_NYM = 'Current verkey for NYM {dest} is {verkey}'
-NOT_OWNER = 'is neither Trustee nor owner of'
 
-
-@pytest.fixture(""module"")
-def trust_anchor_did_signer():
-    return DidSigner(seed=TRUST_ANCHOR_SEED)
-
-
-@pytest.fixture(""module"")
-def trust_anchor_cid_signer():
-    return SimpleSigner(seed=TRUST_ANCHOR_SEED)
+def set_verkey(looper, sdk_pool_handle, sdk_wallet_sender, dest, verkey):
+    wh, _ = sdk_wallet_sender
+    nym_request, new_did = looper.loop.run_until_complete(
+        prepare_nym_request(sdk_wallet_sender, None,
+                            None, TRUST_ANCHOR_STRING, dest, verkey, False if verkey else True))
+    request_couple = sdk_sign_and_send_prepared_request(looper, sdk_wallet_sender,
+                                                        sdk_pool_handle, nym_request)
+    sdk_get_and_check_replies(looper, [request_couple])
+    return wh, new_did
 
 
 @pytest.fixture(""module"")
-def trustAnchorWallet(trustAnchorSigner):
-    w = Wallet(trustAnchorSigner.identifier)
-    w.addIdentifier(signer=trustAnchorSigner)
-    return w
-
-
-def testPoolNodesStarted(poolNodesStarted):
-    pass
-
-
-@pytest.fixture(scope=""module"")
-def aliceCli(be, do, poolNodesStarted, aliceCLI, wallet):
-    be(aliceCLI)
-    do('prompt Alice', expect=prompt_is('Alice'))
-    addAndActivateCLIWallet(aliceCLI, wallet)
-    connect_and_check_output(do, aliceCLI.txn_dir)
-    return aliceCLI
-
-
-@pytest.fixture(scope=""module"")
-def trustAnchorCli(be, do, poolNodesStarted, earlCLI,
-                   trustAnchorWallet):
-    be(earlCLI)
-    do('prompt Earl', expect=prompt_is('Earl'))
-    addAndActivateCLIWallet(earlCLI, trustAnchorWallet)
-    connect_and_check_output(do, earlCLI.txn_dir)
-    return earlCLI
-
-
-def getNym(be, do, userCli, idr, expectedMsgs):
-    be(userCli)
-    do('send GET_NYM dest={}'.format(idr),
-       within=3,
-       expect=expectedMsgs
-       )
-
-
-def getNymNotFoundExpectedMsgs(idr):
-    return [""NYM {} not found"".format(idr)]
-
-
-def testGetDIDWithoutAddingIt(be, do, philCli, trust_anchor_did_signer):
-    ensureConnectedToTestEnv(be, do, philCli)
-    getNym(be, do, philCli, trust_anchor_did_signer.identifier,
-           getNymNotFoundExpectedMsgs(trust_anchor_did_signer.identifier))
-
-
-def testGetCIDWithoutAddingIt(be, do, philCli, trust_anchor_cid_signer):
-    ensureConnectedToTestEnv(be, do, philCli)
-    getNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           getNymNotFoundExpectedMsgs(trust_anchor_cid_signer.identifier))
-
+def trust_anchor_did_verkey(looper, sdk_wallet_client):
+    wh, _ = sdk_wallet_client
+    named_did, verkey = looper.loop.run_until_complete(
+        create_and_store_my_did(wh, json.dumps({'seed': TRUST_ANCHOR_SEED})))
+    return named_did, verkey
 
-def addAndActivateCLIWallet(cli, wallet):
-    cli.wallets[wallet.name] = wallet
-    cli.activeWallet = wallet
 
-
-@pytest.fixture(scope=""module"")
-def didAdded(be, do, philCli, trust_anchor_did_signer):
-    ensureConnectedToTestEnv(be, do, philCli)
-    addNym(be, do, philCli,
-           trust_anchor_did_signer.identifier,
-           role=Roles.TRUST_ANCHOR.name
-           )
-    return philCli
+def get_nym(looper, sdk_pool_handle, sdk_wallet_steward, t_did):
+    _, s_did = sdk_wallet_steward
+    get_nym_req = looper.loop.run_until_complete(build_get_nym_request(s_did, t_did))
+    req = sdk_sign_and_send_prepared_request(looper, sdk_wallet_steward,
+                                             sdk_pool_handle, get_nym_req)
+    return sdk_get_and_check_replies(looper, [req])
 
 
-def testAddDID(didAdded):
-    pass
+def test_get_nym_without_adding_it(looper, sdk_pool_handle, sdk_wallet_steward,
+                                   trust_anchor_did_verkey):
+    t_did, _ = trust_anchor_did_verkey
+    rep = get_nym(looper, sdk_pool_handle, sdk_wallet_steward, t_did)
+    assert not rep[0][1]['result']['data']
 
 
 @pytest.fixture(scope=""module"")
-def cidAdded(be, do, philCli, trust_anchor_cid_signer):
-    addNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           role=Roles.TRUST_ANCHOR.name)
-    return philCli
+def nym_added(looper, sdk_pool_handle, sdk_wallet_steward, trust_anchor_did_verkey):
+    dest, _ = trust_anchor_did_verkey
+    set_verkey(looper, sdk_pool_handle, sdk_wallet_steward, dest, None)
 
 
-def testAddCID(cidAdded):
+def test_add_nym(nym_added):
     pass
 
 
-def getNoVerkeyEverAssignedMsgs(idr):
-    return [""No verkey ever assigned to the DID {}"".format(idr)]
-
-
-def testGetDIDWithoutVerkey(be, do, philCli, didAdded,
-                            trust_anchor_did_signer):
-    getNym(be, do, philCli, trust_anchor_did_signer.identifier,
-           getNoVerkeyEverAssignedMsgs(trust_anchor_did_signer.identifier))
-
-
-def getVerkeyIsSameAsIdentifierMsgs(idr):
-    return [""Current verkey is same as DID {}"".format(idr)]
-
-
-def testGetCIDWithoutVerkey(be, do, philCli, cidAdded,
-                            trust_anchor_cid_signer):
-    getNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           getVerkeyIsSameAsIdentifierMsgs(trust_anchor_cid_signer.identifier))
+def test_get_nym_without_verkey(looper, sdk_pool_handle, sdk_wallet_steward, nym_added,
+                                trust_anchor_did_verkey):
+    t_did, _ = trust_anchor_did_verkey
+    rep = get_nym(looper, sdk_pool_handle, sdk_wallet_steward, t_did)
+    assert rep[0][1]['result']['data']
+    assert not json.loads(rep[0][1]['result']['data'])['verkey']
 
 
 @pytest.fixture(scope=""module"")
-def verkeyAddedToDID(be, do, philCli, didAdded, trust_anchor_did_signer):
-    addNym(be, do, philCli, trust_anchor_did_signer.identifier,
-           trust_anchor_did_signer.verkey)
+def verkey_added_to_nym(looper, sdk_pool_handle, sdk_wallet_steward, nym_added, trust_anchor_did_verkey):
+    wh, _ = sdk_wallet_steward
+    did, _ = trust_anchor_did_verkey
+    verkey = looper.loop.run_until_complete(replace_keys_start(wh, did, json.dumps({'': ''})))
+    set_verkey(looper, sdk_pool_handle, sdk_wallet_steward, did, verkey)
+    looper.loop.run_until_complete(replace_keys_apply(wh, did))
 
 
-def testAddVerkeyToExistingDID(verkeyAddedToDID):
+def test_add_verkey_to_existing_nym(verkey_added_to_nym):
     pass
 
 
-@pytest.fixture(scope=""module"")
-def verkeyAddedToCID(be, do, philCli, cidAdded, trust_anchor_cid_signer):
-    # newSigner = SimpleSigner(identifier=trust_anchor_cid_signer.identifier)
-    # new_verkey = newSigner.verkey
-
-    addNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           verkey=trust_anchor_cid_signer.verkey)
-    return trust_anchor_cid_signer
-
-
-def testAddVerkeyToExistingCID(verkeyAddedToCID):
-    pass
-
-
-def getCurrentVerkeyIsgMsgs(idr, verkey):
-    return [""Current verkey for NYM {} is {}"".format(idr, verkey)]
-
-
-def testGetDIDWithVerKey(be, do, philCli, verkeyAddedToDID,
-                         trust_anchor_did_signer):
-    getNym(be, do, philCli, trust_anchor_did_signer.identifier,
-           getCurrentVerkeyIsgMsgs(trust_anchor_did_signer.identifier,
-                                   trust_anchor_did_signer.verkey))
-
-
-def testGetCIDWithVerKey(be, do, philCli, verkeyAddedToCID,
-                         trust_anchor_cid_signer):
-    getNym(be, do, philCli, trust_anchor_cid_signer.identifier,
-           getCurrentVerkeyIsgMsgs(trust_anchor_cid_signer.identifier,
-                                   trust_anchor_cid_signer.verkey))
-
-
-def getNoActiveVerkeyFoundMsgs(idr):
-    return [""No active verkey found for the identifier {}"".format(idr)]
-
+def test_get_did_with_verkey(looper, sdk_pool_handle, sdk_wallet_steward, verkey_added_to_nym,
+                             trust_anchor_did_verkey):
+    t_did, _ = trust_anchor_did_verkey
+    rep = get_nym(looper, sdk_pool_handle, sdk_wallet_steward, t_did)
+    assert rep[0][1]['result']['data']
+    assert json.loads(rep[0][1]['result']['data'])['verkey']
 
-def addAttribToNym(be, do, userCli, idr, raw):
-    be(userCli)
-    do('send ATTRIB dest={} raw={}'.format(idr, raw),
-       within=5,
-       expect=[""Attribute added for nym {}"".format(idr)])
 
-
-@pytest.mark.skip(""INDY- This should not have worked"")
-def testSendAttribForDID(be, do, verkeyAddedToDID,
-                         trust_anchor_did_signer, aliceCli):
+def test_send_attrib_for_did(looper, sdk_pool_handle, sdk_wallet_steward,
+                             verkey_added_to_nym, trust_anchor_did_verkey):
     raw = '{""name"": ""Alice""}'
-    addAttribToNym(be, do, aliceCli, trust_anchor_did_signer.identifier, raw)
-
-
-@pytest.mark.skip(""INDY- This should not have worked"")
-def testSendAttribForCID(be, do, verkeyAddedToCID,
-                         trust_anchor_cid_signer, trustAnchorCli):
-    raw = '{""name"": ""Earl""}'
-    addAttribToNym(be, do, trustAnchorCli,
-                   trust_anchor_cid_signer.identifier, raw)
-
-
-@pytest.fixture(scope=""module"")
-def verkeyRemovedFromExistingDID(
-        be, do, verkeyAddedToDID, abbrevIdr, aliceCli):
-    be(aliceCli)
-    addNym(be, do, aliceCli, abbrevIdr, '')
-    getNym(be, do, aliceCli, abbrevIdr, getNoActiveVerkeyFoundMsgs(abbrevIdr))
-
-
-@pytest.mark.skip(reason=""verkey removal is not supported"")
-def testRemoveVerkeyFromDID(verkeyRemovedFromExistingDID):
-    pass
+    dest, _ = trust_anchor_did_verkey
+    wh, _ = sdk_wallet_steward
+    sdk_add_attribute_and_check(looper, sdk_pool_handle, (wh, dest), raw, dest)
 
 
 @pytest.fixture(scope=""module"")
-def verkeyRemovedFromExistingCID(
-        be,
-        do,
-        verkeyAddedToCID,
-        trustAnchorSigner,
-        trustAnchorCli,
-        trustAnchorWallet):
-    be(trustAnchorCli)
-    addNym(be, do, trustAnchorCli, trustAnchorSigner.identifier, '')
-    getNym(be, do, trustAnchorCli, trustAnchorSigner.identifier,
-           getNoActiveVerkeyFoundMsgs(trustAnchorSigner.identifier))
+def verkey_removed_from_existing_did(looper, sdk_pool_handle, sdk_wallet_steward,
+                                     verkey_added_to_nym, trust_anchor_did_verkey):
+    did, _ = trust_anchor_did_verkey
+    wh, _ = sdk_wallet_steward
+    set_verkey(looper, sdk_pool_handle, (wh, did), did, None)
 
 
-@pytest.mark.skip(reason=""verkey removal is not supported"")
-def testRemoveVerkeyFromCID(verkeyRemovedFromExistingCID):
+def test_remove_verkey_from_did(verkey_removed_from_existing_did):
     pass
 
 
 @pytest.mark.skip(
     reason=""SOV-568. Obsolete assumption, if an identity has set ""
-    ""its verkey to blank, no-one including ""
-    ""itself can change it"")
-def testNewverkeyAddedToDID(be, do, philCli, abbrevIdr,
-                            verkeyRemovedFromExistingDID):
-    newSigner = DidSigner()
-    addNym(be, do, philCli, abbrevIdr, newSigner.verkey)
-    getNym(be, do, philCli, abbrevIdr,
-           getCurrentVerkeyIsgMsgs(abbrevIdr, newSigner.verkey))
-
-
-@pytest.mark.skip(
-    reason=""SOV-568. Obsolete assumption, if an identity has set ""
-    ""its verkey to blank, no-one including ""
-    ""itself can change it"")
-def testNewverkeyAddedToCID(be, do, philCli, trustAnchorSigner,
-                            verkeyRemovedFromExistingCID):
-    newSigner = DidSigner()
-    addNym(be, do, philCli, trustAnchorSigner.identifier, newSigner.verkey)
-    getNym(
-        be,
-        do,
-        philCli,
-        trustAnchorSigner.identifier,
-        getCurrentVerkeyIsgMsgs(
-            trustAnchorSigner.identifier,
-            newSigner.verkey))
-
-
-def testNewKeyChangesWalletsDefaultId(be, do, poolNodesStarted, poolTxnData,
-                                      susanCLI):
-    mywallet = Wallet('my wallet')
-    keyseed = 'a' * 32
-    idr, _ = mywallet.addIdentifier(seed=keyseed.encode(""utf-8""))
-
-    be(susanCLI)
-
-    connect_and_check_output(do, susanCLI.txn_dir)
-
-    do('new key with seed {}'.format(keyseed))
-
-    do('send NYM dest={}'.format(idr))
-
-    do('new key with seed {}'.format(poolTxnData['seeds']['Steward1']))
-
-    do('send NYM dest={}'.format(idr), within=3,
-       expect=[""Nym {} added"".format(idr)])
-
-
-def test_send_same_nyms_only_first_gets_written(",370,2018-04-27 08:48:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/184626756,https://github.com/hyperledger/indy-node/pull/669#discussion_r184626756,ArtObr
https://github.com/hyperledger/indy-node/pull/662,https://github.com/hyperledger/indy-node/pull/662,"I don't think this is a correct statement. This guide is for the old GSG, not the new one.",059dac0fe9a524875641ad2615e52e9e3fdd6894,2018-04-25 08:32:42,183978837,"@@ -1,14 +1,16 @@
 # Setting Up a Test Indy Network in VMs
 
+**WARNING:** Here use deprecated client. Please, use [new client from SDK](https://github.com/hyperledger/indy-sdk/tree/master/cli)
+
 When you're finished working through this document, you will be able to proceed through to the [*Getting
-Started Guide*](../../../../getting-started.md) or if you would like, you may continue setting up an actual Developer Environment connected to a sandbox by following these [instructions](https://github.com/hyperledger/indy-node/blob/master/environment/vagrant/sandbox/DevelopmentEnvironment/Virtualbox/Vagrantfile).
+Started Guide*](https://github.com/hyperledger/indy-sdk/blob/master/doc/getting-started/run-getting-started.md) or if you would like, you may continue setting up an actual Developer Environment connected to a sandbox by following these [instructions](https://github.com/hyperledger/indy-node/blob/master/environment/vagrant/sandbox/DevelopmentEnvironment/Virtualbox/Vagrantfile).",,2018-04-25 09:36:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/183978837,https://github.com/hyperledger/indy-node/pull/662#discussion_r183978837,ashcherbakov
https://github.com/hyperledger/indy-node/pull/662,https://github.com/hyperledger/indy-node/pull/662,"I would write it as follows:
**WARNING:** This guideline assumes using of a deprecated CLI and deprecated Getting Started Guide.
Please have a look at [new client from SDK](https://github.com/hyperledger/indy-sdk/tree/master/cli) and [new Getting Started Guide](...) instead.",059dac0fe9a524875641ad2615e52e9e3fdd6894,2018-04-25 08:34:28,183979339,"@@ -1,14 +1,16 @@
 # Setting Up a Test Indy Network in VMs
 
+**WARNING:** Here use deprecated client. Please, use [new client from SDK](https://github.com/hyperledger/indy-sdk/tree/master/cli)",,2018-04-25 09:36:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/183979339,https://github.com/hyperledger/indy-node/pull/662#discussion_r183979339,ashcherbakov
https://github.com/hyperledger/indy-node/pull/662,https://github.com/hyperledger/indy-node/pull/662,Will back to the old link. Are here should be link to a new GSG or warning about deprecated this GSG?,059dac0fe9a524875641ad2615e52e9e3fdd6894,2018-04-25 08:38:13,183980427,"@@ -1,14 +1,16 @@
 # Setting Up a Test Indy Network in VMs
 
+**WARNING:** Here use deprecated client. Please, use [new client from SDK](https://github.com/hyperledger/indy-sdk/tree/master/cli)
+
 When you're finished working through this document, you will be able to proceed through to the [*Getting
-Started Guide*](../../../../getting-started.md) or if you would like, you may continue setting up an actual Developer Environment connected to a sandbox by following these [instructions](https://github.com/hyperledger/indy-node/blob/master/environment/vagrant/sandbox/DevelopmentEnvironment/Virtualbox/Vagrantfile).
+Started Guide*](https://github.com/hyperledger/indy-sdk/blob/master/doc/getting-started/run-getting-started.md) or if you would like, you may continue setting up an actual Developer Environment connected to a sandbox by following these [instructions](https://github.com/hyperledger/indy-node/blob/master/environment/vagrant/sandbox/DevelopmentEnvironment/Virtualbox/Vagrantfile).",,2018-04-25 09:36:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/183980427,https://github.com/hyperledger/indy-node/pull/662#discussion_r183980427,Toktar
https://github.com/hyperledger/indy-node/pull/662,https://github.com/hyperledger/indy-node/pull/662,Or warning with a new link in the start willl be enough?,059dac0fe9a524875641ad2615e52e9e3fdd6894,2018-04-25 08:40:27,183981075,"@@ -1,14 +1,16 @@
 # Setting Up a Test Indy Network in VMs
 
+**WARNING:** Here use deprecated client. Please, use [new client from SDK](https://github.com/hyperledger/indy-sdk/tree/master/cli)
+
 When you're finished working through this document, you will be able to proceed through to the [*Getting
-Started Guide*](../../../../getting-started.md) or if you would like, you may continue setting up an actual Developer Environment connected to a sandbox by following these [instructions](https://github.com/hyperledger/indy-node/blob/master/environment/vagrant/sandbox/DevelopmentEnvironment/Virtualbox/Vagrantfile).
+Started Guide*](https://github.com/hyperledger/indy-sdk/blob/master/doc/getting-started/run-getting-started.md) or if you would like, you may continue setting up an actual Developer Environment connected to a sandbox by following these [instructions](https://github.com/hyperledger/indy-node/blob/master/environment/vagrant/sandbox/DevelopmentEnvironment/Virtualbox/Vagrantfile).",,2018-04-25 09:36:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/183981075,https://github.com/hyperledger/indy-node/pull/662#discussion_r183981075,Toktar
https://github.com/hyperledger/indy-node/pull/662,https://github.com/hyperledger/indy-node/pull/662,I think a link at the start is enough,059dac0fe9a524875641ad2615e52e9e3fdd6894,2018-04-25 09:20:44,183992357,"@@ -1,14 +1,16 @@
 # Setting Up a Test Indy Network in VMs
 
+**WARNING:** Here use deprecated client. Please, use [new client from SDK](https://github.com/hyperledger/indy-sdk/tree/master/cli)
+
 When you're finished working through this document, you will be able to proceed through to the [*Getting
-Started Guide*](../../../../getting-started.md) or if you would like, you may continue setting up an actual Developer Environment connected to a sandbox by following these [instructions](https://github.com/hyperledger/indy-node/blob/master/environment/vagrant/sandbox/DevelopmentEnvironment/Virtualbox/Vagrantfile).
+Started Guide*](https://github.com/hyperledger/indy-sdk/blob/master/doc/getting-started/run-getting-started.md) or if you would like, you may continue setting up an actual Developer Environment connected to a sandbox by following these [instructions](https://github.com/hyperledger/indy-node/blob/master/environment/vagrant/sandbox/DevelopmentEnvironment/Virtualbox/Vagrantfile).",,2018-04-25 09:36:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/183992357,https://github.com/hyperledger/indy-node/pull/662#discussion_r183992357,ashcherbakov
https://github.com/hyperledger/indy-node/pull/648,https://github.com/hyperledger/indy-node/pull/648,"We already have package on our repo. Just add into /etc/apt/sources.list string like:
`deb https://repo.sovrin.org/deb xenial master`
and
`apt install rocksdb`

Also, we will merge PR with docs changing. You can see it in
https://github.com/hyperledger/indy-node/pull/642/files",7edd4621a0212a5befa0eecf6a56c96cb2a64eae,2018-04-12 08:03:24,180995350,"@@ -202,3 +202,22 @@ and run tests
 ```
 pytest .
 ```
+
+## Issues with Quick Setup on Ubuntu 16.04
+
+If encountering `fatal error: rocksdb/slice.h: No such file or directory` when running the `init-dev-project.sh <github-name> <new-virtualenv-name>` command during the quick setup (step 7) here is a guide to solve this issue:
+
+Independently install rocksdb with the following commands:
+```
+apt-get install build-essential
+apt-get install libsnappy-dev zlib1g-dev libbz2-dev libgflags-dev liblz4-dev
+git clone https://github.com/facebook/rocksdb.git",13,2018-04-12 08:11:37,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180995350,https://github.com/hyperledger/indy-node/pull/648#discussion_r180995350,anikitinDSR
https://github.com/hyperledger/indy-node/pull/648,https://github.com/hyperledger/indy-node/pull/648,"That is a much nicer solution! Im new to this, sorry for the inconvenience.",7edd4621a0212a5befa0eecf6a56c96cb2a64eae,2018-04-12 11:52:29,181053738,"@@ -202,3 +202,22 @@ and run tests
 ```
 pytest .
 ```
+
+## Issues with Quick Setup on Ubuntu 16.04
+
+If encountering `fatal error: rocksdb/slice.h: No such file or directory` when running the `init-dev-project.sh <github-name> <new-virtualenv-name>` command during the quick setup (step 7) here is a guide to solve this issue:
+
+Independently install rocksdb with the following commands:
+```
+apt-get install build-essential
+apt-get install libsnappy-dev zlib1g-dev libbz2-dev libgflags-dev liblz4-dev
+git clone https://github.com/facebook/rocksdb.git",13,2018-04-12 11:52:29,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181053738,https://github.com/hyperledger/indy-node/pull/648#discussion_r181053738,johadahl
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,"/* Request for validator info */
{
    'operation': {
        'type': '120',        
    },
    
    'identifier': 'L5AD5g65TDQr1PPHHRoiGf',
    'reqId': 1514215425836443,
    'protocolVersion': 1,    
}


/* Reply for validator info */
{
    'op': 'REPLY', 
    'result': {
        'type': '120',
        'identifier': 'L5AD5g65TDQr1PPHHRoiGf',
        'reqId': 1514214863899317,	
     },
        
     'data': {
	 <Json with specific data>
     },                
}",17e12cc77fd8c082ae006572d0a2927312653166,2018-04-13 12:21:06,181370557,"@@ -65,9 +65,12 @@ This file is updated by node once a minute and contains following information:
 ```
 
 ## Modification - New Read Command
-Validator_info should be accessible as read command, available for TRUSTEE and STEWARDS only. New command should provide info from
-all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
-requesting all parameters or some subset of parameters.
+Validator_info accessible as read command, available for all clients. New command provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd).
+Command allow requesting all parameters or some subset of parameters.
+
+The client sends a command to each node. After receiving the request, each node starts a validator-info script, and then sends the Jason result without compression to the client.
+The client should not wait for the consensus of the all node, but should handle the response from each node separately.
 
 For reference: [INDY-1184](https://jira.hyperledger.org/browse/INDY-1184)
 ",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181370557,https://github.com/hyperledger/indy-node/pull/644#discussion_r181370557,SergeyPalamarchuk
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,May be just send node_info.json instead of running validator-info?,17e12cc77fd8c082ae006572d0a2927312653166,2018-04-13 12:21:09,181370570,"@@ -65,9 +65,12 @@ This file is updated by node once a minute and contains following information:
 ```
 
 ## Modification - New Read Command
-Validator_info should be accessible as read command, available for TRUSTEE and STEWARDS only. New command should provide info from
-all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
-requesting all parameters or some subset of parameters.
+Validator_info accessible as read command, available for all clients. New command provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd).
+Command allow requesting all parameters or some subset of parameters.
+
+The client sends a command to each node. After receiving the request, each node starts a validator-info script, and then sends the Jason result without compression to the client.",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181370570,https://github.com/hyperledger/indy-node/pull/644#discussion_r181370570,anikitinDSR
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,"@SergeyPalamarchuk Will the following format convenient for you?
/* Request for validator info */
{'protocolVersion': 1, 
'operation': {'type': '119'}, 
'reqId': 83193,
 'identifier': 'M9BJDuS24bqbJNvBRsoGg3'}

/* Reply from validator info */
{
'op': 'REPLY',
'result': {
          'reqId': 83193, 
           'msg': None,   
           'data': {<Json with specific data>}, 
           'type': '119', 
            'isSuccess': True, 
            'identifier': 'M9BJDuS24bqbJNvBRsoGg3'}
}",17e12cc77fd8c082ae006572d0a2927312653166,2018-04-17 13:50:33,182079360,"@@ -65,9 +65,12 @@ This file is updated by node once a minute and contains following information:
 ```
 
 ## Modification - New Read Command
-Validator_info should be accessible as read command, available for TRUSTEE and STEWARDS only. New command should provide info from
-all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
-requesting all parameters or some subset of parameters.
+Validator_info accessible as read command, available for all clients. New command provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd).
+Command allow requesting all parameters or some subset of parameters.
+
+The client sends a command to each node. After receiving the request, each node starts a validator-info script, and then sends the Jason result without compression to the client.
+The client should not wait for the consensus of the all node, but should handle the response from each node separately.
 
 For reference: [INDY-1184](https://jira.hyperledger.org/browse/INDY-1184)
 ",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182079360,https://github.com/hyperledger/indy-node/pull/644#discussion_r182079360,Toktar
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,Please mention new commands (restart and validator info) in https://github.com/hyperledger/indy-node/blob/master/docs/requests.md,17e12cc77fd8c082ae006572d0a2927312653166,2018-04-20 08:07:28,182974785,"@@ -65,9 +65,35 @@ This file is updated by node once a minute and contains following information:
 ```
 
 ## Modification - New Read Command
-Validator_info should be accessible as read command, available for TRUSTEE and STEWARDS only. New command should provide info from
-all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
-requesting all parameters or some subset of parameters.
+Validator_info accessible as read command, available for all clients. New command provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd).
+Command allow requesting all parameters or some subset of parameters.
+
+The client sends a command with some parameters to each node. There are only one parameter now - node alias for get its info. But parameters list will expanded later.
+After receiving the request, each node starts a validator-info script, and then sends the Json result without compression to the client.
+The client should not wait for the consensus of the all node, but should handle the response from each node separately.
+
+Request for getting validator info data :",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182974785,https://github.com/hyperledger/indy-node/pull/644#discussion_r182974785,ashcherbakov
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,"Do we call script?
or read already prepared file?
or run gather logic again?",17e12cc77fd8c082ae006572d0a2927312653166,2018-04-20 08:43:58,182983475,"@@ -65,9 +65,35 @@ This file is updated by node once a minute and contains following information:
 ```
 
 ## Modification - New Read Command
-Validator_info should be accessible as read command, available for TRUSTEE and STEWARDS only. New command should provide info from
-all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
-requesting all parameters or some subset of parameters.
+Validator_info accessible as read command, available for all clients. New command provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd).
+Command allow requesting all parameters or some subset of parameters.
+
+The client sends a command with some parameters to each node. There are only one parameter now - node alias for get its info. But parameters list will expanded later.
+After receiving the request, each node starts a validator-info script, and then sends the Json result without compression to the client.",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182983475,https://github.com/hyperledger/indy-node/pull/644#discussion_r182983475,dsurnin
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,"Is it ok to pass error via bool flag and text msg?
If we need to provide negative command result it is better to use dedicated packet type.
In our case I think we can reuse REJECT packet, or create COMMAND_ERROR packet.",17e12cc77fd8c082ae006572d0a2927312653166,2018-04-20 08:51:26,182985726,"@@ -65,9 +65,35 @@ This file is updated by node once a minute and contains following information:
 ```
 
 ## Modification - New Read Command
-Validator_info should be accessible as read command, available for TRUSTEE and STEWARDS only. New command should provide info from
-all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
-requesting all parameters or some subset of parameters.
+Validator_info accessible as read command, available for all clients. New command provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd).
+Command allow requesting all parameters or some subset of parameters.
+
+The client sends a command with some parameters to each node. There are only one parameter now - node alias for get its info. But parameters list will expanded later.
+After receiving the request, each node starts a validator-info script, and then sends the Json result without compression to the client.
+The client should not wait for the consensus of the all node, but should handle the response from each node separately.
+
+Request for getting validator info data :
+```
+{'protocolVersion': 1,
+'operation': {'type': '119'},
+'reqId': 83193,
+'identifier': 'M9BJDuS24bqbJNvBRsoGg3'}
+```
+
+Reply from the one node :
+```
+{
+'op': 'REPLY',
+'result': {
+'reqId': 83193,
+'msg': None,
+'data': { <Json with specific data> },
+'type': '119',
+'isSuccess': True,",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182985726,https://github.com/hyperledger/indy-node/pull/644#discussion_r182985726,dsurnin
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,"I think it is better to move to the begging of the except block and extend message with the input req
In case of InvalidClientReq we will not have any logs",17e12cc77fd8c082ae006572d0a2927312653166,2018-04-20 09:01:40,182988667,"@@ -68,16 +71,25 @@ def validate(self, req: Request):
                     Roles.nameFromValue(origin_role)))
 
     def apply(self, req: Request, cons_time: int = None):
-        if req.txn_type != POOL_RESTART:
-            raise InvalidClientRequest(""{} is not type of action transaction""
-                                       .format(req.txn_type))
         result = {}
         try:
-            self.restarter.handleActionTxn(req)
-            result = self._generate_action_result(req)
+            if req.txn_type == POOL_RESTART:
+                self.restarter.handleActionTxn(req)
+                result = self._generate_action_result(req)
+            elif req.txn_type == VALIDATOR_INFO:
+                result = self._generate_action_result(req)
+                result[DATA] = self.info_tool.info
+            else:
+                raise InvalidClientRequest(
+                    ""{} is not type of action transaction""
+                    .format(req.txn_type))
         except Exception as ex:
-            result = self._generate_action_result(req, False, ex.args[0])
-            logger.warning(""Restart is failed"")
+            if isinstance(ex, InvalidClientRequest):
+                raise ex
+            result = self._generate_action_result(req,
+                                                  False,
+                                                  ex.args[0])
+            logger.warning(""Operation is failed"")",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182988667,https://github.com/hyperledger/indy-node/pull/644#discussion_r182988667,dsurnin
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,Do we log each command started and finished?,17e12cc77fd8c082ae006572d0a2927312653166,2018-04-20 09:05:54,182989837,"@@ -68,16 +71,25 @@ def validate(self, req: Request):
                     Roles.nameFromValue(origin_role)))
 
     def apply(self, req: Request, cons_time: int = None):
-        if req.txn_type != POOL_RESTART:
-            raise InvalidClientRequest(""{} is not type of action transaction""
-                                       .format(req.txn_type))
         result = {}
         try:
-            self.restarter.handleActionTxn(req)
-            result = self._generate_action_result(req)
+            if req.txn_type == POOL_RESTART:
+                self.restarter.handleActionTxn(req)",49,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182989837,https://github.com/hyperledger/indy-node/pull/644#discussion_r182989837,dsurnin
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,"As I understand REJECT, it should to be used with authentication problem or other dynamic validation. It means that input data was incorrect. But in this case we want to answer client reason why we couldn't do action with valid input.
May be COMMAND_ERROR packet is a good idea but need more time for implementation.",17e12cc77fd8c082ae006572d0a2927312653166,2018-04-20 09:27:18,182995437,"@@ -65,9 +65,35 @@ This file is updated by node once a minute and contains following information:
 ```
 
 ## Modification - New Read Command
-Validator_info should be accessible as read command, available for TRUSTEE and STEWARDS only. New command should provide info from
-all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
-requesting all parameters or some subset of parameters.
+Validator_info accessible as read command, available for all clients. New command provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd).
+Command allow requesting all parameters or some subset of parameters.
+
+The client sends a command with some parameters to each node. There are only one parameter now - node alias for get its info. But parameters list will expanded later.
+After receiving the request, each node starts a validator-info script, and then sends the Json result without compression to the client.
+The client should not wait for the consensus of the all node, but should handle the response from each node separately.
+
+Request for getting validator info data :
+```
+{'protocolVersion': 1,
+'operation': {'type': '119'},
+'reqId': 83193,
+'identifier': 'M9BJDuS24bqbJNvBRsoGg3'}
+```
+
+Reply from the one node :
+```
+{
+'op': 'REPLY',
+'result': {
+'reqId': 83193,
+'msg': None,
+'data': { <Json with specific data> },
+'type': '119',
+'isSuccess': True,",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182995437,https://github.com/hyperledger/indy-node/pull/644#discussion_r182995437,Toktar
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,"No, but we log getting message from client. If it's not enough we can log start and finish point of command.",17e12cc77fd8c082ae006572d0a2927312653166,2018-04-20 09:34:34,182997375,"@@ -68,16 +71,25 @@ def validate(self, req: Request):
                     Roles.nameFromValue(origin_role)))
 
     def apply(self, req: Request, cons_time: int = None):
-        if req.txn_type != POOL_RESTART:
-            raise InvalidClientRequest(""{} is not type of action transaction""
-                                       .format(req.txn_type))
         result = {}
         try:
-            self.restarter.handleActionTxn(req)
-            result = self._generate_action_result(req)
+            if req.txn_type == POOL_RESTART:
+                self.restarter.handleActionTxn(req)",49,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182997375,https://github.com/hyperledger/indy-node/pull/644#discussion_r182997375,Toktar
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,"Yes, I would prefer to have star and finish in the log
I think it is useful for example to compare and debug nodes' performance ",17e12cc77fd8c082ae006572d0a2927312653166,2018-04-20 09:50:53,183001211,"@@ -68,16 +71,25 @@ def validate(self, req: Request):
                     Roles.nameFromValue(origin_role)))
 
     def apply(self, req: Request, cons_time: int = None):
-        if req.txn_type != POOL_RESTART:
-            raise InvalidClientRequest(""{} is not type of action transaction""
-                                       .format(req.txn_type))
         result = {}
         try:
-            self.restarter.handleActionTxn(req)
-            result = self._generate_action_result(req)
+            if req.txn_type == POOL_RESTART:
+                self.restarter.handleActionTxn(req)",49,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/183001211,https://github.com/hyperledger/indy-node/pull/644#discussion_r183001211,dsurnin
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,"It's typo in my documentation. @anikitinDSR suggest to use field from node that script use. Then we wil not work with files. If we need more parameters for this command, may be we can use script without works with file for every request ",17e12cc77fd8c082ae006572d0a2927312653166,2018-04-20 10:06:05,183004980,"@@ -65,9 +65,35 @@ This file is updated by node once a minute and contains following information:
 ```
 
 ## Modification - New Read Command
-Validator_info should be accessible as read command, available for TRUSTEE and STEWARDS only. New command should provide info from
-all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
-requesting all parameters or some subset of parameters.
+Validator_info accessible as read command, available for all clients. New command provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd).
+Command allow requesting all parameters or some subset of parameters.
+
+The client sends a command with some parameters to each node. There are only one parameter now - node alias for get its info. But parameters list will expanded later.
+After receiving the request, each node starts a validator-info script, and then sends the Json result without compression to the client.",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/183004980,https://github.com/hyperledger/indy-node/pull/644#discussion_r183004980,Toktar
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,done,17e12cc77fd8c082ae006572d0a2927312653166,2018-04-24 08:38:55,183648507,"@@ -68,16 +71,25 @@ def validate(self, req: Request):
                     Roles.nameFromValue(origin_role)))
 
     def apply(self, req: Request, cons_time: int = None):
-        if req.txn_type != POOL_RESTART:
-            raise InvalidClientRequest(""{} is not type of action transaction""
-                                       .format(req.txn_type))
         result = {}
         try:
-            self.restarter.handleActionTxn(req)
-            result = self._generate_action_result(req)
+            if req.txn_type == POOL_RESTART:
+                self.restarter.handleActionTxn(req)",49,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/183648507,https://github.com/hyperledger/indy-node/pull/644#discussion_r183648507,Toktar
https://github.com/hyperledger/indy-node/pull/644,https://github.com/hyperledger/indy-node/pull/644,done,17e12cc77fd8c082ae006572d0a2927312653166,2018-04-24 08:39:10,183648572,"@@ -65,9 +65,35 @@ This file is updated by node once a minute and contains following information:
 ```
 
 ## Modification - New Read Command
-Validator_info should be accessible as read command, available for TRUSTEE and STEWARDS only. New command should provide info from
-all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
-requesting all parameters or some subset of parameters.
+Validator_info accessible as read command, available for all clients. New command provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd).
+Command allow requesting all parameters or some subset of parameters.
+
+The client sends a command with some parameters to each node. There are only one parameter now - node alias for get its info. But parameters list will expanded later.
+After receiving the request, each node starts a validator-info script, and then sends the Json result without compression to the client.
+The client should not wait for the consensus of the all node, but should handle the response from each node separately.
+
+Request for getting validator info data :",,2018-04-24 09:53:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/183648572,https://github.com/hyperledger/indy-node/pull/644#discussion_r183648572,Toktar
https://github.com/hyperledger/indy-node/pull/643,https://github.com/hyperledger/indy-node/pull/643,"1) We need to be able to specify delay (random delay is just one of the possible options that also makes sense)
2) We need to be able to specify the type of request (nym, attr, claim_def, etc.). Random choosing of req type is just one of the options (which makes total sense).",0b300f8f9e8e4a56df75cd716af075724d12dcee,2018-04-18 08:54:46,182354358,"@@ -0,0 +1,288 @@
+""""""
+Created on Feb 27, 2018
+
+@author: nhan.nguyen
+
+This module contains class ""TesterSimulateTraffic"" that simulates the real time
+traffic.
+""""""
+
+import threading
+import random
+import time
+import utils
+import os
+import asyncio
+import argparse
+import requests_sender
+import requests_builder
+import perf_add_requests
+
+from perf_tester import Tester
+
+
+class Option:
+    def __init__(self):
+        parser = argparse.ArgumentParser(
+            description='Script to simulate the traffic which will send'
+                        'request to ledger in several sets. Each set contains '
+                        'a specified number of requests and between two set, '
+                        'the system will be delayed for a random length of'
+                        ' time (from 1 to 10 seconds).\n\n',
+
+            usage='To create 5 client to simulate the traffic in 50 seconds '
+                  'and you want each set contains 100 request.'
+                  '\nuse: python3.6 perf_traffic.py -c 5 -t 50 -n 100')
+
+        parser.add_argument('-c',
+                            help='Specify the number of clients '
+                                 'will be simulated. Default value will be 1.',
+                            action='store',
+                            type=int, default=1, dest='clients')
+
+        parser.add_argument('-n',
+                            help='Number of transactions will be sent '
+                                 'in a set. Default value will be 100.',
+                            action='store', type=int,
+                            default=100, dest='transactions_delay')
+
+        parser.add_argument('--log',
+                            help='To see all log. If this flag does not exist,'
+                                 'program just only print fail message',
+                            action='store_true', default=False, dest='log')
+
+        parser.add_argument('-to',
+                            help='Timeout of testing. '
+                                 'Default value will be 100.',
+                            action='store', type=int,
+                            default=100, dest='time_out')
+
+        parser.add_argument('--init',
+                            help='To build ""GET"" request, we need to '
+                                 'send ""ADD"" request first. This argument is '
+                                 'the number of ""ADD"" request will be sent '
+                                 'to ledger to make sample for ""GET"" requests.'
+                                 ' Default value will be 100',
+                            action='store', type=int,
+                            default=100, dest='number_of_request_samples')
+
+        self.args = parser.parse_args()
+
+
+def catch_number_of_request_samples():
+    """"""
+    Parse number of sample of ""GET"" requests will be created.
+    If the number is less than of equal with zero, default value (100) will be
+    returned.
+
+    :return: number of sample of ""GET"" requests.
+    """"""
+    import sys
+    result = 100
+
+    if ""--init"" in sys.argv:
+        index = sys.argv.index(""--init"")
+        if index < len(sys.argv) - 1:
+            temp = -1
+            try:
+                temp = int(sys.argv[index + 1])
+            except ValueError:
+                pass
+            if temp > 0:
+                result = temp
+
+    return result
+
+
+class TesterSimulateTraffic(Tester):
+    __sample_req_info = {}
+    __kinds_of_request = [""nym"", ""attribute"", ""schema"", ""claim"",
+                          ""get_nym"", ""get_attribute"", ""get_schema"",
+                          ""get_claim""]
+    __number_of_request_samples = catch_number_of_request_samples()
+
+    def __init__(self, number_of_clients: int = 2,
+                 transactions_delay: int = 100,
+                 time_out: int = 300, log=False,
+                 seed=""000000000000000000000000Trustee1""):
+        super().__init__(log=log, seed=seed)
+        utils.run_async_method(
+            None, TesterSimulateTraffic._prepare_samples_for_get_req,
+            TesterSimulateTraffic.__number_of_request_samples)
+
+        if time_out <= 0 or transactions_delay <= 0 or number_of_clients <= 0:
+            return
+
+        self.transactions_delay = transactions_delay
+        self.time_out = time_out
+        self.number_of_clients = number_of_clients
+        self.current_total_txn = 0
+        self.__current_time = time.time()
+        self.__lock = threading.Lock()
+        self.__sender = requests_sender.RequestsSender()
+
+    async def _test(self):
+        """"""
+        Override from ""Tester"" class to implement testing steps.
+        """"""
+        lst_threads = list()
+        self.__current_time = time.time()
+        for _ in range(self.number_of_clients):
+            thread = threading.Thread(target=self.__simulate_client)
+            thread.setDaemon(True)
+            thread.start()
+            lst_threads.append(thread)
+
+        for thread in lst_threads:
+            thread.join(self.time_out * 1.1)
+
+        self.passed_req = self.__sender.passed_req
+        self.failed_req = self.__sender.failed_req
+        self.fastest_txn = self.__sender.fastest_txn
+        self.lowest_txn = self.__sender.lowest_txn
+
+    def __update(self):
+        """"""
+        Synchronize within threads to update some necessary information.
+        """"""
+        self.__lock.acquire()
+
+        if self.start_time == 0 and self.finish_time != 0:
+            self.start_time = self.finish_time
+
+        if self.current_total_txn != 0 and \
+                self.current_total_txn % self.transactions_delay == 0:
+            time.sleep(random.randint(1, 10))",155,2018-04-18 09:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182354358,https://github.com/hyperledger/indy-node/pull/643#discussion_r182354358,ashcherbakov
https://github.com/hyperledger/indy-node/pull/643,https://github.com/hyperledger/indy-node/pull/643,"It looks like we are still waiting for the reply. So, we are waiting for the reply, then sleeping for some random time, and only then sending a new request.
We need to be able to send requests without waiting for results (sending request, say, every 1 sec).",0b300f8f9e8e4a56df75cd716af075724d12dcee,2018-04-18 08:57:33,182355184,"@@ -0,0 +1,288 @@
+""""""
+Created on Feb 27, 2018
+
+@author: nhan.nguyen
+
+This module contains class ""TesterSimulateTraffic"" that simulates the real time
+traffic.
+""""""
+
+import threading
+import random
+import time
+import utils
+import os
+import asyncio
+import argparse
+import requests_sender
+import requests_builder
+import perf_add_requests
+
+from perf_tester import Tester
+
+
+class Option:
+    def __init__(self):
+        parser = argparse.ArgumentParser(
+            description='Script to simulate the traffic which will send'
+                        'request to ledger in several sets. Each set contains '
+                        'a specified number of requests and between two set, '
+                        'the system will be delayed for a random length of'
+                        ' time (from 1 to 10 seconds).\n\n',
+
+            usage='To create 5 client to simulate the traffic in 50 seconds '
+                  'and you want each set contains 100 request.'
+                  '\nuse: python3.6 perf_traffic.py -c 5 -t 50 -n 100')
+
+        parser.add_argument('-c',
+                            help='Specify the number of clients '
+                                 'will be simulated. Default value will be 1.',
+                            action='store',
+                            type=int, default=1, dest='clients')
+
+        parser.add_argument('-n',
+                            help='Number of transactions will be sent '
+                                 'in a set. Default value will be 100.',
+                            action='store', type=int,
+                            default=100, dest='transactions_delay')
+
+        parser.add_argument('--log',
+                            help='To see all log. If this flag does not exist,'
+                                 'program just only print fail message',
+                            action='store_true', default=False, dest='log')
+
+        parser.add_argument('-to',
+                            help='Timeout of testing. '
+                                 'Default value will be 100.',
+                            action='store', type=int,
+                            default=100, dest='time_out')
+
+        parser.add_argument('--init',
+                            help='To build ""GET"" request, we need to '
+                                 'send ""ADD"" request first. This argument is '
+                                 'the number of ""ADD"" request will be sent '
+                                 'to ledger to make sample for ""GET"" requests.'
+                                 ' Default value will be 100',
+                            action='store', type=int,
+                            default=100, dest='number_of_request_samples')
+
+        self.args = parser.parse_args()
+
+
+def catch_number_of_request_samples():
+    """"""
+    Parse number of sample of ""GET"" requests will be created.
+    If the number is less than of equal with zero, default value (100) will be
+    returned.
+
+    :return: number of sample of ""GET"" requests.
+    """"""
+    import sys
+    result = 100
+
+    if ""--init"" in sys.argv:
+        index = sys.argv.index(""--init"")
+        if index < len(sys.argv) - 1:
+            temp = -1
+            try:
+                temp = int(sys.argv[index + 1])
+            except ValueError:
+                pass
+            if temp > 0:
+                result = temp
+
+    return result
+
+
+class TesterSimulateTraffic(Tester):
+    __sample_req_info = {}
+    __kinds_of_request = [""nym"", ""attribute"", ""schema"", ""claim"",
+                          ""get_nym"", ""get_attribute"", ""get_schema"",
+                          ""get_claim""]
+    __number_of_request_samples = catch_number_of_request_samples()
+
+    def __init__(self, number_of_clients: int = 2,
+                 transactions_delay: int = 100,
+                 time_out: int = 300, log=False,
+                 seed=""000000000000000000000000Trustee1""):
+        super().__init__(log=log, seed=seed)
+        utils.run_async_method(
+            None, TesterSimulateTraffic._prepare_samples_for_get_req,
+            TesterSimulateTraffic.__number_of_request_samples)
+
+        if time_out <= 0 or transactions_delay <= 0 or number_of_clients <= 0:
+            return
+
+        self.transactions_delay = transactions_delay
+        self.time_out = time_out
+        self.number_of_clients = number_of_clients
+        self.current_total_txn = 0
+        self.__current_time = time.time()
+        self.__lock = threading.Lock()
+        self.__sender = requests_sender.RequestsSender()
+
+    async def _test(self):
+        """"""
+        Override from ""Tester"" class to implement testing steps.
+        """"""
+        lst_threads = list()
+        self.__current_time = time.time()
+        for _ in range(self.number_of_clients):
+            thread = threading.Thread(target=self.__simulate_client)
+            thread.setDaemon(True)
+            thread.start()
+            lst_threads.append(thread)
+
+        for thread in lst_threads:
+            thread.join(self.time_out * 1.1)
+
+        self.passed_req = self.__sender.passed_req
+        self.failed_req = self.__sender.failed_req
+        self.fastest_txn = self.__sender.fastest_txn
+        self.lowest_txn = self.__sender.lowest_txn
+
+    def __update(self):
+        """"""
+        Synchronize within threads to update some necessary information.
+        """"""
+        self.__lock.acquire()
+
+        if self.start_time == 0 and self.finish_time != 0:
+            self.start_time = self.finish_time
+
+        if self.current_total_txn != 0 and \
+                self.current_total_txn % self.transactions_delay == 0:
+            time.sleep(random.randint(1, 10))
+
+        self.current_total_txn += 1
+        self.__lock.release()
+
+    def __simulate_client(self):
+        """"""
+        Simulate a client to create real time traffic.
+        """"""
+        loop = asyncio.new_event_loop()
+        args = {""wallet_handle"": self.wallet_handle,
+                ""pool_handle"": self.pool_handle,
+                ""submitter_did"": self.submitter_did}
+
+        asyncio.set_event_loop(loop)
+        while True:
+            self.__update()
+            if time.time() - self.__current_time >= self.time_out:
+                break
+
+            self.finish_time = utils.run_async_method(
+                loop, TesterSimulateTraffic._build_and_send_request,
+                self.__sender, args)
+
+        loop.close()
+
+    @staticmethod
+    async def generate_sample_request_info(kind,
+                                           sample_num: int = 100) -> list:
+        """"""
+        Generate sample request information.
+
+        :param kind: kind of request.
+        :param sample_num: number of samples will be generated.
+        :return: a list of samples request information.
+        """"""
+        kinds = [""nym"", ""schema"", ""attribute"", ""claim""]
+
+        if kind not in kinds or sample_num <= 0:
+            return []
+
+        generator = perf_add_requests.PerformanceTesterForAddingRequest(
+            request_num=sample_num, request_kind=kind)
+
+        await generator.test()
+        lst_info = list()
+        with open(generator.info_file_path, ""r"") as info_file:
+            for line in info_file:
+                if len(line) > 2:
+                    lst_info.append(line)
+
+        try:
+            os.remove(generator.info_file_path)
+        except IOError:
+            pass
+
+        return lst_info
+
+    @staticmethod
+    async def _prepare_samples_for_get_req(sample_num: int = 100):
+        """"""
+        Init samples for ""GET"" requests.
+
+        :param sample_num: create a number of samples request information for
+                           each kind of request (nym, attribute, claim, schema)
+        """"""
+        if TesterSimulateTraffic.__sample_req_info:
+            return
+
+        keys = [""nym"", ""attribute"", ""schema"", ""claim""]
+        if sample_num <= 0:
+            return
+
+        for key in keys:
+            TesterSimulateTraffic.__sample_req_info[key] = \
+                await TesterSimulateTraffic.generate_sample_request_info(
+                key, sample_num)
+
+    @staticmethod
+    def _random_req_kind():
+        """"""
+        Random choice a request kind.
+
+        :return: request kind.
+        """"""
+        return random.choice(TesterSimulateTraffic.__kinds_of_request)
+
+    @staticmethod
+    def _random_sample_for_get_request(kind: str):
+        """"""
+        Choice randomly a sample of request info base on kind of request.
+
+        :param kind: kind of request (get_nym, get_attribute,
+                     get_claim, get_schema).
+        :return: a random sample of request info.
+        """"""
+        if kind.startswith(""get_""):
+            return random.choice(
+                TesterSimulateTraffic.__sample_req_info[kind.replace(
+                    ""get_"", """")])
+        return """"
+
+    @staticmethod
+    async def _build_and_send_request(sender, args):
+        """"""
+        Build a request and send it onto ledger.
+
+        :param sender: send the request.
+        :param args: contains some arguments to send request to ledger
+                     (pool handle, wallet handle, submitter did)
+        :return: response time.
+        """"""
+        kind = TesterSimulateTraffic._random_req_kind()
+        data = TesterSimulateTraffic._random_sample_for_get_request(kind)
+
+        req = await requests_builder.RequestBuilder.build_request(args, kind,",270,2018-04-18 09:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182355184,https://github.com/hyperledger/indy-node/pull/643#discussion_r182355184,ashcherbakov
https://github.com/hyperledger/indy-node/pull/643,https://github.com/hyperledger/indy-node/pull/643,"Why do we need multiple scripts that all do almost the same? What is the difference between PerformanceTesterForAddingRequest, TesterSimulateLoad, TesterSimulateTraffic? Why can't we have just one script with parameters specifying type of requests, delay between requests, flag whether to wait for reply before sending the next request, etc.
",0b300f8f9e8e4a56df75cd716af075724d12dcee,2018-04-18 09:00:28,182356119,"@@ -1,118 +1,374 @@
-#!/usr/bin/env python3
+""""""
+Created on Feb 2, 2018
+
+@author: nhan.nguyen
+
+This module contains class ""PerformanceTestRunner"" that executes the test base
+on the mode that user pass to system.
+""""""
+
 import os
 import argparse
 import time
+import threading
+import asyncio
 import sys
-from threading import Thread, Lock
-
-global txns
-global clients
-clients = 100
-txns = 100
-
-#                   ==================== Notes and information ====================
-# This script will run multiple instances (threaded) of the the Perf_Add_nyms.py script or the Perf_get_nyms.py. The
-# command line parameters for each script are different and can be set from this script without modifying Add_nyms or
-# Get_nyms scripts.
-# The settings for Perf runner are 'clients' and 'txns'.  Clients is the number of threads (or client machines) to use,
-# the txns indicates how many transactions will run per client (thread).  These settings are specific to Perf_runner.py
-#
-# The command line for both performance scripts is created in the 'command' variable found below.  The default setting
-# for Perf_Add_nyms.py uses the -n and -s parameters to specify the number of threads and clients to use.  The value
-# from clients is iterated through and uses 'i' to track which iteration is processing.
-# The default vaiables for the Add_nyms script will be  used.  If any of the default settings for Add_nyms or Get_nyms
-# needs to be modified, add the changes here to the perf runner by modifying the 'command' variable.
-#                   ================================================================
-# Example:
-# Run Perf_Add_nyms.py:   python3.6 Perf_runner.py -a
-# Run Perf_gert_nyms.py using 3 clients (threads) - by setting clients to 3:  python3.6 Perf_runner.py -g
-
-parser = argparse.ArgumentParser(description='This script will create multiple threads of the Perf_Add_nyms.py or '
-                                             'the Perf_get_nyms.py.')
-
-parser.add_argument('-a', help='Use this parameter to start Perf_Add_nyms.py', action='store_true',
-                    default=False, required=False)
-parser.add_argument('-g', help='Use this parameter to start Perf_get_nyms.py', action='store_true',
-                    default=False, required=False)
-
-# parser.print_help()
-results = parser.parse_args()
-if results.a:
-    results.a = 'Perf_Add_nyms.py'
-if results.g:
-    results.g = 'Perf_get_nyms.py'
-
-
-def run_test(i, lock):
-
-    print(""This is a test : "" + repr(results.g))
-    print(""This is a test : "" + repr(results.a))
-    if results.a:
-        # The value for -n is the 'txns' variable at the top of this script
-        command = 'python3 ' + results.a + ' -n ' + str(txns) + ' -s ' + repr(i)
-    elif results.g:
-        # The default values for -d -t and -g in get_nym will be used
-        command = 'python3 ' + results.g + ' -s ' + repr(clients) + ' -d nym_files'
-    else:
-        print(""\n\nPlease specify a script to use or run Perf_runner.py -h for additional information"")
-        sys.exit(1)
-
-    with lock:
-        print(""Starting thread {}"".format(i))
-
-    # Run the command
-    # print(command)
-    os.system(command)
-
-    with lock:
-        print(""Thread {} stopped"".format(i))
-
-
-# Create threads
-lock = Lock()
-
-# Start Time
-# timeBegin = datetime.now()
-overmind_start_time = time.time()
-
-# get the number of clients (threads) to create
-threads = [Thread(target=run_test, args=(i, lock)) for i in range(clients)]
-
-# Start threads
-for x in threads:
-    x.start()
-
-# Stop threads
-for x in threads:
-    x.join()
-
-# Total Time
-totalTime = time.time() - overmind_start_time
-
-hours = totalTime / 3600
-totalTime = 3600 * hours
-minutes = totalTime / 60
-seconds = 60 * minutes
-
-ttl_txns = clients * txns
-ttl_seconds = int((hours * 3600) + (minutes * 60) + seconds)
-try:
-    txns_per_second = int(ttl_txns / ttl_seconds)
-except Exception as E:
-    txns_per_second = None
-    print(""There is too small test run time that causes an error: "", E)
-
-print(""\n -----------  Total time to run the test: %dh:%dm:%ds"" % (hours, minutes, seconds) + ""  -----------"")
-print(""\n Clients = "" + str(clients))
-print(""\n Transaction per client = "" + str(txns))
-print(""\n Total transactions requested = "" + str(ttl_txns))
-print(""\n Estimated transactions per second = "" + str(txns_per_second))
-
-tm = time.strftime(""%d-%m-%Y_%H-%M-%S"")
-file = open(""test_results_time_"" + tm + "".log"", ""w"")
-file.write(""\n -----------  Total time to run the test: %dh:%dm:%ds"" % (hours, minutes, seconds) + ""  -----------\n"")
-file.write(""\n Clients = "" + str(clients))
-file.write(""\n Transaction per client = "" + str(txns))
-file.write(""\n Total transactions requested = "" + str(ttl_txns))
-file.write(""\n Estimated transactions per second = "" + str(txns_per_second))
-file.close()
+import perf_add_requests
+import perf_get_requests
+import perf_load
+import perf_traffic
+import requests_sender
+import utils
+
+
+class Options:
+    def __init__(self):
+        parser = argparse.ArgumentParser(
+            description='This script will execute the test base on the '
+                        'mode that user passes to system.')
+
+        parser.add_argument('-a',
+                            help='Use this parameter to start adding '
+                                 'request performance testing',
+                            action='store_true',
+                            default=False, required=False, dest='adding')
+
+        parser.add_argument('-g',
+                            help='Use this parameter to start getting '
+                                 'request performance testing',
+                            action='store_true',
+                            default=False, required=False, dest='getting')
+
+        parser.add_argument('-l',
+                            help='Use this parameter to perform load test',
+                            action='store_true',
+                            default=False, required=False, dest='loading')
+
+        parser.add_argument('-t',
+                            help='Use this parameter to simulate traffic',
+                            action='store_true',
+                            default=False, required=False,
+                            dest='simulate_traffic')
+
+        parser.add_argument('-c',
+                            help='Number of client you want to create. '
+                                 'Default value will be 1',
+                            default=1, type=int, required=False,
+                            dest='clients')
+
+        parser.add_argument('-d',
+                            help='Directory you want to store requests '
+                                 'info when sending adding request. '
+                                 'If you start getting request testing, '
+                                 'program will collect info from '
+                                 'this dir instead.'
+                                 'Default value will be {}'.
+                            format(os.path.join(os.path.dirname(__file__),
+                                                ""request_info"")),
+                            default=os.path.join(os.path.dirname(__file__),
+                                                 ""request_info""),
+                            required=False,
+                            dest='info_dir')
+
+        parser.add_argument('-n',
+                            help='How many transactions you want to submit to '
+                                 'ledger when starting adding requests.'
+                                 'If you start getting request testing, '
+                                 'this arg will be ignore.'
+                                 'In case that you use flag ""-t"", this '
+                                 'parameter will be the number of '
+                                 'transactions of a set.'
+                                 'Default value will be 100',
+                            default=100, type=int, required=False, dest='txns')
+
+        parser.add_argument('-s',
+                            help='Number of thread will '
+                                 'be created by each client.'
+                                 'Default value is 1',
+                            default=1, type=int, required=False,
+                            dest='thread_num')
+
+        parser.add_argument('-k',
+                            help='Kind of request to be sent. '
+                                 'The default value will be ""nym""',
+                            action='store',
+                            choices=['nym', 'schema', 'attribute', 'claim'],
+                            default='nym', dest='kind', required=False)
+
+        parser.add_argument('--log',
+                            help='To see all log. If this flag does not exist,'
+                                 'program just only print fail message',
+                            action='store_true', default=False, dest='log',
+                            required=False)
+
+        parser.add_argument('-to',
+                            help='Timeout of testing. This flag '
+                                 'just visible in two mode ""-l"" and ""-t""'
+                                 'Default value will be 100.',
+                            action='store', type=int,
+                            default=100, dest='time_out', required=False)
+
+        parser.add_argument('--init',
+                            help='To build ""GET"" request, we need to '
+                                 'send ""ADD"" request first. This argument is '
+                                 'the number of ""ADD"" request will be sent '
+                                 'to ledger to make sample for ""GET"" requests.'
+                                 ' Default value will be 100',
+                            action='store', type=int, required=False,
+                            default=100, dest='number_of_request_samples')
+
+        self.args = parser.parse_args()
+
+
+class PerformanceTestRunner:
+    modes = [""-t"", ""-l"", ""-a"", ""-g""]
+
+    def __init__(self):
+        self.options = Options().args
+
+        self.tester = None
+
+        temp = 0
+        for mode in PerformanceTestRunner.modes:
+            if mode in sys.argv:
+                temp += 1
+
+        if temp == 0:
+            utils.print_error(
+                'Cannot determine any kind of request for testing')
+            utils.print_error(
+                'May be you missing arguments ""-a"" or ""-b"" or ""-t"" or ""-l""')
+            sys.exit(1)
+
+        if temp > 1:
+            utils.force_print_error_to_console(
+                '""-a"" and ""-g"" and ""-t"" and ""-l"" '
+                'cannot exist at the same time\n')
+            sys.exit(1)
+
+        self.list_tester = list()
+
+        self.start_time = self.finish_time = 0
+        self.lowest = self.fastest = 0
+        self.passed_req = self.failed_req = 0
+        self.result_path = os.path.join(os.path.dirname(__file__), 'results')
+        utils.create_folder(self.result_path)
+        log_path = os.path.join(os.path.dirname(__file__), 'logs')
+        utils.create_folder(log_path)
+
+        now = time.strftime(""%d-%m-%Y_%H-%M-%S"")
+        self.result_path = os.path.join(self.result_path,
+                                        'result_{}.txt'.format(now))
+
+        log_path = os.path.join(
+            log_path, self.create_log_file_name())
+        requests_sender.RequestsSender.init_log_file(log_path)
+        utils.create_folder(self.options.info_dir)
+
+    def run(self):
+        """"""
+        Run the test.
+        """"""
+
+        utils.print_header(""Start {}...\n"".format(self.get_kind_of_test()))
+
+        if not self.options.log:
+            utils.start_capture_console()
+        self.start_time = time.time()
+        if self.options.adding or self.options.getting \
+                and self.options.clients > 1:
+            self.start_tester_in_thread()
+        else:
+            self.list_tester.append(self.create_tester())
+            utils.run_async_method(None, self.list_tester[-1].test)
+
+        self.finish_time = time.time()
+
+        utils.stop_capture_console()
+        self.collect_result()
+        with open(self.result_path, 'w') as result:
+            self.write_result(result)
+        self.write_result(sys.stdout)
+        requests_sender.RequestsSender.close_log_file()
+
+        utils.print_header(""\nFinish {}\n"".format(self.get_kind_of_test()))
+
+    def collect_result(self):
+        """"""
+        Collect all necessary information to make the result.
+        """"""
+        self.passed_req = self.failed_req = 0
+        for tester in self.list_tester:
+            self.failed_req += tester.failed_req
+            self.passed_req += tester.passed_req
+
+        self.find_lowest_and_fastest_transaction()
+
+        self.find_start_and_finish_time()
+
+    def write_result(self, result_file):
+        """"""
+        Compute and write result to file.
+
+        :param result_file: the file that result will be written.
+        """"""
+        total_time = self.finish_time - self.start_time
+        hours = total_time / 3600
+        minutes = total_time / 60 % 60
+        seconds = total_time % 60
+
+        ttl_txns = int(self.passed_req + self.failed_req)
+
+        ttl_seconds = total_time
+        if ttl_seconds == 0:
+            print('\nThere is no request sent.\n', file=result_file)
+            return
+        txns_per_second = int(ttl_txns / ttl_seconds)
+        txns_per_client = ttl_txns / self.options.clients
+
+        print(""\n -----------  Total time to run the test: %dh:%dm:%ds"" % (
+            hours, minutes, seconds) + ""  -----------"", file=result_file)
+        print(""\n Kind: "" + self.get_kind_of_test(), file=result_file)
+        print(""\n Client(s): "" + str(self.options.clients), file=result_file)
+        print(""\n Fastest transaction (individual thread): {} second(s)"".
+              format(str(self.fastest)),
+              file=result_file)
+        print(""\n Lowest transaction (individual thread): {} second(s)"".
+              format(str(self.lowest)), file=result_file)
+        print(""\n Transaction per client: "" + str(int(txns_per_client)),
+              file=result_file)
+        print(""\n Total requested transactions: "" + str(int(ttl_txns)),
+              file=result_file)
+        print(""\n Total passed transactions: "" + str(self.passed_req),
+              file=result_file)
+        print(""\n Total failed transactions: "" + str(self.failed_req),
+              file=result_file)
+        print(""\n Average time of a transaction ""
+              ""(multiple threads): {} second(s)"".
+              format(str((self.finish_time - self.start_time) / ttl_txns)),
+              file=result_file)
+        print(""\n Estimated transactions per second: "" + str(txns_per_second),
+              file=result_file)
+
+    def find_lowest_and_fastest_transaction(self):
+        """"""
+        Find lowest and fastest transactions.
+        """"""
+        self.lowest = self.list_tester[0].lowest_txn
+        self.fastest = self.list_tester[0].fastest_txn
+        for tester in self.list_tester:
+            temp_lowest = tester.lowest_txn
+            temp_fastest = tester.fastest_txn
+            if self.lowest < temp_lowest:
+                self.lowest = temp_lowest
+            if self.fastest > temp_fastest:
+                self.fastest = temp_fastest
+
+    def find_start_and_finish_time(self):
+        """"""
+        Find the earliest time that a client is started and latest time that a
+        client is finished.
+        """"""
+        self.start_time = self.list_tester[0].start_time
+        self.finish_time = self.list_tester[0].finish_time
+
+        for tester in self.list_tester:
+            if self.start_time > tester.start_time:
+                self.start_time = tester.start_time
+
+            if self.finish_time < tester.finish_time:
+                self.finish_time = tester.finish_time
+
+    def start_tester_in_thread(self):
+        """"""
+        Create thread and start all the tester in list.
+        """"""
+        threads = list()
+        for _ in range(self.options.clients):
+            tester = self.create_tester()
+            self.list_tester.append(tester)
+            thread = threading.Thread(target=self.run_tester_in_thread,
+                                      kwargs={'tester': tester})
+            thread.daemon = True
+            thread.start()
+            threads.append(thread)
+
+        for thread in threads:
+            thread.join()
+
+    @staticmethod
+    def run_tester_in_thread(tester):
+        """"""
+        Execute testing function of tester.
+        """"""
+        loop = asyncio.new_event_loop()
+        utils.run_async_method(loop, tester.test)
+        loop.close()
+
+    def create_tester(self):
+        """"""
+        Create tester base mode ""-a"", ""-t"", ""-g"", ""-l"".
+
+        :return: tester
+        """"""
+        if self.options.adding:",428,2018-04-18 09:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182356119,https://github.com/hyperledger/indy-node/pull/643#discussion_r182356119,ashcherbakov
https://github.com/hyperledger/indy-node/pull/643,https://github.com/hyperledger/indy-node/pull/643,It looks like all scripts can't send requests in a real traffic mode. All of them are waiting for the result of the previous request before sending the next one.,0b300f8f9e8e4a56df75cd716af075724d12dcee,2018-04-18 09:01:12,182356314,"@@ -1,118 +1,374 @@
-#!/usr/bin/env python3
+""""""
+Created on Feb 2, 2018
+
+@author: nhan.nguyen
+
+This module contains class ""PerformanceTestRunner"" that executes the test base
+on the mode that user pass to system.
+""""""
+
 import os
 import argparse
 import time
+import threading
+import asyncio
 import sys
-from threading import Thread, Lock
-
-global txns
-global clients
-clients = 100
-txns = 100
-
-#                   ==================== Notes and information ====================
-# This script will run multiple instances (threaded) of the the Perf_Add_nyms.py script or the Perf_get_nyms.py. The
-# command line parameters for each script are different and can be set from this script without modifying Add_nyms or
-# Get_nyms scripts.
-# The settings for Perf runner are 'clients' and 'txns'.  Clients is the number of threads (or client machines) to use,
-# the txns indicates how many transactions will run per client (thread).  These settings are specific to Perf_runner.py
-#
-# The command line for both performance scripts is created in the 'command' variable found below.  The default setting
-# for Perf_Add_nyms.py uses the -n and -s parameters to specify the number of threads and clients to use.  The value
-# from clients is iterated through and uses 'i' to track which iteration is processing.
-# The default vaiables for the Add_nyms script will be  used.  If any of the default settings for Add_nyms or Get_nyms
-# needs to be modified, add the changes here to the perf runner by modifying the 'command' variable.
-#                   ================================================================
-# Example:
-# Run Perf_Add_nyms.py:   python3.6 Perf_runner.py -a
-# Run Perf_gert_nyms.py using 3 clients (threads) - by setting clients to 3:  python3.6 Perf_runner.py -g
-
-parser = argparse.ArgumentParser(description='This script will create multiple threads of the Perf_Add_nyms.py or '
-                                             'the Perf_get_nyms.py.')
-
-parser.add_argument('-a', help='Use this parameter to start Perf_Add_nyms.py', action='store_true',
-                    default=False, required=False)
-parser.add_argument('-g', help='Use this parameter to start Perf_get_nyms.py', action='store_true',
-                    default=False, required=False)
-
-# parser.print_help()
-results = parser.parse_args()
-if results.a:
-    results.a = 'Perf_Add_nyms.py'
-if results.g:
-    results.g = 'Perf_get_nyms.py'
-
-
-def run_test(i, lock):
-
-    print(""This is a test : "" + repr(results.g))
-    print(""This is a test : "" + repr(results.a))
-    if results.a:
-        # The value for -n is the 'txns' variable at the top of this script
-        command = 'python3 ' + results.a + ' -n ' + str(txns) + ' -s ' + repr(i)
-    elif results.g:
-        # The default values for -d -t and -g in get_nym will be used
-        command = 'python3 ' + results.g + ' -s ' + repr(clients) + ' -d nym_files'
-    else:
-        print(""\n\nPlease specify a script to use or run Perf_runner.py -h for additional information"")
-        sys.exit(1)
-
-    with lock:
-        print(""Starting thread {}"".format(i))
-
-    # Run the command
-    # print(command)
-    os.system(command)
-
-    with lock:
-        print(""Thread {} stopped"".format(i))
-
-
-# Create threads
-lock = Lock()
-
-# Start Time
-# timeBegin = datetime.now()
-overmind_start_time = time.time()
-
-# get the number of clients (threads) to create
-threads = [Thread(target=run_test, args=(i, lock)) for i in range(clients)]
-
-# Start threads
-for x in threads:
-    x.start()
-
-# Stop threads
-for x in threads:
-    x.join()
-
-# Total Time
-totalTime = time.time() - overmind_start_time
-
-hours = totalTime / 3600
-totalTime = 3600 * hours
-minutes = totalTime / 60
-seconds = 60 * minutes
-
-ttl_txns = clients * txns
-ttl_seconds = int((hours * 3600) + (minutes * 60) + seconds)
-try:
-    txns_per_second = int(ttl_txns / ttl_seconds)
-except Exception as E:
-    txns_per_second = None
-    print(""There is too small test run time that causes an error: "", E)
-
-print(""\n -----------  Total time to run the test: %dh:%dm:%ds"" % (hours, minutes, seconds) + ""  -----------"")
-print(""\n Clients = "" + str(clients))
-print(""\n Transaction per client = "" + str(txns))
-print(""\n Total transactions requested = "" + str(ttl_txns))
-print(""\n Estimated transactions per second = "" + str(txns_per_second))
-
-tm = time.strftime(""%d-%m-%Y_%H-%M-%S"")
-file = open(""test_results_time_"" + tm + "".log"", ""w"")
-file.write(""\n -----------  Total time to run the test: %dh:%dm:%ds"" % (hours, minutes, seconds) + ""  -----------\n"")
-file.write(""\n Clients = "" + str(clients))
-file.write(""\n Transaction per client = "" + str(txns))
-file.write(""\n Total transactions requested = "" + str(ttl_txns))
-file.write(""\n Estimated transactions per second = "" + str(txns_per_second))
-file.close()
+import perf_add_requests
+import perf_get_requests
+import perf_load
+import perf_traffic
+import requests_sender
+import utils
+
+
+class Options:
+    def __init__(self):
+        parser = argparse.ArgumentParser(
+            description='This script will execute the test base on the '
+                        'mode that user passes to system.')
+
+        parser.add_argument('-a',
+                            help='Use this parameter to start adding '
+                                 'request performance testing',
+                            action='store_true',
+                            default=False, required=False, dest='adding')
+
+        parser.add_argument('-g',
+                            help='Use this parameter to start getting '
+                                 'request performance testing',
+                            action='store_true',
+                            default=False, required=False, dest='getting')
+
+        parser.add_argument('-l',
+                            help='Use this parameter to perform load test',
+                            action='store_true',
+                            default=False, required=False, dest='loading')
+
+        parser.add_argument('-t',
+                            help='Use this parameter to simulate traffic',
+                            action='store_true',
+                            default=False, required=False,
+                            dest='simulate_traffic')
+
+        parser.add_argument('-c',
+                            help='Number of client you want to create. '
+                                 'Default value will be 1',
+                            default=1, type=int, required=False,
+                            dest='clients')
+
+        parser.add_argument('-d',
+                            help='Directory you want to store requests '
+                                 'info when sending adding request. '
+                                 'If you start getting request testing, '
+                                 'program will collect info from '
+                                 'this dir instead.'
+                                 'Default value will be {}'.
+                            format(os.path.join(os.path.dirname(__file__),
+                                                ""request_info"")),
+                            default=os.path.join(os.path.dirname(__file__),
+                                                 ""request_info""),
+                            required=False,
+                            dest='info_dir')
+
+        parser.add_argument('-n',
+                            help='How many transactions you want to submit to '
+                                 'ledger when starting adding requests.'
+                                 'If you start getting request testing, '
+                                 'this arg will be ignore.'
+                                 'In case that you use flag ""-t"", this '
+                                 'parameter will be the number of '
+                                 'transactions of a set.'
+                                 'Default value will be 100',
+                            default=100, type=int, required=False, dest='txns')
+
+        parser.add_argument('-s',
+                            help='Number of thread will '
+                                 'be created by each client.'
+                                 'Default value is 1',
+                            default=1, type=int, required=False,
+                            dest='thread_num')
+
+        parser.add_argument('-k',
+                            help='Kind of request to be sent. '
+                                 'The default value will be ""nym""',
+                            action='store',
+                            choices=['nym', 'schema', 'attribute', 'claim'],
+                            default='nym', dest='kind', required=False)
+
+        parser.add_argument('--log',
+                            help='To see all log. If this flag does not exist,'
+                                 'program just only print fail message',
+                            action='store_true', default=False, dest='log',
+                            required=False)
+
+        parser.add_argument('-to',
+                            help='Timeout of testing. This flag '
+                                 'just visible in two mode ""-l"" and ""-t""'
+                                 'Default value will be 100.',
+                            action='store', type=int,
+                            default=100, dest='time_out', required=False)
+
+        parser.add_argument('--init',
+                            help='To build ""GET"" request, we need to '
+                                 'send ""ADD"" request first. This argument is '
+                                 'the number of ""ADD"" request will be sent '
+                                 'to ledger to make sample for ""GET"" requests.'
+                                 ' Default value will be 100',
+                            action='store', type=int, required=False,
+                            default=100, dest='number_of_request_samples')
+
+        self.args = parser.parse_args()
+
+
+class PerformanceTestRunner:
+    modes = [""-t"", ""-l"", ""-a"", ""-g""]
+
+    def __init__(self):
+        self.options = Options().args
+
+        self.tester = None
+
+        temp = 0
+        for mode in PerformanceTestRunner.modes:
+            if mode in sys.argv:
+                temp += 1
+
+        if temp == 0:
+            utils.print_error(
+                'Cannot determine any kind of request for testing')
+            utils.print_error(
+                'May be you missing arguments ""-a"" or ""-b"" or ""-t"" or ""-l""')
+            sys.exit(1)
+
+        if temp > 1:
+            utils.force_print_error_to_console(
+                '""-a"" and ""-g"" and ""-t"" and ""-l"" '
+                'cannot exist at the same time\n')
+            sys.exit(1)
+
+        self.list_tester = list()
+
+        self.start_time = self.finish_time = 0
+        self.lowest = self.fastest = 0
+        self.passed_req = self.failed_req = 0
+        self.result_path = os.path.join(os.path.dirname(__file__), 'results')
+        utils.create_folder(self.result_path)
+        log_path = os.path.join(os.path.dirname(__file__), 'logs')
+        utils.create_folder(log_path)
+
+        now = time.strftime(""%d-%m-%Y_%H-%M-%S"")
+        self.result_path = os.path.join(self.result_path,
+                                        'result_{}.txt'.format(now))
+
+        log_path = os.path.join(
+            log_path, self.create_log_file_name())
+        requests_sender.RequestsSender.init_log_file(log_path)
+        utils.create_folder(self.options.info_dir)
+
+    def run(self):
+        """"""
+        Run the test.
+        """"""
+
+        utils.print_header(""Start {}...\n"".format(self.get_kind_of_test()))
+
+        if not self.options.log:
+            utils.start_capture_console()
+        self.start_time = time.time()
+        if self.options.adding or self.options.getting \
+                and self.options.clients > 1:
+            self.start_tester_in_thread()
+        else:
+            self.list_tester.append(self.create_tester())
+            utils.run_async_method(None, self.list_tester[-1].test)
+
+        self.finish_time = time.time()
+
+        utils.stop_capture_console()
+        self.collect_result()
+        with open(self.result_path, 'w') as result:
+            self.write_result(result)
+        self.write_result(sys.stdout)
+        requests_sender.RequestsSender.close_log_file()
+
+        utils.print_header(""\nFinish {}\n"".format(self.get_kind_of_test()))
+
+    def collect_result(self):
+        """"""
+        Collect all necessary information to make the result.
+        """"""
+        self.passed_req = self.failed_req = 0
+        for tester in self.list_tester:
+            self.failed_req += tester.failed_req
+            self.passed_req += tester.passed_req
+
+        self.find_lowest_and_fastest_transaction()
+
+        self.find_start_and_finish_time()
+
+    def write_result(self, result_file):
+        """"""
+        Compute and write result to file.
+
+        :param result_file: the file that result will be written.
+        """"""
+        total_time = self.finish_time - self.start_time
+        hours = total_time / 3600
+        minutes = total_time / 60 % 60
+        seconds = total_time % 60
+
+        ttl_txns = int(self.passed_req + self.failed_req)
+
+        ttl_seconds = total_time
+        if ttl_seconds == 0:
+            print('\nThere is no request sent.\n', file=result_file)
+            return
+        txns_per_second = int(ttl_txns / ttl_seconds)
+        txns_per_client = ttl_txns / self.options.clients
+
+        print(""\n -----------  Total time to run the test: %dh:%dm:%ds"" % (
+            hours, minutes, seconds) + ""  -----------"", file=result_file)
+        print(""\n Kind: "" + self.get_kind_of_test(), file=result_file)
+        print(""\n Client(s): "" + str(self.options.clients), file=result_file)
+        print(""\n Fastest transaction (individual thread): {} second(s)"".
+              format(str(self.fastest)),
+              file=result_file)
+        print(""\n Lowest transaction (individual thread): {} second(s)"".
+              format(str(self.lowest)), file=result_file)
+        print(""\n Transaction per client: "" + str(int(txns_per_client)),
+              file=result_file)
+        print(""\n Total requested transactions: "" + str(int(ttl_txns)),
+              file=result_file)
+        print(""\n Total passed transactions: "" + str(self.passed_req),
+              file=result_file)
+        print(""\n Total failed transactions: "" + str(self.failed_req),
+              file=result_file)
+        print(""\n Average time of a transaction ""
+              ""(multiple threads): {} second(s)"".
+              format(str((self.finish_time - self.start_time) / ttl_txns)),
+              file=result_file)
+        print(""\n Estimated transactions per second: "" + str(txns_per_second),
+              file=result_file)
+
+    def find_lowest_and_fastest_transaction(self):
+        """"""
+        Find lowest and fastest transactions.
+        """"""
+        self.lowest = self.list_tester[0].lowest_txn
+        self.fastest = self.list_tester[0].fastest_txn
+        for tester in self.list_tester:
+            temp_lowest = tester.lowest_txn
+            temp_fastest = tester.fastest_txn
+            if self.lowest < temp_lowest:
+                self.lowest = temp_lowest
+            if self.fastest > temp_fastest:
+                self.fastest = temp_fastest
+
+    def find_start_and_finish_time(self):
+        """"""
+        Find the earliest time that a client is started and latest time that a
+        client is finished.
+        """"""
+        self.start_time = self.list_tester[0].start_time
+        self.finish_time = self.list_tester[0].finish_time
+
+        for tester in self.list_tester:
+            if self.start_time > tester.start_time:
+                self.start_time = tester.start_time
+
+            if self.finish_time < tester.finish_time:
+                self.finish_time = tester.finish_time
+
+    def start_tester_in_thread(self):
+        """"""
+        Create thread and start all the tester in list.
+        """"""
+        threads = list()
+        for _ in range(self.options.clients):
+            tester = self.create_tester()
+            self.list_tester.append(tester)
+            thread = threading.Thread(target=self.run_tester_in_thread,
+                                      kwargs={'tester': tester})
+            thread.daemon = True
+            thread.start()
+            threads.append(thread)
+
+        for thread in threads:
+            thread.join()
+
+    @staticmethod
+    def run_tester_in_thread(tester):
+        """"""
+        Execute testing function of tester.
+        """"""
+        loop = asyncio.new_event_loop()
+        utils.run_async_method(loop, tester.test)
+        loop.close()
+
+    def create_tester(self):
+        """"""
+        Create tester base mode ""-a"", ""-t"", ""-g"", ""-l"".
+
+        :return: tester
+        """"""
+        if self.options.adding:
+            return perf_add_requests.PerformanceTesterForAddingRequest(
+                self.options.info_dir, self.options.txns, self.options.kind,
+                thread_num=self.options.thread_num, log=self.options.log)
+
+        elif self.options.getting:
+            return perf_get_requests.PerformanceTesterGetSentRequestFromLedger(
+                self.options.info_dir, self.options.kind,
+                self.options.thread_num, log=self.options.log)
+
+        elif self.options.loading:
+            return perf_load.TesterSimulateLoad(
+                self.options.clients, self.options.txns,
+                self.options.time_out, self.options.log)
+
+        elif self.options.simulate_traffic:",443,2018-04-18 09:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/182356314,https://github.com/hyperledger/indy-node/pull/643#discussion_r182356314,ashcherbakov
https://github.com/hyperledger/indy-node/pull/633,https://github.com/hyperledger/indy-node/pull/633,I think it should be re-factored using intermediate result variable.,64f531f35309babefd491ed19127234dabcdf11d,2018-03-30 16:14:47,178320219,"@@ -499,55 +495,53 @@ def handleGetRevocRegDelta(self, request: Request):
         req_ts_from = request.operation.get(FROM, None)
         req_ts_to = request.operation.get(TO)
         revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
-        author_did = request.identifier
         reply = None
         # Get root hash for ""to"" timestamp
         # Get REVOC_REG_ENTRY and ACCUM record for timestamp ""to""
-        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
-                                                                       revoc_reg_def_id=revoc_reg_def_id)
-        path_to_reg_entry_accum = domain.make_state_path_for_revoc_reg_entry_accum(authors_did=author_did,
-                                                                                   revoc_reg_def_id=revoc_reg_def_id)
+        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(revoc_reg_def_id=revoc_reg_def_id)
+        path_to_reg_entry_accum = domain.make_state_path_for_revoc_reg_entry_accum(revoc_reg_def_id=revoc_reg_def_id)
         past_root_to, reg_entry_to = self._get_reg_entry_by_timestamp(req_ts_to, path_to_reg_entry)
         reg_entry_accum_to, \
             seq_no_to, \
             last_update_time_to, \
             reg_entry_accum_proof_to = self._get_reg_entry_accum_by_timestamp(req_ts_to, path_to_reg_entry_accum)
-        if past_root_to:
+        if reg_entry_accum_to and past_root_to:
             # Get issuance type from REVOC_REG_DEF
-            encoded_revoc_reg_def = self.state.get_for_root_hash(past_root_to, revoc_reg_def_id)
-            assert encoded_revoc_reg_def
-            revoc_reg_def, _, _ = domain.decode_state_value(encoded_revoc_reg_def)
-            strategy_cls = self.get_revocation_strategy(revoc_reg_def[VALUE][ISSUANCE_TYPE])
-
-            if req_ts_from:
-                past_root_from, reg_entry_from = self._get_reg_entry_by_timestamp(req_ts_from, path_to_reg_entry)
-                req_entry_accum_from, \
-                    seq_no_from, \
-                    last_update_time_from, \
-                    reg_entry_accum_proof_from = self._get_reg_entry_accum_by_timestamp(req_ts_from, path_to_reg_entry_accum)
-                # Compute issued/revoked lists corresponding with ISSUANCE_TYPE strategy
-                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_to[VALUE].get(REVOKED, [])},
-                                                                       {ISSUED: reg_entry_from[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_from[VALUE].get(REVOKED, [])})
-            else:
-                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_to[VALUE].get(REVOKED, [])},
-                                                                       None)
-            reply = {
-                REVOC_REG_ID: str(path_to_reg_entry),
-                REVOC_TYPE: revoc_reg_def.get(REVOC_TYPE),
-                VALUE: {
-                    ACCUM_TO: reg_entry_accum_to,
-                    ISSUED: result_issued,
-                    REVOKED: result_revoked
-                }
+            encoded_revoc_reg_def = self.state.get_for_root_hash(past_root_to,
+                                                                 revoc_reg_def_id)
+            if encoded_revoc_reg_def:
+                revoc_reg_def, _, _ = domain.decode_state_value(encoded_revoc_reg_def)
+                strategy_cls = self.get_revocation_strategy(revoc_reg_def[VALUE][ISSUANCE_TYPE])
+
+                if req_ts_from:
+                    past_root_from, reg_entry_from = self._get_reg_entry_by_timestamp(req_ts_from, path_to_reg_entry)
+                    req_entry_accum_from, \
+                        seq_no_from, \
+                        last_update_time_from, \
+                        reg_entry_accum_proof_from = self._get_reg_entry_accum_by_timestamp(req_ts_from, path_to_reg_entry_accum)",,2018-04-02 08:01:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/178320219,https://github.com/hyperledger/indy-node/pull/633#discussion_r178320219,sergey-shilov
https://github.com/hyperledger/indy-node/pull/633,https://github.com/hyperledger/indy-node/pull/633,"Passed objects should be stored in separate variables, it is really hard to read.",64f531f35309babefd491ed19127234dabcdf11d,2018-03-30 16:17:04,178320602,"@@ -499,55 +495,53 @@ def handleGetRevocRegDelta(self, request: Request):
         req_ts_from = request.operation.get(FROM, None)
         req_ts_to = request.operation.get(TO)
         revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
-        author_did = request.identifier
         reply = None
         # Get root hash for ""to"" timestamp
         # Get REVOC_REG_ENTRY and ACCUM record for timestamp ""to""
-        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
-                                                                       revoc_reg_def_id=revoc_reg_def_id)
-        path_to_reg_entry_accum = domain.make_state_path_for_revoc_reg_entry_accum(authors_did=author_did,
-                                                                                   revoc_reg_def_id=revoc_reg_def_id)
+        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(revoc_reg_def_id=revoc_reg_def_id)
+        path_to_reg_entry_accum = domain.make_state_path_for_revoc_reg_entry_accum(revoc_reg_def_id=revoc_reg_def_id)
         past_root_to, reg_entry_to = self._get_reg_entry_by_timestamp(req_ts_to, path_to_reg_entry)
         reg_entry_accum_to, \
             seq_no_to, \
             last_update_time_to, \
             reg_entry_accum_proof_to = self._get_reg_entry_accum_by_timestamp(req_ts_to, path_to_reg_entry_accum)
-        if past_root_to:
+        if reg_entry_accum_to and past_root_to:
             # Get issuance type from REVOC_REG_DEF
-            encoded_revoc_reg_def = self.state.get_for_root_hash(past_root_to, revoc_reg_def_id)
-            assert encoded_revoc_reg_def
-            revoc_reg_def, _, _ = domain.decode_state_value(encoded_revoc_reg_def)
-            strategy_cls = self.get_revocation_strategy(revoc_reg_def[VALUE][ISSUANCE_TYPE])
-
-            if req_ts_from:
-                past_root_from, reg_entry_from = self._get_reg_entry_by_timestamp(req_ts_from, path_to_reg_entry)
-                req_entry_accum_from, \
-                    seq_no_from, \
-                    last_update_time_from, \
-                    reg_entry_accum_proof_from = self._get_reg_entry_accum_by_timestamp(req_ts_from, path_to_reg_entry_accum)
-                # Compute issued/revoked lists corresponding with ISSUANCE_TYPE strategy
-                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_to[VALUE].get(REVOKED, [])},
-                                                                       {ISSUED: reg_entry_from[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_from[VALUE].get(REVOKED, [])})
-            else:
-                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_to[VALUE].get(REVOKED, [])},
-                                                                       None)
-            reply = {
-                REVOC_REG_ID: str(path_to_reg_entry),
-                REVOC_TYPE: revoc_reg_def.get(REVOC_TYPE),
-                VALUE: {
-                    ACCUM_TO: reg_entry_accum_to,
-                    ISSUED: result_issued,
-                    REVOKED: result_revoked
-                }
+            encoded_revoc_reg_def = self.state.get_for_root_hash(past_root_to,
+                                                                 revoc_reg_def_id)
+            if encoded_revoc_reg_def:
+                revoc_reg_def, _, _ = domain.decode_state_value(encoded_revoc_reg_def)
+                strategy_cls = self.get_revocation_strategy(revoc_reg_def[VALUE][ISSUANCE_TYPE])
+
+                if req_ts_from:
+                    past_root_from, reg_entry_from = self._get_reg_entry_by_timestamp(req_ts_from, path_to_reg_entry)
+                    req_entry_accum_from, \
+                        seq_no_from, \
+                        last_update_time_from, \
+                        reg_entry_accum_proof_from = self._get_reg_entry_accum_by_timestamp(req_ts_from, path_to_reg_entry_accum)
+                    # Compute issued/revoked lists corresponding with ISSUANCE_TYPE strategy
+                    result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),",,2018-04-02 08:01:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/178320602,https://github.com/hyperledger/indy-node/pull/633#discussion_r178320602,sergey-shilov
https://github.com/hyperledger/indy-node/pull/633,https://github.com/hyperledger/indy-node/pull/633,"Passed object should be stored in separate variable, it is really hard to read.",64f531f35309babefd491ed19127234dabcdf11d,2018-03-30 16:17:19,178320644,"@@ -499,55 +495,53 @@ def handleGetRevocRegDelta(self, request: Request):
         req_ts_from = request.operation.get(FROM, None)
         req_ts_to = request.operation.get(TO)
         revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
-        author_did = request.identifier
         reply = None
         # Get root hash for ""to"" timestamp
         # Get REVOC_REG_ENTRY and ACCUM record for timestamp ""to""
-        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
-                                                                       revoc_reg_def_id=revoc_reg_def_id)
-        path_to_reg_entry_accum = domain.make_state_path_for_revoc_reg_entry_accum(authors_did=author_did,
-                                                                                   revoc_reg_def_id=revoc_reg_def_id)
+        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(revoc_reg_def_id=revoc_reg_def_id)
+        path_to_reg_entry_accum = domain.make_state_path_for_revoc_reg_entry_accum(revoc_reg_def_id=revoc_reg_def_id)
         past_root_to, reg_entry_to = self._get_reg_entry_by_timestamp(req_ts_to, path_to_reg_entry)
         reg_entry_accum_to, \
             seq_no_to, \
             last_update_time_to, \
             reg_entry_accum_proof_to = self._get_reg_entry_accum_by_timestamp(req_ts_to, path_to_reg_entry_accum)
-        if past_root_to:
+        if reg_entry_accum_to and past_root_to:
             # Get issuance type from REVOC_REG_DEF
-            encoded_revoc_reg_def = self.state.get_for_root_hash(past_root_to, revoc_reg_def_id)
-            assert encoded_revoc_reg_def
-            revoc_reg_def, _, _ = domain.decode_state_value(encoded_revoc_reg_def)
-            strategy_cls = self.get_revocation_strategy(revoc_reg_def[VALUE][ISSUANCE_TYPE])
-
-            if req_ts_from:
-                past_root_from, reg_entry_from = self._get_reg_entry_by_timestamp(req_ts_from, path_to_reg_entry)
-                req_entry_accum_from, \
-                    seq_no_from, \
-                    last_update_time_from, \
-                    reg_entry_accum_proof_from = self._get_reg_entry_accum_by_timestamp(req_ts_from, path_to_reg_entry_accum)
-                # Compute issued/revoked lists corresponding with ISSUANCE_TYPE strategy
-                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_to[VALUE].get(REVOKED, [])},
-                                                                       {ISSUED: reg_entry_from[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_from[VALUE].get(REVOKED, [])})
-            else:
-                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_to[VALUE].get(REVOKED, [])},
-                                                                       None)
-            reply = {
-                REVOC_REG_ID: str(path_to_reg_entry),
-                REVOC_TYPE: revoc_reg_def.get(REVOC_TYPE),
-                VALUE: {
-                    ACCUM_TO: reg_entry_accum_to,
-                    ISSUED: result_issued,
-                    REVOKED: result_revoked
-                }
+            encoded_revoc_reg_def = self.state.get_for_root_hash(past_root_to,
+                                                                 revoc_reg_def_id)
+            if encoded_revoc_reg_def:
+                revoc_reg_def, _, _ = domain.decode_state_value(encoded_revoc_reg_def)
+                strategy_cls = self.get_revocation_strategy(revoc_reg_def[VALUE][ISSUANCE_TYPE])
+
+                if req_ts_from:
+                    past_root_from, reg_entry_from = self._get_reg_entry_by_timestamp(req_ts_from, path_to_reg_entry)
+                    req_entry_accum_from, \
+                        seq_no_from, \
+                        last_update_time_from, \
+                        reg_entry_accum_proof_from = self._get_reg_entry_accum_by_timestamp(req_ts_from, path_to_reg_entry_accum)
+                    # Compute issued/revoked lists corresponding with ISSUANCE_TYPE strategy
+                    result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),
+                                                                            REVOKED: reg_entry_to[VALUE].get(REVOKED, [])},
+                                                                           {ISSUED: reg_entry_from[VALUE].get(ISSUED, []),
+                                                                            REVOKED: reg_entry_from[VALUE].get(REVOKED, [])})
+                else:
+                    result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),",,2018-04-02 08:01:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/178320644,https://github.com/hyperledger/indy-node/pull/633#discussion_r178320644,sergey-shilov
https://github.com/hyperledger/indy-node/pull/633,https://github.com/hyperledger/indy-node/pull/633,What about moving it to a separate helper function?,64f531f35309babefd491ed19127234dabcdf11d,2018-03-30 16:26:30,178322316,"@@ -499,55 +495,53 @@ def handleGetRevocRegDelta(self, request: Request):
         req_ts_from = request.operation.get(FROM, None)
         req_ts_to = request.operation.get(TO)
         revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
-        author_did = request.identifier
         reply = None
         # Get root hash for ""to"" timestamp
         # Get REVOC_REG_ENTRY and ACCUM record for timestamp ""to""
-        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
-                                                                       revoc_reg_def_id=revoc_reg_def_id)
-        path_to_reg_entry_accum = domain.make_state_path_for_revoc_reg_entry_accum(authors_did=author_did,
-                                                                                   revoc_reg_def_id=revoc_reg_def_id)
+        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(revoc_reg_def_id=revoc_reg_def_id)
+        path_to_reg_entry_accum = domain.make_state_path_for_revoc_reg_entry_accum(revoc_reg_def_id=revoc_reg_def_id)
         past_root_to, reg_entry_to = self._get_reg_entry_by_timestamp(req_ts_to, path_to_reg_entry)
         reg_entry_accum_to, \
             seq_no_to, \
             last_update_time_to, \
             reg_entry_accum_proof_to = self._get_reg_entry_accum_by_timestamp(req_ts_to, path_to_reg_entry_accum)
-        if past_root_to:
+        if reg_entry_accum_to and past_root_to:
             # Get issuance type from REVOC_REG_DEF
-            encoded_revoc_reg_def = self.state.get_for_root_hash(past_root_to, revoc_reg_def_id)
-            assert encoded_revoc_reg_def
-            revoc_reg_def, _, _ = domain.decode_state_value(encoded_revoc_reg_def)
-            strategy_cls = self.get_revocation_strategy(revoc_reg_def[VALUE][ISSUANCE_TYPE])
-
-            if req_ts_from:
-                past_root_from, reg_entry_from = self._get_reg_entry_by_timestamp(req_ts_from, path_to_reg_entry)
-                req_entry_accum_from, \
-                    seq_no_from, \
-                    last_update_time_from, \
-                    reg_entry_accum_proof_from = self._get_reg_entry_accum_by_timestamp(req_ts_from, path_to_reg_entry_accum)
-                # Compute issued/revoked lists corresponding with ISSUANCE_TYPE strategy
-                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_to[VALUE].get(REVOKED, [])},
-                                                                       {ISSUED: reg_entry_from[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_from[VALUE].get(REVOKED, [])})
-            else:
-                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE].get(ISSUED, []),
-                                                                        REVOKED: reg_entry_to[VALUE].get(REVOKED, [])},
-                                                                       None)
-            reply = {
-                REVOC_REG_ID: str(path_to_reg_entry),
-                REVOC_TYPE: revoc_reg_def.get(REVOC_TYPE),
-                VALUE: {
-                    ACCUM_TO: reg_entry_accum_to,
-                    ISSUED: result_issued,
-                    REVOKED: result_revoked
-                }
+            encoded_revoc_reg_def = self.state.get_for_root_hash(past_root_to,
+                                                                 revoc_reg_def_id)
+            if encoded_revoc_reg_def:
+                revoc_reg_def, _, _ = domain.decode_state_value(encoded_revoc_reg_def)
+                strategy_cls = self.get_revocation_strategy(revoc_reg_def[VALUE][ISSUANCE_TYPE])
+
+                if req_ts_from:",,2018-04-02 08:01:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/178322316,https://github.com/hyperledger/indy-node/pull/633#discussion_r178322316,sergey-shilov
https://github.com/hyperledger/indy-node/pull/629,https://github.com/hyperledger/indy-node/pull/629,Are not empty?,c48f31b756c681be6e14c13f9f62fc36a647eeb5,2018-03-28 08:38:57,177676140,"@@ -47,6 +55,18 @@ def validate(self, current_entry, req: Request):
                                        ""value: {} in transaction"".format(
                                            current_accum,
                                            value_from_state.get(PREV_ACCUM)))
+        if len(issued_from_txn) == 0 and len(revoked_from_txn) == 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Got '{}' and '{}' but '{}' and '{}' lists are empty"".format(
+                                           PREV_ACCUM, ACCUM,
+                                           ISSUED, REVOKED))
+        if prev_accum == accum and (len(issued_from_txn) > 0 or len(revoked_from_txn) > 0):
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Got equal accum and prev_accum but ""
+                                       ""issued and revoked indicies are empty"")",,2018-03-28 10:26:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/177676140,https://github.com/hyperledger/indy-node/pull/629#discussion_r177676140,ashcherbakov
https://github.com/hyperledger/indy-node/pull/625,https://github.com/hyperledger/indy-node/pull/625,I think we can now remove libsodium18 from other places (like Vagrant) so that we test that it's installed properly.,8e0b68f1224079f9d47d955124d008c9094acfea,2018-03-23 16:02:40,176783442,"@@ -27,6 +27,7 @@ fpm --input-type ""python"" \
     --exclude ""*.pyo"" \
     --depends at \
     --depends iptables \
+    --depends libsodium18 \",4,2018-03-26 08:24:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176783442,https://github.com/hyperledger/indy-node/pull/625#discussion_r176783442,ashcherbakov
https://github.com/hyperledger/indy-node/pull/625,https://github.com/hyperledger/indy-node/pull/625,"Yes. After this fix, libsodium18 installation steps in vagrant/docker will not be needed.",8e0b68f1224079f9d47d955124d008c9094acfea,2018-03-23 16:11:24,176785991,"@@ -27,6 +27,7 @@ fpm --input-type ""python"" \
     --exclude ""*.pyo"" \
     --depends at \
     --depends iptables \
+    --depends libsodium18 \",4,2018-03-26 08:24:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176785991,https://github.com/hyperledger/indy-node/pull/625#discussion_r176785991,anikitinDSR
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"This field must be replaced with `DATETIME` (please introduce such the constant with `'datetime'` value). `DATETIME` will contain a string representation of a datetime, so it will be of the type `NonEmptyStringField(optional=true)`.",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 15:42:33,176776567,"@@ -273,6 +273,14 @@ class ClientPoolUpgradeOperation(MessageValidator):
     )
 
 
+class ClientPoolRestartOperation(MessageValidator):
+    schema = (
+        (TXN_TYPE, ConstantField(POOL_RESTART)),
+        (ACTION, ChooseField(values=(START, CANCEL,))),
+        (SCHEDULE, NonNegativeNumberField(optional=True)),  # TODO: correct format for field",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176776567,https://github.com/hyperledger/indy-node/pull/624#discussion_r176776567,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,This message validator must be registered in `indy_common.types.ClientOperationField` for `POOL_RESTART` operation type.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 15:49:20,176778941,"@@ -273,6 +273,14 @@ class ClientPoolUpgradeOperation(MessageValidator):
     )
 
 
+class ClientPoolRestartOperation(MessageValidator):",23,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176778941,https://github.com/hyperledger/indy-node/pull/624#discussion_r176778941,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"Actually `POOL_RESTART` does not relate to any of the currently existing `RequestHandler` subclasses. Each currently existing `RequestHandler` subclass (except for test ones) is specific to some ledger. It serves a number of write requests (`write_types`) and query requests (`query_types`) related to this ledger. Action requests will not relate to any ledger. So they need their own request handler. Let's name it `ActionRequestHandler`.

Currently the base class `RequestHandler` implies handling of requests related to some ledger. So let's extract ledger-oriented stuff (such as `commit`, `updateState`, etc.) from `RequestHandler` to its new subclass `LedgerRequestHandler`. So `RequestHandler` will contain only common stuff (such as `doStaticValidation`, `validate`, `apply`, etc.). `ActionRequestHandler` will inherit `RequestHandler` while all specific ledger handlers will inherit `LedgerRequestHandler`.

Fields `write_types` and `query_types` will be introduced on `LedgerRequestHandler` level. On `RequestHandler` level more common `operation_types` must be introduced. `POOL_RESTART` operation type will be included into `operation_types` of `ActionRequestHandler` and will be handled there.",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 17:14:06,176804792,"@@ -16,13 +17,14 @@
 
 
 class ConfigReqHandler(RequestHandler):
-    write_types = {POOL_UPGRADE, NODE_UPGRADE, POOL_CONFIG}
+    write_types = {POOL_UPGRADE, NODE_UPGRADE, POOL_CONFIG, POOL_RESTART}",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176804792,https://github.com/hyperledger/indy-node/pull/624#discussion_r176804792,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"`POOL_RESTART` is not related to any ledger and so must not be included into `write_types` or `query_types`. See the comment below for details.

Instead, in `CoreAuthMixin` a field `action_types` and a method `is_action` should be introduced. `POOL_RESTART` should be included into `action_types`. However, it may be included into `action_types` of some subclass of `CoreAuthMixin` because `CoreAuthMixin` itself is defined on plenum level.",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 17:46:26,176814007,"@@ -17,9 +18,11 @@ class LedgerBasedAuthNr(CoreAuthMixin, NaclAuthNr):
     """"""
 
     write_types = CoreAuthMixin.write_types.union({ATTRIB, SCHEMA, CLAIM_DEF,
-                                                   POOL_CONFIG, POOL_UPGRADE, REVOC_REG_DEF, REVOC_REG_ENTRY})
+                                                   POOL_CONFIG, POOL_UPGRADE, POOL_RESTART,",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176814007,https://github.com/hyperledger/indy-node/pull/624#discussion_r176814007,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"We should avoid comparison with specific operation types in `Node.processRequest` without strong necessity. Instead, we should introduce `Node.is_action` method (that will use `ActionRequestHandler.operation_types` list) and use it here to dispatch the request (decide whether or not to pass the request to `ActionRequestHandler` instance).",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 18:12:43,176822396,"@@ -296,22 +308,54 @@ def processRequest(self, request: Request, frm: str):
             self.process_query(request, frm)
             self.total_read_request_number += 1
         else:
+            if request.operation[TXN_TYPE] == POOL_RESTART:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176822396,https://github.com/hyperledger/indy-node/pull/624#discussion_r176822396,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,The value for `Reply.result` should be produced in `ActionRequestHandler` (in the same way as implementations of `RequestHandler.get_query_response` produce `Reply.result` value for query-requests). `Node` should only wrap the produced result into `Reply` instance.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 18:25:11,176825897,"@@ -296,22 +308,54 @@ def processRequest(self, request: Request, frm: str):
             self.process_query(request, frm)
             self.total_read_request_number += 1
         else:
+            if request.operation[TXN_TYPE] == POOL_RESTART:
+                reply = {}
+                try:
+                    self.configReqHandler.validate(request)
+                    reply = self.generate_action_result(request)
+                    if not self.isProcessingReq(*request.key):
+                        self.startedProcessingReq(*request.key, frm)
+                except Exception as ex:
+                    reply = self.generate_action_result(request,
+                                                        False,
+                                                        ex.args[0])
+                    logger.warning(""Restart is failed"")
+                finally:
+                    self.sendReplyToClient(reply,
+                                           (request.identifier, request.reqId))
+                    self.configReqHandler.applyRestart(request)
             # forced request should be processed before consensus
             if (request.operation[TXN_TYPE] in [
                     POOL_UPGRADE, POOL_CONFIG]) and request.isForced():
                 self.configReqHandler.validate(request)
                 self.configReqHandler.applyForced(request)
             # here we should have write transactions that should be processed
+            # pool_restart should not be written to ledger
             # only on writable pool
-            if self.poolCfg.isWritable() or (request.operation[TXN_TYPE] in [
-                    POOL_UPGRADE, POOL_CONFIG]):
+            if request.operation[TXN_TYPE] != POOL_RESTART and (
+                self.poolCfg.isWritable() or (request.operation[TXN_TYPE] in [
+                    POOL_UPGRADE, POOL_CONFIG])):
                 super().processRequest(request, frm)
-            else:
+
+            elif request.operation[TXN_TYPE] != POOL_RESTART:
                 raise InvalidClientRequest(
                     request.identifier,
                     request.reqId,
                     'Pool is in readonly mode, try again in 60 seconds')
 
+    def generate_action_result(self, request: Request, is_success=True,",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176825897,https://github.com/hyperledger/indy-node/pull/624#discussion_r176825897,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,I think that we need not a separate class for handling each command involving `NodeControlTool`. It should be one class. So far it was `Upgrader`. Let's rename it to `NodeController`. It will be responsible for handling all the commands involving `NodeControlTool`.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 18:34:11,176828993,"@@ -0,0 +1,159 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_UPGRADE, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, NODE_UPGRADE, IN_PROGRESS, FORCE, \
+    POOL_RESTART, RESTART
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(HasActionQueue):",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176828993,https://github.com/hyperledger/indy-node/pull/624#discussion_r176828993,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Both `RestartMessage` and `UpgradeMessage` should be subclasses of a common base class of messages to `NodeControlTool`. Let's name it `NodeControlMessage`. `NodeControlMessage` must declare `msg_type` field. This field must get proper values in the subclasses.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 18:40:09,176830654,"@@ -0,0 +1,159 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_UPGRADE, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, NODE_UPGRADE, IN_PROGRESS, FORCE, \
+    POOL_RESTART, RESTART
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(HasActionQueue):
+
+    def __init__(self,
+                 nodeId,
+                 nodeName,
+                 dataDir,
+                 config,
+                 ledger,
+                 restart_failed_callback: Callable = None,
+                 restart_start_callback: Callable = None):
+
+        self.nodeId = nodeId
+        self.nodeName = nodeName
+        self.config = config
+        self.dataDir = dataDir
+        self.ledger = ledger
+        self.scheduled_restart = None  # type: Tuple[str, int, str]
+        self._notifier = notifier_plugin_manager.PluginManager()
+        self._restartFailedCallback = \
+            restart_failed_callback if restart_failed_callback else lambda: None
+        self._restart_start_callback = \
+            restart_start_callback if restart_start_callback else lambda: None
+
+        self.retry_timeout = 5
+        self.retry_limit = 3
+
+        HasActionQueue.__init__(self)
+
+    def __repr__(self):
+        # Since nodeid can be null till pool ledger has not caught up
+        return self.nodeId or ''
+
+    def service(self):
+        return self._serviceActions()
+
+    def handleRestartTxn(self, txn) -> None:
+        """"""
+        Handles transaction of type POOL_RESTART
+        Can schedule to restart node
+
+        :param txn:
+        """"""
+        logger.info(""Node '{}' handles restart txn {}"".format(
+            self.nodeName, txn))
+        action = txn[DATA][ACTION]
+        restart_id = None
+        if action == START:
+            when = txn[DATA][SCHEDULE]
+            if isinstance(when, str):
+                when = dateutil.parser.parse(when)
+            if self.scheduled_restart:
+                self._schedule_restart(when, restart_id)
+            self._call_restart_agent()
+
+    def _schedule_restart(self,
+                          when: Union[datetime, str],
+                          restart_id) -> None:
+        """"""
+        Schedules node restart to a newer version
+
+        :param when: restart time
+        :param restart_id: restart identifier (req_id+seq_no) of a txn that started the restart
+        """"""
+        assert isinstance(when, (str, datetime))
+        logger.info(""{}'s restarter processing restart""
+                    .format(self))
+        if isinstance(when, str):
+            when = dateutil.parser.parse(when)
+        now = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
+
+        # self._notifier.sendMessageUponNodeRestarteScheduled(
+        #     ""Restart of node has been scheduled on {}"".format(
+        #         self.nodeName, when))
+        # self._restartLog.appendScheduled(when, restart_id)
+
+        call_agent = partial(self._call_restart_agent)
+        delay = 0
+        if now < when:
+            delay = (when - now).total_seconds()
+        self.scheduled_restart = (when, restart_id)
+        self._schedule(call_agent, delay)
+
+    def _call_restart_agent(self) -> None:
+        """"""
+        Callback which is called when restart time come.
+        Writes restart record to restart log and asks
+        node control service to perform restart
+
+        :param when: restart time
+        :param version: version to restart to
+        """"""
+
+        logger.info(""{}'s restart calling agent for restart"".format(self))
+        self._restart_start_callback()
+        self.scheduled_restart = None
+        asyncio.ensure_future(self._send_update_request())
+
+    async def _send_update_request(self):
+        retry_limit = self.retry_limit
+        while retry_limit:
+            try:
+                msg = RestartMessage(RESTART).toJson()
+                logger.info(""Sending message to control tool: {}"".format(msg))
+                await self._open_connection_and_send(msg)
+                break
+            except Exception as ex:
+                logger.warning(""Failed to communicate to control tool: {}""
+                               .format(ex))
+                asyncio.sleep(self.retry_timeout)
+                retry_limit -= 1
+        if not retry_limit:
+            raise Exception(""Failed to communicate to control tool"")
+
+    async def _open_connection_and_send(self, message: str):
+        control_service_host = self.config.controlServiceHost
+        control_service_port = self.config.controlServicePort
+        msg_bytes = bytes(message, ""utf-8"")
+        _, writer = await asyncio.open_connection(
+            host=control_service_host,
+            port=control_service_port
+        )
+        writer.write(msg_bytes)
+        writer.close()
+
+
+class RestartMessage:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176830654,https://github.com/hyperledger/indy-node/pull/624#discussion_r176830654,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Use the value of `msg_type` key to identify the message type. See the comment above for details.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 18:49:24,176833175,"@@ -236,13 +237,22 @@ def _upgrade(self, new_version, migrate=True, rollback=True):
             if rollback:
                 self._upgrade(current_version, rollback=False)
 
+    def _restart(self):
+        try:
+            self._call_restart_node_script()
+        except Exception as ex:
+            logger.error(""Restart fail: "" + ex.args[0])
+
     def _process_data(self, data):
         import json
         try:
             command = json.loads(data.decode(""utf-8""))
             logger.debug(""Decoded "", command)
-            new_version = command['version']
-            self._upgrade(new_version)
+            if command.get(""version"") is not None:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176833175,https://github.com/hyperledger/indy-node/pull/624#discussion_r176833175,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Please support both `START` and `CANCEL` actions.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-23 19:24:18,176841499,"@@ -0,0 +1,159 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_UPGRADE, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, NODE_UPGRADE, IN_PROGRESS, FORCE, \
+    POOL_RESTART, RESTART
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(HasActionQueue):
+
+    def __init__(self,
+                 nodeId,
+                 nodeName,
+                 dataDir,
+                 config,
+                 ledger,
+                 restart_failed_callback: Callable = None,
+                 restart_start_callback: Callable = None):
+
+        self.nodeId = nodeId
+        self.nodeName = nodeName
+        self.config = config
+        self.dataDir = dataDir
+        self.ledger = ledger
+        self.scheduled_restart = None  # type: Tuple[str, int, str]
+        self._notifier = notifier_plugin_manager.PluginManager()
+        self._restartFailedCallback = \
+            restart_failed_callback if restart_failed_callback else lambda: None
+        self._restart_start_callback = \
+            restart_start_callback if restart_start_callback else lambda: None
+
+        self.retry_timeout = 5
+        self.retry_limit = 3
+
+        HasActionQueue.__init__(self)
+
+    def __repr__(self):
+        # Since nodeid can be null till pool ledger has not caught up
+        return self.nodeId or ''
+
+    def service(self):
+        return self._serviceActions()
+
+    def handleRestartTxn(self, txn) -> None:
+        """"""
+        Handles transaction of type POOL_RESTART
+        Can schedule to restart node
+
+        :param txn:
+        """"""
+        logger.info(""Node '{}' handles restart txn {}"".format(
+            self.nodeName, txn))
+        action = txn[DATA][ACTION]
+        restart_id = None
+        if action == START:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176841499,https://github.com/hyperledger/indy-node/pull/624#discussion_r176841499,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,The filed `DATETIME` (to which `SCHEDULE` will be renamed) is optional. So it may be absent.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-24 12:21:09,176907800,"@@ -32,10 +34,17 @@ def doStaticValidation(self, request: Request):
             self._doStaticValidationPoolUpgrade(identifier, req_id, operation)
         elif operation[TXN_TYPE] == POOL_CONFIG:
             self._doStaticValidationPoolConfig(identifier, req_id, operation)
+        elif operation[TXN_TYPE] == POOL_RESTART:
+            self._doStaticValidationPoolRestart(identifier, req_id, operation)
 
     def _doStaticValidationPoolConfig(self, identifier, reqId, operation):
         pass
 
+    def _doStaticValidationPoolRestart(self, identifier, req_id, operation):
+        if not operation.get(DATA).get(SCHEDULE):
+            raise InvalidClientRequest(identifier, req_id,
+                                       ""time for restart can not be empty"")",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176907800,https://github.com/hyperledger/indy-node/pull/624#discussion_r176907800,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"Creating and sending a reply to the client must be performed after the restart is scheduled (for `action=start`) or cancelled (for `action=cancel`).

In case `action=start` the node need to have some short operability time before the restart in order to send the reply to the client. For this, check in the request validation that if `DATETIME` value is provided then it is greater than or equal to the current time + some time delta. Let's this time delta will be 5 seconds. If `DATETIME` value is not provided then schedule the restart to the current time + this time delta.",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-24 13:05:00,176908694,"@@ -296,22 +308,54 @@ def processRequest(self, request: Request, frm: str):
             self.process_query(request, frm)
             self.total_read_request_number += 1
         else:
+            if request.operation[TXN_TYPE] == POOL_RESTART:
+                reply = {}
+                try:
+                    self.configReqHandler.validate(request)
+                    reply = self.generate_action_result(request)
+                    if not self.isProcessingReq(*request.key):
+                        self.startedProcessingReq(*request.key, frm)
+                except Exception as ex:
+                    reply = self.generate_action_result(request,
+                                                        False,
+                                                        ex.args[0])
+                    logger.warning(""Restart is failed"")
+                finally:
+                    self.sendReplyToClient(reply,
+                                           (request.identifier, request.reqId))",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176908694,https://github.com/hyperledger/indy-node/pull/624#discussion_r176908694,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Should it be optional? And then what validation can we do?,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-26 07:00:53,176994625,"@@ -32,10 +34,17 @@ def doStaticValidation(self, request: Request):
             self._doStaticValidationPoolUpgrade(identifier, req_id, operation)
         elif operation[TXN_TYPE] == POOL_CONFIG:
             self._doStaticValidationPoolConfig(identifier, req_id, operation)
+        elif operation[TXN_TYPE] == POOL_RESTART:
+            self._doStaticValidationPoolRestart(identifier, req_id, operation)
 
     def _doStaticValidationPoolConfig(self, identifier, reqId, operation):
         pass
 
+    def _doStaticValidationPoolRestart(self, identifier, req_id, operation):
+        if not operation.get(DATA).get(SCHEDULE):
+            raise InvalidClientRequest(identifier, req_id,
+                                       ""time for restart can not be empty"")",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176994625,https://github.com/hyperledger/indy-node/pull/624#discussion_r176994625,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"Yes, `DATETIME` should be optional. If the request contains `DATETIME` field then its value must be validated.",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-26 09:00:27,177020849,"@@ -32,10 +34,17 @@ def doStaticValidation(self, request: Request):
             self._doStaticValidationPoolUpgrade(identifier, req_id, operation)
         elif operation[TXN_TYPE] == POOL_CONFIG:
             self._doStaticValidationPoolConfig(identifier, req_id, operation)
+        elif operation[TXN_TYPE] == POOL_RESTART:
+            self._doStaticValidationPoolRestart(identifier, req_id, operation)
 
     def _doStaticValidationPoolConfig(self, identifier, reqId, operation):
         pass
 
+    def _doStaticValidationPoolRestart(self, identifier, req_id, operation):
+        if not operation.get(DATA).get(SCHEDULE):
+            raise InvalidClientRequest(identifier, req_id,
+                                       ""time for restart can not be empty"")",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/177020849,https://github.com/hyperledger/indy-node/pull/624#discussion_r177020849,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Are we need RestartLog for this operations?,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-03-27 09:34:53,177363389,"@@ -0,0 +1,159 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_UPGRADE, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, NODE_UPGRADE, IN_PROGRESS, FORCE, \
+    POOL_RESTART, RESTART
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(HasActionQueue):
+
+    def __init__(self,
+                 nodeId,
+                 nodeName,
+                 dataDir,
+                 config,
+                 ledger,
+                 restart_failed_callback: Callable = None,
+                 restart_start_callback: Callable = None):
+
+        self.nodeId = nodeId
+        self.nodeName = nodeName
+        self.config = config
+        self.dataDir = dataDir
+        self.ledger = ledger
+        self.scheduled_restart = None  # type: Tuple[str, int, str]
+        self._notifier = notifier_plugin_manager.PluginManager()
+        self._restartFailedCallback = \
+            restart_failed_callback if restart_failed_callback else lambda: None
+        self._restart_start_callback = \
+            restart_start_callback if restart_start_callback else lambda: None
+
+        self.retry_timeout = 5
+        self.retry_limit = 3
+
+        HasActionQueue.__init__(self)
+
+    def __repr__(self):
+        # Since nodeid can be null till pool ledger has not caught up
+        return self.nodeId or ''
+
+    def service(self):
+        return self._serviceActions()
+
+    def handleRestartTxn(self, txn) -> None:
+        """"""
+        Handles transaction of type POOL_RESTART
+        Can schedule to restart node
+
+        :param txn:
+        """"""
+        logger.info(""Node '{}' handles restart txn {}"".format(
+            self.nodeName, txn))
+        action = txn[DATA][ACTION]
+        restart_id = None
+        if action == START:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/177363389,https://github.com/hyperledger/indy-node/pull/624#discussion_r177363389,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Where is this field assigned?,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 10:48:52,180711043,"@@ -0,0 +1,288 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from indy_node.server.node_maintainer import NodeMaintainer
+from indy_node.server.restart_log import RestartLog
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_RESTART, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, IN_PROGRESS, FORCE
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(NodeMaintainer):
+
+    def _defaultLog(self, dataDir, config):
+        log = os.path.join(dataDir, config.restartLogFile)
+        return RestartLog(filePath=log)
+
+    def _is_action_started(self):
+        if not self.lastActionEventInfo:
+            logger.debug('Node {} has no restart events'
+                         .format(self.nodeName))
+            return False
+
+        (event_type, when) = self.lastActionEventInfo
+
+        if event_type != RestartLog.STARTED:
+            logger.debug(
+                'Restart for node {} was not scheduled. Last event is {}:{}:{}'.format(
+                    self.nodeName, event_type, when))
+            return False
+
+        return True
+
+    def _update_action_log_for_started_action(self):
+        (event_type, when) = self.lastActionEventInfo
+
+        if not self.didLastExecutedRestartSucceeded:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180711043,https://github.com/hyperledger/indy-node/pull/624#discussion_r180711043,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Nowhere. Remove this condition or implementation the solution if the restart is unsuccessful?,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 11:00:04,180713868,"@@ -0,0 +1,288 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from indy_node.server.node_maintainer import NodeMaintainer
+from indy_node.server.restart_log import RestartLog
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_RESTART, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, IN_PROGRESS, FORCE
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(NodeMaintainer):
+
+    def _defaultLog(self, dataDir, config):
+        log = os.path.join(dataDir, config.restartLogFile)
+        return RestartLog(filePath=log)
+
+    def _is_action_started(self):
+        if not self.lastActionEventInfo:
+            logger.debug('Node {} has no restart events'
+                         .format(self.nodeName))
+            return False
+
+        (event_type, when) = self.lastActionEventInfo
+
+        if event_type != RestartLog.STARTED:
+            logger.debug(
+                'Restart for node {} was not scheduled. Last event is {}:{}:{}'.format(
+                    self.nodeName, event_type, when))
+            return False
+
+        return True
+
+    def _update_action_log_for_started_action(self):
+        (event_type, when) = self.lastActionEventInfo
+
+        if not self.didLastExecutedRestartSucceeded:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180713868,https://github.com/hyperledger/indy-node/pull/624#discussion_r180713868,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,This notification is made in `Upgrader` only. Thus `_action_started` is now reset to `False` in `Upgrader` class only. And this is wrong.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 11:36:58,180721825,"@@ -223,10 +240,10 @@ def acknowledge_upgrade(self):
 
         self.startedProcessingReq(*request.key, self.nodestack.name)
         self.send(request)
-        self.upgrader.notified_about_upgrade_result()
+        self.upgrader.notified_about_action_result()",85,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180721825,https://github.com/hyperledger/indy-node/pull/624#discussion_r180721825,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Why is this prefixed with `_`?,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 15:52:42,180806078,"@@ -37,8 +37,8 @@ def __init__(self, root_hash=None, value=None, seq_no=None, update_time=None, pr
 
 class DomainReqHandler(PHandler):
     write_types = {NYM, ATTRIB, SCHEMA, CLAIM_DEF, REVOC_REG_DEF, REVOC_REG_ENTRY}
-    query_types = {GET_NYM, GET_ATTR, GET_SCHEMA, GET_CLAIM_DEF,
-                   GET_REVOC_REG_DEF, GET_REVOC_REG, GET_REVOC_REG_DELTA}
+    _query_types = {GET_NYM, GET_ATTR, GET_SCHEMA, GET_CLAIM_DEF,",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180806078,https://github.com/hyperledger/indy-node/pull/624#discussion_r180806078,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Why do we use `SCHEDULE` here instead of `DATETIME`?,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 16:14:16,180813323,"@@ -0,0 +1,288 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from indy_node.server.node_maintainer import NodeMaintainer
+from indy_node.server.restart_log import RestartLog
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_RESTART, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, IN_PROGRESS, FORCE
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(NodeMaintainer):
+
+    def _defaultLog(self, dataDir, config):
+        log = os.path.join(dataDir, config.restartLogFile)
+        return RestartLog(filePath=log)
+
+    def _is_action_started(self):
+        if not self.lastActionEventInfo:
+            logger.debug('Node {} has no restart events'
+                         .format(self.nodeName))
+            return False
+
+        (event_type, when) = self.lastActionEventInfo
+
+        if event_type != RestartLog.STARTED:
+            logger.debug(
+                'Restart for node {} was not scheduled. Last event is {}:{}:{}'.format(
+                    self.nodeName, event_type, when))
+            return False
+
+        return True
+
+    def _update_action_log_for_started_action(self):
+        (event_type, when) = self.lastActionEventInfo
+
+        if not self.didLastExecutedRestartSucceeded:
+            self._actionLog.appendFailed(when)
+            self._action_failed(scheduled_on=when,
+                                external_reason=True)
+            return
+
+        self._actionLog.appendSucceeded(when)
+        logger.info(""Node '{}' successfully restarted""
+                    .format(self.nodeName))
+        self._notifier.sendMessageUponNodeRestartComplete(
+            ""Restart of node '{}' scheduled on {} ""
+            ""completed successfully""
+                .format(self.nodeName, when))
+
+    def handleActionTxn(self, txn) -> None:
+        """"""
+        Handles transaction of type POOL_RESTART
+        Can schedule or cancel restart to a newer
+        version at specified time
+
+        :param txn:
+        """"""
+        FINALIZING_EVENT_TYPES = [
+            RestartLog.SUCCEEDED, RestartLog.FAILED]
+
+        if txn[TXN_TYPE] != POOL_RESTART:
+            return
+
+        when = txn[SCHEDULE] if SCHEDULE in txn.keys() else None",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180813323,https://github.com/hyperledger/indy-node/pull/624#discussion_r180813323,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,`POOL_RESTART` command does not have a schedule with time for every node.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 16:15:55,180813922,"@@ -0,0 +1,288 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from indy_node.server.node_maintainer import NodeMaintainer
+from indy_node.server.restart_log import RestartLog
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_RESTART, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, IN_PROGRESS, FORCE
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(NodeMaintainer):
+
+    def _defaultLog(self, dataDir, config):
+        log = os.path.join(dataDir, config.restartLogFile)
+        return RestartLog(filePath=log)
+
+    def _is_action_started(self):
+        if not self.lastActionEventInfo:
+            logger.debug('Node {} has no restart events'
+                         .format(self.nodeName))
+            return False
+
+        (event_type, when) = self.lastActionEventInfo
+
+        if event_type != RestartLog.STARTED:
+            logger.debug(
+                'Restart for node {} was not scheduled. Last event is {}:{}:{}'.format(
+                    self.nodeName, event_type, when))
+            return False
+
+        return True
+
+    def _update_action_log_for_started_action(self):
+        (event_type, when) = self.lastActionEventInfo
+
+        if not self.didLastExecutedRestartSucceeded:
+            self._actionLog.appendFailed(when)
+            self._action_failed(scheduled_on=when,
+                                external_reason=True)
+            return
+
+        self._actionLog.appendSucceeded(when)
+        logger.info(""Node '{}' successfully restarted""
+                    .format(self.nodeName))
+        self._notifier.sendMessageUponNodeRestartComplete(
+            ""Restart of node '{}' scheduled on {} ""
+            ""completed successfully""
+                .format(self.nodeName, when))
+
+    def handleActionTxn(self, txn) -> None:
+        """"""
+        Handles transaction of type POOL_RESTART
+        Can schedule or cancel restart to a newer
+        version at specified time
+
+        :param txn:
+        """"""
+        FINALIZING_EVENT_TYPES = [
+            RestartLog.SUCCEEDED, RestartLog.FAILED]
+
+        if txn[TXN_TYPE] != POOL_RESTART:
+            return
+
+        when = txn[SCHEDULE] if SCHEDULE in txn.keys() else None
+        if isinstance(when, str) and when != ""0"":
+            when = dateutil.parser.parse(when)
+        now = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
+        if when is None or when == ""0"" or now >= when:
+            msg = RestartMessage(action=POOL_RESTART).toJson()
+            try:
+                asyncio.ensure_future(self._open_connection_and_send(msg))
+            except Exception as ex:
+                logger.warning(ex.args[0])
+            return
+
+        action = txn[ACTION]
+        if action == START:
+            # forced txn could have partial schedule list
+            if self.nodeId not in txn[SCHEDULE]:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180813922,https://github.com/hyperledger/indy-node/pull/624#discussion_r180813922,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Please see my previous unprocessed note on this class.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 16:43:15,180822173,"@@ -0,0 +1,288 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from indy_node.server.node_maintainer import NodeMaintainer
+from indy_node.server.restart_log import RestartLog
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_RESTART, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, IN_PROGRESS, FORCE
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(NodeMaintainer):
+
+    def _defaultLog(self, dataDir, config):
+        log = os.path.join(dataDir, config.restartLogFile)
+        return RestartLog(filePath=log)
+
+    def _is_action_started(self):
+        if not self.lastActionEventInfo:
+            logger.debug('Node {} has no restart events'
+                         .format(self.nodeName))
+            return False
+
+        (event_type, when) = self.lastActionEventInfo
+
+        if event_type != RestartLog.STARTED:
+            logger.debug(
+                'Restart for node {} was not scheduled. Last event is {}:{}:{}'.format(
+                    self.nodeName, event_type, when))
+            return False
+
+        return True
+
+    def _update_action_log_for_started_action(self):
+        (event_type, when) = self.lastActionEventInfo
+
+        if not self.didLastExecutedRestartSucceeded:
+            self._actionLog.appendFailed(when)
+            self._action_failed(scheduled_on=when,
+                                external_reason=True)
+            return
+
+        self._actionLog.appendSucceeded(when)
+        logger.info(""Node '{}' successfully restarted""
+                    .format(self.nodeName))
+        self._notifier.sendMessageUponNodeRestartComplete(
+            ""Restart of node '{}' scheduled on {} ""
+            ""completed successfully""
+                .format(self.nodeName, when))
+
+    def handleActionTxn(self, txn) -> None:
+        """"""
+        Handles transaction of type POOL_RESTART
+        Can schedule or cancel restart to a newer
+        version at specified time
+
+        :param txn:
+        """"""
+        FINALIZING_EVENT_TYPES = [
+            RestartLog.SUCCEEDED, RestartLog.FAILED]
+
+        if txn[TXN_TYPE] != POOL_RESTART:
+            return
+
+        when = txn[SCHEDULE] if SCHEDULE in txn.keys() else None
+        if isinstance(when, str) and when != ""0"":
+            when = dateutil.parser.parse(when)
+        now = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
+        if when is None or when == ""0"" or now >= when:
+            msg = RestartMessage(action=POOL_RESTART).toJson()
+            try:
+                asyncio.ensure_future(self._open_connection_and_send(msg))
+            except Exception as ex:
+                logger.warning(ex.args[0])
+            return
+
+        action = txn[ACTION]
+        if action == START:
+            # forced txn could have partial schedule list
+            if self.nodeId not in txn[SCHEDULE]:
+                logger.info(""Node '{}' disregards restart txn {}"".format(
+                    self.nodeName, txn))
+                return
+
+            last_event = self.lastActionEventInfo
+            if last_event and last_event[
+                0] in FINALIZING_EVENT_TYPES:
+                logger.info(
+                    ""Node '{}' has already performed an restart. ""
+                    ""Last recorded event is {}"".format(
+                        self.nodeName, last_event))
+                return
+
+            failTimeout = txn.get(TIMEOUT, self.defaultActionTimeout)
+
+            if self.scheduledAction:
+                if isinstance(when, str):
+                    when = dateutil.parser.parse(when)
+                if self.scheduledAction == when:
+                    logger.debug(
+                        ""Node {} already scheduled restart"".format(
+                            self.nodeName))
+                    return
+                else:
+                    logger.info(
+                        ""Node '{}' cancels previous restart and schedules a new one"".format(
+                            self.nodeName))
+                    self._cancelScheduledRestart()
+
+            logger.info(""Node '{}' schedules restart"".format(
+                self.nodeName))
+
+            self._scheduleRestart(when, failTimeout)
+            return
+
+        if action == CANCEL:
+            if self.scheduledAction:
+                self._cancelScheduledRestart()
+                logger.info(""Node '{}' cancels restart"".format(
+                    self.nodeName))
+            return
+
+        logger.error(
+            ""Got {} transaction with unsupported action {}"".format(
+                POOL_RESTART, action))
+
+    def _scheduleRestart(self,
+                         when: Union[datetime, str],
+                         failTimeout) -> None:
+        """"""
+        Schedules node restart to a newer version
+
+        :param version: version to restart to
+        :param when: restart time
+        """"""
+        assert isinstance(when, (str, datetime))
+        logger.info(""{}'s restartr processing restart""
+                    .format(self))
+        if isinstance(when, str):
+            when = dateutil.parser.parse(when)
+        now = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
+
+        self._notifier.sendMessageUponNodeRestartScheduled(
+            ""Restart of node '{}' has been scheduled on {}"".format(
+                self.nodeName, when))
+        self._actionLog.appendScheduled(when)
+
+        callAgent = partial(self._callRestartAgent, when,
+                            failTimeout)
+        delay = 0
+        if now < when:
+            delay = (when - now).total_seconds()
+        self.scheduledAction = (when)
+        self._schedule(callAgent, delay)
+
+    def _cancelScheduledRestart(self, justification=None) -> None:
+        """"""
+        Cancels scheduled restart
+
+        :param when: time restart was scheduled to
+        :param version: version restart scheduled for
+        """"""
+
+        if self.scheduledAction:
+            why_prefix = "": ""
+            why = justification
+            if justification is None:
+                why_prefix = "", ""
+                why = ""cancellation reason not specified""
+
+            when = self.scheduledAction
+            logger.info(""Cancelling restart""
+                        "" of node {node}""
+                        "" scheduled on {when}""
+                        ""{why_prefix}{why}""
+                        .format(node=self.nodeName,
+                                when=when,
+                                why_prefix=why_prefix,
+                                why=why))
+
+            self._unscheduleAction()
+            self._actionLog.appendCancelled(when)
+            self._notifier.sendMessageUponPoolRestartCancel(
+                ""Restart of node '{}'""
+                ""has been cancelled due to {}"".format(
+                    self.nodeName, why))
+
+    def _callRestartAgent(self, when, failTimeout) -> None:
+        """"""
+        Callback which is called when restart time come.
+        Writes restart record to restart log and asks
+        node control service to perform restart
+
+        :param when: restart time
+        :param version: version to restart to
+        """"""
+
+        logger.info(""{}'s restartr calling agent for restart"".format(self))
+        self._actionLog.appendStarted(when)
+        self._action_start_callback()
+        self.scheduledAction = None
+        asyncio.ensure_future(
+            self._sendUpdateRequest(when, failTimeout))
+
+    async def _sendUpdateRequest(self, when, failTimeout):
+        retryLimit = self.retry_limit
+        while retryLimit:
+            try:
+                msg = RestartMessage(action=POOL_RESTART).toJson()
+                logger.info(""Sending message to control tool: {}"".format(msg))
+                await self._open_connection_and_send(msg)
+                break
+            except Exception as ex:
+                logger.warning(""Failed to communicate to control tool: {}""
+                               .format(ex))
+                asyncio.sleep(self.retry_timeout)
+                retryLimit -= 1
+        if not retryLimit:
+            self._action_failed(scheduled_on=when,
+                                reason=""problems in communication with ""
+                                       ""node control service"")
+            self._unscheduleAction()
+            self._actionFailedCallback()
+        else:
+            logger.info(""Waiting {} minutes for restart to be performed""
+                        .format(failTimeout))
+            timesUp = partial(self._declareTimeoutExceeded, when)
+            self._schedule(timesUp, self.get_timeout(failTimeout))
+
+    def _declareTimeoutExceeded(self, when):
+        """"""
+        This function is called when time for restart is up
+        """"""
+
+        logger.info(""Timeout exceeded for {}"".format(when))
+        last = self._actionLog.lastEvent
+        if last and last[1:-1] == (RestartLog.FAILED, when):
+            return None
+
+        self._action_failed(scheduled_on=when,
+                            reason=""exceeded restart timeout"")
+
+        self._unscheduleAction()
+        self._actionFailedCallback()
+
+    def _action_failed(self, *,
+                       scheduled_on,
+                       reason=None,
+                       external_reason=False):
+        if reason is None:
+            reason = ""unknown reason""
+        error_message = ""Node {node} failed restart"" \
+                        ""scheduled on {scheduled_on} "" \
+                        ""because of {reason}"" \
+            .format(node=self.nodeName,
+                    scheduled_on=scheduled_on,
+                    reason=reason)
+        logger.error(error_message)
+        if external_reason:
+            logger.error(""This problem may have external reasons, ""
+                         ""check syslog for more information"")
+        self._notifier.sendMessageUponNodeRestartFail(error_message)
+
+
+class RestartMessage:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180822173,https://github.com/hyperledger/indy-node/pull/624#discussion_r180822173,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"At first, determine the type of action.",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 16:46:35,180823222,"@@ -0,0 +1,94 @@
+import dateutil.parser
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest
+from plenum.common.messages.node_messages import Reply
+from plenum.common.txn_util import reqToTxn
+from plenum.common.types import f
+from plenum.server.req_handler import RequestHandler
+from plenum.common.constants import TXN_TYPE
+from indy_common.auth import Authoriser
+from indy_common.constants import SCHEDULE, ACTION, POOL_RESTART
+from indy_common.roles import Roles
+from indy_common.types import Request
+from indy_node.persistence.idr_cache import IdrCache
+from indy_node.server.restarter import Restarter
+from indy_node.server.pool_config import PoolConfig
+from stp_core.common.log import getlogger
+
+
+logger = getlogger()
+
+
+class ActionReqHandler(RequestHandler):
+    operation_types = {POOL_RESTART}
+
+    def __init__(self, idrCache: IdrCache,
+                 restarter: Restarter, poolManager, poolCfg: PoolConfig):
+        self.idrCache = idrCache
+        self.restarter = restarter
+        self.poolManager = poolManager
+        self.poolCfg = poolCfg
+
+    def doStaticValidation(self, request: Request):
+        identifier, req_id, operation = request.identifier, request.reqId, request.operation
+        if operation[TXN_TYPE] == POOL_RESTART:
+            self._doStaticValidationPoolRestart(identifier, req_id, operation)
+
+    def _doStaticValidationPoolRestart(self, identifier, req_id, operation):
+        if SCHEDULE in operation.keys() is None and operation[SCHEDULE] != ""0"":
+            try:
+                dateutil.parser.parse(operation[SCHEDULE])
+            except Exception:
+                raise InvalidClientRequest(identifier, req_id,
+                                           ""time is not valid"")
+
+    def validate(self, req: Request):
+        status = None
+        operation = req.operation
+        typ = operation.get(TXN_TYPE)
+        if typ not in [POOL_RESTART]:
+            return
+        origin = req.identifier
+        try:
+            origin_role = self.idrCache.getRole(origin, isCommitted=False)
+        except BaseException:
+            raise UnauthorizedClientRequest(
+                req.identifier,
+                req.reqId,
+                ""Nym {} not added to the ledger yet"".format(origin))
+        action = """"
+        if typ == POOL_RESTART:
+            action = operation.get(ACTION)
+        r, msg = Authoriser.authorised(
+            typ, origin_role, field=ACTION, oldVal=status, newVal=action)
+        if not r:
+            raise UnauthorizedClientRequest(
+                req.identifier, req.reqId, ""{} cannot do restart"".format(
+                    Roles.nameFromValue(origin_role)))
+
+    def apply(self, req: Request, cons_time: int = None):
+        if req.txn_type != POOL_RESTART:
+            raise InvalidClientRequest(""{} is not type of action transaction""
+                                       .format(req.txn_type))
+        result = {}
+        try:
+            txn = reqToTxn(req)
+            self.restarter.handleActionTxn(txn)",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180823222,https://github.com/hyperledger/indy-node/pull/624#discussion_r180823222,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,We must not transform an action request to a transaction because we will not write it to ledger.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 16:51:27,180824810,"@@ -0,0 +1,94 @@
+import dateutil.parser
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest
+from plenum.common.messages.node_messages import Reply
+from plenum.common.txn_util import reqToTxn
+from plenum.common.types import f
+from plenum.server.req_handler import RequestHandler
+from plenum.common.constants import TXN_TYPE
+from indy_common.auth import Authoriser
+from indy_common.constants import SCHEDULE, ACTION, POOL_RESTART
+from indy_common.roles import Roles
+from indy_common.types import Request
+from indy_node.persistence.idr_cache import IdrCache
+from indy_node.server.restarter import Restarter
+from indy_node.server.pool_config import PoolConfig
+from stp_core.common.log import getlogger
+
+
+logger = getlogger()
+
+
+class ActionReqHandler(RequestHandler):
+    operation_types = {POOL_RESTART}
+
+    def __init__(self, idrCache: IdrCache,
+                 restarter: Restarter, poolManager, poolCfg: PoolConfig):
+        self.idrCache = idrCache
+        self.restarter = restarter
+        self.poolManager = poolManager
+        self.poolCfg = poolCfg
+
+    def doStaticValidation(self, request: Request):
+        identifier, req_id, operation = request.identifier, request.reqId, request.operation
+        if operation[TXN_TYPE] == POOL_RESTART:
+            self._doStaticValidationPoolRestart(identifier, req_id, operation)
+
+    def _doStaticValidationPoolRestart(self, identifier, req_id, operation):
+        if SCHEDULE in operation.keys() is None and operation[SCHEDULE] != ""0"":
+            try:
+                dateutil.parser.parse(operation[SCHEDULE])
+            except Exception:
+                raise InvalidClientRequest(identifier, req_id,
+                                           ""time is not valid"")
+
+    def validate(self, req: Request):
+        status = None
+        operation = req.operation
+        typ = operation.get(TXN_TYPE)
+        if typ not in [POOL_RESTART]:
+            return
+        origin = req.identifier
+        try:
+            origin_role = self.idrCache.getRole(origin, isCommitted=False)
+        except BaseException:
+            raise UnauthorizedClientRequest(
+                req.identifier,
+                req.reqId,
+                ""Nym {} not added to the ledger yet"".format(origin))
+        action = """"
+        if typ == POOL_RESTART:
+            action = operation.get(ACTION)
+        r, msg = Authoriser.authorised(
+            typ, origin_role, field=ACTION, oldVal=status, newVal=action)
+        if not r:
+            raise UnauthorizedClientRequest(
+                req.identifier, req.reqId, ""{} cannot do restart"".format(
+                    Roles.nameFromValue(origin_role)))
+
+    def apply(self, req: Request, cons_time: int = None):
+        if req.txn_type != POOL_RESTART:
+            raise InvalidClientRequest(""{} is not type of action transaction""
+                                       .format(req.txn_type))
+        result = {}
+        try:
+            txn = reqToTxn(req)",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180824810,https://github.com/hyperledger/indy-node/pull/624#discussion_r180824810,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"Action result must also contain the request-specific fields. So return the merged dictionary:

        return {**request.operation, **{
            f.IDENTIFIER.nm: request.identifier,
            f.REQ_ID.nm: request.reqId,
            f.IS_SUCCESS.nm: is_success,
            f.MSG.nm: msg}
        }}

So `type` and request-specific fields will be taken from `request.operation`.",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 17:13:54,180831269,"@@ -0,0 +1,94 @@
+import dateutil.parser
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest
+from plenum.common.messages.node_messages import Reply
+from plenum.common.txn_util import reqToTxn
+from plenum.common.types import f
+from plenum.server.req_handler import RequestHandler
+from plenum.common.constants import TXN_TYPE
+from indy_common.auth import Authoriser
+from indy_common.constants import SCHEDULE, ACTION, POOL_RESTART
+from indy_common.roles import Roles
+from indy_common.types import Request
+from indy_node.persistence.idr_cache import IdrCache
+from indy_node.server.restarter import Restarter
+from indy_node.server.pool_config import PoolConfig
+from stp_core.common.log import getlogger
+
+
+logger = getlogger()
+
+
+class ActionReqHandler(RequestHandler):
+    operation_types = {POOL_RESTART}
+
+    def __init__(self, idrCache: IdrCache,
+                 restarter: Restarter, poolManager, poolCfg: PoolConfig):
+        self.idrCache = idrCache
+        self.restarter = restarter
+        self.poolManager = poolManager
+        self.poolCfg = poolCfg
+
+    def doStaticValidation(self, request: Request):
+        identifier, req_id, operation = request.identifier, request.reqId, request.operation
+        if operation[TXN_TYPE] == POOL_RESTART:
+            self._doStaticValidationPoolRestart(identifier, req_id, operation)
+
+    def _doStaticValidationPoolRestart(self, identifier, req_id, operation):
+        if SCHEDULE in operation.keys() is None and operation[SCHEDULE] != ""0"":
+            try:
+                dateutil.parser.parse(operation[SCHEDULE])
+            except Exception:
+                raise InvalidClientRequest(identifier, req_id,
+                                           ""time is not valid"")
+
+    def validate(self, req: Request):
+        status = None
+        operation = req.operation
+        typ = operation.get(TXN_TYPE)
+        if typ not in [POOL_RESTART]:
+            return
+        origin = req.identifier
+        try:
+            origin_role = self.idrCache.getRole(origin, isCommitted=False)
+        except BaseException:
+            raise UnauthorizedClientRequest(
+                req.identifier,
+                req.reqId,
+                ""Nym {} not added to the ledger yet"".format(origin))
+        action = """"
+        if typ == POOL_RESTART:
+            action = operation.get(ACTION)
+        r, msg = Authoriser.authorised(
+            typ, origin_role, field=ACTION, oldVal=status, newVal=action)
+        if not r:
+            raise UnauthorizedClientRequest(
+                req.identifier, req.reqId, ""{} cannot do restart"".format(
+                    Roles.nameFromValue(origin_role)))
+
+    def apply(self, req: Request, cons_time: int = None):
+        if req.txn_type != POOL_RESTART:
+            raise InvalidClientRequest(""{} is not type of action transaction""
+                                       .format(req.txn_type))
+        result = {}
+        try:
+            txn = reqToTxn(req)
+            self.restarter.handleActionTxn(txn)
+            result = self._generate_action_result(req)
+        except Exception as ex:
+            result = self._generate_action_result(req,
+                                                 False,
+                                                 ex.args[0])
+            logger.warning(""Restart is failed"")
+        finally:
+            return result
+
+    def _generate_action_result(self, request: Request, is_success=True,
+                                msg=None):
+        return {TXN_TYPE: request.operation.get(TXN_TYPE),
+                      f.IDENTIFIER.nm: request.identifier,
+                      f.REQ_ID.nm: request.reqId,
+                      f.IS_SUCCESS.nm: is_success,
+                      f.MSG.nm: msg}",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180831269,https://github.com/hyperledger/indy-node/pull/624#discussion_r180831269,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,This check is redundant. We will never come here if the request is action.,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-11 17:30:53,180836448,"@@ -295,18 +312,22 @@ def processRequest(self, request: Request, frm: str):
         if self.is_query(request.operation[TXN_TYPE]):
             self.process_query(request, frm)
             self.total_read_request_number += 1
+        elif self.is_action(request.operation[TXN_TYPE]):
+            self.process_action(request, frm)
         else:
             # forced request should be processed before consensus
             if (request.operation[TXN_TYPE] in [
                     POOL_UPGRADE, POOL_CONFIG]) and request.isForced():
                 self.configReqHandler.validate(request)
                 self.configReqHandler.applyForced(request)
             # here we should have write transactions that should be processed
+            # pool_restart should not be written to ledger
             # only on writable pool
             if self.poolCfg.isWritable() or (request.operation[TXN_TYPE] in [
                     POOL_UPGRADE, POOL_CONFIG]):
                 super().processRequest(request, frm)
-            else:
+
+            elif request.operation[TXN_TYPE] != POOL_RESTART:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/180836448,https://github.com/hyperledger/indy-node/pull/624#discussion_r180836448,spivachuk
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"I can found only NODE, NYM, GET_TXN in this place. All operations for this txn contains its own validate, but POOL_RESTART, POOL_UPGRADE and all other haven't this function. I don't understand logic of adding POOL_RESTART in indy_common.types.ClientOperationField.",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:36:34,181021399,"@@ -273,6 +273,14 @@ class ClientPoolUpgradeOperation(MessageValidator):
     )
 
 
+class ClientPoolRestartOperation(MessageValidator):",23,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181021399,https://github.com/hyperledger/indy-node/pull/624#discussion_r181021399,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"get_query_response() doesn't work such as get_query_response. We can add get_query_response() in the actionHandler, but current logic is based on Upgrade force idea. Is it a good to lead action logic to other writeble txns?",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:44:40,181023719,"@@ -296,22 +308,54 @@ def processRequest(self, request: Request, frm: str):
             self.process_query(request, frm)
             self.total_read_request_number += 1
         else:
+            if request.operation[TXN_TYPE] == POOL_RESTART:
+                reply = {}
+                try:
+                    self.configReqHandler.validate(request)
+                    reply = self.generate_action_result(request)
+                    if not self.isProcessingReq(*request.key):
+                        self.startedProcessingReq(*request.key, frm)
+                except Exception as ex:
+                    reply = self.generate_action_result(request,
+                                                        False,
+                                                        ex.args[0])
+                    logger.warning(""Restart is failed"")
+                finally:
+                    self.sendReplyToClient(reply,
+                                           (request.identifier, request.reqId))
+                    self.configReqHandler.applyRestart(request)
             # forced request should be processed before consensus
             if (request.operation[TXN_TYPE] in [
                     POOL_UPGRADE, POOL_CONFIG]) and request.isForced():
                 self.configReqHandler.validate(request)
                 self.configReqHandler.applyForced(request)
             # here we should have write transactions that should be processed
+            # pool_restart should not be written to ledger
             # only on writable pool
-            if self.poolCfg.isWritable() or (request.operation[TXN_TYPE] in [
-                    POOL_UPGRADE, POOL_CONFIG]):
+            if request.operation[TXN_TYPE] != POOL_RESTART and (
+                self.poolCfg.isWritable() or (request.operation[TXN_TYPE] in [
+                    POOL_UPGRADE, POOL_CONFIG])):
                 super().processRequest(request, frm)
-            else:
+
+            elif request.operation[TXN_TYPE] != POOL_RESTART:
                 raise InvalidClientRequest(
                     request.identifier,
                     request.reqId,
                     'Pool is in readonly mode, try again in 60 seconds')
 
+    def generate_action_result(self, request: Request, is_success=True,",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181023719,https://github.com/hyperledger/indy-node/pull/624#discussion_r181023719,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,done,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:45:00,181023793,"@@ -17,9 +18,11 @@ class LedgerBasedAuthNr(CoreAuthMixin, NaclAuthNr):
     """"""
 
     write_types = CoreAuthMixin.write_types.union({ATTRIB, SCHEMA, CLAIM_DEF,
-                                                   POOL_CONFIG, POOL_UPGRADE, REVOC_REG_DEF, REVOC_REG_ENTRY})
+                                                   POOL_CONFIG, POOL_UPGRADE, POOL_RESTART,",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181023793,https://github.com/hyperledger/indy-node/pull/624#discussion_r181023793,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,done,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:45:14,181023855,"@@ -296,22 +308,54 @@ def processRequest(self, request: Request, frm: str):
             self.process_query(request, frm)
             self.total_read_request_number += 1
         else:
+            if request.operation[TXN_TYPE] == POOL_RESTART:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181023855,https://github.com/hyperledger/indy-node/pull/624#discussion_r181023855,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"done
",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:45:38,181023970,"@@ -0,0 +1,159 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_UPGRADE, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, NODE_UPGRADE, IN_PROGRESS, FORCE, \
+    POOL_RESTART, RESTART
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(HasActionQueue):",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181023970,https://github.com/hyperledger/indy-node/pull/624#discussion_r181023970,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,What is the reason for this abstraction? We will not use it in NodeMaintainer(NodeControlMessage),cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:48:17,181024732,"@@ -0,0 +1,159 @@
+import os
+from collections import deque
+from datetime import datetime, timedelta
+from functools import partial
+from typing import Tuple, Union, Optional, Callable, Dict
+
+import dateutil.parser
+import dateutil.tz
+
+from stp_core.common.log import getlogger
+from plenum.common.constants import TXN_TYPE, VERSION, DATA, IDENTIFIER
+from plenum.common.types import f
+from plenum.server.has_action_queue import HasActionQueue
+from indy_common.constants import ACTION, POOL_UPGRADE, START, SCHEDULE, \
+    CANCEL, JUSTIFICATION, TIMEOUT, REINSTALL, NODE_UPGRADE, IN_PROGRESS, FORCE, \
+    POOL_RESTART, RESTART
+from plenum.server import notifier_plugin_manager
+from ledger.util import F
+import asyncio
+
+logger = getlogger()
+
+
+class Restarter(HasActionQueue):
+
+    def __init__(self,
+                 nodeId,
+                 nodeName,
+                 dataDir,
+                 config,
+                 ledger,
+                 restart_failed_callback: Callable = None,
+                 restart_start_callback: Callable = None):
+
+        self.nodeId = nodeId
+        self.nodeName = nodeName
+        self.config = config
+        self.dataDir = dataDir
+        self.ledger = ledger
+        self.scheduled_restart = None  # type: Tuple[str, int, str]
+        self._notifier = notifier_plugin_manager.PluginManager()
+        self._restartFailedCallback = \
+            restart_failed_callback if restart_failed_callback else lambda: None
+        self._restart_start_callback = \
+            restart_start_callback if restart_start_callback else lambda: None
+
+        self.retry_timeout = 5
+        self.retry_limit = 3
+
+        HasActionQueue.__init__(self)
+
+    def __repr__(self):
+        # Since nodeid can be null till pool ledger has not caught up
+        return self.nodeId or ''
+
+    def service(self):
+        return self._serviceActions()
+
+    def handleRestartTxn(self, txn) -> None:
+        """"""
+        Handles transaction of type POOL_RESTART
+        Can schedule to restart node
+
+        :param txn:
+        """"""
+        logger.info(""Node '{}' handles restart txn {}"".format(
+            self.nodeName, txn))
+        action = txn[DATA][ACTION]
+        restart_id = None
+        if action == START:
+            when = txn[DATA][SCHEDULE]
+            if isinstance(when, str):
+                when = dateutil.parser.parse(when)
+            if self.scheduled_restart:
+                self._schedule_restart(when, restart_id)
+            self._call_restart_agent()
+
+    def _schedule_restart(self,
+                          when: Union[datetime, str],
+                          restart_id) -> None:
+        """"""
+        Schedules node restart to a newer version
+
+        :param when: restart time
+        :param restart_id: restart identifier (req_id+seq_no) of a txn that started the restart
+        """"""
+        assert isinstance(when, (str, datetime))
+        logger.info(""{}'s restarter processing restart""
+                    .format(self))
+        if isinstance(when, str):
+            when = dateutil.parser.parse(when)
+        now = datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc())
+
+        # self._notifier.sendMessageUponNodeRestarteScheduled(
+        #     ""Restart of node has been scheduled on {}"".format(
+        #         self.nodeName, when))
+        # self._restartLog.appendScheduled(when, restart_id)
+
+        call_agent = partial(self._call_restart_agent)
+        delay = 0
+        if now < when:
+            delay = (when - now).total_seconds()
+        self.scheduled_restart = (when, restart_id)
+        self._schedule(call_agent, delay)
+
+    def _call_restart_agent(self) -> None:
+        """"""
+        Callback which is called when restart time come.
+        Writes restart record to restart log and asks
+        node control service to perform restart
+
+        :param when: restart time
+        :param version: version to restart to
+        """"""
+
+        logger.info(""{}'s restart calling agent for restart"".format(self))
+        self._restart_start_callback()
+        self.scheduled_restart = None
+        asyncio.ensure_future(self._send_update_request())
+
+    async def _send_update_request(self):
+        retry_limit = self.retry_limit
+        while retry_limit:
+            try:
+                msg = RestartMessage(RESTART).toJson()
+                logger.info(""Sending message to control tool: {}"".format(msg))
+                await self._open_connection_and_send(msg)
+                break
+            except Exception as ex:
+                logger.warning(""Failed to communicate to control tool: {}""
+                               .format(ex))
+                asyncio.sleep(self.retry_timeout)
+                retry_limit -= 1
+        if not retry_limit:
+            raise Exception(""Failed to communicate to control tool"")
+
+    async def _open_connection_and_send(self, message: str):
+        control_service_host = self.config.controlServiceHost
+        control_service_port = self.config.controlServicePort
+        msg_bytes = bytes(message, ""utf-8"")
+        _, writer = await asyncio.open_connection(
+            host=control_service_host,
+            port=control_service_port
+        )
+        writer.write(msg_bytes)
+        writer.close()
+
+
+class RestartMessage:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181024732,https://github.com/hyperledger/indy-node/pull/624#discussion_r181024732,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,"If we haven't abstraction of message in NodeMaintainer and other developer will send incorrect msg_type, he cant work with node_control_tool.py. I think, if some developer will add s new type, node_control_tool.py will be needed in changes too.",cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:55:06,181026670,"@@ -236,13 +237,22 @@ def _upgrade(self, new_version, migrate=True, rollback=True):
             if rollback:
                 self._upgrade(current_version, rollback=False)
 
+    def _restart(self):
+        try:
+            self._call_restart_node_script()
+        except Exception as ex:
+            logger.error(""Restart fail: "" + ex.args[0])
+
     def _process_data(self, data):
         import json
         try:
             command = json.loads(data.decode(""utf-8""))
             logger.debug(""Decoded "", command)
-            new_version = command['version']
-            self._upgrade(new_version)
+            if command.get(""version"") is not None:",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181026670,https://github.com/hyperledger/indy-node/pull/624#discussion_r181026670,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,done,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:55:25,181026749,"@@ -32,10 +34,17 @@ def doStaticValidation(self, request: Request):
             self._doStaticValidationPoolUpgrade(identifier, req_id, operation)
         elif operation[TXN_TYPE] == POOL_CONFIG:
             self._doStaticValidationPoolConfig(identifier, req_id, operation)
+        elif operation[TXN_TYPE] == POOL_RESTART:
+            self._doStaticValidationPoolRestart(identifier, req_id, operation)
 
     def _doStaticValidationPoolConfig(self, identifier, reqId, operation):
         pass
 
+    def _doStaticValidationPoolRestart(self, identifier, req_id, operation):
+        if not operation.get(DATA).get(SCHEDULE):
+            raise InvalidClientRequest(identifier, req_id,
+                                       ""time for restart can not be empty"")",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181026749,https://github.com/hyperledger/indy-node/pull/624#discussion_r181026749,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,done,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:56:32,181027048,"@@ -296,22 +308,54 @@ def processRequest(self, request: Request, frm: str):
             self.process_query(request, frm)
             self.total_read_request_number += 1
         else:
+            if request.operation[TXN_TYPE] == POOL_RESTART:
+                reply = {}
+                try:
+                    self.configReqHandler.validate(request)
+                    reply = self.generate_action_result(request)
+                    if not self.isProcessingReq(*request.key):
+                        self.startedProcessingReq(*request.key, frm)
+                except Exception as ex:
+                    reply = self.generate_action_result(request,
+                                                        False,
+                                                        ex.args[0])
+                    logger.warning(""Restart is failed"")
+                finally:
+                    self.sendReplyToClient(reply,
+                                           (request.identifier, request.reqId))",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181027048,https://github.com/hyperledger/indy-node/pull/624#discussion_r181027048,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,done,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 09:57:01,181027170,"@@ -223,10 +240,10 @@ def acknowledge_upgrade(self):
 
         self.startedProcessingReq(*request.key, self.nodestack.name)
         self.send(request)
-        self.upgrader.notified_about_upgrade_result()
+        self.upgrader.notified_about_action_result()",85,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181027170,https://github.com/hyperledger/indy-node/pull/624#discussion_r181027170,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,Has already been done in this commit - https://github.com/Toktar/indy-node/commit/f398ca6e2fc7be680c0a82c30b2193af0adb4ee1,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 10:42:02,181037846,"@@ -0,0 +1,94 @@
+import dateutil.parser
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest
+from plenum.common.messages.node_messages import Reply
+from plenum.common.txn_util import reqToTxn
+from plenum.common.types import f
+from plenum.server.req_handler import RequestHandler
+from plenum.common.constants import TXN_TYPE
+from indy_common.auth import Authoriser
+from indy_common.constants import SCHEDULE, ACTION, POOL_RESTART
+from indy_common.roles import Roles
+from indy_common.types import Request
+from indy_node.persistence.idr_cache import IdrCache
+from indy_node.server.restarter import Restarter
+from indy_node.server.pool_config import PoolConfig
+from stp_core.common.log import getlogger
+
+
+logger = getlogger()
+
+
+class ActionReqHandler(RequestHandler):
+    operation_types = {POOL_RESTART}
+
+    def __init__(self, idrCache: IdrCache,
+                 restarter: Restarter, poolManager, poolCfg: PoolConfig):
+        self.idrCache = idrCache
+        self.restarter = restarter
+        self.poolManager = poolManager
+        self.poolCfg = poolCfg
+
+    def doStaticValidation(self, request: Request):
+        identifier, req_id, operation = request.identifier, request.reqId, request.operation
+        if operation[TXN_TYPE] == POOL_RESTART:
+            self._doStaticValidationPoolRestart(identifier, req_id, operation)
+
+    def _doStaticValidationPoolRestart(self, identifier, req_id, operation):
+        if SCHEDULE in operation.keys() is None and operation[SCHEDULE] != ""0"":
+            try:
+                dateutil.parser.parse(operation[SCHEDULE])
+            except Exception:
+                raise InvalidClientRequest(identifier, req_id,
+                                           ""time is not valid"")
+
+    def validate(self, req: Request):
+        status = None
+        operation = req.operation
+        typ = operation.get(TXN_TYPE)
+        if typ not in [POOL_RESTART]:
+            return
+        origin = req.identifier
+        try:
+            origin_role = self.idrCache.getRole(origin, isCommitted=False)
+        except BaseException:
+            raise UnauthorizedClientRequest(
+                req.identifier,
+                req.reqId,
+                ""Nym {} not added to the ledger yet"".format(origin))
+        action = """"
+        if typ == POOL_RESTART:
+            action = operation.get(ACTION)
+        r, msg = Authoriser.authorised(
+            typ, origin_role, field=ACTION, oldVal=status, newVal=action)
+        if not r:
+            raise UnauthorizedClientRequest(
+                req.identifier, req.reqId, ""{} cannot do restart"".format(
+                    Roles.nameFromValue(origin_role)))
+
+    def apply(self, req: Request, cons_time: int = None):
+        if req.txn_type != POOL_RESTART:
+            raise InvalidClientRequest(""{} is not type of action transaction""
+                                       .format(req.txn_type))
+        result = {}
+        try:
+            txn = reqToTxn(req)
+            self.restarter.handleActionTxn(txn)",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181037846,https://github.com/hyperledger/indy-node/pull/624#discussion_r181037846,Toktar
https://github.com/hyperledger/indy-node/pull/624,https://github.com/hyperledger/indy-node/pull/624,reqToTxn() transforms request to transactions. We have needed it for saving the logic of all handlers work,cc2eec9dd85ac25cbdc9dd7d65fee8a045438664,2018-04-12 10:46:32,181038986,"@@ -0,0 +1,94 @@
+import dateutil.parser
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest
+from plenum.common.messages.node_messages import Reply
+from plenum.common.txn_util import reqToTxn
+from plenum.common.types import f
+from plenum.server.req_handler import RequestHandler
+from plenum.common.constants import TXN_TYPE
+from indy_common.auth import Authoriser
+from indy_common.constants import SCHEDULE, ACTION, POOL_RESTART
+from indy_common.roles import Roles
+from indy_common.types import Request
+from indy_node.persistence.idr_cache import IdrCache
+from indy_node.server.restarter import Restarter
+from indy_node.server.pool_config import PoolConfig
+from stp_core.common.log import getlogger
+
+
+logger = getlogger()
+
+
+class ActionReqHandler(RequestHandler):
+    operation_types = {POOL_RESTART}
+
+    def __init__(self, idrCache: IdrCache,
+                 restarter: Restarter, poolManager, poolCfg: PoolConfig):
+        self.idrCache = idrCache
+        self.restarter = restarter
+        self.poolManager = poolManager
+        self.poolCfg = poolCfg
+
+    def doStaticValidation(self, request: Request):
+        identifier, req_id, operation = request.identifier, request.reqId, request.operation
+        if operation[TXN_TYPE] == POOL_RESTART:
+            self._doStaticValidationPoolRestart(identifier, req_id, operation)
+
+    def _doStaticValidationPoolRestart(self, identifier, req_id, operation):
+        if SCHEDULE in operation.keys() is None and operation[SCHEDULE] != ""0"":
+            try:
+                dateutil.parser.parse(operation[SCHEDULE])
+            except Exception:
+                raise InvalidClientRequest(identifier, req_id,
+                                           ""time is not valid"")
+
+    def validate(self, req: Request):
+        status = None
+        operation = req.operation
+        typ = operation.get(TXN_TYPE)
+        if typ not in [POOL_RESTART]:
+            return
+        origin = req.identifier
+        try:
+            origin_role = self.idrCache.getRole(origin, isCommitted=False)
+        except BaseException:
+            raise UnauthorizedClientRequest(
+                req.identifier,
+                req.reqId,
+                ""Nym {} not added to the ledger yet"".format(origin))
+        action = """"
+        if typ == POOL_RESTART:
+            action = operation.get(ACTION)
+        r, msg = Authoriser.authorised(
+            typ, origin_role, field=ACTION, oldVal=status, newVal=action)
+        if not r:
+            raise UnauthorizedClientRequest(
+                req.identifier, req.reqId, ""{} cannot do restart"".format(
+                    Roles.nameFromValue(origin_role)))
+
+    def apply(self, req: Request, cons_time: int = None):
+        if req.txn_type != POOL_RESTART:
+            raise InvalidClientRequest(""{} is not type of action transaction""
+                                       .format(req.txn_type))
+        result = {}
+        try:
+            txn = reqToTxn(req)",,2018-04-19 12:38:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181038986,https://github.com/hyperledger/indy-node/pull/624#discussion_r181038986,Toktar
https://github.com/hyperledger/indy-node/pull/623,https://github.com/hyperledger/indy-node/pull/623,"Read ledger for rocksdb should look differently.
It should not create a tmp copy, and should open the db in read-only mode.",e34591b5473a92c117917b276691b69ea96426e9,2018-03-21 13:59:58,176090262,"@@ -92,7 +92,7 @@ def get_ledger(type_, ledger_data_dir):
         print(""Unknown ledger type: {}"".format(type_))
         exit()
 
-    hash_store = LevelDbHashStore(dataDir=ledger_data_dir, fileNamePrefix=type_)
+    hash_store = initHashStore(ledger_data_dir, type_, config)
     return Ledger(CompactMerkleTree(hashStore=hash_store), dataDir=ledger_data_dir, fileName=ledger_name)",15,2018-03-21 15:01:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176090262,https://github.com/hyperledger/indy-node/pull/623#discussion_r176090262,ashcherbakov
https://github.com/hyperledger/indy-node/pull/623,https://github.com/hyperledger/indy-node/pull/623,"Yes, I know. But I planned to make it in a separate PR as it requires changes (traversing of read_only flag through init helpers) and testing.",e34591b5473a92c117917b276691b69ea96426e9,2018-03-21 14:36:13,176104355,"@@ -92,7 +92,7 @@ def get_ledger(type_, ledger_data_dir):
         print(""Unknown ledger type: {}"".format(type_))
         exit()
 
-    hash_store = LevelDbHashStore(dataDir=ledger_data_dir, fileNamePrefix=type_)
+    hash_store = initHashStore(ledger_data_dir, type_, config)
     return Ledger(CompactMerkleTree(hashStore=hash_store), dataDir=ledger_data_dir, fileName=ledger_name)",15,2018-03-21 15:01:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176104355,https://github.com/hyperledger/indy-node/pull/623#discussion_r176104355,sergey-shilov
https://github.com/hyperledger/indy-node/pull/623,https://github.com/hyperledger/indy-node/pull/623,ok,e34591b5473a92c117917b276691b69ea96426e9,2018-03-21 14:50:40,176110163,"@@ -92,7 +92,7 @@ def get_ledger(type_, ledger_data_dir):
         print(""Unknown ledger type: {}"".format(type_))
         exit()
 
-    hash_store = LevelDbHashStore(dataDir=ledger_data_dir, fileNamePrefix=type_)
+    hash_store = initHashStore(ledger_data_dir, type_, config)
     return Ledger(CompactMerkleTree(hashStore=hash_store), dataDir=ledger_data_dir, fileName=ledger_name)",15,2018-03-21 15:01:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/176110163,https://github.com/hyperledger/indy-node/pull/623#discussion_r176110163,ashcherbakov
https://github.com/hyperledger/indy-node/pull/616,https://github.com/hyperledger/indy-node/pull/616,"Please update GET_REVOC_REG_DELTA reply (with accumFrom, accumTo, etc.)",823219877d5fb33cb9121ed1bd151c30b9373825,2018-03-21 07:07:17,175995710,"@@ -364,7 +364,29 @@ This is needed to avoid dirty writes and updates of accumulator.
 contains aggregated accum_value, issued and revoked arrays.
 
 <b>Hint</b>: We should consider using BitMask to store the current aggregated state of issued and revoked arrays",,2018-03-21 08:23:14,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175995710,https://github.com/hyperledger/indy-node/pull/616#discussion_r175995710,ashcherbakov
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,"A separate path and entry needs to be used for GET_REVOC_REG in the state trie, otherwise the state proof can not be verified. The VALUE must be the same as the one stored in the state trie (here we store ACCUM+ISSUED/REVOKED, while return ACCUM only).
Also please add tests that state proofs in replies to GET_REVOC_REG and GET_REVOC_REG_DELTA can be verified.",abbb562fed569b75cb936145538e05b9682f44b2,2018-03-19 12:57:31,175424305,"@@ -422,6 +426,122 @@ def handleGetRevocRegDefReq(self, request: Request):
                                   proof=proof)
         return result
 
+    def handleGetRevocRegReq(self, request: Request):
+        req_ts = request.operation.get(TIMESTAMP)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        # Get root hash corresponding with givtimestamp
+        past_root = self.tsRevoc_store.get_equal_or_prev(req_ts)
+        # Path to corresponding REVOC_REG_ENTRY
+        path = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                          revoc_reg_def_id=revoc_reg_def_id)
+        if past_root is None:
+            reply_data = None
+            seq_no = None
+            last_update_time = None
+            proof = None
+        else:
+            encoded_entry = self.state.get_for_root_hash(past_root, path)
+            revoc_reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+
+            reply_data = None if revoc_reg_entry is None else \
+                {
+                    REVOC_REG_DEF_ID: revoc_reg_def_id,
+                    REVOC_TYPE: revoc_reg_entry.get(REVOC_TYPE),
+                    VALUE: {
+                        ACCUM: revoc_reg_entry[VALUE].get(ACCUM)
+                    }
+                }
+            proof = self.make_proof(path, head_hash=past_root)",,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175424305,https://github.com/hyperledger/indy-node/pull/610#discussion_r175424305,ashcherbakov
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,"This is `encoded_revoc_reg_def`, isn't it?",abbb562fed569b75cb936145538e05b9682f44b2,2018-03-19 13:21:00,175430400,"@@ -422,6 +426,122 @@ def handleGetRevocRegDefReq(self, request: Request):
                                   proof=proof)
         return result
 
+    def handleGetRevocRegReq(self, request: Request):
+        req_ts = request.operation.get(TIMESTAMP)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        # Get root hash corresponding with givtimestamp
+        past_root = self.tsRevoc_store.get_equal_or_prev(req_ts)
+        # Path to corresponding REVOC_REG_ENTRY
+        path = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                          revoc_reg_def_id=revoc_reg_def_id)
+        if past_root is None:
+            reply_data = None
+            seq_no = None
+            last_update_time = None
+            proof = None
+        else:
+            encoded_entry = self.state.get_for_root_hash(past_root, path)
+            revoc_reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+
+            reply_data = None if revoc_reg_entry is None else \
+                {
+                    REVOC_REG_DEF_ID: revoc_reg_def_id,
+                    REVOC_TYPE: revoc_reg_entry.get(REVOC_TYPE),
+                    VALUE: {
+                        ACCUM: revoc_reg_entry[VALUE].get(ACCUM)
+                    }
+                }
+            proof = self.make_proof(path, head_hash=past_root)
+        return self.make_result(request=request,
+                                data=reply_data,
+                                last_seq_no=seq_no,
+                                update_time=last_update_time,
+                                proof=proof)
+
+    def _get_reg_entry_by_timestamp(self, timestamp, path_to_reg_entry):
+        reg_entry = None
+        seq_no = None
+        last_update_time = None
+        reg_entry_proof = None
+        past_root = self.tsRevoc_store.get_equal_or_prev(timestamp)
+        if past_root:
+            encoded_entry = self.state.get_for_root_hash(past_root, path_to_reg_entry)
+            reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+            reg_entry_proof = self.make_proof(path_to_reg_entry, head_hash=past_root)
+        return past_root, reg_entry, seq_no, last_update_time, reg_entry_proof
+
+    def handleGetRevocRegDelta(self, request: Request):
+        """"""
+        For getting reply we need:
+        1. Get REVOC_REG_ENTRY by ""TO"" timestamp from state
+        2. If FROM is given in request, then Get REVOC_REG_ENTRY by ""FROM"" timestamp from state
+        3. Get ISSUANCE_TYPE for REVOC_REG_DEF (revoked/issued strategy)
+        4. Compute issued and revoked indices by corresponding strategy
+        5. Make result
+           5.1 Now, if ""FROM"" is presented in request, then STATE_PROOF_FROM and ACCUM (revocation entry for ""FROM"" timestamp)
+               will added into data section
+           5.2 If not, then only STATE_PROOF for ""TO"" revocation entry will added
+        :param request:
+        :return: Reply
+        """"""
+
+        req_ts_from = request.operation.get(FROM, None)
+        req_ts_to = request.operation.get(TO)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        reply = None
+        # Get root hash for ""to"" timestamp
+        # Get REVOC_REG_ENTRY for timestamp ""to""
+        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                                       revoc_reg_def_id=revoc_reg_def_id)
+        past_root_to, \
+            reg_entry_to, \
+            seq_no_to, \
+            last_update_time_to, \
+            reg_entry_proof_to = self._get_reg_entry_by_timestamp(req_ts_to, path_to_reg_entry)
+        if past_root_to:
+            # Get issuance type from REVOC_REG_DEF
+            encoded_revoc_reg = self.state.get_for_root_hash(past_root_to, revoc_reg_def_id)",,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175430400,https://github.com/hyperledger/indy-node/pull/610#discussion_r175430400,ashcherbakov
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,"This is `revoc_reg_def`, isn't it?",abbb562fed569b75cb936145538e05b9682f44b2,2018-03-19 13:21:15,175430473,"@@ -422,6 +426,122 @@ def handleGetRevocRegDefReq(self, request: Request):
                                   proof=proof)
         return result
 
+    def handleGetRevocRegReq(self, request: Request):
+        req_ts = request.operation.get(TIMESTAMP)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        # Get root hash corresponding with givtimestamp
+        past_root = self.tsRevoc_store.get_equal_or_prev(req_ts)
+        # Path to corresponding REVOC_REG_ENTRY
+        path = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                          revoc_reg_def_id=revoc_reg_def_id)
+        if past_root is None:
+            reply_data = None
+            seq_no = None
+            last_update_time = None
+            proof = None
+        else:
+            encoded_entry = self.state.get_for_root_hash(past_root, path)
+            revoc_reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+
+            reply_data = None if revoc_reg_entry is None else \
+                {
+                    REVOC_REG_DEF_ID: revoc_reg_def_id,
+                    REVOC_TYPE: revoc_reg_entry.get(REVOC_TYPE),
+                    VALUE: {
+                        ACCUM: revoc_reg_entry[VALUE].get(ACCUM)
+                    }
+                }
+            proof = self.make_proof(path, head_hash=past_root)
+        return self.make_result(request=request,
+                                data=reply_data,
+                                last_seq_no=seq_no,
+                                update_time=last_update_time,
+                                proof=proof)
+
+    def _get_reg_entry_by_timestamp(self, timestamp, path_to_reg_entry):
+        reg_entry = None
+        seq_no = None
+        last_update_time = None
+        reg_entry_proof = None
+        past_root = self.tsRevoc_store.get_equal_or_prev(timestamp)
+        if past_root:
+            encoded_entry = self.state.get_for_root_hash(past_root, path_to_reg_entry)
+            reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+            reg_entry_proof = self.make_proof(path_to_reg_entry, head_hash=past_root)
+        return past_root, reg_entry, seq_no, last_update_time, reg_entry_proof
+
+    def handleGetRevocRegDelta(self, request: Request):
+        """"""
+        For getting reply we need:
+        1. Get REVOC_REG_ENTRY by ""TO"" timestamp from state
+        2. If FROM is given in request, then Get REVOC_REG_ENTRY by ""FROM"" timestamp from state
+        3. Get ISSUANCE_TYPE for REVOC_REG_DEF (revoked/issued strategy)
+        4. Compute issued and revoked indices by corresponding strategy
+        5. Make result
+           5.1 Now, if ""FROM"" is presented in request, then STATE_PROOF_FROM and ACCUM (revocation entry for ""FROM"" timestamp)
+               will added into data section
+           5.2 If not, then only STATE_PROOF for ""TO"" revocation entry will added
+        :param request:
+        :return: Reply
+        """"""
+
+        req_ts_from = request.operation.get(FROM, None)
+        req_ts_to = request.operation.get(TO)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        reply = None
+        # Get root hash for ""to"" timestamp
+        # Get REVOC_REG_ENTRY for timestamp ""to""
+        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                                       revoc_reg_def_id=revoc_reg_def_id)
+        past_root_to, \
+            reg_entry_to, \
+            seq_no_to, \
+            last_update_time_to, \
+            reg_entry_proof_to = self._get_reg_entry_by_timestamp(req_ts_to, path_to_reg_entry)
+        if past_root_to:
+            # Get issuance type from REVOC_REG_DEF
+            encoded_revoc_reg = self.state.get_for_root_hash(past_root_to, revoc_reg_def_id)
+            assert encoded_revoc_reg
+            revoc_reg, _, _ = domain.decode_state_value(encoded_revoc_reg)",,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175430473,https://github.com/hyperledger/indy-node/pull/610#discussion_r175430473,ashcherbakov
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,This must be part of VALUE. It should contain two ACCUMs: `accumFrom` and `accumTo`. Please fix in design as well.,abbb562fed569b75cb936145538e05b9682f44b2,2018-03-19 13:26:20,175431942,"@@ -422,6 +426,122 @@ def handleGetRevocRegDefReq(self, request: Request):
                                   proof=proof)
         return result
 
+    def handleGetRevocRegReq(self, request: Request):
+        req_ts = request.operation.get(TIMESTAMP)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        # Get root hash corresponding with givtimestamp
+        past_root = self.tsRevoc_store.get_equal_or_prev(req_ts)
+        # Path to corresponding REVOC_REG_ENTRY
+        path = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                          revoc_reg_def_id=revoc_reg_def_id)
+        if past_root is None:
+            reply_data = None
+            seq_no = None
+            last_update_time = None
+            proof = None
+        else:
+            encoded_entry = self.state.get_for_root_hash(past_root, path)
+            revoc_reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+
+            reply_data = None if revoc_reg_entry is None else \
+                {
+                    REVOC_REG_DEF_ID: revoc_reg_def_id,
+                    REVOC_TYPE: revoc_reg_entry.get(REVOC_TYPE),
+                    VALUE: {
+                        ACCUM: revoc_reg_entry[VALUE].get(ACCUM)
+                    }
+                }
+            proof = self.make_proof(path, head_hash=past_root)
+        return self.make_result(request=request,
+                                data=reply_data,
+                                last_seq_no=seq_no,
+                                update_time=last_update_time,
+                                proof=proof)
+
+    def _get_reg_entry_by_timestamp(self, timestamp, path_to_reg_entry):
+        reg_entry = None
+        seq_no = None
+        last_update_time = None
+        reg_entry_proof = None
+        past_root = self.tsRevoc_store.get_equal_or_prev(timestamp)
+        if past_root:
+            encoded_entry = self.state.get_for_root_hash(past_root, path_to_reg_entry)
+            reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+            reg_entry_proof = self.make_proof(path_to_reg_entry, head_hash=past_root)
+        return past_root, reg_entry, seq_no, last_update_time, reg_entry_proof
+
+    def handleGetRevocRegDelta(self, request: Request):
+        """"""
+        For getting reply we need:
+        1. Get REVOC_REG_ENTRY by ""TO"" timestamp from state
+        2. If FROM is given in request, then Get REVOC_REG_ENTRY by ""FROM"" timestamp from state
+        3. Get ISSUANCE_TYPE for REVOC_REG_DEF (revoked/issued strategy)
+        4. Compute issued and revoked indices by corresponding strategy
+        5. Make result
+           5.1 Now, if ""FROM"" is presented in request, then STATE_PROOF_FROM and ACCUM (revocation entry for ""FROM"" timestamp)
+               will added into data section
+           5.2 If not, then only STATE_PROOF for ""TO"" revocation entry will added
+        :param request:
+        :return: Reply
+        """"""
+
+        req_ts_from = request.operation.get(FROM, None)
+        req_ts_to = request.operation.get(TO)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        reply = None
+        # Get root hash for ""to"" timestamp
+        # Get REVOC_REG_ENTRY for timestamp ""to""
+        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                                       revoc_reg_def_id=revoc_reg_def_id)
+        past_root_to, \
+            reg_entry_to, \
+            seq_no_to, \
+            last_update_time_to, \
+            reg_entry_proof_to = self._get_reg_entry_by_timestamp(req_ts_to, path_to_reg_entry)
+        if past_root_to:
+            # Get issuance type from REVOC_REG_DEF
+            encoded_revoc_reg = self.state.get_for_root_hash(past_root_to, revoc_reg_def_id)
+            assert encoded_revoc_reg
+            revoc_reg, _, _ = domain.decode_state_value(encoded_revoc_reg)
+            strategy_cls = self.get_revocation_strategy(revoc_reg[VALUE][ISSUANCE_TYPE])
+
+            if req_ts_from:
+                past_root_from, \
+                    reg_entry_from, \
+                    seq_no_from, \
+                    last_update_time_from, \
+                    reg_entry_proof_from = self._get_reg_entry_by_timestamp(req_ts_from, path_to_reg_entry)
+                # Compute issued/revoked lists corresponding with ISSUANCE_TYPE strategy
+                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE][ISSUED],
+                                                                        REVOKED: reg_entry_to[VALUE][REVOKED]},
+                                                                       {ISSUED: reg_entry_from[VALUE][ISSUED],
+                                                                        REVOKED: reg_entry_from[VALUE][REVOKED]})
+            else:
+                result_issued, result_revoked = strategy_cls.get_delta({ISSUED: reg_entry_to[VALUE][ISSUED],
+                                                                        REVOKED: reg_entry_to[VALUE][REVOKED]},
+                                                                       None)
+            reply = {
+                REVOC_REG_ID: str(path_to_reg_entry),
+                REVOC_TYPE: revoc_reg.get(REVOC_TYPE),
+                VALUE: {
+                    ACCUM: reg_entry_to[VALUE].get(ACCUM),
+                    ISSUED: result_issued,
+                    REVOKED: result_revoked
+                }
+            }
+            # If we got ""from"" timestamp, then add state proof into ""data"" section of reply
+            if req_ts_from:
+                reply[STATE_PROOF_FROM] = reg_entry_proof_from
+                reply[ACCUM] = reg_entry_from[VALUE][ACCUM]",,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175431942,https://github.com/hyperledger/indy-node/pull/610#discussion_r175431942,ashcherbakov
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,Do we have tests when the value is not found (proof of non-existence)?,abbb562fed569b75cb936145538e05b9682f44b2,2018-03-19 13:29:42,175432950,"@@ -422,6 +426,122 @@ def handleGetRevocRegDefReq(self, request: Request):
                                   proof=proof)
         return result
 
+    def handleGetRevocRegReq(self, request: Request):
+        req_ts = request.operation.get(TIMESTAMP)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        # Get root hash corresponding with givtimestamp
+        past_root = self.tsRevoc_store.get_equal_or_prev(req_ts)
+        # Path to corresponding REVOC_REG_ENTRY
+        path = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                          revoc_reg_def_id=revoc_reg_def_id)
+        if past_root is None:
+            reply_data = None
+            seq_no = None
+            last_update_time = None
+            proof = None
+        else:
+            encoded_entry = self.state.get_for_root_hash(past_root, path)
+            revoc_reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+
+            reply_data = None if revoc_reg_entry is None else \
+                {
+                    REVOC_REG_DEF_ID: revoc_reg_def_id,
+                    REVOC_TYPE: revoc_reg_entry.get(REVOC_TYPE),
+                    VALUE: {
+                        ACCUM: revoc_reg_entry[VALUE].get(ACCUM)
+                    }
+                }
+            proof = self.make_proof(path, head_hash=past_root)
+        return self.make_result(request=request,
+                                data=reply_data,
+                                last_seq_no=seq_no,
+                                update_time=last_update_time,
+                                proof=proof)
+
+    def _get_reg_entry_by_timestamp(self, timestamp, path_to_reg_entry):
+        reg_entry = None
+        seq_no = None
+        last_update_time = None
+        reg_entry_proof = None
+        past_root = self.tsRevoc_store.get_equal_or_prev(timestamp)
+        if past_root:
+            encoded_entry = self.state.get_for_root_hash(past_root, path_to_reg_entry)
+            reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+            reg_entry_proof = self.make_proof(path_to_reg_entry, head_hash=past_root)
+        return past_root, reg_entry, seq_no, last_update_time, reg_entry_proof
+
+    def handleGetRevocRegDelta(self, request: Request):
+        """"""
+        For getting reply we need:
+        1. Get REVOC_REG_ENTRY by ""TO"" timestamp from state
+        2. If FROM is given in request, then Get REVOC_REG_ENTRY by ""FROM"" timestamp from state
+        3. Get ISSUANCE_TYPE for REVOC_REG_DEF (revoked/issued strategy)
+        4. Compute issued and revoked indices by corresponding strategy
+        5. Make result
+           5.1 Now, if ""FROM"" is presented in request, then STATE_PROOF_FROM and ACCUM (revocation entry for ""FROM"" timestamp)
+               will added into data section
+           5.2 If not, then only STATE_PROOF for ""TO"" revocation entry will added
+        :param request:
+        :return: Reply
+        """"""
+
+        req_ts_from = request.operation.get(FROM, None)
+        req_ts_to = request.operation.get(TO)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        reply = None
+        # Get root hash for ""to"" timestamp
+        # Get REVOC_REG_ENTRY for timestamp ""to""
+        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                                       revoc_reg_def_id=revoc_reg_def_id)
+        past_root_to, \
+            reg_entry_to, \
+            seq_no_to, \
+            last_update_time_to, \
+            reg_entry_proof_to = self._get_reg_entry_by_timestamp(req_ts_to, path_to_reg_entry)
+        if past_root_to:",,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175432950,https://github.com/hyperledger/indy-node/pull/610#discussion_r175432950,ashcherbakov
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,Do we have tests with from/to times not equal to the state update times?,abbb562fed569b75cb936145538e05b9682f44b2,2018-03-19 14:12:11,175447805,"@@ -0,0 +1,90 @@
+import json
+import copy
+from plenum.common.util import get_utc_epoch
+from plenum.test.helper import sdk_send_and_check, sdk_sign_request_from_dict
+from indy_common.constants import REVOC_REG_DEF_ID, VALUE, FROM, TO, ISSUED, \
+    REVOKED, PREV_ACCUM, ACCUM, STATE_PROOF_FROM
+from plenum.common.constants import TXN_TIME, DATA
+from plenum.common.types import f
+from plenum.common.util import randomString
+
+
+def test_send_with_only_to_by_default(looper,
+                            txnPoolNodeSet,
+                            sdk_pool_handle,
+                            send_revoc_reg_entry_by_default,
+                            build_get_revoc_reg_delta):
+    rev_entry_req, reg_reply = send_revoc_reg_entry_by_default
+    get_revoc_reg_delta = copy.deepcopy(build_get_revoc_reg_delta)
+    del get_revoc_reg_delta['operation'][FROM]
+    get_revoc_reg_delta['operation'][REVOC_REG_DEF_ID] = rev_entry_req['operation'][REVOC_REG_DEF_ID]
+    get_revoc_reg_delta['operation'][TO] = get_utc_epoch() + 1000
+    sdk_reply = sdk_send_and_check([json.dumps(get_revoc_reg_delta)], looper, txnPoolNodeSet, sdk_pool_handle)
+    reply = sdk_reply[0][1]
+    assert rev_entry_req['operation'][REVOC_REG_DEF_ID] == reply['result'][REVOC_REG_DEF_ID]
+    assert rev_entry_req['operation'][VALUE][ACCUM] == reply['result'][DATA][VALUE][ACCUM]
+    assert rev_entry_req['operation'][VALUE][REVOKED] == reply['result'][DATA][VALUE][REVOKED]
+
+
+def test_send_earlier_then_first_entry_by_default(
+        looper,
+        txnPoolNodeSet,
+        sdk_pool_handle,
+        send_revoc_reg_entry_by_default,
+        build_get_revoc_reg_delta):
+    rev_entry_req, reg_reply = send_revoc_reg_entry_by_default
+    get_revoc_reg_delta = copy.deepcopy(build_get_revoc_reg_delta)
+    del get_revoc_reg_delta['operation'][FROM]
+    get_revoc_reg_delta['operation'][REVOC_REG_DEF_ID] = rev_entry_req['operation'][REVOC_REG_DEF_ID]
+    get_revoc_reg_delta['operation'][TO] = get_utc_epoch() - 1000
+    sdk_reply = sdk_send_and_check([json.dumps(get_revoc_reg_delta)], looper, txnPoolNodeSet, sdk_pool_handle)
+    reply = sdk_reply[0][1]
+    assert reply['result'][DATA] is None
+    assert reply['result'][f.SEQ_NO.nm] is None
+    assert reply['result'][TXN_TIME] is None
+
+
+def test_send_with_from_by_default(looper,
+        txnPoolNodeSet,
+        sdk_pool_handle,
+        sdk_wallet_steward,
+        send_revoc_reg_entry_by_default,
+        build_get_revoc_reg_delta):
+    # We save timestamp of state changes.
+    # looper and txnPoolNodeSet has ""module"", therefore,
+    # when we send request with FROM section, it's not a clean situation
+    looper.runFor(3)
+    # Assume, that send_revoc_reg_entry_by_default will add into revoked [1,2,3,4,5]
+    rev_reg_req1, rev_reg_reply1 = send_revoc_reg_entry_by_default
+    rev_reg_req1['operation'][VALUE][REVOKED] = []
+    # Issue [1,2,3], Revoked now must be [4,5]
+    rev_reg_req1['operation'][VALUE][ISSUED] = [1, 2, 3]
+    rev_reg_req1['operation'][VALUE][PREV_ACCUM] = rev_reg_req1['operation'][VALUE][ACCUM]
+    rev_reg_req1['operation'][VALUE][ACCUM] = randomString(10)
+    rev_reg_req2, rev_reg_reply2 = sdk_send_and_check(
+        [json.dumps(sdk_sign_request_from_dict(
+            looper, sdk_wallet_steward, rev_reg_req1['operation']))],
+        looper,
+        txnPoolNodeSet,
+        sdk_pool_handle)[0]
+    # Revoke [10, 11]
+    rev_reg_req2['operation'][VALUE][REVOKED] = [10, 11]
+    rev_reg_req2['operation'][VALUE][ISSUED] = []
+    rev_reg_req2['operation'][VALUE][PREV_ACCUM] = rev_reg_req2['operation'][VALUE][ACCUM]
+    rev_reg_req2['operation'][VALUE][ACCUM] = randomString(10)
+    rev_reg_req3, rev_reg_reply3 = sdk_send_and_check(
+        [json.dumps(sdk_sign_request_from_dict(
+            looper, sdk_wallet_steward, rev_reg_req2['operation']))],
+        looper,
+        txnPoolNodeSet,
+        sdk_pool_handle)[0]
+    reg_delta_req = copy.deepcopy(build_get_revoc_reg_delta)
+    reg_delta_req['operation'][REVOC_REG_DEF_ID] = rev_reg_req1['operation'][REVOC_REG_DEF_ID]
+    reg_delta_req['operation'][FROM] = rev_reg_reply1['result'][TXN_TIME]",83,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175447805,https://github.com/hyperledger/indy-node/pull/610#discussion_r175447805,ashcherbakov
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,Where is it used?,abbb562fed569b75cb936145538e05b9682f44b2,2018-03-19 14:13:10,175448138,"@@ -238,6 +239,37 @@ class ClientGetRevocRegDefField(MessageValidator):
     )
 
 
+class ClientGetRevocRegField(MessageValidator):
+    schema = (
+        (REVOC_REG_DEF_ID, NonEmptyStringField()),
+        (TIMESTAMP, IntegerField()),
+        (TXN_TYPE, ConstantField(GET_REVOC_REG)),
+    )
+
+
+class ClientGetRevocRegDeltaField(MessageValidator):
+    schema = (
+        (TXN_TYPE, ConstantField(GET_REVOC_REG_DELTA)),
+        (REVOC_REG_DEF_ID, NonEmptyStringField()),
+        (FROM, IntegerField(optional=True)),
+        (TO, IntegerField()),
+    )
+
+
+class ReplyRevocRegEntryValueField(MessageValidator):
+    schema = (
+        (ACCUM, NonEmptyStringField())
+    )
+
+
+class ReplyRevocRegEntryField(MessageValidator):",,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175448138,https://github.com/hyperledger/indy-node/pull/610#discussion_r175448138,ashcherbakov
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,"Tests for this:
 test_send_earlier_then_first_entry_by_default
test_send_earlier_then_first_entry_by_demand",abbb562fed569b75cb936145538e05b9682f44b2,2018-03-19 14:19:05,175450305,"@@ -422,6 +426,122 @@ def handleGetRevocRegDefReq(self, request: Request):
                                   proof=proof)
         return result
 
+    def handleGetRevocRegReq(self, request: Request):
+        req_ts = request.operation.get(TIMESTAMP)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        # Get root hash corresponding with givtimestamp
+        past_root = self.tsRevoc_store.get_equal_or_prev(req_ts)
+        # Path to corresponding REVOC_REG_ENTRY
+        path = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                          revoc_reg_def_id=revoc_reg_def_id)
+        if past_root is None:
+            reply_data = None
+            seq_no = None
+            last_update_time = None
+            proof = None
+        else:
+            encoded_entry = self.state.get_for_root_hash(past_root, path)
+            revoc_reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+
+            reply_data = None if revoc_reg_entry is None else \
+                {
+                    REVOC_REG_DEF_ID: revoc_reg_def_id,
+                    REVOC_TYPE: revoc_reg_entry.get(REVOC_TYPE),
+                    VALUE: {
+                        ACCUM: revoc_reg_entry[VALUE].get(ACCUM)
+                    }
+                }
+            proof = self.make_proof(path, head_hash=past_root)
+        return self.make_result(request=request,
+                                data=reply_data,
+                                last_seq_no=seq_no,
+                                update_time=last_update_time,
+                                proof=proof)
+
+    def _get_reg_entry_by_timestamp(self, timestamp, path_to_reg_entry):
+        reg_entry = None
+        seq_no = None
+        last_update_time = None
+        reg_entry_proof = None
+        past_root = self.tsRevoc_store.get_equal_or_prev(timestamp)
+        if past_root:
+            encoded_entry = self.state.get_for_root_hash(past_root, path_to_reg_entry)
+            reg_entry, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+            reg_entry_proof = self.make_proof(path_to_reg_entry, head_hash=past_root)
+        return past_root, reg_entry, seq_no, last_update_time, reg_entry_proof
+
+    def handleGetRevocRegDelta(self, request: Request):
+        """"""
+        For getting reply we need:
+        1. Get REVOC_REG_ENTRY by ""TO"" timestamp from state
+        2. If FROM is given in request, then Get REVOC_REG_ENTRY by ""FROM"" timestamp from state
+        3. Get ISSUANCE_TYPE for REVOC_REG_DEF (revoked/issued strategy)
+        4. Compute issued and revoked indices by corresponding strategy
+        5. Make result
+           5.1 Now, if ""FROM"" is presented in request, then STATE_PROOF_FROM and ACCUM (revocation entry for ""FROM"" timestamp)
+               will added into data section
+           5.2 If not, then only STATE_PROOF for ""TO"" revocation entry will added
+        :param request:
+        :return: Reply
+        """"""
+
+        req_ts_from = request.operation.get(FROM, None)
+        req_ts_to = request.operation.get(TO)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        reply = None
+        # Get root hash for ""to"" timestamp
+        # Get REVOC_REG_ENTRY for timestamp ""to""
+        path_to_reg_entry = domain.make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                                                       revoc_reg_def_id=revoc_reg_def_id)
+        past_root_to, \
+            reg_entry_to, \
+            seq_no_to, \
+            last_update_time_to, \
+            reg_entry_proof_to = self._get_reg_entry_by_timestamp(req_ts_to, path_to_reg_entry)
+        if past_root_to:",,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175450305,https://github.com/hyperledger/indy-node/pull/610#discussion_r175450305,anikitinDSR
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,"Tests for this:
test_send_with_from_by_default
test_send_with_from_by_demand",abbb562fed569b75cb936145538e05b9682f44b2,2018-03-19 14:20:55,175450895,"@@ -0,0 +1,90 @@
+import json
+import copy
+from plenum.common.util import get_utc_epoch
+from plenum.test.helper import sdk_send_and_check, sdk_sign_request_from_dict
+from indy_common.constants import REVOC_REG_DEF_ID, VALUE, FROM, TO, ISSUED, \
+    REVOKED, PREV_ACCUM, ACCUM, STATE_PROOF_FROM
+from plenum.common.constants import TXN_TIME, DATA
+from plenum.common.types import f
+from plenum.common.util import randomString
+
+
+def test_send_with_only_to_by_default(looper,
+                            txnPoolNodeSet,
+                            sdk_pool_handle,
+                            send_revoc_reg_entry_by_default,
+                            build_get_revoc_reg_delta):
+    rev_entry_req, reg_reply = send_revoc_reg_entry_by_default
+    get_revoc_reg_delta = copy.deepcopy(build_get_revoc_reg_delta)
+    del get_revoc_reg_delta['operation'][FROM]
+    get_revoc_reg_delta['operation'][REVOC_REG_DEF_ID] = rev_entry_req['operation'][REVOC_REG_DEF_ID]
+    get_revoc_reg_delta['operation'][TO] = get_utc_epoch() + 1000
+    sdk_reply = sdk_send_and_check([json.dumps(get_revoc_reg_delta)], looper, txnPoolNodeSet, sdk_pool_handle)
+    reply = sdk_reply[0][1]
+    assert rev_entry_req['operation'][REVOC_REG_DEF_ID] == reply['result'][REVOC_REG_DEF_ID]
+    assert rev_entry_req['operation'][VALUE][ACCUM] == reply['result'][DATA][VALUE][ACCUM]
+    assert rev_entry_req['operation'][VALUE][REVOKED] == reply['result'][DATA][VALUE][REVOKED]
+
+
+def test_send_earlier_then_first_entry_by_default(
+        looper,
+        txnPoolNodeSet,
+        sdk_pool_handle,
+        send_revoc_reg_entry_by_default,
+        build_get_revoc_reg_delta):
+    rev_entry_req, reg_reply = send_revoc_reg_entry_by_default
+    get_revoc_reg_delta = copy.deepcopy(build_get_revoc_reg_delta)
+    del get_revoc_reg_delta['operation'][FROM]
+    get_revoc_reg_delta['operation'][REVOC_REG_DEF_ID] = rev_entry_req['operation'][REVOC_REG_DEF_ID]
+    get_revoc_reg_delta['operation'][TO] = get_utc_epoch() - 1000
+    sdk_reply = sdk_send_and_check([json.dumps(get_revoc_reg_delta)], looper, txnPoolNodeSet, sdk_pool_handle)
+    reply = sdk_reply[0][1]
+    assert reply['result'][DATA] is None
+    assert reply['result'][f.SEQ_NO.nm] is None
+    assert reply['result'][TXN_TIME] is None
+
+
+def test_send_with_from_by_default(looper,
+        txnPoolNodeSet,
+        sdk_pool_handle,
+        sdk_wallet_steward,
+        send_revoc_reg_entry_by_default,
+        build_get_revoc_reg_delta):
+    # We save timestamp of state changes.
+    # looper and txnPoolNodeSet has ""module"", therefore,
+    # when we send request with FROM section, it's not a clean situation
+    looper.runFor(3)
+    # Assume, that send_revoc_reg_entry_by_default will add into revoked [1,2,3,4,5]
+    rev_reg_req1, rev_reg_reply1 = send_revoc_reg_entry_by_default
+    rev_reg_req1['operation'][VALUE][REVOKED] = []
+    # Issue [1,2,3], Revoked now must be [4,5]
+    rev_reg_req1['operation'][VALUE][ISSUED] = [1, 2, 3]
+    rev_reg_req1['operation'][VALUE][PREV_ACCUM] = rev_reg_req1['operation'][VALUE][ACCUM]
+    rev_reg_req1['operation'][VALUE][ACCUM] = randomString(10)
+    rev_reg_req2, rev_reg_reply2 = sdk_send_and_check(
+        [json.dumps(sdk_sign_request_from_dict(
+            looper, sdk_wallet_steward, rev_reg_req1['operation']))],
+        looper,
+        txnPoolNodeSet,
+        sdk_pool_handle)[0]
+    # Revoke [10, 11]
+    rev_reg_req2['operation'][VALUE][REVOKED] = [10, 11]
+    rev_reg_req2['operation'][VALUE][ISSUED] = []
+    rev_reg_req2['operation'][VALUE][PREV_ACCUM] = rev_reg_req2['operation'][VALUE][ACCUM]
+    rev_reg_req2['operation'][VALUE][ACCUM] = randomString(10)
+    rev_reg_req3, rev_reg_reply3 = sdk_send_and_check(
+        [json.dumps(sdk_sign_request_from_dict(
+            looper, sdk_wallet_steward, rev_reg_req2['operation']))],
+        looper,
+        txnPoolNodeSet,
+        sdk_pool_handle)[0]
+    reg_delta_req = copy.deepcopy(build_get_revoc_reg_delta)
+    reg_delta_req['operation'][REVOC_REG_DEF_ID] = rev_reg_req1['operation'][REVOC_REG_DEF_ID]
+    reg_delta_req['operation'][FROM] = rev_reg_reply1['result'][TXN_TIME]",83,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175450895,https://github.com/hyperledger/indy-node/pull/610#discussion_r175450895,anikitinDSR
https://github.com/hyperledger/indy-node/pull/610,https://github.com/hyperledger/indy-node/pull/610,Why do we call it here and not in `validate`?,abbb562fed569b75cb936145538e05b9682f44b2,2018-03-20 14:11:28,175778903,"@@ -422,6 +426,138 @@ def handleGetRevocRegDefReq(self, request: Request):
                                   proof=proof)
         return result
 
+    def handleGetRevocRegReq(self, request: Request):
+        req_ts = request.operation.get(TIMESTAMP)
+        revoc_reg_def_id = request.operation.get(REVOC_REG_DEF_ID)
+        author_did = request.identifier
+        # Get root hash corresponding with given timestamp
+        past_root = self.tsRevoc_store.get_equal_or_prev(req_ts)
+        # Path to corresponding ACCUM record in state
+        path = domain.make_state_path_for_revoc_reg_entry_accum(authors_did=author_did,
+                                                                revoc_reg_def_id=revoc_reg_def_id)
+        if past_root is None:
+            reply_data = None
+            seq_no = None
+            last_update_time = None
+            proof = None
+        else:
+            encoded_entry = self.state.get_for_root_hash(past_root, path)
+            revoc_reg_entry_accum, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+
+            reply_data = None if revoc_reg_entry_accum is None else revoc_reg_entry_accum
+
+            proof = self.make_proof(path, head_hash=past_root)
+        return self.make_result(request=request,
+                                data=reply_data,
+                                last_seq_no=seq_no,
+                                update_time=last_update_time,
+                                proof=proof)
+
+    def _get_reg_entry_by_timestamp(self, timestamp, path_to_reg_entry):
+        reg_entry = None
+        past_root = self.tsRevoc_store.get_equal_or_prev(timestamp)
+        if past_root:
+            encoded_entry = self.state.get_for_root_hash(past_root, path_to_reg_entry)
+            assert encoded_entry
+            reg_entry, _, _ = domain.decode_state_value(encoded_entry)
+        return past_root, reg_entry
+
+    def _get_reg_entry_accum_by_timestamp(self, timestamp, path_to_reg_entry_accum):
+        reg_entry_accum = None
+        seq_no = None
+        last_update_time = None
+        reg_entry_accum_proof = None
+        past_root = self.tsRevoc_store.get_equal_or_prev(timestamp)
+        if past_root:
+            encoded_entry = self.state.get_for_root_hash(past_root, path_to_reg_entry_accum)
+            reg_entry_accum, seq_no, last_update_time = domain.decode_state_value(encoded_entry)
+            reg_entry_accum_proof = self.make_proof(path_to_reg_entry_accum, head_hash=past_root)
+        return reg_entry_accum, seq_no, last_update_time, reg_entry_accum_proof
+
+    def _validateGetRevocRegDelta(self, request: Request):
+        assert request.operation
+        req_ts_to = request.operation.get(TO, None)
+        assert req_ts_to
+        req_ts_from = request.operation.get(FROM, None)
+        if req_ts_from and req_ts_from > req_ts_to:
+            raise InvalidClientRequest(request.identifier,
+                                       request.reqId,
+                                       ""Timestamp FROM more then TO: {} > {}"".format(req_ts_from, req_ts_to))
+
+    def handleGetRevocRegDelta(self, request: Request):
+        """"""
+        For getting reply we need:
+        1. Get REVOC_REG_ENTRY by ""TO"" timestamp from state
+        2. If FROM is given in request, then Get REVOC_REG_ENTRY by ""FROM"" timestamp from state
+        3. Get ISSUANCE_TYPE for REVOC_REG_DEF (revoked/issued strategy)
+        4. Compute issued and revoked indices by corresponding strategy
+        5. Make result
+           5.1 Now, if ""FROM"" is presented in request, then STATE_PROOF_FROM and ACCUM (revocation entry for ""FROM"" timestamp)
+               will added into data section
+           5.2 If not, then only STATE_PROOF for ""TO"" revocation entry will added
+        :param request:
+        :return: Reply
+        """"""
+        self._validateGetRevocRegDelta(request)",,2018-03-20 15:54:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/175778903,https://github.com/hyperledger/indy-node/pull/610#discussion_r175778903,ashcherbakov
https://github.com/hyperledger/indy-node/pull/602,https://github.com/hyperledger/indy-node/pull/602,"We need to store timestamps of all state updates (not only revocation) to reduce the risk of malicious nodes sending incorrect old results.
So, it's better to rename it to `state_ts_db`",0dcf5f2b699843e5f8f643c8756ebeee76261fa3,2018-03-13 16:46:23,174204078,"@@ -51,6 +51,7 @@
 configStateDbName = 'config_state'
 attrDbName = 'attr_db'
 idrCacheDbName = 'idr_cache_db'
+tsRevocationDbName = ""timestamp_revoc_db""",,2018-03-15 07:59:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174204078,https://github.com/hyperledger/indy-node/pull/602#discussion_r174204078,ashcherbakov
https://github.com/hyperledger/indy-node/pull/602,https://github.com/hyperledger/indy-node/pull/602,"I think this needs to be moved to KeyValueStorage Interface level, so that we can easily replace leveldb by rockdsb in this class.",0dcf5f2b699843e5f8f643c8756ebeee76261fa3,2018-03-14 11:12:53,174424371,"@@ -0,0 +1,41 @@
+from stp_core.common.log import getlogger
+from storage.kv_store_leveldb_int_keys import KeyValueStorageLeveldbIntKeys
+
+logger = getlogger()
+
+
+class StateTsDbStorage():
+    def __init__(self, name, db_dir, db_name):
+        logger.debug(""Initializing timestamp-root_hash storage for revocation"")
+        self._storage = KeyValueStorageLeveldbIntKeys(db_dir, db_name)
+        self._name = name
+
+    def __repr__(self):
+        return self._name
+
+    def get(self, timestamp: int):
+        value = self._storage.get(str(timestamp))
+        return value
+
+    def set(self, timestamp: int, root_hash: bytes):
+        self._storage.put(str(timestamp), root_hash)
+
+    def close(self):
+        self._storage.close()
+
+    def get_equal_or_prev(self, timestamp):",25,2018-03-15 07:59:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174424371,https://github.com/hyperledger/indy-node/pull/602#discussion_r174424371,ashcherbakov
https://github.com/hyperledger/indy-node/pull/600,https://github.com/hyperledger/indy-node/pull/600,Why do we prevent View Change only here? Don't we need to prevent the view change for the whole test?,e27d6b988d4f52f1d00d47924b6e01abd6c410f9,2018-03-14 08:15:03,174378978,"@@ -229,15 +230,17 @@ def patched_com(self, stateRoot):
 
     waitNodeDataEquality(looper, nodeSet[0], *nodeSet[1:])
 
-    keys = {}
-    for _ in range(3):
-        idy, _ = new_identity()
-        keys[idy.identifier] = idy.verkey
-        submit_id_req(idy)
-        looper.runFor(.01)
-
-    # Correct number of uncommitted entries
-    looper.run(eventually(check_uncommitted, 3, retryWait=1))
+    stashers = [n.nodeIbStasher for n in nodeSet]
+    with delay_rules(stashers, icDelay()):",,2018-03-14 10:49:21,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174378978,https://github.com/hyperledger/indy-node/pull/600#discussion_r174378978,ashcherbakov
https://github.com/hyperledger/indy-node/pull/600,https://github.com/hyperledger/indy-node/pull/600,"@ashcherbakov in fact View Change was offending only this part (or at least it seemed so), so I tried to make minimal change in test behaviour",e27d6b988d4f52f1d00d47924b6e01abd6c410f9,2018-03-14 08:18:48,174379705,"@@ -229,15 +230,17 @@ def patched_com(self, stateRoot):
 
     waitNodeDataEquality(looper, nodeSet[0], *nodeSet[1:])
 
-    keys = {}
-    for _ in range(3):
-        idy, _ = new_identity()
-        keys[idy.identifier] = idy.verkey
-        submit_id_req(idy)
-        looper.runFor(.01)
-
-    # Correct number of uncommitted entries
-    looper.run(eventually(check_uncommitted, 3, retryWait=1))
+    stashers = [n.nodeIbStasher for n in nodeSet]
+    with delay_rules(stashers, icDelay()):",,2018-03-14 10:49:21,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174379705,https://github.com/hyperledger/indy-node/pull/600#discussion_r174379705,skhoroshavin
https://github.com/hyperledger/indy-node/pull/598,https://github.com/hyperledger/indy-node/pull/598,It's better to name it `test_can_not_submit_claim_def_by_identity_owner`.,cd7f3dc3f00ff0fc0ad98ad54c6f39420b10b1b0,2018-03-13 08:42:06,174049590,"@@ -9,21 +9,21 @@
 logger = getlogger()
 
 
-def test_submit_claim_def(submitted_claim_def):
-    assert submitted_claim_def
+def test_error_submit_claim_def_by_client(submitted_schema_ID,",,2018-03-13 11:10:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174049590,https://github.com/hyperledger/indy-node/pull/598#discussion_r174049590,ashcherbakov
https://github.com/hyperledger/indy-node/pull/598,https://github.com/hyperledger/indy-node/pull/598,"I think this check doesn't make sense. The owner is related to the DID who owns the corresponding verkey.
Here we just need to make sure that only the person who created the ClaimDef can modify it. But this is in fact always guaranteed since sender's DID (identifier) is part of the ClaimDef's key in the state trie.
So, I think that the whole check for whether we already have a Claim Def can be removed.",cd7f3dc3f00ff0fc0ad98ad54c6f39420b10b1b0,2018-03-13 08:50:07,174051728,"@@ -250,11 +270,38 @@ def _validate_claim_def(self, req: Request):
             schemaSeqNo=schema_ref,
             signatureType=signature_type
         )
+
+        try:
+            origin_role = self.idrCache.getRole(
+                req.identifier, isCommitted=False) or None
+        except BaseException:
+            raise UnknownIdentifier(
+                req.identifier,
+                req.reqId)
         if claim_def:
-            raise InvalidClientRequest(identifier, req.reqId,
-                                       '{} can have one and only one CLAIM_DEF for '
-                                       'and schema ref {} and signature type {}'
-                                       .format(identifier, schema_ref, signature_type))
+            origin = req.identifier
+            owner = self.idrCache.getOwnerFor(req.identifier, isCommitted=False)",,2018-03-13 11:10:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174051728,https://github.com/hyperledger/indy-node/pull/598#discussion_r174051728,ashcherbakov
https://github.com/hyperledger/indy-node/pull/598,https://github.com/hyperledger/indy-node/pull/598,It's better to name it `test_can_not_submit_schema_by_identity_owner`.,cd7f3dc3f00ff0fc0ad98ad54c6f39420b10b1b0,2018-03-13 08:51:04,174051982,"@@ -33,6 +33,15 @@ def test_submit_same_schema_twice(looper, public_repo,
         ex_info.match(""can have one and only one SCHEMA with name GVT and version 1.0'"")
 
 
+def test_submit_schema_without_role(looper, public_repo_for_client,",,2018-03-13 11:10:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174051982,https://github.com/hyperledger/indy-node/pull/598#discussion_r174051982,ashcherbakov
https://github.com/hyperledger/indy-node/pull/598,https://github.com/hyperledger/indy-node/pull/598,"There is no need to call `getClaimDef`, isn't it?",cd7f3dc3f00ff0fc0ad98ad54c6f39420b10b1b0,2018-03-13 10:16:15,174076192,"@@ -278,23 +278,14 @@ def _validate_claim_def(self, req: Request):
             raise UnknownIdentifier(
                 req.identifier,
                 req.reqId)
-        if claim_def:",,2018-03-13 11:10:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174076192,https://github.com/hyperledger/indy-node/pull/598#discussion_r174076192,ashcherbakov
https://github.com/hyperledger/indy-node/pull/598,https://github.com/hyperledger/indy-node/pull/598,An existing field of the transaction should be used rather than not existing (`role`). For `SCHEMA` transaction it makes sense to use `name` filed here.,cd7f3dc3f00ff0fc0ad98ad54c6f39420b10b1b0,2018-03-14 16:16:22,174519144,"@@ -32,6 +32,10 @@ class Authoriser:
             {TRUSTEE: []},
         '{}_role_{}_'.format(NYM, TRUST_ANCHOR):
             {TRUSTEE: []},
+        '{}_role_<any>_<any>'.format(SCHEMA):
+            {TRUSTEE: [OWNER, ], STEWARD: [OWNER, ], TRUST_ANCHOR: [OWNER, ]},",14,2018-03-14 16:16:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174519144,https://github.com/hyperledger/indy-node/pull/598#discussion_r174519144,spivachuk
https://github.com/hyperledger/indy-node/pull/598,https://github.com/hyperledger/indy-node/pull/598,An existing field of the transaction should be used rather than not existing (`role`). For `CLAIM_DEF` transaction it makes sense to use `ref` filed here.,cd7f3dc3f00ff0fc0ad98ad54c6f39420b10b1b0,2018-03-14 16:17:50,174519661,"@@ -32,6 +32,10 @@ class Authoriser:
             {TRUSTEE: []},
         '{}_role_{}_'.format(NYM, TRUST_ANCHOR):
             {TRUSTEE: []},
+        '{}_role_<any>_<any>'.format(SCHEMA):
+            {TRUSTEE: [OWNER, ], STEWARD: [OWNER, ], TRUST_ANCHOR: [OWNER, ]},
+        '{}_role_<any>_<any>'.format(CLAIM_DEF):
+            {TRUSTEE: [OWNER, ], STEWARD: [OWNER, ], TRUST_ANCHOR: [OWNER, ]},",16,2018-03-14 16:17:50,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174519661,https://github.com/hyperledger/indy-node/pull/598#discussion_r174519661,spivachuk
https://github.com/hyperledger/indy-node/pull/596,https://github.com/hyperledger/indy-node/pull/596,Please use camel case,5429d1b8c975099d720dcd31d8bc0266d29f3f5c,2018-03-12 13:32:20,173796275,"@@ -27,6 +27,7 @@
 REINSTALL = 'reinstall'
 SIGNATURE_TYPE = 'signature_type'
 
+REVOC_TYPE = ""revoc_type""",,2018-03-12 13:39:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/173796275,https://github.com/hyperledger/indy-node/pull/596#discussion_r173796275,ashcherbakov
https://github.com/hyperledger/indy-node/pull/590,https://github.com/hyperledger/indy-node/pull/590,`isCommitted` must be True. Please add test for this.,24d4910c5d4f1529979df15633346d3effea8a75,2018-03-05 11:36:48,172159714,"@@ -369,6 +371,20 @@ def handleGetClaimDefReq(self, request: Request):
         result[SIGNATURE_TYPE] = signatureType
         return result
 
+    def handleGetRevocRegDefReq(self, request: Request):
+        state_path = request.operation.get(ID, None)
+        assert state_path
+        try:
+            keys, last_seq_no, last_update_time, proof = self.lookup(state_path, isCommitted=False)",,2018-03-06 08:55:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/172159714,https://github.com/hyperledger/indy-node/pull/590#discussion_r172159714,ashcherbakov
https://github.com/hyperledger/indy-node/pull/590,https://github.com/hyperledger/indy-node/pull/590,Please check the returned content (that we really got a correct and expected RevocRegDef),24d4910c5d4f1529979df15633346d3effea8a75,2018-03-05 11:38:09,172160049,"@@ -0,0 +1,36 @@
+import json
+from indy_common.constants import CRED_DEF_ID, ID, TYPE, TAG, GET_REVOC_REG_DEF
+from indy_common.state import domain
+from plenum.test.helper import sdk_sign_request_from_dict
+from plenum.test.helper import sdk_send_and_check
+
+def test_send_get_revoc_reg_def(looper,
+                                txnPoolNodeSet,
+                                sdk_wallet_steward,
+                                sdk_pool_handle,
+                                send_claim_def,
+                                build_revoc_def_by_default):
+    _, author_did = sdk_wallet_steward
+    claim_def_req = send_claim_def
+    revoc_reg = build_revoc_def_by_default
+    revoc_reg['operation'][CRED_DEF_ID] = "":"".join([author_did,
+                                                    domain.MARKER_CLAIM_DEF,
+                                                    claim_def_req['operation'][""signature_type""],
+                                                    str(claim_def_req['operation'][""ref""])])
+    revoc_req = sdk_sign_request_from_dict(looper, sdk_wallet_steward, revoc_reg['operation'])
+    sdk_send_and_check([json.dumps(revoc_req)], looper, txnPoolNodeSet, sdk_pool_handle)
+    get_revoc_reg_def_req = {
+        ID: "":"".join([author_did,
+                     domain.MARKER_REVOC_DEF,
+                      revoc_reg['operation'][CRED_DEF_ID],
+                      revoc_reg['operation'][TYPE],
+                      revoc_reg['operation'][TAG]]),
+        TYPE: GET_REVOC_REG_DEF,
+    }
+    get_revoc_reg_def_req = sdk_sign_request_from_dict(looper,
+                                                       sdk_wallet_steward,
+                                                       get_revoc_reg_def_req)
+    sdk_send_and_check([json.dumps(get_revoc_reg_def_req)],",,2018-03-06 08:55:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/172160049,https://github.com/hyperledger/indy-node/pull/590#discussion_r172160049,ashcherbakov
https://github.com/hyperledger/indy-node/pull/590,https://github.com/hyperledger/indy-node/pull/590,"Please check all data, not just ID",24d4910c5d4f1529979df15633346d3effea8a75,2018-03-06 08:13:21,172437152,"@@ -0,0 +1,74 @@
+import json
+import time
+from indy_common.constants import CRED_DEF_ID, ID, TYPE, TAG, GET_REVOC_REG_DEF, VALUE, MAX_CRED_NUM
+from indy_common.state import domain
+from indy_common.types import Request
+from plenum.test.helper import sdk_sign_request_from_dict
+from plenum.test.helper import sdk_send_and_check
+
+
+def test_send_get_revoc_reg_def(looper,
+                                txnPoolNodeSet,
+                                sdk_wallet_steward,
+                                sdk_pool_handle,
+                                send_revoc_reg_def):
+    _, author_did = sdk_wallet_steward
+    revoc_req = send_revoc_reg_def
+    revoc_reg_def_id = revoc_req['operation'][ID]
+    get_revoc_reg_def_req = {
+        ID: "":"".join([author_did,
+                      domain.MARKER_REVOC_DEF,
+                      revoc_req['operation'][CRED_DEF_ID],
+                      revoc_req['operation'][TYPE],
+                      revoc_req['operation'][TAG]]),
+        TYPE: GET_REVOC_REG_DEF,
+    }
+    get_revoc_reg_def_req = sdk_sign_request_from_dict(looper,
+                                                       sdk_wallet_steward,
+                                                       get_revoc_reg_def_req)
+    replies = sdk_send_and_check([json.dumps(get_revoc_reg_def_req)],
+                                 looper,
+                                 txnPoolNodeSet,
+                                 sdk_pool_handle)
+    req, reply = replies[0]
+    assert revoc_reg_def_id == reply['result']['data'][ID]",,2018-03-06 08:55:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/172437152,https://github.com/hyperledger/indy-node/pull/590#discussion_r172437152,ashcherbakov
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,"As far as I understand there could be other cases of states for not enabled service.
https://github.com/Supervisor/supervisor/blob/b609b6738121a43765ee5cb09fade07d1a286381/supervisor/states.py#L14. Could you please take them into account or add logging if they are not expected instead of returning True?",3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-04 14:03:56,179151264,"@@ -385,6 +423,18 @@ class ValidatorStats(BaseStats):
             )
             return None
 
+    @staticmethod
+    def get_enabled_state_via_supervisorctl():
+        ret = subprocess.check_output(
+            ""supervisorctl status indy-node | awk '{print $2}'; exit 0"",
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret == 'STOPPED':
+            return False
+        else:
+            return True
+",,2018-04-12 21:28:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/179151264,https://github.com/hyperledger/indy-node/pull/588#discussion_r179151264,andkononykhin
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,We don't have `ntp` in requirements list. Why did you list it here?,3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-04 14:05:18,179151699,"@@ -120,6 +120,57 @@ TimeoutSec=300
 WantedBy=multi-user.target
 EOF
 
+# add supervisord script
+cat <<EOF > /etc/supervisor/indy-node.conf
+[supervisord]
+nodaemon=true
+logfile=/var/log/indy/supervisord.log
+logfile_maxbytes=10MB
+loglevel=critical
+
+[supervisorctl]
+serverurl=http://127.0.0.1:9001
+
+[inet_http_server]
+port = 127.0.0.1:9001
+
+[rpcinterface:supervisor]
+supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
+
+[program:ntp]",,2018-04-12 21:28:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/179151699,https://github.com/hyperledger/indy-node/pull/588#discussion_r179151699,andkononykhin
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,Could you please use the same start command as for systemd?,3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-04 14:08:19,179152814,"@@ -120,6 +120,57 @@ TimeoutSec=300
 WantedBy=multi-user.target
 EOF
 
+# add supervisord script
+cat <<EOF > /etc/supervisor/indy-node.conf
+[supervisord]
+nodaemon=true
+logfile=/var/log/indy/supervisord.log
+logfile_maxbytes=10MB
+loglevel=critical
+
+[supervisorctl]
+serverurl=http://127.0.0.1:9001
+
+[inet_http_server]
+port = 127.0.0.1:9001
+
+[rpcinterface:supervisor]
+supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
+
+[program:ntp]
+command=/usr/sbin/ntpd -n
+autorestart=true
+startsecs=15
+startretries=6
+stopasgroup=true
+killasgroup=true
+
+[program:indy-node]
+command=/usr/local/bin/init_and_start_indy_node.sh
+user=indy
+stdout_logfile=/dev/stdout
+stdout_logfile_maxbytes=0
+stderr_logfile=/dev/stderr
+stderr_logfile_maxbytes=0
+autorestart=true
+startsecs=15
+startretries=6
+stopasgroup=true
+killasgroup=true
+
+[program:indy-node-control]
+command=/usr/local/bin/start_node_control_tool",,2018-04-12 21:28:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/179152814,https://github.com/hyperledger/indy-node/pull/588#discussion_r179152814,andkononykhin
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,Why do you need to couple `init_indy_node` and `start_indy_node`? As it is [documented](https://github.com/hyperledger/indy-node/blob/master/docs/start-nodes.md#scripts-for-initialization) for now keys initialization is a separate operation and shouldn't be performed each time node starts.,3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-04 14:11:56,179154056,"@@ -120,6 +120,57 @@ TimeoutSec=300
 WantedBy=multi-user.target
 EOF
 
+# add supervisord script
+cat <<EOF > /etc/supervisor/indy-node.conf
+[supervisord]
+nodaemon=true
+logfile=/var/log/indy/supervisord.log
+logfile_maxbytes=10MB
+loglevel=critical
+
+[supervisorctl]
+serverurl=http://127.0.0.1:9001
+
+[inet_http_server]
+port = 127.0.0.1:9001
+
+[rpcinterface:supervisor]
+supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
+
+[program:ntp]
+command=/usr/sbin/ntpd -n
+autorestart=true
+startsecs=15
+startretries=6
+stopasgroup=true
+killasgroup=true
+
+[program:indy-node]
+command=/usr/local/bin/init_and_start_indy_node.sh",,2018-04-12 21:28:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/179154056,https://github.com/hyperledger/indy-node/pull/588#discussion_r179154056,andkononykhin
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,I removed ntp,3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-05 16:32:26,179524588,"@@ -120,6 +120,57 @@ TimeoutSec=300
 WantedBy=multi-user.target
 EOF
 
+# add supervisord script
+cat <<EOF > /etc/supervisor/indy-node.conf
+[supervisord]
+nodaemon=true
+logfile=/var/log/indy/supervisord.log
+logfile_maxbytes=10MB
+loglevel=critical
+
+[supervisorctl]
+serverurl=http://127.0.0.1:9001
+
+[inet_http_server]
+port = 127.0.0.1:9001
+
+[rpcinterface:supervisor]
+supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
+
+[program:ntp]",,2018-04-12 21:28:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/179524588,https://github.com/hyperledger/indy-node/pull/588#discussion_r179524588,smithbk
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,done,3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-05 16:32:45,179524669,"@@ -120,6 +120,57 @@ TimeoutSec=300
 WantedBy=multi-user.target
 EOF
 
+# add supervisord script
+cat <<EOF > /etc/supervisor/indy-node.conf
+[supervisord]
+nodaemon=true
+logfile=/var/log/indy/supervisord.log
+logfile_maxbytes=10MB
+loglevel=critical
+
+[supervisorctl]
+serverurl=http://127.0.0.1:9001
+
+[inet_http_server]
+port = 127.0.0.1:9001
+
+[rpcinterface:supervisor]
+supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
+
+[program:ntp]
+command=/usr/sbin/ntpd -n
+autorestart=true
+startsecs=15
+startretries=6
+stopasgroup=true
+killasgroup=true
+
+[program:indy-node]
+command=/usr/local/bin/init_and_start_indy_node.sh
+user=indy
+stdout_logfile=/dev/stdout
+stdout_logfile_maxbytes=0
+stderr_logfile=/dev/stderr
+stderr_logfile_maxbytes=0
+autorestart=true
+startsecs=15
+startretries=6
+stopasgroup=true
+killasgroup=true
+
+[program:indy-node-control]
+command=/usr/local/bin/start_node_control_tool",,2018-04-12 21:28:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/179524669,https://github.com/hyperledger/indy-node/pull/588#discussion_r179524669,smithbk
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,done,3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-05 16:33:24,179524879,"@@ -385,6 +423,18 @@ class ValidatorStats(BaseStats):
             )
             return None
 
+    @staticmethod
+    def get_enabled_state_via_supervisorctl():
+        ret = subprocess.check_output(
+            ""supervisorctl status indy-node | awk '{print $2}'; exit 0"",
+            stderr=subprocess.STDOUT, shell=True
+        )
+        ret = ret.decode().strip()
+        if ret == 'STOPPED':
+            return False
+        else:
+            return True
+",,2018-04-12 21:28:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/179524879,https://github.com/hyperledger/indy-node/pull/588#discussion_r179524879,smithbk
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,"It seems some things won't work here as expected:

`/usr/local/bin/start_node_control_tool ${TEST_MODE} --hold-ext ${HOLD_EXT}`
here escapes for dollar signs are missed thus bash will expand the variables at the time `postinst_node` is running but we need them to be expanded at the time when `start_node_control_tool` is being started instead

`sed -i ""s/\\\\\""/\""/g"" $GENERAL_CONFIG_DIR/node_control.conf`
I don't think such workaround is necessary, it's better to fix current weird code related to that:

- use quotes here for HOLD_EXT as it is expected as list of strings separated by space: `""\${HOLD_EXT}""`
- set empty default value for HOLD_EXT in node_control.conf below instead of `\""\""`: `HOLD_EXT=`

Also it would be great to fix systemd related logic adding quotes there as well.",3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-12 09:57:51,181027412,"@@ -120,6 +120,49 @@ TimeoutSec=300
 WantedBy=multi-user.target
 EOF
 
+# add supervisord script
+cat <<EOF > /etc/supervisor/indy-node.conf
+[supervisord]
+nodaemon=true
+logfile=/var/log/indy/supervisord.log
+logfile_maxbytes=10MB
+loglevel=critical
+
+[supervisorctl]
+serverurl=http://127.0.0.1:9001
+
+[inet_http_server]
+port = 127.0.0.1:9001
+
+[rpcinterface:supervisor]
+supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
+
+[program:indy-node]
+command=/usr/bin/env python3 -O /usr/local/bin/start_indy_node %(ENV_NODE_NAME)s %(ENV_NODE_PORT)s %(ENV_NODE_CLIENT_PORT)s
+user=indy
+stdout_logfile=/dev/stdout
+stdout_logfile_maxbytes=0
+stderr_logfile=/dev/stderr
+stderr_logfile_maxbytes=0
+autorestart=true
+startsecs=15
+startretries=6
+stopasgroup=true
+killasgroup=true
+
+[program:indy-node-control]
+command=sh -ac 'sed -i ""s/\\\\\""/\""/g"" $GENERAL_CONFIG_DIR/node_control.conf;. $GENERAL_CONFIG_DIR/node_control.conf;/usr/bin/env python3 -O /usr/local/bin/start_node_control_tool ${TEST_MODE} --hold-ext ${HOLD_EXT}'",,2018-04-12 21:28:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181027412,https://github.com/hyperledger/indy-node/pull/588#discussion_r181027412,andkononykhin
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,"Could you please clarify how NODE_NAME, NODE_PORT and NODE_CLIENT will be available in env? Have I missed something in supervisor's logic?",3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-12 10:04:41,181029160,"@@ -120,6 +120,49 @@ TimeoutSec=300
 WantedBy=multi-user.target
 EOF
 
+# add supervisord script
+cat <<EOF > /etc/supervisor/indy-node.conf
+[supervisord]
+nodaemon=true
+logfile=/var/log/indy/supervisord.log
+logfile_maxbytes=10MB
+loglevel=critical
+
+[supervisorctl]
+serverurl=http://127.0.0.1:9001
+
+[inet_http_server]
+port = 127.0.0.1:9001
+
+[rpcinterface:supervisor]
+supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
+
+[program:indy-node]
+command=/usr/bin/env python3 -O /usr/local/bin/start_indy_node %(ENV_NODE_NAME)s %(ENV_NODE_PORT)s %(ENV_NODE_CLIENT_PORT)s",,2018-04-12 21:28:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181029160,https://github.com/hyperledger/indy-node/pull/588#discussion_r181029160,andkononykhin
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,Fixed,3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-12 21:33:15,181228273,"@@ -120,6 +120,49 @@ TimeoutSec=300
 WantedBy=multi-user.target
 EOF
 
+# add supervisord script
+cat <<EOF > /etc/supervisor/indy-node.conf
+[supervisord]
+nodaemon=true
+logfile=/var/log/indy/supervisord.log
+logfile_maxbytes=10MB
+loglevel=critical
+
+[supervisorctl]
+serverurl=http://127.0.0.1:9001
+
+[inet_http_server]
+port = 127.0.0.1:9001
+
+[rpcinterface:supervisor]
+supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
+
+[program:indy-node]
+command=/usr/bin/env python3 -O /usr/local/bin/start_indy_node %(ENV_NODE_NAME)s %(ENV_NODE_PORT)s %(ENV_NODE_CLIENT_PORT)s",,2018-04-12 21:33:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181228273,https://github.com/hyperledger/indy-node/pull/588#discussion_r181228273,smithbk
https://github.com/hyperledger/indy-node/pull/588,https://github.com/hyperledger/indy-node/pull/588,Fixed,3c03d29242cca2467ee7b3318d36f37aadffc2d9,2018-04-12 21:33:33,181228334,"@@ -120,6 +120,49 @@ TimeoutSec=300
 WantedBy=multi-user.target
 EOF
 
+# add supervisord script
+cat <<EOF > /etc/supervisor/indy-node.conf
+[supervisord]
+nodaemon=true
+logfile=/var/log/indy/supervisord.log
+logfile_maxbytes=10MB
+loglevel=critical
+
+[supervisorctl]
+serverurl=http://127.0.0.1:9001
+
+[inet_http_server]
+port = 127.0.0.1:9001
+
+[rpcinterface:supervisor]
+supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface
+
+[program:indy-node]
+command=/usr/bin/env python3 -O /usr/local/bin/start_indy_node %(ENV_NODE_NAME)s %(ENV_NODE_PORT)s %(ENV_NODE_CLIENT_PORT)s
+user=indy
+stdout_logfile=/dev/stdout
+stdout_logfile_maxbytes=0
+stderr_logfile=/dev/stderr
+stderr_logfile_maxbytes=0
+autorestart=true
+startsecs=15
+startretries=6
+stopasgroup=true
+killasgroup=true
+
+[program:indy-node-control]
+command=sh -ac 'sed -i ""s/\\\\\""/\""/g"" $GENERAL_CONFIG_DIR/node_control.conf;. $GENERAL_CONFIG_DIR/node_control.conf;/usr/bin/env python3 -O /usr/local/bin/start_node_control_tool ${TEST_MODE} --hold-ext ${HOLD_EXT}'",,2018-04-12 21:33:33,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/181228334,https://github.com/hyperledger/indy-node/pull/588#discussion_r181228334,smithbk
https://github.com/hyperledger/indy-node/pull/584,https://github.com/hyperledger/indy-node/pull/584,I think it should be accessible by STEWARDS as well,94dfe336ea88180362211a479087c8cbff7d7c74,2018-02-27 10:57:30,170885084,"@@ -0,0 +1,163 @@
+# Extension of validator_info
+The document contains list of possible extensions and modifications of validator_info command to simplify node state monitoring and debug process
+
+* [Validator_info Description](#cur-description)
+* [Modification - New Read Command](#new-command)
+* [Extension - Additional Fields](#new-fields)
+
+## Validator_info Description
+Validator_info is a script that formats and prints data provided by node. The script should be run manually by
+the user who has a read access to the \<node name\>_info.json file from the node's data directory.
+This file is updated by node once a minute and contains following information:
+```
+{
+    ""did"": ""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"", # node's identidier
+    ""response-version"": ""0.0.1"", # 0.0.1 for now
+    ""timestamp"": 1519711338, # current time 
+    ""verkey"": ""33nHHYKnqmtGAVfZZGoP8hpeExeH45Fo8cKmd5mcnKYk7XgWNBxkkKJ"", # node's verkey
+    ""pool"": { # current pool
+        ""reachable"": { # reachable nodes
+            ""list"": [""Node1"", ""Node2"", ""Node3"", ""Node4""],
+            ""count"": 4
+         },
+        
+        ""total-count"": 4, # total count of nodes
+        ""unreachable"": { # unreachable nodes
+           ""list"": [],
+           ""count"": 0
+        }
+     },
+    
+    ""bindings"": { # node's network configuration
+       ""client"": {
+            ""port"": 9702,
+            ""protocol"": ""tcp""
+        },
+       
+       ""node"": {
+            ""port"": 9701,
+            ""protocol"": ""tcp""
+        }
+    },
+    
+    ""metrics"": { # some numeric characteristics
+        ""transaction-count"": { # txn count by ledger
+            ""pool"": 4,
+            ""ledger"": 19,
+            ""config"": 0
+        },
+        
+        ""average-per-second"": { # performance counters
+            ""write-transactions"": 0.013294133790137249,
+            ""read-transactions"": 0.0
+        },
+        
+        ""uptime"": 300 # uptaime
+    },
+    
+    ""software"": { # packets' versions
+        ""indy-node"": ""1.3.319"",
+        ""sovrin"": null
+    },
+    
+    ""alias"": ""Node1"" # node's name
+}
+```
+
+## Modification - New Read Command
+Validator_info should be accessible as read command, available for TRUSTEE only. New command should provide info from",,2018-02-27 11:09:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/170885084,https://github.com/hyperledger/indy-node/pull/584#discussion_r170885084,ashcherbakov
https://github.com/hyperledger/indy-node/pull/584,https://github.com/hyperledger/indy-node/pull/584,os - typo,94dfe336ea88180362211a479087c8cbff7d7c74,2018-02-27 10:57:55,170885172,"@@ -0,0 +1,163 @@
+# Extension of validator_info
+The document contains list of possible extensions and modifications of validator_info command to simplify node state monitoring and debug process
+
+* [Validator_info Description](#cur-description)
+* [Modification - New Read Command](#new-command)
+* [Extension - Additional Fields](#new-fields)
+
+## Validator_info Description
+Validator_info is a script that formats and prints data provided by node. The script should be run manually by
+the user who has a read access to the \<node name\>_info.json file from the node's data directory.
+This file is updated by node once a minute and contains following information:
+```
+{
+    ""did"": ""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"", # node's identidier
+    ""response-version"": ""0.0.1"", # 0.0.1 for now
+    ""timestamp"": 1519711338, # current time 
+    ""verkey"": ""33nHHYKnqmtGAVfZZGoP8hpeExeH45Fo8cKmd5mcnKYk7XgWNBxkkKJ"", # node's verkey
+    ""pool"": { # current pool
+        ""reachable"": { # reachable nodes
+            ""list"": [""Node1"", ""Node2"", ""Node3"", ""Node4""],
+            ""count"": 4
+         },
+        
+        ""total-count"": 4, # total count of nodes
+        ""unreachable"": { # unreachable nodes
+           ""list"": [],
+           ""count"": 0
+        }
+     },
+    
+    ""bindings"": { # node's network configuration
+       ""client"": {
+            ""port"": 9702,
+            ""protocol"": ""tcp""
+        },
+       
+       ""node"": {
+            ""port"": 9701,
+            ""protocol"": ""tcp""
+        }
+    },
+    
+    ""metrics"": { # some numeric characteristics
+        ""transaction-count"": { # txn count by ledger
+            ""pool"": 4,
+            ""ledger"": 19,
+            ""config"": 0
+        },
+        
+        ""average-per-second"": { # performance counters
+            ""write-transactions"": 0.013294133790137249,
+            ""read-transactions"": 0.0
+        },
+        
+        ""uptime"": 300 # uptaime
+    },
+    
+    ""software"": { # packets' versions
+        ""indy-node"": ""1.3.319"",
+        ""sovrin"": null
+    },
+    
+    ""alias"": ""Node1"" # node's name
+}
+```
+
+## Modification - New Read Command
+Validator_info should be accessible as read command, available for TRUSTEE only. New command should provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
+requesting os all parameters or some subset of parameters.",,2018-02-27 11:09:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/170885172,https://github.com/hyperledger/indy-node/pull/584#discussion_r170885172,ashcherbakov
https://github.com/hyperledger/indy-node/pull/584,https://github.com/hyperledger/indy-node/pull/584,changed,94dfe336ea88180362211a479087c8cbff7d7c74,2018-02-27 11:11:30,170888512,"@@ -0,0 +1,163 @@
+# Extension of validator_info
+The document contains list of possible extensions and modifications of validator_info command to simplify node state monitoring and debug process
+
+* [Validator_info Description](#cur-description)
+* [Modification - New Read Command](#new-command)
+* [Extension - Additional Fields](#new-fields)
+
+## Validator_info Description
+Validator_info is a script that formats and prints data provided by node. The script should be run manually by
+the user who has a read access to the \<node name\>_info.json file from the node's data directory.
+This file is updated by node once a minute and contains following information:
+```
+{
+    ""did"": ""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"", # node's identidier
+    ""response-version"": ""0.0.1"", # 0.0.1 for now
+    ""timestamp"": 1519711338, # current time 
+    ""verkey"": ""33nHHYKnqmtGAVfZZGoP8hpeExeH45Fo8cKmd5mcnKYk7XgWNBxkkKJ"", # node's verkey
+    ""pool"": { # current pool
+        ""reachable"": { # reachable nodes
+            ""list"": [""Node1"", ""Node2"", ""Node3"", ""Node4""],
+            ""count"": 4
+         },
+        
+        ""total-count"": 4, # total count of nodes
+        ""unreachable"": { # unreachable nodes
+           ""list"": [],
+           ""count"": 0
+        }
+     },
+    
+    ""bindings"": { # node's network configuration
+       ""client"": {
+            ""port"": 9702,
+            ""protocol"": ""tcp""
+        },
+       
+       ""node"": {
+            ""port"": 9701,
+            ""protocol"": ""tcp""
+        }
+    },
+    
+    ""metrics"": { # some numeric characteristics
+        ""transaction-count"": { # txn count by ledger
+            ""pool"": 4,
+            ""ledger"": 19,
+            ""config"": 0
+        },
+        
+        ""average-per-second"": { # performance counters
+            ""write-transactions"": 0.013294133790137249,
+            ""read-transactions"": 0.0
+        },
+        
+        ""uptime"": 300 # uptaime
+    },
+    
+    ""software"": { # packets' versions
+        ""indy-node"": ""1.3.319"",
+        ""sovrin"": null
+    },
+    
+    ""alias"": ""Node1"" # node's name
+}
+```
+
+## Modification - New Read Command
+Validator_info should be accessible as read command, available for TRUSTEE only. New command should provide info from",,2018-02-27 11:11:30,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/170888512,https://github.com/hyperledger/indy-node/pull/584#discussion_r170888512,dsurnin
https://github.com/hyperledger/indy-node/pull/584,https://github.com/hyperledger/indy-node/pull/584,fixed,94dfe336ea88180362211a479087c8cbff7d7c74,2018-02-27 11:11:39,170888542,"@@ -0,0 +1,163 @@
+# Extension of validator_info
+The document contains list of possible extensions and modifications of validator_info command to simplify node state monitoring and debug process
+
+* [Validator_info Description](#cur-description)
+* [Modification - New Read Command](#new-command)
+* [Extension - Additional Fields](#new-fields)
+
+## Validator_info Description
+Validator_info is a script that formats and prints data provided by node. The script should be run manually by
+the user who has a read access to the \<node name\>_info.json file from the node's data directory.
+This file is updated by node once a minute and contains following information:
+```
+{
+    ""did"": ""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"", # node's identidier
+    ""response-version"": ""0.0.1"", # 0.0.1 for now
+    ""timestamp"": 1519711338, # current time 
+    ""verkey"": ""33nHHYKnqmtGAVfZZGoP8hpeExeH45Fo8cKmd5mcnKYk7XgWNBxkkKJ"", # node's verkey
+    ""pool"": { # current pool
+        ""reachable"": { # reachable nodes
+            ""list"": [""Node1"", ""Node2"", ""Node3"", ""Node4""],
+            ""count"": 4
+         },
+        
+        ""total-count"": 4, # total count of nodes
+        ""unreachable"": { # unreachable nodes
+           ""list"": [],
+           ""count"": 0
+        }
+     },
+    
+    ""bindings"": { # node's network configuration
+       ""client"": {
+            ""port"": 9702,
+            ""protocol"": ""tcp""
+        },
+       
+       ""node"": {
+            ""port"": 9701,
+            ""protocol"": ""tcp""
+        }
+    },
+    
+    ""metrics"": { # some numeric characteristics
+        ""transaction-count"": { # txn count by ledger
+            ""pool"": 4,
+            ""ledger"": 19,
+            ""config"": 0
+        },
+        
+        ""average-per-second"": { # performance counters
+            ""write-transactions"": 0.013294133790137249,
+            ""read-transactions"": 0.0
+        },
+        
+        ""uptime"": 300 # uptaime
+    },
+    
+    ""software"": { # packets' versions
+        ""indy-node"": ""1.3.319"",
+        ""sovrin"": null
+    },
+    
+    ""alias"": ""Node1"" # node's name
+}
+```
+
+## Modification - New Read Command
+Validator_info should be accessible as read command, available for TRUSTEE only. New command should provide info from
+all the connected nodes without need of consensus (similar to force=True flag in upgrade cmd). Command should allow
+requesting os all parameters or some subset of parameters.",,2018-02-27 11:11:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/170888542,https://github.com/hyperledger/indy-node/pull/584#discussion_r170888542,dsurnin
https://github.com/hyperledger/indy-node/pull/584,https://github.com/hyperledger/indy-node/pull/584,"Please add the following from INDY-967:
- the BLS key
- the timezone",94dfe336ea88180362211a479087c8cbff7d7c74,2018-03-15 16:44:32,174851919,"@@ -0,0 +1,163 @@
+# Extension of validator_info
+The document contains list of possible extensions and modifications of validator_info command to simplify node state monitoring and debug process
+
+* [Validator_info Description](#cur-description)
+* [Modification - New Read Command](#new-command)
+* [Extension - Additional Fields](#new-fields)
+
+## Validator_info Description
+Validator_info is a script that formats and prints data provided by node. The script should be run manually by
+the user who has a read access to the \<node name\>_info.json file from the node's data directory.
+This file is updated by node once a minute and contains following information:
+```
+{
+    ""did"": ""Gw6pDLhcBcoQesN72qfotTgFa7cbuqZpkX3Xo6pLhPhv"", # node's identidier
+    ""response-version"": ""0.0.1"", # 0.0.1 for now
+    ""timestamp"": 1519711338, # current time 
+    ""verkey"": ""33nHHYKnqmtGAVfZZGoP8hpeExeH45Fo8cKmd5mcnKYk7XgWNBxkkKJ"", # node's verkey
+    ""pool"": { # current pool
+        ""reachable"": { # reachable nodes
+            ""list"": [""Node1"", ""Node2"", ""Node3"", ""Node4""],
+            ""count"": 4
+         },
+        
+        ""total-count"": 4, # total count of nodes
+        ""unreachable"": { # unreachable nodes
+           ""list"": [],
+           ""count"": 0
+        }
+     },
+    
+    ""bindings"": { # node's network configuration
+       ""client"": {
+            ""port"": 9702,
+            ""protocol"": ""tcp""
+        },
+       
+       ""node"": {
+            ""port"": 9701,
+            ""protocol"": ""tcp""
+        }
+    },
+    
+    ""metrics"": { # some numeric characteristics
+        ""transaction-count"": { # txn count by ledger
+            ""pool"": 4,
+            ""ledger"": 19,
+            ""config"": 0
+        },
+        
+        ""average-per-second"": { # performance counters
+            ""write-transactions"": 0.013294133790137249,
+            ""read-transactions"": 0.0
+        },
+        
+        ""uptime"": 300 # uptaime
+    },
+    
+    ""software"": { # packets' versions
+        ""indy-node"": ""1.3.319"",
+        ""sovrin"": null
+    },
+    
+    ""alias"": ""Node1"" # node's name
+}
+```
+
+## Modification - New Read Command
+Validator_info should be accessible as read command, available for TRUSTEE only. New command should provide info from",,2018-03-15 16:44:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/174851919,https://github.com/hyperledger/indy-node/pull/584#discussion_r174851919,mgbailey
https://github.com/hyperledger/indy-node/pull/581,https://github.com/hyperledger/indy-node/pull/581,"This line duplicates line 19, it's enough to leave only asserts under condition.",2f1e1bfbd7c000b2c4f74fad26d32045477128e2,2018-02-26 08:28:20,170520055,"@@ -19,14 +19,9 @@ def test_nym_send_twice(looper, sdk_pool_handle, sdk_wallet_steward):
             result = json.loads(looper.loop.run_until_complete(submit_request(sdk_pool_handle, req_signed)))
             assert result['op'] == REPLY
         else:
-            # TODO(INDY-1069): Ugly hack to deal with old libindy which raises exception on REJECT,
-            # in fact it should be simple:
-            # assert result['op'] == REJECT
-            try:
-                json.loads(looper.loop.run_until_complete(submit_request(sdk_pool_handle, req_signed)))
-                assert False
-            except IndyError as ex:
-                assert ex.error_code == ErrorCode.LedgerInvalidTransaction
+            result = json.loads(looper.loop.run_until_complete(submit_request(sdk_pool_handle, req_signed)))",12,2018-02-26 08:28:29,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/170520055,https://github.com/hyperledger/indy-node/pull/581#discussion_r170520055,sergey-shilov
https://github.com/hyperledger/indy-node/pull/581,https://github.com/hyperledger/indy-node/pull/581,Done. Will be changed with new PR.,2f1e1bfbd7c000b2c4f74fad26d32045477128e2,2018-02-26 12:34:03,170577002,"@@ -19,14 +19,9 @@ def test_nym_send_twice(looper, sdk_pool_handle, sdk_wallet_steward):
             result = json.loads(looper.loop.run_until_complete(submit_request(sdk_pool_handle, req_signed)))
             assert result['op'] == REPLY
         else:
-            # TODO(INDY-1069): Ugly hack to deal with old libindy which raises exception on REJECT,
-            # in fact it should be simple:
-            # assert result['op'] == REJECT
-            try:
-                json.loads(looper.loop.run_until_complete(submit_request(sdk_pool_handle, req_signed)))
-                assert False
-            except IndyError as ex:
-                assert ex.error_code == ErrorCode.LedgerInvalidTransaction
+            result = json.loads(looper.loop.run_until_complete(submit_request(sdk_pool_handle, req_signed)))",12,2018-02-26 12:34:03,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/170577002,https://github.com/hyperledger/indy-node/pull/581#discussion_r170577002,ArtObr
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,"The state should accumulate all issued and revoked indices.
Please also add a test for this.  ",62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-22 15:17:17,169989951,"@@ -135,6 +144,22 @@ def prepare_revoc_def_for_state(txn):
     return path, value_bytes
 
 
+def prepare_revoc_reg_entry_for_state(txn):
+    author_did = txn.get(f.IDENTIFIER.nm)
+    revoc_reg_def_id = txn.get(REVOC_REG_DEF_ID)
+    assert author_did
+    assert revoc_reg_def_id
+    path = make_state_path_for_revoc_reg_entry(authors_did=author_did,
+                                               revoc_reg_def_id=revoc_reg_def_id)
+
+    seq_no = txn[f.SEQ_NO.nm]
+    txn_time = txn[TXN_TIME]
+    assert seq_no
+    assert txn_time
+    value_bytes = encode_state_value(txn, seq_no, txn_time)",55,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/169989951,https://github.com/hyperledger/indy-node/pull/576#discussion_r169989951,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,Can we add this check now?,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-22 15:17:39,169990049,"@@ -252,6 +257,12 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
 
+    def _validate_revoc_reg_entry(self, req: Request):
+        operation = req.operation
+        revoc_reg_def_id = operation.get(REVOC_REG_DEF_ID)
+        assert revoc_reg_def_id
+        # TODO Add check that sufficient revoc_reg_def exist",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/169990049,https://github.com/hyperledger/indy-node/pull/576#discussion_r169990049,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,Should it be `IntegerField` here as well?,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:02:34,171177936,"@@ -106,6 +106,23 @@ class ClientRevocDefSubmitField(MessageValidator):
     )
 
 
+class RevocRegEntryValueField(MessageValidator):
+    schema = (
+        (PREV_ACCUM, NonEmptyStringField()),
+        (ACCUM, NonEmptyStringField()),
+        (ISSUED, IterableField(inner_field_type=IntegerField())),
+        (REVOKED, IterableField(inner_field_type=NonEmptyStringField()))",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171177936,https://github.com/hyperledger/indy-node/pull/576#discussion_r171177936,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,Please move the strategies into a separate file,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:03:35,171178183,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171178183,https://github.com/hyperledger/indy-node/pull/576#discussion_r171178183,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,"Why do we need this? We use inheritance for this, don't we? So, it's better to use abstract method to perform strategy-specific validation (do not forget to use @abstractmethod for an abstract class)",62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:04:32,171178368,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:
+
+    def __init__(self, state):
+        self.state = state
+        self.author_did = None
+        self.revoc_reg_def_id = None
+        self.req_id = None
+
+    def set_parameters_from_txn(self, author_did, revoc_reg_def_id, req_id):
+        self.author_did = author_did
+        self.revoc_reg_def_id = revoc_reg_def_id
+        self.req_id = req_id
+
+    def set_strategy(self, strategy):",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171178368,https://github.com/hyperledger/indy-node/pull/576#discussion_r171178368,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,I believe it should be an abstract class with `metaclass=ABCMeta` inheritance.,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:06:51,171178941,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171178941,https://github.com/hyperledger/indy-node/pull/576#discussion_r171178941,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,"Probably it's better to say: 'Can not have an index in both ""issued"" and ""revoked"" lists'.",62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:08:18,171179257,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:
+
+    def __init__(self, state):
+        self.state = state
+        self.author_did = None
+        self.revoc_reg_def_id = None
+        self.req_id = None
+
+    def set_parameters_from_txn(self, author_did, revoc_reg_def_id, req_id):
+        self.author_did = author_did
+        self.revoc_reg_def_id = revoc_reg_def_id
+        self.req_id = req_id
+
+    def set_strategy(self, strategy):
+        self.strategy = strategy
+
+    def set_to_state(self, txn):
+        assert self.strategy
+        self.strategy.write(txn)
+
+    def validate_txn(self, current_entry, req: Request):
+        self.set_parameters_from_txn(author_did=req.identifier,
+                                     revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
+                                     req_id=req.reqId)
+        # General checks for all Revocation entries
+        operation = req.operation
+        value_from_txn = operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED)
+        revoked_from_txn = value_from_txn.get(REVOKED)
+        intersection = set(issued_from_txn).intersection(set(revoked_from_txn))
+        if len(intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Indices {} are existed in issued and revoked list"".format(intersection))",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171179257,https://github.com/hyperledger/indy-node/pull/576#discussion_r171179257,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,"It's better to say:
The current accumulator value {} must be equal to the last accumulator value {} in transaction.
",62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:10:01,171179643,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:
+
+    def __init__(self, state):
+        self.state = state
+        self.author_did = None
+        self.revoc_reg_def_id = None
+        self.req_id = None
+
+    def set_parameters_from_txn(self, author_did, revoc_reg_def_id, req_id):
+        self.author_did = author_did
+        self.revoc_reg_def_id = revoc_reg_def_id
+        self.req_id = req_id
+
+    def set_strategy(self, strategy):
+        self.strategy = strategy
+
+    def set_to_state(self, txn):
+        assert self.strategy
+        self.strategy.write(txn)
+
+    def validate_txn(self, current_entry, req: Request):
+        self.set_parameters_from_txn(author_did=req.identifier,
+                                     revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
+                                     req_id=req.reqId)
+        # General checks for all Revocation entries
+        operation = req.operation
+        value_from_txn = operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED)
+        revoked_from_txn = value_from_txn.get(REVOKED)
+        intersection = set(issued_from_txn).intersection(set(revoked_from_txn))
+        if len(intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Indices {} are existed in issued and revoked list"".format(intersection))
+        if current_entry is None:
+            return None
+        value_from_state = current_entry.get(VALUE)
+        assert value_from_state
+        current_accum = value_from_state.get(ACCUM)
+        if current_accum != value_from_txn.get(PREV_ACCUM):
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Accum value from state: {} ""
+                                       ""do not equal with {} value """,,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171179643,https://github.com/hyperledger/indy-node/pull/576#discussion_r171179643,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,Use @abstractmethod,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:10:11,171179673,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:
+
+    def __init__(self, state):
+        self.state = state
+        self.author_did = None
+        self.revoc_reg_def_id = None
+        self.req_id = None
+
+    def set_parameters_from_txn(self, author_did, revoc_reg_def_id, req_id):
+        self.author_did = author_did
+        self.revoc_reg_def_id = revoc_reg_def_id
+        self.req_id = req_id
+
+    def set_strategy(self, strategy):
+        self.strategy = strategy
+
+    def set_to_state(self, txn):
+        assert self.strategy
+        self.strategy.write(txn)
+
+    def validate_txn(self, current_entry, req: Request):
+        self.set_parameters_from_txn(author_did=req.identifier,
+                                     revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
+                                     req_id=req.reqId)
+        # General checks for all Revocation entries
+        operation = req.operation
+        value_from_txn = operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED)
+        revoked_from_txn = value_from_txn.get(REVOKED)
+        intersection = set(issued_from_txn).intersection(set(revoked_from_txn))
+        if len(intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Indices {} are existed in issued and revoked list"".format(intersection))
+        if current_entry is None:
+            return None
+        value_from_state = current_entry.get(VALUE)
+        assert value_from_state
+        current_accum = value_from_state.get(ACCUM)
+        if current_accum != value_from_txn.get(PREV_ACCUM):
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Accum value from state: {} ""
+                                       ""do not equal with {} value ""
+                                       ""from txn: {}"".format(current_accum,
+                                                             PREV_ACCUM,
+                                                             value_from_state.get(PREV_ACCUM)))
+
+        # Strategy specific validation
+        self.strategy.validate(current_entry, req)
+
+    def write(self, current_reg_entry, txn):",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171179673,https://github.com/hyperledger/indy-node/pull/576#discussion_r171179673,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,better to say: are not present in the current ....,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:13:41,171180632,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:
+
+    def __init__(self, state):
+        self.state = state
+        self.author_did = None
+        self.revoc_reg_def_id = None
+        self.req_id = None
+
+    def set_parameters_from_txn(self, author_did, revoc_reg_def_id, req_id):
+        self.author_did = author_did
+        self.revoc_reg_def_id = revoc_reg_def_id
+        self.req_id = req_id
+
+    def set_strategy(self, strategy):
+        self.strategy = strategy
+
+    def set_to_state(self, txn):
+        assert self.strategy
+        self.strategy.write(txn)
+
+    def validate_txn(self, current_entry, req: Request):
+        self.set_parameters_from_txn(author_did=req.identifier,
+                                     revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
+                                     req_id=req.reqId)
+        # General checks for all Revocation entries
+        operation = req.operation
+        value_from_txn = operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED)
+        revoked_from_txn = value_from_txn.get(REVOKED)
+        intersection = set(issued_from_txn).intersection(set(revoked_from_txn))
+        if len(intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Indices {} are existed in issued and revoked list"".format(intersection))
+        if current_entry is None:
+            return None
+        value_from_state = current_entry.get(VALUE)
+        assert value_from_state
+        current_accum = value_from_state.get(ACCUM)
+        if current_accum != value_from_txn.get(PREV_ACCUM):
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Accum value from state: {} ""
+                                       ""do not equal with {} value ""
+                                       ""from txn: {}"".format(current_accum,
+                                                             PREV_ACCUM,
+                                                             value_from_state.get(PREV_ACCUM)))
+
+        # Strategy specific validation
+        self.strategy.validate(current_entry, req)
+
+    def write(self, current_reg_entry, txn):
+        raise NotImplementedError()
+
+
+class RevokedStrategy(RevocationStrategy):
+    # This strategy save in state only revoked indices
+
+    def __init__(self, state):
+        super().__init__(state)
+
+    def validate(self, current_reg_entry, req: Request):
+        value_from_state = current_reg_entry.get(VALUE)
+        assert value_from_state
+        indices = value_from_state.get(REVOKED, [])
+        value_from_txn = req.operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED, [])
+        revoked_from_txn = value_from_txn.get(REVOKED, [])
+        issued_difference = set(issued_from_txn).difference(indices)
+        if len(issued_difference) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Issued indices from txn: {} ""
+                                       ""does not exist in current """,,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171180632,https://github.com/hyperledger/indy-node/pull/576#discussion_r171180632,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,better to say: are not present in the current ....,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:18:55,171181870,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:
+
+    def __init__(self, state):
+        self.state = state
+        self.author_did = None
+        self.revoc_reg_def_id = None
+        self.req_id = None
+
+    def set_parameters_from_txn(self, author_did, revoc_reg_def_id, req_id):
+        self.author_did = author_did
+        self.revoc_reg_def_id = revoc_reg_def_id
+        self.req_id = req_id
+
+    def set_strategy(self, strategy):
+        self.strategy = strategy
+
+    def set_to_state(self, txn):
+        assert self.strategy
+        self.strategy.write(txn)
+
+    def validate_txn(self, current_entry, req: Request):
+        self.set_parameters_from_txn(author_did=req.identifier,
+                                     revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
+                                     req_id=req.reqId)
+        # General checks for all Revocation entries
+        operation = req.operation
+        value_from_txn = operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED)
+        revoked_from_txn = value_from_txn.get(REVOKED)
+        intersection = set(issued_from_txn).intersection(set(revoked_from_txn))
+        if len(intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Indices {} are existed in issued and revoked list"".format(intersection))
+        if current_entry is None:
+            return None
+        value_from_state = current_entry.get(VALUE)
+        assert value_from_state
+        current_accum = value_from_state.get(ACCUM)
+        if current_accum != value_from_txn.get(PREV_ACCUM):
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Accum value from state: {} ""
+                                       ""do not equal with {} value ""
+                                       ""from txn: {}"".format(current_accum,
+                                                             PREV_ACCUM,
+                                                             value_from_state.get(PREV_ACCUM)))
+
+        # Strategy specific validation
+        self.strategy.validate(current_entry, req)
+
+    def write(self, current_reg_entry, txn):
+        raise NotImplementedError()
+
+
+class RevokedStrategy(RevocationStrategy):
+    # This strategy save in state only revoked indices
+
+    def __init__(self, state):
+        super().__init__(state)
+
+    def validate(self, current_reg_entry, req: Request):
+        value_from_state = current_reg_entry.get(VALUE)
+        assert value_from_state
+        indices = value_from_state.get(REVOKED, [])
+        value_from_txn = req.operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED, [])
+        revoked_from_txn = value_from_txn.get(REVOKED, [])
+        issued_difference = set(issued_from_txn).difference(indices)
+        if len(issued_difference) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Issued indices from txn: {} ""
+                                       ""does not exist in current ""
+                                       ""revoked list from state: {}"".format(issued_difference,
+                                                                            indices))
+        revoked_intersection = set(indices).intersection(revoked_from_txn)
+        if len(revoked_intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Revoked indices from txn: {} ""
+                                       ""already revoked ""
+                                       ""in current state: {}"".format(revoked_intersection,
+                                                                     indices))
+
+    def write(self, current_reg_entry, txn):
+        self.set_parameters_from_txn(author_did=txn.get(f.IDENTIFIER.nm),
+                                     revoc_reg_def_id=txn.get(REVOC_REG_DEF_ID),
+                                     req_id=txn.get(f.REQ_ID.nm))
+        if current_reg_entry is not None:
+            value_from_state = current_reg_entry.get(VALUE)
+            assert value_from_state
+            indices = value_from_state.get(REVOKED, [])
+            value_from_txn = txn.get(VALUE)
+            issued_from_txn = value_from_txn.get(ISSUED, [])
+            revoked_from_txn = value_from_txn.get(REVOKED, [])
+            # set with all previous revoked minus issued from txn
+            result_indicies = set(indices).difference(issued_from_txn)
+            result_indicies.update(revoked_from_txn)
+            value_from_txn[ISSUED] = []
+            value_from_txn[REVOKED] = list(result_indicies)
+            txn[VALUE] = value_from_txn
+        # contains already changed txn
+        path, value_bytes = domain.prepare_revoc_reg_entry_for_state(txn)
+        self.state.set(path, value_bytes)
+
+
+class IssuedStrategy(RevocationStrategy):
+    # This strategy saves in state only issued indices
+
+    def __init__(self, state):
+        super().__init__(state)
+
+    def validate(self, current_reg_entry, req: Request):
+        value_from_state = current_reg_entry.get(VALUE)
+        assert value_from_state
+        indices = value_from_state.get(ISSUED, [])
+        value_from_txn = req.operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED, [])
+        revoked_from_txn = value_from_txn.get(REVOKED, [])
+        revoked_difference = set(revoked_from_txn).difference(indices)
+        if len(revoked_difference) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Revoked indices from txn: {} ""
+                                       ""does not exist in current """,,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171181870,https://github.com/hyperledger/indy-node/pull/576#discussion_r171181870,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,are already...,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:19:24,171181992,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:
+
+    def __init__(self, state):
+        self.state = state
+        self.author_did = None
+        self.revoc_reg_def_id = None
+        self.req_id = None
+
+    def set_parameters_from_txn(self, author_did, revoc_reg_def_id, req_id):
+        self.author_did = author_did
+        self.revoc_reg_def_id = revoc_reg_def_id
+        self.req_id = req_id
+
+    def set_strategy(self, strategy):
+        self.strategy = strategy
+
+    def set_to_state(self, txn):
+        assert self.strategy
+        self.strategy.write(txn)
+
+    def validate_txn(self, current_entry, req: Request):
+        self.set_parameters_from_txn(author_did=req.identifier,
+                                     revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
+                                     req_id=req.reqId)
+        # General checks for all Revocation entries
+        operation = req.operation
+        value_from_txn = operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED)
+        revoked_from_txn = value_from_txn.get(REVOKED)
+        intersection = set(issued_from_txn).intersection(set(revoked_from_txn))
+        if len(intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Indices {} are existed in issued and revoked list"".format(intersection))
+        if current_entry is None:
+            return None
+        value_from_state = current_entry.get(VALUE)
+        assert value_from_state
+        current_accum = value_from_state.get(ACCUM)
+        if current_accum != value_from_txn.get(PREV_ACCUM):
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Accum value from state: {} ""
+                                       ""do not equal with {} value ""
+                                       ""from txn: {}"".format(current_accum,
+                                                             PREV_ACCUM,
+                                                             value_from_state.get(PREV_ACCUM)))
+
+        # Strategy specific validation
+        self.strategy.validate(current_entry, req)
+
+    def write(self, current_reg_entry, txn):
+        raise NotImplementedError()
+
+
+class RevokedStrategy(RevocationStrategy):
+    # This strategy save in state only revoked indices
+
+    def __init__(self, state):
+        super().__init__(state)
+
+    def validate(self, current_reg_entry, req: Request):
+        value_from_state = current_reg_entry.get(VALUE)
+        assert value_from_state
+        indices = value_from_state.get(REVOKED, [])
+        value_from_txn = req.operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED, [])
+        revoked_from_txn = value_from_txn.get(REVOKED, [])
+        issued_difference = set(issued_from_txn).difference(indices)
+        if len(issued_difference) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Issued indices from txn: {} ""
+                                       ""does not exist in current ""
+                                       ""revoked list from state: {}"".format(issued_difference,
+                                                                            indices))
+        revoked_intersection = set(indices).intersection(revoked_from_txn)
+        if len(revoked_intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Revoked indices from txn: {} ""
+                                       ""already revoked ""
+                                       ""in current state: {}"".format(revoked_intersection,
+                                                                     indices))
+
+    def write(self, current_reg_entry, txn):
+        self.set_parameters_from_txn(author_did=txn.get(f.IDENTIFIER.nm),
+                                     revoc_reg_def_id=txn.get(REVOC_REG_DEF_ID),
+                                     req_id=txn.get(f.REQ_ID.nm))
+        if current_reg_entry is not None:
+            value_from_state = current_reg_entry.get(VALUE)
+            assert value_from_state
+            indices = value_from_state.get(REVOKED, [])
+            value_from_txn = txn.get(VALUE)
+            issued_from_txn = value_from_txn.get(ISSUED, [])
+            revoked_from_txn = value_from_txn.get(REVOKED, [])
+            # set with all previous revoked minus issued from txn
+            result_indicies = set(indices).difference(issued_from_txn)
+            result_indicies.update(revoked_from_txn)
+            value_from_txn[ISSUED] = []
+            value_from_txn[REVOKED] = list(result_indicies)
+            txn[VALUE] = value_from_txn
+        # contains already changed txn
+        path, value_bytes = domain.prepare_revoc_reg_entry_for_state(txn)
+        self.state.set(path, value_bytes)
+
+
+class IssuedStrategy(RevocationStrategy):
+    # This strategy saves in state only issued indices
+
+    def __init__(self, state):
+        super().__init__(state)
+
+    def validate(self, current_reg_entry, req: Request):
+        value_from_state = current_reg_entry.get(VALUE)
+        assert value_from_state
+        indices = value_from_state.get(ISSUED, [])
+        value_from_txn = req.operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED, [])
+        revoked_from_txn = value_from_txn.get(REVOKED, [])
+        revoked_difference = set(revoked_from_txn).difference(indices)
+        if len(revoked_difference) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Revoked indices from txn: {} ""
+                                       ""does not exist in current ""
+                                       ""issued list from state: {}"".format(revoked_difference,
+                                                                           indices))
+        issued_intersection = set(indices).intersection(issued_from_txn)
+        if len(issued_intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Issued indices from txn: {} ""
+                                       ""already issued """,,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171181992,https://github.com/hyperledger/indy-node/pull/576#discussion_r171181992,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,Shouldn't we use ISSUED value here?,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:20:06,171182160,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:
+
+    def __init__(self, state):
+        self.state = state
+        self.author_did = None
+        self.revoc_reg_def_id = None
+        self.req_id = None
+
+    def set_parameters_from_txn(self, author_did, revoc_reg_def_id, req_id):
+        self.author_did = author_did
+        self.revoc_reg_def_id = revoc_reg_def_id
+        self.req_id = req_id
+
+    def set_strategy(self, strategy):
+        self.strategy = strategy
+
+    def set_to_state(self, txn):
+        assert self.strategy
+        self.strategy.write(txn)
+
+    def validate_txn(self, current_entry, req: Request):
+        self.set_parameters_from_txn(author_did=req.identifier,
+                                     revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
+                                     req_id=req.reqId)
+        # General checks for all Revocation entries
+        operation = req.operation
+        value_from_txn = operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED)
+        revoked_from_txn = value_from_txn.get(REVOKED)
+        intersection = set(issued_from_txn).intersection(set(revoked_from_txn))
+        if len(intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Indices {} are existed in issued and revoked list"".format(intersection))
+        if current_entry is None:
+            return None
+        value_from_state = current_entry.get(VALUE)
+        assert value_from_state
+        current_accum = value_from_state.get(ACCUM)
+        if current_accum != value_from_txn.get(PREV_ACCUM):
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Accum value from state: {} ""
+                                       ""do not equal with {} value ""
+                                       ""from txn: {}"".format(current_accum,
+                                                             PREV_ACCUM,
+                                                             value_from_state.get(PREV_ACCUM)))
+
+        # Strategy specific validation
+        self.strategy.validate(current_entry, req)
+
+    def write(self, current_reg_entry, txn):
+        raise NotImplementedError()
+
+
+class RevokedStrategy(RevocationStrategy):
+    # This strategy save in state only revoked indices
+
+    def __init__(self, state):
+        super().__init__(state)
+
+    def validate(self, current_reg_entry, req: Request):
+        value_from_state = current_reg_entry.get(VALUE)
+        assert value_from_state
+        indices = value_from_state.get(REVOKED, [])
+        value_from_txn = req.operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED, [])
+        revoked_from_txn = value_from_txn.get(REVOKED, [])
+        issued_difference = set(issued_from_txn).difference(indices)
+        if len(issued_difference) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Issued indices from txn: {} ""
+                                       ""does not exist in current ""
+                                       ""revoked list from state: {}"".format(issued_difference,
+                                                                            indices))
+        revoked_intersection = set(indices).intersection(revoked_from_txn)
+        if len(revoked_intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Revoked indices from txn: {} ""
+                                       ""already revoked ""
+                                       ""in current state: {}"".format(revoked_intersection,
+                                                                     indices))
+
+    def write(self, current_reg_entry, txn):
+        self.set_parameters_from_txn(author_did=txn.get(f.IDENTIFIER.nm),
+                                     revoc_reg_def_id=txn.get(REVOC_REG_DEF_ID),
+                                     req_id=txn.get(f.REQ_ID.nm))
+        if current_reg_entry is not None:
+            value_from_state = current_reg_entry.get(VALUE)
+            assert value_from_state
+            indices = value_from_state.get(REVOKED, [])
+            value_from_txn = txn.get(VALUE)
+            issued_from_txn = value_from_txn.get(ISSUED, [])
+            revoked_from_txn = value_from_txn.get(REVOKED, [])
+            # set with all previous revoked minus issued from txn
+            result_indicies = set(indices).difference(issued_from_txn)
+            result_indicies.update(revoked_from_txn)
+            value_from_txn[ISSUED] = []
+            value_from_txn[REVOKED] = list(result_indicies)
+            txn[VALUE] = value_from_txn
+        # contains already changed txn
+        path, value_bytes = domain.prepare_revoc_reg_entry_for_state(txn)
+        self.state.set(path, value_bytes)
+
+
+class IssuedStrategy(RevocationStrategy):
+    # This strategy saves in state only issued indices
+
+    def __init__(self, state):
+        super().__init__(state)
+
+    def validate(self, current_reg_entry, req: Request):
+        value_from_state = current_reg_entry.get(VALUE)
+        assert value_from_state
+        indices = value_from_state.get(ISSUED, [])
+        value_from_txn = req.operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED, [])
+        revoked_from_txn = value_from_txn.get(REVOKED, [])
+        revoked_difference = set(revoked_from_txn).difference(indices)
+        if len(revoked_difference) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Revoked indices from txn: {} ""
+                                       ""does not exist in current ""
+                                       ""issued list from state: {}"".format(revoked_difference,
+                                                                           indices))
+        issued_intersection = set(indices).intersection(issued_from_txn)
+        if len(issued_intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Issued indices from txn: {} ""
+                                       ""already issued ""
+                                       ""in current state: {}"".format(issued_intersection,
+                                                                     indices))
+
+    def write(self, current_reg_entry, txn):
+        self.set_parameters_from_txn(author_did=txn.get(f.IDENTIFIER.nm),
+                                     revoc_reg_def_id=txn.get(REVOC_REG_DEF_ID),
+                                     req_id=txn.get(f.REQ_ID.nm))
+        if current_reg_entry is not None:
+            value_from_state = current_reg_entry.get(VALUE)
+            assert value_from_state
+            indices = value_from_state.get(ISSUED, [])
+            value_from_txn = txn.get(VALUE)
+            issued_from_txn = value_from_txn.get(ISSUED, [])
+            revoked_from_txn = value_from_txn.get(REVOKED, [])
+            # set with all previous issued minus revoked from txn
+            result_indicies = set(indices).difference(revoked_from_txn)
+            result_indicies.update(issued_from_txn)
+            value_from_txn[ISSUED] = []",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171182160,https://github.com/hyperledger/indy-node/pull/576#discussion_r171182160,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,"Please use constants for ""ISSUANCE_BY_DEFAULT"" and ""ISSUANCE_ON_DEMAND""",62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:20:33,171182266,"@@ -22,9 +23,172 @@
 logger = getlogger()
 
 
+class RevocationStrategy:
+
+    def __init__(self, state):
+        self.state = state
+        self.author_did = None
+        self.revoc_reg_def_id = None
+        self.req_id = None
+
+    def set_parameters_from_txn(self, author_did, revoc_reg_def_id, req_id):
+        self.author_did = author_did
+        self.revoc_reg_def_id = revoc_reg_def_id
+        self.req_id = req_id
+
+    def set_strategy(self, strategy):
+        self.strategy = strategy
+
+    def set_to_state(self, txn):
+        assert self.strategy
+        self.strategy.write(txn)
+
+    def validate_txn(self, current_entry, req: Request):
+        self.set_parameters_from_txn(author_did=req.identifier,
+                                     revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
+                                     req_id=req.reqId)
+        # General checks for all Revocation entries
+        operation = req.operation
+        value_from_txn = operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED)
+        revoked_from_txn = value_from_txn.get(REVOKED)
+        intersection = set(issued_from_txn).intersection(set(revoked_from_txn))
+        if len(intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Indices {} are existed in issued and revoked list"".format(intersection))
+        if current_entry is None:
+            return None
+        value_from_state = current_entry.get(VALUE)
+        assert value_from_state
+        current_accum = value_from_state.get(ACCUM)
+        if current_accum != value_from_txn.get(PREV_ACCUM):
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Accum value from state: {} ""
+                                       ""do not equal with {} value ""
+                                       ""from txn: {}"".format(current_accum,
+                                                             PREV_ACCUM,
+                                                             value_from_state.get(PREV_ACCUM)))
+
+        # Strategy specific validation
+        self.strategy.validate(current_entry, req)
+
+    def write(self, current_reg_entry, txn):
+        raise NotImplementedError()
+
+
+class RevokedStrategy(RevocationStrategy):
+    # This strategy save in state only revoked indices
+
+    def __init__(self, state):
+        super().__init__(state)
+
+    def validate(self, current_reg_entry, req: Request):
+        value_from_state = current_reg_entry.get(VALUE)
+        assert value_from_state
+        indices = value_from_state.get(REVOKED, [])
+        value_from_txn = req.operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED, [])
+        revoked_from_txn = value_from_txn.get(REVOKED, [])
+        issued_difference = set(issued_from_txn).difference(indices)
+        if len(issued_difference) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Issued indices from txn: {} ""
+                                       ""does not exist in current ""
+                                       ""revoked list from state: {}"".format(issued_difference,
+                                                                            indices))
+        revoked_intersection = set(indices).intersection(revoked_from_txn)
+        if len(revoked_intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Revoked indices from txn: {} ""
+                                       ""already revoked ""
+                                       ""in current state: {}"".format(revoked_intersection,
+                                                                     indices))
+
+    def write(self, current_reg_entry, txn):
+        self.set_parameters_from_txn(author_did=txn.get(f.IDENTIFIER.nm),
+                                     revoc_reg_def_id=txn.get(REVOC_REG_DEF_ID),
+                                     req_id=txn.get(f.REQ_ID.nm))
+        if current_reg_entry is not None:
+            value_from_state = current_reg_entry.get(VALUE)
+            assert value_from_state
+            indices = value_from_state.get(REVOKED, [])
+            value_from_txn = txn.get(VALUE)
+            issued_from_txn = value_from_txn.get(ISSUED, [])
+            revoked_from_txn = value_from_txn.get(REVOKED, [])
+            # set with all previous revoked minus issued from txn
+            result_indicies = set(indices).difference(issued_from_txn)
+            result_indicies.update(revoked_from_txn)
+            value_from_txn[ISSUED] = []
+            value_from_txn[REVOKED] = list(result_indicies)
+            txn[VALUE] = value_from_txn
+        # contains already changed txn
+        path, value_bytes = domain.prepare_revoc_reg_entry_for_state(txn)
+        self.state.set(path, value_bytes)
+
+
+class IssuedStrategy(RevocationStrategy):
+    # This strategy saves in state only issued indices
+
+    def __init__(self, state):
+        super().__init__(state)
+
+    def validate(self, current_reg_entry, req: Request):
+        value_from_state = current_reg_entry.get(VALUE)
+        assert value_from_state
+        indices = value_from_state.get(ISSUED, [])
+        value_from_txn = req.operation.get(VALUE)
+        issued_from_txn = value_from_txn.get(ISSUED, [])
+        revoked_from_txn = value_from_txn.get(REVOKED, [])
+        revoked_difference = set(revoked_from_txn).difference(indices)
+        if len(revoked_difference) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Revoked indices from txn: {} ""
+                                       ""does not exist in current ""
+                                       ""issued list from state: {}"".format(revoked_difference,
+                                                                           indices))
+        issued_intersection = set(indices).intersection(issued_from_txn)
+        if len(issued_intersection) > 0:
+            raise InvalidClientRequest(self.author_did,
+                                       self.req_id,
+                                       ""Issued indices from txn: {} ""
+                                       ""already issued ""
+                                       ""in current state: {}"".format(issued_intersection,
+                                                                     indices))
+
+    def write(self, current_reg_entry, txn):
+        self.set_parameters_from_txn(author_did=txn.get(f.IDENTIFIER.nm),
+                                     revoc_reg_def_id=txn.get(REVOC_REG_DEF_ID),
+                                     req_id=txn.get(f.REQ_ID.nm))
+        if current_reg_entry is not None:
+            value_from_state = current_reg_entry.get(VALUE)
+            assert value_from_state
+            indices = value_from_state.get(ISSUED, [])
+            value_from_txn = txn.get(VALUE)
+            issued_from_txn = value_from_txn.get(ISSUED, [])
+            revoked_from_txn = value_from_txn.get(REVOKED, [])
+            # set with all previous issued minus revoked from txn
+            result_indicies = set(indices).difference(revoked_from_txn)
+            result_indicies.update(issued_from_txn)
+            value_from_txn[ISSUED] = []
+            value_from_txn[REVOKED] = list(result_indicies)
+            txn[VALUE] = value_from_txn
+        # contains already changed txn
+        path, value_bytes = domain.prepare_revoc_reg_entry_for_state(txn)
+        self.state.set(path, value_bytes)
+
+
 class DomainReqHandler(PHandler):
-    write_types = {NYM, ATTRIB, SCHEMA, CLAIM_DEF, REVOC_REG_DEF}
+    write_types = {NYM, ATTRIB, SCHEMA, CLAIM_DEF, REVOC_REG_DEF, REVOC_REG_ENTRY}
     query_types = {GET_NYM, GET_ATTR, GET_SCHEMA, GET_CLAIM_DEF}
+    revocation_strategy_map = {
+        ""ISSUANCE_BY_DEFAULT"": RevokedStrategy,",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171182266,https://github.com/hyperledger/indy-node/pull/576#discussion_r171182266,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,"Since we call this method as part of dynamic validation (that is for new txns added to uncommitted list), we must get the uncommitted values to take into account all txns in the batch ",62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:23:04,171182925,"@@ -252,6 +423,32 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
 
+    def get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, req_id):
+        assert author_did
+        assert revoc_reg_def_id
+        # TODO Need to be ""isCommited""==True?",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171182925,https://github.com/hyperledger/indy-node/pull/576#discussion_r171182925,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,The same as above,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:23:55,171183142,"@@ -252,6 +423,32 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
 
+    def get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, req_id):
+        assert author_did
+        assert revoc_reg_def_id
+        # TODO Need to be ""isCommited""==True?
+        current_entry, _, _, _ = self.getRevocDefEntry(author_did=author_did,
+                                                       revoc_reg_def_id=revoc_reg_def_id,
+                                                       isCommitted=False)
+        # TODO Need to be ""isCommited""==True ?",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171183142,https://github.com/hyperledger/indy-node/pull/576#discussion_r171183142,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,Should it be a private method? (with _ prefix),62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:24:43,171183356,"@@ -252,6 +423,32 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
 
+    def get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, req_id):",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171183356,https://github.com/hyperledger/indy-node/pull/576#discussion_r171183356,ashcherbakov
https://github.com/hyperledger/indy-node/pull/576,https://github.com/hyperledger/indy-node/pull/576,Ugly line! See comment about inheritance.,62d7622fdebc95f3093c25b84f607de95d6c78fd,2018-02-28 09:25:16,171183496,"@@ -252,6 +423,32 @@ def _validate_revoc_reg_def(self, req: Request):
         assert revoc_def_tag
         assert revoc_def_type
 
+    def get_current_revoc_entry_and_revoc_def(self, author_did, revoc_reg_def_id, req_id):
+        assert author_did
+        assert revoc_reg_def_id
+        # TODO Need to be ""isCommited""==True?
+        current_entry, _, _, _ = self.getRevocDefEntry(author_did=author_did,
+                                                       revoc_reg_def_id=revoc_reg_def_id,
+                                                       isCommitted=False)
+        # TODO Need to be ""isCommited""==True ?
+        revoc_def, _, _, _ = self.lookup(revoc_reg_def_id, isCommitted=False)
+        if revoc_def is None:
+            raise InvalidClientRequest(author_did,
+                                       req_id,
+                                       ""There is no any REVOC_REG_DEF by path: {}"".format(revoc_reg_def_id))
+        return current_entry, revoc_def
+
+    def _validate_revoc_reg_entry(self, req: Request):
+        current_entry, revoc_def = self.get_current_revoc_entry_and_revoc_def(
+            author_did=req.identifier,
+            revoc_reg_def_id=req.operation[REVOC_REG_DEF_ID],
+            req_id=req.reqId
+        )
+        validator_cls = self.get_revocation_strategy(revoc_def[VALUE][ISSUANCE_TYPE])
+        validator = validator_cls(self.state)
+        validator.set_strategy(validator)",,2018-02-28 10:33:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171183496,https://github.com/hyperledger/indy-node/pull/576#discussion_r171183496,ashcherbakov
https://github.com/hyperledger/indy-node/pull/567,https://github.com/hyperledger/indy-node/pull/567,"It doesn't match the design.
For now it would be sufficient to have the following fields:
- type
- tag
- credDefId
- value
where `value` is `type`-specific, and for `CL` type has the following fields:
   - issuanceType
   - maxCredNum
   - publicKeys
   - tailsHash
   - tailsLocation",375c50e68f1980d2eec1c353383ac503ea0e0170,2018-02-16 16:02:58,168797193,"@@ -101,7 +102,8 @@
           SCHEMA: ([NAME, VERSION, ATTR_NAMES]),
           GET_SCHEMA: ([], []),
           CLAIM_DEF: ([REF, DATA, SIGNATURE_TYPE]),
-          GET_CLAIM_DEF: ([REF, ORIGIN, SIGNATURE_TYPE])
+          GET_CLAIM_DEF: ([REF, ORIGIN, SIGNATURE_TYPE]),
+          REVOC_REG_DEF: ([REF, DATA, REQ_METADATA, SIGNATURE_TYPE])",,2018-02-21 08:15:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/168797193,https://github.com/hyperledger/indy-node/pull/567#discussion_r168797193,ashcherbakov
https://github.com/hyperledger/indy-node/pull/567,https://github.com/hyperledger/indy-node/pull/567,Please add a test for this,375c50e68f1980d2eec1c353383ac503ea0e0170,2018-02-19 08:32:21,169009630,"@@ -83,6 +86,26 @@ class ClaimDefField(MessageValidator):
     )
 
 
+class RevocDefValueField(MessageValidator):",34,2018-02-21 08:15:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/169009630,https://github.com/hyperledger/indy-node/pull/567#discussion_r169009630,ashcherbakov
https://github.com/hyperledger/indy-node/pull/567,https://github.com/hyperledger/indy-node/pull/567,Please add a test for this,375c50e68f1980d2eec1c353383ac503ea0e0170,2018-02-19 08:32:27,169009652,"@@ -83,6 +86,26 @@ class ClaimDefField(MessageValidator):
     )
 
 
+class RevocDefValueField(MessageValidator):
+    schema = (
+        (ISSUANCE_TYPE, NonEmptyStringField()),
+        (MAX_CRED_NUM, IntegerField()),
+        (PUBLIC_KEYS, AnyMapField()),
+        (TAILS_HASH, NonEmptyStringField()),
+        (TAILS_LOCATION, NonEmptyStringField()),
+    )
+
+
+class ClientRevocDefSubmitField(MessageValidator):",44,2018-02-21 08:15:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/169009652,https://github.com/hyperledger/indy-node/pull/567#discussion_r169009652,ashcherbakov
https://github.com/hyperledger/indy-node/pull/567,https://github.com/hyperledger/indy-node/pull/567,Do we need this check?,375c50e68f1980d2eec1c353383ac503ea0e0170,2018-02-19 08:33:49,169009921,"@@ -237,6 +242,24 @@ def _validate_claim_def(self, req: Request):
                                        'and schema ref {} and signature type {}'
                                        .format(identifier, schema_ref, signature_type))
 
+    def _validate_revoc_reg_def(self, req: Request):
+        # TODO Need to check that CRED_DEF for this REVOC_DEF exist
+        author_did = req.identifier
+        operation = req.operation
+
+        cred_def_id = operation.get(""id"")
+        revoc_def_type = operation.get(""type"")
+        revoc_def_tag = operation.get(""tag"")
+        revoc_def, _, _, _ = self.getRevocDef(",,2018-02-21 08:15:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/169009921,https://github.com/hyperledger/indy-node/pull/567#discussion_r169009921,ashcherbakov
https://github.com/hyperledger/indy-node/pull/563,https://github.com/hyperledger/indy-node/pull/563,This is Indy repository. It should have no Sovrin dependencies.,15526d575b399c6aff0bd9d3a3d36ea9265d4ccc,2018-02-12 08:03:58,167484211,"@@ -1393,7 +1393,7 @@
                     {
                       ""Ref"": ""Validator01OperatingSystem""
                     },
-                    ""indy""
+                    ""sovrin""",,2018-02-13 14:11:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/167484211,https://github.com/hyperledger/indy-node/pull/563#discussion_r167484211,ashcherbakov
https://github.com/hyperledger/indy-node/pull/563,https://github.com/hyperledger/indy-node/pull/563,"@ashcherbakov - This is just a key/name used to lookup a value in the RepositoryKeys hash here using Fn::FindInMap:

https://github.com/hyperledger/indy-node/blob/master/environment/cloudformation/training/IndyCluster.json#L5067

When you say this CloudFormation should not have Sovrin dependencies, are you referring to this repo URI?

https://github.com/hyperledger/indy-node/blob/master/environment/cloudformation/training/IndyCluster.json#L5078-L5079

A more detailed explanation is as follows:
The ""68DB5E88"" is appended to the following apt-key command when Fn::FindInMap is called on the RepositoryKeys map with the name of the operating system and the name of the repo:
`                ""apt-key adv --keyserver keyserver.ubuntu.com --recv-keys "",
                {
                  ""Fn::FindInMap"": [
                    ""RepositoryKeys"",
                    {
                      ""Ref"": ""Validator01OperatingSystem""
                    },
                    ""indy""
                  ]
                },
                ""\n"",
`
The following add-apt-repository command adds debian repo ""https://repo.sovrin.org/deb xenial"" based on operating system and branch/codebase

`
                ""add-apt-repository \"""",
                {
                  ""Fn::FindInMap"": [
                    ""RepositoryEvernym"",
                    {
                      ""Ref"": ""Validator01OperatingSystem""
                    },
                    {
                      ""Ref"": ""CodeBase""
                    }
                  ]
                },`",15526d575b399c6aff0bd9d3a3d36ea9265d4ccc,2018-02-12 16:19:35,167606526,"@@ -1393,7 +1393,7 @@
                     {
                       ""Ref"": ""Validator01OperatingSystem""
                     },
-                    ""indy""
+                    ""sovrin""",,2018-02-13 14:11:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/167606526,https://github.com/hyperledger/indy-node/pull/563#discussion_r167606526,ckochenower
https://github.com/hyperledger/indy-node/pull/563,https://github.com/hyperledger/indy-node/pull/563,"It must install `indy-node`, not `sovrin`. `indy-node` contains all necessary dependencies and scripts.",15526d575b399c6aff0bd9d3a3d36ea9265d4ccc,2018-02-13 08:55:20,167795028,"@@ -1425,10 +1425,14 @@
                 ""\""\n"",
                 ""apt-get update\n"",
                 ""DEBIAN_FRONTEND=noninteractive apt-get install -y debsigs debsig-verify apt-transport-https\n"",
-                ""DEBIAN_FRONTEND=noninteractive apt-get install -y dialog figlet python-pip python3-pip python3.5-dev libsodium18 unzip make screen indy-node tmux vim wget\n"",
+                ""DEBIAN_FRONTEND=noninteractive apt-get install -y dialog figlet python-pip python3-pip python3.5-dev unzip make screen sovrin tmux vim wget\n"",",,2018-02-13 14:11:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/167795028,https://github.com/hyperledger/indy-node/pull/563#discussion_r167795028,ashcherbakov
https://github.com/hyperledger/indy-node/pull/548,https://github.com/hyperledger/indy-node/pull/548,"Can't we just remove 
```
    if attr_type == ENC:
        return hash_of(attr), attr
```
from `parse_attr_txn`?",8b165cc9a632241f60776654f487aba07e0d7183,2018-02-02 13:53:06,165649350,"@@ -75,13 +75,17 @@ def prepare_attr_for_state(txn):
     """"""
     assert txn[TXN_TYPE] in {ATTRIB, GET_ATTR}
     nym = txn[TARGET_NYM]
-    attr_key, value = parse_attr_txn(txn)
-    hashed_value = hash_of(value) if value else ''
+    attr_type, attr_key, value = parse_attr_txn(txn)
+    if attr_type == ENC:",,2018-02-02 14:04:47,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165649350,https://github.com/hyperledger/indy-node/pull/548#discussion_r165649350,ashcherbakov
https://github.com/hyperledger/indy-node/pull/548,https://github.com/hyperledger/indy-node/pull/548,"Agreed, done.",8b165cc9a632241f60776654f487aba07e0d7183,2018-02-02 14:03:56,165652043,"@@ -75,13 +75,17 @@ def prepare_attr_for_state(txn):
     """"""
     assert txn[TXN_TYPE] in {ATTRIB, GET_ATTR}
     nym = txn[TARGET_NYM]
-    attr_key, value = parse_attr_txn(txn)
-    hashed_value = hash_of(value) if value else ''
+    attr_type, attr_key, value = parse_attr_txn(txn)
+    if attr_type == ENC:",,2018-02-02 14:04:47,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165652043,https://github.com/hyperledger/indy-node/pull/548#discussion_r165652043,sergey-shilov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,`Anoncreds Link` to `Anoncreds References`,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 20:30:00,165478765,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165478765,https://github.com/hyperledger/indy-node/pull/547#discussion_r165478765,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"We should use the word ""Schema author"" rather than `Schema Issuer`, since the author of the schema is not issuing the credential, it is the author of the credential definition that issues credential.",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 20:40:55,165481195,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165481195,https://github.com/hyperledger/indy-node/pull/547#discussion_r165481195,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,missing `by` between `existing schema` and  `adding`,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 20:42:27,165481548,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165481548,https://github.com/hyperledger/indy-node/pull/547#discussion_r165481548,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"Are we decoupling issuer and revocation authority, where the issuer while issuing/revoking a claim communicates to the revocation authority?",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 21:18:43,165490423,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. ",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165490423,https://github.com/hyperledger/indy-node/pull/547#discussion_r165490423,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,There can be `issuanceTime` or there always is `issuanceTime`?,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 21:18:47,165490438,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165490438,https://github.com/hyperledger/indy-node/pull/547#discussion_r165490438,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,Is `issuanceTime` the exact time or there some `>` or `<` or both condition(s)? So get a CRED_DEF published after/before/between this time?,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 21:18:50,165490449,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165490449,https://github.com/hyperledger/indy-node/pull/547#discussion_r165490449,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,Does `modified/changed/evolved` lead to a schema with different UUID? The what ties all modifications of a schema?,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 21:34:01,165494429,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165494429,https://github.com/hyperledger/indy-node/pull/547#discussion_r165494429,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"Rather than using the process which engages multiple nodes for each claim issuance, cant the prover just reject the credential when he receives it if `issuanceTime` is not acceptable. Or cant the issuer just embed Sovrin's latest BLS signed state since that contains timestamp too. The issuer can get the BLS signed state from observers/validators/some third party. Thus the Validators don't need to do more work and less development effort too. The downside is that each credential becomes bigger than it needs to be  (not much though)",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 21:56:24,165500224,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.",474,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165500224,https://github.com/hyperledger/indy-node/pull/547#discussion_r165500224,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,`Verifier should use Predicates` to `Prover should use Predicates`,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 21:56:44,165500316,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`",482,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165500316,https://github.com/hyperledger/indy-node/pull/547#discussion_r165500316,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"You dont need 2 records, since the primary purpose of the trie is not query but merkle proofs, you can have a secondary data structure like `IdrCache` for this.  ",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 22:04:54,165502405,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165502405,https://github.com/hyperledger/indy-node/pull/547#discussion_r165502405,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,Use a cache to lookup the key in the trie and use that key to get data with proof from the trie.,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 22:06:39,165502809,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165502809,https://github.com/hyperledger/indy-node/pull/547#discussion_r165502809,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"Leveldb and Rocksdb keep the keys sorted so you can keep the timestamp as a key (part of key, use a custom comparator)  and the value for that key is the key in trie",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 22:11:36,165503994,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given",442,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165503994,https://github.com/hyperledger/indy-node/pull/547#discussion_r165503994,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,What are `10` and `30`?,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 22:17:36,165505361,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`
+using Record2. 
+1. Lookup State Trie to get data by the key found above (Record1).
+
+So, we will have 2 lookups for each request. 
+
+### CRED_DEF
+
+The Definition of credentials for the given Schema by the given Issuer.
+It contains public keys (primary and revocation),
+signature type and reference to the Schema. 
+
+#### CRED_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", ",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165505361,https://github.com/hyperledger/indy-node/pull/547#discussion_r165505361,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,What does `issued using key1 (key2)` mean?,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 22:24:50,165507001,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`
+using Record2. 
+1. Lookup State Trie to get data by the key found above (Record1).
+
+So, we will have 2 lookups for each request. 
+
+### CRED_DEF
+
+The Definition of credentials for the given Schema by the given Issuer.
+It contains public keys (primary and revocation),
+signature type and reference to the Schema. 
+
+#### CRED_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", 
+            ""to"": ""30"",
+        }
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""HHAD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+* `uuid` is CredDef's UUID. It's different from `issuerDid`.
+* `oldKeyTrustTime` can be set each time the key is rotated and defines
+ `the intervals when we still can trust the previous value of the key`.
+ This is delta; all intervals are accumulated and appended in the State. 
+It is needed to deprecate credentials issued during the time when we suspect
+the keys were stolen.
+We can not always use revocation to deprecate old credentials, since revocation keys can
+be stolen as well.  
+ 
+
+#### Restrictions
+
+* Existing CredDef (identified by the CredDef `uuid`) can be modified/changed/evolved.
+That is rotation of keys is supported.
+* Only the `issuerDID` created the CredDef can modify it (that is we need to keep the ownership). 
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger).
+
+#### State
+
+We need to have two records for CredDef in State Trie in order to have
+1. Simple referencing of CredDef in the protocol (by CredDef DID)
+1. Requirements 8
+
+Record 1:
+* key: `credDefIssuerDid | CredDefMarker | schemaUUID | signatureType | credDefUUID` 
+* value: aggregated txn data plus `trustTime` as an array (each next `trustTme` is appended).
+
+Record 2:
+* key: `credDefUUID`
+* value: Record 1 key
+
+#### How oldKeyTrustTime works
+Let's assume that 
+* `key1` was issued at `timeA`
+* `key2` was issued at `timeC`, and we suspect that `key1` is stolen at `timeB`
+* `key3` was issued at `timeE`, and we suspect that `key2` is stolen at `timeD`
+
+So, we need to use (and return by `GET_CRED_DEF`) the following keys, depending on 
+the interval the `issuanceTime` belongs to:
+* [A,B] -> key1
+* [B,C] -> key2 
+* [C,D] -> key2
+* [D,E] -> key3
+* [E, current] -> key3
+
+So, the Credentials issued at intervals [B,C] and [D,E], that is at intervals
+when keys are suspicious, will not be verifiable anymore, because they were issued using key1 (key2),",513,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165507001,https://github.com/hyperledger/indy-node/pull/547#discussion_r165507001,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"At what times is each of the transaction made like after A, B, etc?",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 22:26:24,165507359,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`
+using Record2. 
+1. Lookup State Trie to get data by the key found above (Record1).
+
+So, we will have 2 lookups for each request. 
+
+### CRED_DEF
+
+The Definition of credentials for the given Schema by the given Issuer.
+It contains public keys (primary and revocation),
+signature type and reference to the Schema. 
+
+#### CRED_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", 
+            ""to"": ""30"",
+        }
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""HHAD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+* `uuid` is CredDef's UUID. It's different from `issuerDid`.
+* `oldKeyTrustTime` can be set each time the key is rotated and defines
+ `the intervals when we still can trust the previous value of the key`.
+ This is delta; all intervals are accumulated and appended in the State. 
+It is needed to deprecate credentials issued during the time when we suspect
+the keys were stolen.
+We can not always use revocation to deprecate old credentials, since revocation keys can
+be stolen as well.  
+ 
+
+#### Restrictions
+
+* Existing CredDef (identified by the CredDef `uuid`) can be modified/changed/evolved.
+That is rotation of keys is supported.
+* Only the `issuerDID` created the CredDef can modify it (that is we need to keep the ownership). 
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger).
+
+#### State
+
+We need to have two records for CredDef in State Trie in order to have
+1. Simple referencing of CredDef in the protocol (by CredDef DID)
+1. Requirements 8
+
+Record 1:
+* key: `credDefIssuerDid | CredDefMarker | schemaUUID | signatureType | credDefUUID` 
+* value: aggregated txn data plus `trustTime` as an array (each next `trustTme` is appended).
+
+Record 2:
+* key: `credDefUUID`
+* value: Record 1 key
+
+#### How oldKeyTrustTime works
+Let's assume that 
+* `key1` was issued at `timeA`
+* `key2` was issued at `timeC`, and we suspect that `key1` is stolen at `timeB`
+* `key3` was issued at `timeE`, and we suspect that `key2` is stolen at `timeD`
+
+So, we need to use (and return by `GET_CRED_DEF`) the following keys, depending on 
+the interval the `issuanceTime` belongs to:
+* [A,B] -> key1
+* [B,C] -> key2 
+* [C,D] -> key2
+* [D,E] -> key3
+* [E, current] -> key3
+
+So, the Credentials issued at intervals [B,C] and [D,E], that is at intervals
+when keys are suspicious, will not be verifiable anymore, because they were issued using key1 (key2),
+but the Verifies will use key2 (key3) for verification (as returned by `GET_CRED_DEF`). 
+
+The following txns will be put on Ledger:",516,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165507359,https://github.com/hyperledger/indy-node/pull/547#discussion_r165507359,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"Again, dont need 2 keys, just one key holding the information needed to be given to the client is enough, that key can be looked up in cache by several filters",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-01 22:28:27,165507776,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`
+using Record2. 
+1. Lookup State Trie to get data by the key found above (Record1).
+
+So, we will have 2 lookups for each request. 
+
+### CRED_DEF
+
+The Definition of credentials for the given Schema by the given Issuer.
+It contains public keys (primary and revocation),
+signature type and reference to the Schema. 
+
+#### CRED_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", 
+            ""to"": ""30"",
+        }
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""HHAD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+* `uuid` is CredDef's UUID. It's different from `issuerDid`.
+* `oldKeyTrustTime` can be set each time the key is rotated and defines
+ `the intervals when we still can trust the previous value of the key`.
+ This is delta; all intervals are accumulated and appended in the State. 
+It is needed to deprecate credentials issued during the time when we suspect
+the keys were stolen.
+We can not always use revocation to deprecate old credentials, since revocation keys can
+be stolen as well.  
+ 
+
+#### Restrictions
+
+* Existing CredDef (identified by the CredDef `uuid`) can be modified/changed/evolved.
+That is rotation of keys is supported.
+* Only the `issuerDID` created the CredDef can modify it (that is we need to keep the ownership). 
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger).
+
+#### State
+
+We need to have two records for CredDef in State Trie in order to have
+1. Simple referencing of CredDef in the protocol (by CredDef DID)
+1. Requirements 8
+
+Record 1:
+* key: `credDefIssuerDid | CredDefMarker | schemaUUID | signatureType | credDefUUID` 
+* value: aggregated txn data plus `trustTime` as an array (each next `trustTme` is appended).
+
+Record 2:
+* key: `credDefUUID`
+* value: Record 1 key
+
+#### How oldKeyTrustTime works
+Let's assume that 
+* `key1` was issued at `timeA`
+* `key2` was issued at `timeC`, and we suspect that `key1` is stolen at `timeB`
+* `key3` was issued at `timeE`, and we suspect that `key2` is stolen at `timeD`
+
+So, we need to use (and return by `GET_CRED_DEF`) the following keys, depending on 
+the interval the `issuanceTime` belongs to:
+* [A,B] -> key1
+* [B,C] -> key2 
+* [C,D] -> key2
+* [D,E] -> key3
+* [E, current] -> key3
+
+So, the Credentials issued at intervals [B,C] and [D,E], that is at intervals
+when keys are suspicious, will not be verifiable anymore, because they were issued using key1 (key2),
+but the Verifies will use key2 (key3) for verification (as returned by `GET_CRED_DEF`). 
+
+The following txns will be put on Ledger:
+1.    
+ ```
+ ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {key1},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+    },
+```
+2.    
+ ```
+ ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {key2},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {          
+            (""from"": ""A"", ""to"": ""B""),
+            (""from"": ""C""),
+        }
+    },
+```
+3.    
+ ```
+ ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {key3},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {          
+            (""from"": ""C"", ""to"": ""D""),
+            (""from"": ""E""),
+        }
+    },
+```
+
+
+The current state (Record1) will look the following:
+* key: `HHAD5g65TDQr1PPHHRoiGf|CRED_DEF|GEzcdDLhCpGCYRHW82kjHd|CL|TYzcdDLhCpGCYRHW82kjHd`
+* value:
+ ```
+ ....
+ ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {key3},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {          
+            (""from"": ""A"", ""to"": ""B""),
+            (""from"": ""C"", ""to"": ""D""),
+            (""from"": ""E""),
+        }
+    },
+ ....
+```
+ 
+#### GET_CRED_DEF
+```
+{
+    'data': {
+        'uuid': 'TYzcdDLhCpGCYRHW82kjHd',
+        'issuanceTime': 20, (optional)
+    },
+...
+}
+```
+There is a special logic to get the valid and trusted value of the keys
+depending on the issuance time:
+1. Lookup State Trie to get `credDefIssuerDid | CredDefMarker | schemaUUID | signatureType | credDefUUID`  by `uuid`
+using Record2. 
+1. Lookup State Trie to get the current state by the key found above (Record1).
+1. If no `issuanceTime` provided, then just return the current value.  
+1. Try to find the interval (in `oldKeyTrustTime` array) the `issuanceTime` belongs to.
+    * If it's greater than the most right interval, then return the current value.
+    * If it belongs to an interval, then get the left value (`from`) of the interval.
+    * If it's in between intervals, then get the right interval, and get the left value (`from`)
+of this interval.
+1. Use generic logic to get the root of the State trie at the time `to` found above. 
+1. Lookup State Trie with the found root to find the state at that time (the same way as in Steps 1 and 2)
+
+So, we will have from 2 to 5 lookups for each request. 
+
+Result for the Example above:
+* `issuanceTime < A` => [A,B] => state at timeA => key1 (OK)
+* `A <= issuanceTime <= B` => [A,B] => state at timeA => key1 (OK)
+* `B < issuanceTime < C` => [C,D] => state at timeC => key2 (deprecated credentials)
+* `C <= issuanceTime <= D` => [C,D] => state at timeC => key2 (OK)
+* `D < issuanceTime < E` => [E,...] => state at timeE => key3 (deprecated credentials)
+* `issuanceTime > E` => [E,...] => state at timeE => key3 (OK)
+
+
+### REVOC_REG_DEF
+
+The Definition of revocation registry for the given CredDef.
+It contains public keys, maximum number of credentials the registry may contain,
+reference to the CredDef, plus some revocation registry specific data.
+
+#### REVOC_REG_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""ZXzcdDLhCpGCYRHW82kjHd"",
+        ""type"":""CL_ACCUM"",
+        ""credDefRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""maxCredNum"": 1000000,
+        ""metadata"": {
+            ""tailsHash"": ""<SHA256 hash>"",
+            ""tailsLocation"": ""<URL>""
+        }
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", 
+            ""to"": ""30"",
+        }
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""MMAD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+* `uuid` is RevocRegDef's UUID. It's different from `issuerDid`.
+* `oldKeyTrustTime` can be set each time the accumulator key is rotated and defines
+ `the interval when we still can trust the previous value of the key`. 
+It is needed to deprecate credentials issued during the time when we suspect
+the keys were stolen.
+We can not always use revocation to deprecate old credentials, since revocation keys can
+be stolen as well.  
+ 
+
+#### Restrictions
+
+* Existing RevocRegDef (identified by the RevocRegDef `uuid`) can be modified/changed/evolved.
+That is rotation of keys is supported.
+* Only the `issuerDid` who created the RevocRegDef can modify it (that is we need to keep the ownership). 
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger).
+
+#### State
+
+We need to have two records for RevocRegDef in State Trie in order to have
+1. Simple referencing of RevocRegDef in the protocol (by RevocRegDef DID)
+1. Requirements 8
+
+Record 1:",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165507776,https://github.com/hyperledger/indy-node/pull/547#discussion_r165507776,lovesh
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"Yes, I believe we can support this decoupling by just not requiring that REVOC_REG author/issuer is the same as CLAIM_DEF's Issuer.",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 08:35:39,165583872,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. ",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165583872,https://github.com/hyperledger/indy-node/pull/547#discussion_r165583872,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"If we want to support Requirement 6, then there must be `issuanceTime`.
It can be that this is not so critical requirement and we do not support it at all.
Or we may say that it's up to the Issuer whether to support this requirement or not, and hence `issuanceTime` may be present or not.",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 08:37:13,165584185,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165584185,https://github.com/hyperledger/indy-node/pull/547#discussion_r165584185,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"When doing lookup at the ledger, it can be not exact time.
The Verifier may request a predicate that the `issuanceTime` is not greater than X, and send requests to the ledger to get CRED_DEF at time X.",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 08:41:40,165585022,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165585022,https://github.com/hyperledger/indy-node/pull/547#discussion_r165585022,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"Yes. But we also need to be able to find the value for the timestamps which are not exact keys in the Leveldb.
So, let's assume that it contains keys `timeA` and  `timeB`, and we want to the get the value for `timeC`, so that `timeA < timeC < timeB`.",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 08:46:00,165585792,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given",442,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165585792,https://github.com/hyperledger/indy-node/pull/547#discussion_r165585792,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"> Rather than using the process which engages multiple nodes for each claim issuance, cant the prover just reject the credential when he receives it if issuanceTime is not acceptable.

But what if Prover and Issuer are malicious and Prover will not reject it?

> cant the issuer just embed Sovrin's latest BLS signed state since that contains timestamp too

What prevent Issuer from embeding an old state for the time in past he wants?
",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 08:48:30,165586258,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.",474,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165586258,https://github.com/hyperledger/indy-node/pull/547#discussion_r165586258,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"No, this is the Verifier who sends the proof request (asking for either a predicate or disclosure)",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 08:49:24,165586426,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`",482,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165586426,https://github.com/hyperledger/indy-node/pull/547#discussion_r165586426,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"Modification assumes that UUID will be the same, this is essential.",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:03:08,165590068,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165590068,https://github.com/hyperledger/indy-node/pull/547#discussion_r165590068,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"Yes, agree, Record 2 can be in another DB (like a cache).",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:03:45,165590188,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165590188,https://github.com/hyperledger/indy-node/pull/547#discussion_r165590188,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,+1,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:03:53,165590219,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165590219,https://github.com/hyperledger/indy-node/pull/547#discussion_r165590219,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,"timestamps :) maybe not the good values, but just for simplicity.",3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:04:19,165590304,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`
+using Record2. 
+1. Lookup State Trie to get data by the key found above (Record1).
+
+So, we will have 2 lookups for each request. 
+
+### CRED_DEF
+
+The Definition of credentials for the given Schema by the given Issuer.
+It contains public keys (primary and revocation),
+signature type and reference to the Schema. 
+
+#### CRED_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", ",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165590304,https://github.com/hyperledger/indy-node/pull/547#discussion_r165590304,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,That the credentials were Issued by the Issuer using key1 as Issuer's public key,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:04:48,165590424,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`
+using Record2. 
+1. Lookup State Trie to get data by the key found above (Record1).
+
+So, we will have 2 lookups for each request. 
+
+### CRED_DEF
+
+The Definition of credentials for the given Schema by the given Issuer.
+It contains public keys (primary and revocation),
+signature type and reference to the Schema. 
+
+#### CRED_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", 
+            ""to"": ""30"",
+        }
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""HHAD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+* `uuid` is CredDef's UUID. It's different from `issuerDid`.
+* `oldKeyTrustTime` can be set each time the key is rotated and defines
+ `the intervals when we still can trust the previous value of the key`.
+ This is delta; all intervals are accumulated and appended in the State. 
+It is needed to deprecate credentials issued during the time when we suspect
+the keys were stolen.
+We can not always use revocation to deprecate old credentials, since revocation keys can
+be stolen as well.  
+ 
+
+#### Restrictions
+
+* Existing CredDef (identified by the CredDef `uuid`) can be modified/changed/evolved.
+That is rotation of keys is supported.
+* Only the `issuerDID` created the CredDef can modify it (that is we need to keep the ownership). 
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger).
+
+#### State
+
+We need to have two records for CredDef in State Trie in order to have
+1. Simple referencing of CredDef in the protocol (by CredDef DID)
+1. Requirements 8
+
+Record 1:
+* key: `credDefIssuerDid | CredDefMarker | schemaUUID | signatureType | credDefUUID` 
+* value: aggregated txn data plus `trustTime` as an array (each next `trustTme` is appended).
+
+Record 2:
+* key: `credDefUUID`
+* value: Record 1 key
+
+#### How oldKeyTrustTime works
+Let's assume that 
+* `key1` was issued at `timeA`
+* `key2` was issued at `timeC`, and we suspect that `key1` is stolen at `timeB`
+* `key3` was issued at `timeE`, and we suspect that `key2` is stolen at `timeD`
+
+So, we need to use (and return by `GET_CRED_DEF`) the following keys, depending on 
+the interval the `issuanceTime` belongs to:
+* [A,B] -> key1
+* [B,C] -> key2 
+* [C,D] -> key2
+* [D,E] -> key3
+* [E, current] -> key3
+
+So, the Credentials issued at intervals [B,C] and [D,E], that is at intervals
+when keys are suspicious, will not be verifiable anymore, because they were issued using key1 (key2),",513,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165590424,https://github.com/hyperledger/indy-node/pull/547#discussion_r165590424,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,First one at timeA; second at timeC; third at timeE (will update it),3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:05:55,165590657,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`
+using Record2. 
+1. Lookup State Trie to get data by the key found above (Record1).
+
+So, we will have 2 lookups for each request. 
+
+### CRED_DEF
+
+The Definition of credentials for the given Schema by the given Issuer.
+It contains public keys (primary and revocation),
+signature type and reference to the Schema. 
+
+#### CRED_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", 
+            ""to"": ""30"",
+        }
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""HHAD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+* `uuid` is CredDef's UUID. It's different from `issuerDid`.
+* `oldKeyTrustTime` can be set each time the key is rotated and defines
+ `the intervals when we still can trust the previous value of the key`.
+ This is delta; all intervals are accumulated and appended in the State. 
+It is needed to deprecate credentials issued during the time when we suspect
+the keys were stolen.
+We can not always use revocation to deprecate old credentials, since revocation keys can
+be stolen as well.  
+ 
+
+#### Restrictions
+
+* Existing CredDef (identified by the CredDef `uuid`) can be modified/changed/evolved.
+That is rotation of keys is supported.
+* Only the `issuerDID` created the CredDef can modify it (that is we need to keep the ownership). 
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger).
+
+#### State
+
+We need to have two records for CredDef in State Trie in order to have
+1. Simple referencing of CredDef in the protocol (by CredDef DID)
+1. Requirements 8
+
+Record 1:
+* key: `credDefIssuerDid | CredDefMarker | schemaUUID | signatureType | credDefUUID` 
+* value: aggregated txn data plus `trustTime` as an array (each next `trustTme` is appended).
+
+Record 2:
+* key: `credDefUUID`
+* value: Record 1 key
+
+#### How oldKeyTrustTime works
+Let's assume that 
+* `key1` was issued at `timeA`
+* `key2` was issued at `timeC`, and we suspect that `key1` is stolen at `timeB`
+* `key3` was issued at `timeE`, and we suspect that `key2` is stolen at `timeD`
+
+So, we need to use (and return by `GET_CRED_DEF`) the following keys, depending on 
+the interval the `issuanceTime` belongs to:
+* [A,B] -> key1
+* [B,C] -> key2 
+* [C,D] -> key2
+* [D,E] -> key3
+* [E, current] -> key3
+
+So, the Credentials issued at intervals [B,C] and [D,E], that is at intervals
+when keys are suspicious, will not be verifiable anymore, because they were issued using key1 (key2),
+but the Verifies will use key2 (key3) for verification (as returned by `GET_CRED_DEF`). 
+
+The following txns will be put on Ledger:",516,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165590657,https://github.com/hyperledger/indy-node/pull/547#discussion_r165590657,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,+1,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:06:01,165590679,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.
+    1. We need to keep reputation for Schema's Issuer DID.
+    1. We should not have any semver assumptions for Schema's version by the Ledger.
+1. Creation of Cred Def:
+    1. CredDef Issuer may not be the same as Schema issuer.
+    1. CredDef Issuer needs to be able to create multiple CredDefs by the same issuer DID.
+    1. CredDef Issuer needs to be able to create multiple CredDefs for the same Schema by the same issuer DID.
+    1. We need to keep reputation for CredDef's Issuer DID.
+1. Creation of Revocation entities (Def and Registry):
+    1. RevocRegDef Issuer may not be the same as Schema Issuer and CredDef issuer. 
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDefs for the same issuer DID.
+    1. RevocRegDef Issuer needs to be able to create multiple RevocRegDef for the same CredDef by the same issuer DID.
+    1. We need to keep reputation for RevocRegDef's Issuer DID.
+1. Referencing Schema/CredDef/RevocRegDef:
+    1. Prover needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential.  
+    1. Verifier needs to know what CredDef (public keys), Schema and RevocRegDef 
+    were used for issuing the credential from the proof.
+1. <b>Keys rotation</b>:
+    1. Issuer needs to be able to rotate the keys and issue new credentials with the new keys.
+    1. Issuer needs to be able to rotate the keys using the same Issuer DID.
+1. <b>Validity of already issued credentials when key is compromised</b>: 
+    1. If the Issuer's key is compromised and the issuer suspects that it's compromised 
+    from the very beginning, then the Issuer should be able to rotate the key so that all issued credentials
+    becomes invalid.
+    All new credentials issued after rotation should be verifiable against the new key.
+    1. If the Issuer published a key at time A, and at time C he realised that the key was compromised at time B (A < B < C), 
+    then the Issuer should be able to rotate the key so that all credentials
+    issued before time B can be successfully verified using old key, and
+    all credentials issued between B and C becomes invalid.
+    All new credentials issued after C should be verifiable against the new key.
+    1. The Issuer needs to be able to rotate the keys multiple times. Requirement 5.ii must be true for each key rotation.  
+1. <b>Revocation</b>
+    1. Verifier needs to be able to Verify that the credential is not revoked at the current time
+    (the time when proof request is created).
+    1. Verifier needs to be able to Verify that the credential is not revoked at the given time (any time in the past).       
+1. Querying
+    1. One needs to be able to get all CRED_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name created by the given Issuer DID.
+    1. One needs to be able to get all SCHEMAs with the given name and version created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID.
+    1. One needs to be able to get all REVOC_REG_DEFs created by the given Issuer DID for the given CRED_DEF.    
+
+### Technical goals
+* Define how Schemas, CreDefs and RevocRegDefs are identified (seqNo, UUID, primary key tuples?)
+* Define how to deal with Requirements 6.
+* Define Revocation-related transactions and necessary changes in indy-node.
+
+
+### Referencing Schema and CredDef in Credentials and Proofs
+* Schema is referenced by unique `SchemaUUID`.
+    * Created for each new Schema.
+    * This is different from Schema Issuer DID (DID used to send `SCHEMA` txn) which can be the same for 
+    any number of Schemas.
+* CredDef is referenced by unique `CredDefUUID`.
+    * Created for each new CredDef.
+    * This is different from CredDef Issuer DID (DID used to send `CRED_DEF` txn) which can be the same for 
+    any number of CredDef.
+* RevocRegDef and RevocReg are referenced by unique `RevocRegDefUUID`.
+    * Created for each new RevocRegDef.
+    * Used to update RevocReg.
+    * This is different from RevocRegDef Issuer DID (DID used to send `REVOC_REG_DEF` txn) which can be the same for 
+    any number of RevocRegDef.
+* Each `UUID` can be considered as a global UUID within the Ledger.
+The Ledger can guarantee that malicious party can not change/break existing entity 
+defined by a UUID by 
+and checking if there is an entity with the given UUID already existent, plus
+checking the ownership when modifying existing entities (only the issuer who created en entity with the given UUID can modify it). 
+
+      
+### How Prover and Verifier get keys for Credentials and Proofs
+* Proofs and credentials come with `schemaUUID`, `credDefUUID`, `revocDefUUID`.
+* Also there can be `issuanceTime` attribute in each credential (which can be disclosed in the proof).
+* Prover/Verifier looks up SCHEMA using `GET_SCHEMA(schemaUUID)` request to the ledger
+* Prover/Verifier looks up CRED_DEF using `GET_CRED_DEF(credDefUUID, issuanceTime)` request to the ledger
+* Prover/Verifier looks up REVOC_REG_DEF using `GET_REVOC_REG_DEF(revocDefUUID, issuanceTime)` request to the ledger
+* Prover looks up REVOC_REG to update the witness for the given `timestamp` 
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Verifies looks up REVOC_REG to get accumulator value for the given `timestamp`  
+ using `GET_REVOC_REG(revocDefUUID, timestamp)` request to the ledger
+* Prover and Verifier should look up REVOC_REG by the same `timestamp` when generating and verifying the proof.
+
+### Timestamp Support in State
+
+We need to have a generic way to get the State at the given time.
+- State Trie allows to go to the past, that is given the root hash, get the state with this root.
+- We may have a mapping of each State update (timestamp) to the corresponding root.
+- We need to find a data structure that can help us to find the nearest state timestamp (to get the root) for the given
+time.
+- So, we will be able to get the data (state) at the given time.
+
+This approach can be used for
+* getting `REVOC_REG` at desired time (the same for both proper and verifier),
+possibly long ago in the past;
+* dealing with Requirement 6. 
+
+### Changes in Anoncreds Protocol
+
+If want to support Requirement 6, then the following changes are required in the
+anoncerds protocol:
+
+* Each Credential must have a reserved mandatory attribute: `issuanceTime`.
+    * It's set by the Issuer to specify the time of Issuance.
+    * It's needed to fulfill Requirements 5.
+* This attribute can be considered as `m3` special attribute (`m1` is master secret, `m2` is credential context, `m3` is issuance time).
+* Since the Issuer may be malicious (if keys were compromised already), then 
+a proof that `issuanceTime` is really the current time and not the time from the past is needed.
+    * We can use our blockchain to prepare such a proof.
+    * Issuer signs (by his Cred Def's public key) the `issuanceTime` and sends it to the pool.
+    * Each node verifies that `issuanceTime` is not less that the current one, and signs the result with BLS key.
+    * Each node then sends the signed result to the Issuer (no need to write anything to the ledger).
+    * The issuer prepares a BLS multi-signature (making sure that there is a consensus)
+    and adds the BLS-signed proof of the `issuanceTime` to the credential.
+    * The verifier will then use the proof to make sure that the `issuanceTime` is really the correct one.
+* The `issuanceTime` needs to be verified in each proof.
+    * The Verifier should use Predicates (instead of disclosing) for the value of `issuanceTime`
+    to avoid correlation. 
+    * It's possible also to disclose `issuanceTime`, but we don't force it.
+    * If it's not disclosed and not verified as a Predicate, then there is a chance the the proof verification will fail because 
+of key rotations, since the latest keys will be used.
+
+
+
+### SCHEMA
+
+#### SCHEMA txn
+```
+{
+    ""data"": {
+        ""uuid"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""attrNames"": [""undergrad"",""last_name"",""first_name"",""birth_date"",""postgrad"",""expiry_date""],
+        ""name"":""Degree"",
+        ""version"":""1.0"",
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""L5AD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+`uuid` is Schema's UUID. It's different from `issuerDid`.
+
+#### Restrictions
+
+* Existing Schema (identified by the Schema `uuid`) can be modified/changed/evolved.
+* Only the `issuerDid` who created the Schema can modify it (that is we need to keep the ownership).
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger). 
+
+#### State
+
+We need to have two records for Schema in State Trie in order to have
+1. Simple referencing of Schemas in the protocol (by Schema DID)
+1. Requirements 8
+
+Record 1:
+* key: `schemaIssuerDid | SchemaMarker | schemaName | schemaVersion | schemaUUID` 
+* value: aggregated txn data
+
+Record 2:
+* key: `schemaUUID`
+* value: Record 1 key
+
+
+#### GET_SCHEMA
+```
+{
+    'data': {
+        'uuid': 'GEzcdDLhCpGCYRHW82kjHd',
+    },
+...
+}
+```
+1. Lookup State Trie to get `schemaIssuerDid | SchemaMarker |schemaName | schemaVersion | schemaUUID` by `uuid`
+using Record2. 
+1. Lookup State Trie to get data by the key found above (Record1).
+
+So, we will have 2 lookups for each request. 
+
+### CRED_DEF
+
+The Definition of credentials for the given Schema by the given Issuer.
+It contains public keys (primary and revocation),
+signature type and reference to the Schema. 
+
+#### CRED_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", 
+            ""to"": ""30"",
+        }
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""HHAD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+* `uuid` is CredDef's UUID. It's different from `issuerDid`.
+* `oldKeyTrustTime` can be set each time the key is rotated and defines
+ `the intervals when we still can trust the previous value of the key`.
+ This is delta; all intervals are accumulated and appended in the State. 
+It is needed to deprecate credentials issued during the time when we suspect
+the keys were stolen.
+We can not always use revocation to deprecate old credentials, since revocation keys can
+be stolen as well.  
+ 
+
+#### Restrictions
+
+* Existing CredDef (identified by the CredDef `uuid`) can be modified/changed/evolved.
+That is rotation of keys is supported.
+* Only the `issuerDID` created the CredDef can modify it (that is we need to keep the ownership). 
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger).
+
+#### State
+
+We need to have two records for CredDef in State Trie in order to have
+1. Simple referencing of CredDef in the protocol (by CredDef DID)
+1. Requirements 8
+
+Record 1:
+* key: `credDefIssuerDid | CredDefMarker | schemaUUID | signatureType | credDefUUID` 
+* value: aggregated txn data plus `trustTime` as an array (each next `trustTme` is appended).
+
+Record 2:
+* key: `credDefUUID`
+* value: Record 1 key
+
+#### How oldKeyTrustTime works
+Let's assume that 
+* `key1` was issued at `timeA`
+* `key2` was issued at `timeC`, and we suspect that `key1` is stolen at `timeB`
+* `key3` was issued at `timeE`, and we suspect that `key2` is stolen at `timeD`
+
+So, we need to use (and return by `GET_CRED_DEF`) the following keys, depending on 
+the interval the `issuanceTime` belongs to:
+* [A,B] -> key1
+* [B,C] -> key2 
+* [C,D] -> key2
+* [D,E] -> key3
+* [E, current] -> key3
+
+So, the Credentials issued at intervals [B,C] and [D,E], that is at intervals
+when keys are suspicious, will not be verifiable anymore, because they were issued using key1 (key2),
+but the Verifies will use key2 (key3) for verification (as returned by `GET_CRED_DEF`). 
+
+The following txns will be put on Ledger:
+1.    
+ ```
+ ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {key1},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+    },
+```
+2.    
+ ```
+ ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {key2},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {          
+            (""from"": ""A"", ""to"": ""B""),
+            (""from"": ""C""),
+        }
+    },
+```
+3.    
+ ```
+ ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {key3},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {          
+            (""from"": ""C"", ""to"": ""D""),
+            (""from"": ""E""),
+        }
+    },
+```
+
+
+The current state (Record1) will look the following:
+* key: `HHAD5g65TDQr1PPHHRoiGf|CRED_DEF|GEzcdDLhCpGCYRHW82kjHd|CL|TYzcdDLhCpGCYRHW82kjHd`
+* value:
+ ```
+ ....
+ ""data"": {
+        ""uuid"":""TYzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {key3},
+        ""schemaRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""signatureType"":""CL"",
+        ""oldKeyTrustTime"": {          
+            (""from"": ""A"", ""to"": ""B""),
+            (""from"": ""C"", ""to"": ""D""),
+            (""from"": ""E""),
+        }
+    },
+ ....
+```
+ 
+#### GET_CRED_DEF
+```
+{
+    'data': {
+        'uuid': 'TYzcdDLhCpGCYRHW82kjHd',
+        'issuanceTime': 20, (optional)
+    },
+...
+}
+```
+There is a special logic to get the valid and trusted value of the keys
+depending on the issuance time:
+1. Lookup State Trie to get `credDefIssuerDid | CredDefMarker | schemaUUID | signatureType | credDefUUID`  by `uuid`
+using Record2. 
+1. Lookup State Trie to get the current state by the key found above (Record1).
+1. If no `issuanceTime` provided, then just return the current value.  
+1. Try to find the interval (in `oldKeyTrustTime` array) the `issuanceTime` belongs to.
+    * If it's greater than the most right interval, then return the current value.
+    * If it belongs to an interval, then get the left value (`from`) of the interval.
+    * If it's in between intervals, then get the right interval, and get the left value (`from`)
+of this interval.
+1. Use generic logic to get the root of the State trie at the time `to` found above. 
+1. Lookup State Trie with the found root to find the state at that time (the same way as in Steps 1 and 2)
+
+So, we will have from 2 to 5 lookups for each request. 
+
+Result for the Example above:
+* `issuanceTime < A` => [A,B] => state at timeA => key1 (OK)
+* `A <= issuanceTime <= B` => [A,B] => state at timeA => key1 (OK)
+* `B < issuanceTime < C` => [C,D] => state at timeC => key2 (deprecated credentials)
+* `C <= issuanceTime <= D` => [C,D] => state at timeC => key2 (OK)
+* `D < issuanceTime < E` => [E,...] => state at timeE => key3 (deprecated credentials)
+* `issuanceTime > E` => [E,...] => state at timeE => key3 (OK)
+
+
+### REVOC_REG_DEF
+
+The Definition of revocation registry for the given CredDef.
+It contains public keys, maximum number of credentials the registry may contain,
+reference to the CredDef, plus some revocation registry specific data.
+
+#### REVOC_REG_DEF txn
+```
+{
+    ""data"": {
+        ""uuid"":""ZXzcdDLhCpGCYRHW82kjHd"",
+        ""type"":""CL_ACCUM"",
+        ""credDefRef"":""GEzcdDLhCpGCYRHW82kjHd"",
+        ""publicKeys"": {},
+        ""maxCredNum"": 1000000,
+        ""metadata"": {
+            ""tailsHash"": ""<SHA256 hash>"",
+            ""tailsLocation"": ""<URL>""
+        }
+        ""oldKeyTrustTime"": {                    (optional)
+            ""from"": ""10"", 
+            ""to"": ""30"",
+        }
+    },
+    
+    ""reqMetadata"": {
+        ""issuerDid"":""MMAD5g65TDQr1PPHHRoiGf"",
+        .....
+    },
+    
+....
+}
+```
+* `uuid` is RevocRegDef's UUID. It's different from `issuerDid`.
+* `oldKeyTrustTime` can be set each time the accumulator key is rotated and defines
+ `the interval when we still can trust the previous value of the key`. 
+It is needed to deprecate credentials issued during the time when we suspect
+the keys were stolen.
+We can not always use revocation to deprecate old credentials, since revocation keys can
+be stolen as well.  
+ 
+
+#### Restrictions
+
+* Existing RevocRegDef (identified by the RevocRegDef `uuid`) can be modified/changed/evolved.
+That is rotation of keys is supported.
+* Only the `issuerDid` who created the RevocRegDef can modify it (that is we need to keep the ownership). 
+* It's not possible to create multiple entities with the same `uuid` (so, it's unique within the ledger).
+
+#### State
+
+We need to have two records for RevocRegDef in State Trie in order to have
+1. Simple referencing of RevocRegDef in the protocol (by RevocRegDef DID)
+1. Requirements 8
+
+Record 1:",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165590679,https://github.com/hyperledger/indy-node/pull/547#discussion_r165590679,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,Done,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:08:03,165591081,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165591081,https://github.com/hyperledger/indy-node/pull/547#discussion_r165591081,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,Done,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:08:46,165591224,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165591224,https://github.com/hyperledger/indy-node/pull/547#discussion_r165591224,ashcherbakov
https://github.com/hyperledger/indy-node/pull/547,https://github.com/hyperledger/indy-node/pull/547,Fixed,3ff1bf14896eb6ceda22931c796c509373caecd5,2018-02-02 09:09:09,165591288,"@@ -0,0 +1,507 @@
+# Anoncreds Design
+Here you can find the requirements and design for Anoncreds workflow (including revocation).
+
+* [Anoncreds Link](#anoncreds-links)
+* [Requirements](#requirements)
+* [Technical goals](#technical-goals)
+* [Referencing Schema and CredDef in Credentials and Proofs](#referencing-schema-and-creddef-in-credentials-and-proofs)
+* [How Prover and Verifier get keys for Credentials and Proofs](#how-prover-and-verifier-get-keys-for-credentials-and-proofs)
+* [Timestamp Support in State](#timestamp-support-in-state)
+* [Changes in Anoncreds Protocol](#changes-in-anoncreds-protocol)
+* [SCHEMA](#schema)
+* [CRED_DEF](#cred_def)
+* [REVOC_REG_DEF](#revoc_reg_def)
+* [REVOC_REG](#revoc_reg)
+
+### Anoncreds Links
+
+Anoncreds protocol links:
+- [Anoncreds Sequence Diagram](https://github.com/hyperledger/indy-sdk/blob/master/doc/libindy-anoncreds.svg)
+- [Anoncreds Protocol Math](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/AnonCred.pdf)
+- [Anoncreds Protocol Crypto API](https://github.com/hyperledger/indy-crypto/blob/master/libindy-crypto/docs/anoncreds-design.md)
+
+### Requirements
+1. Creation of Schemas:
+    1. Schema Issuer needs to be able to create multiple schemas by the same issuer DID.
+    1. Schema Issuer needs to be able to evolve existing schema adding new attributes.",,2018-02-12 14:09:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165591288,https://github.com/hyperledger/indy-node/pull/547#discussion_r165591288,ashcherbakov
https://github.com/hyperledger/indy-node/pull/545,https://github.com/hyperledger/indy-node/pull/545,documents and diagrams,542fb9baabc0bbe99f0e2649bcf305553997d657,2018-02-01 15:24:51,165389099,"@@ -157,15 +161,23 @@ If you made changes in both indy-plenum and indy-node, you need to do the follow
 
 ## Docs and links
 
-- Please have a look at documents ad diagrams in [docs](docs) folder
 - Indy-plenum is based on [RBFT](https://pakupaku.me/plaublin/rbft/5000a297.pdf) protocol
+- Please have a look at documents ad diagrams in [docs](docs) folder",,2018-02-02 11:29:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165389099,https://github.com/hyperledger/indy-node/pull/545#discussion_r165389099,andkononykhin
https://github.com/hyperledger/indy-node/pull/545,https://github.com/hyperledger/indy-node/pull/545,the same as above,542fb9baabc0bbe99f0e2649bcf305553997d657,2018-02-01 15:25:08,165389189,"@@ -157,15 +161,23 @@ If you made changes in both indy-plenum and indy-node, you need to do the follow
 
 ## Docs and links
 
-- Please have a look at documents ad diagrams in [docs](docs) folder
 - Indy-plenum is based on [RBFT](https://pakupaku.me/plaublin/rbft/5000a297.pdf) protocol
+- Please have a look at documents ad diagrams in [docs](docs) folder
+- Please have a look at documents ad diagrams in Plenum's [docs](https://github.com/hyperledger/indy-plenum/tree/master/docs) folder:",,2018-02-02 11:29:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165389189,https://github.com/hyperledger/indy-node/pull/545#discussion_r165389189,andkononykhin
https://github.com/hyperledger/indy-node/pull/545,https://github.com/hyperledger/indy-node/pull/545,I think a link will be helpful here,542fb9baabc0bbe99f0e2649bcf305553997d657,2018-02-01 15:30:51,165391074,"@@ -0,0 +1,70 @@
+# Pool Upgrade Guideline
+
+There is quite interesting and automated process of the pool (network) upgrade.
+- The whole pool (that is each node in the pool) can be upgraded automatically without any manual actions
+via `POOL_UPGRADE` transaction. 
+- As a result of Upgrade, each Node will be at the specified version,
+ that is a new package, for example deb package, will be installed.
+- Migration scripts can also be performed during Upgrade to deal with breaking changes between the versions. 
+
+
+### Pool Upgrade Transaction
+
+- Pool Upgrade is done via `POOL_UPGRADE` transaction.
+- The txn defines a schedule of Upgrade (upgrade time) for each node in the pool.
+- Only the `TRUSTEE` can send `POOL_UPGRADE`.
+- This is a common transaction (written to config ledger), so consensus is required.
+- There are two main modes for `POOL_UPGRADE`: forced and non-forced (default).
+    - Non-forced mode schedules upgrade only after `POOL_UPGRADE` transaction is written to the ledger, that is 
+there was consensus. Forced upgrade schedules upgrade for each node regardless of whether `POOL_UPGRADE` transaction is actually 
+    written to the ledger, that is it can be scheduled even if the pool lost consensus.
+    - Non-forced mode requires that upgrade of each node is done sequentially and not at the same time (so that
+a pool is still working and can reach consensus during upgrade).
+    Forced upgrade allows upgrade of the whole pool at the same time.
+- One should usually use non-forced Upgrades assuming that all changes are backward-compatible.
+- If there are non-backward-compatible (breaking) changes, then one needs to use forced Upgrade and 
+make it happen at the same time on all nodes (see below).  
+     
+### Node Upgrade Transaction
+
+- Each node sends `NODE_UPGRADE` transaction twice:
+    - `in_progress` action: just before start of the Upgrade (that is re-starting the node and applying a new package)
+    to log that Upgrade started on the node.
+    - `success` or `fail` action: after upgrade of the node to log the upgrade result.
+- `NODE_UPGRADE` transaction is a common transaction (written to config ledger), so consensus is required.
+
+### Node Control Tool
+
+- Upgrade is performed by a `node-control-tool`.
+- See `node_control_tool.py`.",,2018-02-02 11:29:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165391074,https://github.com/hyperledger/indy-node/pull/545#discussion_r165391074,andkononykhin
https://github.com/hyperledger/indy-node/pull/543,https://github.com/hyperledger/indy-node/pull/543,"why 'ubuntu' only, e.g. such a conditional will fail on debian where apt is also available",eae5b37ba0466275dc8365a5eb067f7e849f8d16,2018-02-02 16:38:17,165694682,"@@ -272,7 +273,8 @@ def _run_shell_script(cls, command, timeout):
                               timeout=timeout)
 
     def start(self):
-        self._hold_packages()
+        if 'ubuntu' in platform.platform().lower():",,2018-03-02 14:56:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165694682,https://github.com/hyperledger/indy-node/pull/543#discussion_r165694682,andkononykhin
https://github.com/hyperledger/indy-node/pull/543,https://github.com/hyperledger/indy-node/pull/543,So checking of apt-mark executable is needed to be more generic,eae5b37ba0466275dc8365a5eb067f7e849f8d16,2018-02-03 10:38:58,165811288,"@@ -272,7 +273,8 @@ def _run_shell_script(cls, command, timeout):
                               timeout=timeout)
 
     def start(self):
-        self._hold_packages()
+        if 'ubuntu' in platform.platform().lower():",,2018-03-02 14:56:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/165811288,https://github.com/hyperledger/indy-node/pull/543#discussion_r165811288,M0Rf30
https://github.com/hyperledger/indy-node/pull/543,https://github.com/hyperledger/indy-node/pull/543,It will work. But I don't think that it is ok to skip hold-packages stage silently. Also if we someday want to call `_hold_packages` from some other place we should copy-paste the conditional you added. Does it make sense to move the conditional inside the method itself? Could you add some logging/warning in case no operations performed?,eae5b37ba0466275dc8365a5eb067f7e849f8d16,2018-03-01 10:04:53,171511280,"@@ -271,7 +271,8 @@ def _run_shell_script(cls, command, timeout):
                               timeout=timeout)
 
     def start(self):
-        self._hold_packages()
+        if shutil.which(""apt-mark""):
+            self._hold_packages()",,2018-03-02 14:56:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171511280,https://github.com/hyperledger/indy-node/pull/543#discussion_r171511280,andkononykhin
https://github.com/hyperledger/indy-node/pull/543,https://github.com/hyperledger/indy-node/pull/543,"Please, add logging (warning) for the case when we skip packages holding. Thank you",eae5b37ba0466275dc8365a5eb067f7e849f8d16,2018-03-02 13:18:25,171843997,"@@ -271,7 +271,8 @@ def _run_shell_script(cls, command, timeout):
                               timeout=timeout)
 
     def start(self):
-        self._hold_packages()
+        if shutil.which(""apt-mark""):
+            self._hold_packages()",,2018-03-02 14:56:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/171843997,https://github.com/hyperledger/indy-node/pull/543#discussion_r171843997,andkononykhin
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,@AlexanderShekhovcov Where is the actual serialised data that was signed? Or does the sdk know how to serialise the data,3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-17 16:44:41,189026768,"@@ -0,0 +1,1941 @@
+# Requests
+* [Common Message Structure](#common-message-structure)
+* [Signed Message Structure](#signed-message-structure)
+* [Common Request Structure](#common-request-structure)
+* [Common Reply Structure](#common-reply-structure)
+* [Command Reply Structure](#command-reply-structure)
+* [ACK Structure](#ack-structure)
+* [NACK Structure](#nack-structure)
+* [Reject Structure](#reject-structure)
+* [Write Requests](#write-requests)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    * [NODE](#node)
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+* [Read Requests](#read-requests)
+
+    * [GET_NYM](#get_nym)    
+    * [GET_ATTRIB](#get_attrib)    
+    * [GET_SCHEMA](#get_schema)
+    * [GET_CLAIM_DEF](#get_claim_def)
+    * [GET_TXN](#get_txn)
+    
+This doc is about supported client""s Request (both write and read ones).
+If you are interested in transactions and their representation on the Ledger (that is internal one),
+then have a look at [transactions](transactions.md).
+
+[indy-sdk](https://github.com/hyperledger/indy-sdk) expects the format as specified below.
+
+See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions.
+
+
+## Base Client-to-Node and Node-to-Node serialization 
+
+The main Client-to-Node and Node-to-Node envelope is serialized in MsgPack format.
+
+## Common Message Structure
+
+This is a common structure for ALL messages (both Node-to-Node and Client-to-Node).
+
+```
+    ""type"": <...>,
+    ""protocolVersion"": <...>,
+    ""ver"": 1,
+    
+    ""data"": {
+        ""ver"": 1,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        <msg-specific fields>
+    },
+    
+    ""pluginData"": {
+        <plugin-specific-fields>
+    }
+```
+- `type` (enum integer): 
+ 
+    Msg type.
+    
+- `protocolVersion` (integer; optional): 
+
+    The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+    Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+    between clients and nodes.     
+
+- `ver` (integer, optional):
+
+    Data/Metdata version.
+
+- `data` (dict):
+
+    Message-specific data.
+
+- `metadata` (dict):
+
+    Message-specific metadata.
+
+- `pluginData` (dict):
+
+    Plugin-specific data.
+
+## Signed Message Structure
+
+A message (see above) can be wrapped into a Signed Message envelope.
+All write requests must be signed.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    
+    ""signature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>,
+        ],
+        ""threshold"": <...>
+    },
+    
+    ""serialization"": <...>,
+    ""msg"": <serialized-msg>
+}
+```
+- `signature` (dict):
+
+    Submitter's signature over serialized `msg` field.
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+    
+- `serialization` (string enum, optional):
+
+    Defines how the `msg` is serialized
+     - JSON: json
+     - MSG_PACK: msgpack
+        
+- `msg` (dict):
+    
+    Serialized message.
+    
+    
+## Common Request Structure
+
+Each Request (both write and read) follows the pattern as shown above.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+
+- Message Type `type` is one of the following values:
+
+    - NODE = 0
+    - NYM = 1
+    - ATTRIB = 100
+    - SCHEMA = 101
+    - CLAIM_DEF = 102
+    - POOL_UPGRADE = 109
+    - NODE_UPGRADE = 110
+    - POOL_CONFIG = 111
+    - GET_TXN = 3
+    - GET_ATTR = 104
+    - GET_NYM = 105
+    - GET_SCHEMA = 107
+    - GET_CLAIM_DEF = 108 
+
+- `metadata` (dict):
+
+    Metadata coming with the Request and saving in the transaction as is (if this is a write request).
+
+    - `from` (base58-encoded string):
+         Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+         for 16 or 32 bit DID value.
+         It must be present on Ledger for write requests and can be any value for read requests.
+         
+         It may differ from `did` field for some of requests (for example NYM), where `did` is a 
+         target identifier (for example, a newly created DID identifier).
+         
+         *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+         
+    - `reqId` (integer): 
+        Unique ID number of the request with transaction.
+        
+- Please find the format of each request-specific data for each type of request below.
+
+## Common Reply Structure
+
+Each Write/Read Reply follows the pattern as shown above.
+
+```
+{
+    ""type"": REPLY,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        ""results"": [
+            ""result"": {
+                <result>
+            },
+            
+            ""multiSignature"": {
+                ""type"": <...>,
+                ""value"": <...>,
+                ""from"": <...>,
+                ""serialization"": <...>,
+                ""signedState"": <...>
+            }, 
+        
+            ""stateProof"": <...>,
+            ""auditProof"": <...>, 
+        ]
+    },
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+where `multiSignature`'s `signedState` is a serialized value having the following form:",233,2018-05-17 16:44:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189026768,https://github.com/hyperledger/indy-node/pull/536#discussion_r189026768,lovesh
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"This is the data serialized and signed by nodes. So, the serialized data is signed, not actual one.
This data is not re-serialized on nodes side and passed to clients in serialized format. So, the client can verify the signature over serialized data.
Then it can de-serialize the data according to the serialization specified in ""serialization"" field.

BTW the same approach is going to be applied for Requests, where signature is calculated against serialized data, and the serialized data is passed to the pool, not actual one, and re-serializations on node side for requests is not needed.",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-17 17:03:03,189031950,"@@ -0,0 +1,1941 @@
+# Requests
+* [Common Message Structure](#common-message-structure)
+* [Signed Message Structure](#signed-message-structure)
+* [Common Request Structure](#common-request-structure)
+* [Common Reply Structure](#common-reply-structure)
+* [Command Reply Structure](#command-reply-structure)
+* [ACK Structure](#ack-structure)
+* [NACK Structure](#nack-structure)
+* [Reject Structure](#reject-structure)
+* [Write Requests](#write-requests)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    * [NODE](#node)
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+* [Read Requests](#read-requests)
+
+    * [GET_NYM](#get_nym)    
+    * [GET_ATTRIB](#get_attrib)    
+    * [GET_SCHEMA](#get_schema)
+    * [GET_CLAIM_DEF](#get_claim_def)
+    * [GET_TXN](#get_txn)
+    
+This doc is about supported client""s Request (both write and read ones).
+If you are interested in transactions and their representation on the Ledger (that is internal one),
+then have a look at [transactions](transactions.md).
+
+[indy-sdk](https://github.com/hyperledger/indy-sdk) expects the format as specified below.
+
+See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions.
+
+
+## Base Client-to-Node and Node-to-Node serialization 
+
+The main Client-to-Node and Node-to-Node envelope is serialized in MsgPack format.
+
+## Common Message Structure
+
+This is a common structure for ALL messages (both Node-to-Node and Client-to-Node).
+
+```
+    ""type"": <...>,
+    ""protocolVersion"": <...>,
+    ""ver"": 1,
+    
+    ""data"": {
+        ""ver"": 1,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        <msg-specific fields>
+    },
+    
+    ""pluginData"": {
+        <plugin-specific-fields>
+    }
+```
+- `type` (enum integer): 
+ 
+    Msg type.
+    
+- `protocolVersion` (integer; optional): 
+
+    The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+    Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+    between clients and nodes.     
+
+- `ver` (integer, optional):
+
+    Data/Metdata version.
+
+- `data` (dict):
+
+    Message-specific data.
+
+- `metadata` (dict):
+
+    Message-specific metadata.
+
+- `pluginData` (dict):
+
+    Plugin-specific data.
+
+## Signed Message Structure
+
+A message (see above) can be wrapped into a Signed Message envelope.
+All write requests must be signed.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    
+    ""signature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>,
+        ],
+        ""threshold"": <...>
+    },
+    
+    ""serialization"": <...>,
+    ""msg"": <serialized-msg>
+}
+```
+- `signature` (dict):
+
+    Submitter's signature over serialized `msg` field.
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+    
+- `serialization` (string enum, optional):
+
+    Defines how the `msg` is serialized
+     - JSON: json
+     - MSG_PACK: msgpack
+        
+- `msg` (dict):
+    
+    Serialized message.
+    
+    
+## Common Request Structure
+
+Each Request (both write and read) follows the pattern as shown above.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+
+- Message Type `type` is one of the following values:
+
+    - NODE = 0
+    - NYM = 1
+    - ATTRIB = 100
+    - SCHEMA = 101
+    - CLAIM_DEF = 102
+    - POOL_UPGRADE = 109
+    - NODE_UPGRADE = 110
+    - POOL_CONFIG = 111
+    - GET_TXN = 3
+    - GET_ATTR = 104
+    - GET_NYM = 105
+    - GET_SCHEMA = 107
+    - GET_CLAIM_DEF = 108 
+
+- `metadata` (dict):
+
+    Metadata coming with the Request and saving in the transaction as is (if this is a write request).
+
+    - `from` (base58-encoded string):
+         Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+         for 16 or 32 bit DID value.
+         It must be present on Ledger for write requests and can be any value for read requests.
+         
+         It may differ from `did` field for some of requests (for example NYM), where `did` is a 
+         target identifier (for example, a newly created DID identifier).
+         
+         *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+         
+    - `reqId` (integer): 
+        Unique ID number of the request with transaction.
+        
+- Please find the format of each request-specific data for each type of request below.
+
+## Common Reply Structure
+
+Each Write/Read Reply follows the pattern as shown above.
+
+```
+{
+    ""type"": REPLY,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        ""results"": [
+            ""result"": {
+                <result>
+            },
+            
+            ""multiSignature"": {
+                ""type"": <...>,
+                ""value"": <...>,
+                ""from"": <...>,
+                ""serialization"": <...>,
+                ""signedState"": <...>
+            }, 
+        
+            ""stateProof"": <...>,
+            ""auditProof"": <...>, 
+        ]
+    },
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+where `multiSignature`'s `signedState` is a serialized value having the following form:",233,2018-05-17 17:03:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189031950,https://github.com/hyperledger/indy-node/pull/536#discussion_r189031950,ashcherbakov
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"But what is the data that is serialised? `signedState` just has 2 metadata objects, eg. in a `GET_NYM` txn, the serialised data will have the actual NYM and verkey, does that not live under `signedState`?",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-17 17:09:35,189033814,"@@ -0,0 +1,1941 @@
+# Requests
+* [Common Message Structure](#common-message-structure)
+* [Signed Message Structure](#signed-message-structure)
+* [Common Request Structure](#common-request-structure)
+* [Common Reply Structure](#common-reply-structure)
+* [Command Reply Structure](#command-reply-structure)
+* [ACK Structure](#ack-structure)
+* [NACK Structure](#nack-structure)
+* [Reject Structure](#reject-structure)
+* [Write Requests](#write-requests)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    * [NODE](#node)
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+* [Read Requests](#read-requests)
+
+    * [GET_NYM](#get_nym)    
+    * [GET_ATTRIB](#get_attrib)    
+    * [GET_SCHEMA](#get_schema)
+    * [GET_CLAIM_DEF](#get_claim_def)
+    * [GET_TXN](#get_txn)
+    
+This doc is about supported client""s Request (both write and read ones).
+If you are interested in transactions and their representation on the Ledger (that is internal one),
+then have a look at [transactions](transactions.md).
+
+[indy-sdk](https://github.com/hyperledger/indy-sdk) expects the format as specified below.
+
+See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions.
+
+
+## Base Client-to-Node and Node-to-Node serialization 
+
+The main Client-to-Node and Node-to-Node envelope is serialized in MsgPack format.
+
+## Common Message Structure
+
+This is a common structure for ALL messages (both Node-to-Node and Client-to-Node).
+
+```
+    ""type"": <...>,
+    ""protocolVersion"": <...>,
+    ""ver"": 1,
+    
+    ""data"": {
+        ""ver"": 1,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        <msg-specific fields>
+    },
+    
+    ""pluginData"": {
+        <plugin-specific-fields>
+    }
+```
+- `type` (enum integer): 
+ 
+    Msg type.
+    
+- `protocolVersion` (integer; optional): 
+
+    The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+    Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+    between clients and nodes.     
+
+- `ver` (integer, optional):
+
+    Data/Metdata version.
+
+- `data` (dict):
+
+    Message-specific data.
+
+- `metadata` (dict):
+
+    Message-specific metadata.
+
+- `pluginData` (dict):
+
+    Plugin-specific data.
+
+## Signed Message Structure
+
+A message (see above) can be wrapped into a Signed Message envelope.
+All write requests must be signed.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    
+    ""signature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>,
+        ],
+        ""threshold"": <...>
+    },
+    
+    ""serialization"": <...>,
+    ""msg"": <serialized-msg>
+}
+```
+- `signature` (dict):
+
+    Submitter's signature over serialized `msg` field.
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+    
+- `serialization` (string enum, optional):
+
+    Defines how the `msg` is serialized
+     - JSON: json
+     - MSG_PACK: msgpack
+        
+- `msg` (dict):
+    
+    Serialized message.
+    
+    
+## Common Request Structure
+
+Each Request (both write and read) follows the pattern as shown above.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+
+- Message Type `type` is one of the following values:
+
+    - NODE = 0
+    - NYM = 1
+    - ATTRIB = 100
+    - SCHEMA = 101
+    - CLAIM_DEF = 102
+    - POOL_UPGRADE = 109
+    - NODE_UPGRADE = 110
+    - POOL_CONFIG = 111
+    - GET_TXN = 3
+    - GET_ATTR = 104
+    - GET_NYM = 105
+    - GET_SCHEMA = 107
+    - GET_CLAIM_DEF = 108 
+
+- `metadata` (dict):
+
+    Metadata coming with the Request and saving in the transaction as is (if this is a write request).
+
+    - `from` (base58-encoded string):
+         Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+         for 16 or 32 bit DID value.
+         It must be present on Ledger for write requests and can be any value for read requests.
+         
+         It may differ from `did` field for some of requests (for example NYM), where `did` is a 
+         target identifier (for example, a newly created DID identifier).
+         
+         *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+         
+    - `reqId` (integer): 
+        Unique ID number of the request with transaction.
+        
+- Please find the format of each request-specific data for each type of request below.
+
+## Common Reply Structure
+
+Each Write/Read Reply follows the pattern as shown above.
+
+```
+{
+    ""type"": REPLY,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        ""results"": [
+            ""result"": {
+                <result>
+            },
+            
+            ""multiSignature"": {
+                ""type"": <...>,
+                ""value"": <...>,
+                ""from"": <...>,
+                ""serialization"": <...>,
+                ""signedState"": <...>
+            }, 
+        
+            ""stateProof"": <...>,
+            ""auditProof"": <...>, 
+        ]
+    },
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+where `multiSignature`'s `signedState` is a serialized value having the following form:",233,2018-05-17 17:09:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189033814,https://github.com/hyperledger/indy-node/pull/536#discussion_r189033814,lovesh
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"This is the  ""ledgerMetadata"" + ""stateMetadata"" as mentioned below.
Other data is not part of this and is in <result> above.",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 07:23:24,189182669,"@@ -0,0 +1,1941 @@
+# Requests
+* [Common Message Structure](#common-message-structure)
+* [Signed Message Structure](#signed-message-structure)
+* [Common Request Structure](#common-request-structure)
+* [Common Reply Structure](#common-reply-structure)
+* [Command Reply Structure](#command-reply-structure)
+* [ACK Structure](#ack-structure)
+* [NACK Structure](#nack-structure)
+* [Reject Structure](#reject-structure)
+* [Write Requests](#write-requests)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    * [NODE](#node)
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+* [Read Requests](#read-requests)
+
+    * [GET_NYM](#get_nym)    
+    * [GET_ATTRIB](#get_attrib)    
+    * [GET_SCHEMA](#get_schema)
+    * [GET_CLAIM_DEF](#get_claim_def)
+    * [GET_TXN](#get_txn)
+    
+This doc is about supported client""s Request (both write and read ones).
+If you are interested in transactions and their representation on the Ledger (that is internal one),
+then have a look at [transactions](transactions.md).
+
+[indy-sdk](https://github.com/hyperledger/indy-sdk) expects the format as specified below.
+
+See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions.
+
+
+## Base Client-to-Node and Node-to-Node serialization 
+
+The main Client-to-Node and Node-to-Node envelope is serialized in MsgPack format.
+
+## Common Message Structure
+
+This is a common structure for ALL messages (both Node-to-Node and Client-to-Node).
+
+```
+    ""type"": <...>,
+    ""protocolVersion"": <...>,
+    ""ver"": 1,
+    
+    ""data"": {
+        ""ver"": 1,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        <msg-specific fields>
+    },
+    
+    ""pluginData"": {
+        <plugin-specific-fields>
+    }
+```
+- `type` (enum integer): 
+ 
+    Msg type.
+    
+- `protocolVersion` (integer; optional): 
+
+    The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+    Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+    between clients and nodes.     
+
+- `ver` (integer, optional):
+
+    Data/Metdata version.
+
+- `data` (dict):
+
+    Message-specific data.
+
+- `metadata` (dict):
+
+    Message-specific metadata.
+
+- `pluginData` (dict):
+
+    Plugin-specific data.
+
+## Signed Message Structure
+
+A message (see above) can be wrapped into a Signed Message envelope.
+All write requests must be signed.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    
+    ""signature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>,
+        ],
+        ""threshold"": <...>
+    },
+    
+    ""serialization"": <...>,
+    ""msg"": <serialized-msg>
+}
+```
+- `signature` (dict):
+
+    Submitter's signature over serialized `msg` field.
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+    
+- `serialization` (string enum, optional):
+
+    Defines how the `msg` is serialized
+     - JSON: json
+     - MSG_PACK: msgpack
+        
+- `msg` (dict):
+    
+    Serialized message.
+    
+    
+## Common Request Structure
+
+Each Request (both write and read) follows the pattern as shown above.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+
+- Message Type `type` is one of the following values:
+
+    - NODE = 0
+    - NYM = 1
+    - ATTRIB = 100
+    - SCHEMA = 101
+    - CLAIM_DEF = 102
+    - POOL_UPGRADE = 109
+    - NODE_UPGRADE = 110
+    - POOL_CONFIG = 111
+    - GET_TXN = 3
+    - GET_ATTR = 104
+    - GET_NYM = 105
+    - GET_SCHEMA = 107
+    - GET_CLAIM_DEF = 108 
+
+- `metadata` (dict):
+
+    Metadata coming with the Request and saving in the transaction as is (if this is a write request).
+
+    - `from` (base58-encoded string):
+         Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+         for 16 or 32 bit DID value.
+         It must be present on Ledger for write requests and can be any value for read requests.
+         
+         It may differ from `did` field for some of requests (for example NYM), where `did` is a 
+         target identifier (for example, a newly created DID identifier).
+         
+         *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+         
+    - `reqId` (integer): 
+        Unique ID number of the request with transaction.
+        
+- Please find the format of each request-specific data for each type of request below.
+
+## Common Reply Structure
+
+Each Write/Read Reply follows the pattern as shown above.
+
+```
+{
+    ""type"": REPLY,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        ""results"": [
+            ""result"": {
+                <result>
+            },
+            
+            ""multiSignature"": {
+                ""type"": <...>,
+                ""value"": <...>,
+                ""from"": <...>,
+                ""serialization"": <...>,
+                ""signedState"": <...>
+            }, 
+        
+            ""stateProof"": <...>,
+            ""auditProof"": <...>, 
+        ]
+    },
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+where `multiSignature`'s `signedState` is a serialized value having the following form:",233,2018-05-18 07:23:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189182669,https://github.com/hyperledger/indy-node/pull/536#discussion_r189182669,ashcherbakov
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"Ok, can you point out where is the data that is serialised for verifying the proof?",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 14:30:54,189287756,"@@ -0,0 +1,1941 @@
+# Requests
+* [Common Message Structure](#common-message-structure)
+* [Signed Message Structure](#signed-message-structure)
+* [Common Request Structure](#common-request-structure)
+* [Common Reply Structure](#common-reply-structure)
+* [Command Reply Structure](#command-reply-structure)
+* [ACK Structure](#ack-structure)
+* [NACK Structure](#nack-structure)
+* [Reject Structure](#reject-structure)
+* [Write Requests](#write-requests)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    * [NODE](#node)
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+* [Read Requests](#read-requests)
+
+    * [GET_NYM](#get_nym)    
+    * [GET_ATTRIB](#get_attrib)    
+    * [GET_SCHEMA](#get_schema)
+    * [GET_CLAIM_DEF](#get_claim_def)
+    * [GET_TXN](#get_txn)
+    
+This doc is about supported client""s Request (both write and read ones).
+If you are interested in transactions and their representation on the Ledger (that is internal one),
+then have a look at [transactions](transactions.md).
+
+[indy-sdk](https://github.com/hyperledger/indy-sdk) expects the format as specified below.
+
+See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions.
+
+
+## Base Client-to-Node and Node-to-Node serialization 
+
+The main Client-to-Node and Node-to-Node envelope is serialized in MsgPack format.
+
+## Common Message Structure
+
+This is a common structure for ALL messages (both Node-to-Node and Client-to-Node).
+
+```
+    ""type"": <...>,
+    ""protocolVersion"": <...>,
+    ""ver"": 1,
+    
+    ""data"": {
+        ""ver"": 1,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        <msg-specific fields>
+    },
+    
+    ""pluginData"": {
+        <plugin-specific-fields>
+    }
+```
+- `type` (enum integer): 
+ 
+    Msg type.
+    
+- `protocolVersion` (integer; optional): 
+
+    The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+    Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+    between clients and nodes.     
+
+- `ver` (integer, optional):
+
+    Data/Metdata version.
+
+- `data` (dict):
+
+    Message-specific data.
+
+- `metadata` (dict):
+
+    Message-specific metadata.
+
+- `pluginData` (dict):
+
+    Plugin-specific data.
+
+## Signed Message Structure
+
+A message (see above) can be wrapped into a Signed Message envelope.
+All write requests must be signed.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    
+    ""signature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>,
+        ],
+        ""threshold"": <...>
+    },
+    
+    ""serialization"": <...>,
+    ""msg"": <serialized-msg>
+}
+```
+- `signature` (dict):
+
+    Submitter's signature over serialized `msg` field.
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+    
+- `serialization` (string enum, optional):
+
+    Defines how the `msg` is serialized
+     - JSON: json
+     - MSG_PACK: msgpack
+        
+- `msg` (dict):
+    
+    Serialized message.
+    
+    
+## Common Request Structure
+
+Each Request (both write and read) follows the pattern as shown above.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+
+- Message Type `type` is one of the following values:
+
+    - NODE = 0
+    - NYM = 1
+    - ATTRIB = 100
+    - SCHEMA = 101
+    - CLAIM_DEF = 102
+    - POOL_UPGRADE = 109
+    - NODE_UPGRADE = 110
+    - POOL_CONFIG = 111
+    - GET_TXN = 3
+    - GET_ATTR = 104
+    - GET_NYM = 105
+    - GET_SCHEMA = 107
+    - GET_CLAIM_DEF = 108 
+
+- `metadata` (dict):
+
+    Metadata coming with the Request and saving in the transaction as is (if this is a write request).
+
+    - `from` (base58-encoded string):
+         Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+         for 16 or 32 bit DID value.
+         It must be present on Ledger for write requests and can be any value for read requests.
+         
+         It may differ from `did` field for some of requests (for example NYM), where `did` is a 
+         target identifier (for example, a newly created DID identifier).
+         
+         *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+         
+    - `reqId` (integer): 
+        Unique ID number of the request with transaction.
+        
+- Please find the format of each request-specific data for each type of request below.
+
+## Common Reply Structure
+
+Each Write/Read Reply follows the pattern as shown above.
+
+```
+{
+    ""type"": REPLY,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        ""results"": [
+            ""result"": {
+                <result>
+            },
+            
+            ""multiSignature"": {
+                ""type"": <...>,
+                ""value"": <...>,
+                ""from"": <...>,
+                ""serialization"": <...>,
+                ""signedState"": <...>
+            }, 
+        
+            ""stateProof"": <...>,
+            ""auditProof"": <...>, 
+        ]
+    },
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+where `multiSignature`'s `signedState` is a serialized value having the following form:",233,2018-05-18 14:30:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189287756,https://github.com/hyperledger/indy-node/pull/536#discussion_r189287756,lovesh
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"Data used to verify BLS multisig is in `signedState `
Data used to verify state proof (I think you mean the real result for the get request including key and value in state trie) is in <result>.",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 15:59:23,189316502,"@@ -0,0 +1,1941 @@
+# Requests
+* [Common Message Structure](#common-message-structure)
+* [Signed Message Structure](#signed-message-structure)
+* [Common Request Structure](#common-request-structure)
+* [Common Reply Structure](#common-reply-structure)
+* [Command Reply Structure](#command-reply-structure)
+* [ACK Structure](#ack-structure)
+* [NACK Structure](#nack-structure)
+* [Reject Structure](#reject-structure)
+* [Write Requests](#write-requests)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    * [NODE](#node)
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+* [Read Requests](#read-requests)
+
+    * [GET_NYM](#get_nym)    
+    * [GET_ATTRIB](#get_attrib)    
+    * [GET_SCHEMA](#get_schema)
+    * [GET_CLAIM_DEF](#get_claim_def)
+    * [GET_TXN](#get_txn)
+    
+This doc is about supported client""s Request (both write and read ones).
+If you are interested in transactions and their representation on the Ledger (that is internal one),
+then have a look at [transactions](transactions.md).
+
+[indy-sdk](https://github.com/hyperledger/indy-sdk) expects the format as specified below.
+
+See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions.
+
+
+## Base Client-to-Node and Node-to-Node serialization 
+
+The main Client-to-Node and Node-to-Node envelope is serialized in MsgPack format.
+
+## Common Message Structure
+
+This is a common structure for ALL messages (both Node-to-Node and Client-to-Node).
+
+```
+    ""type"": <...>,
+    ""protocolVersion"": <...>,
+    ""ver"": 1,
+    
+    ""data"": {
+        ""ver"": 1,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        <msg-specific fields>
+    },
+    
+    ""pluginData"": {
+        <plugin-specific-fields>
+    }
+```
+- `type` (enum integer): 
+ 
+    Msg type.
+    
+- `protocolVersion` (integer; optional): 
+
+    The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+    Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+    between clients and nodes.     
+
+- `ver` (integer, optional):
+
+    Data/Metdata version.
+
+- `data` (dict):
+
+    Message-specific data.
+
+- `metadata` (dict):
+
+    Message-specific metadata.
+
+- `pluginData` (dict):
+
+    Plugin-specific data.
+
+## Signed Message Structure
+
+A message (see above) can be wrapped into a Signed Message envelope.
+All write requests must be signed.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    
+    ""signature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>,
+        ],
+        ""threshold"": <...>
+    },
+    
+    ""serialization"": <...>,
+    ""msg"": <serialized-msg>
+}
+```
+- `signature` (dict):
+
+    Submitter's signature over serialized `msg` field.
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+    
+- `serialization` (string enum, optional):
+
+    Defines how the `msg` is serialized
+     - JSON: json
+     - MSG_PACK: msgpack
+        
+- `msg` (dict):
+    
+    Serialized message.
+    
+    
+## Common Request Structure
+
+Each Request (both write and read) follows the pattern as shown above.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+
+- Message Type `type` is one of the following values:
+
+    - NODE = 0
+    - NYM = 1
+    - ATTRIB = 100
+    - SCHEMA = 101
+    - CLAIM_DEF = 102
+    - POOL_UPGRADE = 109
+    - NODE_UPGRADE = 110
+    - POOL_CONFIG = 111
+    - GET_TXN = 3
+    - GET_ATTR = 104
+    - GET_NYM = 105
+    - GET_SCHEMA = 107
+    - GET_CLAIM_DEF = 108 
+
+- `metadata` (dict):
+
+    Metadata coming with the Request and saving in the transaction as is (if this is a write request).
+
+    - `from` (base58-encoded string):
+         Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+         for 16 or 32 bit DID value.
+         It must be present on Ledger for write requests and can be any value for read requests.
+         
+         It may differ from `did` field for some of requests (for example NYM), where `did` is a 
+         target identifier (for example, a newly created DID identifier).
+         
+         *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+         
+    - `reqId` (integer): 
+        Unique ID number of the request with transaction.
+        
+- Please find the format of each request-specific data for each type of request below.
+
+## Common Reply Structure
+
+Each Write/Read Reply follows the pattern as shown above.
+
+```
+{
+    ""type"": REPLY,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        ""results"": [
+            ""result"": {
+                <result>
+            },
+            
+            ""multiSignature"": {
+                ""type"": <...>,
+                ""value"": <...>,
+                ""from"": <...>,
+                ""serialization"": <...>,
+                ""signedState"": <...>
+            }, 
+        
+            ""stateProof"": <...>,
+            ""auditProof"": <...>, 
+        ]
+    },
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+where `multiSignature`'s `signedState` is a serialized value having the following form:",233,2018-05-18 15:59:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189316502,https://github.com/hyperledger/indy-node/pull/536#discussion_r189316502,ashcherbakov
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"> Data used to verify state proof (I think you mean the real result for the get request including key and value in state trie) is in .

In what?",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 16:23:53,189323193,"@@ -0,0 +1,1941 @@
+# Requests
+* [Common Message Structure](#common-message-structure)
+* [Signed Message Structure](#signed-message-structure)
+* [Common Request Structure](#common-request-structure)
+* [Common Reply Structure](#common-reply-structure)
+* [Command Reply Structure](#command-reply-structure)
+* [ACK Structure](#ack-structure)
+* [NACK Structure](#nack-structure)
+* [Reject Structure](#reject-structure)
+* [Write Requests](#write-requests)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    * [NODE](#node)
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+* [Read Requests](#read-requests)
+
+    * [GET_NYM](#get_nym)    
+    * [GET_ATTRIB](#get_attrib)    
+    * [GET_SCHEMA](#get_schema)
+    * [GET_CLAIM_DEF](#get_claim_def)
+    * [GET_TXN](#get_txn)
+    
+This doc is about supported client""s Request (both write and read ones).
+If you are interested in transactions and their representation on the Ledger (that is internal one),
+then have a look at [transactions](transactions.md).
+
+[indy-sdk](https://github.com/hyperledger/indy-sdk) expects the format as specified below.
+
+See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions.
+
+
+## Base Client-to-Node and Node-to-Node serialization 
+
+The main Client-to-Node and Node-to-Node envelope is serialized in MsgPack format.
+
+## Common Message Structure
+
+This is a common structure for ALL messages (both Node-to-Node and Client-to-Node).
+
+```
+    ""type"": <...>,
+    ""protocolVersion"": <...>,
+    ""ver"": 1,
+    
+    ""data"": {
+        ""ver"": 1,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        <msg-specific fields>
+    },
+    
+    ""pluginData"": {
+        <plugin-specific-fields>
+    }
+```
+- `type` (enum integer): 
+ 
+    Msg type.
+    
+- `protocolVersion` (integer; optional): 
+
+    The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+    Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+    between clients and nodes.     
+
+- `ver` (integer, optional):
+
+    Data/Metdata version.
+
+- `data` (dict):
+
+    Message-specific data.
+
+- `metadata` (dict):
+
+    Message-specific metadata.
+
+- `pluginData` (dict):
+
+    Plugin-specific data.
+
+## Signed Message Structure
+
+A message (see above) can be wrapped into a Signed Message envelope.
+All write requests must be signed.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    
+    ""signature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>,
+        ],
+        ""threshold"": <...>
+    },
+    
+    ""serialization"": <...>,
+    ""msg"": <serialized-msg>
+}
+```
+- `signature` (dict):
+
+    Submitter's signature over serialized `msg` field.
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+    
+- `serialization` (string enum, optional):
+
+    Defines how the `msg` is serialized
+     - JSON: json
+     - MSG_PACK: msgpack
+        
+- `msg` (dict):
+    
+    Serialized message.
+    
+    
+## Common Request Structure
+
+Each Request (both write and read) follows the pattern as shown above.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+
+- Message Type `type` is one of the following values:
+
+    - NODE = 0
+    - NYM = 1
+    - ATTRIB = 100
+    - SCHEMA = 101
+    - CLAIM_DEF = 102
+    - POOL_UPGRADE = 109
+    - NODE_UPGRADE = 110
+    - POOL_CONFIG = 111
+    - GET_TXN = 3
+    - GET_ATTR = 104
+    - GET_NYM = 105
+    - GET_SCHEMA = 107
+    - GET_CLAIM_DEF = 108 
+
+- `metadata` (dict):
+
+    Metadata coming with the Request and saving in the transaction as is (if this is a write request).
+
+    - `from` (base58-encoded string):
+         Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+         for 16 or 32 bit DID value.
+         It must be present on Ledger for write requests and can be any value for read requests.
+         
+         It may differ from `did` field for some of requests (for example NYM), where `did` is a 
+         target identifier (for example, a newly created DID identifier).
+         
+         *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+         
+    - `reqId` (integer): 
+        Unique ID number of the request with transaction.
+        
+- Please find the format of each request-specific data for each type of request below.
+
+## Common Reply Structure
+
+Each Write/Read Reply follows the pattern as shown above.
+
+```
+{
+    ""type"": REPLY,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        ""results"": [
+            ""result"": {
+                <result>
+            },
+            
+            ""multiSignature"": {
+                ""type"": <...>,
+                ""value"": <...>,
+                ""from"": <...>,
+                ""serialization"": <...>,
+                ""signedState"": <...>
+            }, 
+        
+            ""stateProof"": <...>,
+            ""auditProof"": <...>, 
+        ]
+    },
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+where `multiSignature`'s `signedState` is a serialized value having the following form:",233,2018-05-18 16:23:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189323193,https://github.com/hyperledger/indy-node/pull/536#discussion_r189323193,lovesh
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,Why we need `from` again here? It would be same as `txn.metadata.from`. `txn.metadata.from` specifies the author(s) of the transaction and i am not seeing the case where a txn will have signatures from non-authors. We should remove `from` from `txn.metadata`,3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 22:04:36,189403196,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {
+        ""type"": <...>,
+        ""protocolVersion"": <...>,
+        
+        ""data"": {
+            ""ver"": <...>,
+            <txn-specific fields>
+        },
+        
+        ""metadata"": {
+            ""reqId"": <...>,
+            ""from"": <...>
+        },
+    },
+    ""txnMetadata"": {
+        ""ver"": <...>,
+        ""creationTime"": <...>,
+        ""seqNo"": <...>,  
+    },
+    ""reqSignature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,",79,2018-05-18 22:25:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189403196,https://github.com/hyperledger/indy-node/pull/536#discussion_r189403196,lovesh
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"`values` is not valid json. It should be an object since it has keys. But we need to support txns with multiple signatures so we need to make it an array of objects, like this
```
values: [
    {
        from: <id1>,
        signature: <sig1>
    },
    {
        from: <id2>,
        signature: <sig2>
    },
    .....
]
```",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 22:11:31,189404202,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {
+        ""type"": <...>,
+        ""protocolVersion"": <...>,
+        
+        ""data"": {
+            ""ver"": <...>,
+            <txn-specific fields>
+        },
+        
+        ""metadata"": {
+            ""reqId"": <...>,
+            ""from"": <...>
+        },
+    },
+    ""txnMetadata"": {
+        ""ver"": <...>,
+        ""creationTime"": <...>,
+        ""seqNo"": <...>,  
+    },
+    ""reqSignature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [",78,2018-05-18 22:25:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189404202,https://github.com/hyperledger/indy-node/pull/536#discussion_r189404202,lovesh
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"Its not functionally wrong, but `txn` under transaction seems odd, maybe call it `payload`",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 22:27:28,189406400,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {",56,2018-05-18 22:27:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189406400,https://github.com/hyperledger/indy-node/pull/536#discussion_r189406400,lovesh
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,A submission could be submitted by a trust anchor on behalf of a DID owner in which case knowing who submitted the transaction and which DID the transaction is about.,3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 22:29:22,189406644,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {
+        ""type"": <...>,
+        ""protocolVersion"": <...>,
+        
+        ""data"": {
+            ""ver"": <...>,
+            <txn-specific fields>
+        },
+        
+        ""metadata"": {
+            ""reqId"": <...>,
+            ""from"": <...>
+        },
+    },
+    ""txnMetadata"": {
+        ""ver"": <...>,
+        ""creationTime"": <...>,
+        ""seqNo"": <...>,  
+    },
+    ""reqSignature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,",79,2018-05-18 22:29:22,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189406644,https://github.com/hyperledger/indy-node/pull/536#discussion_r189406644,kdenhartog
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"I agree with the sentiment of needing to modify the ""values"" key to an array such that it can accept a multisig. Would we also need to move ver (I think this means verkey) into this object to support this new format? Also, symantically I'd prefer that we refer to them as signatures instead of values, but it's not incredibly important because it's stated above it.",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 22:36:12,189407503,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {
+        ""type"": <...>,
+        ""protocolVersion"": <...>,
+        
+        ""data"": {
+            ""ver"": <...>,
+            <txn-specific fields>
+        },
+        
+        ""metadata"": {
+            ""reqId"": <...>,
+            ""from"": <...>
+        },
+    },
+    ""txnMetadata"": {
+        ""ver"": <...>,
+        ""creationTime"": <...>,
+        ""seqNo"": <...>,  
+    },
+    ""reqSignature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [",78,2018-05-18 22:36:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189407503,https://github.com/hyperledger/indy-node/pull/536#discussion_r189407503,kdenhartog
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"+1 to switching this to payload, but again comes down to semantics, so it's more of a preference than a necessity. ",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 22:39:11,189407872,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {",56,2018-05-18 22:39:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189407872,https://github.com/hyperledger/indy-node/pull/536#discussion_r189407872,kdenhartog
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"Can you give an example of `id`? If `did1` is creating (`did1` is a trust anchor) `did2`, what is `id`? Hash of `did1` or hash of `did2`? Also when do you need to look at a NYM in ledger txn and then go to state trie? And if you need state key, do we need to store the key, cant we store a reference to a mechanism like `1->sha256`, `2->sha3`, etc. Also if we changed our NYM to state key conversion mechanism, wouldn't it be reflected in the `protocolVersion` or txn version? ",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-18 22:41:08,189408353,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {
+        ""type"": <...>,
+        ""protocolVersion"": <...>,
+        
+        ""data"": {
+            ""ver"": <...>,
+            <txn-specific fields>
+        },
+        
+        ""metadata"": {
+            ""reqId"": <...>,
+            ""from"": <...>
+        },
+    },
+    ""txnMetadata"": {
+        ""ver"": <...>,
+        ""creationTime"": <...>,
+        ""seqNo"": <...>,  
+    },
+    ""reqSignature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>
+        ]
+    }
+}
+```
+- `txn` (dict):
+    
+    Transaction-specific payload (data)
+
+    - `type` (enum number as integer): 
+    
+        Supported transaction type:
+        
+        - NODE = 0
+        - NYM = 1
+        - ATTRIB = 100
+        - SCHEMA = 101
+        - CLAIM_DEF = 102
+        - POOL_UPGRADE = 109
+        - NODE_UPGRADE = 110
+        - POOL_CONFIG = 111
+
+    - `protocolVersion` (integer; optional): 
+    
+        The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+        Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+        between clients and nodes.     
+     
+    - `ver` (integer):
+    
+        Transaction version to be able to evolve content.
+        The content of `data` and `metadata` may depend on the version.       
+ 
+    - `data` (dict):
+
+        Transaction-specific data fields (see next sections for each transaction description).  
+       
+    - `metadata` (dict):
+    
+        Metadata as came from the Request.
+
+        - `from` (base58-encoded string):
+             Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+             for 16 or 32 bit DID value.
+             It may differ from `did` field for some of transaction (for example NYM), where `did` is a 
+             target identifier (for example, a newly created DID identifier).
+             
+             *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+             
+        - `reqId` (integer): 
+            Unique ID number of the request with transaction.
+  
+    - `txnMetadata` (dict):
+    
+        Metadata attached to the transaction.    
+        
+         - `version` (integer):
+            Transaction version to be able to evolve `txnMetadata`.
+            The content of `txnMetadata` may depend on the version.  
+        
+        - `creationTime` (integer as POSIX timestamp): 
+            The time when transaction was written to the Ledger as POSIX timestamp.
+            
+        - `seqNo` (integer):
+            A unique sequence number of the transaction on Ledger
+  
+- `reqSignature` (dict):
+
+    Submitter's signature over request with transaction (`txn` field).
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+
+Please note that all these metadata fields may be absent for genesis transactions.
+
+## Domain Ledger
+
+#### NYM
+Creates a new NYM record for a specific user, trust anchor, steward or trustee.
+Note that only trustees and stewards can create new trust anchors and trustee can be created only by other trusties (see [roles](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0)).
+
+The transaction can be used for 
+creation of new DIDs, setting and rotation of verification key, setting and changing of roles.
+
+- `id` (string):
+
+    Nym's ID as State Trie key (address or descriptive data). It must be unique within the ledger. ",176,2018-05-18 22:46:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189408353,https://github.com/hyperledger/indy-node/pull/536#discussion_r189408353,lovesh
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"Sorry, in `<result>`",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-21 07:02:29,189508624,"@@ -0,0 +1,1941 @@
+# Requests
+* [Common Message Structure](#common-message-structure)
+* [Signed Message Structure](#signed-message-structure)
+* [Common Request Structure](#common-request-structure)
+* [Common Reply Structure](#common-reply-structure)
+* [Command Reply Structure](#command-reply-structure)
+* [ACK Structure](#ack-structure)
+* [NACK Structure](#nack-structure)
+* [Reject Structure](#reject-structure)
+* [Write Requests](#write-requests)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    * [NODE](#node)
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+* [Read Requests](#read-requests)
+
+    * [GET_NYM](#get_nym)    
+    * [GET_ATTRIB](#get_attrib)    
+    * [GET_SCHEMA](#get_schema)
+    * [GET_CLAIM_DEF](#get_claim_def)
+    * [GET_TXN](#get_txn)
+    
+This doc is about supported client""s Request (both write and read ones).
+If you are interested in transactions and their representation on the Ledger (that is internal one),
+then have a look at [transactions](transactions.md).
+
+[indy-sdk](https://github.com/hyperledger/indy-sdk) expects the format as specified below.
+
+See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions.
+
+
+## Base Client-to-Node and Node-to-Node serialization 
+
+The main Client-to-Node and Node-to-Node envelope is serialized in MsgPack format.
+
+## Common Message Structure
+
+This is a common structure for ALL messages (both Node-to-Node and Client-to-Node).
+
+```
+    ""type"": <...>,
+    ""protocolVersion"": <...>,
+    ""ver"": 1,
+    
+    ""data"": {
+        ""ver"": 1,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        <msg-specific fields>
+    },
+    
+    ""pluginData"": {
+        <plugin-specific-fields>
+    }
+```
+- `type` (enum integer): 
+ 
+    Msg type.
+    
+- `protocolVersion` (integer; optional): 
+
+    The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+    Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+    between clients and nodes.     
+
+- `ver` (integer, optional):
+
+    Data/Metdata version.
+
+- `data` (dict):
+
+    Message-specific data.
+
+- `metadata` (dict):
+
+    Message-specific metadata.
+
+- `pluginData` (dict):
+
+    Plugin-specific data.
+
+## Signed Message Structure
+
+A message (see above) can be wrapped into a Signed Message envelope.
+All write requests must be signed.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    
+    ""signature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>,
+        ],
+        ""threshold"": <...>
+    },
+    
+    ""serialization"": <...>,
+    ""msg"": <serialized-msg>
+}
+```
+- `signature` (dict):
+
+    Submitter's signature over serialized `msg` field.
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+    
+- `serialization` (string enum, optional):
+
+    Defines how the `msg` is serialized
+     - JSON: json
+     - MSG_PACK: msgpack
+        
+- `msg` (dict):
+    
+    Serialized message.
+    
+    
+## Common Request Structure
+
+Each Request (both write and read) follows the pattern as shown above.
+
+```
+{
+    ""type"": <...>,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        <msg-specific fields>
+    },
+    
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+
+- Message Type `type` is one of the following values:
+
+    - NODE = 0
+    - NYM = 1
+    - ATTRIB = 100
+    - SCHEMA = 101
+    - CLAIM_DEF = 102
+    - POOL_UPGRADE = 109
+    - NODE_UPGRADE = 110
+    - POOL_CONFIG = 111
+    - GET_TXN = 3
+    - GET_ATTR = 104
+    - GET_NYM = 105
+    - GET_SCHEMA = 107
+    - GET_CLAIM_DEF = 108 
+
+- `metadata` (dict):
+
+    Metadata coming with the Request and saving in the transaction as is (if this is a write request).
+
+    - `from` (base58-encoded string):
+         Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+         for 16 or 32 bit DID value.
+         It must be present on Ledger for write requests and can be any value for read requests.
+         
+         It may differ from `did` field for some of requests (for example NYM), where `did` is a 
+         target identifier (for example, a newly created DID identifier).
+         
+         *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+         
+    - `reqId` (integer): 
+        Unique ID number of the request with transaction.
+        
+- Please find the format of each request-specific data for each type of request below.
+
+## Common Reply Structure
+
+Each Write/Read Reply follows the pattern as shown above.
+
+```
+{
+    ""type"": REPLY,
+    ""ver"": <...>,
+    ""protocolVersion"": <...>,
+    
+    ""data"": {
+        ""ver"": <...>,
+        ""results"": [
+            ""result"": {
+                <result>
+            },
+            
+            ""multiSignature"": {
+                ""type"": <...>,
+                ""value"": <...>,
+                ""from"": <...>,
+                ""serialization"": <...>,
+                ""signedState"": <...>
+            }, 
+        
+            ""stateProof"": <...>,
+            ""auditProof"": <...>, 
+        ]
+    },
+    ""metadata"": {
+        ""reqId"": <...>,
+        ""from"": <...>,
+    },
+}
+```
+where `multiSignature`'s `signedState` is a serialized value having the following form:",233,2018-05-21 07:02:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189508624,https://github.com/hyperledger/indy-node/pull/536#discussion_r189508624,ashcherbakov
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"Yes, `payload` is probably better.",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-21 07:03:48,189508850,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {",56,2018-05-21 07:03:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189508850,https://github.com/hyperledger/indy-node/pull/536#discussion_r189508850,ashcherbakov
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"Yes, it's assumed to be as Lovesh provided, just a typo in the doc.",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-21 07:05:46,189509185,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {
+        ""type"": <...>,
+        ""protocolVersion"": <...>,
+        
+        ""data"": {
+            ""ver"": <...>,
+            <txn-specific fields>
+        },
+        
+        ""metadata"": {
+            ""reqId"": <...>,
+            ""from"": <...>
+        },
+    },
+    ""txnMetadata"": {
+        ""ver"": <...>,
+        ""creationTime"": <...>,
+        ""seqNo"": <...>,  
+    },
+    ""reqSignature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [",78,2018-05-21 07:05:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189509185,https://github.com/hyperledger/indy-node/pull/536#discussion_r189509185,ashcherbakov
https://github.com/hyperledger/indy-node/pull/536,https://github.com/hyperledger/indy-node/pull/536,"We should use a general `txnId` instead of `id`. It can be used to uniquely identify a txn in the state. So, it can contain a key in the state trie.",3e37f16d52c3e51baba3ec2538b530a40bc535e0,2018-05-21 07:08:27,189509603,"@@ -0,0 +1,749 @@
+# Transactions
+
+* [General Information](#general-information)
+* [Genesis Transactions](#genesis-transactions)
+* [Common Structure](#common-structure)
+* [Domain Ledger](#domain-ledger)
+
+    * [NYM](#nym)    
+    * [ATTRIB](#attrib)    
+    * [SCHEMA](#schema)
+    * [CLAIM_DEF](#claim_def)
+    
+* [Pool Ledger](#pool-ledger)    
+    * [NODE](#node)
+    
+* [Config Ledger](#config-ledger)    
+    * [POOL_UPGRADE](#pool_upgrade)
+    * [NODE_UPGRADE](#node_upgrade)
+    * [POOL_CONFIG](#pool_config)
+
+## General Information
+
+This doc is about supported transactions and their representation on the Ledger (that is internal one).
+If you are interested in the format of client's Request (both write and read ones), then have a look at [requests](requests.md).
+
+- All transactions are stored in a distributed Ledger (replicated on all Nodes) 
+- The ledger is based on Merkle Tree
+- The ledger consists of two things:
+    - transactions log as a sequence of key-value pairs 
+where key is a sequence number of the transaction and value is the serialized transaction
+    - merkle tree (where hashes for leaves and nodes are persisted)
+- Each transaction has a sequence number (no gaps) - keys in transactions log
+- So, this can be considered as a blockchain where each block size equals to 1
+- There are multiple ledgers by default:
+    - *pool ledger*: transactions related to pool/network configuration (listing all nodes, their keys and addresses)
+    - *config ledger*: transactions for pool configuration plus transactions related to Pool Upgrade
+    - *domain ledger*: all main domain and application specific transactions (including NYM transactions for DID)
+- All transactions are serialized to MsgPack format
+- All transactions (both transaction log and merkle tree hash stores) are stored in LevelDB
+- One can use `read_ledger` script to get transactions for a specified ledger in a readable (JSON) format
+- See [roles and permissions](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0) on the roles and who can create each type of transactions
+
+Below you can find the format and description of all supported transactions.
+
+## Genesis Transactions
+As Indy is Public **Permissioned** blockchain, each ledger may have a number of pre-defined 
+transactions defining the Pool and the Network.
+- pool genesis transactions defining initial trusted Nodes in the Pool
+- domain genesis transactions defining initial trusted Trustees and Stewards
+
+## Common Structure
+Each transaction has the following structure containing of metadata values (common for all transaction types) and 
+transaction specific data:
+```
+{
+    ""txn"": {
+        ""type"": <...>,
+        ""protocolVersion"": <...>,
+        
+        ""data"": {
+            ""ver"": <...>,
+            <txn-specific fields>
+        },
+        
+        ""metadata"": {
+            ""reqId"": <...>,
+            ""from"": <...>
+        },
+    },
+    ""txnMetadata"": {
+        ""ver"": <...>,
+        ""creationTime"": <...>,
+        ""seqNo"": <...>,  
+    },
+    ""reqSignature"": {
+        ""type"": <...>,
+        ""ver"": <...>,
+        ""values"": [
+            ""from"": <...>,
+            ""value"": <...>
+        ]
+    }
+}
+```
+- `txn` (dict):
+    
+    Transaction-specific payload (data)
+
+    - `type` (enum number as integer): 
+    
+        Supported transaction type:
+        
+        - NODE = 0
+        - NYM = 1
+        - ATTRIB = 100
+        - SCHEMA = 101
+        - CLAIM_DEF = 102
+        - POOL_UPGRADE = 109
+        - NODE_UPGRADE = 110
+        - POOL_CONFIG = 111
+
+    - `protocolVersion` (integer; optional): 
+    
+        The version of client-to-node or node-to-node protocol. Each new version may introduce a new feature in Requests/Replies/Data.
+        Since clients and different Nodes may be at different versions, we need this field to support backward compatibility
+        between clients and nodes.     
+     
+    - `ver` (integer):
+    
+        Transaction version to be able to evolve content.
+        The content of `data` and `metadata` may depend on the version.       
+ 
+    - `data` (dict):
+
+        Transaction-specific data fields (see next sections for each transaction description).  
+       
+    - `metadata` (dict):
+    
+        Metadata as came from the Request.
+
+        - `from` (base58-encoded string):
+             Identifier (DID) of the transaction submitter (client who sent the transaction) as base58-encoded string
+             for 16 or 32 bit DID value.
+             It may differ from `did` field for some of transaction (for example NYM), where `did` is a 
+             target identifier (for example, a newly created DID identifier).
+             
+             *Example*: `from` is a DID of a Trust Anchor creating a new DID, and `did` is a newly created DID.
+             
+        - `reqId` (integer): 
+            Unique ID number of the request with transaction.
+  
+    - `txnMetadata` (dict):
+    
+        Metadata attached to the transaction.    
+        
+         - `version` (integer):
+            Transaction version to be able to evolve `txnMetadata`.
+            The content of `txnMetadata` may depend on the version.  
+        
+        - `creationTime` (integer as POSIX timestamp): 
+            The time when transaction was written to the Ledger as POSIX timestamp.
+            
+        - `seqNo` (integer):
+            A unique sequence number of the transaction on Ledger
+  
+- `reqSignature` (dict):
+
+    Submitter's signature over request with transaction (`txn` field).
+    
+    - `type` (string enum):
+        
+        - ED25519: ed25519 signature
+        - ED25519_MULTI: ed25519 signature in multisig case.
+    
+    - `values` (list): 
+        
+        - `from` (base58-encoded string):
+        Identifier (DID) of signer as base58-encoded string for 16 or 32 bit DID value.
+        
+        - `value` (base58-encoded string):
+         signature value
+
+Please note that all these metadata fields may be absent for genesis transactions.
+
+## Domain Ledger
+
+#### NYM
+Creates a new NYM record for a specific user, trust anchor, steward or trustee.
+Note that only trustees and stewards can create new trust anchors and trustee can be created only by other trusties (see [roles](https://docs.google.com/spreadsheets/d/1TWXF7NtBjSOaUIBeIH77SyZnawfo91cJ_ns4TR-wsq4/edit#gid=0)).
+
+The transaction can be used for 
+creation of new DIDs, setting and rotation of verification key, setting and changing of roles.
+
+- `id` (string):
+
+    Nym's ID as State Trie key (address or descriptive data). It must be unique within the ledger. ",176,2018-05-21 07:08:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/189509603,https://github.com/hyperledger/indy-node/pull/536#discussion_r189509603,ashcherbakov
https://github.com/hyperledger/indy-node/pull/531,https://github.com/hyperledger/indy-node/pull/531,This test should not be in the CLI folder,6eee1cd34575144d1440c09136a2050ed4d854d5,2018-01-26 08:28:12,164054159,"@@ -361,3 +364,18 @@ def test_send_different_nyms_succeeds_when_batched(
 
     do('send GET_NYM dest={dest}',
         mapper=parameters, expect=CURRENT_VERKEY_FOR_NYM, within=2)
+
+
+def test_nym_resend(looper, sdk_pool_handle, sdk_wallet_steward):",,2018-01-26 16:38:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/164054159,https://github.com/hyperledger/indy-node/pull/531#discussion_r164054159,ashcherbakov
https://github.com/hyperledger/indy-node/pull/531,https://github.com/hyperledger/indy-node/pull/531,Do we need this call at all? Doesn't `_validateExistingNym` already do similar validation based on `Authoriser`?,6eee1cd34575144d1440c09136a2050ed4d854d5,2018-01-26 08:33:22,164054967,"@@ -142,6 +138,10 @@ def _validateNym(self, req: Request):
         origin = req.identifier
         op = req.operation
 
+        s, reason = self.canNymRequestBeProcessed(origin, op)",,2018-01-26 16:38:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/164054967,https://github.com/hyperledger/indy-node/pull/531#discussion_r164054967,ashcherbakov
https://github.com/hyperledger/indy-node/pull/531,https://github.com/hyperledger/indy-node/pull/531,"Ok, moved to separate file.",6eee1cd34575144d1440c09136a2050ed4d854d5,2018-01-26 12:52:41,164103676,"@@ -361,3 +364,18 @@ def test_send_different_nyms_succeeds_when_batched(
 
     do('send GET_NYM dest={dest}',
         mapper=parameters, expect=CURRENT_VERKEY_FOR_NYM, within=2)
+
+
+def test_nym_resend(looper, sdk_pool_handle, sdk_wallet_steward):",,2018-01-26 16:38:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/164103676,https://github.com/hyperledger/indy-node/pull/531#discussion_r164103676,sergey-shilov
https://github.com/hyperledger/indy-node/pull/531,https://github.com/hyperledger/indy-node/pull/531,"Yeah, seems like it is double-check, have removed.",6eee1cd34575144d1440c09136a2050ed4d854d5,2018-01-26 12:55:54,164104268,"@@ -142,6 +138,10 @@ def _validateNym(self, req: Request):
         origin = req.identifier
         op = req.operation
 
+        s, reason = self.canNymRequestBeProcessed(origin, op)",,2018-01-26 16:38:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/164104268,https://github.com/hyperledger/indy-node/pull/531#discussion_r164104268,sergey-shilov
https://github.com/hyperledger/indy-node/pull/526,https://github.com/hyperledger/indy-node/pull/526,"Can you please format it as a script (using ""``` ```"")?",6c3b9b53dbd299a7bc859655ca0842352aadb11d,2018-01-18 08:10:53,162271907,"@@ -0,0 +1,155 @@
+# Node Monitoring Tools for Stewards
+
+* [Plugin Manager](#plugin-manager)
+  * [Events Emitted](#events-emitted)
+* [Email Plugin](#email-plugin)
+    * [Prerequisites](#prerequisites)
+    * [Install](#install)
+    * [Configuration](#configuration)
+    * [Email delivery frequency](#email-delivery-frequency)
+* [AWS SNS Plugin](#aws-sns-plugin)
+  * [Prerequisites](#prerequisites)
+  * [Setup](#setup)
+  * [Configuration](#configuration)
+  * [Events](#events)
+  * [Hints](#hints)
+  * [Example](#example)
+
+
+## Plugin Manager
+
+Currently, indy-node emits different events via the Plugin Manager when certain criteria are met. The Plugin Manager tries to import all pip packages which names start with ""sovrinnotifier*"". Each of these packages is required to expose `send_message`; interface which is used to pass the event with the associated message to the package for further handling.
+
+The Plugin Manager code is located at [here](https://github.com/hyperledger/indy-plenum/blob/master/plenum/server/notifier_plugin_manager.py#L23).
+
+### Events Emitted
+
+- .nodeRequestSpike : NodeRequestSuspiciousSpike
+- .clusterThroughputSpike : ClusterThroughputSuspiciousSpike
+- .clusterLatencyTooHigh : ClusterLatencyTooHigh
+- .nodeUpgradeScheduled : NodeUpgradeScheduled
+- .nodeUpgradeComplete : NodeUpgradeComplete
+- .nodeUpgradeFail :  NodeUpgradeFail
+- .poolUpgradeCancel :  PoolUpgradeCancel
+
+
+## Email Plugin
+
+### Prerequisites
+
+* SMTP server must be running on localhost.
+
+* Install SMTP server (if you don't have one already)
+
+The most simple way on Ubuntu is to use `sendmail`:
+
+`$ sudo apt-get install sendmail`
+
+To check that it's working execute:
+
+`echo ""Subject: sendmail test"" | sendmail -v youremail@example.com -f alert@noreply.com`
+
+If you get a email on your youremail@example.com then `sendmail` is working.
+
+### Install
+
+`$ pip3 install sovrinnotifieremail`
+
+`$ Add SOVRIN_NOTIFIER_EMAIL_RECIPIENTS=youremail@example.com to your /etc/environment`
+
+You are required to set system environment variable `SOVRIN_NOTIFIER_EMAIL_RECIPIENTS`.
+
+### Configuration
+
+The package depends on two environment variables:
+
+- `.SOVRIN_NOTIFIER_EMAIL_RECIPIENTS` (required)
+- `.SOVRIN_NOTIFIER_EMAIL_SENDER` (optional)
+
+**SOVRIN_NOTIFIER_EMAIL_RECIPIENTS**
+
+`SOVRIN_NOTIFIER_EMAIL_RECIPIENTS` should be a string in a format of:
+
+`recipient1@adress.com [optional list of events the recipient is going to get],recipient2@adress.com [event list]`
+
+If no list was provided the recipient is going to get notifications for all events. Example:
+
+`steward1@company.com event1 event2, steward2@company.com, steward3@company.com event3`
+
+This way steward1 is going to get notifications for event1 and event2, steward2 is going to get all possible notifications and steward3 is going to get notifications for event3 only.
+
+The current list of events can be found above.
+
+**SOVRIN_NOTIFIER_EMAIL_SENDER**
+
+By default every email notification is going to be from alert@noreply.com. You can change this by setting `SOVRIN_NOTIFIER_EMAIL_SENDER`. May be useful for email filters.
+
+### Email delivery frequency
+
+By default you will not get a email with the same topic more than once an hour. This is defined by `SILENCE_TIMEOUT`. It can be overridden by setting `SOVRIN_NOTIFIER_SILENCE_TIMEOUT` environment variable. Emails regarding update procedure are always delivered.
+
+
+## AWS SNS Plugin
+
+### Prerequisites
+
+- .A AWS SNS topic created with permissions to publish to it.
+- .A installed Sovrin Validator instance.
+
+### Setup
+
+Install the python package for sovrin-notifier-awssns. This should be only be installed using pip3.
+
+`pip3 install sovrinnotifierawssns`
+
+### Configuration
+
+To configure AWS Credentials you will need to know the values for: `aws_access_key_id` and `aws_secret_access_key`. Follow the steps documented here [Boto3 Configuring Credentials.](https://boto3.readthedocs.io/en/latest/guide/configuration.html#configuring-credentials)
+
+Use either of the following ways:
+
+- .Environment variables `AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY`
+- .Shared credential file (~/.aws/credentials)
+- .Boto2 config file (/etc/boto.cfg and ~/.boto)
+
+Configure AWS Region you will need to know the value where the SNS Topic is hosted e.g. us-west-1, us-west-2, sa-east-1
+
+To achieve this:
+
+- .Set a Environment variable AWS\_DEFAULT\_REGION
+- .Set region using file (~/.aws/config)
+
+Define environment variable `SOVRIN_NOTIFIER_AWSSNS_TOPICARN` on the Validator and set valid AWS SNS TopicARN as the value.
+
+### Events
+
+Events that cause a notification:
+
+* `NodeRequestSuspiciousSpike`
+* `ClusterThroughputSuspiciousSpike`
+* `ClusterLatencyTooHigh`
+* `NodeUpgradeScheduled`
+* `NodeUpgradeComplete`
+* `NodeUpgradeFail,`
+* `PoolUpgradeCancel`
+
+
+### Hints
+
+The home directory for the account that runs `sovrin-node.service` on a Validator is `/home/sovrin/`. So the aws credentials/config files must be created in `/home/sovrin/.aws` folder.
+
+To set an environment variable on the Validator you must add it to the file `/home/sovrin/.sovrin/sovrin.env` and restart the Validator. The TopicARN must be defined in this file.
+
+To restart the Validator on a Ubuntu system you must execute the command `sudo systemctl restart sovrin-node.service` while not logged in as a sovrin user.
+
+#### Example
+
+This simple script will complete the setup, assuming that the sovrinnotifierawssns package is already installed:
+
+``#!/bin/bash",,2018-01-23 15:53:18,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/162271907,https://github.com/hyperledger/indy-node/pull/526#discussion_r162271907,ashcherbakov
https://github.com/hyperledger/indy-node/pull/522,https://github.com/hyperledger/indy-node/pull/522,"An issuer should be allowed to have multiple claim definitions for the same schema, it's just that they need to be for different signature schemes",f730a0f84388d98565167105fe3b7a7ba09f2acb,2018-01-15 16:43:19,161568993,"@@ -214,6 +200,40 @@ def _validateAttrib(self, req: Request):
                 ""Only identity owner/guardian can add attribute ""
                 ""for that identity"")
 
+    def _validate_schema(self, req: Request):
+        # we can not add a Schema with already existent NAME and VERSION
+        # sine a Schema needs to be identified by seqNo
+        identifier = req.identifier
+        operation = req.operation
+        schema_name = operation[DATA][NAME]
+        schema_version = operation[DATA][VERSION]
+        schema, _, _, _ = self.getSchema(
+            author=identifier,
+            schemaName=schema_name,
+            schemaVersion=schema_version
+        )
+        if schema:
+            raise InvalidClientRequest(identifier, req.reqId,
+                                       '{} can have one and only one SCHEMA with '
+                                       'name {} and version {}'
+                                       .format(identifier, schema_name, schema_version))
+
+    def _validate_claim_def(self, req: Request):
+        # we can not add a Claim Def with existent ISSUER_DID
+        # sine a Claim Def needs to be identified by seqNo
+        identifier = req.identifier
+        operation = req.operation
+        schema_ref = operation[REF]
+        claim_def, _, _, _ = self.getClaimDef(",,2018-01-15 18:20:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/161568993,https://github.com/hyperledger/indy-node/pull/522#discussion_r161568993,lovesh
https://github.com/hyperledger/indy-node/pull/522,https://github.com/hyperledger/indy-node/pull/522,This should read 'signature scheme {} and schema ref {}',f730a0f84388d98565167105fe3b7a7ba09f2acb,2018-01-15 16:44:25,161569236,"@@ -214,6 +200,40 @@ def _validateAttrib(self, req: Request):
                 ""Only identity owner/guardian can add attribute ""
                 ""for that identity"")
 
+    def _validate_schema(self, req: Request):
+        # we can not add a Schema with already existent NAME and VERSION
+        # sine a Schema needs to be identified by seqNo
+        identifier = req.identifier
+        operation = req.operation
+        schema_name = operation[DATA][NAME]
+        schema_version = operation[DATA][VERSION]
+        schema, _, _, _ = self.getSchema(
+            author=identifier,
+            schemaName=schema_name,
+            schemaVersion=schema_version
+        )
+        if schema:
+            raise InvalidClientRequest(identifier, req.reqId,
+                                       '{} can have one and only one SCHEMA with '
+                                       'name {} and version {}'
+                                       .format(identifier, schema_name, schema_version))
+
+    def _validate_claim_def(self, req: Request):
+        # we can not add a Claim Def with existent ISSUER_DID
+        # sine a Claim Def needs to be identified by seqNo
+        identifier = req.identifier
+        operation = req.operation
+        schema_ref = operation[REF]
+        claim_def, _, _, _ = self.getClaimDef(
+            author=identifier,
+            schemaSeqNo=schema_ref
+        )
+        if claim_def:
+            raise InvalidClientRequest(identifier, req.reqId,
+                                       '{} can have one and only one CLAIM_DEF with '
+                                       'issuer DID (identifier) {} and schema ref {}'",,2018-01-15 18:20:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/161569236,https://github.com/hyperledger/indy-node/pull/522#discussion_r161569236,lovesh
https://github.com/hyperledger/indy-node/pull/522,https://github.com/hyperledger/indy-node/pull/522,Done,f730a0f84388d98565167105fe3b7a7ba09f2acb,2018-01-15 18:22:30,161588871,"@@ -214,6 +200,40 @@ def _validateAttrib(self, req: Request):
                 ""Only identity owner/guardian can add attribute ""
                 ""for that identity"")
 
+    def _validate_schema(self, req: Request):
+        # we can not add a Schema with already existent NAME and VERSION
+        # sine a Schema needs to be identified by seqNo
+        identifier = req.identifier
+        operation = req.operation
+        schema_name = operation[DATA][NAME]
+        schema_version = operation[DATA][VERSION]
+        schema, _, _, _ = self.getSchema(
+            author=identifier,
+            schemaName=schema_name,
+            schemaVersion=schema_version
+        )
+        if schema:
+            raise InvalidClientRequest(identifier, req.reqId,
+                                       '{} can have one and only one SCHEMA with '
+                                       'name {} and version {}'
+                                       .format(identifier, schema_name, schema_version))
+
+    def _validate_claim_def(self, req: Request):
+        # we can not add a Claim Def with existent ISSUER_DID
+        # sine a Claim Def needs to be identified by seqNo
+        identifier = req.identifier
+        operation = req.operation
+        schema_ref = operation[REF]
+        claim_def, _, _, _ = self.getClaimDef(",,2018-01-15 18:22:30,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/161588871,https://github.com/hyperledger/indy-node/pull/522#discussion_r161588871,ashcherbakov
https://github.com/hyperledger/indy-node/pull/522,https://github.com/hyperledger/indy-node/pull/522,Done,f730a0f84388d98565167105fe3b7a7ba09f2acb,2018-01-15 18:22:35,161588879,"@@ -214,6 +200,40 @@ def _validateAttrib(self, req: Request):
                 ""Only identity owner/guardian can add attribute ""
                 ""for that identity"")
 
+    def _validate_schema(self, req: Request):
+        # we can not add a Schema with already existent NAME and VERSION
+        # sine a Schema needs to be identified by seqNo
+        identifier = req.identifier
+        operation = req.operation
+        schema_name = operation[DATA][NAME]
+        schema_version = operation[DATA][VERSION]
+        schema, _, _, _ = self.getSchema(
+            author=identifier,
+            schemaName=schema_name,
+            schemaVersion=schema_version
+        )
+        if schema:
+            raise InvalidClientRequest(identifier, req.reqId,
+                                       '{} can have one and only one SCHEMA with '
+                                       'name {} and version {}'
+                                       .format(identifier, schema_name, schema_version))
+
+    def _validate_claim_def(self, req: Request):
+        # we can not add a Claim Def with existent ISSUER_DID
+        # sine a Claim Def needs to be identified by seqNo
+        identifier = req.identifier
+        operation = req.operation
+        schema_ref = operation[REF]
+        claim_def, _, _, _ = self.getClaimDef(
+            author=identifier,
+            schemaSeqNo=schema_ref
+        )
+        if claim_def:
+            raise InvalidClientRequest(identifier, req.reqId,
+                                       '{} can have one and only one CLAIM_DEF with '
+                                       'issuer DID (identifier) {} and schema ref {}'",,2018-01-15 18:22:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/161588879,https://github.com/hyperledger/indy-node/pull/522#discussion_r161588879,ashcherbakov
https://github.com/hyperledger/indy-node/pull/520,https://github.com/hyperledger/indy-node/pull/520,missing 's' at the end of file name,aeef96fc531bd22d87e8eb95a6912aba4b9055f3,2018-01-12 17:17:55,161278082,"@@ -94,5 +94,6 @@
              'scripts/init_bls_keys',
              'scripts/enable_bls',
              'scripts/create_dirs.sh',
-             'scripts/indy_old_cli_export_dids']
+             'scripts/indy_old_cli_export_dids',
+             'scripts/setup_indy_node_iptable']",,2018-01-15 12:51:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/161278082,https://github.com/hyperledger/indy-node/pull/520#discussion_r161278082,ashcherbakov
https://github.com/hyperledger/indy-node/pull/506,https://github.com/hyperledger/indy-node/pull/506,Probably we can rename the script to `indy_old_cli_export_dids`?,63f6fc3d7ee6d4de9c5af669097268d9b1f743bf,2017-12-22 14:11:23,158498262,"@@ -93,5 +93,6 @@
              'scripts/validator-info',
              'scripts/init_bls_keys',
              'scripts/enable_bls',
-             'scripts/create_dirs.sh']
+             'scripts/create_dirs.sh',
+             'scripts/indy_export_dids']",,2017-12-26 09:51:26,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158498262,https://github.com/hyperledger/indy-node/pull/506#discussion_r158498262,ashcherbakov
https://github.com/hyperledger/indy-node/pull/506,https://github.com/hyperledger/indy-node/pull/506,Should we provide an option to set the destination folder for the exported data?,63f6fc3d7ee6d4de9c5af669097268d9b1f743bf,2017-12-22 14:12:03,158498381,"@@ -0,0 +1,50 @@
+#! /usr/bin/env python3
+""""""
+Script for export DIDs from client wallet.
+
+$indy_export_dids [-e <environment name>] -w <wallet name>
+""""""
+
+import argparse
+import base64
+import json
+import os
+from pathlib import Path
+
+from indy_common.config_util import getConfig
+from plenum.cli.constants import NO_ENV, WALLET_FILE_EXTENSION
+from plenum.client.wallet import WalletStorageHelper
+
+ap = argparse.ArgumentParser()
+ap.add_argument(""-e"", ""--env_name"", default=NO_ENV)
+ap.add_argument(""-w"", ""--wallet_name"", required=True)
+args = ap.parse_args()
+env_name = args.env_name
+wallet_name = args.wallet_name
+
+config = getConfig()
+base_dir = os.path.expanduser(config.CLI_BASE_DIR)
+wallets_dir = os.path.join(base_dir, config.walletsDir)
+
+wallet_dir = os.path.join(wallets_dir, env_name)
+storage_helper = WalletStorageHelper(wallet_dir)
+wallet_path = os.path.join(wallet_dir, ""{}.{}"".format(wallet_name, WALLET_FILE_EXTENSION))
+wallet = storage_helper.loadWallet(wallet_path)
+
+dids = []
+for did, did_signer in wallet.idsToSigners.items():
+    seed_base64 = base64.b64encode(did_signer.seed).decode(""ascii"")
+    dids.append({""did"": did, ""seed"": seed_base64})
+
+dto = {
+    ""version"": 1,
+    ""dids"": dids
+}
+
+out_file_name = ""{}_{}.exp_wallet"".format(env_name, wallet_name)
+path = Path(os.path.join(os.path.curdir, out_file_name))",,2017-12-26 09:51:26,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158498381,https://github.com/hyperledger/indy-node/pull/506#discussion_r158498381,ashcherbakov
https://github.com/hyperledger/indy-node/pull/506,https://github.com/hyperledger/indy-node/pull/506,"We can use `write_text` here to open, write and close the file.",63f6fc3d7ee6d4de9c5af669097268d9b1f743bf,2017-12-22 14:18:17,158499367,"@@ -0,0 +1,50 @@
+#! /usr/bin/env python3
+""""""
+Script for export DIDs from client wallet.
+
+$indy_export_dids [-e <environment name>] -w <wallet name>
+""""""
+
+import argparse
+import base64
+import json
+import os
+from pathlib import Path
+
+from indy_common.config_util import getConfig
+from plenum.cli.constants import NO_ENV, WALLET_FILE_EXTENSION
+from plenum.client.wallet import WalletStorageHelper
+
+ap = argparse.ArgumentParser()
+ap.add_argument(""-e"", ""--env_name"", default=NO_ENV)
+ap.add_argument(""-w"", ""--wallet_name"", required=True)
+args = ap.parse_args()
+env_name = args.env_name
+wallet_name = args.wallet_name
+
+config = getConfig()
+base_dir = os.path.expanduser(config.CLI_BASE_DIR)
+wallets_dir = os.path.join(base_dir, config.walletsDir)
+
+wallet_dir = os.path.join(wallets_dir, env_name)
+storage_helper = WalletStorageHelper(wallet_dir)
+wallet_path = os.path.join(wallet_dir, ""{}.{}"".format(wallet_name, WALLET_FILE_EXTENSION))
+wallet = storage_helper.loadWallet(wallet_path)
+
+dids = []
+for did, did_signer in wallet.idsToSigners.items():
+    seed_base64 = base64.b64encode(did_signer.seed).decode(""ascii"")
+    dids.append({""did"": did, ""seed"": seed_base64})
+
+dto = {
+    ""version"": 1,
+    ""dids"": dids
+}
+
+out_file_name = ""{}_{}.exp_wallet"".format(env_name, wallet_name)
+path = Path(os.path.join(os.path.curdir, out_file_name))
+
+wf = path.open('w')
+wf.write(json.dumps(dto))",,2017-12-26 09:51:26,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158499367,https://github.com/hyperledger/indy-node/pull/506#discussion_r158499367,ashcherbakov
https://github.com/hyperledger/indy-node/pull/506,https://github.com/hyperledger/indy-node/pull/506,"Or may be even out file name? Default destination folder = current folder, current mask as default filename. And alternative optional argument - path to save file (including filename).",63f6fc3d7ee6d4de9c5af669097268d9b1f743bf,2017-12-22 21:06:59,158558174,"@@ -0,0 +1,50 @@
+#! /usr/bin/env python3
+""""""
+Script for export DIDs from client wallet.
+
+$indy_export_dids [-e <environment name>] -w <wallet name>
+""""""
+
+import argparse
+import base64
+import json
+import os
+from pathlib import Path
+
+from indy_common.config_util import getConfig
+from plenum.cli.constants import NO_ENV, WALLET_FILE_EXTENSION
+from plenum.client.wallet import WalletStorageHelper
+
+ap = argparse.ArgumentParser()
+ap.add_argument(""-e"", ""--env_name"", default=NO_ENV)
+ap.add_argument(""-w"", ""--wallet_name"", required=True)
+args = ap.parse_args()
+env_name = args.env_name
+wallet_name = args.wallet_name
+
+config = getConfig()
+base_dir = os.path.expanduser(config.CLI_BASE_DIR)
+wallets_dir = os.path.join(base_dir, config.walletsDir)
+
+wallet_dir = os.path.join(wallets_dir, env_name)
+storage_helper = WalletStorageHelper(wallet_dir)
+wallet_path = os.path.join(wallet_dir, ""{}.{}"".format(wallet_name, WALLET_FILE_EXTENSION))
+wallet = storage_helper.loadWallet(wallet_path)
+
+dids = []
+for did, did_signer in wallet.idsToSigners.items():
+    seed_base64 = base64.b64encode(did_signer.seed).decode(""ascii"")
+    dids.append({""did"": did, ""seed"": seed_base64})
+
+dto = {
+    ""version"": 1,
+    ""dids"": dids
+}
+
+out_file_name = ""{}_{}.exp_wallet"".format(env_name, wallet_name)
+path = Path(os.path.join(os.path.curdir, out_file_name))",,2017-12-26 09:51:26,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158558174,https://github.com/hyperledger/indy-node/pull/506#discussion_r158558174,jovfer
https://github.com/hyperledger/indy-node/pull/487,https://github.com/hyperledger/indy-node/pull/487,"That's not a big problem for migration script and this method, but in general I prefer not having too many embedded conditions, and rather use 
```
if not os.path.exists(general_config_path):
    return
```",baeee0b0914094b1865e5c59f1cee9fbe6ec9c27,2017-12-11 13:39:29,156074444,"@@ -0,0 +1,40 @@
+#!/usr/bin/python3.5
+import os
+
+from stp_core.common.log import getlogger
+from indy_common.config_util import getConfig
+
+import indy_node.general_config.indy_config as indy_config
+
+
+def migrate():
+    config = getConfig()
+    logger = getlogger()
+
+    general_config_path = os.path.join(config.GENERAL_CONFIG_DIR, config.GENERAL_CONFIG_FILE)
+
+    if os.path.exists(general_config_path):",,2017-12-11 13:44:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156074444,https://github.com/hyperledger/indy-node/pull/487#discussion_r156074444,ashcherbakov
https://github.com/hyperledger/indy-node/pull/487,https://github.com/hyperledger/indy-node/pull/487,Ok,baeee0b0914094b1865e5c59f1cee9fbe6ec9c27,2017-12-11 13:41:49,156075024,"@@ -0,0 +1,40 @@
+#!/usr/bin/python3.5
+import os
+
+from stp_core.common.log import getlogger
+from indy_common.config_util import getConfig
+
+import indy_node.general_config.indy_config as indy_config
+
+
+def migrate():
+    config = getConfig()
+    logger = getlogger()
+
+    general_config_path = os.path.join(config.GENERAL_CONFIG_DIR, config.GENERAL_CONFIG_FILE)
+
+    if os.path.exists(general_config_path):",,2017-12-11 13:44:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156075024,https://github.com/hyperledger/indy-node/pull/487#discussion_r156075024,sergey-shilov
https://github.com/hyperledger/indy-node/pull/486,https://github.com/hyperledger/indy-node/pull/486,Why do we have to specify it explicitly? Why can't get it from registered request handlers?,5e3b67df9ce0ae7eab02f0f5985d07038ea0b272,2017-12-13 12:41:26,156647418,"@@ -18,23 +15,10 @@ class LedgerBasedAuthNr(CoreAuthMixin, NaclAuthNr):
     Transaction-based client authenticator.
     """"""
 
-    write_types = CoreAuthMixin.write_types.union(
-        PoolRequestHandler.write_types
-    ).union(
-        DomainReqHandler.write_types
-    ).union(
-        ConfigReqHandler.write_types
-    )
-
-    query_types = CoreAuthMixin.query_types.union(
-        {GET_TXNS, }
-    ).union(
-        PoolRequestHandler.query_types
-    ).union(
-        DomainReqHandler.query_types
-    ).union(
-        ConfigReqHandler.query_types
-    )
+    write_types = CoreAuthMixin.write_types.union({ATTRIB, SCHEMA, CLAIM_DEF,",39,2018-01-24 08:59:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156647418,https://github.com/hyperledger/indy-node/pull/486#discussion_r156647418,ashcherbakov
https://github.com/hyperledger/indy-node/pull/486,https://github.com/hyperledger/indy-node/pull/486,Do we use default executor for CONFIG ledger?,5e3b67df9ce0ae7eab02f0f5985d07038ea0b272,2017-12-13 12:53:36,156650007,"@@ -93,21 +88,6 @@ def __init__(self,
         # TODO: ugly line ahead, don't know how to avoid
         self.clientAuthNr = clientAuthNr or self.defaultAuthNr()
 
-        self.configLedger = self.getConfigLedger()
-        self.ledgerManager.addLedger(
-            CONFIG_LEDGER_ID,
-            self.configLedger,
-            postCatchupCompleteClbk=self.postConfigLedgerCaughtUp,
-            postTxnAddedToLedgerClbk=self.postTxnFromCatchupAddedToLedger)
-        self.on_new_ledger_added(CONFIG_LEDGER_ID)
-        self.states[CONFIG_LEDGER_ID] = self.loadConfigState()
-        self.upgrader = self.getUpgrader()
-        self.poolCfg = self.getPoolConfig()
-        self.configReqHandler = self.getConfigReqHandler()
-        self.initConfigState()
-        self.register_req_handler(CONFIG_LEDGER_ID, self.configReqHandler)
-        self.requestExecuter[CONFIG_LEDGER_ID] = self.executeConfigTxns",67,2018-01-24 08:59:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156650007,https://github.com/hyperledger/indy-node/pull/486#discussion_r156650007,ashcherbakov
https://github.com/hyperledger/indy-node/pull/486,https://github.com/hyperledger/indy-node/pull/486,"Why can't we have a generic method in plenum for execution of txns?
Do we need to override `executeDomainTxns` for Domain ledger?",5e3b67df9ce0ae7eab02f0f5985d07038ea0b272,2017-12-13 12:55:05,156650330,"@@ -378,15 +302,8 @@ def executeDomainTxns(self, ppTime, reqs: List[Request], stateRoot,
         :param ppTime: the time at which PRE-PREPARE was sent
         :param req: the client REQUEST
         """"""
-        req_handler = self.get_req_handler(DOMAIN_LEDGER_ID)
-        return self.commitAndSendReplies(req_handler, ppTime, reqs,
-                                         stateRoot, txnRoot)
-
-    def executeConfigTxns(self, ppTime, reqs: List[Request], stateRoot,
-                          txnRoot) -> List:
-        req_handler = self.get_req_handler(CONFIG_LEDGER_ID)
-        return self.commitAndSendReplies(req_handler, ppTime, reqs,
-                                         stateRoot, txnRoot)
+        return self.default_executer(DOMAIN_LEDGER_ID, ppTime, reqs,",201,2018-01-24 08:59:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156650330,https://github.com/hyperledger/indy-node/pull/486#discussion_r156650330,ashcherbakov
https://github.com/hyperledger/indy-node/pull/486,https://github.com/hyperledger/indy-node/pull/486,Yes,5e3b67df9ce0ae7eab02f0f5985d07038ea0b272,2017-12-15 12:33:28,157190746,"@@ -93,21 +88,6 @@ def __init__(self,
         # TODO: ugly line ahead, don't know how to avoid
         self.clientAuthNr = clientAuthNr or self.defaultAuthNr()
 
-        self.configLedger = self.getConfigLedger()
-        self.ledgerManager.addLedger(
-            CONFIG_LEDGER_ID,
-            self.configLedger,
-            postCatchupCompleteClbk=self.postConfigLedgerCaughtUp,
-            postTxnAddedToLedgerClbk=self.postTxnFromCatchupAddedToLedger)
-        self.on_new_ledger_added(CONFIG_LEDGER_ID)
-        self.states[CONFIG_LEDGER_ID] = self.loadConfigState()
-        self.upgrader = self.getUpgrader()
-        self.poolCfg = self.getPoolConfig()
-        self.configReqHandler = self.getConfigReqHandler()
-        self.initConfigState()
-        self.register_req_handler(CONFIG_LEDGER_ID, self.configReqHandler)
-        self.requestExecuter[CONFIG_LEDGER_ID] = self.executeConfigTxns",67,2018-01-24 08:59:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157190746,https://github.com/hyperledger/indy-node/pull/486#discussion_r157190746,lovesh
https://github.com/hyperledger/indy-node/pull/486,https://github.com/hyperledger/indy-node/pull/486,"Because request handlers are registered with node, not authenticator.",5e3b67df9ce0ae7eab02f0f5985d07038ea0b272,2017-12-15 12:34:02,157190826,"@@ -18,23 +15,10 @@ class LedgerBasedAuthNr(CoreAuthMixin, NaclAuthNr):
     Transaction-based client authenticator.
     """"""
 
-    write_types = CoreAuthMixin.write_types.union(
-        PoolRequestHandler.write_types
-    ).union(
-        DomainReqHandler.write_types
-    ).union(
-        ConfigReqHandler.write_types
-    )
-
-    query_types = CoreAuthMixin.query_types.union(
-        {GET_TXNS, }
-    ).union(
-        PoolRequestHandler.query_types
-    ).union(
-        DomainReqHandler.query_types
-    ).union(
-        ConfigReqHandler.query_types
-    )
+    write_types = CoreAuthMixin.write_types.union({ATTRIB, SCHEMA, CLAIM_DEF,",39,2018-01-24 08:59:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157190826,https://github.com/hyperledger/indy-node/pull/486#discussion_r157190826,lovesh
https://github.com/hyperledger/indy-node/pull/486,https://github.com/hyperledger/indy-node/pull/486,Because `executeDomainTxns` in plenum does an extra action which is not need for this one,5e3b67df9ce0ae7eab02f0f5985d07038ea0b272,2017-12-15 12:34:31,157190909,"@@ -378,15 +302,8 @@ def executeDomainTxns(self, ppTime, reqs: List[Request], stateRoot,
         :param ppTime: the time at which PRE-PREPARE was sent
         :param req: the client REQUEST
         """"""
-        req_handler = self.get_req_handler(DOMAIN_LEDGER_ID)
-        return self.commitAndSendReplies(req_handler, ppTime, reqs,
-                                         stateRoot, txnRoot)
-
-    def executeConfigTxns(self, ppTime, reqs: List[Request], stateRoot,
-                          txnRoot) -> List:
-        req_handler = self.get_req_handler(CONFIG_LEDGER_ID)
-        return self.commitAndSendReplies(req_handler, ppTime, reqs,
-                                         stateRoot, txnRoot)
+        return self.default_executer(DOMAIN_LEDGER_ID, ppTime, reqs,",201,2018-01-24 08:59:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157190909,https://github.com/hyperledger/indy-node/pull/486#discussion_r157190909,lovesh
https://github.com/hyperledger/indy-node/pull/481,https://github.com/hyperledger/indy-node/pull/481,Why can't we use a helper method from plenum?,75d449414aa5bf0e2a42d99a44bbccb598c01e20,2017-12-08 10:37:14,155747855,"@@ -0,0 +1,132 @@
+from types import MethodType
+
+import logging
+import pytest
+
+from indy_client.client.client import Client
+from indy_client.client.wallet.wallet import Wallet
+from indy_common.identity import Identity
+from indy_node.server.node import Node
+from indy_client.test.conftest import nodeSet
+from plenum.common.batched import Batched
+from plenum.test.delayers import cDelay, lsDelay
+from plenum.test.helper import waitForSufficientRepliesForRequests
+from plenum.test.test_node import getNonPrimaryReplicas
+from stp_core.common.log import getlogger
+from stp_core.loop.eventually import eventually
+
+logger = getlogger()
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    oldMax3PCBatchSize = tconf.Max3PCBatchSize
+    tconf.Max3PCBatchSize = 1
+
+    yield tconf
+
+    tconf.Max3PCBatchSize = oldMax3PCBatchSize
+
+
+@pytest.fixture(scope=""module"")
+def disable_transport_batching():
+    original_should_batch = Batched._should_batch
+    Batched._should_batch = lambda self, msgs: False
+
+    yield
+
+    Batched._should_batch = original_should_batch
+
+
+concerningLogLevels = [logging.WARNING,
+                       logging.ERROR,
+                       logging.CRITICAL]
+
+
+def test_3pc_batch_reverted_on_catchup_start_can_be_ordered_before_ledgers_sync(
+        looper,
+        tdirWithPoolTxns,
+        tdirWithDomainTxns,
+        nodeSet,
+        trustAnchor,
+        trustAnchorWallet,
+        allPluginsPath,
+        tconf,
+        disable_transport_batching):
+
+    non_primary_replicas_of_master = getNonPrimaryReplicas(nodeSet, 0)
+    slow_node = non_primary_replicas_of_master[0].node
+
+    slow_node.nodeIbStasher.delay(cDelay(300))
+    slow_node.start_catchup = MethodType(patched_start_catchup, slow_node)
+
+    requests = send_random_requests(trustAnchorWallet, trustAnchor, 1)
+    waitForSufficientRepliesForRequests(looper, trustAnchor, requests=requests)
+
+    no_more_catchups_needed_call_times_before = \
+        slow_node.spylog.count(Node.no_more_catchups_needed.__name__)
+    on_batch_rejected_call_times_before = \
+        slow_node.spylog.count(Node.onBatchRejected.__name__)
+    on_batch_created_call_times_before = \
+        slow_node.spylog.count(Node.onBatchCreated.__name__)
+    process_ordered_call_times_before = \
+        slow_node.spylog.count(Node.processOrdered.__name__)
+
+    slow_node.start_catchup()
+
+    def check_catchup_done():
+        assert slow_node.spylog.count(Node.no_more_catchups_needed.__name__) > \
+               no_more_catchups_needed_call_times_before
+
+    looper.run(eventually(check_catchup_done, retryWait=1, timeout=10))
+
+    on_batch_rejected_call_times_after = \
+        slow_node.spylog.count(Node.onBatchRejected.__name__)
+    on_batch_created_call_times_after = \
+        slow_node.spylog.count(Node.onBatchCreated.__name__)
+    process_ordered_call_times_after = \
+        slow_node.spylog.count(Node.processOrdered.__name__)
+
+    assert on_batch_rejected_call_times_after \
+           - on_batch_rejected_call_times_before == 1
+
+    assert on_batch_created_call_times_after \
+           - on_batch_created_call_times_before == 1
+
+    assert process_ordered_call_times_after \
+           - process_ordered_call_times_before == 2  # one per replica
+    last_2_process_ordered_results = \
+        [call.result for call
+         in slow_node.spylog.getAll(Node.processOrdered.__name__)[-2:]]
+    assert True in last_2_process_ordered_results  # True for master replica
+
+
+def patched_start_catchup(self):
+    Node.start_catchup(self)
+
+    self.nodeIbStasher.reset_delays_and_process_delayeds()
+    self.nodeIbStasher.delay(lsDelay(300))
+
+    self.try_processing_ordered = \
+        MethodType(patched_try_processing_ordered, self)
+    self.start_catchup = MethodType(Node.start_catchup, self)
+
+
+def patched_try_processing_ordered(self, msg):
+    Node.try_processing_ordered(self, msg)
+
+    if msg.instId == 0:
+        self.nodeIbStasher.reset_delays_and_process_delayeds()
+
+        self.try_processing_ordered = \
+            MethodType(Node.try_processing_ordered, self)
+
+
+def send_random_requests(wallet: Wallet, client: Client, count: int):",,2017-12-08 14:35:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/155747855,https://github.com/hyperledger/indy-node/pull/481#discussion_r155747855,ashcherbakov
https://github.com/hyperledger/indy-node/pull/481,https://github.com/hyperledger/indy-node/pull/481,Please add a description on what this test does,75d449414aa5bf0e2a42d99a44bbccb598c01e20,2017-12-08 10:37:58,155747990,"@@ -0,0 +1,132 @@
+from types import MethodType
+
+import logging
+import pytest
+
+from indy_client.client.client import Client
+from indy_client.client.wallet.wallet import Wallet
+from indy_common.identity import Identity
+from indy_node.server.node import Node
+from indy_client.test.conftest import nodeSet
+from plenum.common.batched import Batched
+from plenum.test.delayers import cDelay, lsDelay
+from plenum.test.helper import waitForSufficientRepliesForRequests
+from plenum.test.test_node import getNonPrimaryReplicas
+from stp_core.common.log import getlogger
+from stp_core.loop.eventually import eventually
+
+logger = getlogger()
+
+
+@pytest.fixture(scope=""module"")
+def tconf(tconf):
+    oldMax3PCBatchSize = tconf.Max3PCBatchSize
+    tconf.Max3PCBatchSize = 1
+
+    yield tconf
+
+    tconf.Max3PCBatchSize = oldMax3PCBatchSize
+
+
+@pytest.fixture(scope=""module"")
+def disable_transport_batching():
+    original_should_batch = Batched._should_batch
+    Batched._should_batch = lambda self, msgs: False
+
+    yield
+
+    Batched._should_batch = original_should_batch
+
+
+concerningLogLevels = [logging.WARNING,
+                       logging.ERROR,
+                       logging.CRITICAL]
+
+
+def test_3pc_batch_reverted_on_catchup_start_can_be_ordered_before_ledgers_sync(",,2017-12-08 14:35:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/155747990,https://github.com/hyperledger/indy-node/pull/481#discussion_r155747990,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Please remove commented code,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 11:56:10,152954326,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()",54,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152954326,https://github.com/hyperledger/indy-node/pull/473#discussion_r152954326,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Please remove commented code,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 11:56:17,152954337,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()
+        value = super().get(idr, is_committed=isCommitted)
+        # if isCommitted:
+        #     value = self._keyValueStorage.get(idr)
+        # else:
+        #     # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
+        #     # in reverse to get the latest value
+        #     for key, cache in reversed(self.currentBatchOps):
+        #         if key == idr.decode():
+        #             value = cache
+        #             ta, iv, r = self.unpackIdrValue(value)
+        #             return ta, iv, r
+        #
+        #     for _, cache in reversed(self.unCommitted):
+        #         if idr in cache:
+        #             value = cache[idr]
+        #             break
+        #     else:
+        #         value = self._keyValueStorage.get(idr)
         return self.unpackIdrValue(value)
 
-    def set(self, idr, seqNo, txnTime, ta=None, role=None, verkey=None, isCommitted=True):
+    def set(self, idr, seqNo, txnTime,
+            ta=None, role=None, verkey=None, isCommitted=True):
+        idr = idr.encode()
         val = self.packIdrValue(seqNo, txnTime, ta, role, verkey)
-        if isCommitted:
-            self._keyValueStorage.put(idr, val)
-        else:
-            self.currentBatchOps.append((idr, val))
+        # if isCommitted:",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152954337,https://github.com/hyperledger/indy-node/pull/473#discussion_r152954337,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Please remove commented code,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 11:56:33,152954385,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()
+        value = super().get(idr, is_committed=isCommitted)
+        # if isCommitted:
+        #     value = self._keyValueStorage.get(idr)
+        # else:
+        #     # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
+        #     # in reverse to get the latest value
+        #     for key, cache in reversed(self.currentBatchOps):
+        #         if key == idr.decode():
+        #             value = cache
+        #             ta, iv, r = self.unpackIdrValue(value)
+        #             return ta, iv, r
+        #
+        #     for _, cache in reversed(self.unCommitted):
+        #         if idr in cache:
+        #             value = cache[idr]
+        #             break
+        #     else:
+        #         value = self._keyValueStorage.get(idr)
         return self.unpackIdrValue(value)
 
-    def set(self, idr, seqNo, txnTime, ta=None, role=None, verkey=None, isCommitted=True):
+    def set(self, idr, seqNo, txnTime,
+            ta=None, role=None, verkey=None, isCommitted=True):
+        idr = idr.encode()
         val = self.packIdrValue(seqNo, txnTime, ta, role, verkey)
-        if isCommitted:
-            self._keyValueStorage.put(idr, val)
-        else:
-            self.currentBatchOps.append((idr, val))
+        # if isCommitted:
+        #     self._keyValueStorage.put(idr, val)
+        # else:
+        #     self.currentBatchOps.append((idr, val))
+        super().set(idr, val, is_committed=isCommitted)
 
     def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
-        self.currentBatchOps = []
+        # self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152954385,https://github.com/hyperledger/indy-node/pull/473#discussion_r152954385,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,"Please do not catch a general exception here (it should be avoided to catch base Exception class).
I think it's better to do it like this:
```
expected_state_root = super().first_batch_idr
if expected_state_root is None:
                 logger.warning('{}{} is trying to commit a batch with state root'
                            ' {} but no uncommitted found'
                            .format(THREE_PC_PREFIX, self, stateRoot))
                 return
if expected_state_root != stateRoot:
                 logger.warning('{}{} is trying to commit a batch with state root'
                            ' {} but the next batch to be committed has root {}'
                            .format(THREE_PC_PREFIX, self, stateRoot, expected_state_root))
                 return
super().commit_batch()
```",4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 12:04:17,152955664,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()
+        value = super().get(idr, is_committed=isCommitted)
+        # if isCommitted:
+        #     value = self._keyValueStorage.get(idr)
+        # else:
+        #     # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
+        #     # in reverse to get the latest value
+        #     for key, cache in reversed(self.currentBatchOps):
+        #         if key == idr.decode():
+        #             value = cache
+        #             ta, iv, r = self.unpackIdrValue(value)
+        #             return ta, iv, r
+        #
+        #     for _, cache in reversed(self.unCommitted):
+        #         if idr in cache:
+        #             value = cache[idr]
+        #             break
+        #     else:
+        #         value = self._keyValueStorage.get(idr)
         return self.unpackIdrValue(value)
 
-    def set(self, idr, seqNo, txnTime, ta=None, role=None, verkey=None, isCommitted=True):
+    def set(self, idr, seqNo, txnTime,
+            ta=None, role=None, verkey=None, isCommitted=True):
+        idr = idr.encode()
         val = self.packIdrValue(seqNo, txnTime, ta, role, verkey)
-        if isCommitted:
-            self._keyValueStorage.put(idr, val)
-        else:
-            self.currentBatchOps.append((idr, val))
+        # if isCommitted:
+        #     self._keyValueStorage.put(idr, val)
+        # else:
+        #     self.currentBatchOps.append((idr, val))
+        super().set(idr, val, is_committed=isCommitted)
 
     def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
-        self.currentBatchOps = []
+        # self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
+        # self.currentBatchOps = []
+        super().create_batch_from_current(stateRoot)
 
     def batchRejected(self):
         # Batches are always rejected from end of `self.unCommitted`
-        self.currentBatchOps = []
-        self.unCommitted = self.unCommitted[:-1]
+        # self.currentBatchOps = []
+        # self.unCommitted = self.unCommitted[:-1]
+        super().reject_batch()
 
     def onBatchCommitted(self, stateRoot):
         # Commit an already created batch
-        if not self.unCommitted:
+        try:
+            assert super().first_batch_idr == stateRoot, 'The first created ' \
+                                                         'batch has not been ' \
+                                                         'committed or reverted ' \
+                                                         'and yet another batch ' \
+                                                         'is trying to be ' \
+                                                         'committed, {} {}'.\
+                format(self.unCommitted[0][0], stateRoot)
+            super().commit_batch()
+        except Exception:",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152955664,https://github.com/hyperledger/indy-node/pull/473#discussion_r152955664,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Please remove commented code,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 12:04:40,152955708,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()
+        value = super().get(idr, is_committed=isCommitted)
+        # if isCommitted:
+        #     value = self._keyValueStorage.get(idr)
+        # else:
+        #     # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
+        #     # in reverse to get the latest value
+        #     for key, cache in reversed(self.currentBatchOps):
+        #         if key == idr.decode():
+        #             value = cache
+        #             ta, iv, r = self.unpackIdrValue(value)
+        #             return ta, iv, r
+        #
+        #     for _, cache in reversed(self.unCommitted):
+        #         if idr in cache:
+        #             value = cache[idr]
+        #             break
+        #     else:
+        #         value = self._keyValueStorage.get(idr)
         return self.unpackIdrValue(value)
 
-    def set(self, idr, seqNo, txnTime, ta=None, role=None, verkey=None, isCommitted=True):
+    def set(self, idr, seqNo, txnTime,
+            ta=None, role=None, verkey=None, isCommitted=True):
+        idr = idr.encode()
         val = self.packIdrValue(seqNo, txnTime, ta, role, verkey)
-        if isCommitted:
-            self._keyValueStorage.put(idr, val)
-        else:
-            self.currentBatchOps.append((idr, val))
+        # if isCommitted:
+        #     self._keyValueStorage.put(idr, val)
+        # else:
+        #     self.currentBatchOps.append((idr, val))
+        super().set(idr, val, is_committed=isCommitted)
 
     def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
-        self.currentBatchOps = []
+        # self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
+        # self.currentBatchOps = []
+        super().create_batch_from_current(stateRoot)
 
     def batchRejected(self):
         # Batches are always rejected from end of `self.unCommitted`
-        self.currentBatchOps = []
-        self.unCommitted = self.unCommitted[:-1]
+        # self.currentBatchOps = []
+        # self.unCommitted = self.unCommitted[:-1]
+        super().reject_batch()
 
     def onBatchCommitted(self, stateRoot):
         # Commit an already created batch
-        if not self.unCommitted:
+        try:
+            assert super().first_batch_idr == stateRoot, 'The first created ' \
+                                                         'batch has not been ' \
+                                                         'committed or reverted ' \
+                                                         'and yet another batch ' \
+                                                         'is trying to be ' \
+                                                         'committed, {} {}'.\
+                format(self.unCommitted[0][0], stateRoot)
+            super().commit_batch()
+        except Exception:
             logger.warning('{}{} is trying to commit a batch with state root'
                            ' {} but no uncommitted found'
                            .format(THREE_PC_PREFIX, self, stateRoot))
-        assert self.unCommitted[0][0] == stateRoot, \
-            'The first created batch has ' \
-            'not been committed or ' \
-            'reverted and yet another ' \
-            'batch is trying to be ' \
-            'committed, {} {}'\
-            .format(self.unCommitted[0][0], stateRoot)
-        self._keyValueStorage.setBatch([(idr, val) for idr, val in
-                                        self.unCommitted[0][1].items()])
-        self.unCommitted = self.unCommitted[1:]
+        # if self.unCommitted:",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152955708,https://github.com/hyperledger/indy-node/pull/473#discussion_r152955708,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,I think we already have a list with query txns: `openTxns` in `constants/py`. Let's use just one list in all places.,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:05:29,152965589,"@@ -1,35 +1,41 @@
 from copy import deepcopy
 from hashlib import sha256
 
-from plenum.common.exceptions import UnknownIdentifier
 from plenum.common.types import OPERATION
-from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH, VERKEY
-from plenum.server.client_authn import NaclAuthNr
+from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH
+from plenum.server.client_authn import NaclAuthNr, CoreAuthNr, CoreAuthMixin
 
-from indy_common.constants import ATTRIB
+from indy_common.constants import ATTRIB, POOL_UPGRADE, SCHEMA, CLAIM_DEF, \
+    GET_NYM, GET_ATTR, GET_SCHEMA, GET_CLAIM_DEF, POOL_CONFIG
 from indy_node.persistence.idr_cache import IdrCache
-# from indy_node.persistence.state_tree_store import StateTreeStore
 
 
-class TxnBasedAuthNr(NaclAuthNr):
+class LedgerBasedAuthNr(CoreAuthMixin, NaclAuthNr):
     """"""
     Transaction-based client authenticator.
     """"""
 
+    write_types = CoreAuthMixin.write_types.union({ATTRIB, SCHEMA, CLAIM_DEF,
+                                                   POOL_CONFIG, POOL_UPGRADE})
+    query_types = CoreAuthMixin.query_types.union({GET_NYM, GET_ATTR, GET_SCHEMA,",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152965589,https://github.com/hyperledger/indy-node/pull/473#discussion_r152965589,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Can we use generic code for excuteXTxns?,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:18:02,152967564,"@@ -451,12 +358,14 @@ def executeDomainTxns(self, ppTime, reqs: List[Request], stateRoot,
         :param ppTime: the time at which PRE-PREPARE was sent
         :param req: the client REQUEST
         """"""
-        return self.commitAndSendReplies(self.reqHandler, ppTime, reqs,
+        req_handler = self.get_req_handler(DOMAIN_LEDGER_ID)
+        return self.commitAndSendReplies(req_handler, ppTime, reqs,
                                          stateRoot, txnRoot)
 
     def executeConfigTxns(self, ppTime, reqs: List[Request], stateRoot,",210,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152967564,https://github.com/hyperledger/indy-node/pull/473#discussion_r152967564,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,"We need to remove it in plenum too, and make request handlers decide whether signature verification is needed.",4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:32:34,152970534,"@@ -319,52 +318,8 @@ def authNr(self, req):
         else:
             return super().authNr(req)
 
-    def isSignatureVerificationNeeded(self, msg: Any):",83,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152970534,https://github.com/hyperledger/indy-node/pull/473#discussion_r152970534,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,"`isSignatureVerificationNeeded` is intended for general query txns, like GET_TXN and GET_TXNS, i will change `openTxns`",4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:38:57,152971604,"@@ -319,52 +318,8 @@ def authNr(self, req):
         else:
             return super().authNr(req)
 
-    def isSignatureVerificationNeeded(self, msg: Any):",83,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152971604,https://github.com/hyperledger/indy-node/pull/473#discussion_r152971604,lovesh
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,"I used more generic code in the next PR, this was the structure before",4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:42:08,152972147,"@@ -451,12 +358,14 @@ def executeDomainTxns(self, ppTime, reqs: List[Request], stateRoot,
         :param ppTime: the time at which PRE-PREPARE was sent
         :param req: the client REQUEST
         """"""
-        return self.commitAndSendReplies(self.reqHandler, ppTime, reqs,
+        req_handler = self.get_req_handler(DOMAIN_LEDGER_ID)
+        return self.commitAndSendReplies(req_handler, ppTime, reqs,
                                          stateRoot, txnRoot)
 
     def executeConfigTxns(self, ppTime, reqs: List[Request], stateRoot,",210,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152972147,https://github.com/hyperledger/indy-node/pull/473#discussion_r152972147,lovesh
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Done,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:52:27,152974176,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()
+        value = super().get(idr, is_committed=isCommitted)
+        # if isCommitted:
+        #     value = self._keyValueStorage.get(idr)
+        # else:
+        #     # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
+        #     # in reverse to get the latest value
+        #     for key, cache in reversed(self.currentBatchOps):
+        #         if key == idr.decode():
+        #             value = cache
+        #             ta, iv, r = self.unpackIdrValue(value)
+        #             return ta, iv, r
+        #
+        #     for _, cache in reversed(self.unCommitted):
+        #         if idr in cache:
+        #             value = cache[idr]
+        #             break
+        #     else:
+        #         value = self._keyValueStorage.get(idr)
         return self.unpackIdrValue(value)
 
-    def set(self, idr, seqNo, txnTime, ta=None, role=None, verkey=None, isCommitted=True):
+    def set(self, idr, seqNo, txnTime,
+            ta=None, role=None, verkey=None, isCommitted=True):
+        idr = idr.encode()
         val = self.packIdrValue(seqNo, txnTime, ta, role, verkey)
-        if isCommitted:
-            self._keyValueStorage.put(idr, val)
-        else:
-            self.currentBatchOps.append((idr, val))
+        # if isCommitted:
+        #     self._keyValueStorage.put(idr, val)
+        # else:
+        #     self.currentBatchOps.append((idr, val))
+        super().set(idr, val, is_committed=isCommitted)
 
     def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
-        self.currentBatchOps = []
+        # self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
+        # self.currentBatchOps = []
+        super().create_batch_from_current(stateRoot)
 
     def batchRejected(self):
         # Batches are always rejected from end of `self.unCommitted`
-        self.currentBatchOps = []
-        self.unCommitted = self.unCommitted[:-1]
+        # self.currentBatchOps = []
+        # self.unCommitted = self.unCommitted[:-1]
+        super().reject_batch()
 
     def onBatchCommitted(self, stateRoot):
         # Commit an already created batch
-        if not self.unCommitted:
+        try:
+            assert super().first_batch_idr == stateRoot, 'The first created ' \
+                                                         'batch has not been ' \
+                                                         'committed or reverted ' \
+                                                         'and yet another batch ' \
+                                                         'is trying to be ' \
+                                                         'committed, {} {}'.\
+                format(self.unCommitted[0][0], stateRoot)
+            super().commit_batch()
+        except Exception:",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152974176,https://github.com/hyperledger/indy-node/pull/473#discussion_r152974176,lovesh
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Done,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:52:32,152974185,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()
+        value = super().get(idr, is_committed=isCommitted)
+        # if isCommitted:
+        #     value = self._keyValueStorage.get(idr)
+        # else:
+        #     # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
+        #     # in reverse to get the latest value
+        #     for key, cache in reversed(self.currentBatchOps):
+        #         if key == idr.decode():
+        #             value = cache
+        #             ta, iv, r = self.unpackIdrValue(value)
+        #             return ta, iv, r
+        #
+        #     for _, cache in reversed(self.unCommitted):
+        #         if idr in cache:
+        #             value = cache[idr]
+        #             break
+        #     else:
+        #         value = self._keyValueStorage.get(idr)
         return self.unpackIdrValue(value)
 
-    def set(self, idr, seqNo, txnTime, ta=None, role=None, verkey=None, isCommitted=True):
+    def set(self, idr, seqNo, txnTime,
+            ta=None, role=None, verkey=None, isCommitted=True):
+        idr = idr.encode()
         val = self.packIdrValue(seqNo, txnTime, ta, role, verkey)
-        if isCommitted:
-            self._keyValueStorage.put(idr, val)
-        else:
-            self.currentBatchOps.append((idr, val))
+        # if isCommitted:
+        #     self._keyValueStorage.put(idr, val)
+        # else:
+        #     self.currentBatchOps.append((idr, val))
+        super().set(idr, val, is_committed=isCommitted)
 
     def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
-        self.currentBatchOps = []
+        # self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
+        # self.currentBatchOps = []
+        super().create_batch_from_current(stateRoot)
 
     def batchRejected(self):
         # Batches are always rejected from end of `self.unCommitted`
-        self.currentBatchOps = []
-        self.unCommitted = self.unCommitted[:-1]
+        # self.currentBatchOps = []
+        # self.unCommitted = self.unCommitted[:-1]
+        super().reject_batch()
 
     def onBatchCommitted(self, stateRoot):
         # Commit an already created batch
-        if not self.unCommitted:
+        try:
+            assert super().first_batch_idr == stateRoot, 'The first created ' \
+                                                         'batch has not been ' \
+                                                         'committed or reverted ' \
+                                                         'and yet another batch ' \
+                                                         'is trying to be ' \
+                                                         'committed, {} {}'.\
+                format(self.unCommitted[0][0], stateRoot)
+            super().commit_batch()
+        except Exception:
             logger.warning('{}{} is trying to commit a batch with state root'
                            ' {} but no uncommitted found'
                            .format(THREE_PC_PREFIX, self, stateRoot))
-        assert self.unCommitted[0][0] == stateRoot, \
-            'The first created batch has ' \
-            'not been committed or ' \
-            'reverted and yet another ' \
-            'batch is trying to be ' \
-            'committed, {} {}'\
-            .format(self.unCommitted[0][0], stateRoot)
-        self._keyValueStorage.setBatch([(idr, val) for idr, val in
-                                        self.unCommitted[0][1].items()])
-        self.unCommitted = self.unCommitted[1:]
+        # if self.unCommitted:",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152974185,https://github.com/hyperledger/indy-node/pull/473#discussion_r152974185,lovesh
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,"`openTxns` is meant for txns like `GET_TXNS`, i have made that change",4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:53:41,152974392,"@@ -1,35 +1,41 @@
 from copy import deepcopy
 from hashlib import sha256
 
-from plenum.common.exceptions import UnknownIdentifier
 from plenum.common.types import OPERATION
-from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH, VERKEY
-from plenum.server.client_authn import NaclAuthNr
+from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH
+from plenum.server.client_authn import NaclAuthNr, CoreAuthNr, CoreAuthMixin
 
-from indy_common.constants import ATTRIB
+from indy_common.constants import ATTRIB, POOL_UPGRADE, SCHEMA, CLAIM_DEF, \
+    GET_NYM, GET_ATTR, GET_SCHEMA, GET_CLAIM_DEF, POOL_CONFIG
 from indy_node.persistence.idr_cache import IdrCache
-# from indy_node.persistence.state_tree_store import StateTreeStore
 
 
-class TxnBasedAuthNr(NaclAuthNr):
+class LedgerBasedAuthNr(CoreAuthMixin, NaclAuthNr):
     """"""
     Transaction-based client authenticator.
     """"""
 
+    write_types = CoreAuthMixin.write_types.union({ATTRIB, SCHEMA, CLAIM_DEF,
+                                                   POOL_CONFIG, POOL_UPGRADE})
+    query_types = CoreAuthMixin.query_types.union({GET_NYM, GET_ATTR, GET_SCHEMA,",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152974392,https://github.com/hyperledger/indy-node/pull/473#discussion_r152974392,lovesh
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Done,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:54:46,152974572,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()",54,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152974572,https://github.com/hyperledger/indy-node/pull/473#discussion_r152974572,lovesh
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Done,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:54:52,152974586,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()
+        value = super().get(idr, is_committed=isCommitted)
+        # if isCommitted:
+        #     value = self._keyValueStorage.get(idr)
+        # else:
+        #     # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
+        #     # in reverse to get the latest value
+        #     for key, cache in reversed(self.currentBatchOps):
+        #         if key == idr.decode():
+        #             value = cache
+        #             ta, iv, r = self.unpackIdrValue(value)
+        #             return ta, iv, r
+        #
+        #     for _, cache in reversed(self.unCommitted):
+        #         if idr in cache:
+        #             value = cache[idr]
+        #             break
+        #     else:
+        #         value = self._keyValueStorage.get(idr)
         return self.unpackIdrValue(value)
 
-    def set(self, idr, seqNo, txnTime, ta=None, role=None, verkey=None, isCommitted=True):
+    def set(self, idr, seqNo, txnTime,
+            ta=None, role=None, verkey=None, isCommitted=True):
+        idr = idr.encode()
         val = self.packIdrValue(seqNo, txnTime, ta, role, verkey)
-        if isCommitted:
-            self._keyValueStorage.put(idr, val)
-        else:
-            self.currentBatchOps.append((idr, val))
+        # if isCommitted:",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152974586,https://github.com/hyperledger/indy-node/pull/473#discussion_r152974586,lovesh
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Done,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 13:54:57,152974604,"@@ -79,55 +80,80 @@ def unpackIdrValue(value):
         return seqNo, txnTime, ta, role, verkey
 
     def get(self, idr, isCommitted=True):
-        encoded_idr = idr.encode()
-        if not isCommitted:
-            # Looking for uncommitted values,
-            # iterating over `currentBatchOps and unCommitted`
-            # in reverse to get the latest value
-            for key, cache in reversed(self.currentBatchOps):
-                if key == idr:
-                    return self.unpackIdrValue(cache)
-            for _, cache in reversed(self.unCommitted):
-                if encoded_idr in cache:
-                    return self.unpackIdrValue(cache[encoded_idr])
-        value = self._keyValueStorage.get(encoded_idr)
+        idr = idr.encode()
+        value = super().get(idr, is_committed=isCommitted)
+        # if isCommitted:
+        #     value = self._keyValueStorage.get(idr)
+        # else:
+        #     # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
+        #     # in reverse to get the latest value
+        #     for key, cache in reversed(self.currentBatchOps):
+        #         if key == idr.decode():
+        #             value = cache
+        #             ta, iv, r = self.unpackIdrValue(value)
+        #             return ta, iv, r
+        #
+        #     for _, cache in reversed(self.unCommitted):
+        #         if idr in cache:
+        #             value = cache[idr]
+        #             break
+        #     else:
+        #         value = self._keyValueStorage.get(idr)
         return self.unpackIdrValue(value)
 
-    def set(self, idr, seqNo, txnTime, ta=None, role=None, verkey=None, isCommitted=True):
+    def set(self, idr, seqNo, txnTime,
+            ta=None, role=None, verkey=None, isCommitted=True):
+        idr = idr.encode()
         val = self.packIdrValue(seqNo, txnTime, ta, role, verkey)
-        if isCommitted:
-            self._keyValueStorage.put(idr, val)
-        else:
-            self.currentBatchOps.append((idr, val))
+        # if isCommitted:
+        #     self._keyValueStorage.put(idr, val)
+        # else:
+        #     self.currentBatchOps.append((idr, val))
+        super().set(idr, val, is_committed=isCommitted)
 
     def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
-        self.currentBatchOps = []
+        # self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152974604,https://github.com/hyperledger/indy-node/pull/473#discussion_r152974604,lovesh
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,"Why can't we move openTxns here as well? so, we have all logic related to signature verification skipping in one place?",4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 14:26:47,152980691,"@@ -1,35 +1,41 @@
 from copy import deepcopy
 from hashlib import sha256
 
-from plenum.common.exceptions import UnknownIdentifier
 from plenum.common.types import OPERATION
-from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH, VERKEY
-from plenum.server.client_authn import NaclAuthNr
+from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH
+from plenum.server.client_authn import NaclAuthNr, CoreAuthNr, CoreAuthMixin
 
-from indy_common.constants import ATTRIB
+from indy_common.constants import ATTRIB, POOL_UPGRADE, SCHEMA, CLAIM_DEF, \
+    GET_NYM, GET_ATTR, GET_SCHEMA, GET_CLAIM_DEF, POOL_CONFIG
 from indy_node.persistence.idr_cache import IdrCache
-# from indy_node.persistence.state_tree_store import StateTreeStore
 
 
-class TxnBasedAuthNr(NaclAuthNr):
+class LedgerBasedAuthNr(CoreAuthMixin, NaclAuthNr):
     """"""
     Transaction-based client authenticator.
     """"""
 
+    write_types = CoreAuthMixin.write_types.union({ATTRIB, SCHEMA, CLAIM_DEF,
+                                                   POOL_CONFIG, POOL_UPGRADE})
+    query_types = CoreAuthMixin.query_types.union({GET_NYM, GET_ATTR, GET_SCHEMA,",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152980691,https://github.com/hyperledger/indy-node/pull/473#discussion_r152980691,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,"Can we get `query_types` from registered req handlers? Looks like we have a duplication here (query_types in both Requesthandlers and LedgerBasedAuthNr). Moreover, if new req handlers are added, then we need to change `query_types` in LedgerBasedAuthNr manually.",4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 14:28:50,152981071,"@@ -1,35 +1,41 @@
 from copy import deepcopy
 from hashlib import sha256
 
-from plenum.common.exceptions import UnknownIdentifier
 from plenum.common.types import OPERATION
-from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH, VERKEY
-from plenum.server.client_authn import NaclAuthNr
+from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH
+from plenum.server.client_authn import NaclAuthNr, CoreAuthNr, CoreAuthMixin
 
-from indy_common.constants import ATTRIB
+from indy_common.constants import ATTRIB, POOL_UPGRADE, SCHEMA, CLAIM_DEF, \
+    GET_NYM, GET_ATTR, GET_SCHEMA, GET_CLAIM_DEF, POOL_CONFIG
 from indy_node.persistence.idr_cache import IdrCache
-# from indy_node.persistence.state_tree_store import StateTreeStore
 
 
-class TxnBasedAuthNr(NaclAuthNr):
+class LedgerBasedAuthNr(CoreAuthMixin, NaclAuthNr):
     """"""
     Transaction-based client authenticator.
     """"""
 
+    write_types = CoreAuthMixin.write_types.union({ATTRIB, SCHEMA, CLAIM_DEF,
+                                                   POOL_CONFIG, POOL_UPGRADE})
+    query_types = CoreAuthMixin.query_types.union({GET_NYM, GET_ATTR, GET_SCHEMA,",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152981071,https://github.com/hyperledger/indy-node/pull/473#discussion_r152981071,ashcherbakov
https://github.com/hyperledger/indy-node/pull/473,https://github.com/hyperledger/indy-node/pull/473,Ok,4993091a0a9bb43b38ca1359f8b0e96d6759b305,2017-11-24 14:46:46,152984299,"@@ -1,35 +1,41 @@
 from copy import deepcopy
 from hashlib import sha256
 
-from plenum.common.exceptions import UnknownIdentifier
 from plenum.common.types import OPERATION
-from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH, VERKEY
-from plenum.server.client_authn import NaclAuthNr
+from plenum.common.constants import TXN_TYPE, RAW, ENC, HASH
+from plenum.server.client_authn import NaclAuthNr, CoreAuthNr, CoreAuthMixin
 
-from indy_common.constants import ATTRIB
+from indy_common.constants import ATTRIB, POOL_UPGRADE, SCHEMA, CLAIM_DEF, \
+    GET_NYM, GET_ATTR, GET_SCHEMA, GET_CLAIM_DEF, POOL_CONFIG
 from indy_node.persistence.idr_cache import IdrCache
-# from indy_node.persistence.state_tree_store import StateTreeStore
 
 
-class TxnBasedAuthNr(NaclAuthNr):
+class LedgerBasedAuthNr(CoreAuthMixin, NaclAuthNr):
     """"""
     Transaction-based client authenticator.
     """"""
 
+    write_types = CoreAuthMixin.write_types.union({ATTRIB, SCHEMA, CLAIM_DEF,
+                                                   POOL_CONFIG, POOL_UPGRADE})
+    query_types = CoreAuthMixin.query_types.union({GET_NYM, GET_ATTR, GET_SCHEMA,",,2017-11-27 17:15:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152984299,https://github.com/hyperledger/indy-node/pull/473#discussion_r152984299,lovesh
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,a standard way `indy_node.__version__`  could be used here,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 09:44:08,151941993,"@@ -1,15 +1,17 @@
 import pytest
 
 import indy_node
-from stp_core.loop.eventually import eventually
-from indy_common.constants import IN_PROGRESS, COMPLETE
-from indy_node.test.upgrade.helper import populate_log_with_upgrade_events, check_node_set_acknowledges_upgrade
-from plenum.test import waits as plenumWaits
-
+from indy_node.server.upgrade_log import UpgradeLog
+from indy_common.constants import COMPLETE
+from indy_node.test.upgrade.helper import populate_log_with_upgrade_events, \
+    check_node_sent_acknowledges_upgrade, check_node_do_not_sent_acknowledges_upgrade, \
+    emulate_restart_pool_for_upgrade, emulate_view_change_pool_for_upgrade
 
 whitelist = ['unable to send message']
 # TODO: Implement a client in node
 
+version = indy_node.__metadata__.__version__",18,2017-11-20 10:08:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151941993,https://github.com/hyperledger/indy-node/pull/460#discussion_r151941993,andkononykhin
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,"I think it makes sense to reorganize conditionals above to make logic more clear:
```python
           ...
            if self.scheduledUpgrade:
                if isinstance(when, str):
                    when = dateutil.parser.parse(when)
                if self.scheduledUpgrade == (version, when, upgrade_id):
                    logger.debug(""Node {} already scheduled upgrade to version '{}' "".format(
                        self.nodeName, version))
                    return
                else:
                    logger.info(
                        ""Node '{}' cancels previous upgrade and schedules a new one to {}"".format(
                            self.nodeName, version))
                    self._cancelScheduledUpgrade(justification)

            logger.info(""Node '{}' schedules upgrade to {}"".format(
                self.nodeName, version))

            self._scheduleUpgrade(
                version, when, failTimeout, upgrade_id)
            return
```",301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 09:51:26,151943903,"@@ -285,60 +298,70 @@ def handleUpgradeTxn(self, txn) -> None:
         FINALIZING_EVENT_TYPES = [
             UpgradeLog.UPGRADE_SUCCEEDED, UpgradeLog.UPGRADE_FAILED]
 
-        if txn[TXN_TYPE] == POOL_UPGRADE:
-            logger.info(""Node '{}' handles upgrade txn {}"".format(
-                self.nodeName, txn))
-            action = txn[ACTION]
-            version = txn[VERSION]
-            justification = txn.get(JUSTIFICATION)
-            reinstall = txn.get(REINSTALL, False)
-            currentVersion = self.getVersion()
-            upgrade_id = self.get_upgrade_id(txn)
-
-            if action == START:
-                # forced txn could have partial schedule list
-                if self.nodeId not in txn[SCHEDULE]:
-                    logger.info(""Node '{}' disregards upgrade txn {}"".format(
-                        self.nodeName, txn))
-                    return
-
-                last_event = self.lastUpgradeEventInfo
-                if last_event and last_event[3] == upgrade_id and last_event[0] in FINALIZING_EVENT_TYPES:
-                    logger.info(
-                        ""Node '{}' has already performed an upgrade with upgrade_id {}. ""
-                        ""Last recorded event is {}"". format(
-                            self.nodeName, upgrade_id, last_event))
-                    return
-
-                when = txn[SCHEDULE][self.nodeId]
-                failTimeout = txn.get(TIMEOUT, self.defaultUpgradeTimeout)
-
-                if self.is_version_upgradable(
-                        currentVersion, version, reinstall):
-                    logger.info(""Node '{}' schedules upgrade to {}"".format(
-                        self.nodeName, version))
+        if txn[TXN_TYPE] != POOL_UPGRADE:
+            return
 
-                    if self.scheduledUpgrade:
-                        logger.info(
-                            ""Node '{}' cancels previous upgrade and schedules a new one to {}"". format(
-                                self.nodeName, version))
-                        self._cancelScheduledUpgrade(justification)
+        logger.info(""Node '{}' handles upgrade txn {}"".format(
+            self.nodeName, txn))
+        action = txn[ACTION]
+        version = txn[VERSION]
+        justification = txn.get(JUSTIFICATION)
+        reinstall = txn.get(REINSTALL, False)
+        currentVersion = self.getVersion()
+        upgrade_id = self.get_upgrade_id(txn)
+
+        if action == START:
+            # forced txn could have partial schedule list
+            if self.nodeId not in txn[SCHEDULE]:
+                logger.info(""Node '{}' disregards upgrade txn {}"".format(
+                    self.nodeName, txn))
+                return
 
-                    self._scheduleUpgrade(
-                        version, when, failTimeout, upgrade_id)
+            last_event = self.lastUpgradeEventInfo
+            if last_event and last_event[3] == upgrade_id and last_event[0] in FINALIZING_EVENT_TYPES:
+                logger.info(
+                    ""Node '{}' has already performed an upgrade with upgrade_id {}. ""
+                    ""Last recorded event is {}"".format(
+                        self.nodeName, upgrade_id, last_event))
                 return
 
-            if action == CANCEL:
-                if self.scheduledUpgrade and \
-                        self.scheduledUpgrade[0] == version:
-                    self._cancelScheduledUpgrade(justification)
-                    logger.info(""Node '{}' cancels upgrade to {}"".format(
-                        self.nodeName, version))
+            when = txn[SCHEDULE][self.nodeId]
+            failTimeout = txn.get(TIMEOUT, self.defaultUpgradeTimeout)
+
+            if not self.is_version_upgradable(
+                    currentVersion, version, reinstall):
+                return
+
+            if isinstance(when, str):
+                when = dateutil.parser.parse(when)
+            if self.scheduledUpgrade and self.scheduledUpgrade == (version, when, upgrade_id):
+                logger.debug(""Node {} already scheduled upgrade to version '{}' "".format(
+                    self.nodeName, version))
                 return
 
-            logger.error(
-                ""Got {} transaction with unsupported action {}"".format(
-                    POOL_UPGRADE, action))
+            logger.info(""Node '{}' schedules upgrade to {}"".format(
+                self.nodeName, version))
+
+            if self.scheduledUpgrade:
+                logger.info(
+                    ""Node '{}' cancels previous upgrade and schedules a new one to {}"".format(
+                        self.nodeName, version))
+                self._cancelScheduledUpgrade(justification)
+
+            self._scheduleUpgrade(
+                version, when, failTimeout, upgrade_id)
+            return",192,2017-11-20 10:08:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151943903,https://github.com/hyperledger/indy-node/pull/460#discussion_r151943903,andkononykhin
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,It makes sense to move this class to `indy_node.test.upgrade.helper` module in order not to duplicate it in tests.,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 10:01:47,151946665,"@@ -0,0 +1,36 @@
+import pytest
+
+from indy_common.constants import IN_PROGRESS
+from indy_node.test.helper import TestNode
+from indy_node.test.upgrade.helper import check_node_sent_acknowledges_upgrade
+
+whitelist = ['unable to send message']
+
+
+class TestNodeNoProtocolVersion(TestNode):",10,2017-11-20 10:01:47,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151946665,https://github.com/hyperledger/indy-node/pull/460#discussion_r151946665,spivachuk
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,the same as above,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 10:02:13,151946768,"@@ -0,0 +1,46 @@
+import pytest
+
+import indy_node
+from indy_common.constants import COMPLETE
+from indy_node.test.helper import TestNode
+from indy_node.test.upgrade.helper import populate_log_with_upgrade_events, \
+    check_node_sent_acknowledges_upgrade
+
+whitelist = ['unable to send message']
+
+version = indy_node.__metadata__.__version__",11,2017-11-20 10:08:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151946768,https://github.com/hyperledger/indy-node/pull/460#discussion_r151946768,andkononykhin
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,Please correct: Lof -> Log.,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 10:04:27,151947290,"@@ -113,19 +112,32 @@ def __repr__(self):
     def service(self):
         return self._serviceActions()
 
-    def check_upgrade_succeeded(self):
+    def process_upgrade_log_for_first_run(self):
+        # whether upgrade was started before the Node restarted,
+        # that is whether Upgrade Log contains STARTED event
+        self._upgrade_started = self._is_upgrade_started()
+        if self._upgrade_started:
+            # append SUCCESS or FAIL to the Upgrade Lof",27,2017-11-20 10:04:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151947290,https://github.com/hyperledger/indy-node/pull/460#discussion_r151947290,spivachuk
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,Please correct: NetControlTool -> NodeControlTool.,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 10:04:57,151947389,"@@ -96,10 +96,20 @@ def __init__(self, backup_dir, backup_target, transform=lambda tool: None):
         transform(self.tool)
         self.p = multiprocessing.Process(target=self.tool.start)
         self.p.start()
+        logger.debug(""NCTProcess was started with pid: {}"". format(self.p.pid))
 
     def stop(self):
-        self.p.terminate()
+        logger.debug(""Send stop to NCTProcess with pid: {}"". format(self.p.pid))
         self.tool.server.close()
+        self.p.terminate()
+        # check that process with NetControlTool.start function really stop.",33,2017-11-20 10:04:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151947389,https://github.com/hyperledger/indy-node/pull/460#discussion_r151947389,spivachuk
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,Agree. Let's do it in a separate PR.,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 10:18:42,151950438,"@@ -0,0 +1,36 @@
+import pytest
+
+from indy_common.constants import IN_PROGRESS
+from indy_node.test.helper import TestNode
+from indy_node.test.upgrade.helper import check_node_sent_acknowledges_upgrade
+
+whitelist = ['unable to send message']
+
+
+class TestNodeNoProtocolVersion(TestNode):",10,2017-11-20 10:18:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151950438,https://github.com/hyperledger/indy-node/pull/460#discussion_r151950438,ashcherbakov
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,Agree. Let's do it in a separate PR.,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 10:18:45,151950447,"@@ -113,19 +112,32 @@ def __repr__(self):
     def service(self):
         return self._serviceActions()
 
-    def check_upgrade_succeeded(self):
+    def process_upgrade_log_for_first_run(self):
+        # whether upgrade was started before the Node restarted,
+        # that is whether Upgrade Log contains STARTED event
+        self._upgrade_started = self._is_upgrade_started()
+        if self._upgrade_started:
+            # append SUCCESS or FAIL to the Upgrade Lof",27,2017-11-20 10:18:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151950447,https://github.com/hyperledger/indy-node/pull/460#discussion_r151950447,ashcherbakov
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,Agree. Let's do it in a separate PR.,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 10:18:49,151950464,"@@ -96,10 +96,20 @@ def __init__(self, backup_dir, backup_target, transform=lambda tool: None):
         transform(self.tool)
         self.p = multiprocessing.Process(target=self.tool.start)
         self.p.start()
+        logger.debug(""NCTProcess was started with pid: {}"". format(self.p.pid))
 
     def stop(self):
-        self.p.terminate()
+        logger.debug(""Send stop to NCTProcess with pid: {}"". format(self.p.pid))
         self.tool.server.close()
+        self.p.terminate()
+        # check that process with NetControlTool.start function really stop.",33,2017-11-20 10:18:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151950464,https://github.com/hyperledger/indy-node/pull/460#discussion_r151950464,ashcherbakov
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,Agree. Let's do it in a separate PR.,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 10:19:00,151950506,"@@ -285,60 +298,70 @@ def handleUpgradeTxn(self, txn) -> None:
         FINALIZING_EVENT_TYPES = [
             UpgradeLog.UPGRADE_SUCCEEDED, UpgradeLog.UPGRADE_FAILED]
 
-        if txn[TXN_TYPE] == POOL_UPGRADE:
-            logger.info(""Node '{}' handles upgrade txn {}"".format(
-                self.nodeName, txn))
-            action = txn[ACTION]
-            version = txn[VERSION]
-            justification = txn.get(JUSTIFICATION)
-            reinstall = txn.get(REINSTALL, False)
-            currentVersion = self.getVersion()
-            upgrade_id = self.get_upgrade_id(txn)
-
-            if action == START:
-                # forced txn could have partial schedule list
-                if self.nodeId not in txn[SCHEDULE]:
-                    logger.info(""Node '{}' disregards upgrade txn {}"".format(
-                        self.nodeName, txn))
-                    return
-
-                last_event = self.lastUpgradeEventInfo
-                if last_event and last_event[3] == upgrade_id and last_event[0] in FINALIZING_EVENT_TYPES:
-                    logger.info(
-                        ""Node '{}' has already performed an upgrade with upgrade_id {}. ""
-                        ""Last recorded event is {}"". format(
-                            self.nodeName, upgrade_id, last_event))
-                    return
-
-                when = txn[SCHEDULE][self.nodeId]
-                failTimeout = txn.get(TIMEOUT, self.defaultUpgradeTimeout)
-
-                if self.is_version_upgradable(
-                        currentVersion, version, reinstall):
-                    logger.info(""Node '{}' schedules upgrade to {}"".format(
-                        self.nodeName, version))
+        if txn[TXN_TYPE] != POOL_UPGRADE:
+            return
 
-                    if self.scheduledUpgrade:
-                        logger.info(
-                            ""Node '{}' cancels previous upgrade and schedules a new one to {}"". format(
-                                self.nodeName, version))
-                        self._cancelScheduledUpgrade(justification)
+        logger.info(""Node '{}' handles upgrade txn {}"".format(
+            self.nodeName, txn))
+        action = txn[ACTION]
+        version = txn[VERSION]
+        justification = txn.get(JUSTIFICATION)
+        reinstall = txn.get(REINSTALL, False)
+        currentVersion = self.getVersion()
+        upgrade_id = self.get_upgrade_id(txn)
+
+        if action == START:
+            # forced txn could have partial schedule list
+            if self.nodeId not in txn[SCHEDULE]:
+                logger.info(""Node '{}' disregards upgrade txn {}"".format(
+                    self.nodeName, txn))
+                return
 
-                    self._scheduleUpgrade(
-                        version, when, failTimeout, upgrade_id)
+            last_event = self.lastUpgradeEventInfo
+            if last_event and last_event[3] == upgrade_id and last_event[0] in FINALIZING_EVENT_TYPES:
+                logger.info(
+                    ""Node '{}' has already performed an upgrade with upgrade_id {}. ""
+                    ""Last recorded event is {}"".format(
+                        self.nodeName, upgrade_id, last_event))
                 return
 
-            if action == CANCEL:
-                if self.scheduledUpgrade and \
-                        self.scheduledUpgrade[0] == version:
-                    self._cancelScheduledUpgrade(justification)
-                    logger.info(""Node '{}' cancels upgrade to {}"".format(
-                        self.nodeName, version))
+            when = txn[SCHEDULE][self.nodeId]
+            failTimeout = txn.get(TIMEOUT, self.defaultUpgradeTimeout)
+
+            if not self.is_version_upgradable(
+                    currentVersion, version, reinstall):
+                return
+
+            if isinstance(when, str):
+                when = dateutil.parser.parse(when)
+            if self.scheduledUpgrade and self.scheduledUpgrade == (version, when, upgrade_id):
+                logger.debug(""Node {} already scheduled upgrade to version '{}' "".format(
+                    self.nodeName, version))
                 return
 
-            logger.error(
-                ""Got {} transaction with unsupported action {}"".format(
-                    POOL_UPGRADE, action))
+            logger.info(""Node '{}' schedules upgrade to {}"".format(
+                self.nodeName, version))
+
+            if self.scheduledUpgrade:
+                logger.info(
+                    ""Node '{}' cancels previous upgrade and schedules a new one to {}"".format(
+                        self.nodeName, version))
+                self._cancelScheduledUpgrade(justification)
+
+            self._scheduleUpgrade(
+                version, when, failTimeout, upgrade_id)
+            return",192,2017-11-20 10:19:00,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151950506,https://github.com/hyperledger/indy-node/pull/460#discussion_r151950506,ashcherbakov
https://github.com/hyperledger/indy-node/pull/460,https://github.com/hyperledger/indy-node/pull/460,Agree. Let's do it in a separate PR.,301fb9e1179472b6d8eab47a39e71d2c3c2f4322,2017-11-20 10:19:04,151950521,"@@ -1,15 +1,17 @@
 import pytest
 
 import indy_node
-from stp_core.loop.eventually import eventually
-from indy_common.constants import IN_PROGRESS, COMPLETE
-from indy_node.test.upgrade.helper import populate_log_with_upgrade_events, check_node_set_acknowledges_upgrade
-from plenum.test import waits as plenumWaits
-
+from indy_node.server.upgrade_log import UpgradeLog
+from indy_common.constants import COMPLETE
+from indy_node.test.upgrade.helper import populate_log_with_upgrade_events, \
+    check_node_sent_acknowledges_upgrade, check_node_do_not_sent_acknowledges_upgrade, \
+    emulate_restart_pool_for_upgrade, emulate_view_change_pool_for_upgrade
 
 whitelist = ['unable to send message']
 # TODO: Implement a client in node
 
+version = indy_node.__metadata__.__version__",18,2017-11-20 10:19:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151950521,https://github.com/hyperledger/indy-node/pull/460#discussion_r151950521,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"The current working dir for libindy is .indy_client, not .indy (in the latest stable)",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:17:59,151709258,"@@ -0,0 +1,44 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" 
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """""" 
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete
+    NONE = """"
+
+
+class Constant:
+    """""" 
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709258,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709258,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"In the latest master and RC of indy-node, pool_genesis_txn_files are located in
/var/lib/indy/sandbox/pool_transactions_genesis (for sandbox network)",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:18:13,151709314,"@@ -0,0 +1,44 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" 
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """""" 
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete
+    NONE = """"
+
+
+class Constant:
+    """""" 
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    pool_genesis_txn_file = os.path.expanduser('~') + os.sep + "".sovrin/pool_transactions_sandbox_genesis""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709314,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709314,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,It looks like a log. I think it needs to be removed,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:18:33,151709384,"@@ -0,0 +1,23 @@
+{",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709384,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709384,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,It looks like a log. I think it needs to be removed,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:18:38,151709406,"@@ -0,0 +1,18 @@
+[95m",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709406,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709406,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,It looks like a log. I think it needs to be removed,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:18:42,151709418,"@@ -0,0 +1,173 @@
+{
+  ""testcase"": ""Test_Scenario_09_Remove_And_Add_Role"",",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709418,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709418,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,It looks like a log. I think it needs to be removed,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:18:49,151709448,"@@ -0,0 +1,118 @@
+[95m",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709448,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709448,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,It looks like a log. I think it needs to be removed,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:18:55,151709474,"@@ -0,0 +1,98 @@
+{",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709474,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709474,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,It looks like a log. I think it needs to be removed,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:19:04,151709498,"@@ -0,0 +1,53 @@
+{
+  ""testcase"": ""Test_scenario_03_Check_Connection"",",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709498,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709498,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,It looks like a log. I think it needs to be removed,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:19:10,151709534,"@@ -0,0 +1,28 @@
+{
+  ""testcase"": ""Test_scenario_04_Keyrings_Wallets"",",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709534,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709534,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,It looks like a log. I think it needs to be removed,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:19:15,151709552,"@@ -0,0 +1,293 @@
+<html>",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709552,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709552,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Can we find a better name for the class?,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:20:05,151709750,"@@ -0,0 +1,157 @@
+import asyncio
+import json
+import logging
+import os
+import sys
+import time
+from indy import pool
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.constant import Constant, Colors
+from utils.utils import generate_random_string
+from utils.report import HTMLReport
+from utils.report import TestReport, Status
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class MyVars:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709750,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709750,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"
The same pattern/template is used for each test case (print/try/except).
Can we create an utility method and use this instead of boilerplate code (so that the whole try-except goes there, and we just pass a Callable with a test case)?
I think it will increase test readability and maintenance a lot.
",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:20:22,151709812,"@@ -0,0 +1,157 @@
+import asyncio
+import json
+import logging
+import os
+import sys
+import time
+from indy import pool
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.constant import Constant, Colors
+from utils.utils import generate_random_string
+from utils.report import HTMLReport
+from utils.report import TestReport, Status
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class MyVars:
+    # Data for generating report
+    test_name = ""Test_Scenario_02_Verify_Messages_On_Connection""
+    test_report = TestReport(test_name)
+    the_error_message = ""the information needed to connect was not found""
+    test_results = {""Step 1"": False, ""Step 2"": False, ""Step 3"": False, ""Step 4"": False}
+
+    """"""  Needed some global variables. """"""
+    pool_handle = 0
+    pool_genesis_txn_file = Constant.pool_genesis_txn_file
+    original_pool_genesis_txn_file = Constant.original_pool_genesis_txn_file
+    pool_name = generate_random_string(""test_pool"", size=20)
+    debug = False
+
+    # cmds
+    back_up_pool_genesis_file = 'cp ' + pool_genesis_txn_file + "" "" + original_pool_genesis_txn_file
+    exit_sovrin = 'exit'
+    remove_pool_genesis_file = 'rm ' + pool_genesis_txn_file
+    restore_pool_genesis_file = 'cp ' + original_pool_genesis_txn_file + "" "" + pool_genesis_txn_file
+
+logger = logging.getLogger(__name__)
+logging.basicConfig(level=logging.INFO)
+
+
+def run(cmd):
+    os.system(cmd)
+
+
+def test_precondition():
+    """"""  Make a copy of pool_transactions_sandbox_genesis  """"""
+    print(Colors.HEADER + ""\nPrecondition \n"" + Colors.ENDC)
+    run(MyVars.back_up_pool_genesis_file)
+    open(MyVars.pool_genesis_txn_file, 'w').close()
+
+
+async def test_scenario_02_verify_messages_on_connection():
+    logger.info(""Test Scenario 02 -> started"")
+
+    try:
+        # 1. Create ledger config from genesis txn file  ---------------------------------------------------------
+        step = ""Step1.  Create Ledger""
+        print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+        pool_config = json.dumps({""genesis_txn"": str(MyVars.pool_genesis_txn_file)})
+
+        try:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151709812,https://github.com/hyperledger/indy-node/pull/456#discussion_r151709812,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Can we make this methos Utility one to avoid code duplication?,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-17 15:22:37,151710359,"@@ -0,0 +1,155 @@
+'''
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+'''
+# /usr/bin/env python3.6
+import sys
+import asyncio
+import json
+import os.path
+import logging
+import time
+from indy import signus
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.utils import generate_random_string
+from utils.constant import Colors, Constant
+from utils.common import Common
+from utils.report import TestReport, Status, HTMLReport
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class MyVars:
+    """"""  Needed some global variables. """"""
+    begin_time = 0
+    pool_handle = 0
+    pool_genesis_txn_file = Constant.pool_genesis_txn_file
+    wallet_handle = 0
+    test_name = ""Test_scenario_04_Keyrings_Wallets""
+    test_report = TestReport(test_name)
+    pool_name = generate_random_string(""test_pool"")
+    wallet_name = generate_random_string(""test_wallet"")
+    debug = False
+    test_results = {'Step1': False, 'Step2': False, 'Step3': False, 'Step4': False}
+
+
+logger = logging.getLogger(__name__)
+logging.basicConfig(level=logging.INFO)
+
+
+def test_precondition():
+    """"""  Delete all files out of the .indy/pool and .indy/wallet directories  """"""
+    print(Colors.HEADER + ""\nPrecondition \n"" + Colors.ENDC)
+    Common.clean_up_pool_and_wallet_folder(MyVars.pool_name, MyVars.wallet_name)
+
+
+async def test_scenario_04_keyrings_wallets():
+    logger.info(""Test Scenario 04 -> started"")
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+
+    # 1. Create and open pool Ledger  ---------------------------------------------------------
+    step = ""Step01. Create and open pool Ledger""
+    print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+    try:
+        MyVars.pool_handle, MyVars.wallet_handle = await Common.prepare_pool_and_wallet(MyVars.pool_name, MyVars.wallet_name, MyVars.pool_genesis_txn_file)
+        MyVars.test_results['Step1'] = True
+        MyVars.test_report.set_step_status(step, Status.PASSED)
+    except IndyError as E:
+        MyVars.test_report.set_test_failed()
+        MyVars.test_report.set_step_status(step, Status.FAILED, str(E))
+        print(Colors.FAIL + str(E) + Colors.ENDC)
+        return None
+
+    # 2. verify wallet was created in .indy/wallet
+    step = ""Step02. Verify wallet was created in .indy/wallet""
+    try:
+        print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+        work_dir = os.path.expanduser('~') + os.sep + "".indy""
+        wallet_path = work_dir + ""/wallet/"" + MyVars.wallet_name
+        result = os.path.exists(wallet_path)
+        if result:
+            MyVars.test_results['Step2'] = True
+            MyVars.test_report.set_step_status(step, Status.PASSED)
+            print(""===PASSED==="")
+    except IndyError as E:
+        MyVars.test_report.set_test_failed()
+        MyVars.test_report.set_step_status(step, Status.FAILED, str(E))
+        print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    await asyncio.sleep(0)
+
+    # 3. create DID to check the new wallet work well.
+    step = ""Step03. Create DID to check the new wallet work well""
+    print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+    try:
+        # create and store did to check the new wallet work well.
+        (default_trustee_did, default_trustee_verkey) = await signus.create_and_store_my_did(
+            MyVars.wallet_handle, json.dumps({""seed"": seed_default_trustee}))
+        if default_trustee_did:
+            MyVars.test_results['Step3'] = True
+            MyVars.test_report.set_step_status(step, Status.PASSED)
+            print(""===PASSED==="")
+    except IndyError as E:
+        MyVars.test_report.set_test_failed()
+        MyVars.test_report.set_step_status(step, Status.FAILED, str(E))
+        print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    # ==================================================================================================================
+    #      !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! End of test, run cleanup !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # ==================================================================================================================
+    # 4. Close wallet and pool ------------------------------------------------------------------------------
+    step = ""Step04. Close and delete the wallet and the pool ledger...""
+    print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+    try:
+        await Common.clean_up_pool_and_wallet(MyVars.pool_name, MyVars.pool_handle, MyVars.wallet_name, MyVars.wallet_handle)
+        MyVars.test_results['Step4'] = True
+        MyVars.test_report.set_step_status(step, Status.PASSED)
+        print(""===PASSED==="")
+    except IndyError as E:
+        MyVars.test_report.set_test_failed()
+        MyVars.test_report.set_step_status(step, Status.FAILED, str(E))
+        print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    await asyncio.sleep(0)
+    logger.info(""Test Scenario 04 -> completed"")
+
+
+def final_result():",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151710359,https://github.com/hyperledger/indy-node/pull/456#discussion_r151710359,ashcherbakov
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We removed it.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 10:53:43,152770648,"@@ -0,0 +1,23 @@
+{",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152770648,https://github.com/hyperledger/indy-node/pull/456#discussion_r152770648,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We removed it.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 10:53:52,152770698,"@@ -0,0 +1,18 @@
+[95m",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152770698,https://github.com/hyperledger/indy-node/pull/456#discussion_r152770698,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We removed it.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 10:53:57,152770715,"@@ -0,0 +1,173 @@
+{
+  ""testcase"": ""Test_Scenario_09_Remove_And_Add_Role"",",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152770715,https://github.com/hyperledger/indy-node/pull/456#discussion_r152770715,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We removed it.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 10:54:57,152770905,"@@ -0,0 +1,118 @@
+[95m",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152770905,https://github.com/hyperledger/indy-node/pull/456#discussion_r152770905,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We removed it.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 10:55:45,152771041,"@@ -0,0 +1,98 @@
+{",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152771041,https://github.com/hyperledger/indy-node/pull/456#discussion_r152771041,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We removed it.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 10:55:51,152771061,"@@ -0,0 +1,53 @@
+{
+  ""testcase"": ""Test_scenario_03_Check_Connection"",",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152771061,https://github.com/hyperledger/indy-node/pull/456#discussion_r152771061,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We removed it.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 10:55:57,152771078,"@@ -0,0 +1,28 @@
+{
+  ""testcase"": ""Test_scenario_04_Keyrings_Wallets"",",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152771078,https://github.com/hyperledger/indy-node/pull/456#discussion_r152771078,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We removed it.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 10:56:06,152771108,"@@ -0,0 +1,293 @@
+<html>",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152771108,https://github.com/hyperledger/indy-node/pull/456#discussion_r152771108,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"We restructured the source code. We put those variables into the TestBaseScenario class.
All test instances will inherit this test base class.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 11:00:56,152772030,"@@ -0,0 +1,157 @@
+import asyncio
+import json
+import logging
+import os
+import sys
+import time
+from indy import pool
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.constant import Constant, Colors
+from utils.utils import generate_random_string
+from utils.report import HTMLReport
+from utils.report import TestReport, Status
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class MyVars:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152772030,https://github.com/hyperledger/indy-node/pull/456#discussion_r152772030,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We created perform method in utils.py for print/try/except pattern.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 11:05:40,152772988,"@@ -0,0 +1,157 @@
+import asyncio
+import json
+import logging
+import os
+import sys
+import time
+from indy import pool
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.constant import Constant, Colors
+from utils.utils import generate_random_string
+from utils.report import HTMLReport
+from utils.report import TestReport, Status
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class MyVars:
+    # Data for generating report
+    test_name = ""Test_Scenario_02_Verify_Messages_On_Connection""
+    test_report = TestReport(test_name)
+    the_error_message = ""the information needed to connect was not found""
+    test_results = {""Step 1"": False, ""Step 2"": False, ""Step 3"": False, ""Step 4"": False}
+
+    """"""  Needed some global variables. """"""
+    pool_handle = 0
+    pool_genesis_txn_file = Constant.pool_genesis_txn_file
+    original_pool_genesis_txn_file = Constant.original_pool_genesis_txn_file
+    pool_name = generate_random_string(""test_pool"", size=20)
+    debug = False
+
+    # cmds
+    back_up_pool_genesis_file = 'cp ' + pool_genesis_txn_file + "" "" + original_pool_genesis_txn_file
+    exit_sovrin = 'exit'
+    remove_pool_genesis_file = 'rm ' + pool_genesis_txn_file
+    restore_pool_genesis_file = 'cp ' + original_pool_genesis_txn_file + "" "" + pool_genesis_txn_file
+
+logger = logging.getLogger(__name__)
+logging.basicConfig(level=logging.INFO)
+
+
+def run(cmd):
+    os.system(cmd)
+
+
+def test_precondition():
+    """"""  Make a copy of pool_transactions_sandbox_genesis  """"""
+    print(Colors.HEADER + ""\nPrecondition \n"" + Colors.ENDC)
+    run(MyVars.back_up_pool_genesis_file)
+    open(MyVars.pool_genesis_txn_file, 'w').close()
+
+
+async def test_scenario_02_verify_messages_on_connection():
+    logger.info(""Test Scenario 02 -> started"")
+
+    try:
+        # 1. Create ledger config from genesis txn file  ---------------------------------------------------------
+        step = ""Step1.  Create Ledger""
+        print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+        pool_config = json.dumps({""genesis_txn"": str(MyVars.pool_genesis_txn_file)})
+
+        try:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152772988,https://github.com/hyperledger/indy-node/pull/456#discussion_r152772988,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"We restructured the source code. We put the step make_final_result into the TestBaseScenario class.
All test instances will inherit this test base class.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 11:08:34,152773569,"@@ -0,0 +1,155 @@
+'''
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+'''
+# /usr/bin/env python3.6
+import sys
+import asyncio
+import json
+import os.path
+import logging
+import time
+from indy import signus
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.utils import generate_random_string
+from utils.constant import Colors, Constant
+from utils.common import Common
+from utils.report import TestReport, Status, HTMLReport
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class MyVars:
+    """"""  Needed some global variables. """"""
+    begin_time = 0
+    pool_handle = 0
+    pool_genesis_txn_file = Constant.pool_genesis_txn_file
+    wallet_handle = 0
+    test_name = ""Test_scenario_04_Keyrings_Wallets""
+    test_report = TestReport(test_name)
+    pool_name = generate_random_string(""test_pool"")
+    wallet_name = generate_random_string(""test_wallet"")
+    debug = False
+    test_results = {'Step1': False, 'Step2': False, 'Step3': False, 'Step4': False}
+
+
+logger = logging.getLogger(__name__)
+logging.basicConfig(level=logging.INFO)
+
+
+def test_precondition():
+    """"""  Delete all files out of the .indy/pool and .indy/wallet directories  """"""
+    print(Colors.HEADER + ""\nPrecondition \n"" + Colors.ENDC)
+    Common.clean_up_pool_and_wallet_folder(MyVars.pool_name, MyVars.wallet_name)
+
+
+async def test_scenario_04_keyrings_wallets():
+    logger.info(""Test Scenario 04 -> started"")
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+
+    # 1. Create and open pool Ledger  ---------------------------------------------------------
+    step = ""Step01. Create and open pool Ledger""
+    print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+    try:
+        MyVars.pool_handle, MyVars.wallet_handle = await Common.prepare_pool_and_wallet(MyVars.pool_name, MyVars.wallet_name, MyVars.pool_genesis_txn_file)
+        MyVars.test_results['Step1'] = True
+        MyVars.test_report.set_step_status(step, Status.PASSED)
+    except IndyError as E:
+        MyVars.test_report.set_test_failed()
+        MyVars.test_report.set_step_status(step, Status.FAILED, str(E))
+        print(Colors.FAIL + str(E) + Colors.ENDC)
+        return None
+
+    # 2. verify wallet was created in .indy/wallet
+    step = ""Step02. Verify wallet was created in .indy/wallet""
+    try:
+        print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+        work_dir = os.path.expanduser('~') + os.sep + "".indy""
+        wallet_path = work_dir + ""/wallet/"" + MyVars.wallet_name
+        result = os.path.exists(wallet_path)
+        if result:
+            MyVars.test_results['Step2'] = True
+            MyVars.test_report.set_step_status(step, Status.PASSED)
+            print(""===PASSED==="")
+    except IndyError as E:
+        MyVars.test_report.set_test_failed()
+        MyVars.test_report.set_step_status(step, Status.FAILED, str(E))
+        print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    await asyncio.sleep(0)
+
+    # 3. create DID to check the new wallet work well.
+    step = ""Step03. Create DID to check the new wallet work well""
+    print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+    try:
+        # create and store did to check the new wallet work well.
+        (default_trustee_did, default_trustee_verkey) = await signus.create_and_store_my_did(
+            MyVars.wallet_handle, json.dumps({""seed"": seed_default_trustee}))
+        if default_trustee_did:
+            MyVars.test_results['Step3'] = True
+            MyVars.test_report.set_step_status(step, Status.PASSED)
+            print(""===PASSED==="")
+    except IndyError as E:
+        MyVars.test_report.set_test_failed()
+        MyVars.test_report.set_step_status(step, Status.FAILED, str(E))
+        print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    # ==================================================================================================================
+    #      !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! End of test, run cleanup !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+    # ==================================================================================================================
+    # 4. Close wallet and pool ------------------------------------------------------------------------------
+    step = ""Step04. Close and delete the wallet and the pool ledger...""
+    print(Colors.HEADER + ""\n\t {0}\n"".format(step) + Colors.ENDC)
+    try:
+        await Common.clean_up_pool_and_wallet(MyVars.pool_name, MyVars.pool_handle, MyVars.wallet_name, MyVars.wallet_handle)
+        MyVars.test_results['Step4'] = True
+        MyVars.test_report.set_step_status(step, Status.PASSED)
+        print(""===PASSED==="")
+    except IndyError as E:
+        MyVars.test_report.set_test_failed()
+        MyVars.test_report.set_step_status(step, Status.FAILED, str(E))
+        print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    await asyncio.sleep(0)
+    logger.info(""Test Scenario 04 -> completed"")
+
+
+def final_result():",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152773569,https://github.com/hyperledger/indy-node/pull/456#discussion_r152773569,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"We only see the "".indy"" directory. We are using lib-indy version 1.0.1 . This variable is defined in file ""constant.py"", users can change if needed.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 11:14:17,152774709,"@@ -0,0 +1,44 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" 
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """""" 
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete
+    NONE = """"
+
+
+class Constant:
+    """""" 
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152774709,https://github.com/hyperledger/indy-node/pull/456#discussion_r152774709,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Yup. We changed default path to /var/lib/indy/sandbox/pool_transactions_genesis with the comment that users can change if needed as Steve's comment.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-11-23 11:16:29,152775238,"@@ -0,0 +1,44 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" 
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """""" 
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete
+    NONE = """"
+
+
+class Constant:
+    """""" 
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    pool_genesis_txn_file = os.path.expanduser('~') + os.sep + "".sovrin/pool_transactions_sandbox_genesis""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/152775238,https://github.com/hyperledger/indy-node/pull/456#discussion_r152775238,NgoAnhKhoi
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"The base directory for indy acceptance tests is `indy-node/acceptance`. It should be added to `PYTHONPATH`, not `indy-node/acceptance/indy_acceptance/indy-tests`. (By the way, in PyCharm the directory being opened as a project is added to `PYTHONPATH` automatically.) `indy_acceptance` is the top-level package which contains all the acceptance stuff. This package contains the subpackage `test` which contains pytest-based tests. This subpackage was created just to follow the common layout for all indy projects where all the pytest-based tests are located in subpackages named `test`. Taking into account that the new acceptance tests are not driven by any unit test framework but are standalone python scripts, we should locate them at `indy_acceptance` package, not at `indy_acceptance/indy-tests`. Since `indy-node/acceptance` will be the content root and `indy_acceptance` package will be the top-level package, then all the imports must be corrected correspondingly. For example, `from libraries import utils` must be changed to `from indy_acceptance.libraries import utils`. (In general, it is a bad practice to use so common names as `libraries` for project-specific top-level packages.)",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 10:37:00,156035229,"@@ -0,0 +1,2 @@
+Note: You need to set the PYTHONPATH before you run a test. It should point to the indy_acceptance folder.
+e.g.: export PYTHONPATH=$PYTHONPATH:/home/user_name/indy_acceptance",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156035229,https://github.com/hyperledger/indy-node/pull/456#discussion_r156035229,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,The argument should be named `result` rather than `code`. Actually `result` will contain a code in case it will be of `IndyError` type.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 10:44:24,156037013,"@@ -0,0 +1,131 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Colors, Message
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars"" % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(code):",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156037013,https://github.com/hyperledger/indy-node/pull/456#discussion_r156037013,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"The condition can be simplified just to:
`isinstance(code, Exception)`
because `IndyError` is a subclass of `Exception`.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 10:46:19,156037447,"@@ -0,0 +1,131 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Colors, Message
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars"" % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(code):
+    """"""
+    If ""code"" is an exception then raise the ""code"".
+    Unless ""code"" is an exception then return the ""code"".
+    :param code: (optional) code that you want to check.
+    :return: ""code"" if it is not an exception.
+    """"""
+    if (isinstance(code, IndyError) or (isinstance(code, Exception))):",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156037447,https://github.com/hyperledger/indy-node/pull/456#discussion_r156037447,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"What is the reason to use `new_event_loop` rather than `get_event_loop` here?
As I can see, we should use `get_event_loop` and later call `close` on the returned event loop only one time - at the upper level in `TestScenarioBase.execute_scenario`.
So it seems that the method `run_async_method` is redundant. We can get an event loop, run each async method on it until complete and then close the event loop in `TestScenarioBase.execute_scenario`.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:02:32,156042233,"@@ -0,0 +1,131 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Colors, Message
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars"" % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(code):
+    """"""
+    If ""code"" is an exception then raise the ""code"".
+    Unless ""code"" is an exception then return the ""code"".
+    :param code: (optional) code that you want to check.
+    :return: ""code"" if it is not an exception.
+    """"""
+    if (isinstance(code, IndyError) or (isinstance(code, Exception))):
+        exit(1)
+    else:
+        return code
+
+
+async def perform(steps, func, *agrs):
+    """"""
+    Execute an function and set status, message for the last test step depend on the result of the function.
+
+    :param steps: (optional) list of test steps.
+    :param func: (optional) executed function.
+    :param agrs: argument of function.
+    :return: the result of function of the exception that the function raise.
+    """"""
+    try:
+        result = await func(*agrs)
+        steps.get_last_step().set_status(Status.PASSED)
+    except IndyError as E:
+        print(Colors.FAIL + Message.INDY_ERROR.format(str(E)) + Colors.ENDC)
+        steps.get_last_step().set_message(str(E))
+        steps.get_last_step().set_status(Status.FAILED)
+        return E
+    except Exception as Ex:
+        print(Colors.FAIL + Message.EXCEPTION.format(str(Ex)) + Colors.ENDC)
+        steps.get_last_step().set_message(str(Ex))
+        steps.get_last_step().set_status(Status.FAILED)
+        return Ex
+    return result
+
+
+async def perform_with_expected_code(steps, func, *agrs, expected_code=0):
+    """"""
+    Execute the ""func"" with expectation that the ""func"" raise an IndyError that IndyError.error_code = ""expected_code"".
+
+    :param steps: (optional) list of test steps.
+    :param func: (optional) executed function.
+    :param agrs: arguments of ""func"".
+    :param expected_code: the error code that you expect in IndyError.
+    :return: exception if the ""func"" raise it without ""expected_code"".
+             'None' if the ""func"" run without any exception of the exception contain ""expected_code"".
+    """"""
+    try:
+        await func(*agrs)
+        steps.get_last_step().set_message(""Can execute without exception."")
+        steps.get_last_step().set_status(Status.FAILED)
+        return None
+    except IndyError as E:
+        if E.error_code == expected_code:
+            steps.get_last_step().set_status(Status.PASSED)
+            return None
+        else:
+            print(Colors.FAIL + Message.INDY_ERROR.format(str(E)) + Colors.ENDC)
+            steps.get_last_step().set_message(str(E))
+            return E
+    except Exception as Ex:
+        print(Colors.FAIL + Message.EXCEPTION.format(str(Ex)) + Colors.ENDC)
+        return Ex
+
+
+def run_async_method(method):
+    """"""
+    Run async method until it complete.
+
+    :param method: (optional).
+    """"""
+    import asyncio
+    loop = asyncio.new_event_loop()",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156042233,https://github.com/hyperledger/indy-node/pull/456#discussion_r156042233,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,This line seems to be debug stuff and should be removed.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:10:16,156043991,"@@ -0,0 +1,159 @@
+""""""
+Created on Nov 13, 2017
+
+@author: khoi.ngo
+
+Containing all functions that is common among test scenarios.
+""""""
+
+import asyncio
+import json
+from indy import wallet, pool, ledger
+from .constant import Colors, Constant, Message
+
+
+class Common:
+    """"""
+    Wrapper common function for test scenario.
+    """"""
+
+    @staticmethod
+    async def prepare_pool_and_wallet(pool_name, wallet_name, pool_genesis_txn_file):
+        """"""
+        Prepare pool and wallet to use in a test case.
+
+        :param pool_name: Name of the pool ledger configuration.
+        :param wallet_name: Name of the wallet.
+        :param pool_genesis_txn_file: The path of the pool_genesis_transaction file.
+        :return: The pool handle and the wallet handle were created.
+        """"""
+        pool_handle = await Common().create_and_open_pool(pool_name, pool_genesis_txn_file)
+        wallet_handle = await Common().create_and_open_wallet(pool_name, wallet_name)
+        return pool_handle, wallet_handle
+
+    @staticmethod
+    async def clean_up_pool_and_wallet(pool_name, pool_handle, wallet_name, wallet_handle):
+        """"""
+        Clean up pool and wallet. Using as a post condition of a test case.
+
+        :param pool_name: The name of the pool.
+        :param pool_handle: The handle of the pool.
+        :param wallet_name: The name of the wallet.
+        :param wallet_handle: The handle of the wallet.
+        """"""
+        await Common().close_pool_and_wallet(pool_handle, wallet_handle)
+        await Common().delete_pool_and_wallet(pool_name, wallet_name)
+
+    @staticmethod
+    def clean_up_pool_and_wallet_folder(pool_name, wallet_name):
+        """"""
+        Delete pool and wallet folder without using lib-indy.
+
+        :param pool_name: The name of the pool.
+        :param wallet_name: The name of the wallet.
+        """"""
+        import os
+        import shutil
+        work_dir = Constant.work_dir
+
+        if os.path.exists(work_dir + ""/pool/"" + pool_name):
+            try:
+                shutil.rmtree(work_dir + ""/pool/"" + pool_name)
+            except IOError as E:
+                print(Colors.FAIL + str(E) + Colors.ENDC)
+
+        if os.path.exists(work_dir + ""/wallet/"" + wallet_name):
+            try:
+                shutil.rmtree(work_dir + ""/wallet/"" + wallet_name)
+            except IOError as E:
+                print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    @staticmethod
+    async def build_and_send_nym_request(pool_handle, wallet_handle, submitter_did,
+                                         target_did, target_verkey, alias, role):
+        """"""
+        Build a nym request and send it.
+
+        :param pool_handle: pool handle returned by indy_open_pool_ledger.
+        :param wallet_handle: wallet handle returned by indy_open_wallet.
+        :param submitter_did: Id of Identity stored in secured Wallet.
+        :param target_did: Id of Identity stored in secured Wallet.
+        :param target_verkey: verification key.
+        :param alias: alias.
+        :param role: Role of a user NYM record.
+        :raise Exception if the method has error.
+        """"""
+        nym_txn_req = await ledger.build_nym_request(submitter_did, target_did, target_verkey, alias, role)
+        await ledger.sign_and_submit_request(pool_handle, wallet_handle, submitter_did, nym_txn_req)
+
+    @staticmethod
+    async def create_and_open_pool(pool_name, pool_genesis_txn_file):
+        """"""
+        Creates a new local pool ledger configuration.
+        Then open that pool and return the pool handle that can be used later to connect pool nodes.
+
+        :param pool_name: Name of the pool ledger configuration.
+        :param pool_genesis_txn_file: Pool configuration json. if NULL, then default config will be used.
+        :return: The pool handle was created.
+        """"""
+        import os
+        if os.path.exists(pool_genesis_txn_file) is not True:
+            error_message = Colors.FAIL + ""\n{}\n"".format(Message.ERR_PATH_DOES_NOT_EXIST.format(Constant.pool_genesis_txn_file)) + Colors.ENDC
+            raise ValueError(error_message)
+
+        print(Colors.HEADER + ""\nCreate Ledger\n"" + Colors.ENDC)
+        pool_config = json.dumps({""genesis_txn"": str(pool_genesis_txn_file)})
+        await pool.create_pool_ledger_config(pool_name, pool_config)
+
+        print(Colors.HEADER + ""\nOpen pool ledger\n"" + Colors.ENDC)
+        pool_handle = await pool.open_pool_ledger(pool_name, None)
+        return pool_handle
+
+    @staticmethod
+    async def create_and_open_wallet(pool_name, wallet_name):
+        """"""
+        Creates a new secure wallet with the given unique name.
+        Then open that wallet and get the wallet handle that can
+        be used later to use in methods that require wallet access.
+
+        :param pool_name: Name of the pool that corresponds to this wallet.
+        :param wallet_name: Name of the wallet.
+        :return: The wallet handle was created.
+        """"""
+        print(Colors.HEADER + ""\nCreate wallet\n"" + Colors.ENDC)
+        await wallet.create_wallet(pool_name, wallet_name, None, None, None)
+
+        print(Colors.HEADER + ""\nGet wallet handle\n"" + Colors.ENDC)
+        wallet_handle = await wallet.open_wallet(wallet_name, None, None)
+        return wallet_handle
+
+    @staticmethod
+    async def close_pool_and_wallet(pool_handle, wallet_handle):
+        """"""
+        Close the pool and wallet with the pool and wallet handle.
+
+        :param pool_handle: pool handle returned by indy_open_pool_ledger.
+        :param wallet_handle: wallet handle returned by indy_open_wallet.
+        :raise Exception if the method has error.
+        """"""
+        print(Colors.HEADER + ""\nClose pool\n"" + Colors.ENDC)
+        await pool.close_pool_ledger(pool_handle)
+
+        print(Colors.HEADER + ""\nClose wallet\n"" + Colors.ENDC)
+        await wallet.close_wallet(wallet_handle)
+
+    @staticmethod
+    async def delete_pool_and_wallet(pool_name, wallet_name):
+        """"""
+        Delete the pool and wallet with the pool and wallet name.
+
+        :param pool_name: Name of the pool that corresponds to this wallet.
+        :param wallet_name: Name of the wallet to delete.
+        :raise Exception if the method has error.
+        """"""
+        print(Colors.HEADER + ""\nDelete pool\n"" + Colors.ENDC)
+        await pool.delete_pool_ledger_config(pool_name)
+
+        print(Colors.HEADER + ""\nDelete wallet\n"" + Colors.ENDC)
+        await wallet.delete_wallet(wallet_name, None)
+        await asyncio.sleep(0)",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156043991,https://github.com/hyperledger/indy-node/pull/456#discussion_r156043991,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"There is no need to instantiate a class to access its static member. This line might be corrected as:
`pool_handle = await Common.create_and_open_pool(pool_name, pool_genesis_txn_file)`",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:16:10,156045302,"@@ -0,0 +1,159 @@
+""""""
+Created on Nov 13, 2017
+
+@author: khoi.ngo
+
+Containing all functions that is common among test scenarios.
+""""""
+
+import asyncio
+import json
+from indy import wallet, pool, ledger
+from .constant import Colors, Constant, Message
+
+
+class Common:
+    """"""
+    Wrapper common function for test scenario.
+    """"""
+
+    @staticmethod
+    async def prepare_pool_and_wallet(pool_name, wallet_name, pool_genesis_txn_file):
+        """"""
+        Prepare pool and wallet to use in a test case.
+
+        :param pool_name: Name of the pool ledger configuration.
+        :param wallet_name: Name of the wallet.
+        :param pool_genesis_txn_file: The path of the pool_genesis_transaction file.
+        :return: The pool handle and the wallet handle were created.
+        """"""
+        pool_handle = await Common().create_and_open_pool(pool_name, pool_genesis_txn_file)",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156045302,https://github.com/hyperledger/indy-node/pull/456#discussion_r156045302,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"In Python there is no necessity to use classes as containers of static members as it would be in Java.
In Python a module is a natural container for static data and functions.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:21:28,156046385,"@@ -0,0 +1,159 @@
+""""""
+Created on Nov 13, 2017
+
+@author: khoi.ngo
+
+Containing all functions that is common among test scenarios.
+""""""
+
+import asyncio
+import json
+from indy import wallet, pool, ledger
+from .constant import Colors, Constant, Message
+
+
+class Common:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156046385,https://github.com/hyperledger/indy-node/pull/456#discussion_r156046385,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"In Python there is no necessity to use classes as containers of static members as it would be in Java.
In Python a module is a natural container for static data and functions.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:24:17,156046975,"@@ -0,0 +1,519 @@
+""""""
+Created on Nov 12, 2017
+
+@author: nghia.huynh
+
+Containing all functions and classes to make a HTML report.
+""""""
+import os
+import json
+import socket
+import platform
+import glob
+import sys
+import subprocess
+import errno
+
+
+class FileNameGetter:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156046975,https://github.com/hyperledger/indy-node/pull/456#discussion_r156046975,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"In Python there is no necessity to use classes as containers of static members as it would be in Java.
In Python a module is a natural container for static data and functions.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:25:33,156047248,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156047248,https://github.com/hyperledger/indy-node/pull/456#discussion_r156047248,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,This class must be a subclass of `Enum`. Also the name of enumeration class should be a singular noun.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:31:54,156048477,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156048477,https://github.com/hyperledger/indy-node/pull/456#discussion_r156048477,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,This class must be a subclass of `Enum`. Also the name of enumeration class should be a singular noun.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:32:12,156048535,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156048535,https://github.com/hyperledger/indy-node/pull/456#discussion_r156048535,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"In Python there is no necessity to use classes as containers of static members as it would be in Java.
In Python a module is a natural container for static data and functions.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:33:57,156048817,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""
+    pool_genesis_txn_file = genesis_transaction_file_path + ""pool_transactions_sandbox_genesis""
+    domain_transactions_sandbox_genesis = genesis_transaction_file_path + ""domain_transactions_sandbox_genesis""
+    original_pool_genesis_txn_file = genesis_transaction_file_path + ""original_pool_transactions_sandbox_genesis""
+
+
+class Message:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156048817,https://github.com/hyperledger/indy-node/pull/456#discussion_r156048817,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,This class must be a subclass of `Enum`.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:35:35,156049116,"@@ -0,0 +1,127 @@
+""""""
+Created on Nov 9, 2017
+
+@author: nhan.nguyen
+
+Containing classes to make the test result as a json.
+""""""
+
+import json
+import time
+import os
+import errno
+from .constant import Colors
+
+
+class KeyWord:
+    TEST_CASE = ""testcase""
+    RESULT = ""result""
+    START_TIME = ""starttime""
+    DURATION = ""duration""
+    RUN = ""run""
+    STEP = ""step""
+    STATUS = ""status""
+    MESSAGE = ""message""
+
+
+class Status:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156049116,https://github.com/hyperledger/indy-node/pull/456#discussion_r156049116,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"In Python there is no necessity to use classes as containers of static members as it would be in Java.
In Python a module is a natural container for static data and functions.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:36:20,156049273,"@@ -0,0 +1,127 @@
+""""""
+Created on Nov 9, 2017
+
+@author: nhan.nguyen
+
+Containing classes to make the test result as a json.
+""""""
+
+import json
+import time
+import os
+import errno
+from .constant import Colors
+
+
+class KeyWord:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156049273,https://github.com/hyperledger/indy-node/pull/456#discussion_r156049273,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Any class extends `object`. So there is no need to specify `object` as a superclass explicitly.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:44:10,156050783,"@@ -0,0 +1,88 @@
+""""""
+Created on Nov 22, 2017
+
+@author: nhan.nguyen
+
+Containing classes to catch the log on console and write it file.
+""""""
+
+import sys
+import os
+import time
+import errno
+import logging
+from .result import Status
+from .constant import Colors
+
+
+class Printer(object):",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156050783,https://github.com/hyperledger/indy-node/pull/456#discussion_r156050783,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Any class extends `object`. So there is no need to specify `object` as a superclass explicitly.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 11:44:24,156050827,"@@ -0,0 +1,74 @@
+""""""
+Created on Nov 22, 2017
+
+@author: khoi.ngo
+
+Containing the test base class.
+""""""
+import time
+import os
+import inspect
+from libraries.utils import generate_random_string, run_async_method, make_final_result
+from libraries.constant import Constant
+from libraries.common import Common
+from libraries.logger import Logger
+from libraries.result import TestResult
+from libraries.step import Steps
+
+
+class TestScenarioBase(object):",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156050827,https://github.com/hyperledger/indy-node/pull/456#discussion_r156050827,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,The status of the current step is overwritten many times. So FAILED status may be overwritten by PASSED that is obviously not the expected behavior.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 13:15:56,156069031,"@@ -0,0 +1,421 @@
+""""""
+Created on Nov 8, 2017
+
+@author: nhan.nguyen
+
+Containing test script of test scenario 09: remove and add role.
+""""""
+import json
+from indy import ledger, signus
+from libraries.constant import Constant, Colors, Roles
+from libraries.result import Status
+from libraries.common import Common
+from libraries import utils
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario09(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        """"""
+        This function is the main part of test script.
+        All steps that involve to role TGB (9, 10, a half of 24) will be skipped because
+        role TGB is not supported by libindy.
+        There is a bug in this scenario (in step 22, 23 24) so we log a bug here.
+        """"""
+        try:
+            # 1. Create and open wallet, pool ledger.
+            self.steps.add_step(""Create and open wallet, pool ledger"")
+            result = await utils.perform(self.steps, Common.prepare_pool_and_wallet,
+                                         self.pool_name, self.wallet_name, Constant.pool_genesis_txn_file)
+            utils.exit_if_exception(result)
+            (self.pool_handle, self.wallet_handle) = result
+
+            # 2. Create DIDs.
+            self.steps.add_step(""Create DIDs"")
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = result[0] if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156069031,https://github.com/hyperledger/indy-node/pull/456#discussion_r156069031,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,The status of the current step is overwritten many times. So FAILED status may be overwritten by PASSED that is obviously not the expected behavior.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 13:27:06,156071563,"@@ -0,0 +1,168 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test scripts of test scenario 11: special case for TrustAnchor role.
+""""""
+
+# !/usr/bin/env python3.6
+import json
+from indy import ledger, signus
+from indy.error import IndyError
+from libraries.constant import Constant, Colors, Roles
+from libraries.common import Common
+from libraries.utils import perform, generate_random_string, exit_if_exception, perform_with_expected_code
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class TestScenario11(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        print(""Test Scenario 11 -> started"")
+        # Declare all values use in the test
+        seed_trustee1 = generate_random_string(prefix=""Trustee1"", size=32)
+        seed_trustee2 = generate_random_string(prefix=""Trustee2"", size=32)
+        seed_steward1 = generate_random_string(prefix=""Steward1"", size=32)
+        seed_steward2 = generate_random_string(prefix=""Steward2"", size=32)
+        seed_trustanchor1 = generate_random_string(prefix=""TrustAnchor1"", size=32)
+        seed_trustanchor2 = generate_random_string(prefix=""TrustAnchor2"", size=32)
+        seed_trustanchor3 = generate_random_string(prefix=""TrustAnchor3"", size=32)
+        try:
+            # 1. Create ledger config from genesis txn file  ---------------------------------------------------------
+            self.steps.add_step(""Create and open pool Ledger"")
+            returned_code = await perform(self.steps, Common.prepare_pool_and_wallet, self.pool_name,
+                                          self.wallet_name, self.pool_genesis_txn_file)
+
+            self.pool_handle, self.wallet_handle = exit_if_exception(returned_code)
+
+            # 2. Create DIDs ----------------------------------------------------
+            self.steps.add_step(""Create DIDs"")
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,
+                                          self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = returned_code[0] if len(returned_code) == 2 else (None, None)
+
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156071563,https://github.com/hyperledger/indy-node/pull/456#discussion_r156071563,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Domain transactions genesis file is not used by a client. So this constant should be removed.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 13:48:51,156076706,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""
+    pool_genesis_txn_file = genesis_transaction_file_path + ""pool_transactions_sandbox_genesis""
+    domain_transactions_sandbox_genesis = genesis_transaction_file_path + ""domain_transactions_sandbox_genesis""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156076706,https://github.com/hyperledger/indy-node/pull/456#discussion_r156076706,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"This path is the node path to `sandbox` pool. So it does not relate to the acceptance tests or libindy. By default we should use the pool transactions genesis file bundled with the acceptance tests. It is `pool.txn` from `indy-node/acceptance` directory that must be the content root.
However, `pool.txn` must be updated - BLS keys of nodes must be added to it. Also it makes sense to change IP addresses of nodes in `pool.txn` to ones being used in Docker pool.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 14:03:09,156080321,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156080321,https://github.com/hyperledger/indy-node/pull/456#discussion_r156080321,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please see the comment above.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 14:03:39,156080459,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""
+    pool_genesis_txn_file = genesis_transaction_file_path + ""pool_transactions_sandbox_genesis""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156080459,https://github.com/hyperledger/indy-node/pull/456#discussion_r156080459,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"Ideally we should not continue the test in case some its step has been failed. So, if any exception is raised, the test should not try to recover and continue execution (unless this exception is expected by the test). The whole test must fail at this step. Such the approach simplifies tests. It eliminates necessity to use conditional logic for steps below that depend on the step which can fail.

If in case some step has failed, we still have some steps below that may be verified, then this indicates that we actually have several branches in the test and such the branches should be divided into separate tests.

We think that in one of next pull requests we should divide test scenarios in such a way that we will no need to continue a test if some step has failed. This will allow us to get rid of translating exceptions to return values in helper methods and correspondingly of using conditional logic in handling step results and performing dependent steps below. This, in turn, will significantly simplify the code of tests.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 16:11:25,156118806,"@@ -0,0 +1,421 @@
+""""""
+Created on Nov 8, 2017
+
+@author: nhan.nguyen
+
+Containing test script of test scenario 09: remove and add role.
+""""""
+import json
+from indy import ledger, signus
+from libraries.constant import Constant, Colors, Roles
+from libraries.result import Status
+from libraries.common import Common
+from libraries import utils
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario09(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        """"""
+        This function is the main part of test script.
+        All steps that involve to role TGB (9, 10, a half of 24) will be skipped because
+        role TGB is not supported by libindy.
+        There is a bug in this scenario (in step 22, 23 24) so we log a bug here.
+        """"""
+        try:
+            # 1. Create and open wallet, pool ledger.
+            self.steps.add_step(""Create and open wallet, pool ledger"")
+            result = await utils.perform(self.steps, Common.prepare_pool_and_wallet,
+                                         self.pool_name, self.wallet_name, Constant.pool_genesis_txn_file)
+            utils.exit_if_exception(result)
+            (self.pool_handle, self.wallet_handle) = result
+
+            # 2. Create DIDs.
+            self.steps.add_step(""Create DIDs"")
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = result[0] if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustee1_did, trustee1_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustee2_did, trustee2_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (steward1_did, steward1_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (steward2_did, steward2_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (steward3_did, steward3_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustanchor1_did, trustanchor1_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustanchor2_did, trustanchor2_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustanchor3_did, trustanchor3_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (user1_did, user1_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (user3_did, user3_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (user4_did, user4_verkey) = result if len(result) == 2 else (None, None)
+
+            # ==========================================================================================================
+            # Test starts here !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+            # ==========================================================================================================
+
+            # 3. Using default Trustee to create Trustee1.
+            self.steps.add_step(""Using default Trustee to create Trustee1"")
+            await self.add_nym(default_trustee_did, trustee1_did, trustee1_verkey, None, Roles.TRUSTEE)
+
+            # 4. Verify GET NYM - Trustee1.
+            self.steps.add_step(""Verify GET NYM - Trustee1"")
+            await self.get_nym(default_trustee_did, trustee1_did)
+
+            # 5. Using Trustee1 to create Steward1.
+            self.steps.add_step(""Using Trustee1 to create Steward1"")
+            await self.add_nym(trustee1_did, steward1_did, steward1_verkey, None, Roles.STEWARD)
+
+            # 6. Verify GET NYM - Steward1.
+            self.steps.add_step(""Verify GET NYM - Steward1"")
+            await self.get_nym(trustee1_did, steward1_did)
+
+            # 7. Add identity (no role) by Trustee1.
+            self.steps.add_step(""Add identity (no role) by Trustee1"")
+            await self.add_nym(trustee1_did, user3_did, user3_verkey, None, None)
+
+            # 8. Verify GET NYM - no role.
+            self.steps.add_step(""Verify GET NYM - no role"")
+            await self.get_nym(trustee1_did, user3_did)
+
+            # Role TGB is not exist so we do not execute step 9.
+            # 9. Using Trustee1 to create a TGB role.
+            self.steps.add_step(""Using Trustee1 to create a TGB role (SKIP)"")
+            self.steps.get_last_step().set_status(Status.PASSED)
+
+            # Role TGB is not exist so we do not execute step 12.
+            # 10. Verify GET NYM - TGB1.
+            self.steps.add_step(""Verify GET NYM - TGB1 (SKIP)"")
+            self.steps.get_last_step().set_status(Status.PASSED)
+
+            # 11. Using Steward1 to create TrustAnchor1.
+            self.steps.add_step(""Using Steward1 to create TrustAnchor1"")
+            await self.add_nym(steward1_did, trustanchor1_did, trustanchor1_verkey, None, Roles.TRUST_ANCHOR)
+
+            # 12. Verify GET NYM - TrustAnchor1.
+            self.steps.add_step(""Verify GET NYM - TrustAnchor1"")
+            await self.get_nym(steward1_did, trustanchor1_did)
+
+            # 13. Verify add identity (no role) by Steward1.
+            self.steps.add_step(""Verify add identity (no role) by Steward1"")
+            await self.add_nym(steward1_did, user4_did, user4_verkey, None, None)
+
+            # 14. Verify GET NYM.
+            self.steps.add_step(""Verify GET NYM - no role"")
+            await self.get_nym(steward1_did, user4_did)
+
+            # 15. Verify that a Steward cannot create another Steward.
+            self.steps.add_step(""Verify that Steward cannot create another Steward"")
+            (temp, message) = await self.add_nym(steward1_did, steward2_did, steward2_verkey, None,
+                                                 Roles.STEWARD, error_code=304)
+            if temp:
+                print(Colors.OKGREEN + ""::PASS::Validated that a Steward cannot create a Steward!\n"" + Colors.ENDC)
+            else:
+                if message is None:
+                    message = ""Steward can create another Steward (should fail)""
+                self.steps.get_last_step().set_message(message)
+
+            # 16. Verify that a Steward cannot create a Trustee.
+            self.steps.add_step(""Verify that a Steward cannot create a Trustee"")
+            (temp, message) = await self.add_nym(steward1_did, trustee1_did, trustee1_verkey,
+                                                 None, Roles.TRUSTEE, error_code=304)
+
+            if temp:
+                print(Colors.OKGREEN + ""::PASS::Validated that a Steward cannot create a Trustee!\n"" + Colors.ENDC)
+            else:
+                if message is None:
+                    message = ""Steward can create a Trustee (should fail)""
+                self.steps.get_last_step().set_message(message)
+
+            # 17. Using TrustAnchor1 to add a NYM.
+            self.steps.add_step(""Using TrustAnchor1 to add a NYM"")
+            await self.add_nym(trustanchor1_did, user1_did, user1_verkey, None, None)
+
+            # 18. Verify GET NYM - User1.
+            self.steps.add_step(""Verify GET NYM - User1"")
+            await self.get_nym(trustanchor1_did, user1_did)
+
+            # 19. Verify that TrustAnchor cannot create another TrustAnchor.
+            self.steps.add_step(""Verify that TrustAnchor cannot create another TrustAnchor"")
+            (temp, message) = await self.add_nym(trustanchor1_did, trustanchor2_did, trustanchor2_verkey,
+                                                 None, Roles.TRUST_ANCHOR, error_code=304)
+            if temp:
+                print(Colors.OKGREEN + ""::PASS::Validated that a TrustAnchor cannot create another TrustAnchor!\n"" + Colors.ENDC)
+            else:
+                if message is None:
+                    message = ""TrustAnchor can create another TrustAnchor (should fail)""
+                self.steps.get_last_step().set_message(message)
+
+            # 20. Using default Trustee to remove new roles.
+            bug_is_430 = ""Bug: https://jira.hyperledger.org/browse/IS-430""
+            self.steps.add_step(""Using default Trustee to remove new roles"")
+            message_20 = """"
+            (temp, message) = await self.add_nym(default_trustee_did, trustee1_did, trustee1_verkey,
+                                                 None, Roles.NONE)
+            result = temp
+            if not temp:
+                message_20 += ""\nCannot remove Trustee1's role - "" + message
+            else:
+                (temp, message) = await self.get_nym(default_trustee_did, trustee1_did)
+                if not temp:
+                    message_20 += ""\nCannot check self.get_nym for Trustee1 - "" + message
+                else:
+                    if not TestScenario09.check_role_in_retrieved_nym(message, Roles.NONE):
+                        temp = False
+                        message_20 += ""\nCannot remove Trustee1's role""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156118806,https://github.com/hyperledger/indy-node/pull/456#discussion_r156118806,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,These `try / except` block and logging the whole test start / finish statuses are common for all the test scenarios. They should be moved to `TestScenarioBase`. For this an attribute `name` should be introduced in `TestScenarioBase`. The value for it must be provided when initializing a concrete test scenario class.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 16:27:22,156123925,"@@ -0,0 +1,52 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test script of test scenario 04: keyrings wallets.
+""""""
+# !/usr/bin/env python3.6
+import json
+import os.path
+from indy import signus
+from indy.error import IndyError
+from libraries.constant import Constant, Colors
+from libraries.result import Status
+from libraries.common import Common
+from libraries.utils import exit_if_exception, perform
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario04(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        print(""Test Scenario 04 -> started"")
+        try:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156123925,https://github.com/hyperledger/indy-node/pull/456#discussion_r156123925,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,It is a good practice to name a module correspondingly (except for the case) to the name of the class contained in it (at least in case the module contains a sole class only). Consider renaming test scenario modules or classes for they to correspond with each other.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-11 16:44:10,156129200,"@@ -0,0 +1,59 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test script of test scenario 02: verify messages on connection.
+""""""
+
+import json
+import os
+from indy import pool
+from libraries.constant import Constant, Colors
+from libraries.result import Status
+from libraries.utils import perform
+from test_scripts.test_scenario_base import TestScenarioBase
+
+"""""" cmds """"""
+back_up_pool_genesis_file = 'sudo cp ' + Constant.pool_genesis_txn_file + "" "" + Constant.original_pool_genesis_txn_file
+remove_pool_genesis_file = 'sudo rm ' + Constant.pool_genesis_txn_file
+restore_pool_genesis_file = 'sudo cp ' + Constant.original_pool_genesis_txn_file + "" "" + Constant.pool_genesis_txn_file
+create_empty_pool_genesis_file = 'sudo touch ' + Constant.pool_genesis_txn_file
+
+
+class TestScenario02(TestScenarioBase):",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/156129200,https://github.com/hyperledger/indy-node/pull/456#discussion_r156129200,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"These acceptance tests were written to match the acceptance test documents.  When the documents change, the tests will be refactored to match.  The acceptance tests documents are used to validate the release candidate.  If a single test within an acceptance test document fails, the tester does not stop all testing.  ",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-14 22:04:15,157074808,"@@ -0,0 +1,421 @@
+""""""
+Created on Nov 8, 2017
+
+@author: nhan.nguyen
+
+Containing test script of test scenario 09: remove and add role.
+""""""
+import json
+from indy import ledger, signus
+from libraries.constant import Constant, Colors, Roles
+from libraries.result import Status
+from libraries.common import Common
+from libraries import utils
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario09(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        """"""
+        This function is the main part of test script.
+        All steps that involve to role TGB (9, 10, a half of 24) will be skipped because
+        role TGB is not supported by libindy.
+        There is a bug in this scenario (in step 22, 23 24) so we log a bug here.
+        """"""
+        try:
+            # 1. Create and open wallet, pool ledger.
+            self.steps.add_step(""Create and open wallet, pool ledger"")
+            result = await utils.perform(self.steps, Common.prepare_pool_and_wallet,
+                                         self.pool_name, self.wallet_name, Constant.pool_genesis_txn_file)
+            utils.exit_if_exception(result)
+            (self.pool_handle, self.wallet_handle) = result
+
+            # 2. Create DIDs.
+            self.steps.add_step(""Create DIDs"")
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = result[0] if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustee1_did, trustee1_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustee2_did, trustee2_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (steward1_did, steward1_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (steward2_did, steward2_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (steward3_did, steward3_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustanchor1_did, trustanchor1_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustanchor2_did, trustanchor2_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (trustanchor3_did, trustanchor3_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (user1_did, user1_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (user3_did, user3_verkey) = result if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({}))
+            (user4_did, user4_verkey) = result if len(result) == 2 else (None, None)
+
+            # ==========================================================================================================
+            # Test starts here !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+            # ==========================================================================================================
+
+            # 3. Using default Trustee to create Trustee1.
+            self.steps.add_step(""Using default Trustee to create Trustee1"")
+            await self.add_nym(default_trustee_did, trustee1_did, trustee1_verkey, None, Roles.TRUSTEE)
+
+            # 4. Verify GET NYM - Trustee1.
+            self.steps.add_step(""Verify GET NYM - Trustee1"")
+            await self.get_nym(default_trustee_did, trustee1_did)
+
+            # 5. Using Trustee1 to create Steward1.
+            self.steps.add_step(""Using Trustee1 to create Steward1"")
+            await self.add_nym(trustee1_did, steward1_did, steward1_verkey, None, Roles.STEWARD)
+
+            # 6. Verify GET NYM - Steward1.
+            self.steps.add_step(""Verify GET NYM - Steward1"")
+            await self.get_nym(trustee1_did, steward1_did)
+
+            # 7. Add identity (no role) by Trustee1.
+            self.steps.add_step(""Add identity (no role) by Trustee1"")
+            await self.add_nym(trustee1_did, user3_did, user3_verkey, None, None)
+
+            # 8. Verify GET NYM - no role.
+            self.steps.add_step(""Verify GET NYM - no role"")
+            await self.get_nym(trustee1_did, user3_did)
+
+            # Role TGB is not exist so we do not execute step 9.
+            # 9. Using Trustee1 to create a TGB role.
+            self.steps.add_step(""Using Trustee1 to create a TGB role (SKIP)"")
+            self.steps.get_last_step().set_status(Status.PASSED)
+
+            # Role TGB is not exist so we do not execute step 12.
+            # 10. Verify GET NYM - TGB1.
+            self.steps.add_step(""Verify GET NYM - TGB1 (SKIP)"")
+            self.steps.get_last_step().set_status(Status.PASSED)
+
+            # 11. Using Steward1 to create TrustAnchor1.
+            self.steps.add_step(""Using Steward1 to create TrustAnchor1"")
+            await self.add_nym(steward1_did, trustanchor1_did, trustanchor1_verkey, None, Roles.TRUST_ANCHOR)
+
+            # 12. Verify GET NYM - TrustAnchor1.
+            self.steps.add_step(""Verify GET NYM - TrustAnchor1"")
+            await self.get_nym(steward1_did, trustanchor1_did)
+
+            # 13. Verify add identity (no role) by Steward1.
+            self.steps.add_step(""Verify add identity (no role) by Steward1"")
+            await self.add_nym(steward1_did, user4_did, user4_verkey, None, None)
+
+            # 14. Verify GET NYM.
+            self.steps.add_step(""Verify GET NYM - no role"")
+            await self.get_nym(steward1_did, user4_did)
+
+            # 15. Verify that a Steward cannot create another Steward.
+            self.steps.add_step(""Verify that Steward cannot create another Steward"")
+            (temp, message) = await self.add_nym(steward1_did, steward2_did, steward2_verkey, None,
+                                                 Roles.STEWARD, error_code=304)
+            if temp:
+                print(Colors.OKGREEN + ""::PASS::Validated that a Steward cannot create a Steward!\n"" + Colors.ENDC)
+            else:
+                if message is None:
+                    message = ""Steward can create another Steward (should fail)""
+                self.steps.get_last_step().set_message(message)
+
+            # 16. Verify that a Steward cannot create a Trustee.
+            self.steps.add_step(""Verify that a Steward cannot create a Trustee"")
+            (temp, message) = await self.add_nym(steward1_did, trustee1_did, trustee1_verkey,
+                                                 None, Roles.TRUSTEE, error_code=304)
+
+            if temp:
+                print(Colors.OKGREEN + ""::PASS::Validated that a Steward cannot create a Trustee!\n"" + Colors.ENDC)
+            else:
+                if message is None:
+                    message = ""Steward can create a Trustee (should fail)""
+                self.steps.get_last_step().set_message(message)
+
+            # 17. Using TrustAnchor1 to add a NYM.
+            self.steps.add_step(""Using TrustAnchor1 to add a NYM"")
+            await self.add_nym(trustanchor1_did, user1_did, user1_verkey, None, None)
+
+            # 18. Verify GET NYM - User1.
+            self.steps.add_step(""Verify GET NYM - User1"")
+            await self.get_nym(trustanchor1_did, user1_did)
+
+            # 19. Verify that TrustAnchor cannot create another TrustAnchor.
+            self.steps.add_step(""Verify that TrustAnchor cannot create another TrustAnchor"")
+            (temp, message) = await self.add_nym(trustanchor1_did, trustanchor2_did, trustanchor2_verkey,
+                                                 None, Roles.TRUST_ANCHOR, error_code=304)
+            if temp:
+                print(Colors.OKGREEN + ""::PASS::Validated that a TrustAnchor cannot create another TrustAnchor!\n"" + Colors.ENDC)
+            else:
+                if message is None:
+                    message = ""TrustAnchor can create another TrustAnchor (should fail)""
+                self.steps.get_last_step().set_message(message)
+
+            # 20. Using default Trustee to remove new roles.
+            bug_is_430 = ""Bug: https://jira.hyperledger.org/browse/IS-430""
+            self.steps.add_step(""Using default Trustee to remove new roles"")
+            message_20 = """"
+            (temp, message) = await self.add_nym(default_trustee_did, trustee1_did, trustee1_verkey,
+                                                 None, Roles.NONE)
+            result = temp
+            if not temp:
+                message_20 += ""\nCannot remove Trustee1's role - "" + message
+            else:
+                (temp, message) = await self.get_nym(default_trustee_did, trustee1_did)
+                if not temp:
+                    message_20 += ""\nCannot check self.get_nym for Trustee1 - "" + message
+                else:
+                    if not TestScenario09.check_role_in_retrieved_nym(message, Roles.NONE):
+                        temp = False
+                        message_20 += ""\nCannot remove Trustee1's role""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157074808,https://github.com/hyperledger/indy-node/pull/456#discussion_r157074808,StevenL2015
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please make it so,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-14 22:09:48,157075902,"@@ -0,0 +1,131 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Colors, Message
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars"" % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(code):",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157075902,https://github.com/hyperledger/indy-node/pull/456#discussion_r157075902,StevenL2015
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please make it so,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-14 22:10:03,157075952,"@@ -0,0 +1,131 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Colors, Message
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars"" % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(code):
+    """"""
+    If ""code"" is an exception then raise the ""code"".
+    Unless ""code"" is an exception then return the ""code"".
+    :param code: (optional) code that you want to check.
+    :return: ""code"" if it is not an exception.
+    """"""
+    if (isinstance(code, IndyError) or (isinstance(code, Exception))):",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157075952,https://github.com/hyperledger/indy-node/pull/456#discussion_r157075952,StevenL2015
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please make it so,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-14 22:11:27,157076247,"@@ -0,0 +1,52 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test script of test scenario 04: keyrings wallets.
+""""""
+# !/usr/bin/env python3.6
+import json
+import os.path
+from indy import signus
+from indy.error import IndyError
+from libraries.constant import Constant, Colors
+from libraries.result import Status
+from libraries.common import Common
+from libraries.utils import exit_if_exception, perform
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario04(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        print(""Test Scenario 04 -> started"")
+        try:",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157076247,https://github.com/hyperledger/indy-node/pull/456#discussion_r157076247,StevenL2015
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"Now 3.5 is the target Python version for indy projects.
Why do the acceptance tests require python 3.6?
Earlier python3-indy required Python 3.6. It was so before the version 1.0.0-dev-171. But since the version 1.0.0-dev-171 python3-indy is compatible with Python 3.5. Now indy-node/acceptance depends on python3-indy 1.0.0-dev-177, so it should be compatible with Python 3.5.
Or do the new tests themselves require any Python 3.6 features?",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-18 18:27:35,157562787,"@@ -0,0 +1,61 @@
+
+
+# Basic Indy Acceptance Test
+
+This is Python Basic Acceptance test for Indy. The tests are not driven by any unit test framework but are standalone python scripts.
+
+This test currently requires python 3.6.",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157562787,https://github.com/hyperledger/indy-node/pull/456#discussion_r157562787,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Update the docstring comment correspondingly to the parameter renaming.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-18 18:39:43,157565716,"@@ -0,0 +1,149 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Color
+from . import constant
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(
+            string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars""
+              % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(result):
+    """"""
+    If ""code"" is an exception then raise the ""code"".
+    Unless ""code"" is an exception then return the ""code"".
+    :param code: (optional) code that you want to check.
+    :return: ""code"" if it is not an exception.
+    """"""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157565716,https://github.com/hyperledger/indy-node/pull/456#discussion_r157565716,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,We need not to explicitly create an event loop. We should just call `asyncio.get_event_loop` to get the event loop for the current context using the default event loop policy.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-18 19:07:52,157572616,"@@ -0,0 +1,107 @@
+""""""
+Created on Nov 22, 2017
+
+@author: khoi.ngo
+
+Containing the test base class.
+""""""
+import asyncio
+import inspect
+import os
+import time
+
+from libraries import common
+from libraries import constant
+from libraries import utils
+from libraries.constant import Color
+from libraries.logger import Logger
+from libraries.result import TestResult, Status
+from libraries.step import Steps
+from libraries.utils import generate_random_string, run_async_method,\
+                            make_final_result
+
+
+class TestScenarioBase():
+    """"""
+    Test base....
+    All test scenario should inherit from this class.
+    This class controls the work flow and hold some general test data for
+    test scenarios that inherit it.
+    """"""
+    pool_name = generate_random_string(""test_pool"")
+    wallet_name = generate_random_string(""test_wallet"")
+    pool_handle = 0
+    wallet_handle = 0
+    pool_genesis_txn_file = constant.pool_genesis_txn_file
+    logger = None
+    steps = None
+    test_result = None
+    test_name = """"
+
+    def init_data_test(self):
+        """"""
+        Init test data.
+        If the test case need some extra test date
+        then just override this method.
+        """"""
+        self.test_name = os.path.splitext(
+            os.path.basename(inspect.getfile(self.__class__)))[0]
+        self.test_result = TestResult(self.test_name)
+        self.steps = Steps()
+        self.logger = Logger(self.test_name)
+
+    async def execute_precondition_steps(self):
+        """"""
+         Execute pre-condition of test scenario.
+         If the test case need some extra step in pre-condition
+         then just override this method.
+        """"""
+        common.clean_up_pool_and_wallet_folder(
+            self.pool_name, self.wallet_name)
+
+    async def execute_postcondition_steps(self):
+        """"""
+        Execute post-condition of test scenario.
+        If the test case need some extra step in post-condition
+        then just override this method.
+        """"""
+        await common.clean_up_pool_and_wallet(self.pool_name, self.pool_handle,
+                                              self.wallet_name,
+                                              self.wallet_handle)
+
+    async def execute_test_steps(self):
+        """"""
+        The method where contain all main script of a test scenario.
+        All test scenario inherit TestScenarioBase have to override this method
+        """"""
+        pass
+
+    def execute_scenario(self):
+        """"""
+        Execute the test scenario and control the work flow of
+        this test scenario.
+        """"""
+        begin_time = time.time()
+        self.init_data_test()
+        utils.print_with_color(""\nTest case: {} ----> started\n""
+                               .format(self.test_name), Color.BOLD)
+        loop = asyncio.new_event_loop()
+        asyncio.set_event_loop(loop)",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157572616,https://github.com/hyperledger/indy-node/pull/456#discussion_r157572616,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,@spivachuk We followed the first python3.6 instruction but the tests are able to run with python3.5. Will update the python requirement.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-19 04:33:34,157662506,"@@ -0,0 +1,61 @@
+
+
+# Basic Indy Acceptance Test
+
+This is Python Basic Acceptance test for Indy. The tests are not driven by any unit test framework but are standalone python scripts.
+
+This test currently requires python 3.6.",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157662506,https://github.com/hyperledger/indy-node/pull/456#discussion_r157662506,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Will fix in next commit.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-19 04:38:08,157662885,"@@ -0,0 +1,149 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Color
+from . import constant
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(
+            string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars""
+              % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(result):
+    """"""
+    If ""code"" is an exception then raise the ""code"".
+    Unless ""code"" is an exception then return the ""code"".
+    :param code: (optional) code that you want to check.
+    :return: ""code"" if it is not an exception.
+    """"""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157662885,https://github.com/hyperledger/indy-node/pull/456#discussion_r157662885,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"As running one test at a time, we will remove all new, set and close event loop.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-19 04:40:19,157663045,"@@ -0,0 +1,107 @@
+""""""
+Created on Nov 22, 2017
+
+@author: khoi.ngo
+
+Containing the test base class.
+""""""
+import asyncio
+import inspect
+import os
+import time
+
+from libraries import common
+from libraries import constant
+from libraries import utils
+from libraries.constant import Color
+from libraries.logger import Logger
+from libraries.result import TestResult, Status
+from libraries.step import Steps
+from libraries.utils import generate_random_string, run_async_method,\
+                            make_final_result
+
+
+class TestScenarioBase():
+    """"""
+    Test base....
+    All test scenario should inherit from this class.
+    This class controls the work flow and hold some general test data for
+    test scenarios that inherit it.
+    """"""
+    pool_name = generate_random_string(""test_pool"")
+    wallet_name = generate_random_string(""test_wallet"")
+    pool_handle = 0
+    wallet_handle = 0
+    pool_genesis_txn_file = constant.pool_genesis_txn_file
+    logger = None
+    steps = None
+    test_result = None
+    test_name = """"
+
+    def init_data_test(self):
+        """"""
+        Init test data.
+        If the test case need some extra test date
+        then just override this method.
+        """"""
+        self.test_name = os.path.splitext(
+            os.path.basename(inspect.getfile(self.__class__)))[0]
+        self.test_result = TestResult(self.test_name)
+        self.steps = Steps()
+        self.logger = Logger(self.test_name)
+
+    async def execute_precondition_steps(self):
+        """"""
+         Execute pre-condition of test scenario.
+         If the test case need some extra step in pre-condition
+         then just override this method.
+        """"""
+        common.clean_up_pool_and_wallet_folder(
+            self.pool_name, self.wallet_name)
+
+    async def execute_postcondition_steps(self):
+        """"""
+        Execute post-condition of test scenario.
+        If the test case need some extra step in post-condition
+        then just override this method.
+        """"""
+        await common.clean_up_pool_and_wallet(self.pool_name, self.pool_handle,
+                                              self.wallet_name,
+                                              self.wallet_handle)
+
+    async def execute_test_steps(self):
+        """"""
+        The method where contain all main script of a test scenario.
+        All test scenario inherit TestScenarioBase have to override this method
+        """"""
+        pass
+
+    def execute_scenario(self):
+        """"""
+        Execute the test scenario and control the work flow of
+        this test scenario.
+        """"""
+        begin_time = time.time()
+        self.init_data_test()
+        utils.print_with_color(""\nTest case: {} ----> started\n""
+                               .format(self.test_name), Color.BOLD)
+        loop = asyncio.new_event_loop()
+        asyncio.set_event_loop(loop)",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157663045,https://github.com/hyperledger/indy-node/pull/456#discussion_r157663045,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,This issue has not been fixed.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-19 09:45:50,157705926,"@@ -0,0 +1,421 @@
+""""""
+Created on Nov 8, 2017
+
+@author: nhan.nguyen
+
+Containing test script of test scenario 09: remove and add role.
+""""""
+import json
+from indy import ledger, signus
+from libraries.constant import Constant, Colors, Roles
+from libraries.result import Status
+from libraries.common import Common
+from libraries import utils
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario09(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        """"""
+        This function is the main part of test script.
+        All steps that involve to role TGB (9, 10, a half of 24) will be skipped because
+        role TGB is not supported by libindy.
+        There is a bug in this scenario (in step 22, 23 24) so we log a bug here.
+        """"""
+        try:
+            # 1. Create and open wallet, pool ledger.
+            self.steps.add_step(""Create and open wallet, pool ledger"")
+            result = await utils.perform(self.steps, Common.prepare_pool_and_wallet,
+                                         self.pool_name, self.wallet_name, Constant.pool_genesis_txn_file)
+            utils.exit_if_exception(result)
+            (self.pool_handle, self.wallet_handle) = result
+
+            # 2. Create DIDs.
+            self.steps.add_step(""Create DIDs"")
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = result[0] if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157705926,https://github.com/hyperledger/indy-node/pull/456#discussion_r157705926,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,This issue has not been fixed.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-19 09:46:37,157706119,"@@ -0,0 +1,168 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test scripts of test scenario 11: special case for TrustAnchor role.
+""""""
+
+# !/usr/bin/env python3.6
+import json
+from indy import ledger, signus
+from indy.error import IndyError
+from libraries.constant import Constant, Colors, Roles
+from libraries.common import Common
+from libraries.utils import perform, generate_random_string, exit_if_exception, perform_with_expected_code
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class TestScenario11(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        print(""Test Scenario 11 -> started"")
+        # Declare all values use in the test
+        seed_trustee1 = generate_random_string(prefix=""Trustee1"", size=32)
+        seed_trustee2 = generate_random_string(prefix=""Trustee2"", size=32)
+        seed_steward1 = generate_random_string(prefix=""Steward1"", size=32)
+        seed_steward2 = generate_random_string(prefix=""Steward2"", size=32)
+        seed_trustanchor1 = generate_random_string(prefix=""TrustAnchor1"", size=32)
+        seed_trustanchor2 = generate_random_string(prefix=""TrustAnchor2"", size=32)
+        seed_trustanchor3 = generate_random_string(prefix=""TrustAnchor3"", size=32)
+        try:
+            # 1. Create ledger config from genesis txn file  ---------------------------------------------------------
+            self.steps.add_step(""Create and open pool Ledger"")
+            returned_code = await perform(self.steps, Common.prepare_pool_and_wallet, self.pool_name,
+                                          self.wallet_name, self.pool_genesis_txn_file)
+
+            self.pool_handle, self.wallet_handle = exit_if_exception(returned_code)
+
+            # 2. Create DIDs ----------------------------------------------------
+            self.steps.add_step(""Create DIDs"")
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,
+                                          self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = returned_code[0] if len(returned_code) == 2 else (None, None)
+
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157706119,https://github.com/hyperledger/indy-node/pull/456#discussion_r157706119,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,This issue has not been fixed.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-19 09:52:08,157707433,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157707433,https://github.com/hyperledger/indy-node/pull/456#discussion_r157707433,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,By default we should use the pool transactions genesis file bundled with the acceptance tests. It is `pool.txn`. Please see the comment above for details.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-19 09:55:44,157708364,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""
+    pool_genesis_txn_file = genesis_transaction_file_path + ""pool_transactions_sandbox_genesis""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157708364,https://github.com/hyperledger/indy-node/pull/456#discussion_r157708364,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"Now ""finished"" message may be misinterpreted because it is printed for any test result: success or fail.
It would be better not to print ""finished"" but just to print ""passed"" in case of success and ""failed"" with the error message in case of fail.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-19 10:33:19,157717316,"@@ -0,0 +1,102 @@
+""""""
+Created on Nov 22, 2017
+
+@author: khoi.ngo
+
+Containing the test base class.
+""""""
+import inspect
+import os
+import time
+
+from indy_acceptance.utilities import common
+from indy_acceptance.utilities import constant
+from indy_acceptance.utilities import utils
+from indy_acceptance.utilities.constant import Color
+from indy_acceptance.utilities.logger import Logger
+from indy_acceptance.utilities.result import TestResult, Status
+from indy_acceptance.utilities.step import Steps
+from indy_acceptance.utilities.utils import generate_random_string,\
+                                    run_async_method, make_final_result
+
+
+class TestScenarioBase():
+    """"""
+    Test base....
+    All test scenario should inherit from this class.
+    This class controls the work flow and hold some general test data for
+    test scenarios that inherit it.
+    """"""
+    pool_name = generate_random_string(""test_pool"")
+    wallet_name = generate_random_string(""test_wallet"")
+    pool_handle = 0
+    wallet_handle = 0
+    pool_genesis_txn_file = constant.pool_genesis_txn_file
+    logger = None
+    steps = None
+    test_result = None
+    test_name = """"
+
+    def init_data_test(self):
+        """"""
+        Init test data.
+        If the test case need some extra test date
+        then just override this method.
+        """"""
+        self.test_name = os.path.splitext(
+            os.path.basename(inspect.getfile(self.__class__)))[0]
+        self.test_result = TestResult(self.test_name)
+        self.steps = Steps()
+        self.logger = Logger(self.test_name)
+
+    async def execute_precondition_steps(self):
+        """"""
+         Execute pre-condition of test scenario.
+         If the test case need some extra step in pre-condition
+         then just override this method.
+        """"""
+        common.clean_up_pool_and_wallet_folder(
+            self.pool_name, self.wallet_name)
+
+    async def execute_postcondition_steps(self):
+        """"""
+        Execute post-condition of test scenario.
+        If the test case need some extra step in post-condition
+        then just override this method.
+        """"""
+        await common.clean_up_pool_and_wallet(self.pool_name, self.pool_handle,
+                                              self.wallet_name,
+                                              self.wallet_handle)
+
+    async def execute_test_steps(self):
+        """"""
+        The method where contain all main script of a test scenario.
+        All test scenario inherit TestScenarioBase have to override this method
+        """"""
+        pass
+
+    def execute_scenario(self):
+        """"""
+        Execute the test scenario and control the work flow of
+        this test scenario.
+        """"""
+        begin_time = time.time()
+        self.init_data_test()
+        utils.print_with_color(""\nTest case: {} ----> started\n""
+                               .format(self.test_name), Color.BOLD)
+        try:
+            run_async_method(self.execute_precondition_steps)
+            run_async_method(self.execute_test_steps)
+        except Exception as e:
+            message = constant.EXCEPTION.format(str(e))
+            utils.print_error(""\n{}\n"".format(str(message)))
+            self.steps.get_last_step().set_status(Status.FAILED, message)
+        finally:
+            try:
+                run_async_method(self.execute_postcondition_steps)
+            except Exception as e:
+                utils.print_error(""\n{}\n"".format(str(type(e))))
+            make_final_result(self.test_result, self.steps.get_list_step(),
+                              begin_time, self.logger)
+            utils.print_with_color(""Test case: {} ----> finished\n"".
+                                   format(self.test_name), Color.BOLD)",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157717316,https://github.com/hyperledger/indy-node/pull/456#discussion_r157717316,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"Will update.
FYI, we printed the error message in red on the console for the failure and there will be a failed record in the log file.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-20 03:28:04,157930473,"@@ -0,0 +1,102 @@
+""""""
+Created on Nov 22, 2017
+
+@author: khoi.ngo
+
+Containing the test base class.
+""""""
+import inspect
+import os
+import time
+
+from indy_acceptance.utilities import common
+from indy_acceptance.utilities import constant
+from indy_acceptance.utilities import utils
+from indy_acceptance.utilities.constant import Color
+from indy_acceptance.utilities.logger import Logger
+from indy_acceptance.utilities.result import TestResult, Status
+from indy_acceptance.utilities.step import Steps
+from indy_acceptance.utilities.utils import generate_random_string,\
+                                    run_async_method, make_final_result
+
+
+class TestScenarioBase():
+    """"""
+    Test base....
+    All test scenario should inherit from this class.
+    This class controls the work flow and hold some general test data for
+    test scenarios that inherit it.
+    """"""
+    pool_name = generate_random_string(""test_pool"")
+    wallet_name = generate_random_string(""test_wallet"")
+    pool_handle = 0
+    wallet_handle = 0
+    pool_genesis_txn_file = constant.pool_genesis_txn_file
+    logger = None
+    steps = None
+    test_result = None
+    test_name = """"
+
+    def init_data_test(self):
+        """"""
+        Init test data.
+        If the test case need some extra test date
+        then just override this method.
+        """"""
+        self.test_name = os.path.splitext(
+            os.path.basename(inspect.getfile(self.__class__)))[0]
+        self.test_result = TestResult(self.test_name)
+        self.steps = Steps()
+        self.logger = Logger(self.test_name)
+
+    async def execute_precondition_steps(self):
+        """"""
+         Execute pre-condition of test scenario.
+         If the test case need some extra step in pre-condition
+         then just override this method.
+        """"""
+        common.clean_up_pool_and_wallet_folder(
+            self.pool_name, self.wallet_name)
+
+    async def execute_postcondition_steps(self):
+        """"""
+        Execute post-condition of test scenario.
+        If the test case need some extra step in post-condition
+        then just override this method.
+        """"""
+        await common.clean_up_pool_and_wallet(self.pool_name, self.pool_handle,
+                                              self.wallet_name,
+                                              self.wallet_handle)
+
+    async def execute_test_steps(self):
+        """"""
+        The method where contain all main script of a test scenario.
+        All test scenario inherit TestScenarioBase have to override this method
+        """"""
+        pass
+
+    def execute_scenario(self):
+        """"""
+        Execute the test scenario and control the work flow of
+        this test scenario.
+        """"""
+        begin_time = time.time()
+        self.init_data_test()
+        utils.print_with_color(""\nTest case: {} ----> started\n""
+                               .format(self.test_name), Color.BOLD)
+        try:
+            run_async_method(self.execute_precondition_steps)
+            run_async_method(self.execute_test_steps)
+        except Exception as e:
+            message = constant.EXCEPTION.format(str(e))
+            utils.print_error(""\n{}\n"".format(str(message)))
+            self.steps.get_last_step().set_status(Status.FAILED, message)
+        finally:
+            try:
+                run_async_method(self.execute_postcondition_steps)
+            except Exception as e:
+                utils.print_error(""\n{}\n"".format(str(type(e))))
+            make_final_result(self.test_result, self.steps.get_list_step(),
+                              begin_time, self.logger)
+            utils.print_with_color(""Test case: {} ----> finished\n"".
+                                   format(self.test_name), Color.BOLD)",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157930473,https://github.com/hyperledger/indy-node/pull/456#discussion_r157930473,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"Please refer to 
https://github.com/trongnhan1312400/indy-node/blob/84876afddf1eb493652ca089e8449e9325c0a3eb/acceptance/indy_acceptance/test_scripts/acceptance_tests/remove_and_add_role.py 
for the fixed code.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-20 04:00:08,157933045,"@@ -0,0 +1,421 @@
+""""""
+Created on Nov 8, 2017
+
+@author: nhan.nguyen
+
+Containing test script of test scenario 09: remove and add role.
+""""""
+import json
+from indy import ledger, signus
+from libraries.constant import Constant, Colors, Roles
+from libraries.result import Status
+from libraries.common import Common
+from libraries import utils
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario09(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        """"""
+        This function is the main part of test script.
+        All steps that involve to role TGB (9, 10, a half of 24) will be skipped because
+        role TGB is not supported by libindy.
+        There is a bug in this scenario (in step 22, 23 24) so we log a bug here.
+        """"""
+        try:
+            # 1. Create and open wallet, pool ledger.
+            self.steps.add_step(""Create and open wallet, pool ledger"")
+            result = await utils.perform(self.steps, Common.prepare_pool_and_wallet,
+                                         self.pool_name, self.wallet_name, Constant.pool_genesis_txn_file)
+            utils.exit_if_exception(result)
+            (self.pool_handle, self.wallet_handle) = result
+
+            # 2. Create DIDs.
+            self.steps.add_step(""Create DIDs"")
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = result[0] if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157933045,https://github.com/hyperledger/indy-node/pull/456#discussion_r157933045,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"FYI. It was uploaded to ""Commits on Dec 19, 2017 """,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-20 04:08:28,157933732,"@@ -0,0 +1,421 @@
+""""""
+Created on Nov 8, 2017
+
+@author: nhan.nguyen
+
+Containing test script of test scenario 09: remove and add role.
+""""""
+import json
+from indy import ledger, signus
+from libraries.constant import Constant, Colors, Roles
+from libraries.result import Status
+from libraries.common import Common
+from libraries import utils
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario09(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        """"""
+        This function is the main part of test script.
+        All steps that involve to role TGB (9, 10, a half of 24) will be skipped because
+        role TGB is not supported by libindy.
+        There is a bug in this scenario (in step 22, 23 24) so we log a bug here.
+        """"""
+        try:
+            # 1. Create and open wallet, pool ledger.
+            self.steps.add_step(""Create and open wallet, pool ledger"")
+            result = await utils.perform(self.steps, Common.prepare_pool_and_wallet,
+                                         self.pool_name, self.wallet_name, Constant.pool_genesis_txn_file)
+            utils.exit_if_exception(result)
+            (self.pool_handle, self.wallet_handle) = result
+
+            # 2. Create DIDs.
+            self.steps.add_step(""Create DIDs"")
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = result[0] if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157933732,https://github.com/hyperledger/indy-node/pull/456#discussion_r157933732,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"Please refer to https://github.com/hyperledger/indy-node/pull/456/commits/84876afddf1eb493652ca089e8449e9325c0a3eb#diff-c811b8ce6def5210a2c02403e1237026
then expand the line 47 for your review.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-20 04:16:33,157934311,"@@ -0,0 +1,168 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test scripts of test scenario 11: special case for TrustAnchor role.
+""""""
+
+# !/usr/bin/env python3.6
+import json
+from indy import ledger, signus
+from indy.error import IndyError
+from libraries.constant import Constant, Colors, Roles
+from libraries.common import Common
+from libraries.utils import perform, generate_random_string, exit_if_exception, perform_with_expected_code
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class TestScenario11(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        print(""Test Scenario 11 -> started"")
+        # Declare all values use in the test
+        seed_trustee1 = generate_random_string(prefix=""Trustee1"", size=32)
+        seed_trustee2 = generate_random_string(prefix=""Trustee2"", size=32)
+        seed_steward1 = generate_random_string(prefix=""Steward1"", size=32)
+        seed_steward2 = generate_random_string(prefix=""Steward2"", size=32)
+        seed_trustanchor1 = generate_random_string(prefix=""TrustAnchor1"", size=32)
+        seed_trustanchor2 = generate_random_string(prefix=""TrustAnchor2"", size=32)
+        seed_trustanchor3 = generate_random_string(prefix=""TrustAnchor3"", size=32)
+        try:
+            # 1. Create ledger config from genesis txn file  ---------------------------------------------------------
+            self.steps.add_step(""Create and open pool Ledger"")
+            returned_code = await perform(self.steps, Common.prepare_pool_and_wallet, self.pool_name,
+                                          self.wallet_name, self.pool_genesis_txn_file)
+
+            self.pool_handle, self.wallet_handle = exit_if_exception(returned_code)
+
+            # 2. Create DIDs ----------------------------------------------------
+            self.steps.add_step(""Create DIDs"")
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,
+                                          self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = returned_code[0] if len(returned_code) == 2 else (None, None)
+
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/157934311,https://github.com/hyperledger/indy-node/pull/456#discussion_r157934311,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please remove empty parentheses.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-25 17:37:43,158651614,"@@ -0,0 +1,102 @@
+""""""
+Created on Nov 22, 2017
+
+@author: khoi.ngo
+
+Containing the test base class.
+""""""
+import inspect
+import os
+import time
+
+from indy_acceptance.utilities import common
+from indy_acceptance.utilities import constant
+from indy_acceptance.utilities import utils
+from indy_acceptance.utilities.constant import Color
+from indy_acceptance.utilities.logger import Logger
+from indy_acceptance.utilities.result import TestResult, Status
+from indy_acceptance.utilities.step import Steps
+from indy_acceptance.utilities.utils import generate_random_string,\
+                                    run_async_method, make_final_result
+
+
+class TestScenarioBase():",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158651614,https://github.com/hyperledger/indy-node/pull/456#discussion_r158651614,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"In step 2 ""Create DIDs"" multiple actions are done by calls of `utils.perform`. Each call of `utils.perform` here is done with `ignore_exception=True` which is used by default. So, for example, if creation of trustee1 fails then the current step status will be set to FAILED. But next if creation of trustee2 succeeds then the current step status is overwritten from FAILED to PASSED. Such the behavior is incorrect. Obviously, if some action in the step has failed then the whole step status must be FAILED.

To correct this behavior I propose to add every new step with PASSED status initially and don't update the step's status in `utils.perform` in case `func` has succeeded. With this logic we will get the step passed only if all the actions in it have succeed and we will get the whole step failed if any action in it has failed.

By the way, it is ok to add a new step with the initial PASSED status because if some error occurred not inside `utils.perform` call aborts a test case then the step's status will be set to FAILED in `except` section of `try` block in `TestScenarioBase.execute_scenario`.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-25 18:24:26,158652491,"@@ -0,0 +1,421 @@
+""""""
+Created on Nov 8, 2017
+
+@author: nhan.nguyen
+
+Containing test script of test scenario 09: remove and add role.
+""""""
+import json
+from indy import ledger, signus
+from libraries.constant import Constant, Colors, Roles
+from libraries.result import Status
+from libraries.common import Common
+from libraries import utils
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario09(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        """"""
+        This function is the main part of test script.
+        All steps that involve to role TGB (9, 10, a half of 24) will be skipped because
+        role TGB is not supported by libindy.
+        There is a bug in this scenario (in step 22, 23 24) so we log a bug here.
+        """"""
+        try:
+            # 1. Create and open wallet, pool ledger.
+            self.steps.add_step(""Create and open wallet, pool ledger"")
+            result = await utils.perform(self.steps, Common.prepare_pool_and_wallet,
+                                         self.pool_name, self.wallet_name, Constant.pool_genesis_txn_file)
+            utils.exit_if_exception(result)
+            (self.pool_handle, self.wallet_handle) = result
+
+            # 2. Create DIDs.
+            self.steps.add_step(""Create DIDs"")
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = result[0] if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158652491,https://github.com/hyperledger/indy-node/pull/456#discussion_r158652491,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please see my recent comment to the similar finding above.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-25 18:25:14,158652504,"@@ -0,0 +1,168 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test scripts of test scenario 11: special case for TrustAnchor role.
+""""""
+
+# !/usr/bin/env python3.6
+import json
+from indy import ledger, signus
+from indy.error import IndyError
+from libraries.constant import Constant, Colors, Roles
+from libraries.common import Common
+from libraries.utils import perform, generate_random_string, exit_if_exception, perform_with_expected_code
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class TestScenario11(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        print(""Test Scenario 11 -> started"")
+        # Declare all values use in the test
+        seed_trustee1 = generate_random_string(prefix=""Trustee1"", size=32)
+        seed_trustee2 = generate_random_string(prefix=""Trustee2"", size=32)
+        seed_steward1 = generate_random_string(prefix=""Steward1"", size=32)
+        seed_steward2 = generate_random_string(prefix=""Steward2"", size=32)
+        seed_trustanchor1 = generate_random_string(prefix=""TrustAnchor1"", size=32)
+        seed_trustanchor2 = generate_random_string(prefix=""TrustAnchor2"", size=32)
+        seed_trustanchor3 = generate_random_string(prefix=""TrustAnchor3"", size=32)
+        try:
+            # 1. Create ledger config from genesis txn file  ---------------------------------------------------------
+            self.steps.add_step(""Create and open pool Ledger"")
+            returned_code = await perform(self.steps, Common.prepare_pool_and_wallet, self.pool_name,
+                                          self.wallet_name, self.pool_genesis_txn_file)
+
+            self.pool_handle, self.wallet_handle = exit_if_exception(returned_code)
+
+            # 2. Create DIDs ----------------------------------------------------
+            self.steps.add_step(""Create DIDs"")
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,
+                                          self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = returned_code[0] if len(returned_code) == 2 else (None, None)
+
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158652504,https://github.com/hyperledger/indy-node/pull/456#discussion_r158652504,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please remove this line.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-25 18:32:13,158652603,"@@ -0,0 +1,52 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test script of test scenario 04: keyrings wallets.
+""""""
+# !/usr/bin/env python3.6",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158652603,https://github.com/hyperledger/indy-node/pull/456#discussion_r158652603,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please remove this line.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-25 18:32:20,158652606,"@@ -0,0 +1,210 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test scripts of test scenario 11: special case for TrustAnchor role.
+""""""
+
+# !/usr/bin/env python3.6",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158652606,https://github.com/hyperledger/indy-node/pull/456#discussion_r158652606,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"It will be better just to re-raise the exception 'result' rather than to abort with `exit` call. Correspondingly, the function `exit_if_exception` should be renamed to `raise_if_exception`.

By the way, `exit` internally raises `SystemExit` which is inherited from `BaseException`. Thus with `exit` we will not enter to `except Exception` section of `try` block in `TestScenarioBase.execute_scenario`. Anyway, `exit` is some kind of emergency ways to quit. It doesn't fit an ordinary test fail.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-25 19:01:06,158652999,"@@ -0,0 +1,161 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Color
+from . import constant
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(
+            string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars""
+              % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(result):
+    """"""
+    If ""result"" is an exception then raise the ""result"".
+    Unless ""result"" is an exception then return the ""result"".
+    :param result: the value that you want to check.
+    :return: ""result"" if it is not an exception.
+    """"""
+    if (isinstance(result, Exception)):
+        exit(1)",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158652999,https://github.com/hyperledger/indy-node/pull/456#discussion_r158652999,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please fix this.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-25 19:06:40,158653098,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158653098,https://github.com/hyperledger/indy-node/pull/456#discussion_r158653098,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please fix this.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-25 19:06:46,158653101,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""
+    pool_genesis_txn_file = genesis_transaction_file_path + ""pool_transactions_sandbox_genesis""",,2017-12-26 07:46:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158653101,https://github.com/hyperledger/indy-node/pull/456#discussion_r158653101,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Pointed to pool.txn.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 07:48:15,158677546,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""
+    pool_genesis_txn_file = genesis_transaction_file_path + ""pool_transactions_sandbox_genesis""",,2017-12-26 07:48:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158677546,https://github.com/hyperledger/indy-node/pull/456#discussion_r158677546,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"Updated. Pointed to pool.txn, indy-node/acceptance directory .",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 07:49:08,158677625,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""",,2017-12-26 07:49:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158677625,https://github.com/hyperledger/indy-node/pull/456#discussion_r158677625,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"Fyi, the execution was terminated only after setting the test's status as failed.

Updated as ""raise_if_exception"". The new raised exception will be handled at TestScenarioBase,.execute_scenario.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 07:56:21,158678199,"@@ -0,0 +1,161 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Color
+from . import constant
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(
+            string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars""
+              % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(result):
+    """"""
+    If ""result"" is an exception then raise the ""result"".
+    Unless ""result"" is an exception then return the ""result"".
+    :param result: the value that you want to check.
+    :return: ""result"" if it is not an exception.
+    """"""
+    if (isinstance(result, Exception)):
+        exit(1)",,2017-12-26 07:56:21,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158678199,https://github.com/hyperledger/indy-node/pull/456#discussion_r158678199,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Removed.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 07:56:55,158678245,"@@ -0,0 +1,210 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test scripts of test scenario 11: special case for TrustAnchor role.
+""""""
+
+# !/usr/bin/env python3.6",,2017-12-26 07:56:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158678245,https://github.com/hyperledger/indy-node/pull/456#discussion_r158678245,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Removed.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 07:57:20,158678267,"@@ -0,0 +1,52 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test script of test scenario 04: keyrings wallets.
+""""""
+# !/usr/bin/env python3.6",,2017-12-26 07:57:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158678267,https://github.com/hyperledger/indy-node/pull/456#discussion_r158678267,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Removed.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 07:57:59,158678305,"@@ -0,0 +1,102 @@
+""""""
+Created on Nov 22, 2017
+
+@author: khoi.ngo
+
+Containing the test base class.
+""""""
+import inspect
+import os
+import time
+
+from indy_acceptance.utilities import common
+from indy_acceptance.utilities import constant
+from indy_acceptance.utilities import utils
+from indy_acceptance.utilities.constant import Color
+from indy_acceptance.utilities.logger import Logger
+from indy_acceptance.utilities.result import TestResult, Status
+from indy_acceptance.utilities.step import Steps
+from indy_acceptance.utilities.utils import generate_random_string,\
+                                    run_async_method, make_final_result
+
+
+class TestScenarioBase():",,2017-12-26 07:57:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158678305,https://github.com/hyperledger/indy-node/pull/456#discussion_r158678305,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"As some best practices, the default status of step should be FAILED. With ignore_exception=True, utils.perform will update the status after done as 2 options below:
-If the action is PASSED, the status of step will be updated as PASSED.
-If the action is FAILED, the status of step will be updated to FAILED. Then we freeze this status from other updates. That means we won't change this step's status anymore.

Please refer to the latest code for detail.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:16:42,158679634,"@@ -0,0 +1,421 @@
+""""""
+Created on Nov 8, 2017
+
+@author: nhan.nguyen
+
+Containing test script of test scenario 09: remove and add role.
+""""""
+import json
+from indy import ledger, signus
+from libraries.constant import Constant, Colors, Roles
+from libraries.result import Status
+from libraries.common import Common
+from libraries import utils
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario09(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        """"""
+        This function is the main part of test script.
+        All steps that involve to role TGB (9, 10, a half of 24) will be skipped because
+        role TGB is not supported by libindy.
+        There is a bug in this scenario (in step 22, 23 24) so we log a bug here.
+        """"""
+        try:
+            # 1. Create and open wallet, pool ledger.
+            self.steps.add_step(""Create and open wallet, pool ledger"")
+            result = await utils.perform(self.steps, Common.prepare_pool_and_wallet,
+                                         self.pool_name, self.wallet_name, Constant.pool_genesis_txn_file)
+            utils.exit_if_exception(result)
+            (self.pool_handle, self.wallet_handle) = result
+
+            # 2. Create DIDs.
+            self.steps.add_step(""Create DIDs"")
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = result[0] if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 08:16:42,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158679634,https://github.com/hyperledger/indy-node/pull/456#discussion_r158679634,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Please refer to latest code for detail update.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:17:53,158679729,"@@ -0,0 +1,168 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test scripts of test scenario 11: special case for TrustAnchor role.
+""""""
+
+# !/usr/bin/env python3.6
+import json
+from indy import ledger, signus
+from indy.error import IndyError
+from libraries.constant import Constant, Colors, Roles
+from libraries.common import Common
+from libraries.utils import perform, generate_random_string, exit_if_exception, perform_with_expected_code
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class TestScenario11(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        print(""Test Scenario 11 -> started"")
+        # Declare all values use in the test
+        seed_trustee1 = generate_random_string(prefix=""Trustee1"", size=32)
+        seed_trustee2 = generate_random_string(prefix=""Trustee2"", size=32)
+        seed_steward1 = generate_random_string(prefix=""Steward1"", size=32)
+        seed_steward2 = generate_random_string(prefix=""Steward2"", size=32)
+        seed_trustanchor1 = generate_random_string(prefix=""TrustAnchor1"", size=32)
+        seed_trustanchor2 = generate_random_string(prefix=""TrustAnchor2"", size=32)
+        seed_trustanchor3 = generate_random_string(prefix=""TrustAnchor3"", size=32)
+        try:
+            # 1. Create ledger config from genesis txn file  ---------------------------------------------------------
+            self.steps.add_step(""Create and open pool Ledger"")
+            returned_code = await perform(self.steps, Common.prepare_pool_and_wallet, self.pool_name,
+                                          self.wallet_name, self.pool_genesis_txn_file)
+
+            self.pool_handle, self.wallet_handle = exit_if_exception(returned_code)
+
+            # 2. Create DIDs ----------------------------------------------------
+            self.steps.add_step(""Create DIDs"")
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,
+                                          self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = returned_code[0] if len(returned_code) == 2 else (None, None)
+
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,",,2017-12-26 08:17:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158679729,https://github.com/hyperledger/indy-node/pull/456#discussion_r158679729,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:32:24,158680792,"@@ -0,0 +1,2 @@
+Note: You need to set the PYTHONPATH before you run a test. It should point to the indy_acceptance folder.
+e.g.: export PYTHONPATH=$PYTHONPATH:/home/user_name/indy_acceptance",,2017-12-26 08:32:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680792,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680792,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:32:37,158680800,"@@ -0,0 +1,159 @@
+""""""
+Created on Nov 13, 2017
+
+@author: khoi.ngo
+
+Containing all functions that is common among test scenarios.
+""""""
+
+import asyncio
+import json
+from indy import wallet, pool, ledger
+from .constant import Colors, Constant, Message
+
+
+class Common:",,2017-12-26 08:32:37,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680800,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680800,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:32:52,158680819,"@@ -0,0 +1,159 @@
+""""""
+Created on Nov 13, 2017
+
+@author: khoi.ngo
+
+Containing all functions that is common among test scenarios.
+""""""
+
+import asyncio
+import json
+from indy import wallet, pool, ledger
+from .constant import Colors, Constant, Message
+
+
+class Common:
+    """"""
+    Wrapper common function for test scenario.
+    """"""
+
+    @staticmethod
+    async def prepare_pool_and_wallet(pool_name, wallet_name, pool_genesis_txn_file):
+        """"""
+        Prepare pool and wallet to use in a test case.
+
+        :param pool_name: Name of the pool ledger configuration.
+        :param wallet_name: Name of the wallet.
+        :param pool_genesis_txn_file: The path of the pool_genesis_transaction file.
+        :return: The pool handle and the wallet handle were created.
+        """"""
+        pool_handle = await Common().create_and_open_pool(pool_name, pool_genesis_txn_file)",,2017-12-26 08:32:52,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680819,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680819,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:33:20,158680857,"@@ -0,0 +1,159 @@
+""""""
+Created on Nov 13, 2017
+
+@author: khoi.ngo
+
+Containing all functions that is common among test scenarios.
+""""""
+
+import asyncio
+import json
+from indy import wallet, pool, ledger
+from .constant import Colors, Constant, Message
+
+
+class Common:
+    """"""
+    Wrapper common function for test scenario.
+    """"""
+
+    @staticmethod
+    async def prepare_pool_and_wallet(pool_name, wallet_name, pool_genesis_txn_file):
+        """"""
+        Prepare pool and wallet to use in a test case.
+
+        :param pool_name: Name of the pool ledger configuration.
+        :param wallet_name: Name of the wallet.
+        :param pool_genesis_txn_file: The path of the pool_genesis_transaction file.
+        :return: The pool handle and the wallet handle were created.
+        """"""
+        pool_handle = await Common().create_and_open_pool(pool_name, pool_genesis_txn_file)
+        wallet_handle = await Common().create_and_open_wallet(pool_name, wallet_name)
+        return pool_handle, wallet_handle
+
+    @staticmethod
+    async def clean_up_pool_and_wallet(pool_name, pool_handle, wallet_name, wallet_handle):
+        """"""
+        Clean up pool and wallet. Using as a post condition of a test case.
+
+        :param pool_name: The name of the pool.
+        :param pool_handle: The handle of the pool.
+        :param wallet_name: The name of the wallet.
+        :param wallet_handle: The handle of the wallet.
+        """"""
+        await Common().close_pool_and_wallet(pool_handle, wallet_handle)
+        await Common().delete_pool_and_wallet(pool_name, wallet_name)
+
+    @staticmethod
+    def clean_up_pool_and_wallet_folder(pool_name, wallet_name):
+        """"""
+        Delete pool and wallet folder without using lib-indy.
+
+        :param pool_name: The name of the pool.
+        :param wallet_name: The name of the wallet.
+        """"""
+        import os
+        import shutil
+        work_dir = Constant.work_dir
+
+        if os.path.exists(work_dir + ""/pool/"" + pool_name):
+            try:
+                shutil.rmtree(work_dir + ""/pool/"" + pool_name)
+            except IOError as E:
+                print(Colors.FAIL + str(E) + Colors.ENDC)
+
+        if os.path.exists(work_dir + ""/wallet/"" + wallet_name):
+            try:
+                shutil.rmtree(work_dir + ""/wallet/"" + wallet_name)
+            except IOError as E:
+                print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    @staticmethod
+    async def build_and_send_nym_request(pool_handle, wallet_handle, submitter_did,
+                                         target_did, target_verkey, alias, role):
+        """"""
+        Build a nym request and send it.
+
+        :param pool_handle: pool handle returned by indy_open_pool_ledger.
+        :param wallet_handle: wallet handle returned by indy_open_wallet.
+        :param submitter_did: Id of Identity stored in secured Wallet.
+        :param target_did: Id of Identity stored in secured Wallet.
+        :param target_verkey: verification key.
+        :param alias: alias.
+        :param role: Role of a user NYM record.
+        :raise Exception if the method has error.
+        """"""
+        nym_txn_req = await ledger.build_nym_request(submitter_did, target_did, target_verkey, alias, role)
+        await ledger.sign_and_submit_request(pool_handle, wallet_handle, submitter_did, nym_txn_req)
+
+    @staticmethod
+    async def create_and_open_pool(pool_name, pool_genesis_txn_file):
+        """"""
+        Creates a new local pool ledger configuration.
+        Then open that pool and return the pool handle that can be used later to connect pool nodes.
+
+        :param pool_name: Name of the pool ledger configuration.
+        :param pool_genesis_txn_file: Pool configuration json. if NULL, then default config will be used.
+        :return: The pool handle was created.
+        """"""
+        import os
+        if os.path.exists(pool_genesis_txn_file) is not True:
+            error_message = Colors.FAIL + ""\n{}\n"".format(Message.ERR_PATH_DOES_NOT_EXIST.format(Constant.pool_genesis_txn_file)) + Colors.ENDC
+            raise ValueError(error_message)
+
+        print(Colors.HEADER + ""\nCreate Ledger\n"" + Colors.ENDC)
+        pool_config = json.dumps({""genesis_txn"": str(pool_genesis_txn_file)})
+        await pool.create_pool_ledger_config(pool_name, pool_config)
+
+        print(Colors.HEADER + ""\nOpen pool ledger\n"" + Colors.ENDC)
+        pool_handle = await pool.open_pool_ledger(pool_name, None)
+        return pool_handle
+
+    @staticmethod
+    async def create_and_open_wallet(pool_name, wallet_name):
+        """"""
+        Creates a new secure wallet with the given unique name.
+        Then open that wallet and get the wallet handle that can
+        be used later to use in methods that require wallet access.
+
+        :param pool_name: Name of the pool that corresponds to this wallet.
+        :param wallet_name: Name of the wallet.
+        :return: The wallet handle was created.
+        """"""
+        print(Colors.HEADER + ""\nCreate wallet\n"" + Colors.ENDC)
+        await wallet.create_wallet(pool_name, wallet_name, None, None, None)
+
+        print(Colors.HEADER + ""\nGet wallet handle\n"" + Colors.ENDC)
+        wallet_handle = await wallet.open_wallet(wallet_name, None, None)
+        return wallet_handle
+
+    @staticmethod
+    async def close_pool_and_wallet(pool_handle, wallet_handle):
+        """"""
+        Close the pool and wallet with the pool and wallet handle.
+
+        :param pool_handle: pool handle returned by indy_open_pool_ledger.
+        :param wallet_handle: wallet handle returned by indy_open_wallet.
+        :raise Exception if the method has error.
+        """"""
+        print(Colors.HEADER + ""\nClose pool\n"" + Colors.ENDC)
+        await pool.close_pool_ledger(pool_handle)
+
+        print(Colors.HEADER + ""\nClose wallet\n"" + Colors.ENDC)
+        await wallet.close_wallet(wallet_handle)
+
+    @staticmethod
+    async def delete_pool_and_wallet(pool_name, wallet_name):
+        """"""
+        Delete the pool and wallet with the pool and wallet name.
+
+        :param pool_name: Name of the pool that corresponds to this wallet.
+        :param wallet_name: Name of the wallet to delete.
+        :raise Exception if the method has error.
+        """"""
+        print(Colors.HEADER + ""\nDelete pool\n"" + Colors.ENDC)
+        await pool.delete_pool_ledger_config(pool_name)
+
+        print(Colors.HEADER + ""\nDelete wallet\n"" + Colors.ENDC)
+        await wallet.delete_wallet(wallet_name, None)
+        await asyncio.sleep(0)",,2017-12-26 08:33:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680857,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680857,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:33:28,158680865,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:",,2017-12-26 08:33:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680865,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680865,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:33:39,158680886,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:",,2017-12-26 08:33:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680886,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680886,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:33:51,158680906,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:",,2017-12-26 08:33:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680906,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680906,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:34:17,158680946,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""
+    pool_genesis_txn_file = genesis_transaction_file_path + ""pool_transactions_sandbox_genesis""
+    domain_transactions_sandbox_genesis = genesis_transaction_file_path + ""domain_transactions_sandbox_genesis""",,2017-12-26 08:34:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680946,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680946,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:34:29,158680955,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""
+    pool_genesis_txn_file = genesis_transaction_file_path + ""pool_transactions_sandbox_genesis""
+    domain_transactions_sandbox_genesis = genesis_transaction_file_path + ""domain_transactions_sandbox_genesis""
+    original_pool_genesis_txn_file = genesis_transaction_file_path + ""original_pool_transactions_sandbox_genesis""
+
+
+class Message:",,2017-12-26 08:34:29,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680955,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680955,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:34:40,158680972,"@@ -0,0 +1,88 @@
+""""""
+Created on Nov 22, 2017
+
+@author: nhan.nguyen
+
+Containing classes to catch the log on console and write it file.
+""""""
+
+import sys
+import os
+import time
+import errno
+import logging
+from .result import Status
+from .constant import Colors
+
+
+class Printer(object):",,2017-12-26 08:34:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680972,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680972,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:34:50,158680982,"@@ -0,0 +1,127 @@
+""""""
+Created on Nov 9, 2017
+
+@author: nhan.nguyen
+
+Containing classes to make the test result as a json.
+""""""
+
+import json
+import time
+import os
+import errno
+from .constant import Colors
+
+
+class KeyWord:",,2017-12-26 08:34:51,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680982,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680982,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:34:57,158680997,"@@ -0,0 +1,127 @@
+""""""
+Created on Nov 9, 2017
+
+@author: nhan.nguyen
+
+Containing classes to make the test result as a json.
+""""""
+
+import json
+import time
+import os
+import errno
+from .constant import Colors
+
+
+class KeyWord:
+    TEST_CASE = ""testcase""
+    RESULT = ""result""
+    START_TIME = ""starttime""
+    DURATION = ""duration""
+    RUN = ""run""
+    STEP = ""step""
+    STATUS = ""status""
+    MESSAGE = ""message""
+
+
+class Status:",,2017-12-26 08:34:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158680997,https://github.com/hyperledger/indy-node/pull/456#discussion_r158680997,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:35:10,158681011,"@@ -0,0 +1,131 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Colors, Message
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars"" % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(code):",,2017-12-26 08:35:10,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158681011,https://github.com/hyperledger/indy-node/pull/456#discussion_r158681011,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:35:20,158681023,"@@ -0,0 +1,131 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Colors, Message
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars"" % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(code):
+    """"""
+    If ""code"" is an exception then raise the ""code"".
+    Unless ""code"" is an exception then return the ""code"".
+    :param code: (optional) code that you want to check.
+    :return: ""code"" if it is not an exception.
+    """"""
+    if (isinstance(code, IndyError) or (isinstance(code, Exception))):",,2017-12-26 08:35:20,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158681023,https://github.com/hyperledger/indy-node/pull/456#discussion_r158681023,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:35:36,158681044,"@@ -0,0 +1,131 @@
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all functions used by several test steps on test scenarios.
+""""""
+from indy.error import IndyError
+from .constant import Colors, Message
+from .result import Status
+
+
+def generate_random_string(prefix="""", suffix="""", size=20):
+    """"""
+    Generate random string .
+
+    :param prefix: (optional) Prefix of a string.
+    :param suffix: (optional) Suffix of a string.
+    :param size: (optional) Max length of a string (include prefix and suffix)
+    :return: The random string.
+    """"""
+    import random
+    import string
+    left_size = size - len(prefix) - len(suffix)
+    random_str = """"
+    if left_size > 0:
+        random_str = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(left_size))
+    else:
+        print(""Warning: Length of prefix and suffix more than %s chars"" % str(size))
+    result = str(prefix) + random_str + str(suffix)
+    return result
+
+
+def exit_if_exception(code):
+    """"""
+    If ""code"" is an exception then raise the ""code"".
+    Unless ""code"" is an exception then return the ""code"".
+    :param code: (optional) code that you want to check.
+    :return: ""code"" if it is not an exception.
+    """"""
+    if (isinstance(code, IndyError) or (isinstance(code, Exception))):
+        exit(1)
+    else:
+        return code
+
+
+async def perform(steps, func, *agrs):
+    """"""
+    Execute an function and set status, message for the last test step depend on the result of the function.
+
+    :param steps: (optional) list of test steps.
+    :param func: (optional) executed function.
+    :param agrs: argument of function.
+    :return: the result of function of the exception that the function raise.
+    """"""
+    try:
+        result = await func(*agrs)
+        steps.get_last_step().set_status(Status.PASSED)
+    except IndyError as E:
+        print(Colors.FAIL + Message.INDY_ERROR.format(str(E)) + Colors.ENDC)
+        steps.get_last_step().set_message(str(E))
+        steps.get_last_step().set_status(Status.FAILED)
+        return E
+    except Exception as Ex:
+        print(Colors.FAIL + Message.EXCEPTION.format(str(Ex)) + Colors.ENDC)
+        steps.get_last_step().set_message(str(Ex))
+        steps.get_last_step().set_status(Status.FAILED)
+        return Ex
+    return result
+
+
+async def perform_with_expected_code(steps, func, *agrs, expected_code=0):
+    """"""
+    Execute the ""func"" with expectation that the ""func"" raise an IndyError that IndyError.error_code = ""expected_code"".
+
+    :param steps: (optional) list of test steps.
+    :param func: (optional) executed function.
+    :param agrs: arguments of ""func"".
+    :param expected_code: the error code that you expect in IndyError.
+    :return: exception if the ""func"" raise it without ""expected_code"".
+             'None' if the ""func"" run without any exception of the exception contain ""expected_code"".
+    """"""
+    try:
+        await func(*agrs)
+        steps.get_last_step().set_message(""Can execute without exception."")
+        steps.get_last_step().set_status(Status.FAILED)
+        return None
+    except IndyError as E:
+        if E.error_code == expected_code:
+            steps.get_last_step().set_status(Status.PASSED)
+            return None
+        else:
+            print(Colors.FAIL + Message.INDY_ERROR.format(str(E)) + Colors.ENDC)
+            steps.get_last_step().set_message(str(E))
+            return E
+    except Exception as Ex:
+        print(Colors.FAIL + Message.EXCEPTION.format(str(Ex)) + Colors.ENDC)
+        return Ex
+
+
+def run_async_method(method):
+    """"""
+    Run async method until it complete.
+
+    :param method: (optional).
+    """"""
+    import asyncio
+    loop = asyncio.new_event_loop()",,2017-12-26 08:35:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158681044,https://github.com/hyperledger/indy-node/pull/456#discussion_r158681044,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:35:48,158681068,"@@ -0,0 +1,52 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test script of test scenario 04: keyrings wallets.
+""""""
+# !/usr/bin/env python3.6
+import json
+import os.path
+from indy import signus
+from indy.error import IndyError
+from libraries.constant import Constant, Colors
+from libraries.result import Status
+from libraries.common import Common
+from libraries.utils import exit_if_exception, perform
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario04(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        print(""Test Scenario 04 -> started"")
+        try:",,2017-12-26 08:35:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158681068,https://github.com/hyperledger/indy-node/pull/456#discussion_r158681068,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:36:13,158681095,"@@ -0,0 +1,59 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test script of test scenario 02: verify messages on connection.
+""""""
+
+import json
+import os
+from indy import pool
+from libraries.constant import Constant, Colors
+from libraries.result import Status
+from libraries.utils import perform
+from test_scripts.test_scenario_base import TestScenarioBase
+
+"""""" cmds """"""
+back_up_pool_genesis_file = 'sudo cp ' + Constant.pool_genesis_txn_file + "" "" + Constant.original_pool_genesis_txn_file
+remove_pool_genesis_file = 'sudo rm ' + Constant.pool_genesis_txn_file
+restore_pool_genesis_file = 'sudo cp ' + Constant.original_pool_genesis_txn_file + "" "" + Constant.pool_genesis_txn_file
+create_empty_pool_genesis_file = 'sudo touch ' + Constant.pool_genesis_txn_file
+
+
+class TestScenario02(TestScenarioBase):",,2017-12-26 08:36:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158681095,https://github.com/hyperledger/indy-node/pull/456#discussion_r158681095,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Updated. Please refer to the latest code.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-26 08:36:22,158681115,"@@ -0,0 +1,74 @@
+""""""
+Created on Nov 22, 2017
+
+@author: khoi.ngo
+
+Containing the test base class.
+""""""
+import time
+import os
+import inspect
+from libraries.utils import generate_random_string, run_async_method, make_final_result
+from libraries.constant import Constant
+from libraries.common import Common
+from libraries.logger import Logger
+from libraries.result import TestResult
+from libraries.step import Steps
+
+
+class TestScenarioBase(object):",,2017-12-26 08:36:22,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158681115,https://github.com/hyperledger/indy-node/pull/456#discussion_r158681115,nghia47
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Just noticed the freeze logic in `Step.set_status`. It has fixed the issue.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-27 10:24:22,158793745,"@@ -0,0 +1,421 @@
+""""""
+Created on Nov 8, 2017
+
+@author: nhan.nguyen
+
+Containing test script of test scenario 09: remove and add role.
+""""""
+import json
+from indy import ledger, signus
+from libraries.constant import Constant, Colors, Roles
+from libraries.result import Status
+from libraries.common import Common
+from libraries import utils
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+class TestScenario09(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        """"""
+        This function is the main part of test script.
+        All steps that involve to role TGB (9, 10, a half of 24) will be skipped because
+        role TGB is not supported by libindy.
+        There is a bug in this scenario (in step 22, 23 24) so we log a bug here.
+        """"""
+        try:
+            # 1. Create and open wallet, pool ledger.
+            self.steps.add_step(""Create and open wallet, pool ledger"")
+            result = await utils.perform(self.steps, Common.prepare_pool_and_wallet,
+                                         self.pool_name, self.wallet_name, Constant.pool_genesis_txn_file)
+            utils.exit_if_exception(result)
+            (self.pool_handle, self.wallet_handle) = result
+
+            # 2. Create DIDs.
+            self.steps.add_step(""Create DIDs"")
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,
+                                         self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = result[0] if len(result) == 2 else (None, None)
+
+            result = await utils.perform(self.steps, signus.create_and_store_my_did,",,2017-12-27 10:24:22,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158793745,https://github.com/hyperledger/indy-node/pull/456#discussion_r158793745,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,Just noticed the freeze logic in `Step.set_status`. It has fixed the issue.,ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-27 10:24:59,158793800,"@@ -0,0 +1,168 @@
+""""""
+Created on Nov 8, 2017
+
+@author: khoi.ngo
+
+Containing test scripts of test scenario 11: special case for TrustAnchor role.
+""""""
+
+# !/usr/bin/env python3.6
+import json
+from indy import ledger, signus
+from indy.error import IndyError
+from libraries.constant import Constant, Colors, Roles
+from libraries.common import Common
+from libraries.utils import perform, generate_random_string, exit_if_exception, perform_with_expected_code
+from test_scripts.test_scenario_base import TestScenarioBase
+
+
+# -----------------------------------------------------------------------------------------
+# This will run acceptance tests that will validate the add/remove roles functionality.
+# -----------------------------------------------------------------------------------------
+
+
+class TestScenario11(TestScenarioBase):
+
+    async def execute_test_steps(self):
+        print(""Test Scenario 11 -> started"")
+        # Declare all values use in the test
+        seed_trustee1 = generate_random_string(prefix=""Trustee1"", size=32)
+        seed_trustee2 = generate_random_string(prefix=""Trustee2"", size=32)
+        seed_steward1 = generate_random_string(prefix=""Steward1"", size=32)
+        seed_steward2 = generate_random_string(prefix=""Steward2"", size=32)
+        seed_trustanchor1 = generate_random_string(prefix=""TrustAnchor1"", size=32)
+        seed_trustanchor2 = generate_random_string(prefix=""TrustAnchor2"", size=32)
+        seed_trustanchor3 = generate_random_string(prefix=""TrustAnchor3"", size=32)
+        try:
+            # 1. Create ledger config from genesis txn file  ---------------------------------------------------------
+            self.steps.add_step(""Create and open pool Ledger"")
+            returned_code = await perform(self.steps, Common.prepare_pool_and_wallet, self.pool_name,
+                                          self.wallet_name, self.pool_genesis_txn_file)
+
+            self.pool_handle, self.wallet_handle = exit_if_exception(returned_code)
+
+            # 2. Create DIDs ----------------------------------------------------
+            self.steps.add_step(""Create DIDs"")
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,
+                                          self.wallet_handle, json.dumps({""seed"": Constant.seed_default_trustee}))
+            default_trustee_did = returned_code[0] if len(returned_code) == 2 else (None, None)
+
+            returned_code = await perform(self.steps, signus.create_and_store_my_did,",,2017-12-27 10:24:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158793800,https://github.com/hyperledger/indy-node/pull/456#discussion_r158793800,spivachuk
https://github.com/hyperledger/indy-node/pull/456,https://github.com/hyperledger/indy-node/pull/456,"Please update also the content of the file `pool.txn` as mentioned above.

In order to do this you can run a local pool in Docker and a client for it using https://github.com/evernym/sovrin-environments. For details please see https://github.com/evernym/sovrin-environments/blob/stable/docker/README.md. Use the defaults for the pool and client for it.
Then open a new terminal window and log in to the running client container using the command `docker exec -it sovrinclient bash`.
In the client container open the file `/home/indy/.indy-cli/networks/sandbox/`. The current content of `indy-node/acceptance/pool.txn` should be replaced with the content of this file.",ca6cda2a049171a98e4758240a00e97ea449ea25,2017-12-27 11:17:22,158799437,"@@ -0,0 +1,60 @@
+
+""""""
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+
+Containing all constants that are necessary to execute test scenario.
+""""""
+
+
+class Colors:
+    """"""
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color.
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """"""
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete.
+    NONE = """"
+
+
+class Constant:
+    """"""
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    user_home = os.path.expanduser('~') + os.sep
+    work_dir = user_home + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    # The path to the genesis transaction file is configurable. The default directory is ""/var/lib/indy/sandbox/"".
+    genesis_transaction_file_path = ""/var/lib/indy/sandbox/""",,2017-12-27 11:20:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/158799437,https://github.com/hyperledger/indy-node/pull/456#discussion_r158799437,spivachuk
https://github.com/hyperledger/indy-node/pull/455,https://github.com/hyperledger/indy-node/pull/455,Please remove copyright header for now,0c0896bbc5bc8e3a2e13a6808acef8a946f58979,2017-11-17 08:09:15,151623449,"@@ -1,3 +1,18 @@
+#   Copyright 2017 Sovrin Foundation",,2017-11-17 08:13:11,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151623449,https://github.com/hyperledger/indy-node/pull/455#discussion_r151623449,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,Looks like this code is used in all the tests. Can we create a common method for this?,bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 08:13:25,151624065,"@@ -0,0 +1,185 @@
+import json
+import sys
+import logging
+import os
+import asyncio
+import shutil
+import time
+from indy import pool, signus, wallet
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.constant import Colors, Constant
+from utils.report import TestReport
+
+
+class MyVars:
+    begin_time = 0
+    pool_handle = 0
+    wallet_handle = 0
+    pool_name = ""pool_genesis_test3""
+    wallet_name = ""test_wallet3""
+    debug = False
+    test_report = TestReport(""Test_scenario_03_Check_Connection"")
+    test_results = {""Step 1"": False, ""Step 2"": False, ""Step 3"": False, ""Step 4"": False,
+                    ""Step 5"": False, ""Step 6"": False, ""Step 7"": False, ""Step 8"": False}
+
+
+logger = logging.getLogger(__name__)
+logging.basicConfig(level=logging.INFO)
+
+
+def test_precondition():",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151624065,https://github.com/hyperledger/indy-node/pull/447#discussion_r151624065,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"The same pattern/template is used for each test case (print/try/except).
Can we create an utility method and use this instead of boilerplate code?
I think it will increase test readability and maintenance a lot.",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 08:30:04,151626907,"@@ -0,0 +1,185 @@
+import json
+import sys
+import logging
+import os
+import asyncio
+import shutil
+import time
+from indy import pool, signus, wallet
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.constant import Colors, Constant
+from utils.report import TestReport
+
+
+class MyVars:
+    begin_time = 0
+    pool_handle = 0
+    wallet_handle = 0
+    pool_name = ""pool_genesis_test3""
+    wallet_name = ""test_wallet3""
+    debug = False
+    test_report = TestReport(""Test_scenario_03_Check_Connection"")
+    test_results = {""Step 1"": False, ""Step 2"": False, ""Step 3"": False, ""Step 4"": False,
+                    ""Step 5"": False, ""Step 6"": False, ""Step 7"": False, ""Step 8"": False}
+
+
+logger = logging.getLogger(__name__)
+logging.basicConfig(level=logging.INFO)
+
+
+def test_precondition():
+    print(Colors.HEADER + ""\n\tCheck if the wallet and pool for this test already exist and delete them...\n"" + Colors.ENDC)
+
+    if os.path.exists(Constant.work_dir + ""wallet/"" + MyVars.wallet_name):
+        try:
+            shutil.rmtree(Constant.work_dir + ""wallet/"" + MyVars.wallet_name)
+        except IOError as E:
+            print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    if os.path.exists(Constant.work_dir + ""pool/"" + MyVars.pool_name):
+        try:
+            shutil.rmtree(Constant.work_dir + ""pool/"" + MyVars.pool_name)
+        except IOError as E:
+            print(Colors.FAIL + str(E) + Colors.ENDC)
+
+
+async def test_scenario_03_check_connection():
+    logger.info(""Test scenario 3 -> started"")
+
+    seed_steward01 = ""000000000000000000000000Steward1""
+    pool_config = json.dumps({""genesis_txn"": str(Constant.pool_genesis_txn_file)})
+
+    # 1. Create pool ledger
+    print(Colors.HEADER + ""\n\t1.  Create pool ledger\n"" + Colors.ENDC)",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151626907,https://github.com/hyperledger/indy-node/pull/447#discussion_r151626907,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"The current working dir for libindy is `.indy_client`, not `.indy` (in the latest stable)",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 08:55:02,151630977,"@@ -0,0 +1,32 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" Class to set the colors for text.  Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC) """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""
+    NONE = """"
+
+
+class Constant:
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151630977,https://github.com/hyperledger/indy-node/pull/447#discussion_r151630977,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"In the latest master and RC of indy-node, pool_genesis_txn_files are located in 
`/var/lib/indy/sandbox/pool_transactions_genesis` (for sandbox network)",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 08:57:14,151631383,"@@ -0,0 +1,32 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" Class to set the colors for text.  Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC) """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""
+    NONE = """"
+
+
+class Constant:
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    pool_genesis_txn_file = os.path.expanduser('~') + os.sep + "".sovrin/pool_transactions_sandbox_genesis""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151631383,https://github.com/hyperledger/indy-node/pull/447#discussion_r151631383,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,Is this file needed for tests?,bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 10:57:54,151657884,"@@ -0,0 +1,173 @@
+{
+  ""testcase"": ""Test_Scenario_09_Remove_And_Add_Role"",",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151657884,https://github.com/hyperledger/indy-node/pull/447#discussion_r151657884,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,It looks like a log. I think it needs to be removed,bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 10:58:26,151657979,"@@ -0,0 +1,118 @@
+[95m",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151657979,https://github.com/hyperledger/indy-node/pull/447#discussion_r151657979,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"In the latest master and RC of indy-node, pool_genesis_txn_files are located in
/var/lib/indy/sandbox/pool_transactions_genesis (for sandbox network)",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 10:58:51,151658066,"@@ -0,0 +1,44 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" 
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """""" 
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete
+    NONE = """"
+
+
+class Constant:
+    """""" 
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    pool_genesis_txn_file = os.path.expanduser('~') + os.sep + "".sovrin/pool_transactions_sandbox_genesis""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151658066,https://github.com/hyperledger/indy-node/pull/447#discussion_r151658066,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"The current working dir for libindy is .indy_client, not .indy (in the latest stable)",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 10:59:04,151658105,"@@ -0,0 +1,44 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" 
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """""" 
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete
+    NONE = """"
+
+
+class Constant:
+    """""" 
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151658105,https://github.com/hyperledger/indy-node/pull/447#discussion_r151658105,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"When we run tests with libindy, the .indy directory is created automatically.  I do not believe .indy_client is the default directory anymore.",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 16:07:53,151722577,"@@ -0,0 +1,44 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" 
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """""" 
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete
+    NONE = """"
+
+
+class Constant:
+    """""" 
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151722577,https://github.com/hyperledger/indy-node/pull/447#discussion_r151722577,StevenL2015
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"I agree.  Khoi, please make it so",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 16:09:26,151723030,"@@ -0,0 +1,185 @@
+import json
+import sys
+import logging
+import os
+import asyncio
+import shutil
+import time
+from indy import pool, signus, wallet
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.constant import Colors, Constant
+from utils.report import TestReport
+
+
+class MyVars:
+    begin_time = 0
+    pool_handle = 0
+    wallet_handle = 0
+    pool_name = ""pool_genesis_test3""
+    wallet_name = ""test_wallet3""
+    debug = False
+    test_report = TestReport(""Test_scenario_03_Check_Connection"")
+    test_results = {""Step 1"": False, ""Step 2"": False, ""Step 3"": False, ""Step 4"": False,
+                    ""Step 5"": False, ""Step 6"": False, ""Step 7"": False, ""Step 8"": False}
+
+
+logger = logging.getLogger(__name__)
+logging.basicConfig(level=logging.INFO)
+
+
+def test_precondition():",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151723030,https://github.com/hyperledger/indy-node/pull/447#discussion_r151723030,StevenL2015
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"I agree. Khoi, please make it so",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 16:09:52,151723172,"@@ -0,0 +1,185 @@
+import json
+import sys
+import logging
+import os
+import asyncio
+import shutil
+import time
+from indy import pool, signus, wallet
+from indy.error import IndyError
+sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
+from utils.constant import Colors, Constant
+from utils.report import TestReport
+
+
+class MyVars:
+    begin_time = 0
+    pool_handle = 0
+    wallet_handle = 0
+    pool_name = ""pool_genesis_test3""
+    wallet_name = ""test_wallet3""
+    debug = False
+    test_report = TestReport(""Test_scenario_03_Check_Connection"")
+    test_results = {""Step 1"": False, ""Step 2"": False, ""Step 3"": False, ""Step 4"": False,
+                    ""Step 5"": False, ""Step 6"": False, ""Step 7"": False, ""Step 8"": False}
+
+
+logger = logging.getLogger(__name__)
+logging.basicConfig(level=logging.INFO)
+
+
+def test_precondition():
+    print(Colors.HEADER + ""\n\tCheck if the wallet and pool for this test already exist and delete them...\n"" + Colors.ENDC)
+
+    if os.path.exists(Constant.work_dir + ""wallet/"" + MyVars.wallet_name):
+        try:
+            shutil.rmtree(Constant.work_dir + ""wallet/"" + MyVars.wallet_name)
+        except IOError as E:
+            print(Colors.FAIL + str(E) + Colors.ENDC)
+
+    if os.path.exists(Constant.work_dir + ""pool/"" + MyVars.pool_name):
+        try:
+            shutil.rmtree(Constant.work_dir + ""pool/"" + MyVars.pool_name)
+        except IOError as E:
+            print(Colors.FAIL + str(E) + Colors.ENDC)
+
+
+async def test_scenario_03_check_connection():
+    logger.info(""Test scenario 3 -> started"")
+
+    seed_steward01 = ""000000000000000000000000Steward1""
+    pool_config = json.dumps({""genesis_txn"": str(Constant.pool_genesis_txn_file)})
+
+    # 1. Create pool ledger
+    print(Colors.HEADER + ""\n\t1.  Create pool ledger\n"" + Colors.ENDC)",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151723172,https://github.com/hyperledger/indy-node/pull/447#discussion_r151723172,StevenL2015
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,This path is configurable so the user can use multiple transaction files in multiple locations,bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 16:11:11,151723711,"@@ -0,0 +1,32 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" Class to set the colors for text.  Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC) """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""
+    NONE = """"
+
+
+class Constant:
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    pool_genesis_txn_file = os.path.expanduser('~') + os.sep + "".sovrin/pool_transactions_sandbox_genesis""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151723711,https://github.com/hyperledger/indy-node/pull/447#discussion_r151723711,StevenL2015
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"What version of libindy are you using?
I think it was changed in the latest stable (which was issued last week)",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 16:18:07,151725940,"@@ -0,0 +1,44 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" 
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """""" 
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete
+    NONE = """"
+
+
+class Constant:
+    """""" 
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151725940,https://github.com/hyperledger/indy-node/pull/447#discussion_r151725940,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,"yes, but if you take config files from a sovrin installation, then they will be placed to the location mentioned above (and not to .sovrin)",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 16:19:38,151726389,"@@ -0,0 +1,32 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" Class to set the colors for text.  Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC) """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""
+    NONE = """"
+
+
+class Constant:
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    pool_genesis_txn_file = os.path.expanduser('~') + os.sep + "".sovrin/pool_transactions_sandbox_genesis""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151726389,https://github.com/hyperledger/indy-node/pull/447#discussion_r151726389,ashcherbakov
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447," Khoi, please add a comment above this line that tells the user the path to the genesis transaction file is configurable.  The comment should indicate the default directory for the genesis transaction file is /var/lib/indy/sandbox/ but the user can put the genesis transaction file anywhere they want as long as the path is set in this line.  Please remove .sovrin/ and put the default path as /var/lib/indy/sandbox/ before checking this file in.",bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 16:59:59,151736892,"@@ -0,0 +1,32 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" Class to set the colors for text.  Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC) """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""
+    NONE = """"
+
+
+class Constant:
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""
+    seed_default_trustee = ""000000000000000000000000Trustee1""
+    pool_genesis_txn_file = os.path.expanduser('~') + os.sep + "".sovrin/pool_transactions_sandbox_genesis""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151736892,https://github.com/hyperledger/indy-node/pull/447#discussion_r151736892,StevenL2015
https://github.com/hyperledger/indy-node/pull/447,https://github.com/hyperledger/indy-node/pull/447,I am using the version from the stable build dated 01-Nov-2017.  That is the only build I see in the 1.0.1 directory,bf4840e0afd0735538b9f45edb9c9acaa088fbc8,2017-11-17 17:05:49,151738233,"@@ -0,0 +1,44 @@
+'''
+Created on Nov 9, 2017
+
+@author: khoi.ngo
+'''
+
+
+class Colors:
+    """""" 
+    Class to set the colors for text.
+    Syntax:  print(Colors.OKGREEN +""TEXT HERE"" +Colors.ENDC)
+    """"""
+    HEADER = '\033[95m'
+    OKBLUE = '\033[94m'
+    OKGREEN = '\033[92m'
+    WARNING = '\033[93m'
+    FAIL = '\033[91m'
+    ENDC = '\033[0m'  # Normal default color
+    BOLD = '\033[1m'
+    UNDERLINE = '\033[4m'
+
+
+class Roles:
+    """""" 
+    Class to define roles.
+    """"""
+    TRUSTEE = ""TRUSTEE""
+    STEWARD = ""STEWARD""
+    TRUST_ANCHOR = ""TRUST_ANCHOR""
+    TGB = ""TGB""  # obsolete
+    NONE = """"
+
+
+class Constant:
+    """""" 
+    Class Constant store some necessary paths.
+    """"""
+    import os
+    work_dir = os.path.expanduser('~') + os.sep + "".indy""",,2017-11-23 11:40:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/151738233,https://github.com/hyperledger/indy-node/pull/447#discussion_r151738233,StevenL2015
https://github.com/hyperledger/indy-node/pull/440,https://github.com/hyperledger/indy-node/pull/440,I think it makes sense to check not defined yet mode inside can_send_... methods.,4464a1bf533dca8b218a000dec74948a3a2f1fca,2017-11-09 08:54:10,149896604,"@@ -64,7 +64,7 @@ def runAgent(agent, looper=None, bootstrap=None):
 
     def is_connected(agent):
         client = agent.client
-        if not client.can_send_write_requests():
+        if (client.mode is None) or (not client.can_send_write_requests()):",5,2017-11-09 08:54:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/149896604,https://github.com/hyperledger/indy-node/pull/440#discussion_r149896604,andkononykhin
https://github.com/hyperledger/indy-node/pull/440,https://github.com/hyperledger/indy-node/pull/440,"I agree, I just wanted to make a hot fix here. I will send a separate PR to move this condition to can_send_write_requests()",4464a1bf533dca8b218a000dec74948a3a2f1fca,2017-11-09 08:56:40,149897146,"@@ -64,7 +64,7 @@ def runAgent(agent, looper=None, bootstrap=None):
 
     def is_connected(agent):
         client = agent.client
-        if not client.can_send_write_requests():
+        if (client.mode is None) or (not client.can_send_write_requests()):",5,2017-11-09 08:56:41,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/149897146,https://github.com/hyperledger/indy-node/pull/440#discussion_r149897146,ashcherbakov
https://github.com/hyperledger/indy-node/pull/440,https://github.com/hyperledger/indy-node/pull/440,i see,4464a1bf533dca8b218a000dec74948a3a2f1fca,2017-11-09 08:57:45,149897367,"@@ -64,7 +64,7 @@ def runAgent(agent, looper=None, bootstrap=None):
 
     def is_connected(agent):
         client = agent.client
-        if not client.can_send_write_requests():
+        if (client.mode is None) or (not client.can_send_write_requests()):",5,2017-11-09 08:57:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/149897367,https://github.com/hyperledger/indy-node/pull/440#discussion_r149897367,andkononykhin
https://github.com/hyperledger/indy-node/pull/437,https://github.com/hyperledger/indy-node/pull/437,May be logger.info() instead of logger.error()?,b1ea1928bb39db6c313148572410798c845cf171,2017-11-07 16:22:30,149424375,"@@ -76,110 +71,117 @@ def get_network_name():
 def migrate_general_config(old_general_config, new_general_config, network_name):
     logger.info('Migrate general config file {} -> {} for network {}'.format(
         old_general_config, new_general_config, network_name))
+
     f = open(old_general_config, ""r"")
     lines = f.readlines()
     f.close()
 
-    f = open(new_general_config, ""w"")
+    f = open(new_general_config, ""a+"")
     for line in lines:
         if not line.startswith('current_env') and not line.startswith('poolTransactionsFile') and\
                 not line.startswith('domainTransactionsFile'):
             f.write(line)
     line = ""NETWORK_NAME = '{}'\n"".format(network_name)
     f.write(line)
     f.close()
+    # os.remove(old_general_config)
 
 
-def migrate_cli(old_dir, new_dir, new_txn_dir):
-    if not os.path.exists(new_dir):
-        os.makedirs(new_dir)
-
-    # Move wallets directory
-    logger.info('Move wallets directory {} -> {}'.format(
-        old_dir, new_dir))
-    shutil.move(old_dir, new_dir)
-    logger.info('done')
-
-    # Move txns for CLI
-    migrate_genesis_txn(old_dir, new_txn_dir)
+def remove_network_from_dir_name(root_dir):
+    logger.error(""remove_network_from_dir_name {}"".format(root_dir))",,2017-11-07 16:27:37,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/149424375,https://github.com/hyperledger/indy-node/pull/437#discussion_r149424375,sergey-shilov
https://github.com/hyperledger/indy-node/pull/432,https://github.com/hyperledger/indy-node/pull/432,"Can we have more descriptive exception here, like ""Can not get information about pachages, since 'apt-cache show' return {}""?",fde98c808bf97a22e3b46a24d1c07e7206a12aba,2017-11-03 11:22:21,148758173,"@@ -87,10 +87,8 @@ def _get_info_from_package_manager(cls, package):
             timeout=TIMEOUT)
 
         if ret.returncode != 0:
-            msg = 'Upgrade failed: _get_deps_list returned {}'.format(
-                ret.returncode)
-            logger.error(msg)
-            raise Exception(msg)
+            raise Exception('_get_deps_list returned {}'",,2017-11-03 13:59:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148758173,https://github.com/hyperledger/indy-node/pull/432#discussion_r148758173,ashcherbakov
https://github.com/hyperledger/indy-node/pull/432,https://github.com/hyperledger/indy-node/pull/432,"Can we have more descriptive exception here, like ""Can not update packages, since 'apt update' returned {}""?",fde98c808bf97a22e3b46a24d1c07e7206a12aba,2017-11-03 11:22:49,148758318,"@@ -109,10 +107,8 @@ def _update_package_cache(cls):
             timeout=TIMEOUT)
 
         if ret.returncode != 0:
-            msg = 'Upgrade failed: _get_deps_list returned {}'.format(
-                ret.returncode)
-            logger.error(msg)
-            raise Exception(msg)
+            raise Exception('_get_deps_list returned {}'",,2017-11-03 13:59:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148758318,https://github.com/hyperledger/indy-node/pull/432#discussion_r148758318,ashcherbakov
https://github.com/hyperledger/indy-node/pull/432,https://github.com/hyperledger/indy-node/pull/432,Can we have more descriptive exception here as well?,fde98c808bf97a22e3b46a24d1c07e7206a12aba,2017-11-03 11:23:07,148758424,"@@ -131,10 +127,9 @@ def _hold_packages(self):
             timeout=TIMEOUT)
 
         if ret.returncode != 0:
-            msg = 'Holding {} packages failed: _hold_packages returned {}'.format(
-                self.packages_to_hold, ret.returncode)
-            logger.error(msg)
-            raise Exception(msg)
+            raise Exception('holding {} packages failed: _'",,2017-11-03 13:59:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148758424,https://github.com/hyperledger/indy-node/pull/432#discussion_r148758424,ashcherbakov
https://github.com/hyperledger/indy-node/pull/432,https://github.com/hyperledger/indy-node/pull/432,Can we have more descriptive exception here as well?,fde98c808bf97a22e3b46a24d1c07e7206a12aba,2017-11-03 11:23:34,148758515,"@@ -175,10 +170,8 @@ def _call_upgrade_script(self, version):
             timeout=self.timeout)
 
         if ret.returncode != 0:
-            msg = 'Upgrade failed: _upgrade script returned {}'.format(
-                ret.returncode)
-            logger.error(msg)
-            raise Exception(msg)
+            raise Exception('_upgrade script returned {}'",,2017-11-03 13:59:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148758515,https://github.com/hyperledger/indy-node/pull/432#discussion_r148758515,ashcherbakov
https://github.com/hyperledger/indy-node/pull/432,https://github.com/hyperledger/indy-node/pull/432,A typo in method name,fde98c808bf97a22e3b46a24d1c07e7206a12aba,2017-11-03 11:25:00,148758784,"@@ -279,6 +273,16 @@ def _process_data(self, data):
         except Exception as e:
             logger.error(""Unexpected error in process_data {}"".format(e))
 
+    def _declate_upgrade_failed(self, *,",,2017-11-03 13:59:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148758784,https://github.com/hyperledger/indy-node/pull/432#discussion_r148758784,ashcherbakov
https://github.com/hyperledger/indy-node/pull/427,https://github.com/hyperledger/indy-node/pull/427,It was already described above,a36142d1751c23f3d35b5628a7513f81f67aeed4,2017-11-02 09:49:54,148483088,"@@ -0,0 +1,156 @@
+# Create a Network and Start Nodes
+
+In order to run your own Network, you need to do the following for each Node:
+1. Install Indy Node
+    - A recommended way for ubuntu is installing from deb packages
+    ```
+    sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 68DB5E88
+    sudo echo ""deb https://repo.sovrin.org/deb xenial stable"" >> /etc/apt/sources.list
+    sudo apt-get update
+    sudo apt-get install indy-node
+    ```
+    - It's also possible to install from pypi for test purposes
+        - master version: `pip install indy-node-dev`
+        - stable version: `pip install indy-node`
+2. Initialize Node to be included into the Network
+    - set Network name in config file
+        - the location of the config depends on how a Node was installed. It's usually inside `/etc/indy` for Ubuntu.
+        - the following needs to be added: `NETWORK_NAME={network_name}` where {network_name} matches the one in genesis transaction files above
+    - generate keys
+        - ed25519 transport keys (used by ZMQ for Node-to-Node and Node-to-Client communication)
+        - BLS keys for BLS multi-signature and state proofs support
+    - provide genesis transactions files which will be a basis of initial Pool.
+        - pool transactions genesis file:
+            - The file must be named as `pool_transactions_file_{network_name}_genesis`
+            - The file contains initial set of Nodes a Pool is started from (initial set of NODE transactions in the Ledger)
+            - New Nodes will be added by sending new NODE txn to be written into the Ledger
+            - All new Nodes and Clients will use genesis transaction file to connect to initial set of Nodes,
+            and then catch-up all other NODE transactions to get up-to-date Ledger.
+        - domain transactions genesis file:
+            - The file must be named as `domain_transactions_file_{network_name}_genesis`
+            - The file contains initial NYM transactions (for example, Trustees, Stewards, etc.)
+
+## Scripts for Initialization
+
+There are a number of scripts which can help in generation of keys and running a test network.
+
+#### Generating keys
+
+The following script can generate both ed25519 and BLS keys for a node named `Alpha`
+```
+init_indy_keys --name Alpha [--seed 111111111111111111111111111Alpha] [--force]
+```
+Note: Seed can be any randomly chosen 32 byte value. It does not have to be in the format 11..<name of the node>
+
+Please not that this script must be called *after* CURRENT_NETWORK is set in config (see above).
+
+#### Running Node
+
+The following script will start a Node process which can communicate with other Nodes and Clients
+```
+start_indy_node Alpha 9701 9702
+```
+The node uses a separate TCP channels for communicating with nodes and clients.
+The first port number is for the node-to-node communication channel and the second is for node-to-client communication channel.
+
+
+#### Generating keys and test genesis transaction files for a test network
+
+There is a script that can generate keys and corresponding test genesis files to be used with a Test network.
+
+```
+~$ generate_indy_pool_transactions --nodes 4 --clients 5 --nodeNum 1 [--ips '191.177.76.26,22.185.194.102,247.81.153.79,93.125.199.45'] [--network=sandbox]
+```
+- `--nodes` specifies a total number of nodes in the pool
+- `--clients` specifies a number of pre-configured clients in the pool (in `domain_transactions_file_{network_name}_genesis`)
+- `--nodeNum` specifies a number of this particular node (from 1 to `-nodes` value), that is a number of the Node to create private keys locally for.
+- `--ip` specifies IP addresses for all nodes in the pool (if not specified, then `localhost` is used) 
+- `--network` specifies a Network generate transaction files and keys for. `sandbox` is used by default.
+ 
+We can run the script multiple times for different networks. 
+
+#### Running Node",63,2017-11-02 13:49:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148483088,https://github.com/hyperledger/indy-node/pull/427#discussion_r148483088,andkononykhin
https://github.com/hyperledger/indy-node/pull/427,https://github.com/hyperledger/indy-node/pull/427,What about indy-anoncreds?,a36142d1751c23f3d35b5628a7513f81f67aeed4,2017-11-02 09:54:37,148484145,"@@ -0,0 +1,86 @@
+# Continues integration/delivery
+
+- Unit/Integration tests are executed for each PR
+- Each PR needs to be reviewed
+- PR can be merged only after all tests pass and code is reviewed
+- We use pipeline in code approach and Jenkins as our main CI/CD server
+- CI part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.ci` file. 
+- CI part is run on Hyperledger Jenkins, so it is public and open as every contributor needs to see results of the tests run for his or her PR.
+- CD part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.cd` file.
+- CD part is run on a private Jenkins server dealing with issuing and uploading new builds. 
+
+#### Branches
+
+- Master branch contains the latest changes. All PRs usually need to be sent to master.
+- Stable branch contains latest releases (https://github.com/hyperledger/indy-node/releases). Hotfixes need to be sent to stable.
+
+#### Builds
+
+What artifacts are produced after each push
+- to `master` branch:
+    - indy-plenum:
+        - indy-plenum-dev in [pypi](https://pypi.python.org/pypi/indy-plenum-dev) 
+        - indy-plenum deb package in [https://repo.sovrin.org/deb xenial master-latest](https://repo.sovrin.org/lib/apt/xenial/master-latest/)
+        - indy-plenum release tag (https://github.com/hyperledger/indy-plenum/releases)
+    - indy-node:",,2017-11-02 13:49:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148484145,https://github.com/hyperledger/indy-node/pull/427#discussion_r148484145,andkononykhin
https://github.com/hyperledger/indy-node/pull/427,https://github.com/hyperledger/indy-node/pull/427,"Not sure if it makes sense here but to be more accurate: indy-node is published to master latest as well and then all movements happen (indy-node with all deps including indy-plenum, indy-anoncreds and 3rd party deps that we held in our repo)",a36142d1751c23f3d35b5628a7513f81f67aeed4,2017-11-02 09:59:06,148485310,"@@ -0,0 +1,86 @@
+# Continues integration/delivery
+
+- Unit/Integration tests are executed for each PR
+- Each PR needs to be reviewed
+- PR can be merged only after all tests pass and code is reviewed
+- We use pipeline in code approach and Jenkins as our main CI/CD server
+- CI part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.ci` file. 
+- CI part is run on Hyperledger Jenkins, so it is public and open as every contributor needs to see results of the tests run for his or her PR.
+- CD part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.cd` file.
+- CD part is run on a private Jenkins server dealing with issuing and uploading new builds. 
+
+#### Branches
+
+- Master branch contains the latest changes. All PRs usually need to be sent to master.
+- Stable branch contains latest releases (https://github.com/hyperledger/indy-node/releases). Hotfixes need to be sent to stable.
+
+#### Builds
+
+What artifacts are produced after each push
+- to `master` branch:
+    - indy-plenum:
+        - indy-plenum-dev in [pypi](https://pypi.python.org/pypi/indy-plenum-dev) 
+        - indy-plenum deb package in [https://repo.sovrin.org/deb xenial master-latest](https://repo.sovrin.org/lib/apt/xenial/master-latest/)
+        - indy-plenum release tag (https://github.com/hyperledger/indy-plenum/releases)
+    - indy-node:
+        - indy-node-dev in [pypi](https://pypi.python.org/pypi/indy-node-dev)
+        - indy-node deb package in [https://repo.sovrin.org/deb xenial master](https://repo.sovrin.org/lib/apt/xenial/master/)",,2017-11-02 13:49:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148485310,https://github.com/hyperledger/indy-node/pull/427#discussion_r148485310,andkononykhin
https://github.com/hyperledger/indy-node/pull/427,https://github.com/hyperledger/indy-node/pull/427,"underscores here are interpreted as marks for bold text, it's possible to fix that by escaping (at least two of them) e.g. 
`[\_\_metadata__.py](https://github.com/hyperledger/indy-node/blob/master/indy_node/__metadata__.py)`",a36142d1751c23f3d35b5628a7513f81f67aeed4,2017-11-02 10:06:37,148487239,"@@ -0,0 +1,86 @@
+# Continues integration/delivery
+
+- Unit/Integration tests are executed for each PR
+- Each PR needs to be reviewed
+- PR can be merged only after all tests pass and code is reviewed
+- We use pipeline in code approach and Jenkins as our main CI/CD server
+- CI part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.ci` file. 
+- CI part is run on Hyperledger Jenkins, so it is public and open as every contributor needs to see results of the tests run for his or her PR.
+- CD part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.cd` file.
+- CD part is run on a private Jenkins server dealing with issuing and uploading new builds. 
+
+#### Branches
+
+- Master branch contains the latest changes. All PRs usually need to be sent to master.
+- Stable branch contains latest releases (https://github.com/hyperledger/indy-node/releases). Hotfixes need to be sent to stable.
+
+#### Builds
+
+What artifacts are produced after each push
+- to `master` branch:
+    - indy-plenum:
+        - indy-plenum-dev in [pypi](https://pypi.python.org/pypi/indy-plenum-dev) 
+        - indy-plenum deb package in [https://repo.sovrin.org/deb xenial master-latest](https://repo.sovrin.org/lib/apt/xenial/master-latest/)
+        - indy-plenum release tag (https://github.com/hyperledger/indy-plenum/releases)
+    - indy-node:
+        - indy-node-dev in [pypi](https://pypi.python.org/pypi/indy-node-dev)
+        - indy-node deb package in [https://repo.sovrin.org/deb xenial master](https://repo.sovrin.org/lib/apt/xenial/master/)
+        - indy-plenum deb package in [https://repo.sovrin.org/deb xenial master](https://repo.sovrin.org/lib/apt/xenial/master/) (copied from master-latest)
+        - indy-node release tag (https://github.com/hyperledger/indy-node/releases)
+- to `stable` branch:
+    - indy-plenum:
+        - indy-plenum in [pypi](https://pypi.python.org/pypi/indy-plenum) 
+        - indy-plenum deb package in [https://repo.sovrin.org/deb xenial rc-latest](https://repo.sovrin.org/lib/apt/xenial/rc-latest/)
+        - indy-plenum release tag (https://github.com/hyperledger/indy-plenum/releases)
+    - indy-node:
+        - indy-node in [pypi](https://pypi.python.org/pypi/indy-node)
+        - indy-node deb package in [https://repo.sovrin.org/deb xenial rc](https://repo.sovrin.org/lib/apt/xenial/rc/)
+        - indy-plenum deb package in [https://repo.sovrin.org/deb xenial rc](https://repo.sovrin.org/lib/apt/xenial/rc/) (copied from rc-latest)
+        - indy-node release tag (https://github.com/hyperledger/indy-node/releases)
+        - after build is tested and approved:
+            - indy-node deb package in [https://repo.sovrin.org/deb xenial stable](https://repo.sovrin.org/lib/apt/xenial/stable/) (copied from rc)
+            - indy-plenum deb package in [https://repo.sovrin.org/deb xenial stable](https://repo.sovrin.org/lib/apt/xenial/stable/) (copied from rc)
+
+Use cases for artifacts
+- Pypi artifacts can be used for dev experiments, but not intended to be used for production.
+- Using deb packages is recommended way to be used for a test/production pool on Ubuntu.
+- indy-node deb package from [https://repo.sovrin.org/deb xenial stable](https://repo.sovrin.org/lib/apt/xenial/stable/) 
+is one and the only official stable release that can be used for production. 
+
+#### Versioning
+
+- Please note, that we are using semver approach for versioning (major, minor, patch) for each of the components. 
+- Major and minor parts are set in the code (see [__metadata__.py](https://github.com/hyperledger/indy-node/blob/master/indy_node/__metadata__.py)). They must be incremented for new releases manually from code if needed.",,2017-11-02 13:49:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148487239,https://github.com/hyperledger/indy-node/pull/427#discussion_r148487239,andkononykhin
https://github.com/hyperledger/indy-node/pull/427,https://github.com/hyperledger/indy-node/pull/427,"Here I intentionally didn't mention anoncreds, and provide tutorials only for plenum and node, because of the following:
- anoncreds project will be deprecated soon;
- we should ask all people who wants contribution to anoncreds use libindy
- anoncreds project is quite independent of plenum/node (at least more independent than plenum and node pair). ",a36142d1751c23f3d35b5628a7513f81f67aeed4,2017-11-02 10:26:57,148492017,"@@ -0,0 +1,86 @@
+# Continues integration/delivery
+
+- Unit/Integration tests are executed for each PR
+- Each PR needs to be reviewed
+- PR can be merged only after all tests pass and code is reviewed
+- We use pipeline in code approach and Jenkins as our main CI/CD server
+- CI part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.ci` file. 
+- CI part is run on Hyperledger Jenkins, so it is public and open as every contributor needs to see results of the tests run for his or her PR.
+- CD part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.cd` file.
+- CD part is run on a private Jenkins server dealing with issuing and uploading new builds. 
+
+#### Branches
+
+- Master branch contains the latest changes. All PRs usually need to be sent to master.
+- Stable branch contains latest releases (https://github.com/hyperledger/indy-node/releases). Hotfixes need to be sent to stable.
+
+#### Builds
+
+What artifacts are produced after each push
+- to `master` branch:
+    - indy-plenum:
+        - indy-plenum-dev in [pypi](https://pypi.python.org/pypi/indy-plenum-dev) 
+        - indy-plenum deb package in [https://repo.sovrin.org/deb xenial master-latest](https://repo.sovrin.org/lib/apt/xenial/master-latest/)
+        - indy-plenum release tag (https://github.com/hyperledger/indy-plenum/releases)
+    - indy-node:",,2017-11-02 13:49:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148492017,https://github.com/hyperledger/indy-node/pull/427#discussion_r148492017,ashcherbakov
https://github.com/hyperledger/indy-node/pull/427,https://github.com/hyperledger/indy-node/pull/427,"thanks, I will fix",a36142d1751c23f3d35b5628a7513f81f67aeed4,2017-11-02 10:27:42,148492211,"@@ -0,0 +1,86 @@
+# Continues integration/delivery
+
+- Unit/Integration tests are executed for each PR
+- Each PR needs to be reviewed
+- PR can be merged only after all tests pass and code is reviewed
+- We use pipeline in code approach and Jenkins as our main CI/CD server
+- CI part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.ci` file. 
+- CI part is run on Hyperledger Jenkins, so it is public and open as every contributor needs to see results of the tests run for his or her PR.
+- CD part of the pipeline (running tests for each PR) is defined in `Jenkinsfile.cd` file.
+- CD part is run on a private Jenkins server dealing with issuing and uploading new builds. 
+
+#### Branches
+
+- Master branch contains the latest changes. All PRs usually need to be sent to master.
+- Stable branch contains latest releases (https://github.com/hyperledger/indy-node/releases). Hotfixes need to be sent to stable.
+
+#### Builds
+
+What artifacts are produced after each push
+- to `master` branch:
+    - indy-plenum:
+        - indy-plenum-dev in [pypi](https://pypi.python.org/pypi/indy-plenum-dev) 
+        - indy-plenum deb package in [https://repo.sovrin.org/deb xenial master-latest](https://repo.sovrin.org/lib/apt/xenial/master-latest/)
+        - indy-plenum release tag (https://github.com/hyperledger/indy-plenum/releases)
+    - indy-node:
+        - indy-node-dev in [pypi](https://pypi.python.org/pypi/indy-node-dev)
+        - indy-node deb package in [https://repo.sovrin.org/deb xenial master](https://repo.sovrin.org/lib/apt/xenial/master/)",,2017-11-02 13:49:48,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/148492211,https://github.com/hyperledger/indy-node/pull/427#discussion_r148492211,ashcherbakov
https://github.com/hyperledger/indy-node/pull/410,https://github.com/hyperledger/indy-node/pull/410,Please update docstring to make it describe what happens it test,61117b8ac354800ecf7b3831bb2c09eafafe0c50,2017-10-23 09:15:36,146207584,"@@ -25,6 +25,32 @@ def test_add_same_node_without_any_change(be, do, newStewardCli,
     exitFromCli(do)
 
 
+def test_add_same_node_without_any_change_by_trustee(be, do, trusteeCli,
+                                                     newNodeVals, newNodeAdded,
+                                                     nodeValsEmptyData):
+    '''
+    Checks that it's possible to update BLS keys (just alias and new key are required)
+    '''
+    be(trusteeCli)
+    doSendNodeCmd(do, newNodeVals,
+                  expMsgs=[""node already has the same data as requested""])
+    exitFromCli(do)
+
+
+def test_add_same_node_with_changed_bls_by_trustee(be, do, trusteeCli,
+                                                   newNodeVals, newNodeAdded,
+                                                   nodeValsEmptyData):
+    '''
+    Checks that it's possible to update BLS keys (just alias and new key are required)",,2017-10-23 09:24:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146207584,https://github.com/hyperledger/indy-node/pull/410#discussion_r146207584,mzk-vct
https://github.com/hyperledger/indy-node/pull/410,https://github.com/hyperledger/indy-node/pull/410,Is there a test for successful editing?,61117b8ac354800ecf7b3831bb2c09eafafe0c50,2017-10-23 09:18:48,146208329,"@@ -25,6 +25,32 @@ def test_add_same_node_without_any_change(be, do, newStewardCli,
     exitFromCli(do)
 
 
+def test_add_same_node_without_any_change_by_trustee(be, do, trusteeCli,",13,2017-10-23 09:24:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146208329,https://github.com/hyperledger/indy-node/pull/410#discussion_r146208329,mzk-vct
https://github.com/hyperledger/indy-node/pull/410,https://github.com/hyperledger/indy-node/pull/410,Is there test for successful auth?,61117b8ac354800ecf7b3831bb2c09eafafe0c50,2017-10-23 09:19:08,146208405,"@@ -0,0 +1,23 @@
+from plenum.common.constants import NODE, TRUSTEE, BLS_KEY, STEWARD
+
+from indy_common.auth import Authoriser
+
+
+def test_node_not_allowed_role_error():",6,2017-10-23 09:24:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146208405,https://github.com/hyperledger/indy-node/pull/410#discussion_r146208405,mzk-vct
https://github.com/hyperledger/indy-node/pull/410,https://github.com/hyperledger/indy-node/pull/410,"Yes, recently added tests in `indy_common/test/auth` package (test_auth_node, test_auth_nym, etc.).",61117b8ac354800ecf7b3831bb2c09eafafe0c50,2017-10-23 09:21:04,146208859,"@@ -0,0 +1,23 @@
+from plenum.common.constants import NODE, TRUSTEE, BLS_KEY, STEWARD
+
+from indy_common.auth import Authoriser
+
+
+def test_node_not_allowed_role_error():",6,2017-10-23 09:24:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146208859,https://github.com/hyperledger/indy-node/pull/410#discussion_r146208859,ashcherbakov
https://github.com/hyperledger/indy-node/pull/410,https://github.com/hyperledger/indy-node/pull/410,"Yes, recently added tests in `indy_common/test/auth` package (test_auth_node, test_auth_nym, etc.).",61117b8ac354800ecf7b3831bb2c09eafafe0c50,2017-10-23 09:21:11,146208892,"@@ -25,6 +25,32 @@ def test_add_same_node_without_any_change(be, do, newStewardCli,
     exitFromCli(do)
 
 
+def test_add_same_node_without_any_change_by_trustee(be, do, trusteeCli,",13,2017-10-23 09:24:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146208892,https://github.com/hyperledger/indy-node/pull/410#discussion_r146208892,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,"Why did we rename it? We test POOL_UPGRADE here, don't we?",8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 08:53:43,146202126,"@@ -19,7 +19,7 @@ def validUpgrade(_validUpgrade):
     return _validUpgrade
 
 
-def testPoolUpgradeScheduledOnProperDate(poolNodesStarted,
+def testNodeUpgradeScheduledOnProperDate(poolNodesStarted,",,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146202126,https://github.com/hyperledger/indy-node/pull/408#discussion_r146202126,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,Please use snake case for test names,8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:12:49,146206943,"@@ -0,0 +1,27 @@
+from indy_node.test import waits
+from indy_node.test.upgrade.helper import sendUpgrade, bumpVersion
+from plenum.common.constants import VERSION
+from stp_core.loop.eventually import eventually
+
+
+def testForcedUpgradeNoConsensusOnSingleNode(",,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146206943,https://github.com/hyperledger/indy-node/pull/408#discussion_r146206943,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,"Didn't we bump the version, so it should be more than nup[VERSION]?",8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:19:33,146208514,"@@ -0,0 +1,27 @@
+from indy_node.test import waits
+from indy_node.test.upgrade.helper import sendUpgrade, bumpVersion
+from plenum.common.constants import VERSION
+from stp_core.loop.eventually import eventually
+
+
+def testForcedUpgradeNoConsensusOnSingleNode(
+        validUpgradeExpForceTrue, looper, nodeSet, trustee, trusteeWallet):
+    nup = validUpgradeExpForceTrue.copy()
+    nup.update({VERSION: bumpVersion(validUpgradeExpForceTrue[VERSION])})
+    for node in nodeSet:
+        if node.name != ""Alpha"":
+            node.cleanupOnStopping = False
+            looper.removeProdable(node)
+            node.stop()
+        else:
+            node.upgrader.scheduledUpgrade = None
+    sendUpgrade(trustee, trusteeWallet, nup)
+
+    def testsched():
+        for node in nodeSet:
+            if node.name == ""Alpha"":
+                assert node.upgrader.scheduledUpgrade
+                assert node.upgrader.scheduledUpgrade[0] == nup[VERSION]",24,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146208514,https://github.com/hyperledger/indy-node/pull/408#discussion_r146208514,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,"The module name is `test_pool_upgrade_schedule` since we test the pool upgrade schedule here.
For each node upgrade is scheduled on individual date/time. The test verifies that for each node the upgrade is scheduled on the proper date, so its name is `testNodeUpgradeScheduledOnProperDate`.",8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:24:46,146209793,"@@ -19,7 +19,7 @@ def validUpgrade(_validUpgrade):
     return _validUpgrade
 
 
-def testPoolUpgradeScheduledOnProperDate(poolNodesStarted,
+def testNodeUpgradeScheduledOnProperDate(poolNodesStarted,",,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146209793,https://github.com/hyperledger/indy-node/pull/408#discussion_r146209793,spivachuk
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,Please use snake case,8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:26:13,146210131,"@@ -0,0 +1,2 @@
+def testNodeSchedulesUpgradeExpForceFalse(upgradeScheduledExpForceFalse):",,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146210131,https://github.com/hyperledger/indy-node/pull/408#discussion_r146210131,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,Please use snake case for test name,8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:26:21,146210163,"@@ -0,0 +1,2 @@
+def testNodeSchedulesUpgradeExpForceTrue(upgradeScheduledExpForceTrue):",,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146210163,https://github.com/hyperledger/indy-node/pull/408#discussion_r146210163,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,Please use snake case for test name,8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:26:29,146210191,"@@ -0,0 +1,2 @@
+def testNodeSchedulesUpgrade(upgradeScheduled):",,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146210191,https://github.com/hyperledger/indy-node/pull/408#discussion_r146210191,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,Please use snake case for test name,8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:27:17,146210388,"@@ -0,0 +1,9 @@
+from indy_node.server.upgrade_log import UpgradeLog
+
+
+def testPoolUpgradeForceScheduledOnlyOnce(upgradeScheduledExpForceTrue,",,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146210388,https://github.com/hyperledger/indy-node/pull/408#discussion_r146210388,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,Please use snake case for test name,8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:29:50,146211020,"@@ -19,7 +19,7 @@ def validUpgrade(_validUpgrade):
     return _validUpgrade
 
 
-def testPoolUpgradeScheduledOnProperDate(poolNodesStarted,
+def testNodeUpgradeScheduledOnProperDate(poolNodesStarted,",,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146211020,https://github.com/hyperledger/indy-node/pull/408#discussion_r146211020,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,"This test was written earlier. In scope of this pull request it is only moved to a separate file.
As I can see, we verify that the target version of the scheduled upgrade is the same as we send in `sendUpgrade` call.",8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:30:00,146211065,"@@ -0,0 +1,27 @@
+from indy_node.test import waits
+from indy_node.test.upgrade.helper import sendUpgrade, bumpVersion
+from plenum.common.constants import VERSION
+from stp_core.loop.eventually import eventually
+
+
+def testForcedUpgradeNoConsensusOnSingleNode(
+        validUpgradeExpForceTrue, looper, nodeSet, trustee, trusteeWallet):
+    nup = validUpgradeExpForceTrue.copy()
+    nup.update({VERSION: bumpVersion(validUpgradeExpForceTrue[VERSION])})
+    for node in nodeSet:
+        if node.name != ""Alpha"":
+            node.cleanupOnStopping = False
+            looper.removeProdable(node)
+            node.stop()
+        else:
+            node.upgrader.scheduledUpgrade = None
+    sendUpgrade(trustee, trusteeWallet, nup)
+
+    def testsched():
+        for node in nodeSet:
+            if node.name == ""Alpha"":
+                assert node.upgrader.scheduledUpgrade
+                assert node.upgrader.scheduledUpgrade[0] == nup[VERSION]",24,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146211065,https://github.com/hyperledger/indy-node/pull/408#discussion_r146211065,spivachuk
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,Do we have a test that schedules update twice and checks that they work as expected (as in INDY-382)?,8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 09:32:41,146211749,"@@ -0,0 +1,9 @@
+from indy_node.server.upgrade_log import UpgradeLog
+
+
+def testPoolUpgradeForceScheduledOnlyOnce(upgradeScheduledExpForceTrue,",,2017-10-23 14:01:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146211749,https://github.com/hyperledger/indy-node/pull/408#discussion_r146211749,ashcherbakov
https://github.com/hyperledger/indy-node/pull/408,https://github.com/hyperledger/indy-node/pull/408,Added the tests `test_node_schedules_upgrade_for_proper_datetime` and `test_node_reschedules_upgrade_for_proper_datetime` for verifying actual schedule of pool upgrade for the cases when POOL_UPGRADE transaction is sent once and twice.,8df904dbd4ff590524d21ef10eb1db65da3de9b7,2017-10-23 14:57:38,146293898,"@@ -0,0 +1,9 @@
+from indy_node.server.upgrade_log import UpgradeLog
+
+
+def testPoolUpgradeForceScheduledOnlyOnce(upgradeScheduledExpForceTrue,",,2017-10-23 14:57:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146293898,https://github.com/hyperledger/indy-node/pull/408#discussion_r146293898,spivachuk
https://github.com/hyperledger/indy-node/pull/405,https://github.com/hyperledger/indy-node/pull/405,Please add description for this test,476e6c5a99df555f253ceefb869fafc246af6b16,2017-10-18 14:49:29,145438683,"@@ -7,59 +7,89 @@
 from indy_client.test.cli.helper import doSendNodeCmd
 
 
-def testAddNewNode(newNodeAdded):
+def test_add_new_node(newNodeAdded):
     pass
 
 
-def testConsecutiveAddSameNodeWithoutAnyChange(be, do, newStewardCli,
-                                               newNodeVals, newNodeAdded):
+def test_add_same_node_without_any_change(be, do, newStewardCli,
+                                          newNodeVals, newNodeAdded):
     be(newStewardCli)
     doSendNodeCmd(do, newNodeVals,
                   expMsgs=['node already has the same data as requested'])
     exitFromCli(do)
 
 
-def testConsecutiveAddSameNodeWithNodeAndClientPortSame(be, do, newStewardCli,
-                                                        newNodeVals,
-                                                        newNodeAdded):
+def test_update_node_and_client_port_same(be, do, newStewardCli,
+                                          newNodeVals,
+                                          newNodeAdded,
+                                          nodeValsEmptyData):
     be(newStewardCli)
     nodeIp, nodePort = genHa()
-    newNodeVals['newNodeData'][NODE_IP] = nodeIp
-    newNodeVals['newNodeData'][NODE_PORT] = nodePort
-    newNodeVals['newNodeData'][CLIENT_IP] = nodeIp
-    newNodeVals['newNodeData'][CLIENT_PORT] = nodePort
-    doSendNodeCmd(do, newNodeVals,
+
+    node_vals = nodeValsEmptyData
+    node_vals['newNodeData'][ALIAS] = newNodeVals['newNodeData'][ALIAS]
+    node_vals['newNodeData'][NODE_IP] = nodeIp
+    node_vals['newNodeData'][NODE_PORT] = nodePort
+    node_vals['newNodeData'][CLIENT_IP] = nodeIp
+    node_vals['newNodeData'][CLIENT_PORT] = nodePort
+
+    doSendNodeCmd(do, node_vals,
                   expMsgs=[""node and client ha cannot be same""])
     exitFromCli(do)
 
 
-def testConsecutiveAddSameNodeWithNonAliasChange(be, do, newStewardCli,
-                                                 newNodeVals, newNodeAdded):
+def test_update_ports_and_ips(be, do, newStewardCli,
+                              newNodeVals, newNodeAdded,
+                              nodeValsEmptyData):
     be(newStewardCli)
     nodeIp, nodePort = genHa()
     clientIp, clientPort = genHa()
-    newNodeVals['newNodeData'][NODE_IP] = nodeIp
-    newNodeVals['newNodeData'][NODE_PORT] = nodePort
-    newNodeVals['newNodeData'][CLIENT_IP] = nodeIp
-    newNodeVals['newNodeData'][CLIENT_PORT] = clientPort
-    doSendNodeCmd(do, newNodeVals)
+
+    node_vals = nodeValsEmptyData
+    node_vals['newNodeData'][ALIAS] = newNodeVals['newNodeData'][ALIAS]
+    node_vals['newNodeData'][NODE_IP] = nodeIp
+    node_vals['newNodeData'][NODE_PORT] = nodePort
+    node_vals['newNodeData'][CLIENT_IP] = clientIp
+    node_vals['newNodeData'][CLIENT_PORT] = clientPort
+
+    doSendNodeCmd(do, node_vals,
+                  expMsgs=['Node request completed'])
     exitFromCli(do)
 
 
-def testConsecutiveAddSameNodeWithOnlyBlsChange(be, do,
-                                                newStewardCli, newNodeVals,
-                                                newNodeAdded):
+def test_update_bls(be, do, newStewardCli,
+                    newNodeVals, newNodeAdded,
+                    nodeValsEmptyData):
     be(newStewardCli)
-    newNodeVals['newNodeData'][BLS_KEY] = randomString(32)
-    doSendNodeCmd(do, newNodeVals)
+
+    node_vals = nodeValsEmptyData
+    node_vals['newNodeData'][ALIAS] = newNodeVals['newNodeData'][ALIAS]
+    node_vals['newNodeData'][BLS_KEY] = randomString(32)
+
+    doSendNodeCmd(do, node_vals,
+                  expMsgs=['Node request completed'])
     exitFromCli(do)
 
 
-def testConsecutiveAddSameNodeWithOnlyAliasChange(be, do,
-                                                  newStewardCli, newNodeVals,
-                                                  newNodeAdded):
+def test_add_same_data_alias_changed(be, do,
+                                     newStewardCli, newNodeVals,
+                                     newNodeAdded):
     be(newStewardCli)
     newNodeVals['newNodeData'][ALIAS] = randomString(6)
     doSendNodeCmd(do, newNodeVals,
                   expMsgs=['existing data has conflicts with request data'])
     exitFromCli(do)
+
+
+def test_update_alias(be, do,",123,2017-10-18 15:08:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145438683,https://github.com/hyperledger/indy-node/pull/405#discussion_r145438683,mzk-vct
https://github.com/hyperledger/indy-node/pull/405,https://github.com/hyperledger/indy-node/pull/405,"This name is confusing.
As far as I understand this script creates bls keys and sends transaction to publish them, but it's name tells that it adds bls keys for steward (as if steward can have bls keys)
",476e6c5a99df555f253ceefb869fafc246af6b16,2017-10-18 14:52:49,145439711,"@@ -119,7 +119,8 @@ def run(self):
              'scripts/test_some_write_keys_others_read_them',
              'scripts/test_users_write_and_read_own_keys',
              'scripts/validator-info',
-             'scripts/init_bls_keys'],
+             'scripts/init_bls_keys',
+             'scripts/init_bls_for_stewards'],",,2017-10-18 15:08:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145439711,https://github.com/hyperledger/indy-node/pull/405#discussion_r145439711,mzk-vct
https://github.com/hyperledger/indy-node/pull/405,https://github.com/hyperledger/indy-node/pull/405,If node_seed is used only for generation of `dest` could you please add option to specify `dest` directly?,476e6c5a99df555f253ceefb869fafc246af6b16,2017-10-18 14:57:51,145441432,"@@ -0,0 +1,117 @@
+#! /usr/bin/env python3
+
+import argparse
+import logging
+
+from plenum.common.config_util import getConfig
+from plenum.common.constants import BLS_KEY, ALIAS
+from plenum.common.exceptions import OperationError, NoConsensusYet
+from plenum.common.keygen_utils import init_bls_keys
+from plenum.common.signer_did import DidSigner
+from plenum.common.util import hexToFriendly
+from stp_core.common.log import getlogger, Logger
+from stp_core.crypto.nacl_wrappers import Signer
+from stp_core.loop.eventually import eventually
+from stp_core.loop.looper import Looper
+from stp_core.network.port_dispenser import genHa
+from stp_core.types import HA
+
+from indy_client.client.client import Client
+from indy_client.client.wallet.node import Node
+from indy_client.client.wallet.wallet import Wallet
+from indy_common.util import get_reply_if_confirmed
+
+config = getConfig()
+config.enableStdOutLogging = False
+Logger.setLogLevel(logging.INFO)
+logger = getlogger()
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(
+        description=""Generate BLS keys for a node ""
+                    ""by taking the node's name and seeds ""
+                    ""and send NODE txn with the BLS key specified"")
+
+    parser.add_argument('--name', required=True, help='node name')
+    parser.add_argument('--node_seed', required=True, type=str,",,2017-10-18 15:08:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145441432,https://github.com/hyperledger/indy-node/pull/405#discussion_r145441432,mzk-vct
https://github.com/hyperledger/indy-node/pull/405,https://github.com/hyperledger/indy-node/pull/405,"The requirements for the task is that BLS key needs to be created for a seed (the same seed as used for node keys actually). So I think this option is not required (let's add it if this requirement appears)
",476e6c5a99df555f253ceefb869fafc246af6b16,2017-10-18 15:06:07,145444056,"@@ -0,0 +1,117 @@
+#! /usr/bin/env python3
+
+import argparse
+import logging
+
+from plenum.common.config_util import getConfig
+from plenum.common.constants import BLS_KEY, ALIAS
+from plenum.common.exceptions import OperationError, NoConsensusYet
+from plenum.common.keygen_utils import init_bls_keys
+from plenum.common.signer_did import DidSigner
+from plenum.common.util import hexToFriendly
+from stp_core.common.log import getlogger, Logger
+from stp_core.crypto.nacl_wrappers import Signer
+from stp_core.loop.eventually import eventually
+from stp_core.loop.looper import Looper
+from stp_core.network.port_dispenser import genHa
+from stp_core.types import HA
+
+from indy_client.client.client import Client
+from indy_client.client.wallet.node import Node
+from indy_client.client.wallet.wallet import Wallet
+from indy_common.util import get_reply_if_confirmed
+
+config = getConfig()
+config.enableStdOutLogging = False
+Logger.setLogLevel(logging.INFO)
+logger = getlogger()
+
+
+def parse_args():
+    parser = argparse.ArgumentParser(
+        description=""Generate BLS keys for a node ""
+                    ""by taking the node's name and seeds ""
+                    ""and send NODE txn with the BLS key specified"")
+
+    parser.add_argument('--name', required=True, help='node name')
+    parser.add_argument('--node_seed', required=True, type=str,",,2017-10-18 15:08:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145444056,https://github.com/hyperledger/indy-node/pull/405#discussion_r145444056,ashcherbakov
https://github.com/hyperledger/indy-node/pull/405,https://github.com/hyperledger/indy-node/pull/405,Renamed to `enable_bls`,476e6c5a99df555f253ceefb869fafc246af6b16,2017-10-18 15:08:40,145444978,"@@ -119,7 +119,8 @@ def run(self):
              'scripts/test_some_write_keys_others_read_them',
              'scripts/test_users_write_and_read_own_keys',
              'scripts/validator-info',
-             'scripts/init_bls_keys'],
+             'scripts/init_bls_keys',
+             'scripts/init_bls_for_stewards'],",,2017-10-18 15:08:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145444978,https://github.com/hyperledger/indy-node/pull/405#discussion_r145444978,ashcherbakov
https://github.com/hyperledger/indy-node/pull/405,https://github.com/hyperledger/indy-node/pull/405,Done,476e6c5a99df555f253ceefb869fafc246af6b16,2017-10-18 15:08:45,145444999,"@@ -7,59 +7,89 @@
 from indy_client.test.cli.helper import doSendNodeCmd
 
 
-def testAddNewNode(newNodeAdded):
+def test_add_new_node(newNodeAdded):
     pass
 
 
-def testConsecutiveAddSameNodeWithoutAnyChange(be, do, newStewardCli,
-                                               newNodeVals, newNodeAdded):
+def test_add_same_node_without_any_change(be, do, newStewardCli,
+                                          newNodeVals, newNodeAdded):
     be(newStewardCli)
     doSendNodeCmd(do, newNodeVals,
                   expMsgs=['node already has the same data as requested'])
     exitFromCli(do)
 
 
-def testConsecutiveAddSameNodeWithNodeAndClientPortSame(be, do, newStewardCli,
-                                                        newNodeVals,
-                                                        newNodeAdded):
+def test_update_node_and_client_port_same(be, do, newStewardCli,
+                                          newNodeVals,
+                                          newNodeAdded,
+                                          nodeValsEmptyData):
     be(newStewardCli)
     nodeIp, nodePort = genHa()
-    newNodeVals['newNodeData'][NODE_IP] = nodeIp
-    newNodeVals['newNodeData'][NODE_PORT] = nodePort
-    newNodeVals['newNodeData'][CLIENT_IP] = nodeIp
-    newNodeVals['newNodeData'][CLIENT_PORT] = nodePort
-    doSendNodeCmd(do, newNodeVals,
+
+    node_vals = nodeValsEmptyData
+    node_vals['newNodeData'][ALIAS] = newNodeVals['newNodeData'][ALIAS]
+    node_vals['newNodeData'][NODE_IP] = nodeIp
+    node_vals['newNodeData'][NODE_PORT] = nodePort
+    node_vals['newNodeData'][CLIENT_IP] = nodeIp
+    node_vals['newNodeData'][CLIENT_PORT] = nodePort
+
+    doSendNodeCmd(do, node_vals,
                   expMsgs=[""node and client ha cannot be same""])
     exitFromCli(do)
 
 
-def testConsecutiveAddSameNodeWithNonAliasChange(be, do, newStewardCli,
-                                                 newNodeVals, newNodeAdded):
+def test_update_ports_and_ips(be, do, newStewardCli,
+                              newNodeVals, newNodeAdded,
+                              nodeValsEmptyData):
     be(newStewardCli)
     nodeIp, nodePort = genHa()
     clientIp, clientPort = genHa()
-    newNodeVals['newNodeData'][NODE_IP] = nodeIp
-    newNodeVals['newNodeData'][NODE_PORT] = nodePort
-    newNodeVals['newNodeData'][CLIENT_IP] = nodeIp
-    newNodeVals['newNodeData'][CLIENT_PORT] = clientPort
-    doSendNodeCmd(do, newNodeVals)
+
+    node_vals = nodeValsEmptyData
+    node_vals['newNodeData'][ALIAS] = newNodeVals['newNodeData'][ALIAS]
+    node_vals['newNodeData'][NODE_IP] = nodeIp
+    node_vals['newNodeData'][NODE_PORT] = nodePort
+    node_vals['newNodeData'][CLIENT_IP] = clientIp
+    node_vals['newNodeData'][CLIENT_PORT] = clientPort
+
+    doSendNodeCmd(do, node_vals,
+                  expMsgs=['Node request completed'])
     exitFromCli(do)
 
 
-def testConsecutiveAddSameNodeWithOnlyBlsChange(be, do,
-                                                newStewardCli, newNodeVals,
-                                                newNodeAdded):
+def test_update_bls(be, do, newStewardCli,
+                    newNodeVals, newNodeAdded,
+                    nodeValsEmptyData):
     be(newStewardCli)
-    newNodeVals['newNodeData'][BLS_KEY] = randomString(32)
-    doSendNodeCmd(do, newNodeVals)
+
+    node_vals = nodeValsEmptyData
+    node_vals['newNodeData'][ALIAS] = newNodeVals['newNodeData'][ALIAS]
+    node_vals['newNodeData'][BLS_KEY] = randomString(32)
+
+    doSendNodeCmd(do, node_vals,
+                  expMsgs=['Node request completed'])
     exitFromCli(do)
 
 
-def testConsecutiveAddSameNodeWithOnlyAliasChange(be, do,
-                                                  newStewardCli, newNodeVals,
-                                                  newNodeAdded):
+def test_add_same_data_alias_changed(be, do,
+                                     newStewardCli, newNodeVals,
+                                     newNodeAdded):
     be(newStewardCli)
     newNodeVals['newNodeData'][ALIAS] = randomString(6)
     doSendNodeCmd(do, newNodeVals,
                   expMsgs=['existing data has conflicts with request data'])
     exitFromCli(do)
+
+
+def test_update_alias(be, do,",123,2017-10-18 15:08:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145444999,https://github.com/hyperledger/indy-node/pull/405#discussion_r145444999,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,"Custom `indy_config.py` files on live network have the following form:
```
poolTransactionsFile = 'pool_transactions_live'
domainTransactionsFile = 'domain_transactions_live'
```
So, if we see these lines in config file, we should also assume that network_name = 'live'",df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:01:19,145624867,"@@ -0,0 +1,167 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+from importlib.util import module_from_spec, spec_from_file_location
+
+from stp_core.common.log import getlogger
+
+baseDir = '/var/lib/indy'
+GENERAL_CONFIG_DIR = '/etc/indy'
+GENERAL_CONFIG_FILE = 'indy_config.py'
+LOG_DIR = '/var/log/indy'
+NODE_BASE_DATA_DIR = baseDir
+CLI_BASE_DIR = '/home/indy/.indy-cli'
+CLI_NETWORK_DIR = '/home/indy/.indy-cli/networks'
+
+logger = getlogger()
+
+old_base_dir = '/home/indy/.indy'
+
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    logger.info('Move genesis transactions {} -> {}'.format(
+        old_base_txn_dir, new_base_txn_dir))
+    for suffix in ('sandbox', 'live', 'local'):
+        new_txn_dir = os.path.join(new_base_txn_dir, suffix)
+        os.makedirs(new_txn_dir, exist_ok=True)
+
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+        new_domain_genesis = os.path.join(
+            new_txn_dir, 'domain_transactions_genesis')
+        new_pool_genesis = os.path.join(
+            new_txn_dir, 'pool_transactions_genesis')
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_domain_genesis)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_pool_genesis)
+
+    logger.info('done')
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir):
+    for prefix in ('private', 'public', 'sig', 'verif'):
+        old_keys_dir = os.path.join(old_base_keys_dir, '{}_keys'.format(prefix))
+        if os.path.exists(old_keys_dir) and os.path.isdir(old_keys_dir):
+            shutil.move(old_keys_dir, new_base_keys_dir)
+
+
+def get_network_name():
+    network_name = 'sandbox'
+    old_general_config = os.path.join(old_base_dir, 'indy_config.py')
+    spec = spec_from_file_location('old_general_config', old_general_config)
+    old_cfg = module_from_spec(spec)
+    spec.loader.exec_module(old_cfg)
+    if hasattr(old_cfg, 'current_env') and old_cfg.current_env != 'test':",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145624867,https://github.com/hyperledger/indy-node/pull/404#discussion_r145624867,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,"We should also replace 
```
poolTransactionsFile = 'pool_transactions_live'
domainTransactionsFile = 'domain_transactions_live'
```
to NETWORK_NAME. So, these lines should also be removed from config files.
",df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:03:08,145625186,"@@ -0,0 +1,167 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+from importlib.util import module_from_spec, spec_from_file_location
+
+from stp_core.common.log import getlogger
+
+baseDir = '/var/lib/indy'
+GENERAL_CONFIG_DIR = '/etc/indy'
+GENERAL_CONFIG_FILE = 'indy_config.py'
+LOG_DIR = '/var/log/indy'
+NODE_BASE_DATA_DIR = baseDir
+CLI_BASE_DIR = '/home/indy/.indy-cli'
+CLI_NETWORK_DIR = '/home/indy/.indy-cli/networks'
+
+logger = getlogger()
+
+old_base_dir = '/home/indy/.indy'
+
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    logger.info('Move genesis transactions {} -> {}'.format(
+        old_base_txn_dir, new_base_txn_dir))
+    for suffix in ('sandbox', 'live', 'local'):
+        new_txn_dir = os.path.join(new_base_txn_dir, suffix)
+        os.makedirs(new_txn_dir, exist_ok=True)
+
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+        new_domain_genesis = os.path.join(
+            new_txn_dir, 'domain_transactions_genesis')
+        new_pool_genesis = os.path.join(
+            new_txn_dir, 'pool_transactions_genesis')
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_domain_genesis)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_pool_genesis)
+
+    logger.info('done')
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir):
+    for prefix in ('private', 'public', 'sig', 'verif'):
+        old_keys_dir = os.path.join(old_base_keys_dir, '{}_keys'.format(prefix))
+        if os.path.exists(old_keys_dir) and os.path.isdir(old_keys_dir):
+            shutil.move(old_keys_dir, new_base_keys_dir)
+
+
+def get_network_name():
+    network_name = 'sandbox'
+    old_general_config = os.path.join(old_base_dir, 'indy_config.py')
+    spec = spec_from_file_location('old_general_config', old_general_config)
+    old_cfg = module_from_spec(spec)
+    spec.loader.exec_module(old_cfg)
+    if hasattr(old_cfg, 'current_env') and old_cfg.current_env != 'test':
+        network_name = old_cfg.current_env
+    return network_name
+
+
+def migrate_general_config(old_general_config, new_general_config, network_name):
+    logger.info('Migrate general config file {} -> {} for network {}'.format(
+        old_general_config, new_general_config, network_name))
+    f = open(old_general_config, ""r"")
+    lines = f.readlines()
+    f.close()
+
+    f = open(new_general_config, ""w"")
+    for line in lines:
+        if not line.startswith('current_env'):",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145625186,https://github.com/hyperledger/indy-node/pull/404#discussion_r145625186,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,Please migrate BLS keys as well ('bls_keys' prefix),df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:13:55,145627303,"@@ -0,0 +1,167 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+from importlib.util import module_from_spec, spec_from_file_location
+
+from stp_core.common.log import getlogger
+
+baseDir = '/var/lib/indy'
+GENERAL_CONFIG_DIR = '/etc/indy'
+GENERAL_CONFIG_FILE = 'indy_config.py'
+LOG_DIR = '/var/log/indy'
+NODE_BASE_DATA_DIR = baseDir
+CLI_BASE_DIR = '/home/indy/.indy-cli'
+CLI_NETWORK_DIR = '/home/indy/.indy-cli/networks'
+
+logger = getlogger()
+
+old_base_dir = '/home/indy/.indy'
+
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    logger.info('Move genesis transactions {} -> {}'.format(
+        old_base_txn_dir, new_base_txn_dir))
+    for suffix in ('sandbox', 'live', 'local'):
+        new_txn_dir = os.path.join(new_base_txn_dir, suffix)
+        os.makedirs(new_txn_dir, exist_ok=True)
+
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+        new_domain_genesis = os.path.join(
+            new_txn_dir, 'domain_transactions_genesis')
+        new_pool_genesis = os.path.join(
+            new_txn_dir, 'pool_transactions_genesis')
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_domain_genesis)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_pool_genesis)
+
+    logger.info('done')
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir):
+    for prefix in ('private', 'public', 'sig', 'verif'):",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145627303,https://github.com/hyperledger/indy-node/pull/404#discussion_r145627303,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,"`dir` is a built-in function, so it's better to choose another name for the variable",df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:23:33,145629387,"@@ -1912,8 +1917,13 @@ def getActiveEnv(self):
                                                 self.currPromptText)
         return env
 
+    def get_available_networks(self):
+        return [dir for dir in os.listdir(self.ledger_base_dir)",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145629387,https://github.com/hyperledger/indy-node/pull/404#discussion_r145629387,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,"file is a built-in function, it's better to use another name for the variable",df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:36:52,145632411,"@@ -198,31 +201,31 @@ def _backup_name_ext(self, version):
     def _create_backup(self, version):
         logger.debug('Creating backup for {}'.format(version))
         shutil.make_archive(self._backup_name(version),
-                            self.backup_format, self.indy_dir)
+                            self.backup_format, self.backup_target)
 
     def _restore_from_backup(self, version):
         logger.debug('Restoring from backup for {}'.format(version))
         for file_path in self.files_to_preserve:
             try:
-                shutil.copy2(os.path.join(self.indy_dir, file_path),
+                shutil.copy2(os.path.join(self.backup_target, file_path),
                              os.path.join(self.tmp_dir, file_path))
             except IOError as e:
                 logger.warning(
                     'Copying {} failed due to {}'.format(file_path, e))
         shutil.unpack_archive(self._backup_name_ext(
-            version), self.indy_dir, self.backup_format)
+            version), self.backup_target, self.backup_format)
         for file_path in self.files_to_preserve:
             try:
                 shutil.copy2(os.path.join(self.tmp_dir, file_path),
-                             os.path.join(self.indy_dir, file_path))
+                             os.path.join(self.backup_target, file_path))
             except IOError as e:
                 logger.warning(
                     'Copying {} failed due to {}'.format(file_path, e))
         shutil.rmtree(self.tmp_dir, ignore_errors=True)
 
     def _get_backups(self):
-        files = [os.path.join(self.base_dir, file)
-                 for file in os.listdir(self.base_dir)]
+        files = [os.path.join(self.backup_dir, file)
+                 for file in os.listdir(self.backup_dir)]",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145632411,https://github.com/hyperledger/indy-node/pull/404#discussion_r145632411,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,Please make similar changes in `init_bls_keys` and `enable_bls`,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:40:24,145633195,"@@ -10,7 +10,7 @@ from plenum.common.util import randomString
 from indy_common.config_util import getConfig
 
 config = getConfig()
-keepDir = config.baseDir
+keepDir = os.path.join(config.baseDir, config.NETWORK_NAME)",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145633195,https://github.com/hyperledger/indy-node/pull/404#discussion_r145633195,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,Why do we need to create any dirs in setup.py?,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:41:27,145633478,"@@ -36,10 +36,10 @@
 exec(compile(open(METADATA).read(), METADATA, 'exec'))
 
 BASE_DIR = os.path.join(os.path.expanduser(""~""), "".indy"")
-SAMPLE_DIR = os.path.join(BASE_DIR, "".indy"")
+LOG_DIR = os.path.join(BASE_DIR, ""log"")
 CONFIG_FILE = os.path.join(BASE_DIR, ""indy_config.py"")
 
-for path in [BASE_DIR, SAMPLE_DIR]:
+for path in [BASE_DIR, LOG_DIR]:
     if not os.path.exists(path):
         os.makedirs(path)",11,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145633478,https://github.com/hyperledger/indy-node/pull/404#discussion_r145633478,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,Why did we remove `connectedToTest`?,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:42:42,145633773,"@@ -1349,19 +1301,19 @@ def philCli(be, do, philCLI, trusteeCli, poolTxnData):
 
 
 @pytest.fixture(scope=""module"")
-def faberAddedByPhil(be, do, poolNodesStarted, philCli, connectedToTest,",158,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145633773,https://github.com/hyperledger/indy-node/pull/404#discussion_r145633773,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,"Sub-directory can be None, isn't it?",df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:47:12,145634903,"@@ -255,6 +254,7 @@ def newCLI(looper, tdir, subDirectory=None, conf=None, poolDir=None,
         agentCreator=True)
     if isinstance(new_cli, IndyCli) and agent is not None:
         new_cli.agent = agent
+    new_cli.txn_dir = subDirectory",51,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145634903,https://github.com/hyperledger/indy-node/pull/404#discussion_r145634903,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,"As I can see, Network is taken from `cli.txn_dir` which is set by `sub-directory` parameter in constructor, and it can be None. How do we make sure that we connect to test?",df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-19 08:48:47,145635223,"@@ -83,8 +83,14 @@ def ensureConnectedToTestEnv(be, do, cli):
     be(cli)
     if not cli._isConnectedToAnyEnv():
         timeout = waits.expectedClientToPoolConnectionTimeout(len(cli.nodeReg))
-        do('connect test', within=timeout,
-           expect=['Connected to test'])
+        connect_and_check_output(do, cli.txn_dir, timeout)
+
+
+def connect_and_check_output(do, netwotk, timeout=3, expect=None, mapper=None):
+    if expect is None:",10,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145635223,https://github.com/hyperledger/indy-node/pull/404#discussion_r145635223,ashcherbakov
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,done,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-20 05:45:33,145882233,"@@ -0,0 +1,167 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+from importlib.util import module_from_spec, spec_from_file_location
+
+from stp_core.common.log import getlogger
+
+baseDir = '/var/lib/indy'
+GENERAL_CONFIG_DIR = '/etc/indy'
+GENERAL_CONFIG_FILE = 'indy_config.py'
+LOG_DIR = '/var/log/indy'
+NODE_BASE_DATA_DIR = baseDir
+CLI_BASE_DIR = '/home/indy/.indy-cli'
+CLI_NETWORK_DIR = '/home/indy/.indy-cli/networks'
+
+logger = getlogger()
+
+old_base_dir = '/home/indy/.indy'
+
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    logger.info('Move genesis transactions {} -> {}'.format(
+        old_base_txn_dir, new_base_txn_dir))
+    for suffix in ('sandbox', 'live', 'local'):
+        new_txn_dir = os.path.join(new_base_txn_dir, suffix)
+        os.makedirs(new_txn_dir, exist_ok=True)
+
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+        new_domain_genesis = os.path.join(
+            new_txn_dir, 'domain_transactions_genesis')
+        new_pool_genesis = os.path.join(
+            new_txn_dir, 'pool_transactions_genesis')
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_domain_genesis)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_pool_genesis)
+
+    logger.info('done')
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir):
+    for prefix in ('private', 'public', 'sig', 'verif'):",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145882233,https://github.com/hyperledger/indy-node/pull/404#discussion_r145882233,dsurnin
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,done,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-20 06:55:45,145889992,"@@ -1912,8 +1917,13 @@ def getActiveEnv(self):
                                                 self.currPromptText)
         return env
 
+    def get_available_networks(self):
+        return [dir for dir in os.listdir(self.ledger_base_dir)",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145889992,https://github.com/hyperledger/indy-node/pull/404#discussion_r145889992,dsurnin
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,done,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-20 07:08:12,145891462,"@@ -198,31 +201,31 @@ def _backup_name_ext(self, version):
     def _create_backup(self, version):
         logger.debug('Creating backup for {}'.format(version))
         shutil.make_archive(self._backup_name(version),
-                            self.backup_format, self.indy_dir)
+                            self.backup_format, self.backup_target)
 
     def _restore_from_backup(self, version):
         logger.debug('Restoring from backup for {}'.format(version))
         for file_path in self.files_to_preserve:
             try:
-                shutil.copy2(os.path.join(self.indy_dir, file_path),
+                shutil.copy2(os.path.join(self.backup_target, file_path),
                              os.path.join(self.tmp_dir, file_path))
             except IOError as e:
                 logger.warning(
                     'Copying {} failed due to {}'.format(file_path, e))
         shutil.unpack_archive(self._backup_name_ext(
-            version), self.indy_dir, self.backup_format)
+            version), self.backup_target, self.backup_format)
         for file_path in self.files_to_preserve:
             try:
                 shutil.copy2(os.path.join(self.tmp_dir, file_path),
-                             os.path.join(self.indy_dir, file_path))
+                             os.path.join(self.backup_target, file_path))
             except IOError as e:
                 logger.warning(
                     'Copying {} failed due to {}'.format(file_path, e))
         shutil.rmtree(self.tmp_dir, ignore_errors=True)
 
     def _get_backups(self):
-        files = [os.path.join(self.base_dir, file)
-                 for file in os.listdir(self.base_dir)]
+        files = [os.path.join(self.backup_dir, file)
+                 for file in os.listdir(self.backup_dir)]",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145891462,https://github.com/hyperledger/indy-node/pull/404#discussion_r145891462,dsurnin
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,done,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-20 07:09:01,145891546,"@@ -10,7 +10,7 @@ from plenum.common.util import randomString
 from indy_common.config_util import getConfig
 
 config = getConfig()
-keepDir = config.baseDir
+keepDir = os.path.join(config.baseDir, config.NETWORK_NAME)",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145891546,https://github.com/hyperledger/indy-node/pull/404#discussion_r145891546,dsurnin
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,"we do not use pool network named ""test"" anymore",df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-20 07:34:29,145895016,"@@ -1349,19 +1301,19 @@ def philCli(be, do, philCLI, trusteeCli, poolTxnData):
 
 
 @pytest.fixture(scope=""module"")
-def faberAddedByPhil(be, do, poolNodesStarted, philCli, connectedToTest,",158,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145895016,https://github.com/hyperledger/indy-node/pull/404#discussion_r145895016,dsurnin
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,it looks like it is,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-20 09:31:38,145917950,"@@ -255,6 +254,7 @@ def newCLI(looper, tdir, subDirectory=None, conf=None, poolDir=None,
         agentCreator=True)
     if isinstance(new_cli, IndyCli) and agent is not None:
         new_cli.agent = agent
+    new_cli.txn_dir = subDirectory",51,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145917950,https://github.com/hyperledger/indy-node/pull/404#discussion_r145917950,dsurnin
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,"connect_and_check_output is used only with named clis, so this is ok for now",df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-20 09:32:41,145918112,"@@ -83,8 +83,14 @@ def ensureConnectedToTestEnv(be, do, cli):
     be(cli)
     if not cli._isConnectedToAnyEnv():
         timeout = waits.expectedClientToPoolConnectionTimeout(len(cli.nodeReg))
-        do('connect test', within=timeout,
-           expect=['Connected to test'])
+        connect_and_check_output(do, cli.txn_dir, timeout)
+
+
+def connect_and_check_output(do, netwotk, timeout=3, expect=None, mapper=None):
+    if expect is None:",10,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145918112,https://github.com/hyperledger/indy-node/pull/404#discussion_r145918112,dsurnin
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,done,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-20 11:12:17,145936717,"@@ -0,0 +1,167 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+from importlib.util import module_from_spec, spec_from_file_location
+
+from stp_core.common.log import getlogger
+
+baseDir = '/var/lib/indy'
+GENERAL_CONFIG_DIR = '/etc/indy'
+GENERAL_CONFIG_FILE = 'indy_config.py'
+LOG_DIR = '/var/log/indy'
+NODE_BASE_DATA_DIR = baseDir
+CLI_BASE_DIR = '/home/indy/.indy-cli'
+CLI_NETWORK_DIR = '/home/indy/.indy-cli/networks'
+
+logger = getlogger()
+
+old_base_dir = '/home/indy/.indy'
+
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    logger.info('Move genesis transactions {} -> {}'.format(
+        old_base_txn_dir, new_base_txn_dir))
+    for suffix in ('sandbox', 'live', 'local'):
+        new_txn_dir = os.path.join(new_base_txn_dir, suffix)
+        os.makedirs(new_txn_dir, exist_ok=True)
+
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+        new_domain_genesis = os.path.join(
+            new_txn_dir, 'domain_transactions_genesis')
+        new_pool_genesis = os.path.join(
+            new_txn_dir, 'pool_transactions_genesis')
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_domain_genesis)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_pool_genesis)
+
+    logger.info('done')
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir):
+    for prefix in ('private', 'public', 'sig', 'verif'):
+        old_keys_dir = os.path.join(old_base_keys_dir, '{}_keys'.format(prefix))
+        if os.path.exists(old_keys_dir) and os.path.isdir(old_keys_dir):
+            shutil.move(old_keys_dir, new_base_keys_dir)
+
+
+def get_network_name():
+    network_name = 'sandbox'
+    old_general_config = os.path.join(old_base_dir, 'indy_config.py')
+    spec = spec_from_file_location('old_general_config', old_general_config)
+    old_cfg = module_from_spec(spec)
+    spec.loader.exec_module(old_cfg)
+    if hasattr(old_cfg, 'current_env') and old_cfg.current_env != 'test':",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145936717,https://github.com/hyperledger/indy-node/pull/404#discussion_r145936717,dsurnin
https://github.com/hyperledger/indy-node/pull/404,https://github.com/hyperledger/indy-node/pull/404,done,df3945ad1900cc5e2cec3203c64c6d83c47d1878,2017-10-23 05:34:01,146169083,"@@ -0,0 +1,167 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+from importlib.util import module_from_spec, spec_from_file_location
+
+from stp_core.common.log import getlogger
+
+baseDir = '/var/lib/indy'
+GENERAL_CONFIG_DIR = '/etc/indy'
+GENERAL_CONFIG_FILE = 'indy_config.py'
+LOG_DIR = '/var/log/indy'
+NODE_BASE_DATA_DIR = baseDir
+CLI_BASE_DIR = '/home/indy/.indy-cli'
+CLI_NETWORK_DIR = '/home/indy/.indy-cli/networks'
+
+logger = getlogger()
+
+old_base_dir = '/home/indy/.indy'
+
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    logger.info('Move genesis transactions {} -> {}'.format(
+        old_base_txn_dir, new_base_txn_dir))
+    for suffix in ('sandbox', 'live', 'local'):
+        new_txn_dir = os.path.join(new_base_txn_dir, suffix)
+        os.makedirs(new_txn_dir, exist_ok=True)
+
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+        new_domain_genesis = os.path.join(
+            new_txn_dir, 'domain_transactions_genesis')
+        new_pool_genesis = os.path.join(
+            new_txn_dir, 'pool_transactions_genesis')
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_domain_genesis)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_pool_genesis)
+
+    logger.info('done')
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir):
+    for prefix in ('private', 'public', 'sig', 'verif'):
+        old_keys_dir = os.path.join(old_base_keys_dir, '{}_keys'.format(prefix))
+        if os.path.exists(old_keys_dir) and os.path.isdir(old_keys_dir):
+            shutil.move(old_keys_dir, new_base_keys_dir)
+
+
+def get_network_name():
+    network_name = 'sandbox'
+    old_general_config = os.path.join(old_base_dir, 'indy_config.py')
+    spec = spec_from_file_location('old_general_config', old_general_config)
+    old_cfg = module_from_spec(spec)
+    spec.loader.exec_module(old_cfg)
+    if hasattr(old_cfg, 'current_env') and old_cfg.current_env != 'test':
+        network_name = old_cfg.current_env
+    return network_name
+
+
+def migrate_general_config(old_general_config, new_general_config, network_name):
+    logger.info('Migrate general config file {} -> {} for network {}'.format(
+        old_general_config, new_general_config, network_name))
+    f = open(old_general_config, ""r"")
+    lines = f.readlines()
+    f.close()
+
+    f = open(new_general_config, ""w"")
+    for line in lines:
+        if not line.startswith('current_env'):",,2017-10-23 13:38:36,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/146169083,https://github.com/hyperledger/indy-node/pull/404#discussion_r146169083,dsurnin
https://github.com/hyperledger/indy-node/pull/394,https://github.com/hyperledger/indy-node/pull/394,We can use `get_utc_epoch()` utility method for the same purpose ,c70b0e600954d67a6787b19c17eebb60f5765d70,2017-10-16 09:52:28,144801703,"@@ -133,7 +133,9 @@ def check_node_set_acknowledges_upgrade(
         node_ids=node_ids)
 
     for node in node_set:
-        node.upgrader.scheduledUpgrade = (version, 0, randomString(10))
+        node.upgrader.scheduledUpgrade = (version,
+                                          datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc()),",6,2017-10-16 09:52:28,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/144801703,https://github.com/hyperledger/indy-node/pull/394#discussion_r144801703,ashcherbakov
https://github.com/hyperledger/indy-node/pull/394,https://github.com/hyperledger/indy-node/pull/394,`get_utc_epoch()` returns UTC timestamp (in seconds as `int` value) rather than `datetime`.,c70b0e600954d67a6787b19c17eebb60f5765d70,2017-10-19 12:10:50,145680361,"@@ -133,7 +133,9 @@ def check_node_set_acknowledges_upgrade(
         node_ids=node_ids)
 
     for node in node_set:
-        node.upgrader.scheduledUpgrade = (version, 0, randomString(10))
+        node.upgrader.scheduledUpgrade = (version,
+                                          datetime.utcnow().replace(tzinfo=dateutil.tz.tzutc()),",6,2017-10-19 12:10:50,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/145680361,https://github.com/hyperledger/indy-node/pull/394#discussion_r145680361,spivachuk
https://github.com/hyperledger/indy-node/pull/390,https://github.com/hyperledger/indy-node/pull/390,Please use snake case,2cd959bc93e8471f7f6e19a8a4fb397c8f6d09bc,2017-10-10 07:47:18,143650896,"@@ -0,0 +1,26 @@
+import dateutil
+import pytest
+from datetime import timedelta
+
+from indy_client.test.cli.test_pool_upgrade import poolUpgradeSubmitted
+from indy_client.test.cli.test_pool_upgrade import poolUpgradeScheduled
+from indy_node.test.upgrade.conftest import validUpgrade as _validUpgrade
+
+
+@pytest.fixture(scope='module')
+def validUpgrade(_validUpgrade):",11,2017-10-10 07:47:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143650896,https://github.com/hyperledger/indy-node/pull/390#discussion_r143650896,ashcherbakov
https://github.com/hyperledger/indy-node/pull/390,https://github.com/hyperledger/indy-node/pull/390,Please use snake case,2cd959bc93e8471f7f6e19a8a4fb397c8f6d09bc,2017-10-10 07:47:24,143650904,"@@ -0,0 +1,26 @@
+import dateutil
+import pytest
+from datetime import timedelta
+
+from indy_client.test.cli.test_pool_upgrade import poolUpgradeSubmitted
+from indy_client.test.cli.test_pool_upgrade import poolUpgradeScheduled
+from indy_node.test.upgrade.conftest import validUpgrade as _validUpgrade
+
+
+@pytest.fixture(scope='module')
+def validUpgrade(_validUpgrade):
+    # Add 5 days to the time of the upgrade of each node in schedule parameter
+    # of send POOL_UPGRADE command
+    upgradeSchedule = _validUpgrade['schedule']
+    for nodeId in upgradeSchedule:
+        nodeUpgradeDateTime = dateutil.parser.parse(upgradeSchedule[nodeId])
+        nodeUpgradeDateTime += timedelta(days=5)
+        upgradeSchedule[nodeId] = nodeUpgradeDateTime.isoformat()
+    return _validUpgrade
+
+
+def testPoolUpgradeScheduledOnProperDate(poolNodesStarted,",22,2017-10-10 07:47:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143650904,https://github.com/hyperledger/indy-node/pull/390#discussion_r143650904,ashcherbakov
https://github.com/hyperledger/indy-node/pull/390,https://github.com/hyperledger/indy-node/pull/390,I think this test needs to be in indy_node.test.upgrade ,2cd959bc93e8471f7f6e19a8a4fb397c8f6d09bc,2017-10-10 07:47:59,143651019,"@@ -0,0 +1,26 @@
+import dateutil",1,2017-10-10 07:47:59,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143651019,https://github.com/hyperledger/indy-node/pull/390#discussion_r143651019,ashcherbakov
https://github.com/hyperledger/indy-node/pull/390,https://github.com/hyperledger/indy-node/pull/390,This test operates on CLI level (depends on `poolUpgradeSubmitted` fixture). So it should be located in `indy_client.test.cli` package.,2cd959bc93e8471f7f6e19a8a4fb397c8f6d09bc,2017-10-10 08:26:33,143659386,"@@ -0,0 +1,26 @@
+import dateutil",1,2017-10-10 08:27:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143659386,https://github.com/hyperledger/indy-node/pull/390#discussion_r143659386,spivachuk
https://github.com/hyperledger/indy-node/pull/381,https://github.com/hyperledger/indy-node/pull/381,"Please, use multiline with curly braces for more readability.
As an option bash-like ""${BRANCH_NAME}"" in conditional could be replaced with env.BRANCH_NAME.",e7ec60091601d0e3470658ce7afab9612819281a,2017-10-10 12:19:10,143709252,"@@ -74,10 +74,13 @@ def commonTestUbuntu = {
 
 def buildDebUbuntu = { repoName, releaseVersion, sourcePath ->
     def volumeName = ""$name-deb-u1604""
-    sh ""docker volume rm -f $volumeName""
+    if (""${BRANCH_NAME}"" != '' && ""${BRANCH_NAME}"" != 'master') volumeName = ""${volumeName}.${BRANCH_NAME}""",,2017-10-11 15:11:01,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143709252,https://github.com/hyperledger/indy-node/pull/381#discussion_r143709252,andkononykhin
https://github.com/hyperledger/indy-node/pull/381,https://github.com/hyperledger/indy-node/pull/381,"Please, use multiline with curly braces for more readability.
As an option bash-like ""${BRANCH_NAME}"" in conditional could be replaced with env.BRANCH_NAME.",e7ec60091601d0e3470658ce7afab9612819281a,2017-10-10 12:19:37,143709356,"@@ -74,10 +74,13 @@ def commonTestUbuntu = {
 
 def buildDebUbuntu = { repoName, releaseVersion, sourcePath ->
     def volumeName = ""$name-deb-u1604""
-    sh ""docker volume rm -f $volumeName""
+    if (""${BRANCH_NAME}"" != '' && ""${BRANCH_NAME}"" != 'master') volumeName = ""${volumeName}.${BRANCH_NAME}""",,2017-10-11 15:11:01,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143709356,https://github.com/hyperledger/indy-node/pull/381#discussion_r143709356,andkononykhin
https://github.com/hyperledger/indy-node/pull/381,https://github.com/hyperledger/indy-node/pull/381,I think the previous OUTPUT_VOLUME_NAME value should be set as a default,e7ec60091601d0e3470658ce7afab9612819281a,2017-10-10 12:34:04,143712684,"@@ -3,22 +3,22 @@
 set -x
 set -e
 
-if [ -z $1 ]; then
+if [ -z ""$2"" ]; then
     CMD=""/root/build-3rd-parties.sh /output""
 else
-    CMD=$1
+    CMD=""$2""
 fi
 
 PKG_NAME=indy-node
-IMAGE_NAME=${PKG_NAME}-build-u1604
-OUTPUT_VOLUME_NAME=${PKG_NAME}-deb-u1604
+IMAGE_NAME=""${PKG_NAME}-build-u1604""
+OUTPUT_VOLUME_NAME=""$1""",,2017-10-11 15:11:01,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143712684,https://github.com/hyperledger/indy-node/pull/381#discussion_r143712684,andkononykhin
https://github.com/hyperledger/indy-node/pull/381,https://github.com/hyperledger/indy-node/pull/381,I think the previous OUTPUT_VOLUME_NAME value should be set as a default.,e7ec60091601d0e3470658ce7afab9612819281a,2017-10-10 12:35:12,143712976,"@@ -1,31 +1,31 @@
 #!/bin/bash -xe
 
-PKG_SOURCE_PATH=$1
-VERSION=$2
+PKG_SOURCE_PATH=""$1""
+VERSION=""$2""
 PKG_NAME=indy-node
-IMAGE_NAME=${PKG_NAME}-build-u1604
-OUTPUT_VOLUME_NAME=${PKG_NAME}-deb-u1604
+IMAGE_NAME=""${PKG_NAME}-build-u1604""
+OUTPUT_VOLUME_NAME=""$3""",,2017-10-11 15:11:01,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143712976,https://github.com/hyperledger/indy-node/pull/381#discussion_r143712976,andkononykhin
https://github.com/hyperledger/indy-node/pull/379,https://github.com/hyperledger/indy-node/pull/379,"As of now it is okay, but more strict approach should be considered in a future or we risk to get complex code with lots of if-elses here and there one day.",57819d0c5c1a642bc3687513b57eb8dd412bb9b3,2017-10-06 10:06:58,143154351,"@@ -421,8 +422,11 @@ def make_result(request, data, last_seq_no, update_time, proof):
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
             f.SEQ_NO.nm: last_seq_no,
-            TXN_TIME: update_time,
-            STATE_PROOF: proof
+            TXN_TIME: update_time
         }}
+        if request.protocolVersion and \",16,2017-10-06 10:35:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143154351,https://github.com/hyperledger/indy-node/pull/379#discussion_r143154351,mzk-vct
https://github.com/hyperledger/indy-node/pull/379,https://github.com/hyperledger/indy-node/pull/379,"I agree. The problem is that each protocol version will affect different parts of code (this versions deals with state proofs; the next version may deal with serialization for example).
It would be great to have one place with all the rules (I have feeling that it could not be done easily), or to have, for example, some annotations marking the minimal version the code (method, class) can be run for.",57819d0c5c1a642bc3687513b57eb8dd412bb9b3,2017-10-06 10:38:17,143159970,"@@ -421,8 +422,11 @@ def make_result(request, data, last_seq_no, update_time, proof):
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
             f.SEQ_NO.nm: last_seq_no,
-            TXN_TIME: update_time,
-            STATE_PROOF: proof
+            TXN_TIME: update_time
         }}
+        if request.protocolVersion and \",16,2017-10-06 10:38:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/143159970,https://github.com/hyperledger/indy-node/pull/379#discussion_r143159970,ashcherbakov
https://github.com/hyperledger/indy-node/pull/369,https://github.com/hyperledger/indy-node/pull/369,Should we copy it to USER_CONFIG_DIR=/etc/indy?,1cb701bea7a626c7fe44e1f9132c0011275eaf58,2017-10-04 08:28:46,142608882,"@@ -48,4 +50,14 @@ echo ""Adding manifest\n=======\n$manifest\n=======\n into $manifest_file""
 rm -rf $manifest_file
 echo -e $manifest >$manifest_file
 
+echo ""Preparing config files""
+# Define user config directory
+sed -i ""s/^\(USER_CONFIG_DIR\s*=\s*\).*\$/\1\""$USER_CONFIG_DIR\""/"" ""$repo/sovrin_common/config.py""
+# Create user config
+cp $repo/sovrin_node/user_config/user_config.py $repo/sovrin_node/user_config/indy_config.py",17,2017-10-04 08:28:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/142608882,https://github.com/hyperledger/indy-node/pull/369#discussion_r142608882,ashcherbakov
https://github.com/hyperledger/indy-node/pull/369,https://github.com/hyperledger/indy-node/pull/369,"No, it is the script that prepares sources for packaging, this 'cp' is the first instruction for merging of user config and platform config into single config file indy_config.py: user config is the base (cp), platform config is appended to base (cat >>).
And then installation script puts indy_config.py to USER_CONFIG_DIR=/etc/indy .",1cb701bea7a626c7fe44e1f9132c0011275eaf58,2017-10-04 10:32:59,142635448,"@@ -48,4 +50,14 @@ echo ""Adding manifest\n=======\n$manifest\n=======\n into $manifest_file""
 rm -rf $manifest_file
 echo -e $manifest >$manifest_file
 
+echo ""Preparing config files""
+# Define user config directory
+sed -i ""s/^\(USER_CONFIG_DIR\s*=\s*\).*\$/\1\""$USER_CONFIG_DIR\""/"" ""$repo/sovrin_common/config.py""
+# Create user config
+cp $repo/sovrin_node/user_config/user_config.py $repo/sovrin_node/user_config/indy_config.py",17,2017-10-04 10:34:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/142635448,https://github.com/hyperledger/indy-node/pull/369#discussion_r142635448,sergey-shilov
https://github.com/hyperledger/indy-node/pull/359,https://github.com/hyperledger/indy-node/pull/359,why rename?,35667236bf8f4b603fba3687be4b838820b1782d,2017-09-26 14:36:32,141076233,"@@ -0,0 +1,79 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+
+from stp_core.common.log import getlogger
+from sovrin_common.config_util import getConfig
+
+config = getConfig()
+logger = getlogger()
+
+old_base_dir = '~/.indy'
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    for suffix in ('sandbox', 'live', 'local'):
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_base_txn_dir)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_base_txn_dir)
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir)
+    for prefix in ('private', 'public', 'sig', 'verif'):
+        old_keys_dir = os.path.join(old_base_keys_dir, '{}_keys'.format(prefix))
+        if os.path.exists(old_keys_dir) and os.path.isdir(old_keys_dir):
+            shutil.move(old_keys_dir, new_base_keys_dir)
+
+
+def migrate_all():
+    base_dir = config.baseDir
+
+    old_node_base_data_dir = os.path.join(old_base_dir, 'data')
+    old_nodes_data_dir = os.path.join(old_node_base_data_dir, 'nodes')
+    old_wallets_dir = os.path.join(old_base_dir, 'wallets')
+    old_general_config = os.path.join(old_base_dir, 'indy_config.py')
+    old_daemon_config_base_dir = '/home/indy/.indy'
+    old_daemon_config = os.path.join(old_daemon_config_base_dir, 'indy.env')
+
+    new_log_dir = os.path.join(config.LOG_DIR, config.NETWORK_NAME)
+    new_node_base_dir = os.path.join(base_dir , config.NETWORK_NAME)
+    new_node_base_data_dir = os.path.join(config.NODE_BASE_DATA_DIR, config.NETWORK_NAME)
+
+    new_general_config = os.path.join(config.GENERAL_CONFIG_DIR, config.GENERAL_CONFIG_FILE)
+
+    # Move general config file
+    os.rename(old_general_config, new_general_config)",,2017-09-27 15:21:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/141076233,https://github.com/hyperledger/indy-node/pull/359#discussion_r141076233,keenondrums
https://github.com/hyperledger/indy-node/pull/359,https://github.com/hyperledger/indy-node/pull/359,if we do not find the directory I think we should raise an exception and therefore roll back ,35667236bf8f4b603fba3687be4b838820b1782d,2017-09-26 14:38:21,141076787,"@@ -0,0 +1,79 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+
+from stp_core.common.log import getlogger
+from sovrin_common.config_util import getConfig
+
+config = getConfig()
+logger = getlogger()
+
+old_base_dir = '~/.indy'
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    for suffix in ('sandbox', 'live', 'local'):
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_base_txn_dir)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_base_txn_dir)
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir)
+    for prefix in ('private', 'public', 'sig', 'verif'):
+        old_keys_dir = os.path.join(old_base_keys_dir, '{}_keys'.format(prefix))
+        if os.path.exists(old_keys_dir) and os.path.isdir(old_keys_dir):
+            shutil.move(old_keys_dir, new_base_keys_dir)
+
+
+def migrate_all():
+    base_dir = config.baseDir
+
+    old_node_base_data_dir = os.path.join(old_base_dir, 'data')
+    old_nodes_data_dir = os.path.join(old_node_base_data_dir, 'nodes')
+    old_wallets_dir = os.path.join(old_base_dir, 'wallets')
+    old_general_config = os.path.join(old_base_dir, 'indy_config.py')
+    old_daemon_config_base_dir = '/home/indy/.indy'
+    old_daemon_config = os.path.join(old_daemon_config_base_dir, 'indy.env')
+
+    new_log_dir = os.path.join(config.LOG_DIR, config.NETWORK_NAME)
+    new_node_base_dir = os.path.join(base_dir , config.NETWORK_NAME)
+    new_node_base_data_dir = os.path.join(config.NODE_BASE_DATA_DIR, config.NETWORK_NAME)
+
+    new_general_config = os.path.join(config.GENERAL_CONFIG_DIR, config.GENERAL_CONFIG_FILE)
+
+    # Move general config file
+    os.rename(old_general_config, new_general_config)
+
+    # Move genesis transactions
+    migrate_genesis_txn(old_base_dir, new_node_base_dir)
+
+    for node_name in os.listdir(old_nodes_data_dir):
+        # Move logs
+        old_node_logs_exp = os.path.join(old_base_dir, '{}.log*'.format(node_name))
+        for node_log in glob.glob(old_node_logs_exp):
+            shutil.move(node_log, new_log_dir)
+
+        # Move keys
+        old_keys_dir = os.path.join(old_base_dir, node_name)
+        new_keys_dir = os.path.join(new_node_base_dir, node_name)
+        os.mkdir(new_keys_dir)
+        migrate_keys(old_keys_dir, new_keys_dir)
+
+    # Move nodes data directory
+    shutil.move(old_nodes_data_dir, new_node_base_data_dir)
+
+    # Move wallets directory
+    shutil.move(old_wallets_dir, new_node_base_dir)
+
+    # Move daemon config
+    shutil.move(old_daemon_config, config.GENERAL_CONFIG_DIR)
+
+
+if os.path.exists(old_base_dir):",,2017-09-27 15:21:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/141076787,https://github.com/hyperledger/indy-node/pull/359#discussion_r141076787,keenondrums
https://github.com/hyperledger/indy-node/pull/359,https://github.com/hyperledger/indy-node/pull/359,"It once mentioned that they do not wanna do anything disruptive like moving, they wanna do copying instead. Please write an email to clarify",35667236bf8f4b603fba3687be4b838820b1782d,2017-09-26 14:39:32,141077117,"@@ -0,0 +1,79 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+
+from stp_core.common.log import getlogger
+from sovrin_common.config_util import getConfig
+
+config = getConfig()
+logger = getlogger()
+
+old_base_dir = '~/.indy'
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    for suffix in ('sandbox', 'live', 'local'):
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_base_txn_dir)",,2017-09-27 15:21:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/141077117,https://github.com/hyperledger/indy-node/pull/359#discussion_r141077117,keenondrums
https://github.com/hyperledger/indy-node/pull/359,https://github.com/hyperledger/indy-node/pull/359,I checked this point with Alexander earlier and we decided to use 'move' strategy instead of 'copy'. Who is the person for clarification? Can I leave as is for now?,35667236bf8f4b603fba3687be4b838820b1782d,2017-09-26 15:10:53,141087294,"@@ -0,0 +1,79 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+
+from stp_core.common.log import getlogger
+from sovrin_common.config_util import getConfig
+
+config = getConfig()
+logger = getlogger()
+
+old_base_dir = '~/.indy'
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    for suffix in ('sandbox', 'live', 'local'):
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_base_txn_dir)",,2017-09-27 15:21:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/141087294,https://github.com/hyperledger/indy-node/pull/359#discussion_r141087294,sergey-shilov
https://github.com/hyperledger/indy-node/pull/359,https://github.com/hyperledger/indy-node/pull/359,"I can replace it with shutil.move(), but in fact shutil.move() calls os.rename() if the destination is on the current filesystem (our case, I think). But anyway, ok, I'll use shutil.move() here.",35667236bf8f4b603fba3687be4b838820b1782d,2017-09-26 15:11:28,141087467,"@@ -0,0 +1,79 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+
+from stp_core.common.log import getlogger
+from sovrin_common.config_util import getConfig
+
+config = getConfig()
+logger = getlogger()
+
+old_base_dir = '~/.indy'
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    for suffix in ('sandbox', 'live', 'local'):
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_base_txn_dir)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_base_txn_dir)
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir)
+    for prefix in ('private', 'public', 'sig', 'verif'):
+        old_keys_dir = os.path.join(old_base_keys_dir, '{}_keys'.format(prefix))
+        if os.path.exists(old_keys_dir) and os.path.isdir(old_keys_dir):
+            shutil.move(old_keys_dir, new_base_keys_dir)
+
+
+def migrate_all():
+    base_dir = config.baseDir
+
+    old_node_base_data_dir = os.path.join(old_base_dir, 'data')
+    old_nodes_data_dir = os.path.join(old_node_base_data_dir, 'nodes')
+    old_wallets_dir = os.path.join(old_base_dir, 'wallets')
+    old_general_config = os.path.join(old_base_dir, 'indy_config.py')
+    old_daemon_config_base_dir = '/home/indy/.indy'
+    old_daemon_config = os.path.join(old_daemon_config_base_dir, 'indy.env')
+
+    new_log_dir = os.path.join(config.LOG_DIR, config.NETWORK_NAME)
+    new_node_base_dir = os.path.join(base_dir , config.NETWORK_NAME)
+    new_node_base_data_dir = os.path.join(config.NODE_BASE_DATA_DIR, config.NETWORK_NAME)
+
+    new_general_config = os.path.join(config.GENERAL_CONFIG_DIR, config.GENERAL_CONFIG_FILE)
+
+    # Move general config file
+    os.rename(old_general_config, new_general_config)",,2017-09-27 15:21:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/141087467,https://github.com/hyperledger/indy-node/pull/359#discussion_r141087467,sergey-shilov
https://github.com/hyperledger/indy-node/pull/359,https://github.com/hyperledger/indy-node/pull/359,Done.,35667236bf8f4b603fba3687be4b838820b1782d,2017-09-27 15:01:40,141371609,"@@ -0,0 +1,79 @@
+#!/usr/bin/python3.5
+import os
+import shutil
+import glob
+
+from stp_core.common.log import getlogger
+from sovrin_common.config_util import getConfig
+
+config = getConfig()
+logger = getlogger()
+
+old_base_dir = '~/.indy'
+
+def migrate_genesis_txn(old_base_txn_dir, new_base_txn_dir):
+    for suffix in ('sandbox', 'live', 'local'):
+        old_domain_genesis = os.path.join(
+            old_base_txn_dir, 'domain_transactions_{}_genesis'.format(suffix))
+        old_pool_genesis = os.path.join(
+            old_base_txn_dir, 'pool_transactions_{}_genesis'.format(suffix))
+
+        if os.path.exists(old_domain_genesis):
+            shutil.move(old_domain_genesis, new_base_txn_dir)
+        if os.path.exists(old_pool_genesis):
+            shutil.move(old_pool_genesis, new_base_txn_dir)
+
+
+def migrate_keys(old_base_keys_dir, new_base_keys_dir)
+    for prefix in ('private', 'public', 'sig', 'verif'):
+        old_keys_dir = os.path.join(old_base_keys_dir, '{}_keys'.format(prefix))
+        if os.path.exists(old_keys_dir) and os.path.isdir(old_keys_dir):
+            shutil.move(old_keys_dir, new_base_keys_dir)
+
+
+def migrate_all():
+    base_dir = config.baseDir
+
+    old_node_base_data_dir = os.path.join(old_base_dir, 'data')
+    old_nodes_data_dir = os.path.join(old_node_base_data_dir, 'nodes')
+    old_wallets_dir = os.path.join(old_base_dir, 'wallets')
+    old_general_config = os.path.join(old_base_dir, 'indy_config.py')
+    old_daemon_config_base_dir = '/home/indy/.indy'
+    old_daemon_config = os.path.join(old_daemon_config_base_dir, 'indy.env')
+
+    new_log_dir = os.path.join(config.LOG_DIR, config.NETWORK_NAME)
+    new_node_base_dir = os.path.join(base_dir , config.NETWORK_NAME)
+    new_node_base_data_dir = os.path.join(config.NODE_BASE_DATA_DIR, config.NETWORK_NAME)
+
+    new_general_config = os.path.join(config.GENERAL_CONFIG_DIR, config.GENERAL_CONFIG_FILE)
+
+    # Move general config file
+    os.rename(old_general_config, new_general_config)
+
+    # Move genesis transactions
+    migrate_genesis_txn(old_base_dir, new_node_base_dir)
+
+    for node_name in os.listdir(old_nodes_data_dir):
+        # Move logs
+        old_node_logs_exp = os.path.join(old_base_dir, '{}.log*'.format(node_name))
+        for node_log in glob.glob(old_node_logs_exp):
+            shutil.move(node_log, new_log_dir)
+
+        # Move keys
+        old_keys_dir = os.path.join(old_base_dir, node_name)
+        new_keys_dir = os.path.join(new_node_base_dir, node_name)
+        os.mkdir(new_keys_dir)
+        migrate_keys(old_keys_dir, new_keys_dir)
+
+    # Move nodes data directory
+    shutil.move(old_nodes_data_dir, new_node_base_data_dir)
+
+    # Move wallets directory
+    shutil.move(old_wallets_dir, new_node_base_dir)
+
+    # Move daemon config
+    shutil.move(old_daemon_config, config.GENERAL_CONFIG_DIR)
+
+
+if os.path.exists(old_base_dir):",,2017-09-27 15:21:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/141371609,https://github.com/hyperledger/indy-node/pull/359#discussion_r141371609,sergey-shilov
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,Should it be `Indy-node`?,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-09-25 08:21:34,140713474,"@@ -1,13 +1,13 @@
 [Unit]
-Description=Service for upgrade existing Sovrin and another operations
-#Requires=sovrin.service
-#After=sovrin.service
+Description=Service for upgrade existing Indy and another operations",,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/140713474,https://github.com/hyperledger/indy-node/pull/351#discussion_r140713474,ashcherbakov
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,Should it be `Indy-node`?,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-09-25 08:24:07,140713949,"@@ -65,16 +65,16 @@ WantedBy=multi-user.target
 EOF
 
 
-cat <<EOF > /etc/systemd/system/sovrin-node-control.service
+cat <<EOF > /etc/systemd/system/indy-node-control.service
 [Unit]
-Description=Service for upgrade existing Sovrin and another operations
-#Requires=sovrin.service
-#After=sovrin.service
+Description=Service for upgrade existing Indy and another operations",,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/140713949,https://github.com/hyperledger/indy-node/pull/351#discussion_r140713949,ashcherbakov
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,There should be no changes in migration scripts since they are supposed to be used with an old version of code.,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-09-25 08:26:56,140714461,"@@ -12,8 +12,8 @@
 from storage import store_utils
 from storage.chunked_file_store import ChunkedFileStore
 
-from sovrin_common.config_util import getConfig
-from sovrin_common.txn_util import getTxnOrderedFields
+from indy_common.config_util import getConfig",6,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/140714461,https://github.com/hyperledger/indy-node/pull/351#discussion_r140714461,ashcherbakov
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,There should be no changes in migration scripts since they are supposed to be used with an old version of code.,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-09-25 08:27:02,140714475,"@@ -15,9 +15,9 @@
 from storage.chunked_file_store import ChunkedFileStore
 from stp_core.common.log import getlogger
 
-from sovrin_common.config_util import getConfig",4,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/140714475,https://github.com/hyperledger/indy-node/pull/351#discussion_r140714475,ashcherbakov
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,We should keep the old version of wallet as well to make sure that wallets are backward-compatible,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-09-25 08:54:03,140720003,"@@ -0,0 +1 @@
+{""didMethods"": {""py/object"": ""plenum.common.did_method.DidMethods"", ""default"": {""py/id"": 61}, ""d"": {""indy"": {""py/object"": ""plenum.common.did_method.DidMethod"", ""name"": ""indy"", ""signerConstructor"": {""py/type"": ""plenum.common.signer_did.DidSigner""}, ""pattern"": ""did:indy:""}}}, ""_nodes"": {}, ""_pending"": {""py/reduce"": [{""py/type"": ""collections.deque""}, {""py/tuple"": [[]]}, null, null, null]}, ""defaultId"": ""CzkavE58zgX7rUMrzSinLr"", ""_upgrades"": {}, ""_name"": ""Default"", ""aliasesToIds"": {}, ""_trustAnchored"": {""ULtgFQJe6bjiFbs7ke3NJD"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": true, ""_identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""_verkey"": ""5kh3FB4H3NKq7tUDqeqHc1""}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": ""101""}, ""CzkavE58zgX7rUMrzSinLr"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": true, ""_identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""_verkey"": ""WjXEvZ9xj4Tz9sLtzf7HVP""}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": ""101""}}, ""_pconfigs"": {}, ""py/object"": ""indy_client.client.wallet.wallet.Wallet"", ""ids"": {""ULtgFQJe6bjiFbs7ke3NJD"": {""py/object"": ""plenum.client.wallet.IdData"", ""py/newargs"": {""py/tuple"": [{""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 75}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""ZGQ2ZGI4ZWI5MWNmZGNlNTBmMWE0ODhkOTUzMzI1ZGEyNjdlMzYyMzE5N2EwN2Q0MTQ4YjI1ZjM3\nZWZjMjg3ZQ==\n""}, ""keyhex"": {""py/b64"": ""NDY2MTYyNjU3MjMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAz\nMDMwMzAzMA==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""3W2465HP3OUPGkiNlTMl2iZ+NiMZegfUFIsl8378KH4=\n""}}, ""_signing_key"": {""py/b64"": ""RmFiZXIwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDDdbbjrkc/c5Q8aSI2VMyXaJn42Ixl6B9QU\niyXzfvwofg==\n""}, ""_seed"": {""py/b64"": ""RmFiZXIwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}}, ""verraw"": {""py/b64"": ""3W2465HP3OUPGkiNlTMl2iZ+NiMZegfUFIsl8378KH4=\n""}, ""keyraw"": {""py/b64"": ""RmFiZXIwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}}, ""_identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""RmFiZXIwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}, ""_verkey"": ""5kh3FB4H3NKq7tUDqeqHc1""}, 1502387001630568]}, ""py/seq"": [{""py/id"": 73}, 1502387001630568]}, ""Th7MpTaRZVRYnPiabds81Y"": {""py/object"": ""plenum.client.wallet.IdData"", ""py/newargs"": {""py/tuple"": [{""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 70}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""ZDgyNzQ2NThkMjNiYzJlNDE5NGQxMjMyZmZmNzBlMmIzNDRiYWY2MjEwNjdlYjZhYTkyYjJmY2Vm\nMGM5NGU4ZA==\n""}, ""keyhex"": {""py/b64"": ""MzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwNTM3NDY1Nzc2\nMTcyNjQzMQ==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""2CdGWNI7wuQZTRIy//cOKzRLr2IQZ+tqqSsvzvDJTo0=\n""}}, ""_signing_key"": {""py/b64"": ""MDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwU3Rld2FyZDHYJ0ZY0jvC5BlNEjL/9w4rNEuvYhBn62qp\nKy/O8MlOjQ==\n""}, ""_seed"": {""py/b64"": ""MDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwU3Rld2FyZDE=\n""}}, ""verraw"": {""py/b64"": ""2CdGWNI7wuQZTRIy//cOKzRLr2IQZ+tqqSsvzvDJTo0=\n""}, ""keyraw"": {""py/b64"": ""MDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwU3Rld2FyZDE=\n""}}, ""_identifier"": ""Th7MpTaRZVRYnPiabds81Y"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""MDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwU3Rld2FyZDE=\n""}, ""_verkey"": ""7TYfekw4GUagBnBVCqPjiC""}, 1502385714960301]}, ""py/seq"": [{""py/id"": 68}, 1502385714960301]}, ""CzkavE58zgX7rUMrzSinLr"": {""py/object"": ""plenum.client.wallet.IdData"", ""py/newargs"": {""py/tuple"": [{""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 65}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""NjEyNGM3YmQxZmVjYzVkYmI4ZDYyODNkOTljYThjYWJmMGM4ZTU0NDkwMzE1NTM4OTI5NmJhNmE3\nMjYxYTJkZQ==\n""}, ""keyhex"": {""py/b64"": ""NDE2MzZkNjUzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAz\nMDMwMzAzMA==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""YSTHvR/sxdu41ig9mcqMq/DI5USQMVU4kpa6anJhot4=\n""}}, ""_signing_key"": {""py/b64"": ""QWNtZTAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDBhJMe9H+zF27jWKD2Zyoyr8MjlRJAxVTiS\nlrpqcmGi3g==\n""}, ""_seed"": {""py/b64"": ""QWNtZTAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}}, ""verraw"": {""py/b64"": ""YSTHvR/sxdu41ig9mcqMq/DI5USQMVU4kpa6anJhot4=\n""}, ""keyraw"": {""py/b64"": ""QWNtZTAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}}, ""_identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""QWNtZTAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}, ""_verkey"": ""WjXEvZ9xj4Tz9sLtzf7HVP""}, 1502387801276699]}, ""py/seq"": [{""py/id"": 63}, 1502387801276699]}}, ""_attributes"": {""json://{\""py/tuple\"": [\""73563\"", \""CzkavE58zgX7rUMrzSinLr\"", \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:6666\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""73563"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""endpoint\"", null, \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": null, ""origin"": null, ""encKey"": null, ""name"": ""endpoint"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""endpoint\"", null, \""ULtgFQJe6bjiFbs7ke3NJD\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": null, ""origin"": null, ""encKey"": null, ""name"": ""endpoint"", ""seqNo"": null, ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""a0641\"", \""CzkavE58zgX7rUMrzSinLr\"", \""ULtgFQJe6bjiFbs7ke3NJD\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""a0641"", ""seqNo"": null, ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""45884\"", \""ULtgFQJe6bjiFbs7ke3NJD\"", \""ULtgFQJe6bjiFbs7ke3NJD\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.202:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""origin"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""encKey"": null, ""name"": ""45884"", ""seqNo"": null, ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ledgerStore"": {""py/object"": ""indy_client.client.wallet.attribute.LedgerStore"", ""py/enumvalue"": 4}}, ""json://{\""py/tuple\"": [\""917b5\"", \""CzkavE58zgX7rUMrzSinLr\"", \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.203:6666\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""917b5"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""4f3d1\"", \""ULtgFQJe6bjiFbs7ke3NJD\"", \""ULtgFQJe6bjiFbs7ke3NJD\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""origin"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""encKey"": null, ""name"": ""4f3d1"", ""seqNo"": null, ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""881bb\"", \""CzkavE58zgX7rUMrzSinLr\"", \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:6666\"", \""pubkey\"": \""C5eqjU7NMVMGGfGfx2ub- vX5H9X346bQt5qeziVAo3naQ\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""881bb"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""6db7a\"", \""CzkavE58zgX7rUMrzSinLr\"", \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.203:6666\"", \""pubkey\"": \""C5eqjU7NMVMGGfGfx2ub- vX5H9X346bQt5qeziVAo3naQ\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""6db7a"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}}, ""idsToSigners"": {""ULtgFQJe6bjiFbs7ke3NJD"": {""py/id"": 73}, ""JYeHd6Zn3zFo1UbNVBd6U1"": {""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 79}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""OGUxNjY0OGM3Y2IzYWMxNDMzNTc2MmM1YzVhYTkwZDJkM2I1ODY2NGExOTkyNGM2YWUzNmM1ODQ1\nZDE1MTg4OA==\n""}, ""keyhex"": {""py/b64"": ""ZTFlZmRjYzRmNmJkN2M4ZjhmMTc2MGFiNTkwY2EzMjllNGJjYTYzNTU4M2E5ZDg5NjRkNDljNTJh\nYTRhM2Y4ZA==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""jhZkjHyzrBQzV2LFxaqQ0tO1hmShmSTGrjbFhF0VGIg=\n""}}, ""_signing_key"": {""py/b64"": ""4e/cxPa9fI+PF2CrWQyjKeS8pjVYOp2JZNScUqpKP42OFmSMfLOsFDNXYsXFqpDS07WGZKGZJMau\nNsWEXRUYiA==\n""}, ""_seed"": {""py/b64"": ""4e/cxPa9fI+PF2CrWQyjKeS8pjVYOp2JZNScUqpKP40=\n""}}, ""verraw"": {""py/b64"": ""jhZkjHyzrBQzV2LFxaqQ0tO1hmShmSTGrjbFhF0VGIg=\n""}, ""keyraw"": {""py/b64"": ""4e/cxPa9fI+PF2CrWQyjKeS8pjVYOp2JZNScUqpKP40=\n""}}, ""_identifier"": ""JYeHd6Zn3zFo1UbNVBd6U1"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""4e/cxPa9fI+PF2CrWQyjKeS8pjVYOp2JZNScUqpKP40=\n""}, ""_verkey"": ""T9HBHeNSXBXZCBB8GrgjFm""}, ""Th7MpTaRZVRYnPiabds81Y"": {""py/id"": 68}, ""Siga5PyLFTZdpupPUXogjt"": {""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 83}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""ZDA0NjU4ZGNhMDQ4MjYyNjQ0MmNhZGFiYzZjZWNlMjM0ODc2YTY0MzhkNzBlNWIzNGQ4MTlmZmFj\nODY2MmVlZA==\n""}, ""keyhex"": {""py/b64"": ""YWJlZmEzOGNmYjVkYmYzMjljNTZjMjI4YmEzNjAzMzZjNmY2YWJjZWE0MjZlMDFlMTVkZTNiZGU1\nNjUzYjUxMQ==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""0EZY3KBIJiZELK2rxs7OI0h2pkONcOWzTYGf+shmLu0=\n""}}, ""_signing_key"": {""py/b64"": ""q++jjPtdvzKcVsIoujYDNsb2q86kJuAeFd473lZTtRHQRljcoEgmJkQsravGzs4jSHamQ41w5bNN\ngZ/6yGYu7Q==\n""}, ""_seed"": {""py/b64"": ""q++jjPtdvzKcVsIoujYDNsb2q86kJuAeFd473lZTtRE=\n""}}, ""verraw"": {""py/b64"": ""0EZY3KBIJiZELK2rxs7OI0h2pkONcOWzTYGf+shmLu0=\n""}, ""keyraw"": {""py/b64"": ""q++jjPtdvzKcVsIoujYDNsb2q86kJuAeFd473lZTtRE=\n""}}, ""_identifier"": ""Siga5PyLFTZdpupPUXogjt"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""q++jjPtdvzKcVsIoujYDNsb2q86kJuAeFd473lZTtRE=\n""}, ""_verkey"": ""9wzQSoSNbLwRcNz9JkBFME""}, ""CzkavE58zgX7rUMrzSinLr"": {""py/id"": 63}}, ""_prepared"": {""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502387001630568]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""cfbec5716f611b627475f6a9ab69415630a3244a535f9cadd4fe196705bb3e09"", ""reqId"": 1502387001630568, ""signature"": ""SC1JYwuXnpruhGefBZKCyBvCESmAP9vx8SfUWPPmoR1NH2LDHQYj5XV78zBMCEFAXwuZdHmkpEH6Lu35kuxzMCZ"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""endpoint"", null, ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502385870898879]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""f2c1c5733913f633e7fc58d5b2ec52859979149cdd06e10b578d162c01d25862"", ""reqId"": 1502385870898879, ""signature"": ""5A2BxVk8EowuBT9TKYKWhck9Ng3Bk7Cwo8ego36aWEc4NNx5hNeXwzu37q1FhvmJwZ6fDrRnKvepjCQHXLAL1DbN"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""4f3d1"", ""ULtgFQJe6bjiFbs7ke3NJD"", ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502387071423304]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""45d33c68b9aa557d7b1300656905a446d9e1924e51f55a07e125396202024e37"", ""reqId"": 1502387071423304, ""signature"": ""2dZMNC37ihe7EXjVxk6s1FENZ6Qr15i6TTk9vyT4kEsYig1D3QQLACrgz88vFwoaiycameMseateEEFPhxvFiarZ"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""105"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386049567645]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""079b8ed2360cc6a2c686587a613f8c1109b1941154bcee5fcece4ad2464d7f40"", ""reqId"": 1502386049567645, ""signature"": ""2RNPTPq3K2rNb4MFmoYJEza3n7tmLaz696nRxEegASoyYdJDKNGvCAJLCCFYJvAxAh7Y66duQ7fX2byZWE3EWZAc"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""endpoint"", null, ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502387057277920]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""1cefcc959335319b7f9c5527e5f4dcbb49a7456ebed2c24fd33cc06ab045bbcb"", ""reqId"": 1502387057277920, ""signature"": ""2yzWAuxduX6dQfw1nJFafU6XTeFYDXqWnxyNrdfFM8cammiz4P6YpoKbWbq7kDVA22FS1Hz13DfLdJ5PEnXJZehs"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.203:6666\""}}"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""917b5"", ""CzkavE58zgX7rUMrzSinLr"", ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502385848758045]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""6d45682720c304d825573cd6b9c60bc47d95eda3a70987a4fc410bd6afeadc44"", ""reqId"": 1502385848758045, ""signature"": ""3NLdp4qD15N2CetMjGtrmpQWDKx6ycVVaRtLZ3gKMmzLzxBujvsqQutA7yts74pJPtRodaEPy2w5FvpS7yBzNsr"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""a0641"", ""CzkavE58zgX7rUMrzSinLr"", ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502387071424365]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""0036694829240ca13b5a9108c2f16fe60213c30f054c9b335b35b95d14dec31c"", ""reqId"": 1502387071424365, ""signature"": ""4bf8VGMVGq6JtWeFXdvD4NhdAMseuZdxnvvxw6QaodiGKA54yRxfShbDG9ff2xrDUQHCPJ1PuYMwPmDanx1gpSoB"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""endpoint"", null, ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386144574978]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""ca879f3ce42853d26300fae03dc39a5c27cc3e14e8f1578418729de3d19bcf4b"", ""reqId"": 1502386144574978, ""signature"": ""2u2C32ww9GkdBj78haTzKLvgaU4PqJ2N8VYmmoALSpZT5pTgvaGjgFniRPHd1DSwv8MVyt4vX8m26SgL1zDJVJVY"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""endpoint"", null, ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""Th7MpTaRZVRYnPiabds81Y\"", 1502385611413187]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""949dd184333687d9e81d853dc0d981bfc87f56a1757fd4556e2ad2983573f0ea"", ""reqId"": 1502385611413187, ""signature"": ""5vpkHbSFdCJrRbFXe6sAKW8S1zB2QXqisp56gdFsPXRMrx7bD8Z5Q8yLpjcyszTsDePqy1JELgGHAvwZEPU8KvR4"", ""identifier"": ""Th7MpTaRZVRYnPiabds81Y"", ""operation"": {""role"": ""101"", ""type"": ""1"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""verkey"": ""~5kh3FB4H3NKq7tUDqeqHc1""}}}, ""ULtgFQJe6bjiFbs7ke3NJD""]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502385732035030]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""52c6dbfc7fdf04bddf4e6b0bb43d7316edcb2fc820eaab4c2cada0fe34b310da"", ""reqId"": 1502385732035030, ""signature"": ""4RyhbLSRPpahFjk5pthh3tM3de49G2fz77oP42VyRp4DWwMHWbXrRkD6SYVxGGgYaaa8Ep8xhMEQ2QgvDNmHkaDm"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.203:6666\"", \""pubkey\"": \""C5eqjU7NMVMGGfGfx2ub- vX5H9X346bQt5qeziVAo3naQ\""}}"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""6db7a"", ""CzkavE58zgX7rUMrzSinLr"", ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386097385267]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""0e116050b139e82912740bca170ac8b550a211c34f9bfc52ddd82bdf8a10460d"", ""reqId"": 1502386097385267, ""signature"": ""3GBVvm55r21RhdYYJS1FYKE67yxo9Dokiv4XePh2DTpfETKRKqi3Lap8BiZUcicwVFKi4RTYZi9sfC75iLuNvFWe"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""108"", ""origin"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ref"": 15, ""signature_type"": ""CL""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386050220665]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""d3f84e2352faca0109598e86e8eb74d5fe4039939b88980a00af24bd26e95cab"", ""reqId"": 1502386050220665, ""signature"": ""3bqWZafGMZY384S5Zi2ugEpamTWamezPfLtHVBW7DH6Hgntpd1KTuLjmLoJLw8nh3f6kUV2w2NAgLuQn5ZEceMvP"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""105"", ""dest"": ""JYeHd6Zn3zFo1UbNVBd6U1""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502385681114223]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""c5c275f4963b859d3ca5f84e15e8f09b7bf7ec1fe7e615131daace478b8dee3e"", ""reqId"": 1502385681114223, ""signature"": ""38jKR2T4pQ7ckYqKriuZF2gGoxbr928FCZtMDns5zNVX35DNWFZ3EWNX7pBSiQKa58928oTq4sFFe5h5v6qojAW1"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.202:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""45884"", ""ULtgFQJe6bjiFbs7ke3NJD"", ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502385835239707]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""4bc95d41076677bbfd40407bba1d8ddb69818a79d6a9a24aa57daf0d06ed3770"", ""reqId"": 1502385835239707, ""signature"": ""5R1sAupQwqoee5muMmmud94KWgLvkqkPHxRKj7jPu4VQ5pDCZuvPPpXJXYYSNrtgsDvFurXGg9Jj82S8hEM1H6YH"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:6666\"", \""pubkey\"": \""C5eqjU7NMVMGGfGfx2ub- vX5H9X346bQt5qeziVAo3naQ\""}}"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""881bb"", ""CzkavE58zgX7rUMrzSinLr"", ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386188150095]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""0e98ffb463973aa6873ca2cbb21b724b7c3711e30dc3f0177c42285ec022763e"", ""reqId"": 1502386188150095, ""signature"": ""3wB4HxjzsPhA74yv4Df4SZBdQYX7s8dAkhyKbdgWSfoMxyQo6tyFPmaHLb3AcE3r7rcngvLdQy9WbTQhxj3HYhBC"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""endpoint"", null, ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502385899839362]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""e6b83a2dae024a32b5f3c057d3e3f2357291b8fc0e4dae481907c2a9f5e6d1d7"", ""reqId"": 1502385899839362, ""signature"": ""SySAHLvfYw9epanGaKhWsYGWNx7UJ99LTsum4izbgwPxLiMQkS6NhjDMfWMfeoD96rewiP22WJBRkSe2DyfvbPU"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""endpoint"", null, ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386144573959]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""73a605a704302242669e58cd2f28f58176ab2ed51783f8b3fcb6a06b2fa94fae"", ""reqId"": 1502386144573959, ""signature"": ""3Jz114XGYzyiSMXijXf9j8ttoZh3CsmbjMVwQj2KfFRuVjHosCBsVoPWeJtJfn4gK5MbpmScpyTu4VVFD2qNscWf"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""105"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386085472327]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""cd0692a09506d71387a4f034887e6ef266dc7cf45591f2b9ed3885589ee7d689"", ""reqId"": 1502386085472327, ""signature"": ""5j57ZRTFhD23fS3dHtYxEvUhK7HzA5UVrbmSszgt2JCw2Dyg228fTaiEtqPDgo7ybdKxXkGjyTfzQPe7c5wVgW9G"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""107"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""data"": {""name"": ""Transcript"", ""version"": ""1.2""}}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502387001627354]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""adcffa4444661aaa7e0a35653126b616a1941fae3bc66e8fcafa663144a42d18"", ""reqId"": 1502387001627354, ""signature"": ""ybsbW5JHKn9JGKgbGeKEajUhAnCHMixEWuk9E9YUD7r8xgC5EaDaRhpuASSeyfFoymY65Gbmd3qcCNYuk7VuSrA"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""105"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386049566532]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""3a7bc6b517611dcfdf704b6903ddabec3507d4ecc272d328493b108ed04bde00"", ""reqId"": 1502386049566532, ""signature"": ""4ghzAiyLavPqsrEr6bYUZMyg87xYtHZ38vQHZrDU3CnJVTXBx9VXRM2qLsPwD8mEN86pMVAT3KdVaD2NJt8VhvgV"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""105"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, null]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502387801276699]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""39ee07b502bd4d3c6f32b6d2beab3795e4312690514dd57288a3bac7358d82c4"", ""reqId"": 1502387801276699, ""signature"": ""2ByXW61ND5bxZDF9nV593ZoYWmShj7Ld1qYCyEJ6jthoE1BqDcuerUSqc4y1NCPuQy23BUGbT1BvRmPt9EVJfugW"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:6666\""}}"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""73563"", ""CzkavE58zgX7rUMrzSinLr"", ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""Th7MpTaRZVRYnPiabds81Y\"", 1502385714960301]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""eaea017f0c21a8ff39a880853922748895a8495e61b4a51822a73dff7831c028"", ""reqId"": 1502385714960301, ""signature"": ""5AJvDyr6N4enKP31cyXyojoph1KstDGw9VkfNvGdHyY8b4ruEDHE8LU7JEvwxjwLyEVcEcu7j4QMnykjuF63PqA7"", ""identifier"": ""Th7MpTaRZVRYnPiabds81Y"", ""operation"": {""role"": ""101"", ""type"": ""1"", ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""verkey"": ""~WjXEvZ9xj4Tz9sLtzf7HVP""}}}, ""CzkavE58zgX7rUMrzSinLr""]}, ""json://{\""py/tuple\"": [\""Th7MpTaRZVRYnPiabds81Y\"", 1502385655248947]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""d1095621d406da7a2e95d744b8ba4016db73b75e3fe0faaf4a5fa82b94e065f2"", ""reqId"": 1502385655248947, ""signature"": ""3pY9d3kPfaf9g4L7WoeJ7L7eKQ86SRfzJfGfy4yZKn41WXHwvFdtAsGM7ne96GKUtbfJVknvbeCDo6AHxYX9j5Qm"", ""identifier"": ""Th7MpTaRZVRYnPiabds81Y"", ""operation"": {""role"": ""101"", ""type"": ""1"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""verkey"": ""~5kh3FB4H3NKq7tUDqeqHc1""}}}, ""ULtgFQJe6bjiFbs7ke3NJD""]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502385695560631]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""74b080a5afc1beff66f42a87af9c4fcd032f863197c74883e7d302a8b0f18852"", ""reqId"": 1502385695560631, ""signature"": ""4myAj7GnGrUqb9WKtMbTD19rNvX1ToXZmWv4K7MZQP63DdYYzvW9b5n6mzYKnkdnUUQvPvdkweuUBVTJSMdy6bup"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""role"": ""101"", ""type"": ""1"", ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""verkey"": ""~WjXEvZ9xj4Tz9sLtzf7HVP""}}}, ""CzkavE58zgX7rUMrzSinLr""]}}, ""_connections"": {""py/reduce"": [{""py/type"": ""collections.OrderedDict""}, {""py/tuple"": []}, null, null, {""py/tuple"": [{""py/tuple"": [""Faber College"", {""proofRequests"": [], ""internalId"": null, ""remoteEndPoint"": {""py/tuple"": [""127.0.0.1"", 5555]}, ""request_nonce"": ""b1134a647eb818069c089e7694f63e6d"", ""name"": ""Faber College"", ""connection_status"": ""Accepted"", ""trustAnchor"": ""Faber College"", ""verifiedClaimProofs"": [], ""py/object"": ""indy_client.client.wallet.connection.Connection"", ""connection_last_sync_no"": null, ""localIdentifier"": ""JYeHd6Zn3zFo1UbNVBd6U1"", ""localVerkey"": ""~T9HBHeNSXBXZCBB8GrgjFm"", ""remotePubkey"": ""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z"", ""availableClaims"": [{""py/object"": ""anoncreds.protocol.types.AvailableClaim"", ""py/newargs"": {""py/tuple"": [""Transcript"", ""1.2"", ""ULtgFQJe6bjiFbs7ke3NJD""]}, ""py/seq"": [""Transcript"", ""1.2"", ""ULtgFQJe6bjiFbs7ke3NJD""]}], ""connection_last_synced"": {""py/object"": ""datetime.datetime"", ""__reduce__"": [{""py/type"": ""datetime.datetime""}, [""B+EIChQbHQvKxQ==""]]}, ""_remoteVerkey"": ""~5kh3FB4H3NKq7tUDqeqHc1"", ""remoteIdentifier"": ""ULtgFQJe6bjiFbs7ke3NJD""}]}, {""py/tuple"": [""Acme Corp"", {""proofRequests"": [{""py/object"": ""anoncreds.protocol.types.ProofRequest"", ""attributes"": {""py/reduce"": [{""py/type"": ""collections.OrderedDict""}, {""py/tuple"": []}, null, null, {""py/tuple"": [{""py/tuple"": [""first_name"", ""string""]}, {""py/tuple"": [""last_name"", ""string""]}, {""py/tuple"": [""phone_number"", ""string""]}, {""py/tuple"": [""degree"", ""Bachelor of Science, Marketing""]}, {""py/tuple"": [""status"", ""graduated""]}, {""py/tuple"": [""ssn"", ""123-45-6789""]}]}]}, ""ts"": null, ""version"": ""0.2"", ""verifiableAttributes"": {""777fb1af-a7a0-4f0c-81b8-9e09a8068d16"": {""py/object"": ""anoncreds.protocol.types.AttributeInfo"", ""py/newargs"": {""py/tuple"": [""status"", null, null]}, ""py/seq"": [""status"", null, null]}, ""d5743fcc-d287-4176-a634-3b721d962ea5"": {""py/object"": ""anoncreds.protocol.types.AttributeInfo"", ""py/newargs"": {""py/tuple"": [""ssn"", null, null]}, ""py/seq"": [""ssn"", null, null]}, ""4de5205f-720f-49f0-8397-0576875d904b"": {""py/object"": ""anoncreds.protocol.types.AttributeInfo"", ""py/newargs"": {""py/tuple"": [""degree"", null, null]}, ""py/seq"": [""degree"", null, null]}}, ""nonce"": 1871218719015472932666560146158750511756, ""seqNo"": null, ""name"": ""Job-Application"", ""predicates"": {}, ""fulfilledByClaims"": [{""py/tuple"": [{""py/id"": 12}, {""py/id"": 14}, {""py/reduce"": [{""py/type"": ""collections.OrderedDict""}, {""py/tuple"": []}, null, null, {""py/tuple"": [{""py/tuple"": [""student_name"", ""Alice Garcia""]}, {""py/tuple"": [""ssn"", ""123-45-6789""]}, {""py/tuple"": [""degree"", ""Bachelor of Science, Marketing""]}, {""py/tuple"": [""year"", ""2015""]}, {""py/tuple"": [""status"", ""graduated""]}]}]}]}], ""selfAttestedAttrs"": {}}], ""internalId"": null, ""remoteEndPoint"": {""py/tuple"": [""10.0.0.203"", 6666]}, ""request_nonce"": ""57fbf9dc8c8e6acde33de98c6d747b28c"", ""name"": ""Acme Corp"", ""connection_status"": null, ""trustAnchor"": ""Acme Corp"", ""verifiedClaimProofs"": [], ""py/object"": ""indy_client.client.wallet.connection.Connection"", ""connection_last_sync_no"": null, ""localIdentifier"": ""Siga5PyLFTZdpupPUXogjt"", ""localVerkey"": ""~9wzQSoSNbLwRcNz9JkBFME"", ""remotePubkey"": ""C5eqjU7NMVMGGfGfx2ubvX5H9X346bQt5qeziVAo3naQ"", ""availableClaims"": [], ""connection_last_synced"": {""py/object"": ""datetime.datetime"", ""__reduce__"": [{""py/type"": ""datetime.datetime""}, [""B+EIChQsHwmWIA==""]]}, ""_remoteVerkey"": ""~WjXEvZ9xj4Tz9sLtzf7HVP"", ""remoteIdentifier"": ""CzkavE58zgX7rUMrzSinLr""}]}]}]}, ""replyHandler"": {}, ""knownIds"": {""ULtgFQJe6bjiFbs7ke3NJD"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": null, ""_identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""_verkey"": null}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": null}, ""JYeHd6Zn3zFo1UbNVBd6U1"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": null, ""_identifier"": ""JYeHd6Zn3zFo1UbNVBd6U1"", ""_verkey"": null}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": null}, ""CzkavE58zgX7rUMrzSinLr"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": null, ""_identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""_verkey"": null}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": null}}, ""lastKnownSeqs"": {}, ""env"": ""no-env"", ""classver/indy_client.client.wallet.wallet.Wallet"": 1}",,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/140720003,https://github.com/hyperledger/indy-node/pull/351#discussion_r140720003,ashcherbakov
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,We should not to forget updating other public documentation after this PR is merged (or create a ticket for update).,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-09-25 08:55:08,140720274,"@@ -1,16 +1,16 @@
-# Sovrin -- identity for all",1,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/140720274,https://github.com/hyperledger/indy-node/pull/351#discussion_r140720274,ashcherbakov
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,This file has been removed.,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-10-02 10:12:22,142100731,"@@ -1,13 +1,13 @@
 [Unit]
-Description=Service for upgrade existing Sovrin and another operations
-#Requires=sovrin.service
-#After=sovrin.service
+Description=Service for upgrade existing Indy and another operations",,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/142100731,https://github.com/hyperledger/indy-node/pull/351#discussion_r142100731,spivachuk
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,Corrected.,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-10-02 10:17:22,142101541,"@@ -65,16 +65,16 @@ WantedBy=multi-user.target
 EOF
 
 
-cat <<EOF > /etc/systemd/system/sovrin-node-control.service
+cat <<EOF > /etc/systemd/system/indy-node-control.service
 [Unit]
-Description=Service for upgrade existing Sovrin and another operations
-#Requires=sovrin.service
-#After=sovrin.service
+Description=Service for upgrade existing Indy and another operations",,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/142101541,https://github.com/hyperledger/indy-node/pull/351#discussion_r142101541,spivachuk
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,Migration scripts should be operable on the target code base.,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-10-02 10:18:32,142101726,"@@ -12,8 +12,8 @@
 from storage import store_utils
 from storage.chunked_file_store import ChunkedFileStore
 
-from sovrin_common.config_util import getConfig
-from sovrin_common.txn_util import getTxnOrderedFields
+from indy_common.config_util import getConfig",6,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/142101726,https://github.com/hyperledger/indy-node/pull/351#discussion_r142101726,spivachuk
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,Migration scripts should be operable on the target code base.,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-10-02 10:18:44,142101759,"@@ -15,9 +15,9 @@
 from storage.chunked_file_store import ChunkedFileStore
 from stp_core.common.log import getlogger
 
-from sovrin_common.config_util import getConfig",4,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/142101759,https://github.com/hyperledger/indy-node/pull/351#discussion_r142101759,spivachuk
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,There are other tests for verification of deserialization of wallets in formats of previous versions.,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-10-02 10:20:49,142102085,"@@ -0,0 +1 @@
+{""didMethods"": {""py/object"": ""plenum.common.did_method.DidMethods"", ""default"": {""py/id"": 61}, ""d"": {""indy"": {""py/object"": ""plenum.common.did_method.DidMethod"", ""name"": ""indy"", ""signerConstructor"": {""py/type"": ""plenum.common.signer_did.DidSigner""}, ""pattern"": ""did:indy:""}}}, ""_nodes"": {}, ""_pending"": {""py/reduce"": [{""py/type"": ""collections.deque""}, {""py/tuple"": [[]]}, null, null, null]}, ""defaultId"": ""CzkavE58zgX7rUMrzSinLr"", ""_upgrades"": {}, ""_name"": ""Default"", ""aliasesToIds"": {}, ""_trustAnchored"": {""ULtgFQJe6bjiFbs7ke3NJD"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": true, ""_identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""_verkey"": ""5kh3FB4H3NKq7tUDqeqHc1""}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": ""101""}, ""CzkavE58zgX7rUMrzSinLr"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": true, ""_identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""_verkey"": ""WjXEvZ9xj4Tz9sLtzf7HVP""}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": ""101""}}, ""_pconfigs"": {}, ""py/object"": ""indy_client.client.wallet.wallet.Wallet"", ""ids"": {""ULtgFQJe6bjiFbs7ke3NJD"": {""py/object"": ""plenum.client.wallet.IdData"", ""py/newargs"": {""py/tuple"": [{""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 75}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""ZGQ2ZGI4ZWI5MWNmZGNlNTBmMWE0ODhkOTUzMzI1ZGEyNjdlMzYyMzE5N2EwN2Q0MTQ4YjI1ZjM3\nZWZjMjg3ZQ==\n""}, ""keyhex"": {""py/b64"": ""NDY2MTYyNjU3MjMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAz\nMDMwMzAzMA==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""3W2465HP3OUPGkiNlTMl2iZ+NiMZegfUFIsl8378KH4=\n""}}, ""_signing_key"": {""py/b64"": ""RmFiZXIwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDDdbbjrkc/c5Q8aSI2VMyXaJn42Ixl6B9QU\niyXzfvwofg==\n""}, ""_seed"": {""py/b64"": ""RmFiZXIwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}}, ""verraw"": {""py/b64"": ""3W2465HP3OUPGkiNlTMl2iZ+NiMZegfUFIsl8378KH4=\n""}, ""keyraw"": {""py/b64"": ""RmFiZXIwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}}, ""_identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""RmFiZXIwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}, ""_verkey"": ""5kh3FB4H3NKq7tUDqeqHc1""}, 1502387001630568]}, ""py/seq"": [{""py/id"": 73}, 1502387001630568]}, ""Th7MpTaRZVRYnPiabds81Y"": {""py/object"": ""plenum.client.wallet.IdData"", ""py/newargs"": {""py/tuple"": [{""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 70}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""ZDgyNzQ2NThkMjNiYzJlNDE5NGQxMjMyZmZmNzBlMmIzNDRiYWY2MjEwNjdlYjZhYTkyYjJmY2Vm\nMGM5NGU4ZA==\n""}, ""keyhex"": {""py/b64"": ""MzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwNTM3NDY1Nzc2\nMTcyNjQzMQ==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""2CdGWNI7wuQZTRIy//cOKzRLr2IQZ+tqqSsvzvDJTo0=\n""}}, ""_signing_key"": {""py/b64"": ""MDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwU3Rld2FyZDHYJ0ZY0jvC5BlNEjL/9w4rNEuvYhBn62qp\nKy/O8MlOjQ==\n""}, ""_seed"": {""py/b64"": ""MDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwU3Rld2FyZDE=\n""}}, ""verraw"": {""py/b64"": ""2CdGWNI7wuQZTRIy//cOKzRLr2IQZ+tqqSsvzvDJTo0=\n""}, ""keyraw"": {""py/b64"": ""MDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwU3Rld2FyZDE=\n""}}, ""_identifier"": ""Th7MpTaRZVRYnPiabds81Y"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""MDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwU3Rld2FyZDE=\n""}, ""_verkey"": ""7TYfekw4GUagBnBVCqPjiC""}, 1502385714960301]}, ""py/seq"": [{""py/id"": 68}, 1502385714960301]}, ""CzkavE58zgX7rUMrzSinLr"": {""py/object"": ""plenum.client.wallet.IdData"", ""py/newargs"": {""py/tuple"": [{""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 65}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""NjEyNGM3YmQxZmVjYzVkYmI4ZDYyODNkOTljYThjYWJmMGM4ZTU0NDkwMzE1NTM4OTI5NmJhNmE3\nMjYxYTJkZQ==\n""}, ""keyhex"": {""py/b64"": ""NDE2MzZkNjUzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAzMDMwMzAz\nMDMwMzAzMA==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""YSTHvR/sxdu41ig9mcqMq/DI5USQMVU4kpa6anJhot4=\n""}}, ""_signing_key"": {""py/b64"": ""QWNtZTAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDBhJMe9H+zF27jWKD2Zyoyr8MjlRJAxVTiS\nlrpqcmGi3g==\n""}, ""_seed"": {""py/b64"": ""QWNtZTAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}}, ""verraw"": {""py/b64"": ""YSTHvR/sxdu41ig9mcqMq/DI5USQMVU4kpa6anJhot4=\n""}, ""keyraw"": {""py/b64"": ""QWNtZTAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}}, ""_identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""QWNtZTAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDA=\n""}, ""_verkey"": ""WjXEvZ9xj4Tz9sLtzf7HVP""}, 1502387801276699]}, ""py/seq"": [{""py/id"": 63}, 1502387801276699]}}, ""_attributes"": {""json://{\""py/tuple\"": [\""73563\"", \""CzkavE58zgX7rUMrzSinLr\"", \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:6666\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""73563"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""endpoint\"", null, \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": null, ""origin"": null, ""encKey"": null, ""name"": ""endpoint"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""endpoint\"", null, \""ULtgFQJe6bjiFbs7ke3NJD\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": null, ""origin"": null, ""encKey"": null, ""name"": ""endpoint"", ""seqNo"": null, ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""a0641\"", \""CzkavE58zgX7rUMrzSinLr\"", \""ULtgFQJe6bjiFbs7ke3NJD\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""a0641"", ""seqNo"": null, ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""45884\"", \""ULtgFQJe6bjiFbs7ke3NJD\"", \""ULtgFQJe6bjiFbs7ke3NJD\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.202:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""origin"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""encKey"": null, ""name"": ""45884"", ""seqNo"": null, ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ledgerStore"": {""py/object"": ""indy_client.client.wallet.attribute.LedgerStore"", ""py/enumvalue"": 4}}, ""json://{\""py/tuple\"": [\""917b5\"", \""CzkavE58zgX7rUMrzSinLr\"", \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.203:6666\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""917b5"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""4f3d1\"", \""ULtgFQJe6bjiFbs7ke3NJD\"", \""ULtgFQJe6bjiFbs7ke3NJD\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""origin"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""encKey"": null, ""name"": ""4f3d1"", ""seqNo"": null, ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""881bb\"", \""CzkavE58zgX7rUMrzSinLr\"", \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:6666\"", \""pubkey\"": \""C5eqjU7NMVMGGfGfx2ub- vX5H9X346bQt5qeziVAo3naQ\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""881bb"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}, ""json://{\""py/tuple\"": [\""6db7a\"", \""CzkavE58zgX7rUMrzSinLr\"", \""CzkavE58zgX7rUMrzSinLr\""]}"": {""py/object"": ""indy_client.client.wallet.attribute.Attribute"", ""value"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.203:6666\"", \""pubkey\"": \""C5eqjU7NMVMGGfGfx2ub- vX5H9X346bQt5qeziVAo3naQ\""}}"", ""origin"": ""CzkavE58zgX7rUMrzSinLr"", ""encKey"": null, ""name"": ""6db7a"", ""seqNo"": null, ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""ledgerStore"": {""py/id"": 2}}}, ""idsToSigners"": {""ULtgFQJe6bjiFbs7ke3NJD"": {""py/id"": 73}, ""JYeHd6Zn3zFo1UbNVBd6U1"": {""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 79}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""OGUxNjY0OGM3Y2IzYWMxNDMzNTc2MmM1YzVhYTkwZDJkM2I1ODY2NGExOTkyNGM2YWUzNmM1ODQ1\nZDE1MTg4OA==\n""}, ""keyhex"": {""py/b64"": ""ZTFlZmRjYzRmNmJkN2M4ZjhmMTc2MGFiNTkwY2EzMjllNGJjYTYzNTU4M2E5ZDg5NjRkNDljNTJh\nYTRhM2Y4ZA==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""jhZkjHyzrBQzV2LFxaqQ0tO1hmShmSTGrjbFhF0VGIg=\n""}}, ""_signing_key"": {""py/b64"": ""4e/cxPa9fI+PF2CrWQyjKeS8pjVYOp2JZNScUqpKP42OFmSMfLOsFDNXYsXFqpDS07WGZKGZJMau\nNsWEXRUYiA==\n""}, ""_seed"": {""py/b64"": ""4e/cxPa9fI+PF2CrWQyjKeS8pjVYOp2JZNScUqpKP40=\n""}}, ""verraw"": {""py/b64"": ""jhZkjHyzrBQzV2LFxaqQ0tO1hmShmSTGrjbFhF0VGIg=\n""}, ""keyraw"": {""py/b64"": ""4e/cxPa9fI+PF2CrWQyjKeS8pjVYOp2JZNScUqpKP40=\n""}}, ""_identifier"": ""JYeHd6Zn3zFo1UbNVBd6U1"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""4e/cxPa9fI+PF2CrWQyjKeS8pjVYOp2JZNScUqpKP40=\n""}, ""_verkey"": ""T9HBHeNSXBXZCBB8GrgjFm""}, ""Th7MpTaRZVRYnPiabds81Y"": {""py/id"": 68}, ""Siga5PyLFTZdpupPUXogjt"": {""py/object"": ""plenum.common.signer_did.DidSigner"", ""sk"": {""py/id"": 83}, ""naclSigner"": {""py/object"": ""stp_core.crypto.nacl_wrappers.Signer"", ""verhex"": {""py/b64"": ""ZDA0NjU4ZGNhMDQ4MjYyNjQ0MmNhZGFiYzZjZWNlMjM0ODc2YTY0MzhkNzBlNWIzNGQ4MTlmZmFj\nODY2MmVlZA==\n""}, ""keyhex"": {""py/b64"": ""YWJlZmEzOGNmYjVkYmYzMjljNTZjMjI4YmEzNjAzMzZjNmY2YWJjZWE0MjZlMDFlMTVkZTNiZGU1\nNjUzYjUxMQ==\n""}, ""key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.SigningKey"", ""verify_key"": {""py/object"": ""stp_core.crypto.nacl_wrappers.VerifyKey"", ""_key"": {""py/b64"": ""0EZY3KBIJiZELK2rxs7OI0h2pkONcOWzTYGf+shmLu0=\n""}}, ""_signing_key"": {""py/b64"": ""q++jjPtdvzKcVsIoujYDNsb2q86kJuAeFd473lZTtRHQRljcoEgmJkQsravGzs4jSHamQ41w5bNN\ngZ/6yGYu7Q==\n""}, ""_seed"": {""py/b64"": ""q++jjPtdvzKcVsIoujYDNsb2q86kJuAeFd473lZTtRE=\n""}}, ""verraw"": {""py/b64"": ""0EZY3KBIJiZELK2rxs7OI0h2pkONcOWzTYGf+shmLu0=\n""}, ""keyraw"": {""py/b64"": ""q++jjPtdvzKcVsIoujYDNsb2q86kJuAeFd473lZTtRE=\n""}}, ""_identifier"": ""Siga5PyLFTZdpupPUXogjt"", ""_alias"": null, ""abbreviated"": true, ""seed"": {""py/b64"": ""q++jjPtdvzKcVsIoujYDNsb2q86kJuAeFd473lZTtRE=\n""}, ""_verkey"": ""9wzQSoSNbLwRcNz9JkBFME""}, ""CzkavE58zgX7rUMrzSinLr"": {""py/id"": 63}}, ""_prepared"": {""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502387001630568]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""cfbec5716f611b627475f6a9ab69415630a3244a535f9cadd4fe196705bb3e09"", ""reqId"": 1502387001630568, ""signature"": ""SC1JYwuXnpruhGefBZKCyBvCESmAP9vx8SfUWPPmoR1NH2LDHQYj5XV78zBMCEFAXwuZdHmkpEH6Lu35kuxzMCZ"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""endpoint"", null, ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502385870898879]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""f2c1c5733913f633e7fc58d5b2ec52859979149cdd06e10b578d162c01d25862"", ""reqId"": 1502385870898879, ""signature"": ""5A2BxVk8EowuBT9TKYKWhck9Ng3Bk7Cwo8ego36aWEc4NNx5hNeXwzu37q1FhvmJwZ6fDrRnKvepjCQHXLAL1DbN"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""4f3d1"", ""ULtgFQJe6bjiFbs7ke3NJD"", ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502387071423304]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""45d33c68b9aa557d7b1300656905a446d9e1924e51f55a07e125396202024e37"", ""reqId"": 1502387071423304, ""signature"": ""2dZMNC37ihe7EXjVxk6s1FENZ6Qr15i6TTk9vyT4kEsYig1D3QQLACrgz88vFwoaiycameMseateEEFPhxvFiarZ"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""105"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386049567645]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""079b8ed2360cc6a2c686587a613f8c1109b1941154bcee5fcece4ad2464d7f40"", ""reqId"": 1502386049567645, ""signature"": ""2RNPTPq3K2rNb4MFmoYJEza3n7tmLaz696nRxEegASoyYdJDKNGvCAJLCCFYJvAxAh7Y66duQ7fX2byZWE3EWZAc"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""endpoint"", null, ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502387057277920]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""1cefcc959335319b7f9c5527e5f4dcbb49a7456ebed2c24fd33cc06ab045bbcb"", ""reqId"": 1502387057277920, ""signature"": ""2yzWAuxduX6dQfw1nJFafU6XTeFYDXqWnxyNrdfFM8cammiz4P6YpoKbWbq7kDVA22FS1Hz13DfLdJ5PEnXJZehs"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.203:6666\""}}"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""917b5"", ""CzkavE58zgX7rUMrzSinLr"", ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502385848758045]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""6d45682720c304d825573cd6b9c60bc47d95eda3a70987a4fc410bd6afeadc44"", ""reqId"": 1502385848758045, ""signature"": ""3NLdp4qD15N2CetMjGtrmpQWDKx6ycVVaRtLZ3gKMmzLzxBujvsqQutA7yts74pJPtRodaEPy2w5FvpS7yBzNsr"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""a0641"", ""CzkavE58zgX7rUMrzSinLr"", ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502387071424365]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""0036694829240ca13b5a9108c2f16fe60213c30f054c9b335b35b95d14dec31c"", ""reqId"": 1502387071424365, ""signature"": ""4bf8VGMVGq6JtWeFXdvD4NhdAMseuZdxnvvxw6QaodiGKA54yRxfShbDG9ff2xrDUQHCPJ1PuYMwPmDanx1gpSoB"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""endpoint"", null, ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386144574978]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""ca879f3ce42853d26300fae03dc39a5c27cc3e14e8f1578418729de3d19bcf4b"", ""reqId"": 1502386144574978, ""signature"": ""2u2C32ww9GkdBj78haTzKLvgaU4PqJ2N8VYmmoALSpZT5pTgvaGjgFniRPHd1DSwv8MVyt4vX8m26SgL1zDJVJVY"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""endpoint"", null, ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""Th7MpTaRZVRYnPiabds81Y\"", 1502385611413187]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""949dd184333687d9e81d853dc0d981bfc87f56a1757fd4556e2ad2983573f0ea"", ""reqId"": 1502385611413187, ""signature"": ""5vpkHbSFdCJrRbFXe6sAKW8S1zB2QXqisp56gdFsPXRMrx7bD8Z5Q8yLpjcyszTsDePqy1JELgGHAvwZEPU8KvR4"", ""identifier"": ""Th7MpTaRZVRYnPiabds81Y"", ""operation"": {""role"": ""101"", ""type"": ""1"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""verkey"": ""~5kh3FB4H3NKq7tUDqeqHc1""}}}, ""ULtgFQJe6bjiFbs7ke3NJD""]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502385732035030]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""52c6dbfc7fdf04bddf4e6b0bb43d7316edcb2fc820eaab4c2cada0fe34b310da"", ""reqId"": 1502385732035030, ""signature"": ""4RyhbLSRPpahFjk5pthh3tM3de49G2fz77oP42VyRp4DWwMHWbXrRkD6SYVxGGgYaaa8Ep8xhMEQ2QgvDNmHkaDm"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.203:6666\"", \""pubkey\"": \""C5eqjU7NMVMGGfGfx2ub- vX5H9X346bQt5qeziVAo3naQ\""}}"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""6db7a"", ""CzkavE58zgX7rUMrzSinLr"", ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386097385267]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""0e116050b139e82912740bca170ac8b550a211c34f9bfc52ddd82bdf8a10460d"", ""reqId"": 1502386097385267, ""signature"": ""3GBVvm55r21RhdYYJS1FYKE67yxo9Dokiv4XePh2DTpfETKRKqi3Lap8BiZUcicwVFKi4RTYZi9sfC75iLuNvFWe"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""108"", ""origin"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""ref"": 15, ""signature_type"": ""CL""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386050220665]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""d3f84e2352faca0109598e86e8eb74d5fe4039939b88980a00af24bd26e95cab"", ""reqId"": 1502386050220665, ""signature"": ""3bqWZafGMZY384S5Zi2ugEpamTWamezPfLtHVBW7DH6Hgntpd1KTuLjmLoJLw8nh3f6kUV2w2NAgLuQn5ZEceMvP"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""105"", ""dest"": ""JYeHd6Zn3zFo1UbNVBd6U1""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502385681114223]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""c5c275f4963b859d3ca5f84e15e8f09b7bf7ec1fe7e615131daace478b8dee3e"", ""reqId"": 1502385681114223, ""signature"": ""38jKR2T4pQ7ckYqKriuZF2gGoxbr928FCZtMDns5zNVX35DNWFZ3EWNX7pBSiQKa58928oTq4sFFe5h5v6qojAW1"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""10.0.0.202:5555\"", \""pubkey\"": \""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z\""}}"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""45884"", ""ULtgFQJe6bjiFbs7ke3NJD"", ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502385835239707]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""4bc95d41076677bbfd40407bba1d8ddb69818a79d6a9a24aa57daf0d06ed3770"", ""reqId"": 1502385835239707, ""signature"": ""5R1sAupQwqoee5muMmmud94KWgLvkqkPHxRKj7jPu4VQ5pDCZuvPPpXJXYYSNrtgsDvFurXGg9Jj82S8hEM1H6YH"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:6666\"", \""pubkey\"": \""C5eqjU7NMVMGGfGfx2ub- vX5H9X346bQt5qeziVAo3naQ\""}}"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""881bb"", ""CzkavE58zgX7rUMrzSinLr"", ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386188150095]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""0e98ffb463973aa6873ca2cbb21b724b7c3711e30dc3f0177c42285ec022763e"", ""reqId"": 1502386188150095, ""signature"": ""3wB4HxjzsPhA74yv4Df4SZBdQYX7s8dAkhyKbdgWSfoMxyQo6tyFPmaHLb3AcE3r7rcngvLdQy9WbTQhxj3HYhBC"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""endpoint"", null, ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502385899839362]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""e6b83a2dae024a32b5f3c057d3e3f2357291b8fc0e4dae481907c2a9f5e6d1d7"", ""reqId"": 1502385899839362, ""signature"": ""SySAHLvfYw9epanGaKhWsYGWNx7UJ99LTsum4izbgwPxLiMQkS6NhjDMfWMfeoD96rewiP22WJBRkSe2DyfvbPU"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""104"", ""raw"": ""endpoint"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, {""py/tuple"": [""endpoint"", null, ""ULtgFQJe6bjiFbs7ke3NJD""]}]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386144573959]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""73a605a704302242669e58cd2f28f58176ab2ed51783f8b3fcb6a06b2fa94fae"", ""reqId"": 1502386144573959, ""signature"": ""3Jz114XGYzyiSMXijXf9j8ttoZh3CsmbjMVwQj2KfFRuVjHosCBsVoPWeJtJfn4gK5MbpmScpyTu4VVFD2qNscWf"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""105"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386085472327]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""cd0692a09506d71387a4f034887e6ef266dc7cf45591f2b9ed3885589ee7d689"", ""reqId"": 1502386085472327, ""signature"": ""5j57ZRTFhD23fS3dHtYxEvUhK7HzA5UVrbmSszgt2JCw2Dyg228fTaiEtqPDgo7ybdKxXkGjyTfzQPe7c5wVgW9G"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""107"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""data"": {""name"": ""Transcript"", ""version"": ""1.2""}}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502387001627354]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""adcffa4444661aaa7e0a35653126b616a1941fae3bc66e8fcafa663144a42d18"", ""reqId"": 1502387001627354, ""signature"": ""ybsbW5JHKn9JGKgbGeKEajUhAnCHMixEWuk9E9YUD7r8xgC5EaDaRhpuASSeyfFoymY65Gbmd3qcCNYuk7VuSrA"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""105"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, null]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502386049566532]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""3a7bc6b517611dcfdf704b6903ddabec3507d4ecc272d328493b108ed04bde00"", ""reqId"": 1502386049566532, ""signature"": ""4ghzAiyLavPqsrEr6bYUZMyg87xYtHZ38vQHZrDU3CnJVTXBx9VXRM2qLsPwD8mEN86pMVAT3KdVaD2NJt8VhvgV"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""type"": ""105"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD""}}}, null]}, ""json://{\""py/tuple\"": [\""CzkavE58zgX7rUMrzSinLr\"", 1502387801276699]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""39ee07b502bd4d3c6f32b6d2beab3795e4312690514dd57288a3bac7358d82c4"", ""reqId"": 1502387801276699, ""signature"": ""2ByXW61ND5bxZDF9nV593ZoYWmShj7Ld1qYCyEJ6jthoE1BqDcuerUSqc4y1NCPuQy23BUGbT1BvRmPt9EVJfugW"", ""identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""operation"": {""type"": ""100"", ""raw"": ""{\""endpoint\"": {\""ha\"": \""127.0.0.1:6666\""}}"", ""dest"": ""CzkavE58zgX7rUMrzSinLr""}}}, {""py/tuple"": [""73563"", ""CzkavE58zgX7rUMrzSinLr"", ""CzkavE58zgX7rUMrzSinLr""]}]}, ""json://{\""py/tuple\"": [\""Th7MpTaRZVRYnPiabds81Y\"", 1502385714960301]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""eaea017f0c21a8ff39a880853922748895a8495e61b4a51822a73dff7831c028"", ""reqId"": 1502385714960301, ""signature"": ""5AJvDyr6N4enKP31cyXyojoph1KstDGw9VkfNvGdHyY8b4ruEDHE8LU7JEvwxjwLyEVcEcu7j4QMnykjuF63PqA7"", ""identifier"": ""Th7MpTaRZVRYnPiabds81Y"", ""operation"": {""role"": ""101"", ""type"": ""1"", ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""verkey"": ""~WjXEvZ9xj4Tz9sLtzf7HVP""}}}, ""CzkavE58zgX7rUMrzSinLr""]}, ""json://{\""py/tuple\"": [\""Th7MpTaRZVRYnPiabds81Y\"", 1502385655248947]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""d1095621d406da7a2e95d744b8ba4016db73b75e3fe0faaf4a5fa82b94e065f2"", ""reqId"": 1502385655248947, ""signature"": ""3pY9d3kPfaf9g4L7WoeJ7L7eKQ86SRfzJfGfy4yZKn41WXHwvFdtAsGM7ne96GKUtbfJVknvbeCDo6AHxYX9j5Qm"", ""identifier"": ""Th7MpTaRZVRYnPiabds81Y"", ""operation"": {""role"": ""101"", ""type"": ""1"", ""dest"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""verkey"": ""~5kh3FB4H3NKq7tUDqeqHc1""}}}, ""ULtgFQJe6bjiFbs7ke3NJD""]}, ""json://{\""py/tuple\"": [\""ULtgFQJe6bjiFbs7ke3NJD\"", 1502385695560631]}"": {""py/tuple"": [{""py/object"": ""indy_common.types.Request"", ""py/state"": {""digest"": ""74b080a5afc1beff66f42a87af9c4fcd032f863197c74883e7d302a8b0f18852"", ""reqId"": 1502385695560631, ""signature"": ""4myAj7GnGrUqb9WKtMbTD19rNvX1ToXZmWv4K7MZQP63DdYYzvW9b5n6mzYKnkdnUUQvPvdkweuUBVTJSMdy6bup"", ""identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""operation"": {""role"": ""101"", ""type"": ""1"", ""dest"": ""CzkavE58zgX7rUMrzSinLr"", ""verkey"": ""~WjXEvZ9xj4Tz9sLtzf7HVP""}}}, ""CzkavE58zgX7rUMrzSinLr""]}}, ""_connections"": {""py/reduce"": [{""py/type"": ""collections.OrderedDict""}, {""py/tuple"": []}, null, null, {""py/tuple"": [{""py/tuple"": [""Faber College"", {""proofRequests"": [], ""internalId"": null, ""remoteEndPoint"": {""py/tuple"": [""127.0.0.1"", 5555]}, ""request_nonce"": ""b1134a647eb818069c089e7694f63e6d"", ""name"": ""Faber College"", ""connection_status"": ""Accepted"", ""trustAnchor"": ""Faber College"", ""verifiedClaimProofs"": [], ""py/object"": ""indy_client.client.wallet.connection.Connection"", ""connection_last_sync_no"": null, ""localIdentifier"": ""JYeHd6Zn3zFo1UbNVBd6U1"", ""localVerkey"": ""~T9HBHeNSXBXZCBB8GrgjFm"", ""remotePubkey"": ""5hmMA64DDQz5NzGJNVtRzNwpkZxktNQds21q3Wxxa62z"", ""availableClaims"": [{""py/object"": ""anoncreds.protocol.types.AvailableClaim"", ""py/newargs"": {""py/tuple"": [""Transcript"", ""1.2"", ""ULtgFQJe6bjiFbs7ke3NJD""]}, ""py/seq"": [""Transcript"", ""1.2"", ""ULtgFQJe6bjiFbs7ke3NJD""]}], ""connection_last_synced"": {""py/object"": ""datetime.datetime"", ""__reduce__"": [{""py/type"": ""datetime.datetime""}, [""B+EIChQbHQvKxQ==""]]}, ""_remoteVerkey"": ""~5kh3FB4H3NKq7tUDqeqHc1"", ""remoteIdentifier"": ""ULtgFQJe6bjiFbs7ke3NJD""}]}, {""py/tuple"": [""Acme Corp"", {""proofRequests"": [{""py/object"": ""anoncreds.protocol.types.ProofRequest"", ""attributes"": {""py/reduce"": [{""py/type"": ""collections.OrderedDict""}, {""py/tuple"": []}, null, null, {""py/tuple"": [{""py/tuple"": [""first_name"", ""string""]}, {""py/tuple"": [""last_name"", ""string""]}, {""py/tuple"": [""phone_number"", ""string""]}, {""py/tuple"": [""degree"", ""Bachelor of Science, Marketing""]}, {""py/tuple"": [""status"", ""graduated""]}, {""py/tuple"": [""ssn"", ""123-45-6789""]}]}]}, ""ts"": null, ""version"": ""0.2"", ""verifiableAttributes"": {""777fb1af-a7a0-4f0c-81b8-9e09a8068d16"": {""py/object"": ""anoncreds.protocol.types.AttributeInfo"", ""py/newargs"": {""py/tuple"": [""status"", null, null]}, ""py/seq"": [""status"", null, null]}, ""d5743fcc-d287-4176-a634-3b721d962ea5"": {""py/object"": ""anoncreds.protocol.types.AttributeInfo"", ""py/newargs"": {""py/tuple"": [""ssn"", null, null]}, ""py/seq"": [""ssn"", null, null]}, ""4de5205f-720f-49f0-8397-0576875d904b"": {""py/object"": ""anoncreds.protocol.types.AttributeInfo"", ""py/newargs"": {""py/tuple"": [""degree"", null, null]}, ""py/seq"": [""degree"", null, null]}}, ""nonce"": 1871218719015472932666560146158750511756, ""seqNo"": null, ""name"": ""Job-Application"", ""predicates"": {}, ""fulfilledByClaims"": [{""py/tuple"": [{""py/id"": 12}, {""py/id"": 14}, {""py/reduce"": [{""py/type"": ""collections.OrderedDict""}, {""py/tuple"": []}, null, null, {""py/tuple"": [{""py/tuple"": [""student_name"", ""Alice Garcia""]}, {""py/tuple"": [""ssn"", ""123-45-6789""]}, {""py/tuple"": [""degree"", ""Bachelor of Science, Marketing""]}, {""py/tuple"": [""year"", ""2015""]}, {""py/tuple"": [""status"", ""graduated""]}]}]}]}], ""selfAttestedAttrs"": {}}], ""internalId"": null, ""remoteEndPoint"": {""py/tuple"": [""10.0.0.203"", 6666]}, ""request_nonce"": ""57fbf9dc8c8e6acde33de98c6d747b28c"", ""name"": ""Acme Corp"", ""connection_status"": null, ""trustAnchor"": ""Acme Corp"", ""verifiedClaimProofs"": [], ""py/object"": ""indy_client.client.wallet.connection.Connection"", ""connection_last_sync_no"": null, ""localIdentifier"": ""Siga5PyLFTZdpupPUXogjt"", ""localVerkey"": ""~9wzQSoSNbLwRcNz9JkBFME"", ""remotePubkey"": ""C5eqjU7NMVMGGfGfx2ubvX5H9X346bQt5qeziVAo3naQ"", ""availableClaims"": [], ""connection_last_synced"": {""py/object"": ""datetime.datetime"", ""__reduce__"": [{""py/type"": ""datetime.datetime""}, [""B+EIChQsHwmWIA==""]]}, ""_remoteVerkey"": ""~WjXEvZ9xj4Tz9sLtzf7HVP"", ""remoteIdentifier"": ""CzkavE58zgX7rUMrzSinLr""}]}]}]}, ""replyHandler"": {}, ""knownIds"": {""ULtgFQJe6bjiFbs7ke3NJD"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": null, ""_identifier"": ""ULtgFQJe6bjiFbs7ke3NJD"", ""_verkey"": null}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": null}, ""JYeHd6Zn3zFo1UbNVBd6U1"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": null, ""_identifier"": ""JYeHd6Zn3zFo1UbNVBd6U1"", ""_verkey"": null}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": null}, ""CzkavE58zgX7rUMrzSinLr"": {""py/object"": ""indy_common.identity.Identity"", ""identity"": {""py/object"": ""plenum.common.signer_did.DidIdentity"", ""abbreviated"": null, ""_identifier"": ""CzkavE58zgX7rUMrzSinLr"", ""_verkey"": null}, ""last_synced"": null, ""seqNo"": null, ""trustAnchor"": null, ""_role"": null}}, ""lastKnownSeqs"": {}, ""env"": ""no-env"", ""classver/indy_client.client.wallet.wallet.Wallet"": 1}",,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/142102085,https://github.com/hyperledger/indy-node/pull/351#discussion_r142102085,spivachuk
https://github.com/hyperledger/indy-node/pull/351,https://github.com/hyperledger/indy-node/pull/351,Created INDY-885 for updating documentation beyond GitHub repositories.,1e51d32994b4a17590620fba8c54cd388d2dbeef,2017-10-02 10:45:34,142106481,"@@ -1,16 +1,16 @@
-# Sovrin -- identity for all",1,2017-10-02 15:32:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/142106481,https://github.com/hyperledger/indy-node/pull/351#discussion_r142106481,spivachuk
https://github.com/hyperledger/indy-node/pull/343,https://github.com/hyperledger/indy-node/pull/343,Why config.LOOPER_DEBUG is not used here?,854997698c3478dd332c92841e331c5a1205844b,2017-09-12 12:41:58,138334948,"@@ -392,7 +392,7 @@ def buildCoros(coroFunc, corosArgs):
     clientPoll = ClientPoll(args.clientsListFilePath,
                             args.numberOfClients, args.numberOfClientsToSkip)
 
-    with Looper(debug=True) as looper:
+    with Looper() as looper:",5,2017-09-12 12:42:10,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/138334948,https://github.com/hyperledger/indy-node/pull/343#discussion_r138334948,andkononykhin
https://github.com/hyperledger/indy-node/pull/343,https://github.com/hyperledger/indy-node/pull/343,"Because we decided to use default debug value of Looper class (False) or use False explicitly for testing functionality. As I understand, 'scripts/load_test.py' script is related to tests.",854997698c3478dd332c92841e331c5a1205844b,2017-09-12 14:29:46,138364956,"@@ -392,7 +392,7 @@ def buildCoros(coroFunc, corosArgs):
     clientPoll = ClientPoll(args.clientsListFilePath,
                             args.numberOfClients, args.numberOfClientsToSkip)
 
-    with Looper(debug=True) as looper:
+    with Looper() as looper:",5,2017-09-12 14:29:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/138364956,https://github.com/hyperledger/indy-node/pull/343#discussion_r138364956,sergey-shilov
https://github.com/hyperledger/indy-node/pull/338,https://github.com/hyperledger/indy-node/pull/338,"Is there a guarantee that `res` is always a `list` and not a subclass of `list`? If not then replace by `assert isinstance(res, list)`",5fa2f762d479e68a8e02e2b59b94b4c2829284d8,2017-09-06 15:17:37,137299285,"@@ -45,3 +45,12 @@ def testMigrateTimesOut(monkeypatch):
 
     with pytest.raises(TimeoutError):
         migration_tool.migrate(TEST_VERSION, TEST_NEW_VERSION, TEST_TIMEOUT)
+
+def testGetMigrationScripts():
+    try:
+        res = migration_tool._get_migration_scripts(migration_tool._get_current_platform())
+    except Exception as e:
+        pytest.fail(""Unexpected error: {}"".format(e))
+    else:
+        assert type(res) is list",11,2017-09-06 15:17:37,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/137299285,https://github.com/hyperledger/indy-node/pull/338#discussion_r137299285,lovesh
https://github.com/hyperledger/indy-node/pull/338,https://github.com/hyperledger/indy-node/pull/338,"yes, currently list contructor is used directly https://github.com/andkononykhin/indy-node/blob/5fa2f762d479e68a8e02e2b59b94b4c2829284d8/sovrin_node/utils/migration_tool.py#L76
I think it could be adjusted in future if something changed and test fails.",5fa2f762d479e68a8e02e2b59b94b4c2829284d8,2017-09-06 15:22:21,137300657,"@@ -45,3 +45,12 @@ def testMigrateTimesOut(monkeypatch):
 
     with pytest.raises(TimeoutError):
         migration_tool.migrate(TEST_VERSION, TEST_NEW_VERSION, TEST_TIMEOUT)
+
+def testGetMigrationScripts():
+    try:
+        res = migration_tool._get_migration_scripts(migration_tool._get_current_platform())
+    except Exception as e:
+        pytest.fail(""Unexpected error: {}"".format(e))
+    else:
+        assert type(res) is list",11,2017-09-06 15:22:21,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/137300657,https://github.com/hyperledger/indy-node/pull/338#discussion_r137300657,andkononykhin
https://github.com/hyperledger/indy-node/pull/299,https://github.com/hyperledger/indy-node/pull/299,Why do we check patch versions only? Please have tests for comparison of different major and minor versions as well.,7f6558c9938c1dc214134fec7abe6f023889ccc7,2017-08-11 09:38:48,132649137,"@@ -3,12 +3,10 @@
 
 
 def testVersions():
-    assert Upgrader.isVersionHigher('0.0.5', '0.0.6')
-    assert not Upgrader.isVersionHigher('0.0.9', '0.0.8')
-    assert Upgrader.isVersionHigher('0.0.9', '0.1.0')
-    assert Upgrader.isVersionHigher('0.20.30', '1.0.0')
-    assert Upgrader.isVersionHigher('1.3.19', '1.3.20')
-    versions = ['0.0.1', '0.10.11', '0.0.10', '0.0.2',
-                '1.9.0', '9.10.0', '9.1.0']
-    assert Upgrader.versionsDescOrder(versions) == \
-           ['9.10.0', '9.1.0', '1.9.0', '0.10.11', '0.0.10', '0.0.2', '0.0.1']
+    assert Upgrader.compareVersions('0.0.5', '0.0.6') == 1",,2017-08-11 10:10:17,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132649137,https://github.com/hyperledger/indy-node/pull/299#discussion_r132649137,ashcherbakov
https://github.com/hyperledger/indy-node/pull/298,https://github.com/hyperledger/indy-node/pull/298,Is it possible to specify the new seed from the CLI?,0e233a119cea2e5f7a69d882c38f5d5ccd01e1c6,2017-08-11 08:18:30,132635389,"@@ -1344,6 +1347,32 @@ def _reqClaim(self, matchedVars):
                 self._printNoClaimFoundMsg()
             return True
 
+    def _change_current_key_req(self, matchedVars):
+        if matchedVars.get('change_ckey') == changeKeyCmd.id:
+            if not self.canMakeSovrinRequest:
+                return True
+            self._change_current_key()
+            return True
+
+    def _change_current_key(self, seed=None):",,2017-08-11 09:32:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132635389,https://github.com/hyperledger/indy-node/pull/298#discussion_r132635389,ashcherbakov
https://github.com/hyperledger/indy-node/pull/298,https://github.com/hyperledger/indy-node/pull/298,No for the moment,0e233a119cea2e5f7a69d882c38f5d5ccd01e1c6,2017-08-11 08:31:11,132637549,"@@ -1344,6 +1347,32 @@ def _reqClaim(self, matchedVars):
                 self._printNoClaimFoundMsg()
             return True
 
+    def _change_current_key_req(self, matchedVars):
+        if matchedVars.get('change_ckey') == changeKeyCmd.id:
+            if not self.canMakeSovrinRequest:
+                return True
+            self._change_current_key()
+            return True
+
+    def _change_current_key(self, seed=None):",,2017-08-11 09:32:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132637549,https://github.com/hyperledger/indy-node/pull/298#discussion_r132637549,dsurnin
https://github.com/hyperledger/indy-node/pull/297,https://github.com/hyperledger/indy-node/pull/297,`iter` is a key word. Should it be `idr`?,86e6e81d9a37a2e473fbdba4eb8112fc676128eb,2017-08-11 08:40:17,132638973,"@@ -73,10 +73,12 @@ def get(self, idr, isCommitted=True):
         else:
             # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
             # in reverse to get the latest value
-            for _, cache in reversed(self.currentBatchOps):
-                if idr in cache:
-                    value = cache[idr]
-                    break;
+            for iter, cache in reversed(self.currentBatchOps):",,2017-08-11 13:43:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132638973,https://github.com/hyperledger/indy-node/pull/297#discussion_r132638973,ashcherbakov
https://github.com/hyperledger/indy-node/pull/297,https://github.com/hyperledger/indy-node/pull/297,How is it related to batching? Do we send commands in the same batch?,86e6e81d9a37a2e473fbdba4eb8112fc676128eb,2017-08-11 08:43:19,132639486,"@@ -282,3 +282,42 @@ def testSend2NymsSucceedsWhenBatched(
     do('send GET_NYM dest={dest}',
         mapper=parameters, expect=CURRENT_VERKEY_FOR_NYM, within=2)
 
+def test_send_different_nyms_succeeds_when_batched(",,2017-08-11 13:43:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132639486,https://github.com/hyperledger/indy-node/pull/297#discussion_r132639486,ashcherbakov
https://github.com/hyperledger/indy-node/pull/297,https://github.com/hyperledger/indy-node/pull/297,Why the tests is called `fails`? It looks like the test checks a positive case.,86e6e81d9a37a2e473fbdba4eb8112fc676128eb,2017-08-11 08:44:05,132639593,"@@ -255,7 +255,7 @@ def testNewKeyChangesWalletsDefaultId(be, do, poolNodesStarted, poolTxnData,
        expect=[""Nym {} added"".format(idr)])
 
 
-def testSend2NymsSucceedsWhenBatched(
+def test_send_same_nyms_fails_when_batched(",,2017-08-11 13:43:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132639593,https://github.com/hyperledger/indy-node/pull/297#discussion_r132639593,ashcherbakov
https://github.com/hyperledger/indy-node/pull/297,https://github.com/hyperledger/indy-node/pull/297,I've changed that.,86e6e81d9a37a2e473fbdba4eb8112fc676128eb,2017-08-11 13:57:49,132691457,"@@ -73,10 +73,12 @@ def get(self, idr, isCommitted=True):
         else:
             # Looking for uncommitted values, iterating over `currentBatchOps and unCommitted`
             # in reverse to get the latest value
-            for _, cache in reversed(self.currentBatchOps):
-                if idr in cache:
-                    value = cache[idr]
-                    break;
+            for iter, cache in reversed(self.currentBatchOps):",,2017-08-11 13:57:49,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132691457,https://github.com/hyperledger/indy-node/pull/297#discussion_r132691457,glowkey
https://github.com/hyperledger/indy-node/pull/297,https://github.com/hyperledger/indy-node/pull/297,"there are 2 requests, one with ""entercmd"" and the second with ""do"".  ""entercmd"" doesn't send it to the server so when ""do"" executes it will have both in a batch.  I've entered comments to clarify this.",86e6e81d9a37a2e473fbdba4eb8112fc676128eb,2017-08-11 13:58:46,132691684,"@@ -282,3 +282,42 @@ def testSend2NymsSucceedsWhenBatched(
     do('send GET_NYM dest={dest}',
         mapper=parameters, expect=CURRENT_VERKEY_FOR_NYM, within=2)
 
+def test_send_different_nyms_succeeds_when_batched(",,2017-08-11 13:58:46,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132691684,https://github.com/hyperledger/indy-node/pull/297#discussion_r132691684,glowkey
https://github.com/hyperledger/indy-node/pull/297,https://github.com/hyperledger/indy-node/pull/297,The second request in the batch shouldn't be written (the same behavior as when not batched).  The test verifies this by making sure the first request is what is written.  I've renamed the test to clarify this.,86e6e81d9a37a2e473fbdba4eb8112fc676128eb,2017-08-11 13:59:38,132691882,"@@ -255,7 +255,7 @@ def testNewKeyChangesWalletsDefaultId(be, do, poolNodesStarted, poolTxnData,
        expect=[""Nym {} added"".format(idr)])
 
 
-def testSend2NymsSucceedsWhenBatched(
+def test_send_same_nyms_fails_when_batched(",,2017-08-11 13:59:38,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132691882,https://github.com/hyperledger/indy-node/pull/297#discussion_r132691882,glowkey
https://github.com/hyperledger/indy-node/pull/295,https://github.com/hyperledger/indy-node/pull/295,I think this should be at INFO level,c430c090b4fa414dd4a383265bc0b45610b21ee9,2017-08-10 18:04:24,132526339,"@@ -40,7 +40,7 @@ def bootstrapAgentCli(name, agent, looper, bootstrap, config):
 def runAgentCli(agent, config, looper=None, bootstrap=None):
     def run(looper):
         agent.loop = looper.loop
-        logger.info(""Running {} now (port: {})"".format(agent.name, agent.port))
+        logger.debug(""Running {} now (port: {})"".format(agent.name, agent.port))",,2017-08-14 10:06:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132526339,https://github.com/hyperledger/indy-node/pull/295#discussion_r132526339,ashcherbakov
https://github.com/hyperledger/indy-node/pull/295,https://github.com/hyperledger/indy-node/pull/295,I think this should be at INFO level,c430c090b4fa414dd4a383265bc0b45610b21ee9,2017-08-10 18:04:33,132526378,"@@ -58,7 +58,7 @@ def runAgent(agent, looper=None, bootstrap=None):
     def do_run(looper):
         agent.loop = looper.loop
         looper.add(agent)
-        logger.info(""Running {} now (port: {})"".format(agent.name, agent.port))
+        logger.debug(""Running {} now (port: {})"".format(agent.name, agent.port))",,2017-08-14 10:06:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132526378,https://github.com/hyperledger/indy-node/pull/295#discussion_r132526378,ashcherbakov
https://github.com/hyperledger/indy-node/pull/295,https://github.com/hyperledger/indy-node/pull/295,I think this should be a warning as it is,c430c090b4fa414dd4a383265bc0b45610b21ee9,2017-08-10 18:05:27,132526555,"@@ -118,8 +118,8 @@ def onBatchCommitted(self, stateRoot):
                                             self.unCommitted[0][1].items()])
             self.unCommitted = self.unCommitted[1:]
         else:
-            logger.warning('{} is trying to commit a batch with state root {} '
-                           'but no uncommitted found'.format(self, stateRoot))
+            logger.debug('{} is trying to commit a batch with state root {} '",,2017-08-14 10:06:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132526555,https://github.com/hyperledger/indy-node/pull/295#discussion_r132526555,ashcherbakov
https://github.com/hyperledger/indy-node/pull/295,https://github.com/hyperledger/indy-node/pull/295,Why isn't it an error?,c430c090b4fa414dd4a383265bc0b45610b21ee9,2017-08-10 18:06:05,132526681,"@@ -192,4 +192,4 @@ def getOwnerFor(self, nym, isCommitted=True):
                 return nymData[f.IDENTIFIER.nm]
             else:
                 return nym
-        logger.error('Nym {} not found'.format(nym))",,2017-08-14 10:06:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132526681,https://github.com/hyperledger/indy-node/pull/295#discussion_r132526681,ashcherbakov
https://github.com/hyperledger/indy-node/pull/295,https://github.com/hyperledger/indy-node/pull/295,Why isn't it an error?,c430c090b4fa414dd4a383265bc0b45610b21ee9,2017-08-10 18:06:42,132526812,"@@ -385,7 +385,7 @@ def getAttr(self,
             try:
                 value = self.attributeStore.get(hashed_val)
             except KeyError:
-                logger.error('Could not get value from attribute store for {}'",,2017-08-14 10:06:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132526812,https://github.com/hyperledger/indy-node/pull/295#discussion_r132526812,ashcherbakov
https://github.com/hyperledger/indy-node/pull/295,https://github.com/hyperledger/indy-node/pull/295,"Why isn't it INFO? Do we have INFO level messages for Agents?
The current agents are rather test/demo one, so it makes sense to track some information (present in getting started?) in INFO level",c430c090b4fa414dd4a383265bc0b45610b21ee9,2017-08-10 18:09:51,132527529,"@@ -123,8 +123,8 @@ def _saveWallet(self, wallet: Wallet, contextDir, walletName=None):
             fileName = normalizedWalletFileName(walletName)
             walletFilePath = self.walletSaver.saveWallet(
                 wallet, getWalletFilePath(contextDir, fileName))
-            self.logger.info('Active wallet ""{}"" saved ({})'.
-                             format(walletName, walletFilePath))
+            self.logger.debug('Active wallet ""{}"" saved ({})'.",,2017-08-14 10:06:27,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132527529,https://github.com/hyperledger/indy-node/pull/295#discussion_r132527529,ashcherbakov
https://github.com/hyperledger/indy-node/pull/287,https://github.com/hyperledger/indy-node/pull/287,The test checks merging to an empty link only. Can we also check that merging works for non-empty link (real merging?),a755d8a082175d0590ae64e3b53d30cc4bb957df,2017-08-09 09:54:03,132138957,"@@ -0,0 +1,29 @@
+import pytest
+
+from sovrin_client.agent.agent_issuer import AgentIssuer
+from sovrin_client.agent.agent_prover import AgentProver
+from sovrin_client.agent.agent_verifier import AgentVerifier
+from sovrin_client.agent.walleted import Walleted
+from sovrin_client.client.wallet.connection import Connection
+from sovrin_client.client.wallet.wallet import Wallet
+from sovrin_client.agent.walleted_agent import WalletedAgent
+from plenum.common.constants import NAME, VERSION, ATTRIBUTES, VERIFIABLE_ATTRIBUTES
+
+
+def test_merge_invitation():",,2017-08-09 15:23:57,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/132138957,https://github.com/hyperledger/indy-node/pull/287#discussion_r132138957,ashcherbakov
https://github.com/hyperledger/indy-node/pull/284,https://github.com/hyperledger/indy-node/pull/284,Shouldn't it be INFO level?,d639005346b9705209aac445f5d8daf4659393d1,2017-08-08 11:06:47,131883075,"@@ -255,6 +254,23 @@ def acknowledge_upgrade(self):
             self.startedProcessingReq(*request.key, self.nodestack.name)
             self.send(request)
 
+    def notify_upgrade_start(self):
+        logger.debug('{} is about to be upgraded, '",,2017-08-08 13:03:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/131883075,https://github.com/hyperledger/indy-node/pull/284#discussion_r131883075,ashcherbakov
https://github.com/hyperledger/indy-node/pull/284,https://github.com/hyperledger/indy-node/pull/284,Does the test check that there is no upgrade loop after re-start and catchup?,d639005346b9705209aac445f5d8daf4659393d1,2017-08-08 11:19:46,131885290,"@@ -0,0 +1,42 @@
+from copy import deepcopy
+
+import pytest
+
+from sovrin_node.test import waits
+from stp_core.loop.eventually import eventually
+from plenum.common.constants import VERSION
+
+from sovrin_node.test.upgrade.helper import bumpedVersion, checkUpgradeScheduled, \
+    ensureUpgradeSent
+from sovrin_node.server.upgrade_log import UpgradeLog
+import sovrin_node
+
+
+def test_upgrade_does_not_get_into_loop(looper, tconf, nodeSet,",15,2017-08-08 13:03:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/131885290,https://github.com/hyperledger/indy-node/pull/284#discussion_r131885290,ashcherbakov
https://github.com/hyperledger/indy-node/pull/284,https://github.com/hyperledger/indy-node/pull/284,Looks like this and the tests below do almost the same (just checking for different UPGRADE_SUCCEEDED/UPGRADE_FAILED conditions). Can we have a helper method for this?,d639005346b9705209aac445f5d8daf4659393d1,2017-08-08 11:23:58,131886072,"@@ -0,0 +1,42 @@
+from copy import deepcopy
+
+import pytest
+
+from sovrin_node.test import waits
+from stp_core.loop.eventually import eventually
+from plenum.common.constants import VERSION
+
+from sovrin_node.test.upgrade.helper import bumpedVersion, checkUpgradeScheduled, \
+    ensureUpgradeSent
+from sovrin_node.server.upgrade_log import UpgradeLog
+import sovrin_node
+
+
+def test_upgrade_does_not_get_into_loop(looper, tconf, nodeSet,
+                                             validUpgrade, trustee,
+                                             trusteeWallet, monkeypatch):
+    new_version = bumpedVersion()
+    upgr1 = deepcopy(validUpgrade)
+    upgr1[VERSION] = new_version
+
+    # An upgrade scheduled, it should pass
+    ensureUpgradeSent(looper, trustee, trusteeWallet, upgr1)
+    looper.run(eventually(checkUpgradeScheduled, nodeSet, upgr1[VERSION],
+                          retryWait=1, timeout=waits.expectedUpgradeScheduled()))
+
+    # here we make nodes think they have upgraded successfully
+    monkeypatch.setattr(sovrin_node.__metadata__, '__version__', new_version)
+    for node in nodeSet:
+        # mimicking upgrade start
+        node.upgrader._upgradeLog.appendStarted(0, node.upgrader.scheduledUpgrade[0], node.upgrader.scheduledUpgrade[2])",,2017-08-08 13:03:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/131886072,https://github.com/hyperledger/indy-node/pull/284#discussion_r131886072,ashcherbakov
https://github.com/hyperledger/indy-node/pull/284,https://github.com/hyperledger/indy-node/pull/284,Do we have tests that there is no loop with FORCE=True?,d639005346b9705209aac445f5d8daf4659393d1,2017-08-08 12:16:47,131895204,"@@ -76,6 +80,17 @@ def versionsDescOrder(versions):
         return sorted(versions,
                       key=cmp_to_key(Upgrader.compareVersions))
 
+    @staticmethod
+    def get_upgrade_id(txn):
+        seq_no = txn.get(F.seqNo.name, '')
+        if txn.get(FORCE, None):",46,2017-08-08 13:03:40,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/131895204,https://github.com/hyperledger/indy-node/pull/284#discussion_r131895204,ashcherbakov
https://github.com/hyperledger/indy-node/pull/281,https://github.com/hyperledger/indy-node/pull/281,Do we have a test in CLI reproducing the issue from INDY-378? Does the CLI show exception properly in this case not crashing?,a22e49fe7493a2953ca019edf23a1473def0abc0,2017-08-04 14:35:45,131404199,"@@ -112,14 +114,16 @@ def testGetSchemaBySeqNo(submittedSchemaDefGvt, publicRepo, looper):
 
 
 def testGetSchemaByInvalidSeqNo(submittedSchemaDefGvt, publicRepo, looper):",12,2017-08-04 19:01:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/131404199,https://github.com/hyperledger/indy-node/pull/281#discussion_r131404199,ashcherbakov
https://github.com/hyperledger/indy-node/pull/281,https://github.com/hyperledger/indy-node/pull/281,"Yes, with this fix the CLI shows errors with a wrong `ref` argument properly. Wrote the tests verifying the CLI output in such cases.",a22e49fe7493a2953ca019edf23a1473def0abc0,2017-08-04 19:10:22,131464918,"@@ -112,14 +114,16 @@ def testGetSchemaBySeqNo(submittedSchemaDefGvt, publicRepo, looper):
 
 
 def testGetSchemaByInvalidSeqNo(submittedSchemaDefGvt, publicRepo, looper):",12,2017-08-04 19:10:22,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/131464918,https://github.com/hyperledger/indy-node/pull/281#discussion_r131464918,spivachuk
https://github.com/hyperledger/indy-node/pull/273,https://github.com/hyperledger/indy-node/pull/273,Please add a check for the new syntax in `testSendPoolUpgrade`,1bd23727fc705631098aaf1f55469b432a724dda,2017-08-01 09:31:52,130561157,"@@ -155,7 +155,8 @@
                        '(\s+ (?P<justification_key>justification=)\s*(?P<justification>\""[a-zA-z0-9-_\s]+\"") \s*)? ' \
                        ""(\s+ (?P<schedule_key>schedule=)\s*(?P<schedule>\{{\s*.*\}}) \s*)? "" \
                        ""(\s+ (?P<timeout_key>timeout=)\s*(?P<timeout>[0-9+]+))?)"" \
-                       ""(\s+ (?P<force_key>force=)\s*(?P<force>True|False))?"".format(poolUpgrade=SovrinTransactions.POOL_UPGRADE.name)
+                       ""(\s+ (?P<force_key>force=)\s*(?P<force>True|False))?"" \
+                       ""(\s+ (?P<reinstall_key>reinstall=)\s*(?P<reinstall>True|False))?"".format(poolUpgrade=SovrinTransactions.POOL_UPGRADE.name)",6,2017-08-01 09:43:00,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/130561157,https://github.com/hyperledger/indy-node/pull/273#discussion_r130561157,ashcherbakov
https://github.com/hyperledger/indy-node/pull/273,https://github.com/hyperledger/indy-node/pull/273,please use snake case for methods,1bd23727fc705631098aaf1f55469b432a724dda,2017-08-01 09:35:11,130561867,"@@ -0,0 +1,23 @@
+from copy import deepcopy
+
+import pytest
+
+from sovrin_node.test import waits
+from stp_core.loop.eventually import eventually
+from plenum.common.constants import VERSION, NAME
+
+from sovrin_node.test.upgrade.helper import codeVersion, checkUpgradeScheduled, \
+    ensureUpgradeSent, get_valid_code_hash
+
+
+def testDoNotUpgradeToTheSameVersion(looper, tconf, nodeSet,",,2017-08-01 09:43:00,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/130561867,https://github.com/hyperledger/indy-node/pull/273#discussion_r130561867,ashcherbakov
https://github.com/hyperledger/indy-node/pull/273,https://github.com/hyperledger/indy-node/pull/273,please use snake case for methods,1bd23727fc705631098aaf1f55469b432a724dda,2017-08-01 09:35:15,130561883,"@@ -0,0 +1,24 @@
+from copy import deepcopy
+
+import pytest
+
+from sovrin_node.test import waits
+from stp_core.loop.eventually import eventually
+from plenum.common.constants import VERSION, NAME
+
+from sovrin_node.test.upgrade.helper import codeVersion, checkUpgradeScheduled, \
+    ensureUpgradeSent, get_valid_code_hash
+from sovrin_common.constants import REINSTALL
+
+
+def testDoUpgradeToTheSameVersionIfReinstall(looper, tconf, nodeSet,",,2017-08-01 09:43:00,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/130561883,https://github.com/hyperledger/indy-node/pull/273#discussion_r130561883,ashcherbakov
https://github.com/hyperledger/indy-node/pull/273,https://github.com/hyperledger/indy-node/pull/273,"The test looks pretty same as above. Do we show the same message in CLI in case of re-install True and False?
Can we check that Upgrade is actually scheduled?",1bd23727fc705631098aaf1f55469b432a724dda,2017-08-01 09:38:52,130562621,"@@ -110,4 +110,18 @@ def checksched():
                 assert node.upgrader.scheduledUpgrade
                 assert node.upgrader.scheduledUpgrade[0] == validUpgradeExpForceTrue[VERSION]
 
-    poolNodesStarted.looper.run(eventually(checksched, retryWait=1, timeout=10))
\ No newline at end of file
+    poolNodesStarted.looper.run(eventually(checksched, retryWait=1, timeout=10))
+
+
+def send_reinstall_true_upgrade_cmd(do, expect, upgrade_data):
+    do('send POOL_UPGRADE name={name} version={version} sha256={sha256} '
+       'action={action} schedule={schedule} timeout={timeout} reinstall=True',
+       within=10,
+       expect=expect, mapper=upgrade_data)
+
+
+def send_reinstall_false_upgrade_cmd(do, expect, upgrade_data):
+    do('send POOL_UPGRADE name={name} version={version} sha256={sha256} '
+       'action={action} schedule={schedule} timeout={timeout} reinstall=False',
+       within=10,
+       expect=expect, mapper=upgrade_data)",20,2017-08-01 09:43:00,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/130562621,https://github.com/hyperledger/indy-node/pull/273#discussion_r130562621,ashcherbakov
https://github.com/hyperledger/indy-node/pull/273,https://github.com/hyperledger/indy-node/pull/273,Done,1bd23727fc705631098aaf1f55469b432a724dda,2017-08-01 09:43:12,130563542,"@@ -155,7 +155,8 @@
                        '(\s+ (?P<justification_key>justification=)\s*(?P<justification>\""[a-zA-z0-9-_\s]+\"") \s*)? ' \
                        ""(\s+ (?P<schedule_key>schedule=)\s*(?P<schedule>\{{\s*.*\}}) \s*)? "" \
                        ""(\s+ (?P<timeout_key>timeout=)\s*(?P<timeout>[0-9+]+))?)"" \
-                       ""(\s+ (?P<force_key>force=)\s*(?P<force>True|False))?"".format(poolUpgrade=SovrinTransactions.POOL_UPGRADE.name)
+                       ""(\s+ (?P<force_key>force=)\s*(?P<force>True|False))?"" \
+                       ""(\s+ (?P<reinstall_key>reinstall=)\s*(?P<reinstall>True|False))?"".format(poolUpgrade=SovrinTransactions.POOL_UPGRADE.name)",6,2017-08-01 09:43:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/130563542,https://github.com/hyperledger/indy-node/pull/273#discussion_r130563542,keenondrums
https://github.com/hyperledger/indy-node/pull/273,https://github.com/hyperledger/indy-node/pull/273,Test above waits for an exception raised because the flag is missing. We check the actual sheduling with looper.run(eventually(checkUpgradeScheduled ...,1bd23727fc705631098aaf1f55469b432a724dda,2017-08-01 09:44:03,130563743,"@@ -110,4 +110,18 @@ def checksched():
                 assert node.upgrader.scheduledUpgrade
                 assert node.upgrader.scheduledUpgrade[0] == validUpgradeExpForceTrue[VERSION]
 
-    poolNodesStarted.looper.run(eventually(checksched, retryWait=1, timeout=10))
\ No newline at end of file
+    poolNodesStarted.looper.run(eventually(checksched, retryWait=1, timeout=10))
+
+
+def send_reinstall_true_upgrade_cmd(do, expect, upgrade_data):
+    do('send POOL_UPGRADE name={name} version={version} sha256={sha256} '
+       'action={action} schedule={schedule} timeout={timeout} reinstall=True',
+       within=10,
+       expect=expect, mapper=upgrade_data)
+
+
+def send_reinstall_false_upgrade_cmd(do, expect, upgrade_data):
+    do('send POOL_UPGRADE name={name} version={version} sha256={sha256} '
+       'action={action} schedule={schedule} timeout={timeout} reinstall=False',
+       within=10,
+       expect=expect, mapper=upgrade_data)",20,2017-08-01 09:44:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/130563743,https://github.com/hyperledger/indy-node/pull/273#discussion_r130563743,keenondrums
https://github.com/hyperledger/indy-node/pull/270,https://github.com/hyperledger/indy-node/pull/270,"How do we check that the Node is really demoted?
",4fa116296a9880aaec1541d75cecdd64df0bbe96,2017-07-31 08:38:02,130298112,"@@ -0,0 +1,33 @@
+import pytest
+from plenum.common.signer_did import DidSigner
+from stp_core.crypto.util import randomSeed
+from sovrin_client.test.cli.helper import addAgent
+from plenum.common.constants import SERVICES, VALIDATOR
+from sovrin_client.test.cli.constants import NODE_REQUEST_COMPLETED, NODE_REQUEST_FAILED
+
+
+def ensurePoolIsOperable(be, do, cli):
+    randomNymMapper = {
+        'remote': DidSigner(seed=randomSeed()).identifier
+    }
+    addAgent(be, do, cli, randomNymMapper)
+
+
+#this test messes with other tests so it goes in its own module
+def testStewardCanDemoteNode(
+        be, do, poolNodesStarted, newStewardCli, trusteeCli, newNodeVals):
+
+    ensurePoolIsOperable(be, do, newStewardCli)
+
+    newNodeVals['newNodeData'][SERVICES] = [VALIDATOR]
+
+    be(newStewardCli)
+    do('send NODE dest={newNodeIdr} data={newNodeData}',
+       mapper=newNodeVals, expect=NODE_REQUEST_COMPLETED, within=8)
+
+    newNodeVals['newNodeData'][SERVICES] = []
+
+    do('send NODE dest={newNodeIdr} data={newNodeData}',
+       mapper=newNodeVals, expect=NODE_REQUEST_COMPLETED, within=8)
+
+    ensurePoolIsOperable(be, do, newStewardCli)",33,2017-08-02 16:00:12,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/130298112,https://github.com/hyperledger/indy-node/pull/270#discussion_r130298112,ashcherbakov
https://github.com/hyperledger/indy-node/pull/269,https://github.com/hyperledger/indy-node/pull/269,typo,fa5c5ec52366a2bf9cded69c6d379959ee4b63b1,2017-07-30 19:11:17,130250203,"@@ -97,16 +97,16 @@ Usage:
 ```
 Alice might also try the 'help' command to see a list of the other commands that are available to her.
 
-## Evaluate a Connection Request
+## Evaluate a Connection Invitiation",,2017-07-30 23:25:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/130250203,https://github.com/hyperledger/indy-node/pull/269#discussion_r130250203,dhh1128
https://github.com/hyperledger/indy-node/pull/269,https://github.com/hyperledger/indy-node/pull/269,I have corrected this typo.,fa5c5ec52366a2bf9cded69c6d379959ee4b63b1,2017-07-30 23:25:47,130255807,"@@ -97,16 +97,16 @@ Usage:
 ```
 Alice might also try the 'help' command to see a list of the other commands that are available to her.
 
-## Evaluate a Connection Request
+## Evaluate a Connection Invitiation",,2017-07-30 23:25:47,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/130255807,https://github.com/hyperledger/indy-node/pull/269#discussion_r130255807,TechWritingWhiz
https://github.com/hyperledger/indy-node/pull/250,https://github.com/hyperledger/indy-node/pull/250,"Please use full names (write_force, not_write_not_force, etc.)",1699644c9da2fb8cf737c3aea67aa5ed19ee7eb7,2017-07-20 12:38:46,128502461,"@@ -0,0 +1,29 @@
+from sovrin_client.test.helper import getClientAddedWithRole
+from sovrin_client.test.helper import checkRejects
+from stp_core.loop.eventually import eventually
+from sovrin_node.test.pool_config.helper import ensurePoolConfigSent, checkPoolConfigWritableSet, sendPoolConfig
+from plenum.common.constants import STEWARD
+
+
+def test_only_trustee_send_pool_config_wtff(nodeSet, tdir, looper, trustee, trusteeWallet, poolConfigWTFF):",,2017-07-22 10:02:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/128502461,https://github.com/hyperledger/indy-node/pull/250#discussion_r128502461,ashcherbakov
https://github.com/hyperledger/indy-node/pull/250,https://github.com/hyperledger/indy-node/pull/250,"Do we have tests to check that read (GET) request can be processed regardless of writeable state?
",1699644c9da2fb8cf737c3aea67aa5ed19ee7eb7,2017-07-20 12:49:27,128504824,"@@ -365,12 +379,19 @@ def processRequest(self, request: Request, frm: str):
             self.send_ack_to_client(request.key, frm)
             result = self.reqHandler.handleGetClaimDefReq(request, frm)
             self.transmitToClient(Reply(result), frm)
+        elif request.operation[TXN_TYPE] == GET_TXNS:
+            super().processRequest(request, frm)
         else:
             # forced request should be processed before consensus
-            if request.operation[TXN_TYPE] == POOL_UPGRADE and request.isForced():
+            if (request.operation[TXN_TYPE] in [POOL_UPGRADE, POOL_CONFIG]) and request.isForced():
                 self.configReqHandler.validate(request)
                 self.configReqHandler.applyForced(request)
-            super().processRequest(request, frm)
+            #here we should have write transactions that should be processed only on writable pool
+            if self.poolCfg.isWritable() or (request.operation[TXN_TYPE] == POOL_CONFIG):
+                super().processRequest(request, frm)",,2017-07-22 10:02:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/128504824,https://github.com/hyperledger/indy-node/pull/250#discussion_r128504824,ashcherbakov
https://github.com/hyperledger/indy-node/pull/250,https://github.com/hyperledger/indy-node/pull/250,Get Nym test aded,1699644c9da2fb8cf737c3aea67aa5ed19ee7eb7,2017-07-20 13:17:47,128511208,"@@ -365,12 +379,19 @@ def processRequest(self, request: Request, frm: str):
             self.send_ack_to_client(request.key, frm)
             result = self.reqHandler.handleGetClaimDefReq(request, frm)
             self.transmitToClient(Reply(result), frm)
+        elif request.operation[TXN_TYPE] == GET_TXNS:
+            super().processRequest(request, frm)
         else:
             # forced request should be processed before consensus
-            if request.operation[TXN_TYPE] == POOL_UPGRADE and request.isForced():
+            if (request.operation[TXN_TYPE] in [POOL_UPGRADE, POOL_CONFIG]) and request.isForced():
                 self.configReqHandler.validate(request)
                 self.configReqHandler.applyForced(request)
-            super().processRequest(request, frm)
+            #here we should have write transactions that should be processed only on writable pool
+            if self.poolCfg.isWritable() or (request.operation[TXN_TYPE] == POOL_CONFIG):
+                super().processRequest(request, frm)",,2017-07-22 10:02:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/128511208,https://github.com/hyperledger/indy-node/pull/250#discussion_r128511208,dsurnin
https://github.com/hyperledger/indy-node/pull/250,https://github.com/hyperledger/indy-node/pull/250,Does it replace default PrePrepare handler?,1699644c9da2fb8cf737c3aea67aa5ed19ee7eb7,2017-07-21 11:06:10,128737706,"@@ -86,13 +87,28 @@ def __init__(self,
         self.on_new_ledger_added(CONFIG_LEDGER_ID)
         self.states[CONFIG_LEDGER_ID] = self.loadConfigState()
         self.upgrader = self.getUpgrader()
+        self.poolCfg = self.getPoolConfig()
         self.configReqHandler = self.getConfigReqHandler()
         self.initConfigState()
         self.requestExecuter[CONFIG_LEDGER_ID] = self.executeConfigTxns
 
         self.nodeMsgRouter.routes[Request] = self.processNodeRequest
         self.nodeAuthNr = self.defaultNodeAuthNr()
 
+        self.nodeMsgRouter.routes[PrePrepare] = self.extraPrePrepareProcesing
+
+
+    def extraPrePrepareProcesing(self, msg, frm):",,2017-07-22 10:02:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/128737706,https://github.com/hyperledger/indy-node/pull/250#discussion_r128737706,ashcherbakov
https://github.com/hyperledger/indy-node/pull/250,https://github.com/hyperledger/indy-node/pull/250,"Please add a test to check that PrePrepares are not processed during read-only state unless this is a CONFIG_LEDGER.
Do we process POOL_UPGRADE when read-only? Please add a test",1699644c9da2fb8cf737c3aea67aa5ed19ee7eb7,2017-07-21 11:55:40,128745079,"@@ -86,13 +87,28 @@ def __init__(self,
         self.on_new_ledger_added(CONFIG_LEDGER_ID)
         self.states[CONFIG_LEDGER_ID] = self.loadConfigState()
         self.upgrader = self.getUpgrader()
+        self.poolCfg = self.getPoolConfig()
         self.configReqHandler = self.getConfigReqHandler()
         self.initConfigState()
         self.requestExecuter[CONFIG_LEDGER_ID] = self.executeConfigTxns
 
         self.nodeMsgRouter.routes[Request] = self.processNodeRequest
         self.nodeAuthNr = self.defaultNodeAuthNr()
 
+        self.nodeMsgRouter.routes[PrePrepare] = self.extraPrePrepareProcesing
+
+
+    def extraPrePrepareProcesing(self, msg, frm):",,2017-07-22 10:02:53,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/128745079,https://github.com/hyperledger/indy-node/pull/250#discussion_r128745079,ashcherbakov
https://github.com/hyperledger/indy-node/pull/217,https://github.com/hyperledger/indy-node/pull/217,Please either remove `seqId` or split it into two method (`getPublicKey` and `getPublicKeyBySeqId`),8d3d221a1c033a86decd12dbfdb690ee87310866,2017-07-12 15:35:54,126990142,"@@ -54,30 +54,54 @@ def __init__(self, client, wallet):
         self.displayer = print
 
     async def getSchema(self, id: ID) -> Optional[Schema]:
-        op = {
-            TARGET_NYM: id.schemaKey.issuerId,
-            TXN_TYPE: GET_SCHEMA,
-            DATA: {
-                NAME: id.schemaKey.name,
-                VERSION: id.schemaKey.version,
+        data = None
+        if id.schemaKey:
+            op = {
+                TARGET_NYM: id.schemaKey.issuerId,
+                TXN_TYPE: GET_SCHEMA,
+                DATA: {
+                    NAME: id.schemaKey.name,
+                    VERSION: id.schemaKey.version,
+                }
             }
-        }
-        data, seqNo = await self._sendGetReq(op)
+            data, seqNo = await self._sendGetReq(op)
+
+        else:
+            op = {
+                TXN_TYPE: GET_TXNS,
+                DATA: id.schemaId
+            }
+            res, seqNo = await self._sendGetReq(op)
+            if res:
+                data = json.loads(res[DATA]) if res else {}
+                data[ORIGIN] = res[IDENTIFIER]
+
         return Schema(name=data[NAME],
                       version=data[VERSION],
                       attrNames=data[ATTR_NAMES],
                       issuerId=data[ORIGIN],
                       seqId=seqNo) if data else None
 
-    async def getPublicKey(self, id: ID,
-                           signatureType = 'CL') -> Optional[PublicKey]:
-        op = {
-            TXN_TYPE: GET_CLAIM_DEF,
-            REF: id.schemaId,
-            ORIGIN: id.schemaKey.issuerId,
-            SIGNATURE_TYPE: signatureType
-        }
-        data, seqNo = await self._sendGetReq(op)
+    async def getPublicKey(self, id: ID = None,",,2017-07-13 07:43:19,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/126990142,https://github.com/hyperledger/indy-node/pull/217#discussion_r126990142,ashcherbakov
https://github.com/hyperledger/indy-node/pull/205,https://github.com/hyperledger/indy-node/pull/205,This method needs to be defined on Node and not a `ReqHandler` since a `ReqHandler` corresponds to one ledger only but any ledger can be queried. The client request needs to indicate which ledger needs to be queried for the sequence number. Also this method should be in plenum. ,1a11082227f2f9a73a70e9d4038a9fef85259928,2017-07-04 09:36:11,125430782,"@@ -235,6 +235,21 @@ def handleGetSchemaReq(self, request: Request, frm: str):
         }}
         return result
 
+    def handleGetTnxReq(self, request: Request, frm: str, node):",,2017-07-07 09:37:55,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/125430782,https://github.com/hyperledger/indy-node/pull/205#discussion_r125430782,lovesh
https://github.com/hyperledger/indy-node/pull/197,https://github.com/hyperledger/indy-node/pull/197,Why do we raise `UnauthorizedClientRequest` here? Should we use some other type of exception? `UnauthorizedClientRequest` is usually raised when a sender doesn't have enough permissions (for example Role) to perform a request.,3306b8bd034b448d43ccd5aea81831cfdcc64462,2017-06-29 12:57:21,124791655,"@@ -63,6 +63,12 @@ def validate(self, req: Request, config=None):
             # present
             status = self.upgrader.statusInLedger(req.operation.get(NAME),
                                                   req.operation.get(VERSION))
+            if status == START and action == START:
+                raise UnauthorizedClientRequest(",,2017-07-06 07:24:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124791655,https://github.com/hyperledger/indy-node/pull/197#discussion_r124791655,ashcherbakov
https://github.com/hyperledger/indy-node/pull/197,https://github.com/hyperledger/indy-node/pull/197,"Sure, we can make it a more appropriate message.  The ticket suggested UnauthorizedClientRequest, I will change and re-submit this morning.",3306b8bd034b448d43ccd5aea81831cfdcc64462,2017-06-29 13:01:57,124792638,"@@ -63,6 +63,12 @@ def validate(self, req: Request, config=None):
             # present
             status = self.upgrader.statusInLedger(req.operation.get(NAME),
                                                   req.operation.get(VERSION))
+            if status == START and action == START:
+                raise UnauthorizedClientRequest(",,2017-07-06 07:24:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124792638,https://github.com/hyperledger/indy-node/pull/197#discussion_r124792638,hadleym
https://github.com/hyperledger/indy-node/pull/197,https://github.com/hyperledger/indy-node/pull/197,Should we change this to be `InvalidClientRequest`?,3306b8bd034b448d43ccd5aea81831cfdcc64462,2017-06-29 15:40:00,124837070,"@@ -42,4 +42,10 @@ def testNonTrustyCannotCancelUpgrade(looper, validUpgradeSent,
     looper.run(eventually(checkRejects, stClient, req.reqId,
                           'cannot do'))
 
+def test_accept_then_reject_upgrade(looper, trustee, trusteeWallet, validUpgradeSent, validUpgrade):
+    validUpgrade2 = deepcopy(validUpgrade)
+    _, req = sendUpgrade(trustee, trusteeWallet, validUpgrade2)
+    timeout = plenumWaits.expectedReqNAckQuorumTime()
+    looper.run(eventually(checkRejects, trustee, req.reqId,
+                          'UnauthorizedClientRequest', retryWait=1, timeout=timeout))",,2017-07-06 07:24:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124837070,https://github.com/hyperledger/indy-node/pull/197#discussion_r124837070,ashcherbakov
https://github.com/hyperledger/indy-node/pull/197,https://github.com/hyperledger/indy-node/pull/197,This was changed to InvalidClientRequest.,3306b8bd034b448d43ccd5aea81831cfdcc64462,2017-07-05 22:08:30,125769732,"@@ -42,4 +42,10 @@ def testNonTrustyCannotCancelUpgrade(looper, validUpgradeSent,
     looper.run(eventually(checkRejects, stClient, req.reqId,
                           'cannot do'))
 
+def test_accept_then_reject_upgrade(looper, trustee, trusteeWallet, validUpgradeSent, validUpgrade):
+    validUpgrade2 = deepcopy(validUpgrade)
+    _, req = sendUpgrade(trustee, trusteeWallet, validUpgrade2)
+    timeout = plenumWaits.expectedReqNAckQuorumTime()
+    looper.run(eventually(checkRejects, trustee, req.reqId,
+                          'UnauthorizedClientRequest', retryWait=1, timeout=timeout))",,2017-07-06 07:24:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/125769732,https://github.com/hyperledger/indy-node/pull/197#discussion_r125769732,hadleym
https://github.com/hyperledger/indy-node/pull/197,https://github.com/hyperledger/indy-node/pull/197,"Ah, I was not correcting this properly.",3306b8bd034b448d43ccd5aea81831cfdcc64462,2017-07-06 07:12:17,125825849,"@@ -42,4 +42,10 @@ def testNonTrustyCannotCancelUpgrade(looper, validUpgradeSent,
     looper.run(eventually(checkRejects, stClient, req.reqId,
                           'cannot do'))
 
+def test_accept_then_reject_upgrade(looper, trustee, trusteeWallet, validUpgradeSent, validUpgrade):
+    validUpgrade2 = deepcopy(validUpgrade)
+    _, req = sendUpgrade(trustee, trusteeWallet, validUpgrade2)
+    timeout = plenumWaits.expectedReqNAckQuorumTime()
+    looper.run(eventually(checkRejects, trustee, req.reqId,
+                          'UnauthorizedClientRequest', retryWait=1, timeout=timeout))",,2017-07-06 07:24:07,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/125825849,https://github.com/hyperledger/indy-node/pull/197#discussion_r125825849,hadleym
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,For clarity please use constant value instead of random one,9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:05:21,124534405,"@@ -26,7 +28,7 @@ def validUpgrade(nodeIds, tconf):
         schedule[i] = datetime.isoformat(startAt)
         startAt = startAt + timedelta(seconds=acceptableDiff + 3)
     return dict(name='upgrade-13', version=bumpedVersion(), action=START,
-                schedule=schedule, sha256='aad1242', timeout=1)
+                schedule=schedule, sha256=randomString(64), timeout=1)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124534405,https://github.com/hyperledger/indy-node/pull/196#discussion_r124534405,mzk-vct
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,For clarity please use constant value instead of random one,9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:06:16,124534622,"@@ -91,7 +97,7 @@ def invalidUpgrade(nodeIds, tconf):
         schedule[i] = datetime.isoformat(startAt)
         startAt = startAt + timedelta(seconds=acceptableDiff - 3)
     return dict(name='upgrade-14', version=bumpedVersion(), action=START,
-                schedule=schedule, sha256='ffd1224', timeout=10)
+                schedule=schedule, sha256=randomString(64), timeout=10)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124534622,https://github.com/hyperledger/indy-node/pull/196#discussion_r124534622,mzk-vct
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,For clarity please use constant value instead of random one,9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:06:27,124534660,"@@ -25,7 +25,7 @@ def testDoNotScheduleUpgradeForALowerVersion(looper, tconf, nodeSet,
     upgr2 = deepcopy(upgr1)
     upgr2[VERSION] = bumpVersion(upgr1[VERSION])
     upgr2[NAME] += randomString(3)
-    upgr2[SHA256] = randomString(32)
+    upgr2[SHA256] = randomString(64)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124534660,https://github.com/hyperledger/indy-node/pull/196#discussion_r124534660,mzk-vct
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,For clarity please use constant value instead of random one,9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:06:40,124534703,"@@ -51,12 +51,12 @@ def testUpgradeLatestUncancelledVersion(looper,
     upgr2 = deepcopy(upgr1)
     upgr2[VERSION] = bumpVersion(upgr1[VERSION])
     upgr2[NAME] += randomString(3)
-    upgr2[SHA256] = randomString(32)
+    upgr2[SHA256] = randomString(64)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124534703,https://github.com/hyperledger/indy-node/pull/196#discussion_r124534703,mzk-vct
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,For clarity please use constant value instead of random one,9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:06:46,124534728,"@@ -51,12 +51,12 @@ def testUpgradeLatestUncancelledVersion(looper,
     upgr2 = deepcopy(upgr1)
     upgr2[VERSION] = bumpVersion(upgr1[VERSION])
     upgr2[NAME] += randomString(3)
-    upgr2[SHA256] = randomString(32)
+    upgr2[SHA256] = randomString(64)
 
     upgr3 = deepcopy(upgr2)
     upgr3[VERSION] = bumpVersion(upgr2[VERSION])
     upgr3[NAME] += randomString(3)
-    upgr3[SHA256] = randomString(32)
+    upgr3[SHA256] = randomString(64)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124534728,https://github.com/hyperledger/indy-node/pull/196#discussion_r124534728,mzk-vct
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,Added a test method `get_valid_code_hash` and using that here,9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:16:21,124537150,"@@ -26,7 +28,7 @@ def validUpgrade(nodeIds, tconf):
         schedule[i] = datetime.isoformat(startAt)
         startAt = startAt + timedelta(seconds=acceptableDiff + 3)
     return dict(name='upgrade-13', version=bumpedVersion(), action=START,
-                schedule=schedule, sha256='aad1242', timeout=1)
+                schedule=schedule, sha256=randomString(64), timeout=1)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124537150,https://github.com/hyperledger/indy-node/pull/196#discussion_r124537150,lovesh
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,"Added a test method `get_valid_code_hash` and using that here
",9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:16:26,124537170,"@@ -91,7 +97,7 @@ def invalidUpgrade(nodeIds, tconf):
         schedule[i] = datetime.isoformat(startAt)
         startAt = startAt + timedelta(seconds=acceptableDiff - 3)
     return dict(name='upgrade-14', version=bumpedVersion(), action=START,
-                schedule=schedule, sha256='ffd1224', timeout=10)
+                schedule=schedule, sha256=randomString(64), timeout=10)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124537170,https://github.com/hyperledger/indy-node/pull/196#discussion_r124537170,lovesh
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,Added a test method `get_valid_code_hash` and using that here,9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:16:30,124537189,"@@ -25,7 +25,7 @@ def testDoNotScheduleUpgradeForALowerVersion(looper, tconf, nodeSet,
     upgr2 = deepcopy(upgr1)
     upgr2[VERSION] = bumpVersion(upgr1[VERSION])
     upgr2[NAME] += randomString(3)
-    upgr2[SHA256] = randomString(32)
+    upgr2[SHA256] = randomString(64)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124537189,https://github.com/hyperledger/indy-node/pull/196#discussion_r124537189,lovesh
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,Added a test method `get_valid_code_hash` and using that here,9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:16:34,124537203,"@@ -51,12 +51,12 @@ def testUpgradeLatestUncancelledVersion(looper,
     upgr2 = deepcopy(upgr1)
     upgr2[VERSION] = bumpVersion(upgr1[VERSION])
     upgr2[NAME] += randomString(3)
-    upgr2[SHA256] = randomString(32)
+    upgr2[SHA256] = randomString(64)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124537203,https://github.com/hyperledger/indy-node/pull/196#discussion_r124537203,lovesh
https://github.com/hyperledger/indy-node/pull/196,https://github.com/hyperledger/indy-node/pull/196,Added a test method `get_valid_code_hash` and using that here,9386b117cc8fdc959912b1acb5e2fd2ba71c113a,2017-06-28 13:16:37,124537217,"@@ -51,12 +51,12 @@ def testUpgradeLatestUncancelledVersion(looper,
     upgr2 = deepcopy(upgr1)
     upgr2[VERSION] = bumpVersion(upgr1[VERSION])
     upgr2[NAME] += randomString(3)
-    upgr2[SHA256] = randomString(32)
+    upgr2[SHA256] = randomString(64)
 
     upgr3 = deepcopy(upgr2)
     upgr3[VERSION] = bumpVersion(upgr2[VERSION])
     upgr3[NAME] += randomString(3)
-    upgr3[SHA256] = randomString(32)
+    upgr3[SHA256] = randomString(64)",,2017-06-28 13:34:05,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/124537217,https://github.com/hyperledger/indy-node/pull/196#discussion_r124537217,lovesh
https://github.com/hyperledger/indy-node/pull/175,https://github.com/hyperledger/indy-node/pull/175,"Shouldn't it be `self.unCommitted = self.unCommitted[1:]` so that we remove the first (processed item), not the last one.",a59c8d931333e62e4c92dee0a1823d8e5a932fe7,2017-06-08 13:39:00,120889649,"@@ -91,18 +94,28 @@ def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted[stateRoot] = OrderedDict(self.currentBatchOps)
+        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
         self.currentBatchOps = []
 
-    def batchRejected(self, stateRoot=None):
-        if stateRoot:
-            self.unCommitted[stateRoot] = OrderedDict(self.currentBatchOps)
-        else:
-            self.currentBatchOps = []
+    def batchRejected(self):
+        # Batches are always rejected from end of `self.unCommitted`
+        self.currentBatchOps = []
+        self.unCommitted = self.unCommitted[:-1]
 
     def onBatchCommitted(self, stateRoot):
-        self._keyValueStorage.setBatch([(idr, val) for idr, val in self.unCommitted[stateRoot].items()])
-        self.unCommitted.pop(stateRoot)
+        # Commit an already created batch
+        if self.unCommitted:
+            assert self.unCommitted[0][0] == stateRoot, 'The first created batch has ' \
+                                                     'not been committed or ' \
+                                                     'reverted and yet another ' \
+                                                     'batch is trying to be ' \
+                                                     'committed'
+            self._keyValueStorage.setBatch([(idr, val) for idr, val in
+                                            self.unCommitted[0][1].items()])
+            self.unCommitted = self.unCommitted[:-1]",,2017-06-09 08:10:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/120889649,https://github.com/hyperledger/indy-node/pull/175#discussion_r120889649,ashcherbakov
https://github.com/hyperledger/indy-node/pull/175,https://github.com/hyperledger/indy-node/pull/175,"Can we write a more low-level test that ensures that a sequence of 
currentBatchCreated, batchRejected and onBatchCommitted calls work?
Example:
Test1: - sunny day
- save current state and current unCommitted 
- call currentBatchCreated twice (with different states)
- call onBatchCommitted for the first state
- make sure the state is committed and the unCommitted state is equal to the second state
- call onBatchCommitted for the second state
- make sure the state is committed and unCommitted is empty

Test2: - commit not the first state
- save current state and current unCommitted 
- call currentBatchCreated twice (with different states)
- call onBatchCommitted for the second state
- make sure assertion error is raised

Test3: - reject state
- save current state and current unCommitted 
- call currentBatchCreated twice (with different states)
- call batchRejected 
- make sure the second state is rejected
",a59c8d931333e62e4c92dee0a1823d8e5a932fe7,2017-06-08 13:51:12,120893078,"@@ -91,18 +94,28 @@ def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):",36,2017-06-09 08:10:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/120893078,https://github.com/hyperledger/indy-node/pull/175#discussion_r120893078,ashcherbakov
https://github.com/hyperledger/indy-node/pull/175,https://github.com/hyperledger/indy-node/pull/175,"Why do we assume in the API that batches are always rejected from the end of self.unCommitted and do not pass state into `batchRejected`, but pass the state explicitly into `onBatchCommitted` and check for assertion?
Shouldn't we either pass state into both methods and check assertions in both method (that the state is equal to the first batch's state in onBatchCommitted and is equal to the last batch's state in batchRejected), or don't pass it at all?",a59c8d931333e62e4c92dee0a1823d8e5a932fe7,2017-06-08 13:54:17,120893962,"@@ -91,18 +94,28 @@ def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted[stateRoot] = OrderedDict(self.currentBatchOps)
+        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
         self.currentBatchOps = []
 
-    def batchRejected(self, stateRoot=None):
-        if stateRoot:
-            self.unCommitted[stateRoot] = OrderedDict(self.currentBatchOps)
-        else:
-            self.currentBatchOps = []
+    def batchRejected(self):
+        # Batches are always rejected from end of `self.unCommitted`
+        self.currentBatchOps = []
+        self.unCommitted = self.unCommitted[:-1]
 
     def onBatchCommitted(self, stateRoot):",51,2017-06-09 08:10:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/120893962,https://github.com/hyperledger/indy-node/pull/175#discussion_r120893962,ashcherbakov
https://github.com/hyperledger/indy-node/pull/175,https://github.com/hyperledger/indy-node/pull/175,"Yes, fixed",a59c8d931333e62e4c92dee0a1823d8e5a932fe7,2017-06-08 14:39:17,120906168,"@@ -91,18 +94,28 @@ def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted[stateRoot] = OrderedDict(self.currentBatchOps)
+        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
         self.currentBatchOps = []
 
-    def batchRejected(self, stateRoot=None):
-        if stateRoot:
-            self.unCommitted[stateRoot] = OrderedDict(self.currentBatchOps)
-        else:
-            self.currentBatchOps = []
+    def batchRejected(self):
+        # Batches are always rejected from end of `self.unCommitted`
+        self.currentBatchOps = []
+        self.unCommitted = self.unCommitted[:-1]
 
     def onBatchCommitted(self, stateRoot):
-        self._keyValueStorage.setBatch([(idr, val) for idr, val in self.unCommitted[stateRoot].items()])
-        self.unCommitted.pop(stateRoot)
+        # Commit an already created batch
+        if self.unCommitted:
+            assert self.unCommitted[0][0] == stateRoot, 'The first created batch has ' \
+                                                     'not been committed or ' \
+                                                     'reverted and yet another ' \
+                                                     'batch is trying to be ' \
+                                                     'committed'
+            self._keyValueStorage.setBatch([(idr, val) for idr, val in
+                                            self.unCommitted[0][1].items()])
+            self.unCommitted = self.unCommitted[:-1]",,2017-06-09 08:10:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/120906168,https://github.com/hyperledger/indy-node/pull/175#discussion_r120906168,lovesh
https://github.com/hyperledger/indy-node/pull/175,https://github.com/hyperledger/indy-node/pull/175,"Yes, Test1 can be done. To Test2 there has to be scenario created which will result in calling `revert` in an incorrect order of batches, simply patching some method to deliberately call `onBatchCommitted` with wrong args only proves that an assertion check works, its ok to do it, but not worth investing time in. I would rather create a scenario that result in reverting batches in incorrect order and see failures much before this code is reached. Test3 yes can be done",a59c8d931333e62e4c92dee0a1823d8e5a932fe7,2017-06-08 14:47:10,120908497,"@@ -91,18 +94,28 @@ def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):",36,2017-06-09 08:10:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/120908497,https://github.com/hyperledger/indy-node/pull/175#discussion_r120908497,lovesh
https://github.com/hyperledger/indy-node/pull/175,https://github.com/hyperledger/indy-node/pull/175,"We assume that revert in reverse order is guaranteed by the replica
Because we do not preserve state-root after a pre-prepare in replica, so if we preserve it somewhere then we can pass that to replica and before reverting check it. ",a59c8d931333e62e4c92dee0a1823d8e5a932fe7,2017-06-08 14:55:47,120911023,"@@ -91,18 +94,28 @@ def close(self):
         self._keyValueStorage.close()
 
     def currentBatchCreated(self, stateRoot):
-        self.unCommitted[stateRoot] = OrderedDict(self.currentBatchOps)
+        self.unCommitted.append((stateRoot, OrderedDict(self.currentBatchOps)))
         self.currentBatchOps = []
 
-    def batchRejected(self, stateRoot=None):
-        if stateRoot:
-            self.unCommitted[stateRoot] = OrderedDict(self.currentBatchOps)
-        else:
-            self.currentBatchOps = []
+    def batchRejected(self):
+        # Batches are always rejected from end of `self.unCommitted`
+        self.currentBatchOps = []
+        self.unCommitted = self.unCommitted[:-1]
 
     def onBatchCommitted(self, stateRoot):",51,2017-06-09 08:10:15,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/120911023,https://github.com/hyperledger/indy-node/pull/175#discussion_r120911023,lovesh
https://github.com/hyperledger/indy-node/pull/161,https://github.com/hyperledger/indy-node/pull/161,It must be deleted,f1ecacfbc949fd15435b66483580cee9843e551d,2017-06-01 11:28:02,119589296,"@@ -58,4 +58,5 @@ def testWindowsNoDocker = {
 
 options = new TestAndPublishOptions()
 options.enable([StagesEnum.PACK_RELEASE_DEPS, StagesEnum.PACK_RELEASE_ST_DEPS])
+options.skip([StagesEnum.GITHUB_RELEASE, StagesEnum.PYPI_RELEASE])",,2017-06-01 11:30:43,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119589296,https://github.com/hyperledger/indy-node/pull/161#discussion_r119589296,ashcherbakov
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"I am feeling concerned about two issues with this approach:
1. This creates multiple migration scripts per version change. I want one migration script per update. Anything more is unnecessary complexity. Also, it gives multiple points of failure instead of one, and it gives no responsibility to these individual scripts to know about or coordinate with one another. I think it increases the chances of failure.
2. This mechanism doesn't include in its name the version you are coming from, only the version you are headed to. I think this is problematic because we might have nodes upgrading from more than one starting point.",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-30 16:34:50,119150885,"@@ -0,0 +1,16 @@
+# Migrations for sovrin-node
+
+All migrations are python scripts with names satisfying the following rule:
+```
+<underscored_version-migration-should-be-applied-to>_<migration-name>",,2017-05-31 09:33:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119150885,https://github.com/hyperledger/indy-node/pull/159#discussion_r119150885,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"Why are versions underscored here, but use dots in .deb? Can we use dots here?",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-30 16:35:54,119151127,"@@ -0,0 +1,16 @@
+# Migrations for sovrin-node
+
+All migrations are python scripts with names satisfying the following rule:
+```
+<underscored_version-migration-should-be-applied-to>_<migration-name>",,2017-05-31 09:33:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119151127,https://github.com/hyperledger/indy-node/pull/159#discussion_r119151127,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"type ""relevalnt""",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-30 16:36:17,119151205,"@@ -0,0 +1,52 @@
+#!/usr/bin/python3
+
+import time
+import pkgutil
+import importlib
+
+from stp_core.common.log import getlogger
+
+
+SCRIPT_PREFIX = 'data.migrations.'
+
+
+logger = getlogger()
+
+
+# Returns number of performed migrations
+def migrate(current_version):
+    logger.info('Migrating from {}'.format(current_version))
+    migration_scripts = _get_migration_scripts()
+    logger.debug('Found migration scripts: {}'.format(migration_scripts))
+    migration_scripts = _get_relevalnt_migrations(migration_scripts, current_version)",,2017-05-31 09:33:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119151205,https://github.com/hyperledger/indy-node/pull/159#discussion_r119151205,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,How do we account for differences in import path across upgrades?,495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-30 16:37:37,119151541,"@@ -0,0 +1,52 @@
+#!/usr/bin/python3
+
+import time
+import pkgutil
+import importlib
+
+from stp_core.common.log import getlogger
+
+
+SCRIPT_PREFIX = 'data.migrations.'
+
+
+logger = getlogger()
+
+
+# Returns number of performed migrations
+def migrate(current_version):
+    logger.info('Migrating from {}'.format(current_version))
+    migration_scripts = _get_migration_scripts()
+    logger.debug('Found migration scripts: {}'.format(migration_scripts))
+    migration_scripts = _get_relevalnt_migrations(migration_scripts, current_version)
+    if not len(migration_scripts):
+        logger.info('No migrations can be applied to the current code.')
+        return 0
+    logger.info('Following migrations will be applied: {}'.format(migration_scripts))
+    for migration in migration_scripts:
+        logger.info('Applying migration {}'.format(migration))
+        start_time = time.time()
+        _call_migration_script(migration)
+        logger.info('Migration {} applied in {} seconds'.format(migration, time.time() - start_time))
+    return len(migration_scripts)
+
+
+def _get_migration_scripts():
+    # Data folder is published as a separate 'data' python package
+    from data import migrations
+    return [name for module_finder, name, ispkg in pkgutil.iter_modules(migrations.__path__)]
+
+
+def _get_relevalnt_migrations(migration_scripts, current_version):
+    relevant_migrations = []
+    for migration in migration_scripts:
+        migration_split = migration.split('_')
+        migration_version = '.'.join(migration_split[0:3])
+        if migration_version >= current_version:
+            relevant_migrations.append(migration)
+    relevant_migrations.sort()
+    return relevant_migrations
+
+
+def _call_migration_script(migration_script):
+    importlib.import_module(SCRIPT_PREFIX + migration_script)",52,2017-05-31 09:33:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119151541,https://github.com/hyperledger/indy-node/pull/159#discussion_r119151541,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,subprocess.call(shell=True) is a security risk.,495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-30 16:55:02,119155628,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)",28,2017-05-31 09:33:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119155628,https://github.com/hyperledger/indy-node/pull/159#discussion_r119155628,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,What privileges are in effect when this migration mechanism runs? Does it delegate those privileges to child processes? Should it?,495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-30 16:55:58,119155864,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)",28,2017-05-31 09:33:31,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119155864,https://github.com/hyperledger/indy-node/pull/159#discussion_r119155864,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"You are doing a simple binary sort. On Windows this will violate assumptions that sort is not case sensitive. This makes me wonder: does the mechanism get used on Windows, or only on linux? Should each migration script be cross-platform?",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-30 17:33:28,119165237,"@@ -0,0 +1,52 @@
+#!/usr/bin/python3
+
+import time
+import pkgutil
+import importlib
+
+from stp_core.common.log import getlogger
+
+
+SCRIPT_PREFIX = 'data.migrations.'
+
+
+logger = getlogger()
+
+
+# Returns number of performed migrations
+def migrate(current_version):
+    logger.info('Migrating from {}'.format(current_version))
+    migration_scripts = _get_migration_scripts()
+    logger.debug('Found migration scripts: {}'.format(migration_scripts))
+    migration_scripts = _get_relevalnt_migrations(migration_scripts, current_version)
+    if not len(migration_scripts):
+        logger.info('No migrations can be applied to the current code.')
+        return 0
+    logger.info('Following migrations will be applied: {}'.format(migration_scripts))
+    for migration in migration_scripts:
+        logger.info('Applying migration {}'.format(migration))
+        start_time = time.time()
+        _call_migration_script(migration)
+        logger.info('Migration {} applied in {} seconds'.format(migration, time.time() - start_time))
+    return len(migration_scripts)
+
+
+def _get_migration_scripts():
+    # Data folder is published as a separate 'data' python package
+    from data import migrations
+    return [name for module_finder, name, ispkg in pkgutil.iter_modules(migrations.__path__)]
+
+
+def _get_relevalnt_migrations(migration_scripts, current_version):
+    relevant_migrations = []
+    for migration in migration_scripts:
+        migration_split = migration.split('_')
+        migration_version = '.'.join(migration_split[0:3])
+        if migration_version >= current_version:
+            relevant_migrations.append(migration)
+    relevant_migrations.sort()",47,2017-05-31 15:25:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119165237,https://github.com/hyperledger/indy-node/pull/159#discussion_r119165237,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"What is our recovery plan when an upgrade fails? We need to use design-by-contract principles here; each party needs to know its responsibilities, and then deliver crisply on the contract.",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-30 17:37:35,119166283,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
+    else:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
+    if retcode != 0:
+        msg = 'Upgrade failed: upgrade script returned {}'.format(retcode)",32,2017-05-31 15:25:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119166283,https://github.com/hyperledger/indy-node/pull/159#discussion_r119166283,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"Here we are calling an ""upgrade script"", but elsewhere we are talking about a ""migration script."" Can we clarify the significance of the different terms? I prefer ""upgrade"", but I may not fully understand the intention.",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-30 17:40:29,119166989,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
+    else:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
+    if retcode != 0:
+        msg = 'Upgrade failed: upgrade script returned {}'.format(retcode)",32,2017-05-31 15:25:35,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119166989,https://github.com/hyperledger/indy-node/pull/159#discussion_r119166989,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"@dhh1128 
1) I think we will have a single script almost always. yet I think we need to leave some room for us to wiggle, since it does not cost us anything.
2) It's actually the version you are coming from. I think it does not really matter what version you're updating to
3) Versions are underscored because they are python modules and a python module can not be dotted",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 09:36:18,119313532,"@@ -0,0 +1,16 @@
+# Migrations for sovrin-node
+
+All migrations are python scripts with names satisfying the following rule:
+```
+<underscored_version-migration-should-be-applied-to>_<migration-name>",,2017-05-31 09:36:18,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119313532,https://github.com/hyperledger/indy-node/pull/159#discussion_r119313532,keenondrums
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,@dhh1128 I guess in the future we will switch SCRIPT_PREFIX based on operating system,495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 09:37:32,119313799,"@@ -0,0 +1,52 @@
+#!/usr/bin/python3
+
+import time
+import pkgutil
+import importlib
+
+from stp_core.common.log import getlogger
+
+
+SCRIPT_PREFIX = 'data.migrations.'
+
+
+logger = getlogger()
+
+
+# Returns number of performed migrations
+def migrate(current_version):
+    logger.info('Migrating from {}'.format(current_version))
+    migration_scripts = _get_migration_scripts()
+    logger.debug('Found migration scripts: {}'.format(migration_scripts))
+    migration_scripts = _get_relevalnt_migrations(migration_scripts, current_version)
+    if not len(migration_scripts):
+        logger.info('No migrations can be applied to the current code.')
+        return 0
+    logger.info('Following migrations will be applied: {}'.format(migration_scripts))
+    for migration in migration_scripts:
+        logger.info('Applying migration {}'.format(migration))
+        start_time = time.time()
+        _call_migration_script(migration)
+        logger.info('Migration {} applied in {} seconds'.format(migration, time.time() - start_time))
+    return len(migration_scripts)
+
+
+def _get_migration_scripts():
+    # Data folder is published as a separate 'data' python package
+    from data import migrations
+    return [name for module_finder, name, ispkg in pkgutil.iter_modules(migrations.__path__)]
+
+
+def _get_relevalnt_migrations(migration_scripts, current_version):
+    relevant_migrations = []
+    for migration in migration_scripts:
+        migration_split = migration.split('_')
+        migration_version = '.'.join(migration_split[0:3])
+        if migration_version >= current_version:
+            relevant_migrations.append(migration)
+    relevant_migrations.sort()
+    return relevant_migrations
+
+
+def _call_migration_script(migration_script):
+    importlib.import_module(SCRIPT_PREFIX + migration_script)",52,2017-05-31 09:37:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119313799,https://github.com/hyperledger/indy-node/pull/159#discussion_r119313799,keenondrums
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,@dhh1128 node_control_tool.py is run under root. We need root privileges for upgrade because we install new packages with apt-get.,495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 09:38:24,119313982,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)",28,2017-05-31 09:38:24,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119313982,https://github.com/hyperledger/indy-node/pull/159#discussion_r119313982,keenondrums
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"node_control_tool.py should NOT be run as root (uid==0); it should be run as an account that has elevated privileges to issue calls to apt-get and restart daemons. In other words, it should have limited sudo privileges. If it is run as true root, it is an attack surface.",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 15:28:11,119389665,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)",28,2017-05-31 15:44:47,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119389665,https://github.com/hyperledger/indy-node/pull/159#discussion_r119389665,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,I think each migration should be cross-platform. As to case-sensivity it does not really matter because we will rarely have several migrations for one version. Even if we have then we have a section in readme with recomendations to prefix migration names with digits,495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 15:34:09,119391378,"@@ -0,0 +1,52 @@
+#!/usr/bin/python3
+
+import time
+import pkgutil
+import importlib
+
+from stp_core.common.log import getlogger
+
+
+SCRIPT_PREFIX = 'data.migrations.'
+
+
+logger = getlogger()
+
+
+# Returns number of performed migrations
+def migrate(current_version):
+    logger.info('Migrating from {}'.format(current_version))
+    migration_scripts = _get_migration_scripts()
+    logger.debug('Found migration scripts: {}'.format(migration_scripts))
+    migration_scripts = _get_relevalnt_migrations(migration_scripts, current_version)
+    if not len(migration_scripts):
+        logger.info('No migrations can be applied to the current code.')
+        return 0
+    logger.info('Following migrations will be applied: {}'.format(migration_scripts))
+    for migration in migration_scripts:
+        logger.info('Applying migration {}'.format(migration))
+        start_time = time.time()
+        _call_migration_script(migration)
+        logger.info('Migration {} applied in {} seconds'.format(migration, time.time() - start_time))
+    return len(migration_scripts)
+
+
+def _get_migration_scripts():
+    # Data folder is published as a separate 'data' python package
+    from data import migrations
+    return [name for module_finder, name, ispkg in pkgutil.iter_modules(migrations.__path__)]
+
+
+def _get_relevalnt_migrations(migration_scripts, current_version):
+    relevant_migrations = []
+    for migration in migration_scripts:
+        migration_split = migration.split('_')
+        migration_version = '.'.join(migration_split[0:3])
+        if migration_version >= current_version:
+            relevant_migrations.append(migration)
+    relevant_migrations.sort()",47,2017-05-31 15:34:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119391378,https://github.com/hyperledger/indy-node/pull/159#discussion_r119391378,keenondrums
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,I think each migration should be cross-platform. As to case-sensivity it does not really matter because we will rarely have several migrations for one version. Even if we have then we have a section in readme with recomendations to prefix migration names with digits,495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 15:34:13,119391393,"@@ -0,0 +1,52 @@
+#!/usr/bin/python3
+
+import time
+import pkgutil
+import importlib
+
+from stp_core.common.log import getlogger
+
+
+SCRIPT_PREFIX = 'data.migrations.'
+
+
+logger = getlogger()
+
+
+# Returns number of performed migrations
+def migrate(current_version):
+    logger.info('Migrating from {}'.format(current_version))
+    migration_scripts = _get_migration_scripts()
+    logger.debug('Found migration scripts: {}'.format(migration_scripts))
+    migration_scripts = _get_relevalnt_migrations(migration_scripts, current_version)
+    if not len(migration_scripts):
+        logger.info('No migrations can be applied to the current code.')
+        return 0
+    logger.info('Following migrations will be applied: {}'.format(migration_scripts))
+    for migration in migration_scripts:
+        logger.info('Applying migration {}'.format(migration))
+        start_time = time.time()
+        _call_migration_script(migration)
+        logger.info('Migration {} applied in {} seconds'.format(migration, time.time() - start_time))
+    return len(migration_scripts)
+
+
+def _get_migration_scripts():
+    # Data folder is published as a separate 'data' python package
+    from data import migrations
+    return [name for module_finder, name, ispkg in pkgutil.iter_modules(migrations.__path__)]
+
+
+def _get_relevalnt_migrations(migration_scripts, current_version):
+    relevant_migrations = []
+    for migration in migration_scripts:
+        migration_split = migration.split('_')
+        migration_version = '.'.join(migration_split[0:3])
+        if migration_version >= current_version:
+            relevant_migrations.append(migration)
+    relevant_migrations.sort()",47,2017-05-31 15:34:13,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119391393,https://github.com/hyperledger/indy-node/pull/159#discussion_r119391393,keenondrums
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"I don't agree with the idea that ""it does not cost us anything."" Please collapse to 1 script and eliminate the sorting/collection. The cost of more than 1 script is complexity, as I pointed out. It's not just code complexity--it's communication/doc complexity, and complexity in testing/managing the coordination actions across multiple scripts.

Re #2: versioning needs to include a src and a target version. Of these two, the *target* is more important. We can't say, ""give me a script that upgrades version X to any version later than that"" -- it's just not practical. Instead, we want to say, ""give me a script that upgrades X to Y"". Then we can play all the migrations in order to get from X to Z.

",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 15:38:21,119392573,"@@ -0,0 +1,16 @@
+# Migrations for sovrin-node
+
+All migrations are python scripts with names satisfying the following rule:
+```
+<underscored_version-migration-should-be-applied-to>_<migration-name>",,2017-05-31 15:38:21,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119392573,https://github.com/hyperledger/indy-node/pull/159#discussion_r119392573,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"Apt-get requires root. https://askubuntu.com/questions/339/how-can-i-install-a-package-without-root-access
Even if we can find a way around it's a different issue then, isn't it?",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 17:42:39,119424865,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)",28,2017-05-31 17:42:39,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119424865,https://github.com/hyperledger/indy-node/pull/159#discussion_r119424865,keenondrums
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,Right now a steward should receive an email prior to the upgrade if he has email notifier installed. Then he should receive an email with the result of the upgrade once the node started. If there's a failure he will contact dev department with the logs,495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 17:45:58,119425666,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
+    else:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
+    if retcode != 0:
+        msg = 'Upgrade failed: upgrade script returned {}'.format(retcode)",32,2017-05-31 17:45:58,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119425666,https://github.com/hyperledger/indy-node/pull/159#discussion_r119425666,keenondrums
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"Upgrade script is a script which performs the installation of new code. It's always the same. Migration scripts are optional, they can be applied after upgrade if some major changes appeared in the code, backwards compatibility was broken and system needs to update its state to work with the new code",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-05-31 17:53:01,119427496,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
+    else:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
+    if retcode != 0:
+        msg = 'Upgrade failed: upgrade script returned {}'.format(retcode)",32,2017-05-31 17:53:01,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119427496,https://github.com/hyperledger/indy-node/pull/159#discussion_r119427496,keenondrums
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,"Apt-get does not require root (uid==0). It requires elevated privileges (possibly euid==0). In the past 5 years, I have probably run apt-get 1000 times--5 as root, and 995 via sudo. I believe that sometimes I have run with sudo via a user who had limited privs, not ALL in the sudoers file, which would mean it is possible to create a user that just has the ability to run ""sudo apt-get ..."" in the sudoers file, nothing else.

You are correct that this is a different issue--but I am irritated that we are being sloppy about privileges. Please log a separate ticket.",495c81e49e2b082e7dc4e5a42be706076d283c57,2017-06-01 03:37:30,119522190,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)",28,2017-06-01 03:37:30,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119522190,https://github.com/hyperledger/indy-node/pull/159#discussion_r119522190,dhh1128
https://github.com/hyperledger/indy-node/pull/159,https://github.com/hyperledger/indy-node/pull/159,Thanks for the clarification.,495c81e49e2b082e7dc4e5a42be706076d283c57,2017-06-01 03:40:09,119522407,"@@ -14,30 +19,41 @@ def compose_cmd(cmd):
 
 def call_upgrade_script(version):
     import subprocess
-    print('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
-    try:
-        if test_mode:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
-        else:
-            retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
-        if retcode != 0:
-            print('Upgrade failed')
-    except:
-        print('Something went wrong with calling upgrade script')
+    logger.info('Upgrading sovrin node to version %s, test_mode %d ' % (version, int(test_mode)))
+    if test_mode:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node_test', version]), shell=True)
+    else:
+        retcode = subprocess.call(compose_cmd(['upgrade_sovrin_node', version]), shell=True)
+    if retcode != 0:
+        msg = 'Upgrade failed: upgrade script returned {}'.format(retcode)",32,2017-06-01 03:40:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/119522407,https://github.com/hyperledger/indy-node/pull/159#discussion_r119522407,dhh1128
https://github.com/hyperledger/indy-node/pull/131,https://github.com/hyperledger/indy-node/pull/131,"@spivachuk Can you please replace this `isVersionHigher` with semver comparisons like `semver.match(""0.3.70"", "">0.3.200"")` etc, we are not going to be moving away from semver so lets use the library and get rid of our code.",aa3def0e880ee58cffadb07d2d43f56df4a1db2d,2017-04-26 14:15:14,113462913,"@@ -7,6 +7,8 @@ def testVersions():
     assert not Upgrader.isVersionHigher('0.0.9', '0.0.8')",1,2017-04-26 14:15:29,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/113462913,https://github.com/hyperledger/indy-node/pull/131#discussion_r113462913,lovesh
https://github.com/hyperledger/indy-node/pull/111,https://github.com/hyperledger/indy-node/pull/111,sovrin-client-dev==0.3.57,3b1c597015766c3962fc19044135024bd5b69c50,2017-04-19 07:39:25,112133421,"@@ -89,9 +89,9 @@ def run(self):
     data_files=[(
         (BASE_DIR, ['data/nssm_original.exe'])
     )],
-    install_requires=['sovrin-common-dev==0.2.36', 'python-dateutil'],
+    install_requires=['sovrin-common-dev==0.2.37', 'python-dateutil'],
     setup_requires=['pytest-runner'],
-    tests_require=['pytest', 'sovrin-client-dev==0.3.53'],
+    tests_require=['pytest', 'sovrin-client-dev==0.3.54'],",,2017-04-19 09:38:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112133421,https://github.com/hyperledger/indy-node/pull/111#discussion_r112133421,keenondrums
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"If we need to change a KVStore type, we need to change implementation. It's better to inject `db` into constructor (in addition to `dbpah`), so that using another DB (for example RocksDB) can be done easily using existing `AttributeStore` class.
We can use leveldb as default for `db`",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-18 21:53:16,112073617,"@@ -0,0 +1,25 @@
+from plenum.persistence.kv_store_leveldb import KVStoreLeveldb
+
+
+class AttributeStore:
+    """"""
+    Stores attributes as key value pair where the key is hash of the
+    attribute as stored in ledger and value is the actual value if the attribute
+    """"""
+
+    def __init__(self, dbPath):
+        self.dbPath = dbPath
+        self.db = KVStoreLeveldb(dbPath)",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112073617,https://github.com/hyperledger/indy-node/pull/101#discussion_r112073617,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,What is 'Iv'?,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-18 21:59:37,112074754,"@@ -0,0 +1,201 @@
+import os
+
+from collections import OrderedDict
+import rlp
+
+from plenum.common.constants import VERKEY, TRUSTEE, STEWARD
+from plenum.common.types import f
+from plenum.persistence.kv_store_leveldb import KVStoreLeveldb
+from sovrin_common.constants import ROLE, TGB, TRUST_ANCHOR
+from stp_core.common.log import getlogger
+
+logger = getlogger()
+
+
+class IdrCache:
+    """"""
+    A cache to store a role and verkey of an identifier, the db is only used to
+    store committed data, uncommitted data goes to memory
+    The key is the identifier and value is a pack of fields
+    The first byte indicates whether the identifier has a guardian or not,
+    if it has then the next few bytes will be the guardian's identifier
+    otherwise they will be the verkey. Then there is delimiter byte after which
+    the value of role starts. eg.
+    Value in case of guardian: '\2<guardian's DID>\0<role of the DID>'
+    Value in case of no guardian: '\1<verkey of the DID>\0<role of the DID>'
+    """"""
+
+    unsetVerkey = b'-'
+
+    def __init__(self, basedir: str, name):
+        logger.debug('Initializing identity cache {} at {}'
+                     .format(name, basedir))
+        self._basedir = basedir
+        self._name = name
+        self._db = None
+        self.open()
+        # OrderedDict where key is the state root after batch and value is a
+        # dictionary similar to cache which can be queried like the
+        # database, i.e `self._db`. Keys (state roots are purged) when they
+        # get committed or reverted.
+        self.unCommitted = OrderedDict() # type: Dict[bytes, OrderedDict]
+
+        # Relevant NYMs operation done in current batch, in order
+        self.currentBatchOps = []   # type: List[Tuple]
+
+    @staticmethod
+    def encodeVerkey(verkey):
+        if verkey is None:
+            return IdrCache.unsetVerkey
+        else:
+            if isinstance(verkey, str):
+                return verkey.encode()
+            return verkey
+
+    @staticmethod
+    def decodeVerkey(verkey):
+        if verkey == IdrCache.unsetVerkey:
+            return None
+        else:
+            return verkey.decode()
+
+    @staticmethod
+    def getPrefixAndIv(guardian=None, verkey=None):",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112074754,https://github.com/hyperledger/indy-node/pull/101#discussion_r112074754,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,What is `ta`?,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-18 22:00:31,112074927,"@@ -0,0 +1,201 @@
+import os
+
+from collections import OrderedDict
+import rlp
+
+from plenum.common.constants import VERKEY, TRUSTEE, STEWARD
+from plenum.common.types import f
+from plenum.persistence.kv_store_leveldb import KVStoreLeveldb
+from sovrin_common.constants import ROLE, TGB, TRUST_ANCHOR
+from stp_core.common.log import getlogger
+
+logger = getlogger()
+
+
+class IdrCache:
+    """"""
+    A cache to store a role and verkey of an identifier, the db is only used to
+    store committed data, uncommitted data goes to memory
+    The key is the identifier and value is a pack of fields
+    The first byte indicates whether the identifier has a guardian or not,
+    if it has then the next few bytes will be the guardian's identifier
+    otherwise they will be the verkey. Then there is delimiter byte after which
+    the value of role starts. eg.
+    Value in case of guardian: '\2<guardian's DID>\0<role of the DID>'
+    Value in case of no guardian: '\1<verkey of the DID>\0<role of the DID>'
+    """"""
+
+    unsetVerkey = b'-'
+
+    def __init__(self, basedir: str, name):
+        logger.debug('Initializing identity cache {} at {}'
+                     .format(name, basedir))
+        self._basedir = basedir
+        self._name = name
+        self._db = None
+        self.open()
+        # OrderedDict where key is the state root after batch and value is a
+        # dictionary similar to cache which can be queried like the
+        # database, i.e `self._db`. Keys (state roots are purged) when they
+        # get committed or reverted.
+        self.unCommitted = OrderedDict() # type: Dict[bytes, OrderedDict]
+
+        # Relevant NYMs operation done in current batch, in order
+        self.currentBatchOps = []   # type: List[Tuple]
+
+    @staticmethod
+    def encodeVerkey(verkey):
+        if verkey is None:
+            return IdrCache.unsetVerkey
+        else:
+            if isinstance(verkey, str):
+                return verkey.encode()
+            return verkey
+
+    @staticmethod
+    def decodeVerkey(verkey):
+        if verkey == IdrCache.unsetVerkey:
+            return None
+        else:
+            return verkey.decode()
+
+    @staticmethod
+    def getPrefixAndIv(guardian=None, verkey=None):
+        iv = guardian if guardian else verkey
+        prefix = b'1' if guardian else b'0'
+        return prefix, iv
+
+    @staticmethod
+    def packIdrValue(ta=None, role=None, verkey=None):
+        # prefix, iv = IdrCache.getPrefixAndIv(guardian, verkey)
+        if ta is None:",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112074927,https://github.com/hyperledger/indy-node/pull/101#discussion_r112074927,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"If we need to change a KVStore type, we need to change implementation. It's better to inject db, so that using another DB (for example RocksDB) can be done easily without changing IdrCache class.
We can use leveldb as default for db.",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-18 22:11:02,112076589,"@@ -0,0 +1,201 @@
+import os
+
+from collections import OrderedDict
+import rlp
+
+from plenum.common.constants import VERKEY, TRUSTEE, STEWARD
+from plenum.common.types import f
+from plenum.persistence.kv_store_leveldb import KVStoreLeveldb
+from sovrin_common.constants import ROLE, TGB, TRUST_ANCHOR
+from stp_core.common.log import getlogger
+
+logger = getlogger()
+
+
+class IdrCache:
+    """"""
+    A cache to store a role and verkey of an identifier, the db is only used to
+    store committed data, uncommitted data goes to memory
+    The key is the identifier and value is a pack of fields
+    The first byte indicates whether the identifier has a guardian or not,
+    if it has then the next few bytes will be the guardian's identifier
+    otherwise they will be the verkey. Then there is delimiter byte after which
+    the value of role starts. eg.
+    Value in case of guardian: '\2<guardian's DID>\0<role of the DID>'
+    Value in case of no guardian: '\1<verkey of the DID>\0<role of the DID>'
+    """"""
+
+    unsetVerkey = b'-'
+
+    def __init__(self, basedir: str, name):
+        logger.debug('Initializing identity cache {} at {}'
+                     .format(name, basedir))
+        self._basedir = basedir
+        self._name = name
+        self._db = None
+        self.open()
+        # OrderedDict where key is the state root after batch and value is a
+        # dictionary similar to cache which can be queried like the
+        # database, i.e `self._db`. Keys (state roots are purged) when they
+        # get committed or reverted.
+        self.unCommitted = OrderedDict() # type: Dict[bytes, OrderedDict]
+
+        # Relevant NYMs operation done in current batch, in order
+        self.currentBatchOps = []   # type: List[Tuple]
+
+    @staticmethod
+    def encodeVerkey(verkey):
+        if verkey is None:
+            return IdrCache.unsetVerkey
+        else:
+            if isinstance(verkey, str):
+                return verkey.encode()
+            return verkey
+
+    @staticmethod
+    def decodeVerkey(verkey):
+        if verkey == IdrCache.unsetVerkey:
+            return None
+        else:
+            return verkey.decode()
+
+    @staticmethod
+    def getPrefixAndIv(guardian=None, verkey=None):
+        iv = guardian if guardian else verkey
+        prefix = b'1' if guardian else b'0'
+        return prefix, iv
+
+    @staticmethod
+    def packIdrValue(ta=None, role=None, verkey=None):
+        # prefix, iv = IdrCache.getPrefixAndIv(guardian, verkey)
+        if ta is None:
+            ta = b''
+        if role is None:
+            role = b''
+        verkey = IdrCache.encodeVerkey(verkey)
+        return rlp.encode([ta, verkey, role])
+
+    @staticmethod
+    def unpackIdrValue(value):
+        ta, verkey, role = rlp.decode(value)
+        return ta.decode(), IdrCache.decodeVerkey(verkey), role.decode()
+
+    def get(self, idr, isCommitted=True):
+        idr = idr.encode()
+        if isCommitted:
+            value = self._db.get(idr)
+        else:
+            # Looking for uncommitted values, iterating over `self.unCommitted`
+            # in reverse to get the latest value
+            for i, cache in reversed(self.unCommitted.items()):
+                if idr in cache:
+                    value = cache[idr]
+                    break
+            else:
+                value = self._db.get(idr)
+        ta, iv, r = self.unpackIdrValue(value)
+        return ta, iv, r
+
+    def set(self, idr, ta=None, verkey=None, role=None, isCommitted=True):
+        val = self.packIdrValue(ta, role, verkey)
+        if isCommitted:
+            self._db.set(idr, val)
+        else:
+            self.currentBatchOps.append((idr, val))
+
+    def close(self):
+        self._db.close()
+
+    def open(self):",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112076589,https://github.com/hyperledger/indy-node/pull/101#discussion_r112076589,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"Avoid using the same name for classes from different modules.
Consider rename the current class to SovrinDomainReqHandler",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-18 22:40:15,112081344,"@@ -0,0 +1,346 @@
+import json
+from binascii import unhexlify
+from typing import List
+from hashlib import sha256
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest, UnknownIdentifier
+from plenum.common.constants import TXN_TYPE, TARGET_NYM, RAW, ENC, HASH, \
+    VERKEY, DATA, NAME, VERSION
+from plenum.common.types import f
+from plenum.common.util import check_endpoint_valid
+from plenum.server.domain_req_handler import DomainRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NYM, ROLE, ATTRIB, ENDPOINT, SCHEMA, \
+    ISSUER_KEY, REF
+from sovrin_common.types import Request
+from stp_core.common.log import getlogger
+from stp_core.network.exceptions import EndpointException
+
+
+logger = getlogger()
+
+
+class DomainReqHandler(PHandler):",24,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112081344,https://github.com/hyperledger/indy-node/pull/101#discussion_r112081344,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"We renamed IPK to CLAIM_DEF in master recently, so please use claim_def instead",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-18 22:41:19,112081494,"@@ -0,0 +1,346 @@
+import json
+from binascii import unhexlify
+from typing import List
+from hashlib import sha256
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest, UnknownIdentifier
+from plenum.common.constants import TXN_TYPE, TARGET_NYM, RAW, ENC, HASH, \
+    VERKEY, DATA, NAME, VERSION
+from plenum.common.types import f
+from plenum.common.util import check_endpoint_valid
+from plenum.server.domain_req_handler import DomainRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NYM, ROLE, ATTRIB, ENDPOINT, SCHEMA, \
+    ISSUER_KEY, REF
+from sovrin_common.types import Request
+from stp_core.common.log import getlogger
+from stp_core.network.exceptions import EndpointException
+
+
+logger = getlogger()
+
+
+class DomainReqHandler(PHandler):
+    MARKER_ATTR = ""\01""
+    MARKER_SCHEMA = ""\02""
+    MARKER_IPK = ""\03""",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112081494,https://github.com/hyperledger/indy-node/pull/101#discussion_r112081494,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"Please split the method to perform static validation for each txn type (like `doStaticValidationNym`, `doStaticValidationAttr`)",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-18 22:44:35,112081968,"@@ -0,0 +1,346 @@
+import json
+from binascii import unhexlify
+from typing import List
+from hashlib import sha256
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest, UnknownIdentifier
+from plenum.common.constants import TXN_TYPE, TARGET_NYM, RAW, ENC, HASH, \
+    VERKEY, DATA, NAME, VERSION
+from plenum.common.types import f
+from plenum.common.util import check_endpoint_valid
+from plenum.server.domain_req_handler import DomainRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NYM, ROLE, ATTRIB, ENDPOINT, SCHEMA, \
+    ISSUER_KEY, REF
+from sovrin_common.types import Request
+from stp_core.common.log import getlogger
+from stp_core.network.exceptions import EndpointException
+
+
+logger = getlogger()
+
+
+class DomainReqHandler(PHandler):
+    MARKER_ATTR = ""\01""
+    MARKER_SCHEMA = ""\02""
+    MARKER_IPK = ""\03""
+    LAST_SEQ_NO = ""lsn""
+    VALUE = ""val""
+
+    def __init__(self, ledger, state, requestProcessor, idrCache, attributeStore):
+        super().__init__(ledger, state, requestProcessor)
+        self.idrCache = idrCache
+        self.attributeStore = attributeStore
+
+    def onBatchCreated(self, stateRoot):
+        self.idrCache.currentBatchCreated(stateRoot)
+
+    def onBatchRejected(self, stateRoot=None):
+        self.idrCache.batchRejected(stateRoot)
+
+    def updateState(self, txns, isCommitted=False):
+        for txn in txns:
+            typ = txn.get(TXN_TYPE)
+            nym = txn.get(TARGET_NYM)
+            if typ == NYM:
+                data = {f.IDENTIFIER.nm: txn.get(f.IDENTIFIER.nm)}
+                if ROLE in txn:
+                    data[ROLE] = txn.get(ROLE)
+                if VERKEY in txn:
+                    data[VERKEY] = txn.get(VERKEY)
+                self.updateNym(nym, data, isCommitted=isCommitted)
+            elif typ == ATTRIB:
+                self._addAttr(txn)
+            elif typ == SCHEMA:
+                self._addSchema(txn)
+            elif typ == ISSUER_KEY:
+                self._addIssuerKey(txn)
+            else:
+                logger.debug('Cannot apply request of type {} to state'.format(typ))
+
+    def commit(self, txnCount, stateRoot, txnRoot) -> List:
+        r = super().commit(txnCount, stateRoot, txnRoot)
+        self.idrCache.onBatchCommitted(unhexlify(stateRoot.encode()))
+        return r
+
+    def canNymRequestBeProcessed(self, identifier, msg) -> (bool, str):
+        nym = msg.get(TARGET_NYM)
+        if self.hasNym(nym, isCommitted=False):
+            if not self.idrCache.hasTrustee(identifier, isCommitted=False) and \
+                            self.idrCache.getOwnerFor(nym, isCommitted=False) != identifier:
+                reason = '{} is neither Trustee nor owner of {}'\
+                    .format(identifier, nym)
+                return False, reason
+        return True, ''
+
+    def doStaticValidation(self, identifier, reqId, operation):",76,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112081968,https://github.com/hyperledger/indy-node/pull/101#discussion_r112081968,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"Please split the method to perform validation for each txn type (like doValidateNym, doValidateAttr)",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-18 22:45:29,112082092,"@@ -0,0 +1,346 @@
+import json
+from binascii import unhexlify
+from typing import List
+from hashlib import sha256
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest, UnknownIdentifier
+from plenum.common.constants import TXN_TYPE, TARGET_NYM, RAW, ENC, HASH, \
+    VERKEY, DATA, NAME, VERSION
+from plenum.common.types import f
+from plenum.common.util import check_endpoint_valid
+from plenum.server.domain_req_handler import DomainRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NYM, ROLE, ATTRIB, ENDPOINT, SCHEMA, \
+    ISSUER_KEY, REF
+from sovrin_common.types import Request
+from stp_core.common.log import getlogger
+from stp_core.network.exceptions import EndpointException
+
+
+logger = getlogger()
+
+
+class DomainReqHandler(PHandler):
+    MARKER_ATTR = ""\01""
+    MARKER_SCHEMA = ""\02""
+    MARKER_IPK = ""\03""
+    LAST_SEQ_NO = ""lsn""
+    VALUE = ""val""
+
+    def __init__(self, ledger, state, requestProcessor, idrCache, attributeStore):
+        super().__init__(ledger, state, requestProcessor)
+        self.idrCache = idrCache
+        self.attributeStore = attributeStore
+
+    def onBatchCreated(self, stateRoot):
+        self.idrCache.currentBatchCreated(stateRoot)
+
+    def onBatchRejected(self, stateRoot=None):
+        self.idrCache.batchRejected(stateRoot)
+
+    def updateState(self, txns, isCommitted=False):
+        for txn in txns:
+            typ = txn.get(TXN_TYPE)
+            nym = txn.get(TARGET_NYM)
+            if typ == NYM:
+                data = {f.IDENTIFIER.nm: txn.get(f.IDENTIFIER.nm)}
+                if ROLE in txn:
+                    data[ROLE] = txn.get(ROLE)
+                if VERKEY in txn:
+                    data[VERKEY] = txn.get(VERKEY)
+                self.updateNym(nym, data, isCommitted=isCommitted)
+            elif typ == ATTRIB:
+                self._addAttr(txn)
+            elif typ == SCHEMA:
+                self._addSchema(txn)
+            elif typ == ISSUER_KEY:
+                self._addIssuerKey(txn)
+            else:
+                logger.debug('Cannot apply request of type {} to state'.format(typ))
+
+    def commit(self, txnCount, stateRoot, txnRoot) -> List:
+        r = super().commit(txnCount, stateRoot, txnRoot)
+        self.idrCache.onBatchCommitted(unhexlify(stateRoot.encode()))
+        return r
+
+    def canNymRequestBeProcessed(self, identifier, msg) -> (bool, str):
+        nym = msg.get(TARGET_NYM)
+        if self.hasNym(nym, isCommitted=False):
+            if not self.idrCache.hasTrustee(identifier, isCommitted=False) and \
+                            self.idrCache.getOwnerFor(nym, isCommitted=False) != identifier:
+                reason = '{} is neither Trustee nor owner of {}'\
+                    .format(identifier, nym)
+                return False, reason
+        return True, ''
+
+    def doStaticValidation(self, identifier, reqId, operation):
+        if operation[TXN_TYPE] == NYM:
+            role = operation.get(ROLE)
+            nym = operation.get(TARGET_NYM)
+            if not nym:
+                raise InvalidClientRequest(identifier, reqId,
+                                           ""{} needs to be present"".
+                                           format(TARGET_NYM))
+            if not Authoriser.isValidRole(role):
+                raise InvalidClientRequest(identifier, reqId,
+                                           ""{} not a valid role"".
+                                           format(role))
+            s, reason = self.canNymRequestBeProcessed(identifier, operation)
+            if not s:
+                raise InvalidClientRequest(identifier, reqId, reason)
+
+        if operation[TXN_TYPE] == ATTRIB:
+            dataKeys = {RAW, ENC, HASH}.intersection(set(operation.keys()))
+            if len(dataKeys) != 1:
+                raise InvalidClientRequest(identifier, reqId,
+                                           '{} should have one and only one of '
+                                           '{}, {}, {}'
+                                           .format(ATTRIB, RAW, ENC, HASH))
+            if RAW in dataKeys:
+                try:
+                    data = json.loads(operation[RAW])
+                    endpoint = data.get(ENDPOINT, {}).get('ha')
+                    check_endpoint_valid(endpoint, required=False)
+
+                except EndpointException as exc:
+                    raise InvalidClientRequest(identifier, reqId, str(exc))
+                except BaseException as exc:
+                    raise InvalidClientRequest(identifier, reqId, str(exc))
+                    # PREVIOUS CODE, ASSUMED ANY EXCEPTION WAS A JSON ISSUE
+                    # except:
+                    #     raise InvalidClientRequest(identifier, reqId,
+                    #                                'raw attribute {} should be '
+                    #                                'JSON'.format(operation[RAW]))
+
+            if not (not operation.get(TARGET_NYM) or
+                    self.hasNym(operation[TARGET_NYM], isCommitted=False)):
+                raise InvalidClientRequest(identifier, reqId,
+                                           '{} should be added before adding '
+                                           'attribute for it'.
+                                           format(TARGET_NYM))
+
+    def validate(self, req: Request, config=None):",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112082092,https://github.com/hyperledger/indy-node/pull/101#discussion_r112082092,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,Split to `doValidateExistingNym` and `doValidateNewNym`,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-18 22:46:41,112082285,"@@ -0,0 +1,346 @@
+import json
+from binascii import unhexlify
+from typing import List
+from hashlib import sha256
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest, UnknownIdentifier
+from plenum.common.constants import TXN_TYPE, TARGET_NYM, RAW, ENC, HASH, \
+    VERKEY, DATA, NAME, VERSION
+from plenum.common.types import f
+from plenum.common.util import check_endpoint_valid
+from plenum.server.domain_req_handler import DomainRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NYM, ROLE, ATTRIB, ENDPOINT, SCHEMA, \
+    ISSUER_KEY, REF
+from sovrin_common.types import Request
+from stp_core.common.log import getlogger
+from stp_core.network.exceptions import EndpointException
+
+
+logger = getlogger()
+
+
+class DomainReqHandler(PHandler):
+    MARKER_ATTR = ""\01""
+    MARKER_SCHEMA = ""\02""
+    MARKER_IPK = ""\03""
+    LAST_SEQ_NO = ""lsn""
+    VALUE = ""val""
+
+    def __init__(self, ledger, state, requestProcessor, idrCache, attributeStore):
+        super().__init__(ledger, state, requestProcessor)
+        self.idrCache = idrCache
+        self.attributeStore = attributeStore
+
+    def onBatchCreated(self, stateRoot):
+        self.idrCache.currentBatchCreated(stateRoot)
+
+    def onBatchRejected(self, stateRoot=None):
+        self.idrCache.batchRejected(stateRoot)
+
+    def updateState(self, txns, isCommitted=False):
+        for txn in txns:
+            typ = txn.get(TXN_TYPE)
+            nym = txn.get(TARGET_NYM)
+            if typ == NYM:
+                data = {f.IDENTIFIER.nm: txn.get(f.IDENTIFIER.nm)}
+                if ROLE in txn:
+                    data[ROLE] = txn.get(ROLE)
+                if VERKEY in txn:
+                    data[VERKEY] = txn.get(VERKEY)
+                self.updateNym(nym, data, isCommitted=isCommitted)
+            elif typ == ATTRIB:
+                self._addAttr(txn)
+            elif typ == SCHEMA:
+                self._addSchema(txn)
+            elif typ == ISSUER_KEY:
+                self._addIssuerKey(txn)
+            else:
+                logger.debug('Cannot apply request of type {} to state'.format(typ))
+
+    def commit(self, txnCount, stateRoot, txnRoot) -> List:
+        r = super().commit(txnCount, stateRoot, txnRoot)
+        self.idrCache.onBatchCommitted(unhexlify(stateRoot.encode()))
+        return r
+
+    def canNymRequestBeProcessed(self, identifier, msg) -> (bool, str):
+        nym = msg.get(TARGET_NYM)
+        if self.hasNym(nym, isCommitted=False):
+            if not self.idrCache.hasTrustee(identifier, isCommitted=False) and \
+                            self.idrCache.getOwnerFor(nym, isCommitted=False) != identifier:
+                reason = '{} is neither Trustee nor owner of {}'\
+                    .format(identifier, nym)
+                return False, reason
+        return True, ''
+
+    def doStaticValidation(self, identifier, reqId, operation):
+        if operation[TXN_TYPE] == NYM:
+            role = operation.get(ROLE)
+            nym = operation.get(TARGET_NYM)
+            if not nym:
+                raise InvalidClientRequest(identifier, reqId,
+                                           ""{} needs to be present"".
+                                           format(TARGET_NYM))
+            if not Authoriser.isValidRole(role):
+                raise InvalidClientRequest(identifier, reqId,
+                                           ""{} not a valid role"".
+                                           format(role))
+            s, reason = self.canNymRequestBeProcessed(identifier, operation)
+            if not s:
+                raise InvalidClientRequest(identifier, reqId, reason)
+
+        if operation[TXN_TYPE] == ATTRIB:
+            dataKeys = {RAW, ENC, HASH}.intersection(set(operation.keys()))
+            if len(dataKeys) != 1:
+                raise InvalidClientRequest(identifier, reqId,
+                                           '{} should have one and only one of '
+                                           '{}, {}, {}'
+                                           .format(ATTRIB, RAW, ENC, HASH))
+            if RAW in dataKeys:
+                try:
+                    data = json.loads(operation[RAW])
+                    endpoint = data.get(ENDPOINT, {}).get('ha')
+                    check_endpoint_valid(endpoint, required=False)
+
+                except EndpointException as exc:
+                    raise InvalidClientRequest(identifier, reqId, str(exc))
+                except BaseException as exc:
+                    raise InvalidClientRequest(identifier, reqId, str(exc))
+                    # PREVIOUS CODE, ASSUMED ANY EXCEPTION WAS A JSON ISSUE
+                    # except:
+                    #     raise InvalidClientRequest(identifier, reqId,
+                    #                                'raw attribute {} should be '
+                    #                                'JSON'.format(operation[RAW]))
+
+            if not (not operation.get(TARGET_NYM) or
+                    self.hasNym(operation[TARGET_NYM], isCommitted=False)):
+                raise InvalidClientRequest(identifier, reqId,
+                                           '{} should be added before adding '
+                                           'attribute for it'.
+                                           format(TARGET_NYM))
+
+    def validate(self, req: Request, config=None):
+        op = req.operation
+        typ = op[TXN_TYPE]
+
+        s = self.idrCache
+
+        origin = req.identifier
+
+        if typ == NYM:
+            try:
+                originRole = s.getRole(origin, isCommitted=False) or None
+            except:
+                raise UnknownIdentifier(
+                    req.identifier,
+                    req.reqId)
+
+            nymData = s.getNym(op[TARGET_NYM], isCommitted=False)
+            if not nymData:",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112082285,https://github.com/hyperledger/indy-node/pull/101#discussion_r112082285,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,Should we come back to it and support GET_TXNS?,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 02:07:59,112103238,"@@ -439,120 +317,62 @@ def defaultNodeAuthNr(self):
         c += self.upgrader.service()
         return c
 
-    def processGetNymReq(self, request: Request, frm: str):
-        self.transmitToClient(RequestAck(*request.key), frm)
-        nym = request.operation[TARGET_NYM]
-        txn = self.graphStore.getAddNymTxn(nym)
-        txnId = self.genTxnId(request.identifier, request.reqId)
-        # TODO: We should have a single JSON encoder which does the
-        # encoding for us, like sorting by keys, handling datetime objects.
-        result = {f.IDENTIFIER.nm: request.identifier,
-                  f.REQ_ID.nm: request.reqId,
-                  DATA: json.dumps(txn, sort_keys=True) if txn else None,
-                  TXN_ID: txnId
-                  }
-        result.update(request.operation)
-        self.transmitToClient(Reply(result), frm)
-
-    def processGetTxnReq(self, request: Request, frm: str):
-        nym = request.operation[TARGET_NYM]
-        origin = request.identifier
-        if nym != origin:
-            # TODO not sure this is correct; why does it matter?
-            msg = ""You can only receive transactions for yourself""
-            self.transmitToClient(RequestNack(*request.key, msg), frm)
-        else:
-            self.transmitToClient(RequestAck(*request.key), frm)
-            data = request.operation.get(DATA)
-            addNymTxn = self.graphStore.getAddNymTxn(origin)
-            txnIds = [addNymTxn[TXN_ID], ] + self.graphStore. \
-                getAddAttributeTxnIds(origin)
-            # If sending transactions to a user then should send user's
-            # trust anchor creation transaction also
-            if addNymTxn.get(ROLE) is None:
-                trustAnchorNymTxn = self.graphStore.getAddNymTxn(
-                    addNymTxn.get(f.IDENTIFIER.nm))
-                txnIds = [trustAnchorNymTxn[TXN_ID], ] + txnIds
-            # TODO: Remove this log statement
-            logger.debug(""{} getting replies for {}"".format(self, txnIds))
-            result = self.secondaryStorage.getReplies(*txnIds, seqNo=data)
-            txns = sorted(list(result.values()), key=itemgetter(F.seqNo.name))
-            lastTxn = str(txns[-1][F.seqNo.name]) if len(txns) > 0 else data
-            result = {
-                TXN_ID: self.genTxnId(
-                    request.identifier, request.reqId)
-            }
-            result.update(request.operation)
-            # TODO: We should have a single JSON encoder which does the
-            # encoding for us, like sorting by keys, handling datetime objects.
-            result[DATA] = json.dumps({
-                LAST_TXN: lastTxn,
-                TXNS: txns
-            }, default=dateTimeEncoding, sort_keys=True)
-            result.update({
-                f.IDENTIFIER.nm: request.identifier,
-                f.REQ_ID.nm: request.reqId,
-            })
-            self.transmitToClient(Reply(result), frm)
-
     def processGetSchemaReq(self, request: Request, frm: str):
-        issuerNym = request.operation[TARGET_NYM]
-        name = request.operation[DATA][NAME]
-        version = request.operation[DATA][VERSION]
-        schema = self.graphStore.getSchema(issuerNym, name, version)
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        result.update(request.operation)
-        result[DATA] = json.dumps(schema, sort_keys=True)
-        result.update({
+        self.transmitToClient(RequestAck(*request.key), frm)
+        authorDid = request.operation[TARGET_NYM]
+        schema, lastSeqNo = self.reqHandler.getSchema(
+            author=authorDid,
+            schemaName=(request.operation[DATA][NAME]),
+            schemaVersion=(request.operation[DATA][VERSION])
+        )
+        schema.update({ORIGIN: authorDid})
+        result = {**request.operation, **{
+            DATA: schema,
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+            f.SEQ_NO.nm: lastSeqNo
+        }}
         self.transmitToClient(Reply(result), frm)
 
     def processGetAttrsReq(self, request: Request, frm: str):
         self.transmitToClient(RequestAck(*request.key), frm)
         attrName = request.operation[RAW]
         nym = request.operation[TARGET_NYM]
-        attrWithSeqNo = self.graphStore.getRawAttrs(nym, attrName)
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        if attrWithSeqNo:
-            attr = {attrName: attrWithSeqNo[attrName][0]}
-            result[DATA] = json.dumps(attr, sort_keys=True)
-            result[F.seqNo.name] = attrWithSeqNo[attrName][1]
-        result.update(request.operation)
-        result.update({
+        attrValue, lastSeqNo = \
+            self.reqHandler.getAttr(did=nym, key=attrName)
+        result = {**request.operation, **{
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+        }}
+        if attrValue is not None:
+            attr = json.dumps({attrName: attrValue}, sort_keys=True)
+            result[DATA] = attr
+            result[f.SEQ_NO.nm] = lastSeqNo
         self.transmitToClient(Reply(result), frm)
 
     def processGetIssuerKeyReq(self, request: Request, frm: str):
         self.transmitToClient(RequestAck(*request.key), frm)
-        keys = self.graphStore.getIssuerKeys(request.operation[ORIGIN],
-                                             request.operation[REF])
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        result.update(request.operation)
-        result[DATA] = json.dumps(keys, sort_keys=True)
-        result.update({
+        keys, lastSeqNo = self.reqHandler.getIssuerKey(
+            author=request.operation[ORIGIN],
+            schemaSeqNo=request.operation[REF]
+        )
+        result = {**request.operation, **{
+            DATA: keys,
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+            f.SEQ_NO.nm: lastSeqNo
+        }}
         self.transmitToClient(Reply(result), frm)
 
     def processRequest(self, request: Request, frm: str):
         if request.operation[TXN_TYPE] == GET_NYM:
-            self.processGetNymReq(request, frm)
+            self.transmitToClient(RequestAck(*request.key), frm)
+            result = self.reqHandler.handleGetNymReq(request, frm)
+            self.transmitToClient(Reply(result), frm)
+        # TODO: Come back to it
         elif request.operation[TXN_TYPE] == GET_TXNS:
-            self.processGetTxnReq(request, frm)
+            # self.processGetTxnReq(request, frm)",678,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112103238,https://github.com/hyperledger/indy-node/pull/101#discussion_r112103238,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"It's very inefficient to get all transactions and iterate through them. Do we use this method? If we use it, then it needs to be fixed.",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 02:10:53,112103487,"@@ -10,6 +10,7 @@ class NodeAuthNr(NaclAuthNr):
     def __init__(self, ledger: Ledger):
         self.ledger = ledger
 
+    # TODO: This is not right, what if verkey changes?",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112103487,https://github.com/hyperledger/indy-node/pull/101#discussion_r112103487,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,Please use a different class name (avoid classes with the same name from different packages),40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 02:12:59,112103663,"@@ -0,0 +1,64 @@
+from copy import deepcopy
+
+from ledger.serializers.json_serializer import JsonSerializer
+from plenum.common.constants import TARGET_NYM, DATA, ALIAS, SERVICES
+
+from plenum.common.ledger import Ledger
+from plenum.persistence.pruning_state import PruningState
+from plenum.server.pool_req_handler import PoolRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NODE
+from sovrin_node.persistence.idr_cache import IdrCache
+
+
+class PoolRequestHandler(PHandler):",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112103663,https://github.com/hyperledger/indy-node/pull/101#discussion_r112103663,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,Do we clean KV storages on stopping?,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 02:13:48,112103728,"@@ -241,16 +241,10 @@ def getUpgrader(self):
         return TestUpgrader(self.id, self.name, self.dataLocation, self.config,
                             self.configLedger)
 
-    def _getOrientDbStore(self, name, dbType):
-        if not hasattr(self, '_orientDbStore'):
-            self._orientDbStore = orientdb_store.createOrientDbInMemStore(
-                self.config, name, dbType)
-        return self._orientDbStore
-
     def onStopping(self, *args, **kwargs):
         if self.cleanupOnStopping:
             self.cleanupDataLocation()
-        self.graphStore.store.close()
+        # self.graphStore.store.close()",33,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112103728,https://github.com/hyperledger/indy-node/pull/101#discussion_r112103728,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,Please remove the test if it isn't needed anymore,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 02:14:30,112103783,"@@ -1,179 +1,179 @@
-import pytest
-import json
-
-from pyorient import OrientBinaryObject
-
-from anoncreds.protocol.issuer import Issuer
-from anoncreds.protocol.repo.attributes_repo import AttributeRepoInMemory
-from anoncreds.protocol.types import Schema, ID
-from anoncreds.protocol.wallet.issuer_wallet import IssuerWalletInMemory
-from anoncreds.test.conftest import GVT
-
-from stp_core.loop.eventually import eventually
-from plenum.common.util import randomString
-from plenum.test.test_node import checkNodesConnected
-from plenum.test.node_catchup.helper import checkNodeLedgersForEquality
-
-from sovrin_client.test.conftest import primes1
-from sovrin_client.anon_creds.sovrin_public_repo import SovrinPublicRepo
-from sovrin_client.client.wallet.attribute import Attribute, LedgerStore
-from sovrin_client.client.wallet.wallet import Wallet
-from sovrin_client.client.client import Client
-
-from sovrin_client.test.helper import addRole, getClientAddedWithRole
-from sovrin_client.test.conftest import userWalletA
-from sovrin_common.constants import TGB
-
-from sovrin_node.test.helper import addAttributeAndCheck
-from sovrin_node.test.upgrade.conftest import validUpgrade
-from sovrin_node.test.helper import TestNode
-
-
-@pytest.fixture(scope=""module"")
-def anotherTGB(nodeSet, tdir, looper, trustee, trusteeWallet):
-    return getClientAddedWithRole(nodeSet, tdir, looper,
-                                  trustee, trusteeWallet,
-                                  'newTGB', TGB)
-
-
-@pytest.fixture(scope=""module"")
-def addNymTxn(looper, anotherTGB):
-    """"""
-    Make new NYM transaction
-    The new TGB adds a NYM to ledger
-    """"""
-    addRole(looper, *anotherTGB, name=randomString())
-
-
-@pytest.fixture(scope=""module"")
-def addedRawAttribute(userWalletA: Wallet, trustAnchor: Client,
-                      trustAnchorWallet: Wallet, looper):
-    attrib = Attribute(name='test attribute',
-                       origin=trustAnchorWallet.defaultId,
-                       value=json.dumps({'name': 'Mario'}),
-                       dest=userWalletA.defaultId,
-                       ledgerStore=LedgerStore.RAW)
-    addAttributeAndCheck(looper, trustAnchor, trustAnchorWallet, attrib)
-    return attrib
-
-
-@pytest.fixture(scope=""module"")
-def publicRepo(steward, stewardWallet):
-    return SovrinPublicRepo(steward, stewardWallet)
-
-
-@pytest.fixture(scope=""module"")
-def schemaDefGvt(stewardWallet):
-    return Schema('GVT', '1.0', GVT.attribNames(), 'CL',
-                  stewardWallet.defaultId)
-
-
-@pytest.fixture(scope=""module"")
-def submittedSchemaDefGvt(publicRepo, schemaDefGvt, looper):
-    return looper.run(publicRepo.submitSchema(schemaDefGvt))
-
-
-@pytest.fixture(scope=""module"")
-def submittedPublicKey(submittedPublicKeys):
-    return submittedPublicKeys[0]
-
-
-@pytest.fixture(scope=""module"")
-def issuerGvt(publicRepo):
-    return Issuer(IssuerWalletInMemory('issuer1', publicRepo),
-                  AttributeRepoInMemory())
-
-
-@pytest.fixture(scope=""module"")
-def publicSecretKey(submittedSchemaDefGvtID, issuerGvt, primes1, looper):
-    return looper.run(
-        issuerGvt._primaryIssuer.genKeys(submittedSchemaDefGvtID, **primes1))
-
-
-@pytest.fixture(scope=""module"")
-def publicSecretRevocationKey(issuerGvt, looper):
-    return looper.run(issuerGvt._nonRevocationIssuer.genRevocationKeys())
-
-
-@pytest.fixture(scope=""module"")
-def submittedSchemaDefGvtID(submittedSchemaDefGvt):
-    return ID(schemaKey=submittedSchemaDefGvt.getKey(),
-              schemaId=submittedSchemaDefGvt.seqId)
-
-
-@pytest.fixture(scope=""module"")
-def submittedPublicKeys(submittedSchemaDefGvtID, publicRepo, publicSecretKey,
-                        publicSecretRevocationKey, looper):
-    pk, sk = publicSecretKey
-    pkR, skR = publicSecretRevocationKey
-    return looper.run(
-        publicRepo.submitPublicKeys(id=submittedSchemaDefGvtID, pk=pk, pkR=pkR))
-
-
-def compareGraph(table, nodeSet):
-    """"""
-    compare stopped node graph(db) with
-    other nodes
-    """"""
-    stoppedNodeRecords = []
-    stoppedNodeClient = nodeSet[0].graphStore.client
-    stoppedNodeRecordCount = stoppedNodeClient.db_count_records()
-
-    tableRecodesStoppedNode = stoppedNodeClient.query(""SELECT * FROM {}"".format(table))
-    for nodeRecord in tableRecodesStoppedNode:
-
-        if table == ""IssuerKey"" and isinstance(nodeRecord.oRecordData[""data""], str):
-            nodeRecord.oRecordData[""data""] = json.loads(nodeRecord.oRecordData[""data""])
-
-        stoppedNodeRecords.append({k: v for k, v in nodeRecord.oRecordData.items()
-                                   if not isinstance(v, OrientBinaryObject)
-                                   })
-
-    for node in nodeSet[1:4]:
-        client = node.graphStore.client
-        recordCount = client.db_count_records()
-        assert recordCount == stoppedNodeRecordCount
-
-        records = []
-        tableRecodes = client.query(""SELECT * FROM {}"".format(table))
-        for record in tableRecodes:
-
-            if table == ""IssuerKey"" and isinstance(record.oRecordData[""data""], str):
-                record.oRecordData[""data""] = json.loads(record.oRecordData[""data""])
-
-            records.append({k: v for k, v in record.oRecordData.items()
-                            if not isinstance(v, OrientBinaryObject)
-                            })
-        assert records == stoppedNodeRecords
-
-
-def testReplayLedger(addNymTxn, addedRawAttribute, submittedPublicKeys,
-                     nodeSet, looper, tconf, tdirWithPoolTxns,
-                     allPluginsPath, txnPoolNodeSet):
-    """"""
-    stop first node (which will clean graph db too)
-    then restart node
-    """"""
-    nodeToStop = nodeSet[0]
-    nodeToStop.cleanupOnStopping = False
-    looper.removeProdable(nodeToStop)
-    nodeToStop.stop()
-    name = nodeToStop.name
-    nha = nodeToStop.nodestack.ha
-    cha = nodeToStop.clientstack.ha
-    del nodeToStop
-
-    #client = nodeToStop.graphStore.client
-    #client.db_drop(client._connection.db_opened)
-    newNode = TestNode(name, basedirpath=tdirWithPoolTxns,
-                       config=tconf, pluginPaths=allPluginsPath,
-                       ha=nha, cliha=cha)
-    looper.add(newNode)
-    nodeSet[0] = newNode
-    looper.run(checkNodesConnected(nodeSet, customTimeout=30))
-    looper.run(eventually(checkNodeLedgersForEquality, newNode,
-                          *txnPoolNodeSet[1:4], retryWait=1, timeout=15))
-
-    compareGraph(""NYM"", nodeSet)
-    compareGraph(""IssuerKey"", nodeSet)
-    compareGraph(""Schema"", nodeSet)
+# import pytest",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112103783,https://github.com/hyperledger/indy-node/pull/101#discussion_r112103783,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"Obsolete, remvoed",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 04:13:50,112112636,"@@ -0,0 +1,201 @@
+import os
+
+from collections import OrderedDict
+import rlp
+
+from plenum.common.constants import VERKEY, TRUSTEE, STEWARD
+from plenum.common.types import f
+from plenum.persistence.kv_store_leveldb import KVStoreLeveldb
+from sovrin_common.constants import ROLE, TGB, TRUST_ANCHOR
+from stp_core.common.log import getlogger
+
+logger = getlogger()
+
+
+class IdrCache:
+    """"""
+    A cache to store a role and verkey of an identifier, the db is only used to
+    store committed data, uncommitted data goes to memory
+    The key is the identifier and value is a pack of fields
+    The first byte indicates whether the identifier has a guardian or not,
+    if it has then the next few bytes will be the guardian's identifier
+    otherwise they will be the verkey. Then there is delimiter byte after which
+    the value of role starts. eg.
+    Value in case of guardian: '\2<guardian's DID>\0<role of the DID>'
+    Value in case of no guardian: '\1<verkey of the DID>\0<role of the DID>'
+    """"""
+
+    unsetVerkey = b'-'
+
+    def __init__(self, basedir: str, name):
+        logger.debug('Initializing identity cache {} at {}'
+                     .format(name, basedir))
+        self._basedir = basedir
+        self._name = name
+        self._db = None
+        self.open()
+        # OrderedDict where key is the state root after batch and value is a
+        # dictionary similar to cache which can be queried like the
+        # database, i.e `self._db`. Keys (state roots are purged) when they
+        # get committed or reverted.
+        self.unCommitted = OrderedDict() # type: Dict[bytes, OrderedDict]
+
+        # Relevant NYMs operation done in current batch, in order
+        self.currentBatchOps = []   # type: List[Tuple]
+
+    @staticmethod
+    def encodeVerkey(verkey):
+        if verkey is None:
+            return IdrCache.unsetVerkey
+        else:
+            if isinstance(verkey, str):
+                return verkey.encode()
+            return verkey
+
+    @staticmethod
+    def decodeVerkey(verkey):
+        if verkey == IdrCache.unsetVerkey:
+            return None
+        else:
+            return verkey.decode()
+
+    @staticmethod
+    def getPrefixAndIv(guardian=None, verkey=None):",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112112636,https://github.com/hyperledger/indy-node/pull/101#discussion_r112112636,lovesh
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,Trust Anchor,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 04:14:01,112112647,"@@ -0,0 +1,201 @@
+import os
+
+from collections import OrderedDict
+import rlp
+
+from plenum.common.constants import VERKEY, TRUSTEE, STEWARD
+from plenum.common.types import f
+from plenum.persistence.kv_store_leveldb import KVStoreLeveldb
+from sovrin_common.constants import ROLE, TGB, TRUST_ANCHOR
+from stp_core.common.log import getlogger
+
+logger = getlogger()
+
+
+class IdrCache:
+    """"""
+    A cache to store a role and verkey of an identifier, the db is only used to
+    store committed data, uncommitted data goes to memory
+    The key is the identifier and value is a pack of fields
+    The first byte indicates whether the identifier has a guardian or not,
+    if it has then the next few bytes will be the guardian's identifier
+    otherwise they will be the verkey. Then there is delimiter byte after which
+    the value of role starts. eg.
+    Value in case of guardian: '\2<guardian's DID>\0<role of the DID>'
+    Value in case of no guardian: '\1<verkey of the DID>\0<role of the DID>'
+    """"""
+
+    unsetVerkey = b'-'
+
+    def __init__(self, basedir: str, name):
+        logger.debug('Initializing identity cache {} at {}'
+                     .format(name, basedir))
+        self._basedir = basedir
+        self._name = name
+        self._db = None
+        self.open()
+        # OrderedDict where key is the state root after batch and value is a
+        # dictionary similar to cache which can be queried like the
+        # database, i.e `self._db`. Keys (state roots are purged) when they
+        # get committed or reverted.
+        self.unCommitted = OrderedDict() # type: Dict[bytes, OrderedDict]
+
+        # Relevant NYMs operation done in current batch, in order
+        self.currentBatchOps = []   # type: List[Tuple]
+
+    @staticmethod
+    def encodeVerkey(verkey):
+        if verkey is None:
+            return IdrCache.unsetVerkey
+        else:
+            if isinstance(verkey, str):
+                return verkey.encode()
+            return verkey
+
+    @staticmethod
+    def decodeVerkey(verkey):
+        if verkey == IdrCache.unsetVerkey:
+            return None
+        else:
+            return verkey.decode()
+
+    @staticmethod
+    def getPrefixAndIv(guardian=None, verkey=None):
+        iv = guardian if guardian else verkey
+        prefix = b'1' if guardian else b'0'
+        return prefix, iv
+
+    @staticmethod
+    def packIdrValue(ta=None, role=None, verkey=None):
+        # prefix, iv = IdrCache.getPrefixAndIv(guardian, verkey)
+        if ta is None:",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112112647,https://github.com/hyperledger/indy-node/pull/101#discussion_r112112647,lovesh
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"No, its fine, i was premature to build it",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 04:15:01,112112724,"@@ -439,120 +317,62 @@ def defaultNodeAuthNr(self):
         c += self.upgrader.service()
         return c
 
-    def processGetNymReq(self, request: Request, frm: str):
-        self.transmitToClient(RequestAck(*request.key), frm)
-        nym = request.operation[TARGET_NYM]
-        txn = self.graphStore.getAddNymTxn(nym)
-        txnId = self.genTxnId(request.identifier, request.reqId)
-        # TODO: We should have a single JSON encoder which does the
-        # encoding for us, like sorting by keys, handling datetime objects.
-        result = {f.IDENTIFIER.nm: request.identifier,
-                  f.REQ_ID.nm: request.reqId,
-                  DATA: json.dumps(txn, sort_keys=True) if txn else None,
-                  TXN_ID: txnId
-                  }
-        result.update(request.operation)
-        self.transmitToClient(Reply(result), frm)
-
-    def processGetTxnReq(self, request: Request, frm: str):
-        nym = request.operation[TARGET_NYM]
-        origin = request.identifier
-        if nym != origin:
-            # TODO not sure this is correct; why does it matter?
-            msg = ""You can only receive transactions for yourself""
-            self.transmitToClient(RequestNack(*request.key, msg), frm)
-        else:
-            self.transmitToClient(RequestAck(*request.key), frm)
-            data = request.operation.get(DATA)
-            addNymTxn = self.graphStore.getAddNymTxn(origin)
-            txnIds = [addNymTxn[TXN_ID], ] + self.graphStore. \
-                getAddAttributeTxnIds(origin)
-            # If sending transactions to a user then should send user's
-            # trust anchor creation transaction also
-            if addNymTxn.get(ROLE) is None:
-                trustAnchorNymTxn = self.graphStore.getAddNymTxn(
-                    addNymTxn.get(f.IDENTIFIER.nm))
-                txnIds = [trustAnchorNymTxn[TXN_ID], ] + txnIds
-            # TODO: Remove this log statement
-            logger.debug(""{} getting replies for {}"".format(self, txnIds))
-            result = self.secondaryStorage.getReplies(*txnIds, seqNo=data)
-            txns = sorted(list(result.values()), key=itemgetter(F.seqNo.name))
-            lastTxn = str(txns[-1][F.seqNo.name]) if len(txns) > 0 else data
-            result = {
-                TXN_ID: self.genTxnId(
-                    request.identifier, request.reqId)
-            }
-            result.update(request.operation)
-            # TODO: We should have a single JSON encoder which does the
-            # encoding for us, like sorting by keys, handling datetime objects.
-            result[DATA] = json.dumps({
-                LAST_TXN: lastTxn,
-                TXNS: txns
-            }, default=dateTimeEncoding, sort_keys=True)
-            result.update({
-                f.IDENTIFIER.nm: request.identifier,
-                f.REQ_ID.nm: request.reqId,
-            })
-            self.transmitToClient(Reply(result), frm)
-
     def processGetSchemaReq(self, request: Request, frm: str):
-        issuerNym = request.operation[TARGET_NYM]
-        name = request.operation[DATA][NAME]
-        version = request.operation[DATA][VERSION]
-        schema = self.graphStore.getSchema(issuerNym, name, version)
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        result.update(request.operation)
-        result[DATA] = json.dumps(schema, sort_keys=True)
-        result.update({
+        self.transmitToClient(RequestAck(*request.key), frm)
+        authorDid = request.operation[TARGET_NYM]
+        schema, lastSeqNo = self.reqHandler.getSchema(
+            author=authorDid,
+            schemaName=(request.operation[DATA][NAME]),
+            schemaVersion=(request.operation[DATA][VERSION])
+        )
+        schema.update({ORIGIN: authorDid})
+        result = {**request.operation, **{
+            DATA: schema,
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+            f.SEQ_NO.nm: lastSeqNo
+        }}
         self.transmitToClient(Reply(result), frm)
 
     def processGetAttrsReq(self, request: Request, frm: str):
         self.transmitToClient(RequestAck(*request.key), frm)
         attrName = request.operation[RAW]
         nym = request.operation[TARGET_NYM]
-        attrWithSeqNo = self.graphStore.getRawAttrs(nym, attrName)
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        if attrWithSeqNo:
-            attr = {attrName: attrWithSeqNo[attrName][0]}
-            result[DATA] = json.dumps(attr, sort_keys=True)
-            result[F.seqNo.name] = attrWithSeqNo[attrName][1]
-        result.update(request.operation)
-        result.update({
+        attrValue, lastSeqNo = \
+            self.reqHandler.getAttr(did=nym, key=attrName)
+        result = {**request.operation, **{
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+        }}
+        if attrValue is not None:
+            attr = json.dumps({attrName: attrValue}, sort_keys=True)
+            result[DATA] = attr
+            result[f.SEQ_NO.nm] = lastSeqNo
         self.transmitToClient(Reply(result), frm)
 
     def processGetIssuerKeyReq(self, request: Request, frm: str):
         self.transmitToClient(RequestAck(*request.key), frm)
-        keys = self.graphStore.getIssuerKeys(request.operation[ORIGIN],
-                                             request.operation[REF])
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        result.update(request.operation)
-        result[DATA] = json.dumps(keys, sort_keys=True)
-        result.update({
+        keys, lastSeqNo = self.reqHandler.getIssuerKey(
+            author=request.operation[ORIGIN],
+            schemaSeqNo=request.operation[REF]
+        )
+        result = {**request.operation, **{
+            DATA: keys,
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+            f.SEQ_NO.nm: lastSeqNo
+        }}
         self.transmitToClient(Reply(result), frm)
 
     def processRequest(self, request: Request, frm: str):
         if request.operation[TXN_TYPE] == GET_NYM:
-            self.processGetNymReq(request, frm)
+            self.transmitToClient(RequestAck(*request.key), frm)
+            result = self.reqHandler.handleGetNymReq(request, frm)
+            self.transmitToClient(Reply(result), frm)
+        # TODO: Come back to it
         elif request.operation[TXN_TYPE] == GET_TXNS:
-            self.processGetTxnReq(request, frm)
+            # self.processGetTxnReq(request, frm)",678,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112112724,https://github.com/hyperledger/indy-node/pull/101#discussion_r112112724,lovesh
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"Only for tests, its done when you clean directory of the node",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 04:16:36,112112855,"@@ -241,16 +241,10 @@ def getUpgrader(self):
         return TestUpgrader(self.id, self.name, self.dataLocation, self.config,
                             self.configLedger)
 
-    def _getOrientDbStore(self, name, dbType):
-        if not hasattr(self, '_orientDbStore'):
-            self._orientDbStore = orientdb_store.createOrientDbInMemStore(
-                self.config, name, dbType)
-        return self._orientDbStore
-
     def onStopping(self, *args, **kwargs):
         if self.cleanupOnStopping:
             self.cleanupDataLocation()
-        self.graphStore.store.close()
+        # self.graphStore.store.close()",33,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112112855,https://github.com/hyperledger/indy-node/pull/101#discussion_r112112855,lovesh
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"It will just go over the pool ledger and this happens only in case of succssfull code upgrade but yes, it can be improved",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 12:24:39,112186829,"@@ -10,6 +10,7 @@ class NodeAuthNr(NaclAuthNr):
     def __init__(self, ledger: Ledger):
         self.ledger = ledger
 
+    # TODO: This is not right, what if verkey changes?",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112186829,https://github.com/hyperledger/indy-node/pull/101#discussion_r112186829,lovesh
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"We should avoid leaking details of base classes, its a request handler and in most cases we should not bother the devs with details like its base class, also people dont need to use Plenum's pool request handler unless they are extending it",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 12:26:36,112187269,"@@ -0,0 +1,346 @@
+import json
+from binascii import unhexlify
+from typing import List
+from hashlib import sha256
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest, UnknownIdentifier
+from plenum.common.constants import TXN_TYPE, TARGET_NYM, RAW, ENC, HASH, \
+    VERKEY, DATA, NAME, VERSION
+from plenum.common.types import f
+from plenum.common.util import check_endpoint_valid
+from plenum.server.domain_req_handler import DomainRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NYM, ROLE, ATTRIB, ENDPOINT, SCHEMA, \
+    ISSUER_KEY, REF
+from sovrin_common.types import Request
+from stp_core.common.log import getlogger
+from stp_core.network.exceptions import EndpointException
+
+
+logger = getlogger()
+
+
+class DomainReqHandler(PHandler):",24,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112187269,https://github.com/hyperledger/indy-node/pull/101#discussion_r112187269,lovesh
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"We should avoid leaking details of base classes, its a request handler and in most cases we should not bother the devs with details like its base class, also people dont need to use Plenum's pool request handler unless they are extending it",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 12:26:52,112187322,"@@ -0,0 +1,64 @@
+from copy import deepcopy
+
+from ledger.serializers.json_serializer import JsonSerializer
+from plenum.common.constants import TARGET_NYM, DATA, ALIAS, SERVICES
+
+from plenum.common.ledger import Ledger
+from plenum.persistence.pruning_state import PruningState
+from plenum.server.pool_req_handler import PoolRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NODE
+from sovrin_node.persistence.idr_cache import IdrCache
+
+
+class PoolRequestHandler(PHandler):",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112187322,https://github.com/hyperledger/indy-node/pull/101#discussion_r112187322,lovesh
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"Please use the full name for variables. it's not a common abbreviation, and not clear for the reader of the code",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 15:34:46,112236750,"@@ -0,0 +1,201 @@
+import os
+
+from collections import OrderedDict
+import rlp
+
+from plenum.common.constants import VERKEY, TRUSTEE, STEWARD
+from plenum.common.types import f
+from plenum.persistence.kv_store_leveldb import KVStoreLeveldb
+from sovrin_common.constants import ROLE, TGB, TRUST_ANCHOR
+from stp_core.common.log import getlogger
+
+logger = getlogger()
+
+
+class IdrCache:
+    """"""
+    A cache to store a role and verkey of an identifier, the db is only used to
+    store committed data, uncommitted data goes to memory
+    The key is the identifier and value is a pack of fields
+    The first byte indicates whether the identifier has a guardian or not,
+    if it has then the next few bytes will be the guardian's identifier
+    otherwise they will be the verkey. Then there is delimiter byte after which
+    the value of role starts. eg.
+    Value in case of guardian: '\2<guardian's DID>\0<role of the DID>'
+    Value in case of no guardian: '\1<verkey of the DID>\0<role of the DID>'
+    """"""
+
+    unsetVerkey = b'-'
+
+    def __init__(self, basedir: str, name):
+        logger.debug('Initializing identity cache {} at {}'
+                     .format(name, basedir))
+        self._basedir = basedir
+        self._name = name
+        self._db = None
+        self.open()
+        # OrderedDict where key is the state root after batch and value is a
+        # dictionary similar to cache which can be queried like the
+        # database, i.e `self._db`. Keys (state roots are purged) when they
+        # get committed or reverted.
+        self.unCommitted = OrderedDict() # type: Dict[bytes, OrderedDict]
+
+        # Relevant NYMs operation done in current batch, in order
+        self.currentBatchOps = []   # type: List[Tuple]
+
+    @staticmethod
+    def encodeVerkey(verkey):
+        if verkey is None:
+            return IdrCache.unsetVerkey
+        else:
+            if isinstance(verkey, str):
+                return verkey.encode()
+            return verkey
+
+    @staticmethod
+    def decodeVerkey(verkey):
+        if verkey == IdrCache.unsetVerkey:
+            return None
+        else:
+            return verkey.decode()
+
+    @staticmethod
+    def getPrefixAndIv(guardian=None, verkey=None):
+        iv = guardian if guardian else verkey
+        prefix = b'1' if guardian else b'0'
+        return prefix, iv
+
+    @staticmethod
+    def packIdrValue(ta=None, role=None, verkey=None):
+        # prefix, iv = IdrCache.getPrefixAndIv(guardian, verkey)
+        if ta is None:",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112236750,https://github.com/hyperledger/indy-node/pull/101#discussion_r112236750,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,What details do we expose by renaming? It's easy to make a mistake and import a wrong class (from Plenum) if they have the same name.,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 15:37:23,112237497,"@@ -0,0 +1,346 @@
+import json
+from binascii import unhexlify
+from typing import List
+from hashlib import sha256
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest, UnknownIdentifier
+from plenum.common.constants import TXN_TYPE, TARGET_NYM, RAW, ENC, HASH, \
+    VERKEY, DATA, NAME, VERSION
+from plenum.common.types import f
+from plenum.common.util import check_endpoint_valid
+from plenum.server.domain_req_handler import DomainRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NYM, ROLE, ATTRIB, ENDPOINT, SCHEMA, \
+    ISSUER_KEY, REF
+from sovrin_common.types import Request
+from stp_core.common.log import getlogger
+from stp_core.network.exceptions import EndpointException
+
+
+logger = getlogger()
+
+
+class DomainReqHandler(PHandler):",24,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112237497,https://github.com/hyperledger/indy-node/pull/101#discussion_r112237497,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,Does it mean that GET_TXNS doesn't work now?,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 15:38:38,112237818,"@@ -439,120 +317,62 @@ def defaultNodeAuthNr(self):
         c += self.upgrader.service()
         return c
 
-    def processGetNymReq(self, request: Request, frm: str):
-        self.transmitToClient(RequestAck(*request.key), frm)
-        nym = request.operation[TARGET_NYM]
-        txn = self.graphStore.getAddNymTxn(nym)
-        txnId = self.genTxnId(request.identifier, request.reqId)
-        # TODO: We should have a single JSON encoder which does the
-        # encoding for us, like sorting by keys, handling datetime objects.
-        result = {f.IDENTIFIER.nm: request.identifier,
-                  f.REQ_ID.nm: request.reqId,
-                  DATA: json.dumps(txn, sort_keys=True) if txn else None,
-                  TXN_ID: txnId
-                  }
-        result.update(request.operation)
-        self.transmitToClient(Reply(result), frm)
-
-    def processGetTxnReq(self, request: Request, frm: str):
-        nym = request.operation[TARGET_NYM]
-        origin = request.identifier
-        if nym != origin:
-            # TODO not sure this is correct; why does it matter?
-            msg = ""You can only receive transactions for yourself""
-            self.transmitToClient(RequestNack(*request.key, msg), frm)
-        else:
-            self.transmitToClient(RequestAck(*request.key), frm)
-            data = request.operation.get(DATA)
-            addNymTxn = self.graphStore.getAddNymTxn(origin)
-            txnIds = [addNymTxn[TXN_ID], ] + self.graphStore. \
-                getAddAttributeTxnIds(origin)
-            # If sending transactions to a user then should send user's
-            # trust anchor creation transaction also
-            if addNymTxn.get(ROLE) is None:
-                trustAnchorNymTxn = self.graphStore.getAddNymTxn(
-                    addNymTxn.get(f.IDENTIFIER.nm))
-                txnIds = [trustAnchorNymTxn[TXN_ID], ] + txnIds
-            # TODO: Remove this log statement
-            logger.debug(""{} getting replies for {}"".format(self, txnIds))
-            result = self.secondaryStorage.getReplies(*txnIds, seqNo=data)
-            txns = sorted(list(result.values()), key=itemgetter(F.seqNo.name))
-            lastTxn = str(txns[-1][F.seqNo.name]) if len(txns) > 0 else data
-            result = {
-                TXN_ID: self.genTxnId(
-                    request.identifier, request.reqId)
-            }
-            result.update(request.operation)
-            # TODO: We should have a single JSON encoder which does the
-            # encoding for us, like sorting by keys, handling datetime objects.
-            result[DATA] = json.dumps({
-                LAST_TXN: lastTxn,
-                TXNS: txns
-            }, default=dateTimeEncoding, sort_keys=True)
-            result.update({
-                f.IDENTIFIER.nm: request.identifier,
-                f.REQ_ID.nm: request.reqId,
-            })
-            self.transmitToClient(Reply(result), frm)
-
     def processGetSchemaReq(self, request: Request, frm: str):
-        issuerNym = request.operation[TARGET_NYM]
-        name = request.operation[DATA][NAME]
-        version = request.operation[DATA][VERSION]
-        schema = self.graphStore.getSchema(issuerNym, name, version)
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        result.update(request.operation)
-        result[DATA] = json.dumps(schema, sort_keys=True)
-        result.update({
+        self.transmitToClient(RequestAck(*request.key), frm)
+        authorDid = request.operation[TARGET_NYM]
+        schema, lastSeqNo = self.reqHandler.getSchema(
+            author=authorDid,
+            schemaName=(request.operation[DATA][NAME]),
+            schemaVersion=(request.operation[DATA][VERSION])
+        )
+        schema.update({ORIGIN: authorDid})
+        result = {**request.operation, **{
+            DATA: schema,
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+            f.SEQ_NO.nm: lastSeqNo
+        }}
         self.transmitToClient(Reply(result), frm)
 
     def processGetAttrsReq(self, request: Request, frm: str):
         self.transmitToClient(RequestAck(*request.key), frm)
         attrName = request.operation[RAW]
         nym = request.operation[TARGET_NYM]
-        attrWithSeqNo = self.graphStore.getRawAttrs(nym, attrName)
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        if attrWithSeqNo:
-            attr = {attrName: attrWithSeqNo[attrName][0]}
-            result[DATA] = json.dumps(attr, sort_keys=True)
-            result[F.seqNo.name] = attrWithSeqNo[attrName][1]
-        result.update(request.operation)
-        result.update({
+        attrValue, lastSeqNo = \
+            self.reqHandler.getAttr(did=nym, key=attrName)
+        result = {**request.operation, **{
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+        }}
+        if attrValue is not None:
+            attr = json.dumps({attrName: attrValue}, sort_keys=True)
+            result[DATA] = attr
+            result[f.SEQ_NO.nm] = lastSeqNo
         self.transmitToClient(Reply(result), frm)
 
     def processGetIssuerKeyReq(self, request: Request, frm: str):
         self.transmitToClient(RequestAck(*request.key), frm)
-        keys = self.graphStore.getIssuerKeys(request.operation[ORIGIN],
-                                             request.operation[REF])
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        result.update(request.operation)
-        result[DATA] = json.dumps(keys, sort_keys=True)
-        result.update({
+        keys, lastSeqNo = self.reqHandler.getIssuerKey(
+            author=request.operation[ORIGIN],
+            schemaSeqNo=request.operation[REF]
+        )
+        result = {**request.operation, **{
+            DATA: keys,
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+            f.SEQ_NO.nm: lastSeqNo
+        }}
         self.transmitToClient(Reply(result), frm)
 
     def processRequest(self, request: Request, frm: str):
         if request.operation[TXN_TYPE] == GET_NYM:
-            self.processGetNymReq(request, frm)
+            self.transmitToClient(RequestAck(*request.key), frm)
+            result = self.reqHandler.handleGetNymReq(request, frm)
+            self.transmitToClient(Reply(result), frm)
+        # TODO: Come back to it
         elif request.operation[TXN_TYPE] == GET_TXNS:
-            self.processGetTxnReq(request, frm)
+            # self.processGetTxnReq(request, frm)",678,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112237818,https://github.com/hyperledger/indy-node/pull/101#discussion_r112237818,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,What details do we expose by renaming? It's easy to make a mistake and import a wrong class (from Plenum) if they have the same name.,40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-19 15:39:20,112238017,"@@ -0,0 +1,64 @@
+from copy import deepcopy
+
+from ledger.serializers.json_serializer import JsonSerializer
+from plenum.common.constants import TARGET_NYM, DATA, ALIAS, SERVICES
+
+from plenum.common.ledger import Ledger
+from plenum.persistence.pruning_state import PruningState
+from plenum.server.pool_req_handler import PoolRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NODE
+from sovrin_node.persistence.idr_cache import IdrCache
+
+
+class PoolRequestHandler(PHandler):",,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112238017,https://github.com/hyperledger/indy-node/pull/101#discussion_r112238017,ashcherbakov
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"You are telling a dev that this is a SovrinRequestHandler and hinting that there is another handler, a dev cannot use that handler anywhere unless he gets rid of this and creates a new one from the base. Why do all that? Mistake when, while creating a new handler and replacing the current one? That is extremely rare",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-21 13:23:21,112685838,"@@ -0,0 +1,346 @@
+import json
+from binascii import unhexlify
+from typing import List
+from hashlib import sha256
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest, UnknownIdentifier
+from plenum.common.constants import TXN_TYPE, TARGET_NYM, RAW, ENC, HASH, \
+    VERKEY, DATA, NAME, VERSION
+from plenum.common.types import f
+from plenum.common.util import check_endpoint_valid
+from plenum.server.domain_req_handler import DomainRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NYM, ROLE, ATTRIB, ENDPOINT, SCHEMA, \
+    ISSUER_KEY, REF
+from sovrin_common.types import Request
+from stp_core.common.log import getlogger
+from stp_core.network.exceptions import EndpointException
+
+
+logger = getlogger()
+
+
+class DomainReqHandler(PHandler):",24,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112685838,https://github.com/hyperledger/indy-node/pull/101#discussion_r112685838,lovesh
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"It did not work before either, its been inactive for quiet some time",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-21 13:24:45,112686083,"@@ -439,120 +317,62 @@ def defaultNodeAuthNr(self):
         c += self.upgrader.service()
         return c
 
-    def processGetNymReq(self, request: Request, frm: str):
-        self.transmitToClient(RequestAck(*request.key), frm)
-        nym = request.operation[TARGET_NYM]
-        txn = self.graphStore.getAddNymTxn(nym)
-        txnId = self.genTxnId(request.identifier, request.reqId)
-        # TODO: We should have a single JSON encoder which does the
-        # encoding for us, like sorting by keys, handling datetime objects.
-        result = {f.IDENTIFIER.nm: request.identifier,
-                  f.REQ_ID.nm: request.reqId,
-                  DATA: json.dumps(txn, sort_keys=True) if txn else None,
-                  TXN_ID: txnId
-                  }
-        result.update(request.operation)
-        self.transmitToClient(Reply(result), frm)
-
-    def processGetTxnReq(self, request: Request, frm: str):
-        nym = request.operation[TARGET_NYM]
-        origin = request.identifier
-        if nym != origin:
-            # TODO not sure this is correct; why does it matter?
-            msg = ""You can only receive transactions for yourself""
-            self.transmitToClient(RequestNack(*request.key, msg), frm)
-        else:
-            self.transmitToClient(RequestAck(*request.key), frm)
-            data = request.operation.get(DATA)
-            addNymTxn = self.graphStore.getAddNymTxn(origin)
-            txnIds = [addNymTxn[TXN_ID], ] + self.graphStore. \
-                getAddAttributeTxnIds(origin)
-            # If sending transactions to a user then should send user's
-            # trust anchor creation transaction also
-            if addNymTxn.get(ROLE) is None:
-                trustAnchorNymTxn = self.graphStore.getAddNymTxn(
-                    addNymTxn.get(f.IDENTIFIER.nm))
-                txnIds = [trustAnchorNymTxn[TXN_ID], ] + txnIds
-            # TODO: Remove this log statement
-            logger.debug(""{} getting replies for {}"".format(self, txnIds))
-            result = self.secondaryStorage.getReplies(*txnIds, seqNo=data)
-            txns = sorted(list(result.values()), key=itemgetter(F.seqNo.name))
-            lastTxn = str(txns[-1][F.seqNo.name]) if len(txns) > 0 else data
-            result = {
-                TXN_ID: self.genTxnId(
-                    request.identifier, request.reqId)
-            }
-            result.update(request.operation)
-            # TODO: We should have a single JSON encoder which does the
-            # encoding for us, like sorting by keys, handling datetime objects.
-            result[DATA] = json.dumps({
-                LAST_TXN: lastTxn,
-                TXNS: txns
-            }, default=dateTimeEncoding, sort_keys=True)
-            result.update({
-                f.IDENTIFIER.nm: request.identifier,
-                f.REQ_ID.nm: request.reqId,
-            })
-            self.transmitToClient(Reply(result), frm)
-
     def processGetSchemaReq(self, request: Request, frm: str):
-        issuerNym = request.operation[TARGET_NYM]
-        name = request.operation[DATA][NAME]
-        version = request.operation[DATA][VERSION]
-        schema = self.graphStore.getSchema(issuerNym, name, version)
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        result.update(request.operation)
-        result[DATA] = json.dumps(schema, sort_keys=True)
-        result.update({
+        self.transmitToClient(RequestAck(*request.key), frm)
+        authorDid = request.operation[TARGET_NYM]
+        schema, lastSeqNo = self.reqHandler.getSchema(
+            author=authorDid,
+            schemaName=(request.operation[DATA][NAME]),
+            schemaVersion=(request.operation[DATA][VERSION])
+        )
+        schema.update({ORIGIN: authorDid})
+        result = {**request.operation, **{
+            DATA: schema,
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+            f.SEQ_NO.nm: lastSeqNo
+        }}
         self.transmitToClient(Reply(result), frm)
 
     def processGetAttrsReq(self, request: Request, frm: str):
         self.transmitToClient(RequestAck(*request.key), frm)
         attrName = request.operation[RAW]
         nym = request.operation[TARGET_NYM]
-        attrWithSeqNo = self.graphStore.getRawAttrs(nym, attrName)
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        if attrWithSeqNo:
-            attr = {attrName: attrWithSeqNo[attrName][0]}
-            result[DATA] = json.dumps(attr, sort_keys=True)
-            result[F.seqNo.name] = attrWithSeqNo[attrName][1]
-        result.update(request.operation)
-        result.update({
+        attrValue, lastSeqNo = \
+            self.reqHandler.getAttr(did=nym, key=attrName)
+        result = {**request.operation, **{
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+        }}
+        if attrValue is not None:
+            attr = json.dumps({attrName: attrValue}, sort_keys=True)
+            result[DATA] = attr
+            result[f.SEQ_NO.nm] = lastSeqNo
         self.transmitToClient(Reply(result), frm)
 
     def processGetIssuerKeyReq(self, request: Request, frm: str):
         self.transmitToClient(RequestAck(*request.key), frm)
-        keys = self.graphStore.getIssuerKeys(request.operation[ORIGIN],
-                                             request.operation[REF])
-        result = {
-            TXN_ID: self.genTxnId(
-                request.identifier, request.reqId)
-        }
-        result.update(request.operation)
-        result[DATA] = json.dumps(keys, sort_keys=True)
-        result.update({
+        keys, lastSeqNo = self.reqHandler.getIssuerKey(
+            author=request.operation[ORIGIN],
+            schemaSeqNo=request.operation[REF]
+        )
+        result = {**request.operation, **{
+            DATA: keys,
             f.IDENTIFIER.nm: request.identifier,
             f.REQ_ID.nm: request.reqId,
-        })
+            f.SEQ_NO.nm: lastSeqNo
+        }}
         self.transmitToClient(Reply(result), frm)
 
     def processRequest(self, request: Request, frm: str):
         if request.operation[TXN_TYPE] == GET_NYM:
-            self.processGetNymReq(request, frm)
+            self.transmitToClient(RequestAck(*request.key), frm)
+            result = self.reqHandler.handleGetNymReq(request, frm)
+            self.transmitToClient(Reply(result), frm)
+        # TODO: Come back to it
         elif request.operation[TXN_TYPE] == GET_TXNS:
-            self.processGetTxnReq(request, frm)
+            # self.processGetTxnReq(request, frm)",678,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112686083,https://github.com/hyperledger/indy-node/pull/101#discussion_r112686083,lovesh
https://github.com/hyperledger/indy-node/pull/101,https://github.com/hyperledger/indy-node/pull/101,"Plenum and Sovrin are separate products. If RequestHandler is part of Plenum's API, then dev must know that there are different implementations.
I don't think it's good to have parent and child class have the same name",40a2eaba8d83bb0d86f02161eec21ccee0fede95,2017-04-21 17:24:05,112737749,"@@ -0,0 +1,346 @@
+import json
+from binascii import unhexlify
+from typing import List
+from hashlib import sha256
+
+from plenum.common.exceptions import InvalidClientRequest, \
+    UnauthorizedClientRequest, UnknownIdentifier
+from plenum.common.constants import TXN_TYPE, TARGET_NYM, RAW, ENC, HASH, \
+    VERKEY, DATA, NAME, VERSION
+from plenum.common.types import f
+from plenum.common.util import check_endpoint_valid
+from plenum.server.domain_req_handler import DomainRequestHandler as PHandler
+from sovrin_common.auth import Authoriser
+from sovrin_common.constants import NYM, ROLE, ATTRIB, ENDPOINT, SCHEMA, \
+    ISSUER_KEY, REF
+from sovrin_common.types import Request
+from stp_core.common.log import getlogger
+from stp_core.network.exceptions import EndpointException
+
+
+logger = getlogger()
+
+
+class DomainReqHandler(PHandler):",24,2017-05-12 08:35:04,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/112737749,https://github.com/hyperledger/indy-node/pull/101#discussion_r112737749,ashcherbakov
https://github.com/hyperledger/indy-node/pull/79,https://github.com/hyperledger/indy-node/pull/79,"Have we updated any human instructions (e.g., in Getting Started) and any bash scripts that we've written that might call this command?",397064dc5ac10e54fcd01a67b86ce1958bf7e96d,2017-04-01 04:51:57,109277701,"@@ -42,13 +44,14 @@
 from sovrin_node.server.node_authn import NodeAuthNr
 from sovrin_node.server.pool_manager import HasPoolManager
 from sovrin_node.server.upgrader import Upgrader
+from stp_core.network.exceptions import EndpointException
 
 logger = getlogger()
 jsonSerz = JsonSerializer()
 
 
 class Node(PlenumNode, HasPoolManager):
-    keygenScript = ""init_sovrin_raet_keep""
+    keygenScript = ""init_sovrin_keys""",30,2017-04-02 05:06:06,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/109277701,https://github.com/hyperledger/indy-node/pull/79#discussion_r109277701,dhh1128
https://github.com/hyperledger/indy-node/pull/77,https://github.com/hyperledger/indy-node/pull/77,Shouldn't we make a separate test for this case? Something like blacklistedTrusteeCanNotBlacklistSteward ,b8c0371d2f04e86c966b8f46be67e97450bf1f64,2017-03-31 08:02:44,109107661,"@@ -81,9 +87,12 @@ def testTrustAnchorSuspensionByTrustee(looper, anotherTrustee, anotherTrustAncho
 
 
 def testTrusteeSuspensionByTrustee(looper, trustee, trusteeWallet,
-                                   anotherTrustee):
-    _, trWallet = anotherTrustee
+                                   anotherTrustee, anotherSteward1):
+    trClient, trWallet = anotherTrustee
     suspendRole(looper, trustee, trusteeWallet, trWallet.defaultId)
+    _, sWallet = anotherSteward1
+    with pytest.raises(AssertionError):",23,2017-03-31 08:02:45,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/109107661,https://github.com/hyperledger/indy-node/pull/77#discussion_r109107661,keenondrums
https://github.com/hyperledger/indy-node/pull/77,https://github.com/hyperledger/indy-node/pull/77,"This check is testing whether the suspension really took effect, `suspendRole` is just testing whether the suspension transaction could be made successfully",b8c0371d2f04e86c966b8f46be67e97450bf1f64,2017-03-31 08:08:29,109108473,"@@ -81,9 +87,12 @@ def testTrustAnchorSuspensionByTrustee(looper, anotherTrustee, anotherTrustAncho
 
 
 def testTrusteeSuspensionByTrustee(looper, trustee, trusteeWallet,
-                                   anotherTrustee):
-    _, trWallet = anotherTrustee
+                                   anotherTrustee, anotherSteward1):
+    trClient, trWallet = anotherTrustee
     suspendRole(looper, trustee, trusteeWallet, trWallet.defaultId)
+    _, sWallet = anotherSteward1
+    with pytest.raises(AssertionError):",23,2017-03-31 08:16:32,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/109108473,https://github.com/hyperledger/indy-node/pull/77#discussion_r109108473,lovesh
https://github.com/hyperledger/indy-node/pull/61,https://github.com/hyperledger/indy-node/pull/61,why are these commented out?,b6570cf2f64e886bfa45206e03d2f2d37818fbec,2017-03-22 02:55:28,107323637,"@@ -161,8 +160,8 @@ def testReplayLedger(addNymTxn, addedRawAttribute, submittedPublicKeys,
     nodeToStop.cleanupOnStopping = False
     nodeToStop.stop()
     looper.removeProdable(nodeToStop)
-    client = nodeToStop.graphStore.client
-    client.db_drop(client._connection.db_opened)
+    #client = nodeToStop.graphStore.client",25,2017-03-22 11:28:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/107323637,https://github.com/hyperledger/indy-node/pull/61#discussion_r107323637,dhh1128
https://github.com/hyperledger/indy-node/pull/61,https://github.com/hyperledger/indy-node/pull/61,"Actually nodeToStop.stop() already drops the database, so I think the commented out lines are not needed (I had a failing test with this lines on Ubuntu).
The ticket also doesn't work on Windows. There is a ticket SOV-781 about failing of this test, I pu some comments there.",b6570cf2f64e886bfa45206e03d2f2d37818fbec,2017-03-22 10:53:25,107383247,"@@ -161,8 +160,8 @@ def testReplayLedger(addNymTxn, addedRawAttribute, submittedPublicKeys,
     nodeToStop.cleanupOnStopping = False
     nodeToStop.stop()
     looper.removeProdable(nodeToStop)
-    client = nodeToStop.graphStore.client
-    client.db_drop(client._connection.db_opened)
+    #client = nodeToStop.graphStore.client",25,2017-03-22 11:28:54,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/107383247,https://github.com/hyperledger/indy-node/pull/61#discussion_r107383247,ashcherbakov
https://github.com/hyperledger/indy-node/pull/57,https://github.com/hyperledger/indy-node/pull/57,Why this line is necessary?,a59a16c6bf60e7e725a8a9bb4c790ae119188df0,2017-03-20 11:21:26,106877915,"@@ -565,7 +569,12 @@ def storeTxnAndSendToClient(self, reply):
          client requests it.
         """"""
         result = reply.result
+        if result[TXN_TYPE] in (SCHEMA, ISSUER_KEY):
+            result = deepcopy(result)",,2017-03-21 04:38:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/106877915,https://github.com/hyperledger/indy-node/pull/57#discussion_r106877915,rajeshkalaria80
https://github.com/hyperledger/indy-node/pull/57,https://github.com/hyperledger/indy-node/pull/57,@rajeshkalaria80 deepcopy can be refactored. I will use result as it is. But I need `if` condition because I need to serialize data with txn type `schema` or `issuer_key`.,a59a16c6bf60e7e725a8a9bb4c790ae119188df0,2017-03-21 04:28:56,107071656,"@@ -565,7 +569,12 @@ def storeTxnAndSendToClient(self, reply):
          client requests it.
         """"""
         result = reply.result
+        if result[TXN_TYPE] in (SCHEMA, ISSUER_KEY):
+            result = deepcopy(result)",,2017-03-21 04:38:08,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/107071656,https://github.com/hyperledger/indy-node/pull/57#discussion_r107071656,pradeep1991singh
https://github.com/hyperledger/indy-node/pull/52,https://github.com/hyperledger/indy-node/pull/52,Note my hesitation about the use of the TGB role.,20247bed5bd7d0213855fd009413f2985dc2a415,2017-03-13 18:29:55,105737067,"@@ -1,12 +1,11 @@
 import pytest
 
 from plenum.common.eventually import eventually
+from plenum.common.txn import TRUSTEE, TGB, STEWARD, TRUST_ANCHOR",4,2017-03-14 11:52:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/105737067,https://github.com/hyperledger/indy-node/pull/52#discussion_r105737067,dhh1128
https://github.com/hyperledger/indy-node/pull/52,https://github.com/hyperledger/indy-node/pull/52,"Discussed with Lovesh:
it was discussed with Jason sometime, and approved by him. An example why we need it: sending POOL_UPGRADE txn.",20247bed5bd7d0213855fd009413f2985dc2a415,2017-03-14 11:02:41,105878230,"@@ -1,12 +1,11 @@
 import pytest
 
 from plenum.common.eventually import eventually
+from plenum.common.txn import TRUSTEE, TGB, STEWARD, TRUST_ANCHOR",4,2017-03-14 11:52:44,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/105878230,https://github.com/hyperledger/indy-node/pull/52#discussion_r105878230,ashcherbakov
https://github.com/hyperledger/indy-node/pull/42,https://github.com/hyperledger/indy-node/pull/42,"`dir` is a reserved keyword, avoid using it",267204696109172cc55ae2074092865aec51f4bc,2017-02-20 17:06:55,102060873,"@@ -0,0 +1,77 @@
+#!/usr/bin/env python3
+
+import shutil
+import os
+import pyorient
+import argparse
+import re
+
+
+def pathList(*pathes):
+    return {os.path.expanduser(path) for path in pathes}
+
+TARGET_DIRS = pathList(
+    ""~/.sovrin"",
+    ""~/.plenum""
+)
+
+WHITE_LIST = pathList(
+    ""~/.sovrin/sovrin_config.py"",
+    ""~/.plenum/plenum_config.py"",
+    ""~/.sovrin/.*/role"",
+    ""~/.plenum/.*/role"",
+    ""~/.sovrin/.*log""
+)
+
+ORIENTDB_HOST = ""localhost""
+ORIENTDB_PORT = 2424
+ORIENTDB_USER = ""root""
+ORIENTDB_PASSWORD = ""password""
+
+
+def clean_orientdb():
+    client = pyorient.OrientDB(ORIENTDB_HOST, ORIENTDB_PORT)
+    client.connect(ORIENTDB_USER, ORIENTDB_PASSWORD)
+    names = [n for n in client.db_list().oRecordData['databases'].keys()]
+    for nm in names:
+        try:
+            client.db_drop(nm)
+        except:
+            continue
+
+
+def clean_files(full):
+    if full:
+        for dir in TARGET_DIRS:
+            if os.path.exists(dir):
+                shutil.rmtree(dir)
+        return
+
+    files_to_keep = [re.compile(pattern) for pattern in WHITE_LIST]
+    def isOk(path):
+         return any(pattern.match(path) for pattern in files_to_keep)
+
+    for dir in TARGET_DIRS:",54,2017-02-20 17:21:23,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/102060873,https://github.com/hyperledger/indy-node/pull/42#discussion_r102060873,lovesh
https://github.com/hyperledger/indy-node/pull/16,https://github.com/hyperledger/indy-node/pull/16,Why do you want to return the line endings? We are not using it anyway. I see its being used in `__load` which is incorrect? Can you please remove it from there?,b77a0775255d58381124c1f17867bca4a503e8a7,2017-02-02 05:36:32,99055206,"@@ -58,7 +58,7 @@ def __append(self, type, when, version) -> None:
         now = datetime.utcnow()
         event = (now, type, when, version)
 
-        with open(self.__filePath, mode=""a+"") as file:
+        with open(self.__filePath, mode=""a+"", newline="""") as file:",5,2017-02-02 05:37:37,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/99055206,https://github.com/hyperledger/indy-node/pull/16#discussion_r99055206,lovesh
https://github.com/hyperledger/indy-node/pull/16,https://github.com/hyperledger/indy-node/pull/16,"Before this fix:
Dialect.lineterminator is '\r\n' for csv.writer by default (dialect='excel') while newline parameter of open function is None by default.
From the doc of open function:
""When writing output to the stream, if newline is None, any '\n' characters written are translated to the system default line separator, os.linesep. If newline is '' or '\n', no translation takes place.""
So '\n' character itself was translated to '\r\n' on Windows. All this produced the sequences '\r\r\n' for newlines. When reading, such a sequence was interpreted as two new lines, so empty lines appeared. Attempts to parse these empty lines as events failed.

There are posts about this issue:
http://stackoverflow.com/questions/3191528/csv-in-python-adding-an-extra-carriage-return
http://stackoverflow.com/questions/1170214/python-2-csv-writer-produces-wrong-line-terminator-on-windows

If we use newline='' for open function when writing then '\n' is written ""as is"". Thus with Dialect.lineterminator being '\r\n', the new lines are written as '\r\n' and later are correctly interpreted when reading.

In Python 3 documentation the recommended ways for opening files for csv.reader and csv.writer are with newline=''. Please see:
https://docs.python.org/3/library/csv.html",b77a0775255d58381124c1f17867bca4a503e8a7,2017-02-02 10:36:56,99091852,"@@ -58,7 +58,7 @@ def __append(self, type, when, version) -> None:
         now = datetime.utcnow()
         event = (now, type, when, version)
 
-        with open(self.__filePath, mode=""a+"") as file:
+        with open(self.__filePath, mode=""a+"", newline="""") as file:",5,2017-02-02 10:37:09,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/99091852,https://github.com/hyperledger/indy-node/pull/16#discussion_r99091852,spivachuk
https://github.com/hyperledger/indy-node/pull/16,https://github.com/hyperledger/indy-node/pull/16,@spivachuk Thanks for correcting me. ,b77a0775255d58381124c1f17867bca4a503e8a7,2017-02-02 10:45:16,99093372,"@@ -58,7 +58,7 @@ def __append(self, type, when, version) -> None:
         now = datetime.utcnow()
         event = (now, type, when, version)
 
-        with open(self.__filePath, mode=""a+"") as file:
+        with open(self.__filePath, mode=""a+"", newline="""") as file:",5,2017-02-02 10:45:16,https://api.github.com/repos/hyperledger/indy-node/pulls/comments/99093372,https://github.com/hyperledger/indy-node/pull/16#discussion_r99093372,lovesh
